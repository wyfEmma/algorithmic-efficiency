python3 submission_runner.py --framework=jax --workload=imagenet_vit --submission_path=prize_qualification_baselines/self_tuning/jax_nadamw_full_budget.py --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=prize_qualification_self_tuning/study_2 --overwrite=true --save_checkpoints=false --rng_seed=2402465797 --max_global_steps=559998 --imagenet_v2_data_dir=/data/imagenet/jax --tuning_ruleset=self 2>&1 | tee -a /logs/imagenet_vit_jax_03-02-2024-11-06-03.log
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0302 11:06:25.645311 140077943854912 logger_utils.py:76] Creating experiment directory at /experiment_runs/prize_qualification_self_tuning/study_2/imagenet_vit_jax.
I0302 11:06:26.656783 140077943854912 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host CUDA Interpreter
I0302 11:06:26.657699 140077943854912 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0302 11:06:26.657866 140077943854912 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0302 11:06:27.593044 140077943854912 submission_runner.py:605] Creating directory at /experiment_runs/prize_qualification_self_tuning/study_2/imagenet_vit_jax/trial_1.
I0302 11:06:27.794068 140077943854912 submission_runner.py:206] Initializing dataset.
I0302 11:06:27.810265 140077943854912 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:06:27.820492 140077943854912 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:06:28.204548 140077943854912 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:06:36.585783 140077943854912 submission_runner.py:213] Initializing model.
I0302 11:06:45.537084 140077943854912 submission_runner.py:255] Initializing optimizer.
I0302 11:06:46.530874 140077943854912 submission_runner.py:262] Initializing metrics bundle.
I0302 11:06:46.531093 140077943854912 submission_runner.py:280] Initializing checkpoint and logger.
I0302 11:06:46.532073 140077943854912 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification_self_tuning/study_2/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0302 11:06:46.532217 140077943854912 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification_self_tuning/study_2/imagenet_vit_jax/trial_1/meta_data_0.json.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0302 11:06:46.875368 140077943854912 logger_utils.py:220] Unable to record git information. Continuing without it.
I0302 11:06:47.185521 140077943854912 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification_self_tuning/study_2/imagenet_vit_jax/trial_1/flags_0.json.
I0302 11:06:47.194914 140077943854912 submission_runner.py:314] Starting training loop.
I0302 11:07:29.195873 139916002481920 logging_writer.py:48] [0] global_step=0, grad_norm=0.3873291313648224, loss=6.9077558517456055
I0302 11:07:29.214296 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:07:29.415285 140077943854912 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:07:29.424841 140077943854912 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:07:29.508405 140077943854912 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:07:46.860716 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:07:46.872205 140077943854912 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:07:46.889460 140077943854912 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:07:46.959677 140077943854912 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:08:04.343565 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:08:04.351377 140077943854912 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0302 11:08:04.358506 140077943854912 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0302 11:08:04.410260 140077943854912 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0302 11:08:09.698687 140077943854912 submission_runner.py:411] Time since start: 82.50s, 	Step: 1, 	{'train/accuracy': 0.0010351561941206455, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 42.01926302909851, 'total_duration': 82.50370907783508, 'accumulated_submission_time': 42.01926302909851, 'accumulated_eval_time': 40.48432898521423, 'accumulated_logging_time': 0}
I0302 11:08:09.716651 139881716119296 logging_writer.py:48] [1] accumulated_eval_time=40.484329, accumulated_logging_time=0, accumulated_submission_time=42.019263, global_step=1, preemption_count=0, score=42.019263, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=82.503709, train/accuracy=0.001035, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0302 11:09:12.112701 139915413149440 logging_writer.py:48] [100] global_step=100, grad_norm=0.4730006158351898, loss=6.877213478088379
I0302 11:09:53.641453 139915421542144 logging_writer.py:48] [200] global_step=200, grad_norm=0.6493788957595825, loss=6.746747970581055
I0302 11:10:37.365556 139915413149440 logging_writer.py:48] [300] global_step=300, grad_norm=0.8903814554214478, loss=6.633247375488281
I0302 11:11:21.207663 139915421542144 logging_writer.py:48] [400] global_step=400, grad_norm=0.9373462796211243, loss=6.564476490020752
I0302 11:12:05.093138 139915413149440 logging_writer.py:48] [500] global_step=500, grad_norm=1.0129204988479614, loss=6.465884208679199
I0302 11:12:48.625185 139915421542144 logging_writer.py:48] [600] global_step=600, grad_norm=1.0467463731765747, loss=6.328161239624023
I0302 11:13:32.218626 139915413149440 logging_writer.py:48] [700] global_step=700, grad_norm=1.380800485610962, loss=6.767184734344482
I0302 11:14:15.924045 139915421542144 logging_writer.py:48] [800] global_step=800, grad_norm=1.6040304899215698, loss=6.182112216949463
I0302 11:14:59.344231 139915413149440 logging_writer.py:48] [900] global_step=900, grad_norm=1.0841153860092163, loss=6.171712398529053
I0302 11:15:10.077293 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:15:21.588251 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:15:29.504147 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:15:31.130615 140077943854912 submission_runner.py:411] Time since start: 523.94s, 	Step: 926, 	{'train/accuracy': 0.03437500074505806, 'train/loss': 5.894576072692871, 'validation/accuracy': 0.032999999821186066, 'validation/loss': 5.924591541290283, 'validation/num_examples': 50000, 'test/accuracy': 0.026600001379847527, 'test/loss': 6.037107467651367, 'test/num_examples': 10000, 'score': 462.3217113018036, 'total_duration': 523.9356322288513, 'accumulated_submission_time': 462.3217113018036, 'accumulated_eval_time': 61.537635803222656, 'accumulated_logging_time': 0.027405261993408203}
I0302 11:15:31.147614 139881799980800 logging_writer.py:48] [926] accumulated_eval_time=61.537636, accumulated_logging_time=0.027405, accumulated_submission_time=462.321711, global_step=926, preemption_count=0, score=462.321711, test/accuracy=0.026600, test/loss=6.037107, test/num_examples=10000, total_duration=523.935632, train/accuracy=0.034375, train/loss=5.894576, validation/accuracy=0.033000, validation/loss=5.924592, validation/num_examples=50000
I0302 11:16:00.460631 139881808373504 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.12040114402771, loss=6.1545305252075195
I0302 11:16:42.340400 139881799980800 logging_writer.py:48] [1100] global_step=1100, grad_norm=1.2675163745880127, loss=6.137345314025879
I0302 11:17:25.988275 139881808373504 logging_writer.py:48] [1200] global_step=1200, grad_norm=1.47490656375885, loss=5.872961521148682
I0302 11:18:09.666773 139881799980800 logging_writer.py:48] [1300] global_step=1300, grad_norm=1.0675725936889648, loss=5.871349811553955
I0302 11:18:53.298221 139881808373504 logging_writer.py:48] [1400] global_step=1400, grad_norm=1.1035109758377075, loss=5.917361736297607
I0302 11:19:37.030743 139881799980800 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.1751494407653809, loss=5.804574966430664
I0302 11:20:20.605386 139881808373504 logging_writer.py:48] [1600] global_step=1600, grad_norm=1.1209980249404907, loss=5.838888645172119
I0302 11:21:04.266467 139881799980800 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.2167246341705322, loss=6.668437957763672
I0302 11:21:47.838698 139881808373504 logging_writer.py:48] [1800] global_step=1800, grad_norm=1.0309288501739502, loss=5.674610614776611
I0302 11:22:31.499078 139881799980800 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.9302019476890564, loss=5.774574279785156
I0302 11:22:31.514130 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:22:42.522423 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:22:50.371290 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:22:51.969452 140077943854912 submission_runner.py:411] Time since start: 964.77s, 	Step: 1901, 	{'train/accuracy': 0.0853906199336052, 'train/loss': 5.1030755043029785, 'validation/accuracy': 0.0809599980711937, 'validation/loss': 5.148300647735596, 'validation/num_examples': 50000, 'test/accuracy': 0.05990000441670418, 'test/loss': 5.397579193115234, 'test/num_examples': 10000, 'score': 882.624751329422, 'total_duration': 964.7744688987732, 'accumulated_submission_time': 882.624751329422, 'accumulated_eval_time': 81.992928981781, 'accumulated_logging_time': 0.0549311637878418}
I0302 11:22:51.987544 139881808373504 logging_writer.py:48] [1901] accumulated_eval_time=81.992929, accumulated_logging_time=0.054931, accumulated_submission_time=882.624751, global_step=1901, preemption_count=0, score=882.624751, test/accuracy=0.059900, test/loss=5.397579, test/num_examples=10000, total_duration=964.774469, train/accuracy=0.085391, train/loss=5.103076, validation/accuracy=0.080960, validation/loss=5.148301, validation/num_examples=50000
I0302 11:23:31.040371 139881799980800 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.0103728771209717, loss=5.634215354919434
I0302 11:24:13.833752 139881808373504 logging_writer.py:48] [2100] global_step=2100, grad_norm=1.5933117866516113, loss=5.632997512817383
I0302 11:24:57.539149 139881799980800 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.8991653919219971, loss=6.5579094886779785
I0302 11:25:41.284551 139881808373504 logging_writer.py:48] [2300] global_step=2300, grad_norm=1.5010615587234497, loss=5.502830982208252
I0302 11:26:24.915413 139881799980800 logging_writer.py:48] [2400] global_step=2400, grad_norm=1.0452779531478882, loss=5.291459083557129
I0302 11:27:08.666742 139881808373504 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.0281262397766113, loss=5.344346046447754
I0302 11:27:52.007525 139881799980800 logging_writer.py:48] [2600] global_step=2600, grad_norm=1.4424853324890137, loss=5.3566460609436035
I0302 11:28:35.604635 139881808373504 logging_writer.py:48] [2700] global_step=2700, grad_norm=1.7104876041412354, loss=6.636168956756592
I0302 11:29:19.524876 139881799980800 logging_writer.py:48] [2800] global_step=2800, grad_norm=1.240666389465332, loss=5.73816442489624
I0302 11:29:51.991448 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:30:03.671089 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:30:11.607554 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:30:13.204577 140077943854912 submission_runner.py:411] Time since start: 1406.01s, 	Step: 2877, 	{'train/accuracy': 0.14552734792232513, 'train/loss': 4.522874355316162, 'validation/accuracy': 0.13582000136375427, 'validation/loss': 4.604587554931641, 'validation/num_examples': 50000, 'test/accuracy': 0.10260000824928284, 'test/loss': 4.934473514556885, 'test/num_examples': 10000, 'score': 1302.5669553279877, 'total_duration': 1406.0095813274384, 'accumulated_submission_time': 1302.5669553279877, 'accumulated_eval_time': 103.20603942871094, 'accumulated_logging_time': 0.08366537094116211}
I0302 11:30:13.221734 139881808373504 logging_writer.py:48] [2877] accumulated_eval_time=103.206039, accumulated_logging_time=0.083665, accumulated_submission_time=1302.566955, global_step=2877, preemption_count=0, score=1302.566955, test/accuracy=0.102600, test/loss=4.934474, test/num_examples=10000, total_duration=1406.009581, train/accuracy=0.145527, train/loss=4.522874, validation/accuracy=0.135820, validation/loss=4.604588, validation/num_examples=50000
I0302 11:30:22.661267 139881799980800 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.95279461145401, loss=5.250133514404297
I0302 11:31:01.879525 139881808373504 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.8463239073753357, loss=6.247973442077637
I0302 11:31:45.329487 139881799980800 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.9457314014434814, loss=5.073087215423584
I0302 11:32:28.876823 139881808373504 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.8480852842330933, loss=5.5401201248168945
I0302 11:33:12.377273 139881799980800 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.8887187838554382, loss=5.208356857299805
I0302 11:33:55.756158 139881808373504 logging_writer.py:48] [3400] global_step=3400, grad_norm=1.0653992891311646, loss=5.026525974273682
I0302 11:34:39.275704 139881799980800 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.0249418020248413, loss=4.947761535644531
I0302 11:35:23.177621 139881808373504 logging_writer.py:48] [3600] global_step=3600, grad_norm=1.0827568769454956, loss=4.944247722625732
I0302 11:36:06.752605 139881799980800 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.9319471716880798, loss=5.935201644897461
I0302 11:36:50.359035 139881808373504 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.8555126786231995, loss=4.807696342468262
I0302 11:37:13.301633 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:37:24.691053 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:37:32.654295 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:37:34.250610 140077943854912 submission_runner.py:411] Time since start: 1847.06s, 	Step: 3854, 	{'train/accuracy': 0.20396484434604645, 'train/loss': 4.073319435119629, 'validation/accuracy': 0.19059999287128448, 'validation/loss': 4.152755260467529, 'validation/num_examples': 50000, 'test/accuracy': 0.1454000025987625, 'test/loss': 4.553320407867432, 'test/num_examples': 10000, 'score': 1722.5828483104706, 'total_duration': 1847.0556282997131, 'accumulated_submission_time': 1722.5828483104706, 'accumulated_eval_time': 124.15501117706299, 'accumulated_logging_time': 0.11279463768005371}
I0302 11:37:34.271707 139881799980800 logging_writer.py:48] [3854] accumulated_eval_time=124.155011, accumulated_logging_time=0.112795, accumulated_submission_time=1722.582848, global_step=3854, preemption_count=0, score=1722.582848, test/accuracy=0.145400, test/loss=4.553320, test/num_examples=10000, total_duration=1847.055628, train/accuracy=0.203965, train/loss=4.073319, validation/accuracy=0.190600, validation/loss=4.152755, validation/num_examples=50000
I0302 11:37:52.643744 139881808373504 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.9582156538963318, loss=6.358395099639893
I0302 11:38:33.975903 139881799980800 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.0012062788009644, loss=4.769632816314697
I0302 11:39:17.445872 139881808373504 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.9389456510543823, loss=5.2930474281311035
I0302 11:40:01.054179 139881799980800 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.8639516234397888, loss=4.628836154937744
I0302 11:40:44.613618 139881808373504 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.7900478839874268, loss=4.976015090942383
I0302 11:41:28.390358 139881799980800 logging_writer.py:48] [4400] global_step=4400, grad_norm=1.0757428407669067, loss=4.77199649810791
I0302 11:42:12.027873 139881808373504 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.8694384098052979, loss=4.396705150604248
I0302 11:42:55.627687 139881799980800 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.9397011399269104, loss=4.677924633026123
I0302 11:43:39.368771 139881808373504 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.9644429683685303, loss=4.227364540100098
I0302 11:44:22.969107 139881799980800 logging_writer.py:48] [4800] global_step=4800, grad_norm=1.0367763042449951, loss=4.4985198974609375
I0302 11:44:34.581481 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:44:45.855330 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:44:56.463039 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:44:58.058331 140077943854912 submission_runner.py:411] Time since start: 2290.86s, 	Step: 4828, 	{'train/accuracy': 0.2770312428474426, 'train/loss': 3.557164430618286, 'validation/accuracy': 0.2561799883842468, 'validation/loss': 3.682000160217285, 'validation/num_examples': 50000, 'test/accuracy': 0.195700004696846, 'test/loss': 4.1686320304870605, 'test/num_examples': 10000, 'score': 2142.8305237293243, 'total_duration': 2290.8633484840393, 'accumulated_submission_time': 2142.8305237293243, 'accumulated_eval_time': 147.63187551498413, 'accumulated_logging_time': 0.14507699012756348}
I0302 11:44:58.076526 139881808373504 logging_writer.py:48] [4828] accumulated_eval_time=147.631876, accumulated_logging_time=0.145077, accumulated_submission_time=2142.830524, global_step=4828, preemption_count=0, score=2142.830524, test/accuracy=0.195700, test/loss=4.168632, test/num_examples=10000, total_duration=2290.863348, train/accuracy=0.277031, train/loss=3.557164, validation/accuracy=0.256180, validation/loss=3.682000, validation/num_examples=50000
I0302 11:45:26.630771 139881799980800 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.9923043251037598, loss=4.616571426391602
I0302 11:46:09.283195 139881808373504 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.9261019825935364, loss=4.307960510253906
I0302 11:46:53.175594 139881799980800 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.7638240456581116, loss=5.3816094398498535
I0302 11:47:37.378582 139881808373504 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.9328124523162842, loss=6.257237434387207
I0302 11:48:21.642182 139881799980800 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.9930007457733154, loss=4.288921356201172
I0302 11:49:05.751833 139881808373504 logging_writer.py:48] [5400] global_step=5400, grad_norm=1.194380283355713, loss=4.203563690185547
I0302 11:49:49.961966 139881799980800 logging_writer.py:48] [5500] global_step=5500, grad_norm=1.044954538345337, loss=5.251244068145752
I0302 11:50:33.896941 139881808373504 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.9237646460533142, loss=4.275271892547607
I0302 11:51:17.604482 139881799980800 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.6923040747642517, loss=4.884127616882324
I0302 11:51:58.344612 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:52:10.009368 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:52:18.094080 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:52:19.693981 140077943854912 submission_runner.py:411] Time since start: 2732.50s, 	Step: 5795, 	{'train/accuracy': 0.3194335997104645, 'train/loss': 3.239790916442871, 'validation/accuracy': 0.29670000076293945, 'validation/loss': 3.379960775375366, 'validation/num_examples': 50000, 'test/accuracy': 0.22620001435279846, 'test/loss': 3.9077682495117188, 'test/num_examples': 10000, 'score': 2563.035956144333, 'total_duration': 2732.498987197876, 'accumulated_submission_time': 2563.035956144333, 'accumulated_eval_time': 168.98122477531433, 'accumulated_logging_time': 0.17536330223083496}
I0302 11:52:19.711507 139881808373504 logging_writer.py:48] [5795] accumulated_eval_time=168.981225, accumulated_logging_time=0.175363, accumulated_submission_time=2563.035956, global_step=5795, preemption_count=0, score=2563.035956, test/accuracy=0.226200, test/loss=3.907768, test/num_examples=10000, total_duration=2732.498987, train/accuracy=0.319434, train/loss=3.239791, validation/accuracy=0.296700, validation/loss=3.379961, validation/num_examples=50000
I0302 11:52:22.084883 139881799980800 logging_writer.py:48] [5800] global_step=5800, grad_norm=1.0191642045974731, loss=4.330087661743164
I0302 11:53:01.258176 139881808373504 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.9018202424049377, loss=5.26844596862793
I0302 11:53:44.979869 139881799980800 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.9379677176475525, loss=4.163127899169922
I0302 11:54:28.856296 139881808373504 logging_writer.py:48] [6100] global_step=6100, grad_norm=1.0444008111953735, loss=4.1584930419921875
I0302 11:55:12.714711 139881799980800 logging_writer.py:48] [6200] global_step=6200, grad_norm=1.04437255859375, loss=4.261236190795898
I0302 11:55:56.643723 139881808373504 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.7663243412971497, loss=5.347912788391113
I0302 11:56:41.119406 139881799980800 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.7600005269050598, loss=4.059296131134033
I0302 11:57:25.153369 139881808373504 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.9524235129356384, loss=4.144711971282959
I0302 11:58:08.999677 139881799980800 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.8747228980064392, loss=4.637163162231445
I0302 11:58:52.656081 139881808373504 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.9504329562187195, loss=3.822974681854248
I0302 11:59:20.092834 140077943854912 spec.py:321] Evaluating on the training split.
I0302 11:59:31.663472 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 11:59:42.575553 140077943854912 spec.py:349] Evaluating on the test split.
I0302 11:59:44.167524 140077943854912 submission_runner.py:411] Time since start: 3176.97s, 	Step: 6764, 	{'train/accuracy': 0.36865234375, 'train/loss': 2.9398577213287354, 'validation/accuracy': 0.3310999870300293, 'validation/loss': 3.1599504947662354, 'validation/num_examples': 50000, 'test/accuracy': 0.2533000111579895, 'test/loss': 3.719790458679199, 'test/num_examples': 10000, 'score': 2983.3539803028107, 'total_duration': 3176.9725415706635, 'accumulated_submission_time': 2983.3539803028107, 'accumulated_eval_time': 193.05592393875122, 'accumulated_logging_time': 0.20386409759521484}
I0302 11:59:44.187607 139881799980800 logging_writer.py:48] [6764] accumulated_eval_time=193.055924, accumulated_logging_time=0.203864, accumulated_submission_time=2983.353980, global_step=6764, preemption_count=0, score=2983.353980, test/accuracy=0.253300, test/loss=3.719790, test/num_examples=10000, total_duration=3176.972542, train/accuracy=0.368652, train/loss=2.939858, validation/accuracy=0.331100, validation/loss=3.159950, validation/num_examples=50000
I0302 11:59:58.676584 139881808373504 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.7443250417709351, loss=4.504757404327393
I0302 12:00:39.322974 139881799980800 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.586983323097229, loss=5.11203670501709
I0302 12:01:22.993656 139881808373504 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.7723553776741028, loss=4.190255641937256
I0302 12:02:06.758179 139881799980800 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.8284949660301208, loss=4.335855007171631
I0302 12:02:50.429820 139881808373504 logging_writer.py:48] [7200] global_step=7200, grad_norm=1.00620698928833, loss=3.8876090049743652
I0302 12:03:34.212929 139881799980800 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.8878342509269714, loss=3.8646233081817627
I0302 12:04:17.940607 139881808373504 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.7471179366111755, loss=5.048344135284424
I0302 12:05:02.237056 139881799980800 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.6163855195045471, loss=5.810083389282227
I0302 12:05:46.516471 139881808373504 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.7100529670715332, loss=5.651608467102051
I0302 12:06:31.106846 139881799980800 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.7878962755203247, loss=4.126402378082275
I0302 12:06:44.444349 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:06:56.005969 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:07:07.999336 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:07:09.602195 140077943854912 submission_runner.py:411] Time since start: 3622.41s, 	Step: 7732, 	{'train/accuracy': 0.3927929699420929, 'train/loss': 2.838428497314453, 'validation/accuracy': 0.36715999245643616, 'validation/loss': 2.9767770767211914, 'validation/num_examples': 50000, 'test/accuracy': 0.2832000255584717, 'test/loss': 3.5490877628326416, 'test/num_examples': 10000, 'score': 3403.5411076545715, 'total_duration': 3622.407206058502, 'accumulated_submission_time': 3403.5411076545715, 'accumulated_eval_time': 218.21373295783997, 'accumulated_logging_time': 0.2344825267791748}
I0302 12:07:09.627261 139881808373504 logging_writer.py:48] [7732] accumulated_eval_time=218.213733, accumulated_logging_time=0.234483, accumulated_submission_time=3403.541108, global_step=7732, preemption_count=0, score=3403.541108, test/accuracy=0.283200, test/loss=3.549088, test/num_examples=10000, total_duration=3622.407206, train/accuracy=0.392793, train/loss=2.838428, validation/accuracy=0.367160, validation/loss=2.976777, validation/num_examples=50000
I0302 12:07:36.636983 139881799980800 logging_writer.py:48] [7800] global_step=7800, grad_norm=1.1095774173736572, loss=3.7308614253997803
I0302 12:08:19.602797 139881808373504 logging_writer.py:48] [7900] global_step=7900, grad_norm=1.0062448978424072, loss=3.901954174041748
I0302 12:09:03.045262 139881799980800 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.9581501483917236, loss=3.730879068374634
I0302 12:09:46.809654 139881808373504 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.8742973208427429, loss=3.8154215812683105
I0302 12:10:30.942283 139881799980800 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.9598880410194397, loss=3.9628937244415283
I0302 12:11:14.713978 139881808373504 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.791166365146637, loss=5.518206596374512
I0302 12:11:58.350410 139881799980800 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.6655240058898926, loss=5.491756439208984
I0302 12:12:41.941539 139881808373504 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.0341631174087524, loss=3.7566354274749756
I0302 12:13:25.780578 139881799980800 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.7519955635070801, loss=4.3676371574401855
I0302 12:14:10.029838 139881808373504 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.8784920573234558, loss=3.823704719543457
I0302 12:14:10.043854 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:14:21.192303 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:14:40.014867 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:14:41.611166 140077943854912 submission_runner.py:411] Time since start: 4074.42s, 	Step: 8701, 	{'train/accuracy': 0.41845703125, 'train/loss': 2.6635642051696777, 'validation/accuracy': 0.389739990234375, 'validation/loss': 2.8288674354553223, 'validation/num_examples': 50000, 'test/accuracy': 0.2953000068664551, 'test/loss': 3.4372708797454834, 'test/num_examples': 10000, 'score': 3823.8924305438995, 'total_duration': 4074.4161858558655, 'accumulated_submission_time': 3823.8924305438995, 'accumulated_eval_time': 249.78102779388428, 'accumulated_logging_time': 0.27385377883911133}
I0302 12:14:41.632901 139881799980800 logging_writer.py:48] [8701] accumulated_eval_time=249.781028, accumulated_logging_time=0.273854, accumulated_submission_time=3823.892431, global_step=8701, preemption_count=0, score=3823.892431, test/accuracy=0.295300, test/loss=3.437271, test/num_examples=10000, total_duration=4074.416186, train/accuracy=0.418457, train/loss=2.663564, validation/accuracy=0.389740, validation/loss=2.828867, validation/num_examples=50000
I0302 12:15:20.685652 139881808373504 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.9707882404327393, loss=3.595324754714966
I0302 12:16:04.339591 139881799980800 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.9243159294128418, loss=3.651632308959961
I0302 12:16:48.218896 139881808373504 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.7215834856033325, loss=4.526928424835205
I0302 12:17:32.073950 139881799980800 logging_writer.py:48] [9100] global_step=9100, grad_norm=1.011812448501587, loss=3.6449975967407227
I0302 12:18:15.717559 139881808373504 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.8774474263191223, loss=3.5675928592681885
I0302 12:18:59.340818 139881799980800 logging_writer.py:48] [9300] global_step=9300, grad_norm=1.014669418334961, loss=3.584151268005371
I0302 12:19:42.948192 139881808373504 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.9132382869720459, loss=3.4917521476745605
I0302 12:20:26.656613 139881799980800 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.874004602432251, loss=4.66243839263916
I0302 12:21:10.417326 139881808373504 logging_writer.py:48] [9600] global_step=9600, grad_norm=1.0102300643920898, loss=3.5532474517822266
I0302 12:21:41.958413 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:21:54.320762 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:22:06.041859 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:22:07.637776 140077943854912 submission_runner.py:411] Time since start: 4520.44s, 	Step: 9674, 	{'train/accuracy': 0.4361914098262787, 'train/loss': 2.5769314765930176, 'validation/accuracy': 0.3981599807739258, 'validation/loss': 2.7709803581237793, 'validation/num_examples': 50000, 'test/accuracy': 0.3086000084877014, 'test/loss': 3.3669235706329346, 'test/num_examples': 10000, 'score': 4244.15566444397, 'total_duration': 4520.442771434784, 'accumulated_submission_time': 4244.15566444397, 'accumulated_eval_time': 275.4603519439697, 'accumulated_logging_time': 0.30634307861328125}
I0302 12:22:07.656474 139881799980800 logging_writer.py:48] [9674] accumulated_eval_time=275.460352, accumulated_logging_time=0.306343, accumulated_submission_time=4244.155664, global_step=9674, preemption_count=0, score=4244.155664, test/accuracy=0.308600, test/loss=3.366924, test/num_examples=10000, total_duration=4520.442771, train/accuracy=0.436191, train/loss=2.576931, validation/accuracy=0.398160, validation/loss=2.770980, validation/num_examples=50000
I0302 12:22:18.238082 139881808373504 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.7716214656829834, loss=4.516751289367676
I0302 12:22:59.235798 139881799980800 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.9520756602287292, loss=3.522636651992798
I0302 12:23:43.268203 139881808373504 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.8269004225730896, loss=4.660452842712402
I0302 12:24:27.407082 139881799980800 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.9076864719390869, loss=5.872895240783691
I0302 12:25:11.219470 139881808373504 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.897309422492981, loss=3.383511543273926
I0302 12:25:54.982179 139881799980800 logging_writer.py:48] [10200] global_step=10200, grad_norm=1.0959779024124146, loss=3.6483776569366455
I0302 12:26:38.996326 139881808373504 logging_writer.py:48] [10300] global_step=10300, grad_norm=1.0119925737380981, loss=3.398452043533325
I0302 12:27:22.743522 139881799980800 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.9915291666984558, loss=3.4958882331848145
I0302 12:28:06.533571 139881808373504 logging_writer.py:48] [10500] global_step=10500, grad_norm=1.0225600004196167, loss=3.4773097038269043
I0302 12:28:50.096423 139881799980800 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.6210803985595703, loss=5.550067901611328
I0302 12:29:07.840254 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:29:19.533071 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:29:31.675039 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:29:33.265631 140077943854912 submission_runner.py:411] Time since start: 4966.07s, 	Step: 10642, 	{'train/accuracy': 0.48628905415534973, 'train/loss': 2.3014988899230957, 'validation/accuracy': 0.42396000027656555, 'validation/loss': 2.618833065032959, 'validation/num_examples': 50000, 'test/accuracy': 0.32430002093315125, 'test/loss': 3.2398502826690674, 'test/num_examples': 10000, 'score': 4664.272991895676, 'total_duration': 4966.070648193359, 'accumulated_submission_time': 4664.272991895676, 'accumulated_eval_time': 300.88571643829346, 'accumulated_logging_time': 0.3400704860687256}
I0302 12:29:33.285852 139881808373504 logging_writer.py:48] [10642] accumulated_eval_time=300.885716, accumulated_logging_time=0.340070, accumulated_submission_time=4664.272992, global_step=10642, preemption_count=0, score=4664.272992, test/accuracy=0.324300, test/loss=3.239850, test/num_examples=10000, total_duration=4966.070648, train/accuracy=0.486289, train/loss=2.301499, validation/accuracy=0.423960, validation/loss=2.618833, validation/num_examples=50000
I0302 12:29:56.340769 139881799980800 logging_writer.py:48] [10700] global_step=10700, grad_norm=1.0093992948532104, loss=3.283087730407715
I0302 12:30:38.053475 139881808373504 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.8284662365913391, loss=4.503332138061523
I0302 12:31:22.085954 139881799980800 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.9389570951461792, loss=3.436358690261841
I0302 12:32:06.110338 139881808373504 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.8738347291946411, loss=3.8205997943878174
I0302 12:32:50.039864 139881799980800 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.7356635928153992, loss=5.783767223358154
I0302 12:33:34.039771 139881808373504 logging_writer.py:48] [11200] global_step=11200, grad_norm=1.0252619981765747, loss=3.450565814971924
I0302 12:34:18.187284 139881799980800 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.866265058517456, loss=5.866367816925049
I0302 12:35:01.785342 139881808373504 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.9530553221702576, loss=3.2824220657348633
I0302 12:35:45.747148 139881799980800 logging_writer.py:48] [11500] global_step=11500, grad_norm=1.0387228727340698, loss=3.495436668395996
I0302 12:36:30.027855 139881808373504 logging_writer.py:48] [11600] global_step=11600, grad_norm=1.1165999174118042, loss=3.3433518409729004
I0302 12:36:33.690828 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:36:48.210999 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:37:04.056705 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:37:05.646125 140077943854912 submission_runner.py:411] Time since start: 5418.45s, 	Step: 11610, 	{'train/accuracy': 0.4810546636581421, 'train/loss': 2.291144609451294, 'validation/accuracy': 0.44711998105049133, 'validation/loss': 2.464445114135742, 'validation/num_examples': 50000, 'test/accuracy': 0.34360000491142273, 'test/loss': 3.1111037731170654, 'test/num_examples': 10000, 'score': 5084.614083766937, 'total_duration': 5418.4511461257935, 'accumulated_submission_time': 5084.614083766937, 'accumulated_eval_time': 332.84100675582886, 'accumulated_logging_time': 0.37198662757873535}
I0302 12:37:05.668004 139881799980800 logging_writer.py:48] [11610] accumulated_eval_time=332.841007, accumulated_logging_time=0.371987, accumulated_submission_time=5084.614084, global_step=11610, preemption_count=0, score=5084.614084, test/accuracy=0.343600, test/loss=3.111104, test/num_examples=10000, total_duration=5418.451146, train/accuracy=0.481055, train/loss=2.291145, validation/accuracy=0.447120, validation/loss=2.464445, validation/num_examples=50000
I0302 12:37:41.252001 139881808373504 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.8297189474105835, loss=5.738658905029297
I0302 12:38:24.931315 139881799980800 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.7612291574478149, loss=5.15833044052124
I0302 12:39:08.629679 139881808373504 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.9468448758125305, loss=3.4924845695495605
I0302 12:39:52.299508 139881799980800 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.7489407062530518, loss=4.44076681137085
I0302 12:40:36.086599 139881808373504 logging_writer.py:48] [12100] global_step=12100, grad_norm=1.1963344812393188, loss=3.2238073348999023
I0302 12:41:19.875302 139881799980800 logging_writer.py:48] [12200] global_step=12200, grad_norm=1.077642798423767, loss=3.3473830223083496
I0302 12:42:03.616249 139881808373504 logging_writer.py:48] [12300] global_step=12300, grad_norm=1.004992961883545, loss=3.305720567703247
I0302 12:42:47.322492 139881799980800 logging_writer.py:48] [12400] global_step=12400, grad_norm=1.046233057975769, loss=3.3001608848571777
I0302 12:43:31.629625 139881808373504 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.9752635359764099, loss=3.2339987754821777
I0302 12:44:05.904497 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:44:19.857091 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:44:35.638093 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:44:37.227199 140077943854912 submission_runner.py:411] Time since start: 5870.03s, 	Step: 12579, 	{'train/accuracy': 0.4947851598262787, 'train/loss': 2.2269725799560547, 'validation/accuracy': 0.4521400034427643, 'validation/loss': 2.4417009353637695, 'validation/num_examples': 50000, 'test/accuracy': 0.35180002450942993, 'test/loss': 3.076727867126465, 'test/num_examples': 10000, 'score': 5504.788379192352, 'total_duration': 5870.032203912735, 'accumulated_submission_time': 5504.788379192352, 'accumulated_eval_time': 364.16368222236633, 'accumulated_logging_time': 0.4047729969024658}
I0302 12:44:37.247732 139881799980800 logging_writer.py:48] [12579] accumulated_eval_time=364.163682, accumulated_logging_time=0.404773, accumulated_submission_time=5504.788379, global_step=12579, preemption_count=0, score=5504.788379, test/accuracy=0.351800, test/loss=3.076728, test/num_examples=10000, total_duration=5870.032204, train/accuracy=0.494785, train/loss=2.226973, validation/accuracy=0.452140, validation/loss=2.441701, validation/num_examples=50000
I0302 12:44:45.875364 139881808373504 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.8820996880531311, loss=3.597928524017334
I0302 12:45:26.173225 139881799980800 logging_writer.py:48] [12700] global_step=12700, grad_norm=1.1068295240402222, loss=3.274060010910034
I0302 12:46:10.067727 139881808373504 logging_writer.py:48] [12800] global_step=12800, grad_norm=1.0332697629928589, loss=3.2663559913635254
I0302 12:46:53.747602 139881799980800 logging_writer.py:48] [12900] global_step=12900, grad_norm=1.0970555543899536, loss=3.238621234893799
I0302 12:47:37.626449 139881808373504 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.8347223997116089, loss=3.9472975730895996
I0302 12:48:21.214496 139881799980800 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.9141038060188293, loss=3.3863613605499268
I0302 12:49:04.968264 139881808373504 logging_writer.py:48] [13200] global_step=13200, grad_norm=1.118141770362854, loss=3.0698602199554443
I0302 12:49:48.534123 139881799980800 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.8059200644493103, loss=4.562008380889893
I0302 12:50:32.420993 139881808373504 logging_writer.py:48] [13400] global_step=13400, grad_norm=1.0113977193832397, loss=5.656165599822998
I0302 12:51:16.902412 139881799980800 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.9972508549690247, loss=3.2505741119384766
I0302 12:51:37.478743 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:51:49.176586 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:52:01.972460 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:52:03.568317 140077943854912 submission_runner.py:411] Time since start: 6316.37s, 	Step: 13548, 	{'train/accuracy': 0.5150390267372131, 'train/loss': 2.110365390777588, 'validation/accuracy': 0.4720799922943115, 'validation/loss': 2.342987060546875, 'validation/num_examples': 50000, 'test/accuracy': 0.36510002613067627, 'test/loss': 2.996798276901245, 'test/num_examples': 10000, 'score': 5924.957451581955, 'total_duration': 6316.37331199646, 'accumulated_submission_time': 5924.957451581955, 'accumulated_eval_time': 390.2532448768616, 'accumulated_logging_time': 0.436398983001709}
I0302 12:52:03.595276 139881808373504 logging_writer.py:48] [13548] accumulated_eval_time=390.253245, accumulated_logging_time=0.436399, accumulated_submission_time=5924.957452, global_step=13548, preemption_count=0, score=5924.957452, test/accuracy=0.365100, test/loss=2.996798, test/num_examples=10000, total_duration=6316.373312, train/accuracy=0.515039, train/loss=2.110365, validation/accuracy=0.472080, validation/loss=2.342987, validation/num_examples=50000
I0302 12:52:24.322847 139881799980800 logging_writer.py:48] [13600] global_step=13600, grad_norm=1.0684938430786133, loss=3.3998875617980957
I0302 12:53:05.912427 139881808373504 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.7218159437179565, loss=5.543083667755127
I0302 12:53:50.194610 139881799980800 logging_writer.py:48] [13800] global_step=13800, grad_norm=1.0860894918441772, loss=3.121978759765625
I0302 12:54:34.070868 139881808373504 logging_writer.py:48] [13900] global_step=13900, grad_norm=1.045490026473999, loss=3.2549567222595215
I0302 12:55:18.102763 139881799980800 logging_writer.py:48] [14000] global_step=14000, grad_norm=1.0087850093841553, loss=3.813354969024658
I0302 12:56:01.549908 139881808373504 logging_writer.py:48] [14100] global_step=14100, grad_norm=1.0812408924102783, loss=3.0994176864624023
I0302 12:56:45.759006 139881799980800 logging_writer.py:48] [14200] global_step=14200, grad_norm=1.220645785331726, loss=5.571437358856201
I0302 12:57:29.892821 139881808373504 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.8833194971084595, loss=4.8650054931640625
I0302 12:58:13.939377 139881799980800 logging_writer.py:48] [14400] global_step=14400, grad_norm=1.0421488285064697, loss=3.1845483779907227
I0302 12:58:57.963693 139881808373504 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.0951987504959106, loss=3.1160333156585693
I0302 12:59:03.791350 140077943854912 spec.py:321] Evaluating on the training split.
I0302 12:59:16.381852 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 12:59:31.574552 140077943854912 spec.py:349] Evaluating on the test split.
I0302 12:59:33.160198 140077943854912 submission_runner.py:411] Time since start: 6765.97s, 	Step: 14515, 	{'train/accuracy': 0.5230273604393005, 'train/loss': 2.1068804264068604, 'validation/accuracy': 0.48033997416496277, 'validation/loss': 2.3169755935668945, 'validation/num_examples': 50000, 'test/accuracy': 0.37290000915527344, 'test/loss': 2.967996597290039, 'test/num_examples': 10000, 'score': 6345.0926015377045, 'total_duration': 6765.965216636658, 'accumulated_submission_time': 6345.0926015377045, 'accumulated_eval_time': 419.6220715045929, 'accumulated_logging_time': 0.47377943992614746}
I0302 12:59:33.180500 139881799980800 logging_writer.py:48] [14515] accumulated_eval_time=419.622072, accumulated_logging_time=0.473779, accumulated_submission_time=6345.092602, global_step=14515, preemption_count=0, score=6345.092602, test/accuracy=0.372900, test/loss=2.967997, test/num_examples=10000, total_duration=6765.965217, train/accuracy=0.523027, train/loss=2.106880, validation/accuracy=0.480340, validation/loss=2.316976, validation/num_examples=50000
I0302 13:00:06.800075 139881808373504 logging_writer.py:48] [14600] global_step=14600, grad_norm=1.006714105606079, loss=3.033978223800659
I0302 13:00:49.797320 139881799980800 logging_writer.py:48] [14700] global_step=14700, grad_norm=1.104188323020935, loss=3.130056142807007
I0302 13:01:34.168946 139881808373504 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.878066897392273, loss=5.398700714111328
I0302 13:02:18.208394 139881799980800 logging_writer.py:48] [14900] global_step=14900, grad_norm=1.1191933155059814, loss=2.9411492347717285
I0302 13:03:02.838607 139881808373504 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.1875334978103638, loss=3.1839146614074707
I0302 13:03:47.008855 139881799980800 logging_writer.py:48] [15100] global_step=15100, grad_norm=1.1201611757278442, loss=3.0714337825775146
I0302 13:04:30.807656 139881808373504 logging_writer.py:48] [15200] global_step=15200, grad_norm=1.1124109029769897, loss=3.156027317047119
I0302 13:05:14.744433 139881799980800 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.9566743969917297, loss=5.591734886169434
I0302 13:05:58.580620 139881808373504 logging_writer.py:48] [15400] global_step=15400, grad_norm=1.0517960786819458, loss=3.015291690826416
I0302 13:06:33.286129 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:06:46.470522 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 13:07:03.171458 140077943854912 spec.py:349] Evaluating on the test split.
I0302 13:07:04.761570 140077943854912 submission_runner.py:411] Time since start: 7217.57s, 	Step: 15480, 	{'train/accuracy': 0.5296484231948853, 'train/loss': 2.038872718811035, 'validation/accuracy': 0.4894999861717224, 'validation/loss': 2.242551803588867, 'validation/num_examples': 50000, 'test/accuracy': 0.38040003180503845, 'test/loss': 2.88616681098938, 'test/num_examples': 10000, 'score': 6765.137340545654, 'total_duration': 7217.566586494446, 'accumulated_submission_time': 6765.137340545654, 'accumulated_eval_time': 451.09750509262085, 'accumulated_logging_time': 0.50453782081604}
I0302 13:07:04.782319 139881799980800 logging_writer.py:48] [15480] accumulated_eval_time=451.097505, accumulated_logging_time=0.504538, accumulated_submission_time=6765.137341, global_step=15480, preemption_count=0, score=6765.137341, test/accuracy=0.380400, test/loss=2.886167, test/num_examples=10000, total_duration=7217.566586, train/accuracy=0.529648, train/loss=2.038873, validation/accuracy=0.489500, validation/loss=2.242552, validation/num_examples=50000
I0302 13:07:12.975761 139881808373504 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.375148057937622, loss=3.025235176086426
I0302 13:07:52.055821 139881799980800 logging_writer.py:48] [15600] global_step=15600, grad_norm=1.048933506011963, loss=3.0601048469543457
I0302 13:08:36.161866 139881808373504 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.8925650119781494, loss=4.8411078453063965
I0302 13:09:20.205418 139881799980800 logging_writer.py:48] [15800] global_step=15800, grad_norm=1.0392240285873413, loss=3.072878360748291
I0302 13:10:04.170000 139881808373504 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.8162553906440735, loss=4.502152919769287
I0302 13:10:48.263616 139881799980800 logging_writer.py:48] [16000] global_step=16000, grad_norm=1.0141537189483643, loss=5.383189678192139
I0302 13:11:32.639628 139881808373504 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.9944330453872681, loss=3.078204870223999
I0302 13:12:17.100124 139881799980800 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.8269745111465454, loss=5.438276290893555
I0302 13:13:01.017749 139881808373504 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.8358973264694214, loss=5.5771636962890625
I0302 13:13:45.334065 139881799980800 logging_writer.py:48] [16400] global_step=16400, grad_norm=1.0868632793426514, loss=3.01007080078125
I0302 13:14:04.921820 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:14:18.623952 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 13:14:38.127783 140077943854912 spec.py:349] Evaluating on the test split.
I0302 13:14:39.718943 140077943854912 submission_runner.py:411] Time since start: 7672.52s, 	Step: 16446, 	{'train/accuracy': 0.5384374856948853, 'train/loss': 1.977601408958435, 'validation/accuracy': 0.502299964427948, 'validation/loss': 2.171231746673584, 'validation/num_examples': 50000, 'test/accuracy': 0.3939000070095062, 'test/loss': 2.8300282955169678, 'test/num_examples': 10000, 'score': 7185.215455293655, 'total_duration': 7672.523951292038, 'accumulated_submission_time': 7185.215455293655, 'accumulated_eval_time': 485.8946087360382, 'accumulated_logging_time': 0.53570556640625}
I0302 13:14:39.743100 139881808373504 logging_writer.py:48] [16446] accumulated_eval_time=485.894609, accumulated_logging_time=0.535706, accumulated_submission_time=7185.215455, global_step=16446, preemption_count=0, score=7185.215455, test/accuracy=0.393900, test/loss=2.830028, test/num_examples=10000, total_duration=7672.523951, train/accuracy=0.538437, train/loss=1.977601, validation/accuracy=0.502300, validation/loss=2.171232, validation/num_examples=50000
I0302 13:15:01.216892 139881799980800 logging_writer.py:48] [16500] global_step=16500, grad_norm=1.1681263446807861, loss=3.454798460006714
I0302 13:15:42.129567 139881808373504 logging_writer.py:48] [16600] global_step=16600, grad_norm=1.0639681816101074, loss=3.135180950164795
I0302 13:16:26.500478 139881799980800 logging_writer.py:48] [16700] global_step=16700, grad_norm=1.0141786336898804, loss=3.2973272800445557
I0302 13:17:10.818760 139881808373504 logging_writer.py:48] [16800] global_step=16800, grad_norm=1.0033936500549316, loss=3.2863872051239014
I0302 13:17:55.063265 139881799980800 logging_writer.py:48] [16900] global_step=16900, grad_norm=1.122267723083496, loss=2.940519094467163
I0302 13:18:39.000330 139881808373504 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.0853935480117798, loss=2.8361713886260986
I0302 13:19:23.027091 139881799980800 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.9981072545051575, loss=4.178808212280273
I0302 13:20:07.196353 139881808373504 logging_writer.py:48] [17200] global_step=17200, grad_norm=1.228023886680603, loss=3.1269609928131104
I0302 13:20:51.110745 139881799980800 logging_writer.py:48] [17300] global_step=17300, grad_norm=1.0890856981277466, loss=3.3583550453186035
I0302 13:21:35.424430 139881808373504 logging_writer.py:48] [17400] global_step=17400, grad_norm=1.4474741220474243, loss=3.078909158706665
I0302 13:21:39.946808 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:21:54.576703 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 13:22:13.371771 140077943854912 spec.py:349] Evaluating on the test split.
I0302 13:22:14.960483 140077943854912 submission_runner.py:411] Time since start: 8127.77s, 	Step: 17412, 	{'train/accuracy': 0.5560351610183716, 'train/loss': 1.9124348163604736, 'validation/accuracy': 0.507420003414154, 'validation/loss': 2.158041477203369, 'validation/num_examples': 50000, 'test/accuracy': 0.3972000181674957, 'test/loss': 2.81754994392395, 'test/num_examples': 10000, 'score': 7605.359039306641, 'total_duration': 8127.765516996384, 'accumulated_submission_time': 7605.359039306641, 'accumulated_eval_time': 520.9082908630371, 'accumulated_logging_time': 0.5695958137512207}
I0302 13:22:14.979017 139881799980800 logging_writer.py:48] [17412] accumulated_eval_time=520.908291, accumulated_logging_time=0.569596, accumulated_submission_time=7605.359039, global_step=17412, preemption_count=0, score=7605.359039, test/accuracy=0.397200, test/loss=2.817550, test/num_examples=10000, total_duration=8127.765517, train/accuracy=0.556035, train/loss=1.912435, validation/accuracy=0.507420, validation/loss=2.158041, validation/num_examples=50000
I0302 13:22:49.752334 139881808373504 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.0736666917800903, loss=2.961550712585449
I0302 13:23:33.637490 139881799980800 logging_writer.py:48] [17600] global_step=17600, grad_norm=1.1318488121032715, loss=2.923318386077881
I0302 13:24:18.239889 139881808373504 logging_writer.py:48] [17700] global_step=17700, grad_norm=1.0670182704925537, loss=3.0659232139587402
I0302 13:25:02.824774 139881799980800 logging_writer.py:48] [17800] global_step=17800, grad_norm=1.0508614778518677, loss=3.007650852203369
I0302 13:25:46.719764 139881808373504 logging_writer.py:48] [17900] global_step=17900, grad_norm=1.129250168800354, loss=2.9990503787994385
I0302 13:26:31.073658 139881799980800 logging_writer.py:48] [18000] global_step=18000, grad_norm=1.11775541305542, loss=3.1190364360809326
I0302 13:27:15.379509 139881808373504 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.9476168751716614, loss=3.938352584838867
I0302 13:27:59.622028 139881799980800 logging_writer.py:48] [18200] global_step=18200, grad_norm=1.1590461730957031, loss=2.929419994354248
I0302 13:28:43.659878 139881808373504 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.9934927821159363, loss=3.057032346725464
I0302 13:29:15.102879 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:29:29.985698 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 13:29:47.752844 140077943854912 spec.py:349] Evaluating on the test split.
I0302 13:29:49.349676 140077943854912 submission_runner.py:411] Time since start: 8582.15s, 	Step: 18373, 	{'train/accuracy': 0.5530468821525574, 'train/loss': 1.9021896123886108, 'validation/accuracy': 0.5165199637413025, 'validation/loss': 2.088361978530884, 'validation/num_examples': 50000, 'test/accuracy': 0.4043000340461731, 'test/loss': 2.7631688117980957, 'test/num_examples': 10000, 'score': 8025.422616481781, 'total_duration': 8582.154694318771, 'accumulated_submission_time': 8025.422616481781, 'accumulated_eval_time': 555.1550786495209, 'accumulated_logging_time': 0.5985524654388428}
I0302 13:29:49.371021 139881799980800 logging_writer.py:48] [18373] accumulated_eval_time=555.155079, accumulated_logging_time=0.598552, accumulated_submission_time=8025.422616, global_step=18373, preemption_count=0, score=8025.422616, test/accuracy=0.404300, test/loss=2.763169, test/num_examples=10000, total_duration=8582.154694, train/accuracy=0.553047, train/loss=1.902190, validation/accuracy=0.516520, validation/loss=2.088362, validation/num_examples=50000
I0302 13:30:00.312829 139881808373504 logging_writer.py:48] [18400] global_step=18400, grad_norm=1.2319327592849731, loss=2.9163689613342285
I0302 13:30:41.623900 139881799980800 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.9125299453735352, loss=4.776576995849609
I0302 13:31:25.674404 139881808373504 logging_writer.py:48] [18600] global_step=18600, grad_norm=1.083105206489563, loss=3.0108509063720703
I0302 13:32:10.218128 139881799980800 logging_writer.py:48] [18700] global_step=18700, grad_norm=1.147789716720581, loss=2.9074275493621826
I0302 13:32:54.842612 139881808373504 logging_writer.py:48] [18800] global_step=18800, grad_norm=1.135345220565796, loss=3.0268101692199707
I0302 13:33:39.208178 139881799980800 logging_writer.py:48] [18900] global_step=18900, grad_norm=1.0669610500335693, loss=2.906444549560547
I0302 13:34:23.604260 139881808373504 logging_writer.py:48] [19000] global_step=19000, grad_norm=1.026069164276123, loss=3.2523021697998047
I0302 13:35:08.046750 139881799980800 logging_writer.py:48] [19100] global_step=19100, grad_norm=1.0621811151504517, loss=2.969618082046509
I0302 13:35:52.329957 139881808373504 logging_writer.py:48] [19200] global_step=19200, grad_norm=1.1163853406906128, loss=2.709925651550293
I0302 13:36:36.825121 139881799980800 logging_writer.py:48] [19300] global_step=19300, grad_norm=1.1463969945907593, loss=3.0273256301879883
I0302 13:36:49.362821 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:37:03.479205 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 13:37:24.647066 140077943854912 spec.py:349] Evaluating on the test split.
I0302 13:37:26.239778 140077943854912 submission_runner.py:411] Time since start: 9039.04s, 	Step: 19330, 	{'train/accuracy': 0.5592187643051147, 'train/loss': 1.8991457223892212, 'validation/accuracy': 0.5181199908256531, 'validation/loss': 2.118349313735962, 'validation/num_examples': 50000, 'test/accuracy': 0.3993000090122223, 'test/loss': 2.775531530380249, 'test/num_examples': 10000, 'score': 8445.353466033936, 'total_duration': 9039.04480600357, 'accumulated_submission_time': 8445.353466033936, 'accumulated_eval_time': 592.0320270061493, 'accumulated_logging_time': 0.6309165954589844}
I0302 13:37:26.259681 139881808373504 logging_writer.py:48] [19330] accumulated_eval_time=592.032027, accumulated_logging_time=0.630917, accumulated_submission_time=8445.353466, global_step=19330, preemption_count=0, score=8445.353466, test/accuracy=0.399300, test/loss=2.775532, test/num_examples=10000, total_duration=9039.044806, train/accuracy=0.559219, train/loss=1.899146, validation/accuracy=0.518120, validation/loss=2.118349, validation/num_examples=50000
I0302 13:37:53.994983 139881799980800 logging_writer.py:48] [19400] global_step=19400, grad_norm=1.1600559949874878, loss=2.9832983016967773
I0302 13:38:37.184082 139881808373504 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.0553250312805176, loss=3.053645610809326
I0302 13:39:21.216517 139881799980800 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.9412661194801331, loss=3.8997294902801514
I0302 13:40:05.489863 139881808373504 logging_writer.py:48] [19700] global_step=19700, grad_norm=1.0187327861785889, loss=2.9110991954803467
I0302 13:40:49.897018 139881799980800 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.9388886094093323, loss=4.928167343139648
I0302 13:41:35.096940 139881808373504 logging_writer.py:48] [19900] global_step=19900, grad_norm=1.2073971033096313, loss=2.920276641845703
I0302 13:42:19.867679 139881799980800 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.0912272930145264, loss=3.67075514793396
I0302 13:43:04.696373 139881808373504 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.9305541515350342, loss=5.2441325187683105
I0302 13:43:49.252897 139881799980800 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.8831698298454285, loss=5.459877967834473
I0302 13:44:26.596822 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:44:40.347732 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 13:45:01.939482 140077943854912 spec.py:349] Evaluating on the test split.
I0302 13:45:03.528584 140077943854912 submission_runner.py:411] Time since start: 9496.33s, 	Step: 20286, 	{'train/accuracy': 0.5762304663658142, 'train/loss': 1.809704303741455, 'validation/accuracy': 0.5256400108337402, 'validation/loss': 2.0427417755126953, 'validation/num_examples': 50000, 'test/accuracy': 0.4166000187397003, 'test/loss': 2.704303026199341, 'test/num_examples': 10000, 'score': 8865.62778878212, 'total_duration': 9496.333614110947, 'accumulated_submission_time': 8865.62778878212, 'accumulated_eval_time': 628.9637792110443, 'accumulated_logging_time': 0.6646013259887695}
I0302 13:45:03.549089 139881808373504 logging_writer.py:48] [20286] accumulated_eval_time=628.963779, accumulated_logging_time=0.664601, accumulated_submission_time=8865.627789, global_step=20286, preemption_count=0, score=8865.627789, test/accuracy=0.416600, test/loss=2.704303, test/num_examples=10000, total_duration=9496.333614, train/accuracy=0.576230, train/loss=1.809704, validation/accuracy=0.525640, validation/loss=2.042742, validation/num_examples=50000
I0302 13:45:09.396119 139881799980800 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.9541621208190918, loss=4.766407489776611
I0302 13:45:49.647737 139881808373504 logging_writer.py:48] [20400] global_step=20400, grad_norm=1.0431798696517944, loss=3.042375087738037
I0302 13:46:34.168329 139881799980800 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.0685783624649048, loss=2.940209150314331
I0302 13:47:18.674896 139881808373504 logging_writer.py:48] [20600] global_step=20600, grad_norm=1.0068912506103516, loss=3.1566474437713623
I0302 13:48:03.209547 139881799980800 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.8314803838729858, loss=4.820638179779053
I0302 13:48:47.284153 139881808373504 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.984764575958252, loss=3.400538206100464
I0302 13:49:31.402602 139881799980800 logging_writer.py:48] [20900] global_step=20900, grad_norm=1.0155531167984009, loss=3.004594564437866
I0302 13:50:15.790212 139881808373504 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.1505959033966064, loss=2.880324602127075
I0302 13:51:00.350715 139881799980800 logging_writer.py:48] [21100] global_step=21100, grad_norm=1.2412546873092651, loss=3.174572467803955
I0302 13:51:44.602429 139881808373504 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.8926756978034973, loss=4.062122344970703
I0302 13:52:03.951174 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:52:18.920018 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 13:52:37.708287 140077943854912 spec.py:349] Evaluating on the test split.
I0302 13:52:39.295459 140077943854912 submission_runner.py:411] Time since start: 9952.10s, 	Step: 21245, 	{'train/accuracy': 0.60107421875, 'train/loss': 1.7186756134033203, 'validation/accuracy': 0.5374400019645691, 'validation/loss': 2.0195109844207764, 'validation/num_examples': 50000, 'test/accuracy': 0.4236000180244446, 'test/loss': 2.6766977310180664, 'test/num_examples': 10000, 'score': 9285.970098257065, 'total_duration': 9952.100473880768, 'accumulated_submission_time': 9285.970098257065, 'accumulated_eval_time': 664.3080334663391, 'accumulated_logging_time': 0.694582462310791}
I0302 13:52:39.317126 139881799980800 logging_writer.py:48] [21245] accumulated_eval_time=664.308033, accumulated_logging_time=0.694582, accumulated_submission_time=9285.970098, global_step=21245, preemption_count=0, score=9285.970098, test/accuracy=0.423600, test/loss=2.676698, test/num_examples=10000, total_duration=9952.100474, train/accuracy=0.601074, train/loss=1.718676, validation/accuracy=0.537440, validation/loss=2.019511, validation/num_examples=50000
I0302 13:53:01.187923 139881808373504 logging_writer.py:48] [21300] global_step=21300, grad_norm=1.0804659128189087, loss=2.848649263381958
I0302 13:53:44.577365 139881799980800 logging_writer.py:48] [21400] global_step=21400, grad_norm=1.1783703565597534, loss=2.8118937015533447
I0302 13:54:29.346450 139881808373504 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.1817961931228638, loss=2.9046146869659424
I0302 13:55:13.783133 139881799980800 logging_writer.py:48] [21600] global_step=21600, grad_norm=1.3008203506469727, loss=2.83970046043396
I0302 13:55:58.021740 139881808373504 logging_writer.py:48] [21700] global_step=21700, grad_norm=1.1746948957443237, loss=3.040104866027832
I0302 13:56:42.596741 139881799980800 logging_writer.py:48] [21800] global_step=21800, grad_norm=1.0548498630523682, loss=3.943305015563965
I0302 13:57:26.924133 139881808373504 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.9305901527404785, loss=5.394566059112549
I0302 13:58:11.531021 139881799980800 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.9234986305236816, loss=5.310837745666504
I0302 13:58:55.885579 139881808373504 logging_writer.py:48] [22100] global_step=22100, grad_norm=1.1889657974243164, loss=2.8066623210906982
I0302 13:59:39.408445 140077943854912 spec.py:321] Evaluating on the training split.
I0302 13:59:53.958600 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:00:14.771119 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:00:16.351024 140077943854912 submission_runner.py:411] Time since start: 10409.16s, 	Step: 22200, 	{'train/accuracy': 0.5738281011581421, 'train/loss': 1.7905476093292236, 'validation/accuracy': 0.5320799946784973, 'validation/loss': 1.9965107440948486, 'validation/num_examples': 50000, 'test/accuracy': 0.4204000234603882, 'test/loss': 2.6631360054016113, 'test/num_examples': 10000, 'score': 9706.001689434052, 'total_duration': 10409.156054019928, 'accumulated_submission_time': 9706.001689434052, 'accumulated_eval_time': 701.2506122589111, 'accumulated_logging_time': 0.7266604900360107}
I0302 14:00:16.370939 139881799980800 logging_writer.py:48] [22200] accumulated_eval_time=701.250612, accumulated_logging_time=0.726660, accumulated_submission_time=9706.001689, global_step=22200, preemption_count=0, score=9706.001689, test/accuracy=0.420400, test/loss=2.663136, test/num_examples=10000, total_duration=10409.156054, train/accuracy=0.573828, train/loss=1.790548, validation/accuracy=0.532080, validation/loss=1.996511, validation/num_examples=50000
I0302 14:00:16.763631 139881808373504 logging_writer.py:48] [22200] global_step=22200, grad_norm=1.1560571193695068, loss=2.8074026107788086
I0302 14:00:55.882094 139881799980800 logging_writer.py:48] [22300] global_step=22300, grad_norm=1.243590235710144, loss=2.7210700511932373
I0302 14:01:40.217198 139881808373504 logging_writer.py:48] [22400] global_step=22400, grad_norm=1.0683386325836182, loss=2.897757053375244
I0302 14:02:24.643550 139881799980800 logging_writer.py:48] [22500] global_step=22500, grad_norm=1.0631523132324219, loss=3.015606164932251
I0302 14:03:09.112046 139881808373504 logging_writer.py:48] [22600] global_step=22600, grad_norm=1.1115790605545044, loss=2.770132541656494
I0302 14:03:53.326369 139881799980800 logging_writer.py:48] [22700] global_step=22700, grad_norm=1.207682728767395, loss=2.816535472869873
I0302 14:04:37.436867 139881808373504 logging_writer.py:48] [22800] global_step=22800, grad_norm=1.086295247077942, loss=5.4010114669799805
I0302 14:05:21.638736 139881799980800 logging_writer.py:48] [22900] global_step=22900, grad_norm=1.1189820766448975, loss=2.956345796585083
I0302 14:06:05.888999 139881808373504 logging_writer.py:48] [23000] global_step=23000, grad_norm=1.1085646152496338, loss=2.809361457824707
I0302 14:06:50.153652 139881799980800 logging_writer.py:48] [23100] global_step=23100, grad_norm=1.1403882503509521, loss=2.7284510135650635
I0302 14:07:16.716780 140077943854912 spec.py:321] Evaluating on the training split.
I0302 14:07:27.951209 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:07:48.626615 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:07:50.219570 140077943854912 submission_runner.py:411] Time since start: 10863.02s, 	Step: 23162, 	{'train/accuracy': 0.5878320336341858, 'train/loss': 1.741782546043396, 'validation/accuracy': 0.5437399744987488, 'validation/loss': 1.9589741230010986, 'validation/num_examples': 50000, 'test/accuracy': 0.4255000054836273, 'test/loss': 2.6321370601654053, 'test/num_examples': 10000, 'score': 10126.287100076675, 'total_duration': 10863.024575471878, 'accumulated_submission_time': 10126.287100076675, 'accumulated_eval_time': 734.7533724308014, 'accumulated_logging_time': 0.7566776275634766}
I0302 14:07:50.242863 139881808373504 logging_writer.py:48] [23162] accumulated_eval_time=734.753372, accumulated_logging_time=0.756678, accumulated_submission_time=10126.287100, global_step=23162, preemption_count=0, score=10126.287100, test/accuracy=0.425500, test/loss=2.632137, test/num_examples=10000, total_duration=10863.024575, train/accuracy=0.587832, train/loss=1.741783, validation/accuracy=0.543740, validation/loss=1.958974, validation/num_examples=50000
I0302 14:08:05.464579 139881799980800 logging_writer.py:48] [23200] global_step=23200, grad_norm=1.1162505149841309, loss=2.698741912841797
I0302 14:08:46.931529 139881808373504 logging_writer.py:48] [23300] global_step=23300, grad_norm=1.332894206047058, loss=2.8711061477661133
I0302 14:09:31.295746 139881799980800 logging_writer.py:48] [23400] global_step=23400, grad_norm=1.1753666400909424, loss=2.6782310009002686
I0302 14:10:15.562475 139881808373504 logging_writer.py:48] [23500] global_step=23500, grad_norm=1.1733685731887817, loss=2.9736318588256836
I0302 14:10:59.582801 139881799980800 logging_writer.py:48] [23600] global_step=23600, grad_norm=1.0387476682662964, loss=3.310297727584839
I0302 14:11:43.507497 139881808373504 logging_writer.py:48] [23700] global_step=23700, grad_norm=1.1324464082717896, loss=2.80069637298584
I0302 14:12:27.667030 139881799980800 logging_writer.py:48] [23800] global_step=23800, grad_norm=1.066493034362793, loss=2.876840591430664
I0302 14:13:12.205777 139881808373504 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.938166081905365, loss=4.8282575607299805
I0302 14:13:56.425037 139881799980800 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.9954037070274353, loss=4.942324161529541
I0302 14:14:41.117318 139881808373504 logging_writer.py:48] [24100] global_step=24100, grad_norm=1.11540687084198, loss=3.0484378337860107
I0302 14:14:50.234445 140077943854912 spec.py:321] Evaluating on the training split.
I0302 14:15:00.599745 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:15:20.535082 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:15:22.131923 140077943854912 submission_runner.py:411] Time since start: 11314.94s, 	Step: 24122, 	{'train/accuracy': 0.5895312428474426, 'train/loss': 1.806769847869873, 'validation/accuracy': 0.5410400032997131, 'validation/loss': 2.0305187702178955, 'validation/num_examples': 50000, 'test/accuracy': 0.42510002851486206, 'test/loss': 2.689875602722168, 'test/num_examples': 10000, 'score': 10546.216496706009, 'total_duration': 11314.936919212341, 'accumulated_submission_time': 10546.216496706009, 'accumulated_eval_time': 766.6508240699768, 'accumulated_logging_time': 0.7921888828277588}
I0302 14:15:22.154389 139881799980800 logging_writer.py:48] [24122] accumulated_eval_time=766.650824, accumulated_logging_time=0.792189, accumulated_submission_time=10546.216497, global_step=24122, preemption_count=0, score=10546.216497, test/accuracy=0.425100, test/loss=2.689876, test/num_examples=10000, total_duration=11314.936919, train/accuracy=0.589531, train/loss=1.806770, validation/accuracy=0.541040, validation/loss=2.030519, validation/num_examples=50000
I0302 14:15:52.988887 139881808373504 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.835364818572998, loss=5.288569450378418
I0302 14:16:37.280899 139881799980800 logging_writer.py:48] [24300] global_step=24300, grad_norm=1.2091615200042725, loss=2.764629602432251
I0302 14:17:21.869886 139881808373504 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.9276222586631775, loss=3.3790879249572754
I0302 14:18:06.203511 139881799980800 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.0133395195007324, loss=5.333071708679199
I0302 14:18:50.356123 139881808373504 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.910011351108551, loss=5.257725715637207
I0302 14:19:34.882795 139881799980800 logging_writer.py:48] [24700] global_step=24700, grad_norm=1.1838992834091187, loss=4.406089782714844
I0302 14:20:19.186382 139881808373504 logging_writer.py:48] [24800] global_step=24800, grad_norm=1.3439035415649414, loss=2.7421417236328125
I0302 14:21:03.622641 139881799980800 logging_writer.py:48] [24900] global_step=24900, grad_norm=1.051910400390625, loss=3.6500675678253174
I0302 14:21:47.914870 139881808373504 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.218659520149231, loss=2.7028205394744873
I0302 14:22:22.567804 140077943854912 spec.py:321] Evaluating on the training split.
I0302 14:22:32.724259 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:22:52.852437 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:22:54.441719 140077943854912 submission_runner.py:411] Time since start: 11767.25s, 	Step: 25079, 	{'train/accuracy': 0.6007226705551147, 'train/loss': 1.6918225288391113, 'validation/accuracy': 0.5526800155639648, 'validation/loss': 1.9392848014831543, 'validation/num_examples': 50000, 'test/accuracy': 0.43880000710487366, 'test/loss': 2.607574462890625, 'test/num_examples': 10000, 'score': 10966.567569971085, 'total_duration': 11767.246729373932, 'accumulated_submission_time': 10966.567569971085, 'accumulated_eval_time': 798.524719953537, 'accumulated_logging_time': 0.8267090320587158}
I0302 14:22:54.464887 139881799980800 logging_writer.py:48] [25079] accumulated_eval_time=798.524720, accumulated_logging_time=0.826709, accumulated_submission_time=10966.567570, global_step=25079, preemption_count=0, score=10966.567570, test/accuracy=0.438800, test/loss=2.607574, test/num_examples=10000, total_duration=11767.246729, train/accuracy=0.600723, train/loss=1.691823, validation/accuracy=0.552680, validation/loss=1.939285, validation/num_examples=50000
I0302 14:23:03.041865 139881808373504 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.9184704422950745, loss=5.34599494934082
I0302 14:23:44.050951 139881799980800 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.9346249103546143, loss=5.044350624084473
I0302 14:24:28.226411 139881808373504 logging_writer.py:48] [25300] global_step=25300, grad_norm=1.0697202682495117, loss=5.208052635192871
I0302 14:25:12.884797 139881799980800 logging_writer.py:48] [25400] global_step=25400, grad_norm=1.1289640665054321, loss=2.5675570964813232
I0302 14:25:56.971688 139881808373504 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.9572357535362244, loss=5.205838680267334
I0302 14:26:41.762891 139881799980800 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.9103538990020752, loss=5.278863430023193
I0302 14:27:26.200969 139881808373504 logging_writer.py:48] [25700] global_step=25700, grad_norm=1.2897487878799438, loss=2.602893829345703
I0302 14:28:10.761606 139881799980800 logging_writer.py:48] [25800] global_step=25800, grad_norm=1.4919183254241943, loss=5.199708461761475
I0302 14:28:57.762703 139881808373504 logging_writer.py:48] [25900] global_step=25900, grad_norm=1.1882569789886475, loss=2.652724266052246
I0302 14:29:43.291346 139881799980800 logging_writer.py:48] [26000] global_step=26000, grad_norm=1.0962495803833008, loss=4.81738805770874
I0302 14:29:54.704820 140077943854912 spec.py:321] Evaluating on the training split.
I0302 14:30:05.337124 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:30:26.706624 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:30:28.292418 140077943854912 submission_runner.py:411] Time since start: 12221.10s, 	Step: 26027, 	{'train/accuracy': 0.5960351228713989, 'train/loss': 1.6998733282089233, 'validation/accuracy': 0.5539199709892273, 'validation/loss': 1.9093241691589355, 'validation/num_examples': 50000, 'test/accuracy': 0.4345000088214874, 'test/loss': 2.5865228176116943, 'test/num_examples': 10000, 'score': 11386.746564149857, 'total_duration': 12221.09743642807, 'accumulated_submission_time': 11386.746564149857, 'accumulated_eval_time': 832.1123118400574, 'accumulated_logging_time': 0.8609256744384766}
I0302 14:30:28.311809 139881808373504 logging_writer.py:48] [26027] accumulated_eval_time=832.112312, accumulated_logging_time=0.860926, accumulated_submission_time=11386.746564, global_step=26027, preemption_count=0, score=11386.746564, test/accuracy=0.434500, test/loss=2.586523, test/num_examples=10000, total_duration=12221.097436, train/accuracy=0.596035, train/loss=1.699873, validation/accuracy=0.553920, validation/loss=1.909324, validation/num_examples=50000
I0302 14:30:57.236034 139881799980800 logging_writer.py:48] [26100] global_step=26100, grad_norm=1.0598900318145752, loss=5.337558746337891
I0302 14:31:41.478136 139881808373504 logging_writer.py:48] [26200] global_step=26200, grad_norm=1.1306490898132324, loss=3.1049087047576904
I0302 14:32:26.943744 139881799980800 logging_writer.py:48] [26300] global_step=26300, grad_norm=1.142322063446045, loss=2.7651078701019287
I0302 14:33:12.394926 139881808373504 logging_writer.py:48] [26400] global_step=26400, grad_norm=1.1383860111236572, loss=2.744603157043457
I0302 14:33:56.877368 139881799980800 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.2569276094436646, loss=2.7028489112854004
I0302 14:34:41.617209 139881808373504 logging_writer.py:48] [26600] global_step=26600, grad_norm=1.224697232246399, loss=2.6588847637176514
I0302 14:35:26.348517 139881799980800 logging_writer.py:48] [26700] global_step=26700, grad_norm=1.2675495147705078, loss=2.7821154594421387
I0302 14:36:11.021924 139881808373504 logging_writer.py:48] [26800] global_step=26800, grad_norm=1.1990851163864136, loss=3.164921283721924
I0302 14:36:55.470431 139881799980800 logging_writer.py:48] [26900] global_step=26900, grad_norm=1.1022446155548096, loss=2.7403922080993652
I0302 14:37:28.354287 140077943854912 spec.py:321] Evaluating on the training split.
I0302 14:37:38.432959 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:38:00.481363 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:38:02.082334 140077943854912 submission_runner.py:411] Time since start: 12674.89s, 	Step: 26975, 	{'train/accuracy': 0.6092773079872131, 'train/loss': 1.6344122886657715, 'validation/accuracy': 0.5594599843025208, 'validation/loss': 1.863364815711975, 'validation/num_examples': 50000, 'test/accuracy': 0.4431000351905823, 'test/loss': 2.551481008529663, 'test/num_examples': 10000, 'score': 11806.727120399475, 'total_duration': 12674.887342214584, 'accumulated_submission_time': 11806.727120399475, 'accumulated_eval_time': 865.8403429985046, 'accumulated_logging_time': 0.8936762809753418}
I0302 14:38:02.106201 139881808373504 logging_writer.py:48] [26975] accumulated_eval_time=865.840343, accumulated_logging_time=0.893676, accumulated_submission_time=11806.727120, global_step=26975, preemption_count=0, score=11806.727120, test/accuracy=0.443100, test/loss=2.551481, test/num_examples=10000, total_duration=12674.887342, train/accuracy=0.609277, train/loss=1.634412, validation/accuracy=0.559460, validation/loss=1.863365, validation/num_examples=50000
I0302 14:38:12.272871 139881799980800 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.1102919578552246, loss=2.652312994003296
I0302 14:38:52.648925 139881808373504 logging_writer.py:48] [27100] global_step=27100, grad_norm=1.1528652906417847, loss=2.601639747619629
I0302 14:39:37.150265 139881799980800 logging_writer.py:48] [27200] global_step=27200, grad_norm=1.0911966562271118, loss=2.6873319149017334
I0302 14:40:21.828485 139881808373504 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.8509154319763184, loss=5.244171142578125
I0302 14:41:06.210133 139881799980800 logging_writer.py:48] [27400] global_step=27400, grad_norm=1.0912710428237915, loss=4.142820358276367
I0302 14:41:50.508168 139881808373504 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.9663759469985962, loss=3.6886916160583496
I0302 14:42:34.790875 139881799980800 logging_writer.py:48] [27600] global_step=27600, grad_norm=1.1159526109695435, loss=2.8608579635620117
I0302 14:43:18.904051 139881808373504 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.9444675445556641, loss=4.488001823425293
I0302 14:44:03.457489 139881799980800 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.8668124675750732, loss=4.148149490356445
I0302 14:44:47.660399 139881808373504 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.9023555517196655, loss=4.641292095184326
I0302 14:45:02.494294 140077943854912 spec.py:321] Evaluating on the training split.
I0302 14:45:12.558404 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:45:35.604015 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:45:37.184405 140077943854912 submission_runner.py:411] Time since start: 13129.99s, 	Step: 27935, 	{'train/accuracy': 0.6161523461341858, 'train/loss': 1.614219307899475, 'validation/accuracy': 0.5626599788665771, 'validation/loss': 1.8807896375656128, 'validation/num_examples': 50000, 'test/accuracy': 0.4442000091075897, 'test/loss': 2.544827938079834, 'test/num_examples': 10000, 'score': 12227.053133964539, 'total_duration': 13129.989423274994, 'accumulated_submission_time': 12227.053133964539, 'accumulated_eval_time': 900.530428647995, 'accumulated_logging_time': 0.9298102855682373}
I0302 14:45:37.207628 139881799980800 logging_writer.py:48] [27935] accumulated_eval_time=900.530429, accumulated_logging_time=0.929810, accumulated_submission_time=12227.053134, global_step=27935, preemption_count=0, score=12227.053134, test/accuracy=0.444200, test/loss=2.544828, test/num_examples=10000, total_duration=13129.989423, train/accuracy=0.616152, train/loss=1.614219, validation/accuracy=0.562660, validation/loss=1.880790, validation/num_examples=50000
I0302 14:46:02.985791 139881808373504 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.1616562604904175, loss=2.7751893997192383
I0302 14:46:46.108641 139881799980800 logging_writer.py:48] [28100] global_step=28100, grad_norm=1.2516003847122192, loss=3.499164342880249
I0302 14:47:30.637949 139881808373504 logging_writer.py:48] [28200] global_step=28200, grad_norm=1.3703845739364624, loss=2.6536035537719727
I0302 14:48:14.921388 139881799980800 logging_writer.py:48] [28300] global_step=28300, grad_norm=1.1498714685440063, loss=2.864304304122925
I0302 14:48:59.308826 139881808373504 logging_writer.py:48] [28400] global_step=28400, grad_norm=1.0761103630065918, loss=5.23584508895874
I0302 14:49:44.085147 139881799980800 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.9990469217300415, loss=4.920577526092529
I0302 14:50:28.711027 139881808373504 logging_writer.py:48] [28600] global_step=28600, grad_norm=1.1338595151901245, loss=2.9323537349700928
I0302 14:51:13.398685 139881799980800 logging_writer.py:48] [28700] global_step=28700, grad_norm=1.1671744585037231, loss=2.667983293533325
I0302 14:51:58.122637 139881808373504 logging_writer.py:48] [28800] global_step=28800, grad_norm=1.1471672058105469, loss=2.813875913619995
I0302 14:52:37.595867 140077943854912 spec.py:321] Evaluating on the training split.
I0302 14:52:47.613145 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 14:53:09.519395 140077943854912 spec.py:349] Evaluating on the test split.
I0302 14:53:11.108124 140077943854912 submission_runner.py:411] Time since start: 13583.91s, 	Step: 28890, 	{'train/accuracy': 0.6077929735183716, 'train/loss': 1.6699862480163574, 'validation/accuracy': 0.5683799982070923, 'validation/loss': 1.8518006801605225, 'validation/num_examples': 50000, 'test/accuracy': 0.445000022649765, 'test/loss': 2.535609483718872, 'test/num_examples': 10000, 'score': 12647.381070375443, 'total_duration': 13583.913120269775, 'accumulated_submission_time': 12647.381070375443, 'accumulated_eval_time': 934.0426671504974, 'accumulated_logging_time': 0.9640679359436035}
I0302 14:53:11.132188 139881799980800 logging_writer.py:48] [28890] accumulated_eval_time=934.042667, accumulated_logging_time=0.964068, accumulated_submission_time=12647.381070, global_step=28890, preemption_count=0, score=12647.381070, test/accuracy=0.445000, test/loss=2.535609, test/num_examples=10000, total_duration=13583.913120, train/accuracy=0.607793, train/loss=1.669986, validation/accuracy=0.568380, validation/loss=1.851801, validation/num_examples=50000
I0302 14:53:15.419264 139881808373504 logging_writer.py:48] [28900] global_step=28900, grad_norm=1.2331931591033936, loss=2.706728458404541
I0302 14:53:55.800025 139881799980800 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.085504174232483, loss=4.5959367752075195
I0302 14:54:39.994081 139881808373504 logging_writer.py:48] [29100] global_step=29100, grad_norm=1.0464515686035156, loss=4.307211875915527
I0302 14:55:24.667157 139881799980800 logging_writer.py:48] [29200] global_step=29200, grad_norm=1.1825968027114868, loss=3.205000638961792
I0302 14:56:08.913089 139881808373504 logging_writer.py:48] [29300] global_step=29300, grad_norm=1.0212033987045288, loss=3.359030246734619
I0302 14:56:53.665601 139881799980800 logging_writer.py:48] [29400] global_step=29400, grad_norm=1.1311370134353638, loss=2.86026930809021
I0302 14:57:37.962367 139881808373504 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.1043342351913452, loss=2.6039879322052
I0302 14:58:22.522534 139881799980800 logging_writer.py:48] [29600] global_step=29600, grad_norm=1.2005391120910645, loss=2.566772222518921
I0302 14:59:07.033556 139881808373504 logging_writer.py:48] [29700] global_step=29700, grad_norm=1.1310648918151855, loss=2.97102689743042
I0302 14:59:51.435144 139881799980800 logging_writer.py:48] [29800] global_step=29800, grad_norm=1.0709058046340942, loss=5.0354437828063965
I0302 15:00:11.217654 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:00:21.221371 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:00:43.316950 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:00:44.896541 140077943854912 submission_runner.py:411] Time since start: 14037.70s, 	Step: 29846, 	{'train/accuracy': 0.6141015291213989, 'train/loss': 1.616439938545227, 'validation/accuracy': 0.5706599950790405, 'validation/loss': 1.8262709379196167, 'validation/num_examples': 50000, 'test/accuracy': 0.4506000280380249, 'test/loss': 2.4998276233673096, 'test/num_examples': 10000, 'score': 13067.404882907867, 'total_duration': 14037.70155787468, 'accumulated_submission_time': 13067.404882907867, 'accumulated_eval_time': 967.7215456962585, 'accumulated_logging_time': 0.9999191761016846}
I0302 15:00:44.917013 139881808373504 logging_writer.py:48] [29846] accumulated_eval_time=967.721546, accumulated_logging_time=0.999919, accumulated_submission_time=13067.404883, global_step=29846, preemption_count=0, score=13067.404883, test/accuracy=0.450600, test/loss=2.499828, test/num_examples=10000, total_duration=14037.701558, train/accuracy=0.614102, train/loss=1.616440, validation/accuracy=0.570660, validation/loss=1.826271, validation/num_examples=50000
I0302 15:01:06.392211 139881799980800 logging_writer.py:48] [29900] global_step=29900, grad_norm=1.1607942581176758, loss=2.797835350036621
I0302 15:01:49.257146 139881808373504 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.1474617719650269, loss=2.6874663829803467
I0302 15:02:33.733736 139881799980800 logging_writer.py:48] [30100] global_step=30100, grad_norm=1.1570104360580444, loss=2.517367362976074
I0302 15:03:18.300503 139881808373504 logging_writer.py:48] [30200] global_step=30200, grad_norm=1.4604562520980835, loss=2.740900993347168
I0302 15:04:02.615634 139881799980800 logging_writer.py:48] [30300] global_step=30300, grad_norm=1.1640868186950684, loss=2.895583152770996
I0302 15:04:47.178135 139881808373504 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.9527811408042908, loss=4.346856117248535
I0302 15:05:31.347102 139881799980800 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.2647571563720703, loss=2.9598236083984375
I0302 15:06:15.944320 139881808373504 logging_writer.py:48] [30600] global_step=30600, grad_norm=1.2642102241516113, loss=2.805042028427124
I0302 15:07:00.476805 139881799980800 logging_writer.py:48] [30700] global_step=30700, grad_norm=1.1640316247940063, loss=4.734587669372559
I0302 15:07:45.142650 139881808373504 logging_writer.py:48] [30800] global_step=30800, grad_norm=1.1563180685043335, loss=2.7517282962799072
I0302 15:07:45.156334 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:07:55.449234 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:08:15.771772 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:08:17.359962 140077943854912 submission_runner.py:411] Time since start: 14490.16s, 	Step: 30801, 	{'train/accuracy': 0.6283984184265137, 'train/loss': 1.5483167171478271, 'validation/accuracy': 0.5783599615097046, 'validation/loss': 1.7855757474899292, 'validation/num_examples': 50000, 'test/accuracy': 0.45840001106262207, 'test/loss': 2.4593968391418457, 'test/num_examples': 10000, 'score': 13487.583720207214, 'total_duration': 14490.164947509766, 'accumulated_submission_time': 13487.583720207214, 'accumulated_eval_time': 999.9251253604889, 'accumulated_logging_time': 1.0317416191101074}
I0302 15:08:17.387552 139881799980800 logging_writer.py:48] [30801] accumulated_eval_time=999.925125, accumulated_logging_time=1.031742, accumulated_submission_time=13487.583720, global_step=30801, preemption_count=0, score=13487.583720, test/accuracy=0.458400, test/loss=2.459397, test/num_examples=10000, total_duration=14490.164948, train/accuracy=0.628398, train/loss=1.548317, validation/accuracy=0.578360, validation/loss=1.785576, validation/num_examples=50000
I0302 15:08:56.995181 139881808373504 logging_writer.py:48] [30900] global_step=30900, grad_norm=1.1327815055847168, loss=2.7772738933563232
I0302 15:09:41.287564 139881799980800 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.2864784002304077, loss=2.7204580307006836
I0302 15:10:26.286118 139881808373504 logging_writer.py:48] [31100] global_step=31100, grad_norm=1.245766282081604, loss=2.706538677215576
I0302 15:11:10.622929 139881799980800 logging_writer.py:48] [31200] global_step=31200, grad_norm=1.177242398262024, loss=2.665421485900879
I0302 15:11:54.831667 139881808373504 logging_writer.py:48] [31300] global_step=31300, grad_norm=1.3356918096542358, loss=2.7678885459899902
I0302 15:12:39.194010 139881799980800 logging_writer.py:48] [31400] global_step=31400, grad_norm=1.2954769134521484, loss=2.5622313022613525
I0302 15:13:23.613256 139881808373504 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.9295327663421631, loss=5.052957057952881
I0302 15:14:08.261867 139881799980800 logging_writer.py:48] [31600] global_step=31600, grad_norm=1.1094892024993896, loss=2.529438018798828
I0302 15:14:52.552048 139881808373504 logging_writer.py:48] [31700] global_step=31700, grad_norm=1.006152629852295, loss=4.347381114959717
I0302 15:15:17.595864 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:15:27.824548 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:15:49.934690 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:15:51.519065 140077943854912 submission_runner.py:411] Time since start: 14944.32s, 	Step: 31758, 	{'train/accuracy': 0.6522851586341858, 'train/loss': 1.4674758911132812, 'validation/accuracy': 0.5711199641227722, 'validation/loss': 1.8236415386199951, 'validation/num_examples': 50000, 'test/accuracy': 0.4554000198841095, 'test/loss': 2.479957342147827, 'test/num_examples': 10000, 'score': 13907.73057460785, 'total_duration': 14944.324080467224, 'accumulated_submission_time': 13907.73057460785, 'accumulated_eval_time': 1033.848325252533, 'accumulated_logging_time': 1.0704412460327148}
I0302 15:15:51.540251 139881799980800 logging_writer.py:48] [31758] accumulated_eval_time=1033.848325, accumulated_logging_time=1.070441, accumulated_submission_time=13907.730575, global_step=31758, preemption_count=0, score=13907.730575, test/accuracy=0.455400, test/loss=2.479957, test/num_examples=10000, total_duration=14944.324080, train/accuracy=0.652285, train/loss=1.467476, validation/accuracy=0.571120, validation/loss=1.823642, validation/num_examples=50000
I0302 15:16:08.343161 139881808373504 logging_writer.py:48] [31800] global_step=31800, grad_norm=1.2856050729751587, loss=2.711733818054199
I0302 15:16:50.274167 139881799980800 logging_writer.py:48] [31900] global_step=31900, grad_norm=1.040810227394104, loss=3.16231632232666
I0302 15:17:34.767005 139881808373504 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.2079297304153442, loss=2.658297538757324
I0302 15:18:19.068885 139881799980800 logging_writer.py:48] [32100] global_step=32100, grad_norm=1.0726500749588013, loss=4.960724353790283
I0302 15:19:03.254465 139881808373504 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.9025963544845581, loss=5.162408351898193
I0302 15:19:48.009957 139881799980800 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.8498205542564392, loss=4.776862144470215
I0302 15:20:32.249173 139881808373504 logging_writer.py:48] [32400] global_step=32400, grad_norm=1.1064488887786865, loss=2.5183446407318115
I0302 15:21:16.518988 139881799980800 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.2366827726364136, loss=2.617532253265381
I0302 15:22:01.199909 139881808373504 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.9288892149925232, loss=4.1712541580200195
I0302 15:22:45.779286 139881799980800 logging_writer.py:48] [32700] global_step=32700, grad_norm=1.0652213096618652, loss=4.174108028411865
I0302 15:22:51.646254 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:23:02.146506 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:23:23.648060 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:23:25.227277 140077943854912 submission_runner.py:411] Time since start: 15398.03s, 	Step: 32715, 	{'train/accuracy': 0.6245507597923279, 'train/loss': 1.5911355018615723, 'validation/accuracy': 0.5801599621772766, 'validation/loss': 1.8075169324874878, 'validation/num_examples': 50000, 'test/accuracy': 0.46300002932548523, 'test/loss': 2.479883909225464, 'test/num_examples': 10000, 'score': 14327.77366900444, 'total_duration': 15398.03229379654, 'accumulated_submission_time': 14327.77366900444, 'accumulated_eval_time': 1067.4293353557587, 'accumulated_logging_time': 1.102602243423462}
I0302 15:23:25.250982 139881808373504 logging_writer.py:48] [32715] accumulated_eval_time=1067.429335, accumulated_logging_time=1.102602, accumulated_submission_time=14327.773669, global_step=32715, preemption_count=0, score=14327.773669, test/accuracy=0.463000, test/loss=2.479884, test/num_examples=10000, total_duration=15398.032294, train/accuracy=0.624551, train/loss=1.591136, validation/accuracy=0.580160, validation/loss=1.807517, validation/num_examples=50000
I0302 15:23:58.866119 139881799980800 logging_writer.py:48] [32800] global_step=32800, grad_norm=1.0866799354553223, loss=3.386277198791504
I0302 15:24:43.179012 139881808373504 logging_writer.py:48] [32900] global_step=32900, grad_norm=1.1687678098678589, loss=2.674142837524414
I0302 15:25:27.979211 139881799980800 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.0720603466033936, loss=2.8080596923828125
I0302 15:26:12.090279 139881808373504 logging_writer.py:48] [33100] global_step=33100, grad_norm=1.2411614656448364, loss=2.698735475540161
I0302 15:26:56.576724 139881799980800 logging_writer.py:48] [33200] global_step=33200, grad_norm=1.2274301052093506, loss=2.4614522457122803
I0302 15:27:41.220135 139881808373504 logging_writer.py:48] [33300] global_step=33300, grad_norm=1.1019810438156128, loss=2.441577911376953
I0302 15:28:25.705376 139881799980800 logging_writer.py:48] [33400] global_step=33400, grad_norm=1.2525157928466797, loss=2.54925537109375
I0302 15:29:10.188654 139881808373504 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.2256512641906738, loss=2.7155795097351074
I0302 15:29:54.453763 139881799980800 logging_writer.py:48] [33600] global_step=33600, grad_norm=1.0224525928497314, loss=2.993706226348877
I0302 15:30:25.247951 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:30:35.381862 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:30:54.014887 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:30:55.606274 140077943854912 submission_runner.py:411] Time since start: 15848.41s, 	Step: 33670, 	{'train/accuracy': 0.6285351514816284, 'train/loss': 1.5775716304779053, 'validation/accuracy': 0.5806999802589417, 'validation/loss': 1.7970975637435913, 'validation/num_examples': 50000, 'test/accuracy': 0.4677000343799591, 'test/loss': 2.4360461235046387, 'test/num_examples': 10000, 'score': 14747.711050987244, 'total_duration': 15848.411272764206, 'accumulated_submission_time': 14747.711050987244, 'accumulated_eval_time': 1097.7876312732697, 'accumulated_logging_time': 1.136333703994751}
I0302 15:30:55.634348 139881808373504 logging_writer.py:48] [33670] accumulated_eval_time=1097.787631, accumulated_logging_time=1.136334, accumulated_submission_time=14747.711051, global_step=33670, preemption_count=0, score=14747.711051, test/accuracy=0.467700, test/loss=2.436046, test/num_examples=10000, total_duration=15848.411273, train/accuracy=0.628535, train/loss=1.577572, validation/accuracy=0.580700, validation/loss=1.797098, validation/num_examples=50000
I0302 15:31:07.755650 139881799980800 logging_writer.py:48] [33700] global_step=33700, grad_norm=1.1552070379257202, loss=2.430864095687866
I0302 15:31:50.425019 139881808373504 logging_writer.py:48] [33800] global_step=33800, grad_norm=1.0432063341140747, loss=3.308745861053467
I0302 15:32:34.785303 139881799980800 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.9229367971420288, loss=5.046274662017822
I0302 15:33:19.383720 139881808373504 logging_writer.py:48] [34000] global_step=34000, grad_norm=1.1429073810577393, loss=2.556718349456787
I0302 15:34:04.115525 139881799980800 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.9439117908477783, loss=4.858120918273926
I0302 15:34:48.444495 139881808373504 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.9120410680770874, loss=4.851490020751953
I0302 15:35:33.134371 139881799980800 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.9837716817855835, loss=4.4960551261901855
I0302 15:36:17.560168 139881808373504 logging_writer.py:48] [34400] global_step=34400, grad_norm=1.084539771080017, loss=3.6178395748138428
I0302 15:37:02.286072 139881799980800 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.0091601610183716, loss=4.983823776245117
I0302 15:37:46.710961 139881808373504 logging_writer.py:48] [34600] global_step=34600, grad_norm=1.2818466424942017, loss=2.5947916507720947
I0302 15:37:55.873485 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:38:06.475158 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:38:27.869597 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:38:29.453602 140077943854912 submission_runner.py:411] Time since start: 16302.26s, 	Step: 34622, 	{'train/accuracy': 0.639355480670929, 'train/loss': 1.4995332956314087, 'validation/accuracy': 0.5854399800300598, 'validation/loss': 1.7577393054962158, 'validation/num_examples': 50000, 'test/accuracy': 0.46880000829696655, 'test/loss': 2.4291539192199707, 'test/num_examples': 10000, 'score': 15167.885241985321, 'total_duration': 16302.25860452652, 'accumulated_submission_time': 15167.885241985321, 'accumulated_eval_time': 1131.367756843567, 'accumulated_logging_time': 1.1800377368927002}
I0302 15:38:29.478758 139881799980800 logging_writer.py:48] [34622] accumulated_eval_time=1131.367757, accumulated_logging_time=1.180038, accumulated_submission_time=15167.885242, global_step=34622, preemption_count=0, score=15167.885242, test/accuracy=0.468800, test/loss=2.429154, test/num_examples=10000, total_duration=16302.258605, train/accuracy=0.639355, train/loss=1.499533, validation/accuracy=0.585440, validation/loss=1.757739, validation/num_examples=50000
I0302 15:39:00.336371 139881808373504 logging_writer.py:48] [34700] global_step=34700, grad_norm=1.182692527770996, loss=2.98355770111084
I0302 15:39:44.292872 139881799980800 logging_writer.py:48] [34800] global_step=34800, grad_norm=1.2412720918655396, loss=2.4919471740722656
I0302 15:40:29.145186 139881808373504 logging_writer.py:48] [34900] global_step=34900, grad_norm=1.1770920753479004, loss=3.7394497394561768
I0302 15:41:13.601536 139881799980800 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.0791215896606445, loss=3.1567490100860596
I0302 15:41:58.136496 139881808373504 logging_writer.py:48] [35100] global_step=35100, grad_norm=1.3964223861694336, loss=2.4621691703796387
I0302 15:42:42.718947 139881799980800 logging_writer.py:48] [35200] global_step=35200, grad_norm=1.1816034317016602, loss=2.5867791175842285
I0302 15:43:27.464575 139881808373504 logging_writer.py:48] [35300] global_step=35300, grad_norm=1.229838490486145, loss=2.478468894958496
I0302 15:44:11.819073 139881799980800 logging_writer.py:48] [35400] global_step=35400, grad_norm=1.207999587059021, loss=2.5179014205932617
I0302 15:44:56.377645 139881808373504 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.0428366661071777, loss=3.149954319000244
I0302 15:45:29.848467 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:45:39.884553 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:46:02.363227 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:46:03.947939 140077943854912 submission_runner.py:411] Time since start: 16756.75s, 	Step: 35577, 	{'train/accuracy': 0.6327343583106995, 'train/loss': 1.5223309993743896, 'validation/accuracy': 0.5879799723625183, 'validation/loss': 1.7351510524749756, 'validation/num_examples': 50000, 'test/accuracy': 0.46970000863075256, 'test/loss': 2.40012788772583, 'test/num_examples': 10000, 'score': 15588.195026397705, 'total_duration': 16756.752949476242, 'accumulated_submission_time': 15588.195026397705, 'accumulated_eval_time': 1165.467206954956, 'accumulated_logging_time': 1.2153346538543701}
I0302 15:46:03.976748 139881799980800 logging_writer.py:48] [35577] accumulated_eval_time=1165.467207, accumulated_logging_time=1.215335, accumulated_submission_time=15588.195026, global_step=35577, preemption_count=0, score=15588.195026, test/accuracy=0.469700, test/loss=2.400128, test/num_examples=10000, total_duration=16756.752949, train/accuracy=0.632734, train/loss=1.522331, validation/accuracy=0.587980, validation/loss=1.735151, validation/num_examples=50000
I0302 15:46:13.341099 139881808373504 logging_writer.py:48] [35600] global_step=35600, grad_norm=1.1458841562271118, loss=2.6119046211242676
I0302 15:46:53.941136 139881799980800 logging_writer.py:48] [35700] global_step=35700, grad_norm=1.3767387866973877, loss=2.56243634223938
I0302 15:47:38.465742 139881808373504 logging_writer.py:48] [35800] global_step=35800, grad_norm=1.0416591167449951, loss=3.9611997604370117
I0302 15:48:23.079160 139881799980800 logging_writer.py:48] [35900] global_step=35900, grad_norm=1.2976560592651367, loss=2.6189913749694824
I0302 15:49:07.520440 139881808373504 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.0072389841079712, loss=2.973906993865967
I0302 15:49:51.857754 139881799980800 logging_writer.py:48] [36100] global_step=36100, grad_norm=1.1723482608795166, loss=2.619089126586914
I0302 15:50:35.994389 139881808373504 logging_writer.py:48] [36200] global_step=36200, grad_norm=1.1330420970916748, loss=2.534222364425659
I0302 15:51:20.338119 139881799980800 logging_writer.py:48] [36300] global_step=36300, grad_norm=1.1918439865112305, loss=2.6499745845794678
I0302 15:52:04.978961 139881808373504 logging_writer.py:48] [36400] global_step=36400, grad_norm=1.1912484169006348, loss=2.533405303955078
I0302 15:52:49.654896 139881799980800 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.1887125968933105, loss=2.6584603786468506
I0302 15:53:04.069934 140077943854912 spec.py:321] Evaluating on the training split.
I0302 15:53:14.314809 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 15:53:35.229551 140077943854912 spec.py:349] Evaluating on the test split.
I0302 15:53:36.819370 140077943854912 submission_runner.py:411] Time since start: 17209.62s, 	Step: 36534, 	{'train/accuracy': 0.6396093368530273, 'train/loss': 1.5190812349319458, 'validation/accuracy': 0.5896199941635132, 'validation/loss': 1.7429559230804443, 'validation/num_examples': 50000, 'test/accuracy': 0.4677000343799591, 'test/loss': 2.421023368835449, 'test/num_examples': 10000, 'score': 16008.226280927658, 'total_duration': 17209.62438249588, 'accumulated_submission_time': 16008.226280927658, 'accumulated_eval_time': 1198.2166216373444, 'accumulated_logging_time': 1.2557530403137207}
I0302 15:53:36.843830 139881808373504 logging_writer.py:48] [36534] accumulated_eval_time=1198.216622, accumulated_logging_time=1.255753, accumulated_submission_time=16008.226281, global_step=36534, preemption_count=0, score=16008.226281, test/accuracy=0.467700, test/loss=2.421023, test/num_examples=10000, total_duration=17209.624382, train/accuracy=0.639609, train/loss=1.519081, validation/accuracy=0.589620, validation/loss=1.742956, validation/num_examples=50000
I0302 15:54:03.027467 139881799980800 logging_writer.py:48] [36600] global_step=36600, grad_norm=1.2206214666366577, loss=2.7206594944000244
I0302 15:54:46.613967 139881808373504 logging_writer.py:48] [36700] global_step=36700, grad_norm=1.1989413499832153, loss=2.6030945777893066
I0302 15:55:31.280769 139881799980800 logging_writer.py:48] [36800] global_step=36800, grad_norm=1.2150077819824219, loss=2.5131428241729736
I0302 15:56:15.708401 139881808373504 logging_writer.py:48] [36900] global_step=36900, grad_norm=1.2990539073944092, loss=2.773075580596924
I0302 15:57:00.388135 139881799980800 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.1979905366897583, loss=2.606428623199463
I0302 15:57:45.092728 139881808373504 logging_writer.py:48] [37100] global_step=37100, grad_norm=1.1578149795532227, loss=5.180843353271484
I0302 15:58:29.976378 139881799980800 logging_writer.py:48] [37200] global_step=37200, grad_norm=1.0496265888214111, loss=3.1512532234191895
I0302 15:59:15.010062 139881808373504 logging_writer.py:48] [37300] global_step=37300, grad_norm=1.2408488988876343, loss=2.584662914276123
I0302 16:00:00.184481 139881799980800 logging_writer.py:48] [37400] global_step=37400, grad_norm=1.2782840728759766, loss=2.5493128299713135
I0302 16:00:37.012252 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:00:47.159467 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:01:07.572076 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:01:09.165273 140077943854912 submission_runner.py:411] Time since start: 17661.97s, 	Step: 37483, 	{'train/accuracy': 0.6413280963897705, 'train/loss': 1.495647668838501, 'validation/accuracy': 0.5907399654388428, 'validation/loss': 1.7329176664352417, 'validation/num_examples': 50000, 'test/accuracy': 0.4678000211715698, 'test/loss': 2.402662515640259, 'test/num_examples': 10000, 'score': 16428.334725379944, 'total_duration': 17661.970279455185, 'accumulated_submission_time': 16428.334725379944, 'accumulated_eval_time': 1230.3696205615997, 'accumulated_logging_time': 1.2913818359375}
I0302 16:01:09.190114 139881808373504 logging_writer.py:48] [37483] accumulated_eval_time=1230.369621, accumulated_logging_time=1.291382, accumulated_submission_time=16428.334725, global_step=37483, preemption_count=0, score=16428.334725, test/accuracy=0.467800, test/loss=2.402663, test/num_examples=10000, total_duration=17661.970279, train/accuracy=0.641328, train/loss=1.495648, validation/accuracy=0.590740, validation/loss=1.732918, validation/num_examples=50000
I0302 16:01:16.211377 139881799980800 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.3626344203948975, loss=2.5270957946777344
I0302 16:01:57.533114 139881808373504 logging_writer.py:48] [37600] global_step=37600, grad_norm=1.0190668106079102, loss=5.045200824737549
I0302 16:02:42.147333 139881799980800 logging_writer.py:48] [37700] global_step=37700, grad_norm=0.9672667980194092, loss=3.8448307514190674
I0302 16:03:27.016649 139881808373504 logging_writer.py:48] [37800] global_step=37800, grad_norm=1.0856488943099976, loss=5.157547950744629
I0302 16:04:11.495098 139881799980800 logging_writer.py:48] [37900] global_step=37900, grad_norm=1.169102668762207, loss=2.5493125915527344
I0302 16:04:55.863457 139881808373504 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.2213878631591797, loss=3.00788950920105
I0302 16:05:40.538010 139881799980800 logging_writer.py:48] [38100] global_step=38100, grad_norm=1.179751992225647, loss=2.4030086994171143
I0302 16:06:25.249294 139881808373504 logging_writer.py:48] [38200] global_step=38200, grad_norm=1.226453185081482, loss=2.6076979637145996
I0302 16:07:09.486775 139881799980800 logging_writer.py:48] [38300] global_step=38300, grad_norm=1.0853559970855713, loss=4.755173206329346
I0302 16:07:53.860288 139881808373504 logging_writer.py:48] [38400] global_step=38400, grad_norm=0.9977613091468811, loss=3.2333998680114746
I0302 16:08:09.220824 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:08:19.209787 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:08:41.048439 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:08:42.631745 140077943854912 submission_runner.py:411] Time since start: 18115.44s, 	Step: 38436, 	{'train/accuracy': 0.6577734351158142, 'train/loss': 1.416632056236267, 'validation/accuracy': 0.5920599699020386, 'validation/loss': 1.7245413064956665, 'validation/num_examples': 50000, 'test/accuracy': 0.46710002422332764, 'test/loss': 2.4115984439849854, 'test/num_examples': 10000, 'score': 16848.304398536682, 'total_duration': 18115.436757087708, 'accumulated_submission_time': 16848.304398536682, 'accumulated_eval_time': 1263.7805182933807, 'accumulated_logging_time': 1.3276479244232178}
I0302 16:08:42.653349 139881799980800 logging_writer.py:48] [38436] accumulated_eval_time=1263.780518, accumulated_logging_time=1.327648, accumulated_submission_time=16848.304399, global_step=38436, preemption_count=0, score=16848.304399, test/accuracy=0.467100, test/loss=2.411598, test/num_examples=10000, total_duration=18115.436757, train/accuracy=0.657773, train/loss=1.416632, validation/accuracy=0.592060, validation/loss=1.724541, validation/num_examples=50000
I0302 16:09:08.028890 139881808373504 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.3221626281738281, loss=4.78953218460083
I0302 16:09:50.847143 139881799980800 logging_writer.py:48] [38600] global_step=38600, grad_norm=1.1970089673995972, loss=2.5454742908477783
I0302 16:10:35.232349 139881808373504 logging_writer.py:48] [38700] global_step=38700, grad_norm=1.278182864189148, loss=2.5507521629333496
I0302 16:11:19.817001 139881799980800 logging_writer.py:48] [38800] global_step=38800, grad_norm=1.3619649410247803, loss=2.504392623901367
I0302 16:12:03.953141 139881808373504 logging_writer.py:48] [38900] global_step=38900, grad_norm=1.0834743976593018, loss=5.055206298828125
I0302 16:12:48.633648 139881799980800 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.161197304725647, loss=2.552103281021118
I0302 16:13:32.825754 139881808373504 logging_writer.py:48] [39100] global_step=39100, grad_norm=1.0386254787445068, loss=5.09835147857666
I0302 16:14:17.575461 139881799980800 logging_writer.py:48] [39200] global_step=39200, grad_norm=0.9486762285232544, loss=4.414198398590088
I0302 16:15:02.156605 139881808373504 logging_writer.py:48] [39300] global_step=39300, grad_norm=1.332034945487976, loss=2.5649144649505615
I0302 16:15:42.957854 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:15:53.177741 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:16:14.231183 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:16:15.805001 140077943854912 submission_runner.py:411] Time since start: 18568.61s, 	Step: 39393, 	{'train/accuracy': 0.6365038752555847, 'train/loss': 1.513041615486145, 'validation/accuracy': 0.5950599908828735, 'validation/loss': 1.7173501253128052, 'validation/num_examples': 50000, 'test/accuracy': 0.47540003061294556, 'test/loss': 2.3625006675720215, 'test/num_examples': 10000, 'score': 17268.549030303955, 'total_duration': 18568.60999751091, 'accumulated_submission_time': 17268.549030303955, 'accumulated_eval_time': 1296.6276342868805, 'accumulated_logging_time': 1.3599748611450195}
I0302 16:16:15.829775 139881799980800 logging_writer.py:48] [39393] accumulated_eval_time=1296.627634, accumulated_logging_time=1.359975, accumulated_submission_time=17268.549030, global_step=39393, preemption_count=0, score=17268.549030, test/accuracy=0.475400, test/loss=2.362501, test/num_examples=10000, total_duration=18568.609998, train/accuracy=0.636504, train/loss=1.513042, validation/accuracy=0.595060, validation/loss=1.717350, validation/num_examples=50000
I0302 16:16:18.948323 139881808373504 logging_writer.py:48] [39400] global_step=39400, grad_norm=1.1982489824295044, loss=2.438753128051758
I0302 16:16:59.087192 139881799980800 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.1235358715057373, loss=2.7603795528411865
I0302 16:17:43.731338 139881808373504 logging_writer.py:48] [39600] global_step=39600, grad_norm=0.9726302623748779, loss=4.9778947830200195
I0302 16:18:28.281168 139881799980800 logging_writer.py:48] [39700] global_step=39700, grad_norm=1.3528661727905273, loss=2.6156601905822754
I0302 16:19:13.523866 139881808373504 logging_writer.py:48] [39800] global_step=39800, grad_norm=1.0462700128555298, loss=3.327777147293091
I0302 16:19:57.528219 139881799980800 logging_writer.py:48] [39900] global_step=39900, grad_norm=1.190958023071289, loss=2.567143440246582
I0302 16:20:41.873406 139881808373504 logging_writer.py:48] [40000] global_step=40000, grad_norm=1.0947080850601196, loss=2.7989611625671387
I0302 16:21:26.624406 139881799980800 logging_writer.py:48] [40100] global_step=40100, grad_norm=0.9604374766349792, loss=4.007540225982666
I0302 16:22:11.142472 139881808373504 logging_writer.py:48] [40200] global_step=40200, grad_norm=1.3012022972106934, loss=2.5792417526245117
I0302 16:22:55.583112 139881799980800 logging_writer.py:48] [40300] global_step=40300, grad_norm=1.0455762147903442, loss=3.6287100315093994
I0302 16:23:15.901856 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:23:26.272609 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:23:48.976710 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:23:50.571243 140077943854912 submission_runner.py:411] Time since start: 19023.38s, 	Step: 40347, 	{'train/accuracy': 0.6510156393051147, 'train/loss': 1.4378249645233154, 'validation/accuracy': 0.6019399762153625, 'validation/loss': 1.6753579378128052, 'validation/num_examples': 50000, 'test/accuracy': 0.483100026845932, 'test/loss': 2.3189759254455566, 'test/num_examples': 10000, 'score': 17688.56049466133, 'total_duration': 19023.37623500824, 'accumulated_submission_time': 17688.56049466133, 'accumulated_eval_time': 1331.296977519989, 'accumulated_logging_time': 1.3953208923339844}
I0302 16:23:50.599543 139881808373504 logging_writer.py:48] [40347] accumulated_eval_time=1331.296978, accumulated_logging_time=1.395321, accumulated_submission_time=17688.560495, global_step=40347, preemption_count=0, score=17688.560495, test/accuracy=0.483100, test/loss=2.318976, test/num_examples=10000, total_duration=19023.376235, train/accuracy=0.651016, train/loss=1.437825, validation/accuracy=0.601940, validation/loss=1.675358, validation/num_examples=50000
I0302 16:24:11.691599 139881799980800 logging_writer.py:48] [40400] global_step=40400, grad_norm=0.962881326675415, loss=4.327117443084717
I0302 16:24:54.037448 139881808373504 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.0788187980651855, loss=2.3912594318389893
I0302 16:25:38.858252 139881799980800 logging_writer.py:48] [40600] global_step=40600, grad_norm=1.205627202987671, loss=4.5941386222839355
I0302 16:26:23.686966 139881808373504 logging_writer.py:48] [40700] global_step=40700, grad_norm=1.217880368232727, loss=2.5255701541900635
I0302 16:27:08.256679 139881799980800 logging_writer.py:48] [40800] global_step=40800, grad_norm=1.2509657144546509, loss=2.734342098236084
I0302 16:27:52.826321 139881808373504 logging_writer.py:48] [40900] global_step=40900, grad_norm=1.1134718656539917, loss=2.8480310440063477
I0302 16:28:37.448130 139881799980800 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.2183767557144165, loss=2.509690999984741
I0302 16:29:22.017053 139881808373504 logging_writer.py:48] [41100] global_step=41100, grad_norm=1.0017353296279907, loss=3.4844517707824707
I0302 16:30:06.581634 139881799980800 logging_writer.py:48] [41200] global_step=41200, grad_norm=1.0911715030670166, loss=4.452245712280273
I0302 16:30:51.000264 139881808373504 logging_writer.py:48] [41300] global_step=41300, grad_norm=1.0570342540740967, loss=3.7276546955108643
I0302 16:30:51.013597 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:31:01.264711 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:31:23.933962 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:31:25.520597 140077943854912 submission_runner.py:411] Time since start: 19478.33s, 	Step: 41301, 	{'train/accuracy': 0.6549023389816284, 'train/loss': 1.4472695589065552, 'validation/accuracy': 0.6011599898338318, 'validation/loss': 1.7104378938674927, 'validation/num_examples': 50000, 'test/accuracy': 0.4743000268936157, 'test/loss': 2.380539894104004, 'test/num_examples': 10000, 'score': 18108.91366672516, 'total_duration': 19478.32561135292, 'accumulated_submission_time': 18108.91366672516, 'accumulated_eval_time': 1365.8039565086365, 'accumulated_logging_time': 1.434863567352295}
I0302 16:31:25.543153 139881799980800 logging_writer.py:48] [41301] accumulated_eval_time=1365.803957, accumulated_logging_time=1.434864, accumulated_submission_time=18108.913667, global_step=41301, preemption_count=0, score=18108.913667, test/accuracy=0.474300, test/loss=2.380540, test/num_examples=10000, total_duration=19478.325611, train/accuracy=0.654902, train/loss=1.447270, validation/accuracy=0.601160, validation/loss=1.710438, validation/num_examples=50000
I0302 16:32:05.365610 139881808373504 logging_writer.py:48] [41400] global_step=41400, grad_norm=1.2756856679916382, loss=2.540684223175049
I0302 16:32:49.742517 139881799980800 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.0529838800430298, loss=5.093581199645996
I0302 16:33:34.495286 139881808373504 logging_writer.py:48] [41600] global_step=41600, grad_norm=1.5494651794433594, loss=2.5037453174591064
I0302 16:34:19.039111 139881799980800 logging_writer.py:48] [41700] global_step=41700, grad_norm=0.9537951946258545, loss=4.0320634841918945
I0302 16:35:03.586866 139881808373504 logging_writer.py:48] [41800] global_step=41800, grad_norm=1.2661762237548828, loss=3.8453781604766846
I0302 16:35:47.987154 139881799980800 logging_writer.py:48] [41900] global_step=41900, grad_norm=1.1619515419006348, loss=4.151954650878906
I0302 16:36:32.658056 139881808373504 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.2362265586853027, loss=2.6004247665405273
I0302 16:37:17.129080 139881799980800 logging_writer.py:48] [42100] global_step=42100, grad_norm=1.1637005805969238, loss=2.8484668731689453
I0302 16:38:01.490181 139881808373504 logging_writer.py:48] [42200] global_step=42200, grad_norm=1.1374090909957886, loss=3.1689369678497314
I0302 16:38:25.699832 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:38:35.758321 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:38:57.985954 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:38:59.572168 140077943854912 submission_runner.py:411] Time since start: 19932.38s, 	Step: 42256, 	{'train/accuracy': 0.662109375, 'train/loss': 1.3703303337097168, 'validation/accuracy': 0.6002799868583679, 'validation/loss': 1.6656572818756104, 'validation/num_examples': 50000, 'test/accuracy': 0.47770002484321594, 'test/loss': 2.3627915382385254, 'test/num_examples': 10000, 'score': 18529.00963950157, 'total_duration': 19932.3771443367, 'accumulated_submission_time': 18529.00963950157, 'accumulated_eval_time': 1399.6762397289276, 'accumulated_logging_time': 1.4674532413482666}
I0302 16:38:59.601615 139881799980800 logging_writer.py:48] [42256] accumulated_eval_time=1399.676240, accumulated_logging_time=1.467453, accumulated_submission_time=18529.009640, global_step=42256, preemption_count=0, score=18529.009640, test/accuracy=0.477700, test/loss=2.362792, test/num_examples=10000, total_duration=19932.377144, train/accuracy=0.662109, train/loss=1.370330, validation/accuracy=0.600280, validation/loss=1.665657, validation/num_examples=50000
I0302 16:39:17.181317 139881808373504 logging_writer.py:48] [42300] global_step=42300, grad_norm=1.1221472024917603, loss=3.2560951709747314
I0302 16:39:59.220340 139881799980800 logging_writer.py:48] [42400] global_step=42400, grad_norm=1.1863493919372559, loss=2.5409016609191895
I0302 16:40:43.505491 139881808373504 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.0149797201156616, loss=3.855349540710449
I0302 16:41:28.335223 139881799980800 logging_writer.py:48] [42600] global_step=42600, grad_norm=1.2023471593856812, loss=2.341996908187866
I0302 16:42:12.707134 139881808373504 logging_writer.py:48] [42700] global_step=42700, grad_norm=1.547011137008667, loss=2.485690116882324
I0302 16:42:57.024810 139881799980800 logging_writer.py:48] [42800] global_step=42800, grad_norm=1.0035245418548584, loss=4.475018501281738
I0302 16:43:41.290152 139881808373504 logging_writer.py:48] [42900] global_step=42900, grad_norm=1.3838828802108765, loss=5.0797624588012695
I0302 16:44:25.970115 139881799980800 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.2415183782577515, loss=2.6130459308624268
I0302 16:45:10.420944 139881808373504 logging_writer.py:48] [43100] global_step=43100, grad_norm=1.1582157611846924, loss=3.1268653869628906
I0302 16:45:54.560777 139881799980800 logging_writer.py:48] [43200] global_step=43200, grad_norm=1.2162152528762817, loss=2.483776807785034
I0302 16:46:00.008131 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:46:10.610212 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:46:35.030042 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:46:36.619713 140077943854912 submission_runner.py:411] Time since start: 20389.42s, 	Step: 43214, 	{'train/accuracy': 0.6528710722923279, 'train/loss': 1.4166855812072754, 'validation/accuracy': 0.6093400120735168, 'validation/loss': 1.6414382457733154, 'validation/num_examples': 50000, 'test/accuracy': 0.4887000322341919, 'test/loss': 2.2992591857910156, 'test/num_examples': 10000, 'score': 18949.35471701622, 'total_duration': 20389.424694776535, 'accumulated_submission_time': 18949.35471701622, 'accumulated_eval_time': 1436.2877542972565, 'accumulated_logging_time': 1.508568525314331}
I0302 16:46:36.648430 139881808373504 logging_writer.py:48] [43214] accumulated_eval_time=1436.287754, accumulated_logging_time=1.508569, accumulated_submission_time=18949.354717, global_step=43214, preemption_count=0, score=18949.354717, test/accuracy=0.488700, test/loss=2.299259, test/num_examples=10000, total_duration=20389.424695, train/accuracy=0.652871, train/loss=1.416686, validation/accuracy=0.609340, validation/loss=1.641438, validation/num_examples=50000
I0302 16:47:10.616713 139881799980800 logging_writer.py:48] [43300] global_step=43300, grad_norm=0.885208785533905, loss=4.250122547149658
I0302 16:47:54.598477 139881808373504 logging_writer.py:48] [43400] global_step=43400, grad_norm=1.227768063545227, loss=2.495312213897705
I0302 16:48:39.319029 139881799980800 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.427927851676941, loss=2.44113826751709
I0302 16:49:24.014829 139881808373504 logging_writer.py:48] [43600] global_step=43600, grad_norm=1.1719216108322144, loss=4.877519607543945
I0302 16:50:08.469991 139881799980800 logging_writer.py:48] [43700] global_step=43700, grad_norm=1.0507431030273438, loss=3.066437005996704
I0302 16:50:52.986744 139881808373504 logging_writer.py:48] [43800] global_step=43800, grad_norm=1.292304515838623, loss=2.986588954925537
I0302 16:51:37.618823 139881799980800 logging_writer.py:48] [43900] global_step=43900, grad_norm=1.258693814277649, loss=5.174229621887207
I0302 16:52:22.075909 139881808373504 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.9614246487617493, loss=4.096170425415039
I0302 16:53:06.644637 139881799980800 logging_writer.py:48] [44100] global_step=44100, grad_norm=1.4467631578445435, loss=2.5225720405578613
I0302 16:53:36.917774 140077943854912 spec.py:321] Evaluating on the training split.
I0302 16:53:47.192880 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 16:54:09.988692 140077943854912 spec.py:349] Evaluating on the test split.
I0302 16:54:11.570902 140077943854912 submission_runner.py:411] Time since start: 20844.38s, 	Step: 44170, 	{'train/accuracy': 0.6615234017372131, 'train/loss': 1.3803268671035767, 'validation/accuracy': 0.6105799674987793, 'validation/loss': 1.6226335763931274, 'validation/num_examples': 50000, 'test/accuracy': 0.4886000156402588, 'test/loss': 2.2939584255218506, 'test/num_examples': 10000, 'score': 19369.56394290924, 'total_duration': 20844.375911474228, 'accumulated_submission_time': 19369.56394290924, 'accumulated_eval_time': 1470.940866470337, 'accumulated_logging_time': 1.5481336116790771}
I0302 16:54:11.594368 139881808373504 logging_writer.py:48] [44170] accumulated_eval_time=1470.940866, accumulated_logging_time=1.548134, accumulated_submission_time=19369.563943, global_step=44170, preemption_count=0, score=19369.563943, test/accuracy=0.488600, test/loss=2.293958, test/num_examples=10000, total_duration=20844.375911, train/accuracy=0.661523, train/loss=1.380327, validation/accuracy=0.610580, validation/loss=1.622634, validation/num_examples=50000
I0302 16:54:23.704335 139881799980800 logging_writer.py:48] [44200] global_step=44200, grad_norm=1.0200306177139282, loss=4.707350730895996
I0302 16:55:05.128598 139881808373504 logging_writer.py:48] [44300] global_step=44300, grad_norm=1.0409951210021973, loss=3.634281873703003
I0302 16:55:49.569092 139881799980800 logging_writer.py:48] [44400] global_step=44400, grad_norm=1.0259431600570679, loss=5.091765880584717
I0302 16:56:34.212076 139881808373504 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.4836457967758179, loss=2.6664061546325684
I0302 16:57:18.585301 139881799980800 logging_writer.py:48] [44600] global_step=44600, grad_norm=1.3098169565200806, loss=2.2938215732574463
I0302 16:58:03.085836 139881808373504 logging_writer.py:48] [44700] global_step=44700, grad_norm=0.9869874119758606, loss=3.904006242752075
I0302 16:58:47.542702 139881799980800 logging_writer.py:48] [44800] global_step=44800, grad_norm=1.0987880229949951, loss=3.6357009410858154
I0302 16:59:31.747181 139881808373504 logging_writer.py:48] [44900] global_step=44900, grad_norm=1.1818794012069702, loss=2.560955762863159
I0302 17:00:16.174270 139881799980800 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.2162264585494995, loss=2.4939260482788086
I0302 17:01:00.495990 139881808373504 logging_writer.py:48] [45100] global_step=45100, grad_norm=1.3172670602798462, loss=2.443784236907959
I0302 17:01:11.942517 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:01:22.017894 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:01:44.674736 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:01:46.270808 140077943854912 submission_runner.py:411] Time since start: 21299.08s, 	Step: 45127, 	{'train/accuracy': 0.6758593320846558, 'train/loss': 1.3159501552581787, 'validation/accuracy': 0.6125400066375732, 'validation/loss': 1.6239898204803467, 'validation/num_examples': 50000, 'test/accuracy': 0.48730000853538513, 'test/loss': 2.2900307178497314, 'test/num_examples': 10000, 'score': 19789.847430944443, 'total_duration': 21299.075829267502, 'accumulated_submission_time': 19789.847430944443, 'accumulated_eval_time': 1505.269142627716, 'accumulated_logging_time': 1.5860624313354492}
I0302 17:01:46.292932 139881799980800 logging_writer.py:48] [45127] accumulated_eval_time=1505.269143, accumulated_logging_time=1.586062, accumulated_submission_time=19789.847431, global_step=45127, preemption_count=0, score=19789.847431, test/accuracy=0.487300, test/loss=2.290031, test/num_examples=10000, total_duration=21299.075829, train/accuracy=0.675859, train/loss=1.315950, validation/accuracy=0.612540, validation/loss=1.623990, validation/num_examples=50000
I0302 17:02:15.215341 139881808373504 logging_writer.py:48] [45200] global_step=45200, grad_norm=1.306565523147583, loss=2.6809637546539307
I0302 17:02:58.780722 139881799980800 logging_writer.py:48] [45300] global_step=45300, grad_norm=1.239997148513794, loss=4.909924030303955
I0302 17:03:43.641729 139881808373504 logging_writer.py:48] [45400] global_step=45400, grad_norm=1.1878035068511963, loss=3.0957534313201904
I0302 17:04:28.030876 139881799980800 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.1021591424942017, loss=4.148613929748535
I0302 17:05:12.603095 139881808373504 logging_writer.py:48] [45600] global_step=45600, grad_norm=1.0464991331100464, loss=4.902954578399658
I0302 17:05:57.089979 139881799980800 logging_writer.py:48] [45700] global_step=45700, grad_norm=1.1984264850616455, loss=3.358522653579712
I0302 17:06:41.509947 139881808373504 logging_writer.py:48] [45800] global_step=45800, grad_norm=1.1755362749099731, loss=2.4000744819641113
I0302 17:07:25.993301 139881799980800 logging_writer.py:48] [45900] global_step=45900, grad_norm=1.2382042407989502, loss=2.8283345699310303
I0302 17:08:10.139891 139881808373504 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.0177314281463623, loss=4.530393600463867
I0302 17:08:46.584042 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:08:56.709746 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:09:16.915064 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:09:18.512261 140077943854912 submission_runner.py:411] Time since start: 21751.32s, 	Step: 46084, 	{'train/accuracy': 0.6569140553474426, 'train/loss': 1.404916763305664, 'validation/accuracy': 0.6086599826812744, 'validation/loss': 1.6356945037841797, 'validation/num_examples': 50000, 'test/accuracy': 0.49230003356933594, 'test/loss': 2.3095061779022217, 'test/num_examples': 10000, 'score': 20210.077967882156, 'total_duration': 21751.317249059677, 'accumulated_submission_time': 20210.077967882156, 'accumulated_eval_time': 1537.1973378658295, 'accumulated_logging_time': 1.619213342666626}
I0302 17:09:18.542484 139881799980800 logging_writer.py:48] [46084] accumulated_eval_time=1537.197338, accumulated_logging_time=1.619213, accumulated_submission_time=20210.077968, global_step=46084, preemption_count=0, score=20210.077968, test/accuracy=0.492300, test/loss=2.309506, test/num_examples=10000, total_duration=21751.317249, train/accuracy=0.656914, train/loss=1.404917, validation/accuracy=0.608660, validation/loss=1.635695, validation/num_examples=50000
I0302 17:09:25.182783 139881808373504 logging_writer.py:48] [46100] global_step=46100, grad_norm=1.0299558639526367, loss=4.200343608856201
I0302 17:10:05.698909 139881799980800 logging_writer.py:48] [46200] global_step=46200, grad_norm=1.276573657989502, loss=4.865141868591309
I0302 17:10:49.729052 139881808373504 logging_writer.py:48] [46300] global_step=46300, grad_norm=1.1360979080200195, loss=4.131715297698975
I0302 17:11:34.353850 139881799980800 logging_writer.py:48] [46400] global_step=46400, grad_norm=1.4196056127548218, loss=2.46407413482666
I0302 17:12:19.018331 139881808373504 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.2734434604644775, loss=2.6803953647613525
I0302 17:13:03.389926 139881799980800 logging_writer.py:48] [46600] global_step=46600, grad_norm=1.4246660470962524, loss=2.591374397277832
I0302 17:13:47.676578 139881808373504 logging_writer.py:48] [46700] global_step=46700, grad_norm=1.3307565450668335, loss=2.830767869949341
I0302 17:14:32.043630 139881799980800 logging_writer.py:48] [46800] global_step=46800, grad_norm=1.3741179704666138, loss=2.4612579345703125
I0302 17:15:16.662270 139881808373504 logging_writer.py:48] [46900] global_step=46900, grad_norm=1.1923643350601196, loss=4.217698097229004
I0302 17:16:01.153254 139881799980800 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.1388798952102661, loss=2.7425684928894043
I0302 17:16:18.715903 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:16:28.909379 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:16:52.034038 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:16:53.613506 140077943854912 submission_runner.py:411] Time since start: 22206.42s, 	Step: 47041, 	{'train/accuracy': 0.6555468440055847, 'train/loss': 1.4303855895996094, 'validation/accuracy': 0.6114799976348877, 'validation/loss': 1.6497628688812256, 'validation/num_examples': 50000, 'test/accuracy': 0.4798000156879425, 'test/loss': 2.3286588191986084, 'test/num_examples': 10000, 'score': 20630.187987327576, 'total_duration': 22206.418523073196, 'accumulated_submission_time': 20630.187987327576, 'accumulated_eval_time': 1572.094933271408, 'accumulated_logging_time': 1.6627938747406006}
I0302 17:16:53.637071 139881808373504 logging_writer.py:48] [47041] accumulated_eval_time=1572.094933, accumulated_logging_time=1.662794, accumulated_submission_time=20630.187987, global_step=47041, preemption_count=0, score=20630.187987, test/accuracy=0.479800, test/loss=2.328659, test/num_examples=10000, total_duration=22206.418523, train/accuracy=0.655547, train/loss=1.430386, validation/accuracy=0.611480, validation/loss=1.649763, validation/num_examples=50000
I0302 17:17:17.065001 139881799980800 logging_writer.py:48] [47100] global_step=47100, grad_norm=1.099955439567566, loss=3.2607622146606445
I0302 17:17:59.376898 139881808373504 logging_writer.py:48] [47200] global_step=47200, grad_norm=1.16914963722229, loss=2.9921414852142334
I0302 17:18:44.667072 139881799980800 logging_writer.py:48] [47300] global_step=47300, grad_norm=1.0758343935012817, loss=5.050608158111572
I0302 17:19:29.494534 139881808373504 logging_writer.py:48] [47400] global_step=47400, grad_norm=1.1156222820281982, loss=2.850093126296997
I0302 17:20:13.827163 139881799980800 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.1921031475067139, loss=3.8301637172698975
I0302 17:20:58.459492 139881808373504 logging_writer.py:48] [47600] global_step=47600, grad_norm=1.1960439682006836, loss=3.500671148300171
I0302 17:21:42.917980 139881799980800 logging_writer.py:48] [47700] global_step=47700, grad_norm=1.279333233833313, loss=2.3321075439453125
I0302 17:22:27.427056 139881808373504 logging_writer.py:48] [47800] global_step=47800, grad_norm=1.177059531211853, loss=2.350324869155884
I0302 17:23:11.846819 139881799980800 logging_writer.py:48] [47900] global_step=47900, grad_norm=1.032800555229187, loss=3.7121927738189697
I0302 17:23:53.905737 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:24:04.335282 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:24:27.064996 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:24:28.646661 140077943854912 submission_runner.py:411] Time since start: 22661.45s, 	Step: 47996, 	{'train/accuracy': 0.6664062142372131, 'train/loss': 1.364644169807434, 'validation/accuracy': 0.611739993095398, 'validation/loss': 1.6247352361679077, 'validation/num_examples': 50000, 'test/accuracy': 0.4918000102043152, 'test/loss': 2.2892038822174072, 'test/num_examples': 10000, 'score': 21050.396213054657, 'total_duration': 22661.451620817184, 'accumulated_submission_time': 21050.396213054657, 'accumulated_eval_time': 1606.835849761963, 'accumulated_logging_time': 1.6966009140014648}
I0302 17:24:28.679776 139881808373504 logging_writer.py:48] [47996] accumulated_eval_time=1606.835850, accumulated_logging_time=1.696601, accumulated_submission_time=21050.396213, global_step=47996, preemption_count=0, score=21050.396213, test/accuracy=0.491800, test/loss=2.289204, test/num_examples=10000, total_duration=22661.451621, train/accuracy=0.666406, train/loss=1.364644, validation/accuracy=0.611740, validation/loss=1.624735, validation/num_examples=50000
I0302 17:24:30.630362 139881799980800 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.527079701423645, loss=2.4187493324279785
I0302 17:25:10.752536 139881808373504 logging_writer.py:48] [48100] global_step=48100, grad_norm=1.029335856437683, loss=3.261688709259033
I0302 17:25:54.883356 139881799980800 logging_writer.py:48] [48200] global_step=48200, grad_norm=1.4018702507019043, loss=2.39117431640625
I0302 17:26:39.632679 139881808373504 logging_writer.py:48] [48300] global_step=48300, grad_norm=1.461744785308838, loss=2.313866138458252
I0302 17:27:24.180264 139881799980800 logging_writer.py:48] [48400] global_step=48400, grad_norm=1.0524078607559204, loss=3.7754790782928467
I0302 17:28:08.547746 139881808373504 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.3631534576416016, loss=4.84526252746582
I0302 17:28:52.927673 139881799980800 logging_writer.py:48] [48600] global_step=48600, grad_norm=1.1208521127700806, loss=2.3979954719543457
I0302 17:29:37.632262 139881808373504 logging_writer.py:48] [48700] global_step=48700, grad_norm=1.3522979021072388, loss=2.3683526515960693
I0302 17:30:22.758693 139881799980800 logging_writer.py:48] [48800] global_step=48800, grad_norm=1.2322170734405518, loss=2.423440456390381
I0302 17:31:07.601079 139881808373504 logging_writer.py:48] [48900] global_step=48900, grad_norm=1.27901291847229, loss=2.2935588359832764
I0302 17:31:29.006105 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:31:38.977005 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:32:01.701985 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:32:03.282217 140077943854912 submission_runner.py:411] Time since start: 23116.09s, 	Step: 48950, 	{'train/accuracy': 0.6929882764816284, 'train/loss': 1.2464438676834106, 'validation/accuracy': 0.6179400086402893, 'validation/loss': 1.586337924003601, 'validation/num_examples': 50000, 'test/accuracy': 0.49330002069473267, 'test/loss': 2.256746530532837, 'test/num_examples': 10000, 'score': 21470.66002368927, 'total_duration': 23116.087234020233, 'accumulated_submission_time': 21470.66002368927, 'accumulated_eval_time': 1641.1119446754456, 'accumulated_logging_time': 1.742445945739746}
I0302 17:32:03.308711 139881799980800 logging_writer.py:48] [48950] accumulated_eval_time=1641.111945, accumulated_logging_time=1.742446, accumulated_submission_time=21470.660024, global_step=48950, preemption_count=0, score=21470.660024, test/accuracy=0.493300, test/loss=2.256747, test/num_examples=10000, total_duration=23116.087234, train/accuracy=0.692988, train/loss=1.246444, validation/accuracy=0.617940, validation/loss=1.586338, validation/num_examples=50000
I0302 17:32:23.226051 139881808373504 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.3403431177139282, loss=2.3246023654937744
I0302 17:33:05.723501 139881799980800 logging_writer.py:48] [49100] global_step=49100, grad_norm=1.1905404329299927, loss=4.964920520782471
I0302 17:33:50.125732 139881808373504 logging_writer.py:48] [49200] global_step=49200, grad_norm=1.2108656167984009, loss=2.421147584915161
I0302 17:34:34.545116 139881799980800 logging_writer.py:48] [49300] global_step=49300, grad_norm=1.3653250932693481, loss=2.2545523643493652
I0302 17:35:19.261799 139881808373504 logging_writer.py:48] [49400] global_step=49400, grad_norm=1.2615222930908203, loss=2.523345470428467
I0302 17:36:03.831338 139881799980800 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.1764289140701294, loss=2.709524631500244
I0302 17:36:48.267812 139881808373504 logging_writer.py:48] [49600] global_step=49600, grad_norm=1.241976261138916, loss=2.458921432495117
I0302 17:37:32.533035 139881799980800 logging_writer.py:48] [49700] global_step=49700, grad_norm=1.3087372779846191, loss=4.022030353546143
I0302 17:38:17.031226 139881808373504 logging_writer.py:48] [49800] global_step=49800, grad_norm=1.2301104068756104, loss=3.203054189682007
I0302 17:39:01.384073 139881799980800 logging_writer.py:48] [49900] global_step=49900, grad_norm=1.1459451913833618, loss=5.012468338012695
I0302 17:39:03.366682 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:39:13.640570 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:39:36.389180 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:39:37.985319 140077943854912 submission_runner.py:411] Time since start: 23570.79s, 	Step: 49906, 	{'train/accuracy': 0.6653515696525574, 'train/loss': 1.385420560836792, 'validation/accuracy': 0.6169799566268921, 'validation/loss': 1.6083929538726807, 'validation/num_examples': 50000, 'test/accuracy': 0.49330002069473267, 'test/loss': 2.2742130756378174, 'test/num_examples': 10000, 'score': 21890.65754508972, 'total_duration': 23570.7903380394, 'accumulated_submission_time': 21890.65754508972, 'accumulated_eval_time': 1675.7305736541748, 'accumulated_logging_time': 1.7791416645050049}
I0302 17:39:38.008430 139881808373504 logging_writer.py:48] [49906] accumulated_eval_time=1675.730574, accumulated_logging_time=1.779142, accumulated_submission_time=21890.657545, global_step=49906, preemption_count=0, score=21890.657545, test/accuracy=0.493300, test/loss=2.274213, test/num_examples=10000, total_duration=23570.790338, train/accuracy=0.665352, train/loss=1.385421, validation/accuracy=0.616980, validation/loss=1.608393, validation/num_examples=50000
I0302 17:40:15.458646 139881799980800 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.3067681789398193, loss=2.421619415283203
I0302 17:40:59.699732 139881808373504 logging_writer.py:48] [50100] global_step=50100, grad_norm=1.3626253604888916, loss=2.5202691555023193
I0302 17:41:44.162492 139881799980800 logging_writer.py:48] [50200] global_step=50200, grad_norm=1.2857048511505127, loss=2.4496419429779053
I0302 17:42:28.853732 139881808373504 logging_writer.py:48] [50300] global_step=50300, grad_norm=1.2946605682373047, loss=2.4715089797973633
I0302 17:43:13.155408 139881799980800 logging_writer.py:48] [50400] global_step=50400, grad_norm=1.1450390815734863, loss=4.518322944641113
I0302 17:43:57.578079 139881808373504 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.379636526107788, loss=2.3551297187805176
I0302 17:44:42.039582 139881799980800 logging_writer.py:48] [50600] global_step=50600, grad_norm=1.3014929294586182, loss=2.6926941871643066
I0302 17:45:26.707890 139881808373504 logging_writer.py:48] [50700] global_step=50700, grad_norm=1.2628004550933838, loss=2.7200846672058105
I0302 17:46:11.260598 139881799980800 logging_writer.py:48] [50800] global_step=50800, grad_norm=1.2186408042907715, loss=4.825332164764404
I0302 17:46:38.097633 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:46:48.576887 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:47:11.423743 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:47:13.011967 140077943854912 submission_runner.py:411] Time since start: 24025.82s, 	Step: 50862, 	{'train/accuracy': 0.6701366901397705, 'train/loss': 1.3385523557662964, 'validation/accuracy': 0.6211999654769897, 'validation/loss': 1.5810306072235107, 'validation/num_examples': 50000, 'test/accuracy': 0.4958000183105469, 'test/loss': 2.254197597503662, 'test/num_examples': 10000, 'score': 22310.686877965927, 'total_duration': 24025.816939115524, 'accumulated_submission_time': 22310.686877965927, 'accumulated_eval_time': 1710.644835472107, 'accumulated_logging_time': 1.8122942447662354}
I0302 17:47:13.035159 139881808373504 logging_writer.py:48] [50862] accumulated_eval_time=1710.644835, accumulated_logging_time=1.812294, accumulated_submission_time=22310.686878, global_step=50862, preemption_count=0, score=22310.686878, test/accuracy=0.495800, test/loss=2.254198, test/num_examples=10000, total_duration=24025.816939, train/accuracy=0.670137, train/loss=1.338552, validation/accuracy=0.621200, validation/loss=1.581031, validation/num_examples=50000
I0302 17:47:28.261364 139881799980800 logging_writer.py:48] [50900] global_step=50900, grad_norm=1.221907138824463, loss=2.4770824909210205
I0302 17:48:10.270140 139881808373504 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.3239808082580566, loss=2.49076247215271
I0302 17:48:54.692433 139881799980800 logging_writer.py:48] [51100] global_step=51100, grad_norm=1.0865044593811035, loss=3.6646718978881836
I0302 17:49:39.604135 139881808373504 logging_writer.py:48] [51200] global_step=51200, grad_norm=1.0404791831970215, loss=4.532588005065918
I0302 17:50:24.085282 139881799980800 logging_writer.py:48] [51300] global_step=51300, grad_norm=1.1263775825500488, loss=3.515488624572754
I0302 17:51:08.559905 139881808373504 logging_writer.py:48] [51400] global_step=51400, grad_norm=0.9848787188529968, loss=4.283855438232422
I0302 17:51:52.678152 139881799980800 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.337228536605835, loss=2.457850933074951
I0302 17:52:37.272592 139881808373504 logging_writer.py:48] [51600] global_step=51600, grad_norm=1.3291555643081665, loss=2.4237160682678223
I0302 17:53:21.535854 139881799980800 logging_writer.py:48] [51700] global_step=51700, grad_norm=1.2215625047683716, loss=2.7848989963531494
I0302 17:54:06.066050 139881808373504 logging_writer.py:48] [51800] global_step=51800, grad_norm=1.1039743423461914, loss=4.2942962646484375
I0302 17:54:13.287635 140077943854912 spec.py:321] Evaluating on the training split.
I0302 17:54:23.429201 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 17:54:45.341055 140077943854912 spec.py:349] Evaluating on the test split.
I0302 17:54:46.936141 140077943854912 submission_runner.py:411] Time since start: 24479.74s, 	Step: 51818, 	{'train/accuracy': 0.6743554472923279, 'train/loss': 1.317443609237671, 'validation/accuracy': 0.6154999732971191, 'validation/loss': 1.582787036895752, 'validation/num_examples': 50000, 'test/accuracy': 0.5011000037193298, 'test/loss': 2.231066942214966, 'test/num_examples': 10000, 'score': 22730.878219604492, 'total_duration': 24479.74113345146, 'accumulated_submission_time': 22730.878219604492, 'accumulated_eval_time': 1744.2933213710785, 'accumulated_logging_time': 1.8468284606933594}
I0302 17:54:46.965950 139881799980800 logging_writer.py:48] [51818] accumulated_eval_time=1744.293321, accumulated_logging_time=1.846828, accumulated_submission_time=22730.878220, global_step=51818, preemption_count=0, score=22730.878220, test/accuracy=0.501100, test/loss=2.231067, test/num_examples=10000, total_duration=24479.741133, train/accuracy=0.674355, train/loss=1.317444, validation/accuracy=0.615500, validation/loss=1.582787, validation/num_examples=50000
I0302 17:55:19.730227 139881808373504 logging_writer.py:48] [51900] global_step=51900, grad_norm=1.2352248430252075, loss=2.5897269248962402
I0302 17:56:03.912661 139881799980800 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.4401545524597168, loss=2.5374085903167725
I0302 17:56:48.652416 139881808373504 logging_writer.py:48] [52100] global_step=52100, grad_norm=1.3002277612686157, loss=2.355905532836914
I0302 17:57:33.220324 139881799980800 logging_writer.py:48] [52200] global_step=52200, grad_norm=1.2772188186645508, loss=2.5177528858184814
I0302 17:58:17.544006 139881808373504 logging_writer.py:48] [52300] global_step=52300, grad_norm=1.2039698362350464, loss=2.406379222869873
I0302 17:59:02.234260 139881799980800 logging_writer.py:48] [52400] global_step=52400, grad_norm=1.190871238708496, loss=2.3930716514587402
I0302 17:59:46.744477 139881808373504 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.186076045036316, loss=2.542166233062744
I0302 18:00:31.663114 139881799980800 logging_writer.py:48] [52600] global_step=52600, grad_norm=1.2787280082702637, loss=2.341078758239746
I0302 18:01:16.426100 139881808373504 logging_writer.py:48] [52700] global_step=52700, grad_norm=1.0605015754699707, loss=4.2396955490112305
I0302 18:01:47.019077 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:01:57.484532 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:02:22.321074 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:02:23.901951 140077943854912 submission_runner.py:411] Time since start: 24936.71s, 	Step: 52770, 	{'train/accuracy': 0.6700195074081421, 'train/loss': 1.3372474908828735, 'validation/accuracy': 0.6182599663734436, 'validation/loss': 1.5742107629776, 'validation/num_examples': 50000, 'test/accuracy': 0.5, 'test/loss': 2.2460379600524902, 'test/num_examples': 10000, 'score': 23150.866242170334, 'total_duration': 24936.70695376396, 'accumulated_submission_time': 23150.866242170334, 'accumulated_eval_time': 1781.1761672496796, 'accumulated_logging_time': 1.8918776512145996}
I0302 18:02:23.934388 139881799980800 logging_writer.py:48] [52770] accumulated_eval_time=1781.176167, accumulated_logging_time=1.891878, accumulated_submission_time=23150.866242, global_step=52770, preemption_count=0, score=23150.866242, test/accuracy=0.500000, test/loss=2.246038, test/num_examples=10000, total_duration=24936.706954, train/accuracy=0.670020, train/loss=1.337247, validation/accuracy=0.618260, validation/loss=1.574211, validation/num_examples=50000
I0302 18:02:36.029225 139881808373504 logging_writer.py:48] [52800] global_step=52800, grad_norm=1.1774896383285522, loss=2.500030040740967
I0302 18:03:17.592194 139881799980800 logging_writer.py:48] [52900] global_step=52900, grad_norm=1.0679630041122437, loss=3.862731456756592
I0302 18:04:01.895423 139881808373504 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.2623424530029297, loss=2.353287696838379
I0302 18:04:46.532509 139881799980800 logging_writer.py:48] [53100] global_step=53100, grad_norm=1.240233302116394, loss=4.2420334815979
I0302 18:05:31.181232 139881808373504 logging_writer.py:48] [53200] global_step=53200, grad_norm=1.1218030452728271, loss=3.96410870552063
I0302 18:06:15.449228 139881799980800 logging_writer.py:48] [53300] global_step=53300, grad_norm=1.4286502599716187, loss=2.2645621299743652
I0302 18:06:59.981100 139881808373504 logging_writer.py:48] [53400] global_step=53400, grad_norm=1.0073000192642212, loss=3.2667267322540283
I0302 18:07:44.502475 139881799980800 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.3473021984100342, loss=2.3572311401367188
I0302 18:08:29.084054 139881808373504 logging_writer.py:48] [53600] global_step=53600, grad_norm=1.205734372138977, loss=2.428382635116577
I0302 18:09:13.473838 139881799980800 logging_writer.py:48] [53700] global_step=53700, grad_norm=1.281768560409546, loss=2.5335657596588135
I0302 18:09:24.217989 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:09:34.250447 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:09:57.193760 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:09:58.772523 140077943854912 submission_runner.py:411] Time since start: 25391.58s, 	Step: 53726, 	{'train/accuracy': 0.6646288633346558, 'train/loss': 1.3680269718170166, 'validation/accuracy': 0.6178399920463562, 'validation/loss': 1.5924180746078491, 'validation/num_examples': 50000, 'test/accuracy': 0.4960000216960907, 'test/loss': 2.2424094676971436, 'test/num_examples': 10000, 'score': 23571.08939766884, 'total_duration': 25391.57753252983, 'accumulated_submission_time': 23571.08939766884, 'accumulated_eval_time': 1815.730684518814, 'accumulated_logging_time': 1.9351487159729004}
I0302 18:09:58.796075 139881808373504 logging_writer.py:48] [53726] accumulated_eval_time=1815.730685, accumulated_logging_time=1.935149, accumulated_submission_time=23571.089398, global_step=53726, preemption_count=0, score=23571.089398, test/accuracy=0.496000, test/loss=2.242409, test/num_examples=10000, total_duration=25391.577533, train/accuracy=0.664629, train/loss=1.368027, validation/accuracy=0.617840, validation/loss=1.592418, validation/num_examples=50000
I0302 18:10:28.291619 139881799980800 logging_writer.py:48] [53800] global_step=53800, grad_norm=1.1658658981323242, loss=3.0037946701049805
I0302 18:11:11.798593 139881808373504 logging_writer.py:48] [53900] global_step=53900, grad_norm=1.2093613147735596, loss=2.5492844581604004
I0302 18:11:56.063071 139881799980800 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.7247154712677002, loss=2.6720752716064453
I0302 18:12:40.656377 139881808373504 logging_writer.py:48] [54100] global_step=54100, grad_norm=1.3661293983459473, loss=2.6130261421203613
I0302 18:13:25.359240 139881799980800 logging_writer.py:48] [54200] global_step=54200, grad_norm=1.1700371503829956, loss=4.960824012756348
I0302 18:14:09.785061 139881808373504 logging_writer.py:48] [54300] global_step=54300, grad_norm=1.1965802907943726, loss=2.6621522903442383
I0302 18:14:54.160622 139881799980800 logging_writer.py:48] [54400] global_step=54400, grad_norm=1.372851848602295, loss=2.3375229835510254
I0302 18:15:38.444135 139881808373504 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.2471539974212646, loss=2.403393030166626
I0302 18:16:22.620368 139881799980800 logging_writer.py:48] [54600] global_step=54600, grad_norm=1.3652315139770508, loss=2.3480958938598633
I0302 18:16:59.017768 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:17:09.360648 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:17:30.109754 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:17:31.692970 140077943854912 submission_runner.py:411] Time since start: 25844.50s, 	Step: 54684, 	{'train/accuracy': 0.6791015267372131, 'train/loss': 1.3228133916854858, 'validation/accuracy': 0.6257199645042419, 'validation/loss': 1.5733473300933838, 'validation/num_examples': 50000, 'test/accuracy': 0.4976000189781189, 'test/loss': 2.2368738651275635, 'test/num_examples': 10000, 'score': 23991.25001358986, 'total_duration': 25844.49798321724, 'accumulated_submission_time': 23991.25001358986, 'accumulated_eval_time': 1848.4059002399445, 'accumulated_logging_time': 1.9695231914520264}
I0302 18:17:31.717596 139881808373504 logging_writer.py:48] [54684] accumulated_eval_time=1848.405900, accumulated_logging_time=1.969523, accumulated_submission_time=23991.250014, global_step=54684, preemption_count=0, score=23991.250014, test/accuracy=0.497600, test/loss=2.236874, test/num_examples=10000, total_duration=25844.497983, train/accuracy=0.679102, train/loss=1.322813, validation/accuracy=0.625720, validation/loss=1.573347, validation/num_examples=50000
I0302 18:17:38.341373 139881799980800 logging_writer.py:48] [54700] global_step=54700, grad_norm=1.2575570344924927, loss=2.774562358856201
I0302 18:18:19.155076 139881808373504 logging_writer.py:48] [54800] global_step=54800, grad_norm=1.4901846647262573, loss=2.284853935241699
I0302 18:19:03.542567 139881799980800 logging_writer.py:48] [54900] global_step=54900, grad_norm=1.368276596069336, loss=2.431826591491699
I0302 18:19:47.703382 139881808373504 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.2985671758651733, loss=2.4612677097320557
I0302 18:20:32.416787 139881799980800 logging_writer.py:48] [55100] global_step=55100, grad_norm=1.102716326713562, loss=3.9748435020446777
I0302 18:21:16.678424 139881808373504 logging_writer.py:48] [55200] global_step=55200, grad_norm=1.3592556715011597, loss=2.379110097885132
I0302 18:22:00.878616 139881799980800 logging_writer.py:48] [55300] global_step=55300, grad_norm=1.374367356300354, loss=2.3834328651428223
I0302 18:22:45.653351 139881808373504 logging_writer.py:48] [55400] global_step=55400, grad_norm=1.2490183115005493, loss=2.294234275817871
I0302 18:23:29.848663 139881799980800 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.2881885766983032, loss=2.222886323928833
I0302 18:24:14.349851 139881808373504 logging_writer.py:48] [55600] global_step=55600, grad_norm=1.3107928037643433, loss=2.328608751296997
I0302 18:24:31.718452 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:24:42.430287 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:25:03.085254 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:25:04.673452 140077943854912 submission_runner.py:411] Time since start: 26297.48s, 	Step: 55641, 	{'train/accuracy': 0.6865624785423279, 'train/loss': 1.307192087173462, 'validation/accuracy': 0.6205799579620361, 'validation/loss': 1.6071199178695679, 'validation/num_examples': 50000, 'test/accuracy': 0.49540001153945923, 'test/loss': 2.2573320865631104, 'test/num_examples': 10000, 'score': 24411.1894197464, 'total_duration': 26297.478448867798, 'accumulated_submission_time': 24411.1894197464, 'accumulated_eval_time': 1881.3608667850494, 'accumulated_logging_time': 2.004138708114624}
I0302 18:25:04.706653 139881799980800 logging_writer.py:48] [55641] accumulated_eval_time=1881.360867, accumulated_logging_time=2.004139, accumulated_submission_time=24411.189420, global_step=55641, preemption_count=0, score=24411.189420, test/accuracy=0.495400, test/loss=2.257332, test/num_examples=10000, total_duration=26297.478449, train/accuracy=0.686562, train/loss=1.307192, validation/accuracy=0.620580, validation/loss=1.607120, validation/num_examples=50000
I0302 18:25:28.149961 139881808373504 logging_writer.py:48] [55700] global_step=55700, grad_norm=0.9903094172477722, loss=4.223135948181152
I0302 18:26:11.310750 139881799980800 logging_writer.py:48] [55800] global_step=55800, grad_norm=1.1494258642196655, loss=2.8679399490356445
I0302 18:26:55.949810 139881808373504 logging_writer.py:48] [55900] global_step=55900, grad_norm=1.119376540184021, loss=2.861534595489502
I0302 18:27:40.580772 139881799980800 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.1754435300827026, loss=2.8292503356933594
I0302 18:28:25.032313 139881808373504 logging_writer.py:48] [56100] global_step=56100, grad_norm=1.1150082349777222, loss=4.706773281097412
I0302 18:29:09.359350 139881799980800 logging_writer.py:48] [56200] global_step=56200, grad_norm=1.202476143836975, loss=2.517930746078491
I0302 18:29:53.613947 139881808373504 logging_writer.py:48] [56300] global_step=56300, grad_norm=1.0126349925994873, loss=4.259282112121582
I0302 18:30:38.015419 139881799980800 logging_writer.py:48] [56400] global_step=56400, grad_norm=1.279144048690796, loss=2.7164976596832275
I0302 18:31:22.582919 139881808373504 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.4227477312088013, loss=2.471531629562378
I0302 18:32:05.058638 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:32:15.159099 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:32:37.361603 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:32:38.948262 140077943854912 submission_runner.py:411] Time since start: 26751.75s, 	Step: 56598, 	{'train/accuracy': 0.6784765720367432, 'train/loss': 1.305625319480896, 'validation/accuracy': 0.6305400133132935, 'validation/loss': 1.5344041585922241, 'validation/num_examples': 50000, 'test/accuracy': 0.5113000273704529, 'test/loss': 2.1875674724578857, 'test/num_examples': 10000, 'score': 24831.478422641754, 'total_duration': 26751.75327205658, 'accumulated_submission_time': 24831.478422641754, 'accumulated_eval_time': 1915.2504620552063, 'accumulated_logging_time': 2.0507349967956543}
I0302 18:32:38.977276 139881799980800 logging_writer.py:48] [56598] accumulated_eval_time=1915.250462, accumulated_logging_time=2.050735, accumulated_submission_time=24831.478423, global_step=56598, preemption_count=0, score=24831.478423, test/accuracy=0.511300, test/loss=2.187567, test/num_examples=10000, total_duration=26751.753272, train/accuracy=0.678477, train/loss=1.305625, validation/accuracy=0.630540, validation/loss=1.534404, validation/num_examples=50000
I0302 18:32:40.151458 139881808373504 logging_writer.py:48] [56600] global_step=56600, grad_norm=1.047946810722351, loss=4.812431812286377
I0302 18:33:20.188334 139881799980800 logging_writer.py:48] [56700] global_step=56700, grad_norm=1.1182705163955688, loss=4.218925952911377
I0302 18:34:04.507078 139881808373504 logging_writer.py:48] [56800] global_step=56800, grad_norm=1.2849072217941284, loss=2.053553581237793
I0302 18:34:49.227478 139881799980800 logging_writer.py:48] [56900] global_step=56900, grad_norm=1.1236648559570312, loss=2.548611879348755
I0302 18:35:33.482390 139881808373504 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.1606967449188232, loss=2.5644474029541016
I0302 18:36:17.868267 139881799980800 logging_writer.py:48] [57100] global_step=57100, grad_norm=1.0865241289138794, loss=4.205667972564697
I0302 18:37:02.241654 139881808373504 logging_writer.py:48] [57200] global_step=57200, grad_norm=1.2625399827957153, loss=2.325558662414551
I0302 18:37:46.775361 139881799980800 logging_writer.py:48] [57300] global_step=57300, grad_norm=1.1173336505889893, loss=4.457873344421387
I0302 18:38:31.258625 139881808373504 logging_writer.py:48] [57400] global_step=57400, grad_norm=1.160893440246582, loss=2.729426622390747
I0302 18:39:15.685615 139881799980800 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.3321894407272339, loss=2.3501501083374023
I0302 18:39:39.186934 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:39:49.217783 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:40:11.366265 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:40:12.943651 140077943854912 submission_runner.py:411] Time since start: 27205.75s, 	Step: 57554, 	{'train/accuracy': 0.6798437237739563, 'train/loss': 1.33681058883667, 'validation/accuracy': 0.6278600096702576, 'validation/loss': 1.564784049987793, 'validation/num_examples': 50000, 'test/accuracy': 0.5078999996185303, 'test/loss': 2.219440460205078, 'test/num_examples': 10000, 'score': 25251.627435684204, 'total_duration': 27205.74866914749, 'accumulated_submission_time': 25251.627435684204, 'accumulated_eval_time': 1949.0071649551392, 'accumulated_logging_time': 2.090480327606201}
I0302 18:40:12.969677 139881808373504 logging_writer.py:48] [57554] accumulated_eval_time=1949.007165, accumulated_logging_time=2.090480, accumulated_submission_time=25251.627436, global_step=57554, preemption_count=0, score=25251.627436, test/accuracy=0.507900, test/loss=2.219440, test/num_examples=10000, total_duration=27205.748669, train/accuracy=0.679844, train/loss=1.336811, validation/accuracy=0.627860, validation/loss=1.564784, validation/num_examples=50000
I0302 18:40:31.333772 139881799980800 logging_writer.py:48] [57600] global_step=57600, grad_norm=1.1611932516098022, loss=4.807483673095703
I0302 18:41:13.576199 139881808373504 logging_writer.py:48] [57700] global_step=57700, grad_norm=1.239087700843811, loss=2.7025811672210693
I0302 18:41:58.013142 139881799980800 logging_writer.py:48] [57800] global_step=57800, grad_norm=1.1320430040359497, loss=3.5952141284942627
I0302 18:42:42.527393 139881808373504 logging_writer.py:48] [57900] global_step=57900, grad_norm=1.1358847618103027, loss=3.255251884460449
I0302 18:43:27.103012 139881799980800 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.382230281829834, loss=2.3631575107574463
I0302 18:44:11.649407 139881808373504 logging_writer.py:48] [58100] global_step=58100, grad_norm=1.1709160804748535, loss=3.924422264099121
I0302 18:44:55.896308 139881799980800 logging_writer.py:48] [58200] global_step=58200, grad_norm=1.2124571800231934, loss=2.4560956954956055
I0302 18:45:40.366460 139881808373504 logging_writer.py:48] [58300] global_step=58300, grad_norm=1.4324232339859009, loss=2.433634042739868
I0302 18:46:24.855355 139881799980800 logging_writer.py:48] [58400] global_step=58400, grad_norm=1.1799945831298828, loss=4.254666805267334
I0302 18:47:09.405299 139881808373504 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.2969790697097778, loss=2.2443230152130127
I0302 18:47:13.095909 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:47:23.225955 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:47:44.960938 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:47:46.544990 140077943854912 submission_runner.py:411] Time since start: 27659.35s, 	Step: 58510, 	{'train/accuracy': 0.6871093511581421, 'train/loss': 1.2710402011871338, 'validation/accuracy': 0.6285799741744995, 'validation/loss': 1.5473343133926392, 'validation/num_examples': 50000, 'test/accuracy': 0.5093000531196594, 'test/loss': 2.194056749343872, 'test/num_examples': 10000, 'score': 25671.693274259567, 'total_duration': 27659.35000705719, 'accumulated_submission_time': 25671.693274259567, 'accumulated_eval_time': 1982.4562137126923, 'accumulated_logging_time': 2.126615047454834}
I0302 18:47:46.568819 139881799980800 logging_writer.py:48] [58510] accumulated_eval_time=1982.456214, accumulated_logging_time=2.126615, accumulated_submission_time=25671.693274, global_step=58510, preemption_count=0, score=25671.693274, test/accuracy=0.509300, test/loss=2.194057, test/num_examples=10000, total_duration=27659.350007, train/accuracy=0.687109, train/loss=1.271040, validation/accuracy=0.628580, validation/loss=1.547334, validation/num_examples=50000
I0302 18:48:22.409766 139881808373504 logging_writer.py:48] [58600] global_step=58600, grad_norm=1.3005973100662231, loss=2.7602920532226562
I0302 18:49:06.781036 139881799980800 logging_writer.py:48] [58700] global_step=58700, grad_norm=1.4075685739517212, loss=2.4326109886169434
I0302 18:49:51.341369 139881808373504 logging_writer.py:48] [58800] global_step=58800, grad_norm=1.3296778202056885, loss=2.2834348678588867
I0302 18:50:36.065004 139881799980800 logging_writer.py:48] [58900] global_step=58900, grad_norm=1.158232569694519, loss=2.704275131225586
I0302 18:51:20.299356 139881808373504 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.1714280843734741, loss=3.175743579864502
I0302 18:52:05.101863 139881799980800 logging_writer.py:48] [59100] global_step=59100, grad_norm=1.2629863023757935, loss=2.7100753784179688
I0302 18:52:49.170282 139881808373504 logging_writer.py:48] [59200] global_step=59200, grad_norm=1.337212085723877, loss=2.633280038833618
I0302 18:53:33.772203 139881799980800 logging_writer.py:48] [59300] global_step=59300, grad_norm=1.2132673263549805, loss=4.380316257476807
I0302 18:54:18.227372 139881808373504 logging_writer.py:48] [59400] global_step=59400, grad_norm=1.2643215656280518, loss=2.34238600730896
I0302 18:54:46.659866 140077943854912 spec.py:321] Evaluating on the training split.
I0302 18:54:56.561503 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 18:55:17.647172 140077943854912 spec.py:349] Evaluating on the test split.
I0302 18:55:19.230664 140077943854912 submission_runner.py:411] Time since start: 28112.04s, 	Step: 59466, 	{'train/accuracy': 0.7090429663658142, 'train/loss': 1.2248718738555908, 'validation/accuracy': 0.6277599930763245, 'validation/loss': 1.591611385345459, 'validation/num_examples': 50000, 'test/accuracy': 0.5082000494003296, 'test/loss': 2.2486259937286377, 'test/num_examples': 10000, 'score': 26091.714426994324, 'total_duration': 28112.035681962967, 'accumulated_submission_time': 26091.714426994324, 'accumulated_eval_time': 2015.0270056724548, 'accumulated_logging_time': 2.170564889907837}
I0302 18:55:19.255757 139881799980800 logging_writer.py:48] [59466] accumulated_eval_time=2015.027006, accumulated_logging_time=2.170565, accumulated_submission_time=26091.714427, global_step=59466, preemption_count=0, score=26091.714427, test/accuracy=0.508200, test/loss=2.248626, test/num_examples=10000, total_duration=28112.035682, train/accuracy=0.709043, train/loss=1.224872, validation/accuracy=0.627760, validation/loss=1.591611, validation/num_examples=50000
I0302 18:55:32.933054 139881808373504 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.3664753437042236, loss=2.3038880825042725
I0302 18:56:14.288138 139881799980800 logging_writer.py:48] [59600] global_step=59600, grad_norm=1.3592840433120728, loss=4.272784233093262
I0302 18:56:58.935681 139881808373504 logging_writer.py:48] [59700] global_step=59700, grad_norm=1.330992579460144, loss=2.4067959785461426
I0302 18:57:43.554404 139881799980800 logging_writer.py:48] [59800] global_step=59800, grad_norm=1.3015905618667603, loss=2.442605972290039
I0302 18:58:27.781448 139881808373504 logging_writer.py:48] [59900] global_step=59900, grad_norm=1.3164846897125244, loss=2.462646722793579
I0302 18:59:12.128400 139881799980800 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.219977617263794, loss=2.5956003665924072
I0302 18:59:56.945261 139881808373504 logging_writer.py:48] [60100] global_step=60100, grad_norm=1.4315439462661743, loss=2.3255159854888916
I0302 19:00:41.376300 139881799980800 logging_writer.py:48] [60200] global_step=60200, grad_norm=1.2707136869430542, loss=2.2926692962646484
I0302 19:01:26.018796 139881808373504 logging_writer.py:48] [60300] global_step=60300, grad_norm=1.3484585285186768, loss=2.3427982330322266
I0302 19:02:10.690590 139881799980800 logging_writer.py:48] [60400] global_step=60400, grad_norm=1.1249186992645264, loss=3.9245057106018066
I0302 19:02:19.238593 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:02:29.582222 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:02:52.680697 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:02:54.265494 140077943854912 submission_runner.py:411] Time since start: 28567.07s, 	Step: 60421, 	{'train/accuracy': 0.6841210722923279, 'train/loss': 1.2804559469223022, 'validation/accuracy': 0.632099986076355, 'validation/loss': 1.5170131921768188, 'validation/num_examples': 50000, 'test/accuracy': 0.511900007724762, 'test/loss': 2.176940679550171, 'test/num_examples': 10000, 'score': 26511.63784146309, 'total_duration': 28567.070473909378, 'accumulated_submission_time': 26511.63784146309, 'accumulated_eval_time': 2050.053850412369, 'accumulated_logging_time': 2.206193447113037}
I0302 19:02:54.295815 139881808373504 logging_writer.py:48] [60421] accumulated_eval_time=2050.053850, accumulated_logging_time=2.206193, accumulated_submission_time=26511.637841, global_step=60421, preemption_count=0, score=26511.637841, test/accuracy=0.511900, test/loss=2.176941, test/num_examples=10000, total_duration=28567.070474, train/accuracy=0.684121, train/loss=1.280456, validation/accuracy=0.632100, validation/loss=1.517013, validation/num_examples=50000
I0302 19:03:25.550316 139881799980800 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.2971441745758057, loss=3.399904727935791
I0302 19:04:09.286836 139881808373504 logging_writer.py:48] [60600] global_step=60600, grad_norm=1.2385127544403076, loss=2.302114248275757
I0302 19:04:53.930383 139881799980800 logging_writer.py:48] [60700] global_step=60700, grad_norm=1.165299654006958, loss=3.340590476989746
I0302 19:05:38.296792 139881808373504 logging_writer.py:48] [60800] global_step=60800, grad_norm=1.1571818590164185, loss=3.265320301055908
I0302 19:06:22.971280 139881799980800 logging_writer.py:48] [60900] global_step=60900, grad_norm=1.1841614246368408, loss=2.802119016647339
I0302 19:07:07.464329 139881808373504 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.4445775747299194, loss=2.3027262687683105
I0302 19:07:52.024261 139881799980800 logging_writer.py:48] [61100] global_step=61100, grad_norm=1.1683188676834106, loss=4.854738235473633
I0302 19:08:36.537852 139881808373504 logging_writer.py:48] [61200] global_step=61200, grad_norm=1.2856907844543457, loss=4.993051528930664
I0302 19:09:21.179563 139881799980800 logging_writer.py:48] [61300] global_step=61300, grad_norm=1.242546796798706, loss=2.453387498855591
I0302 19:09:54.586366 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:10:04.861081 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:10:28.282756 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:10:29.872972 140077943854912 submission_runner.py:411] Time since start: 29022.68s, 	Step: 61377, 	{'train/accuracy': 0.6870312094688416, 'train/loss': 1.2437814474105835, 'validation/accuracy': 0.6377999782562256, 'validation/loss': 1.4895076751708984, 'validation/num_examples': 50000, 'test/accuracy': 0.5074000358581543, 'test/loss': 2.163461208343506, 'test/num_examples': 10000, 'score': 26931.867235183716, 'total_duration': 29022.67796754837, 'accumulated_submission_time': 26931.867235183716, 'accumulated_eval_time': 2085.340404987335, 'accumulated_logging_time': 2.2476589679718018}
I0302 19:10:29.903256 139881808373504 logging_writer.py:48] [61377] accumulated_eval_time=2085.340405, accumulated_logging_time=2.247659, accumulated_submission_time=26931.867235, global_step=61377, preemption_count=0, score=26931.867235, test/accuracy=0.507400, test/loss=2.163461, test/num_examples=10000, total_duration=29022.677968, train/accuracy=0.687031, train/loss=1.243781, validation/accuracy=0.637800, validation/loss=1.489508, validation/num_examples=50000
I0302 19:10:39.266082 139881799980800 logging_writer.py:48] [61400] global_step=61400, grad_norm=1.2991669178009033, loss=2.895242214202881
I0302 19:11:20.292668 139881808373504 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.17546808719635, loss=4.751718997955322
I0302 19:12:04.875440 139881799980800 logging_writer.py:48] [61600] global_step=61600, grad_norm=1.0311094522476196, loss=4.051901340484619
I0302 19:12:49.537909 139881808373504 logging_writer.py:48] [61700] global_step=61700, grad_norm=1.1775386333465576, loss=3.1322402954101562
I0302 19:13:34.042649 139881799980800 logging_writer.py:48] [61800] global_step=61800, grad_norm=1.222389817237854, loss=3.031620740890503
I0302 19:14:18.720655 139881808373504 logging_writer.py:48] [61900] global_step=61900, grad_norm=1.347644567489624, loss=2.093825578689575
I0302 19:15:02.964238 139881799980800 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.34644615650177, loss=2.2876319885253906
I0302 19:15:47.518525 139881808373504 logging_writer.py:48] [62100] global_step=62100, grad_norm=1.2131178379058838, loss=2.4615211486816406
I0302 19:16:32.014504 139881799980800 logging_writer.py:48] [62200] global_step=62200, grad_norm=1.338855266571045, loss=2.303325653076172
I0302 19:17:16.583194 139881808373504 logging_writer.py:48] [62300] global_step=62300, grad_norm=1.2454156875610352, loss=2.6028990745544434
I0302 19:17:30.170361 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:17:40.122712 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:18:01.390388 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:18:02.982691 140077943854912 submission_runner.py:411] Time since start: 29475.79s, 	Step: 62332, 	{'train/accuracy': 0.7010741829872131, 'train/loss': 1.2027630805969238, 'validation/accuracy': 0.6353999972343445, 'validation/loss': 1.4932037591934204, 'validation/num_examples': 50000, 'test/accuracy': 0.5136000514030457, 'test/loss': 2.16353702545166, 'test/num_examples': 10000, 'score': 27352.072308063507, 'total_duration': 29475.787707805634, 'accumulated_submission_time': 27352.072308063507, 'accumulated_eval_time': 2118.1527137756348, 'accumulated_logging_time': 2.290111780166626}
I0302 19:18:03.008012 139881799980800 logging_writer.py:48] [62332] accumulated_eval_time=2118.152714, accumulated_logging_time=2.290112, accumulated_submission_time=27352.072308, global_step=62332, preemption_count=0, score=27352.072308, test/accuracy=0.513600, test/loss=2.163537, test/num_examples=10000, total_duration=29475.787708, train/accuracy=0.701074, train/loss=1.202763, validation/accuracy=0.635400, validation/loss=1.493204, validation/num_examples=50000
I0302 19:18:30.207298 139881808373504 logging_writer.py:48] [62400] global_step=62400, grad_norm=1.146238088607788, loss=4.764867305755615
I0302 19:19:13.519908 139881799980800 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.3089141845703125, loss=2.4948906898498535
I0302 19:19:57.685318 139881808373504 logging_writer.py:48] [62600] global_step=62600, grad_norm=1.2669594287872314, loss=2.2658472061157227
I0302 19:20:42.109618 139881799980800 logging_writer.py:48] [62700] global_step=62700, grad_norm=1.0668621063232422, loss=4.644775390625
I0302 19:21:26.475453 139881808373504 logging_writer.py:48] [62800] global_step=62800, grad_norm=1.3021764755249023, loss=2.3548123836517334
I0302 19:22:11.120677 139881799980800 logging_writer.py:48] [62900] global_step=62900, grad_norm=1.3370765447616577, loss=2.2539191246032715
I0302 19:22:55.251028 139881808373504 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.0990188121795654, loss=3.2224626541137695
I0302 19:23:39.840501 139881799980800 logging_writer.py:48] [63100] global_step=63100, grad_norm=1.2799474000930786, loss=2.2209322452545166
I0302 19:24:24.557500 139881808373504 logging_writer.py:48] [63200] global_step=63200, grad_norm=1.1877201795578003, loss=3.497594118118286
I0302 19:25:03.364318 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:25:13.836413 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:25:37.216054 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:25:38.795766 140077943854912 submission_runner.py:411] Time since start: 29931.60s, 	Step: 63289, 	{'train/accuracy': 0.6837499737739563, 'train/loss': 1.3085410594940186, 'validation/accuracy': 0.6333799958229065, 'validation/loss': 1.5339182615280151, 'validation/num_examples': 50000, 'test/accuracy': 0.5095000267028809, 'test/loss': 2.2137796878814697, 'test/num_examples': 10000, 'score': 27772.3682949543, 'total_duration': 29931.60078239441, 'accumulated_submission_time': 27772.3682949543, 'accumulated_eval_time': 2153.5841794013977, 'accumulated_logging_time': 2.325376510620117}
I0302 19:25:38.825584 139881799980800 logging_writer.py:48] [63289] accumulated_eval_time=2153.584179, accumulated_logging_time=2.325377, accumulated_submission_time=27772.368295, global_step=63289, preemption_count=0, score=27772.368295, test/accuracy=0.509500, test/loss=2.213780, test/num_examples=10000, total_duration=29931.600782, train/accuracy=0.683750, train/loss=1.308541, validation/accuracy=0.633380, validation/loss=1.533918, validation/num_examples=50000
I0302 19:25:43.517759 139881808373504 logging_writer.py:48] [63300] global_step=63300, grad_norm=1.539085865020752, loss=2.5964581966400146
I0302 19:26:23.971231 139881799980800 logging_writer.py:48] [63400] global_step=63400, grad_norm=1.3220412731170654, loss=2.379962921142578
I0302 19:27:08.501784 139881808373504 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.2919570207595825, loss=2.2831358909606934
I0302 19:27:53.140985 139881799980800 logging_writer.py:48] [63600] global_step=63600, grad_norm=1.185051441192627, loss=3.3157639503479004
I0302 19:28:37.378191 139881808373504 logging_writer.py:48] [63700] global_step=63700, grad_norm=1.2912025451660156, loss=2.234647512435913
I0302 19:29:21.881110 139881799980800 logging_writer.py:48] [63800] global_step=63800, grad_norm=1.1443843841552734, loss=3.178654432296753
I0302 19:30:06.489830 139881808373504 logging_writer.py:48] [63900] global_step=63900, grad_norm=1.3289198875427246, loss=2.114579439163208
I0302 19:30:50.940290 139881799980800 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.123488187789917, loss=4.320868492126465
I0302 19:31:35.576277 139881808373504 logging_writer.py:48] [64100] global_step=64100, grad_norm=1.1033618450164795, loss=2.48776912689209
I0302 19:32:20.247254 139881799980800 logging_writer.py:48] [64200] global_step=64200, grad_norm=1.268834114074707, loss=2.265554904937744
I0302 19:32:39.217564 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:32:49.435783 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:33:12.685050 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:33:14.270467 140077943854912 submission_runner.py:411] Time since start: 30387.08s, 	Step: 64244, 	{'train/accuracy': 0.6842578053474426, 'train/loss': 1.3000692129135132, 'validation/accuracy': 0.6389999985694885, 'validation/loss': 1.5179568529129028, 'validation/num_examples': 50000, 'test/accuracy': 0.5075000524520874, 'test/loss': 2.188990592956543, 'test/num_examples': 10000, 'score': 28192.699565649033, 'total_duration': 30387.0754737854, 'accumulated_submission_time': 28192.699565649033, 'accumulated_eval_time': 2188.6370465755463, 'accumulated_logging_time': 2.3665175437927246}
I0302 19:33:14.298938 139881808373504 logging_writer.py:48] [64244] accumulated_eval_time=2188.637047, accumulated_logging_time=2.366518, accumulated_submission_time=28192.699566, global_step=64244, preemption_count=0, score=28192.699566, test/accuracy=0.507500, test/loss=2.188991, test/num_examples=10000, total_duration=30387.075474, train/accuracy=0.684258, train/loss=1.300069, validation/accuracy=0.639000, validation/loss=1.517957, validation/num_examples=50000
I0302 19:33:36.564283 139881799980800 logging_writer.py:48] [64300] global_step=64300, grad_norm=1.222151517868042, loss=3.341994524002075
I0302 19:34:19.317147 139881808373504 logging_writer.py:48] [64400] global_step=64400, grad_norm=1.1038947105407715, loss=4.000432968139648
I0302 19:35:03.950863 139881799980800 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.3176586627960205, loss=2.2493183612823486
I0302 19:35:48.370750 139881808373504 logging_writer.py:48] [64600] global_step=64600, grad_norm=1.119308590888977, loss=4.559125900268555
I0302 19:36:32.704509 139881799980800 logging_writer.py:48] [64700] global_step=64700, grad_norm=1.1594411134719849, loss=4.461647987365723
I0302 19:37:17.276324 139881808373504 logging_writer.py:48] [64800] global_step=64800, grad_norm=1.1781245470046997, loss=2.3785743713378906
I0302 19:38:01.627162 139881799980800 logging_writer.py:48] [64900] global_step=64900, grad_norm=1.2623610496520996, loss=4.575839519500732
I0302 19:38:45.819325 139881808373504 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.4151959419250488, loss=2.321457624435425
I0302 19:39:30.367659 139881799980800 logging_writer.py:48] [65100] global_step=65100, grad_norm=1.2202022075653076, loss=2.1524405479431152
I0302 19:40:14.674461 139881808373504 logging_writer.py:48] [65200] global_step=65200, grad_norm=1.1484538316726685, loss=4.812312126159668
I0302 19:40:14.687401 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:40:24.834415 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:40:48.394739 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:40:49.969588 140077943854912 submission_runner.py:411] Time since start: 30842.77s, 	Step: 65201, 	{'train/accuracy': 0.6913281083106995, 'train/loss': 1.2925525903701782, 'validation/accuracy': 0.6354599595069885, 'validation/loss': 1.5564727783203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5093000531196594, 'test/loss': 2.2240333557128906, 'test/num_examples': 10000, 'score': 28613.02726626396, 'total_duration': 30842.774602413177, 'accumulated_submission_time': 28613.02726626396, 'accumulated_eval_time': 2223.919200897217, 'accumulated_logging_time': 2.40610671043396}
I0302 19:40:49.995351 139881799980800 logging_writer.py:48] [65201] accumulated_eval_time=2223.919201, accumulated_logging_time=2.406107, accumulated_submission_time=28613.027266, global_step=65201, preemption_count=0, score=28613.027266, test/accuracy=0.509300, test/loss=2.224033, test/num_examples=10000, total_duration=30842.774602, train/accuracy=0.691328, train/loss=1.292553, validation/accuracy=0.635460, validation/loss=1.556473, validation/num_examples=50000
I0302 19:41:29.532988 139881808373504 logging_writer.py:48] [65300] global_step=65300, grad_norm=1.1691728830337524, loss=2.2393031120300293
I0302 19:42:13.843463 139881799980800 logging_writer.py:48] [65400] global_step=65400, grad_norm=1.2875832319259644, loss=2.147409439086914
I0302 19:42:58.345240 139881808373504 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.2755342721939087, loss=2.611346960067749
I0302 19:43:42.786940 139881799980800 logging_writer.py:48] [65600] global_step=65600, grad_norm=1.126468539237976, loss=3.7584025859832764
I0302 19:44:27.292159 139881808373504 logging_writer.py:48] [65700] global_step=65700, grad_norm=1.1360889673233032, loss=3.4245238304138184
I0302 19:45:11.460081 139881799980800 logging_writer.py:48] [65800] global_step=65800, grad_norm=1.322258710861206, loss=2.3159000873565674
I0302 19:45:55.424283 139881808373504 logging_writer.py:48] [65900] global_step=65900, grad_norm=1.2911654710769653, loss=2.2941532135009766
I0302 19:46:40.051446 139881799980800 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.201305866241455, loss=2.6531596183776855
I0302 19:47:24.443800 139881808373504 logging_writer.py:48] [66100] global_step=66100, grad_norm=1.4029533863067627, loss=2.2818238735198975
I0302 19:47:50.225415 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:48:00.293756 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:48:18.885153 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:48:20.477196 140077943854912 submission_runner.py:411] Time since start: 31293.28s, 	Step: 66160, 	{'train/accuracy': 0.7096288800239563, 'train/loss': 1.2008816003799438, 'validation/accuracy': 0.6379199624061584, 'validation/loss': 1.5290579795837402, 'validation/num_examples': 50000, 'test/accuracy': 0.5128999948501587, 'test/loss': 2.1780552864074707, 'test/num_examples': 10000, 'score': 29033.197748422623, 'total_duration': 31293.28220319748, 'accumulated_submission_time': 29033.197748422623, 'accumulated_eval_time': 2254.170946121216, 'accumulated_logging_time': 2.441678762435913}
I0302 19:48:20.510566 139881799980800 logging_writer.py:48] [66160] accumulated_eval_time=2254.170946, accumulated_logging_time=2.441679, accumulated_submission_time=29033.197748, global_step=66160, preemption_count=0, score=29033.197748, test/accuracy=0.512900, test/loss=2.178055, test/num_examples=10000, total_duration=31293.282203, train/accuracy=0.709629, train/loss=1.200882, validation/accuracy=0.637920, validation/loss=1.529058, validation/num_examples=50000
I0302 19:48:36.553384 139881808373504 logging_writer.py:48] [66200] global_step=66200, grad_norm=1.5705609321594238, loss=2.4145655632019043
I0302 19:49:19.824414 139881799980800 logging_writer.py:48] [66300] global_step=66300, grad_norm=1.2366869449615479, loss=2.5964698791503906
I0302 19:50:03.928953 139881808373504 logging_writer.py:48] [66400] global_step=66400, grad_norm=1.2708100080490112, loss=2.3589494228363037
I0302 19:50:48.284526 139881799980800 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.1986855268478394, loss=2.4699184894561768
I0302 19:51:32.650944 139881808373504 logging_writer.py:48] [66600] global_step=66600, grad_norm=1.3347731828689575, loss=4.320115566253662
I0302 19:52:17.124449 139881799980800 logging_writer.py:48] [66700] global_step=66700, grad_norm=1.388885498046875, loss=2.422783374786377
I0302 19:53:01.399956 139881808373504 logging_writer.py:48] [66800] global_step=66800, grad_norm=1.1480636596679688, loss=4.690229415893555
I0302 19:53:45.776927 139881799980800 logging_writer.py:48] [66900] global_step=66900, grad_norm=1.127684235572815, loss=3.209993839263916
I0302 19:54:30.345167 139881808373504 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.191874384880066, loss=4.525904655456543
I0302 19:55:14.777499 139881799980800 logging_writer.py:48] [67100] global_step=67100, grad_norm=1.384515643119812, loss=4.543747901916504
I0302 19:55:20.702635 140077943854912 spec.py:321] Evaluating on the training split.
I0302 19:55:30.975786 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 19:55:53.872107 140077943854912 spec.py:349] Evaluating on the test split.
I0302 19:55:55.456161 140077943854912 submission_runner.py:411] Time since start: 31748.26s, 	Step: 67115, 	{'train/accuracy': 0.6934179663658142, 'train/loss': 1.2447786331176758, 'validation/accuracy': 0.6399399638175964, 'validation/loss': 1.487149953842163, 'validation/num_examples': 50000, 'test/accuracy': 0.5189000368118286, 'test/loss': 2.1419031620025635, 'test/num_examples': 10000, 'score': 29453.328754663467, 'total_duration': 31748.261180639267, 'accumulated_submission_time': 29453.328754663467, 'accumulated_eval_time': 2288.9244425296783, 'accumulated_logging_time': 2.4865760803222656}
I0302 19:55:55.481131 139881808373504 logging_writer.py:48] [67115] accumulated_eval_time=2288.924443, accumulated_logging_time=2.486576, accumulated_submission_time=29453.328755, global_step=67115, preemption_count=0, score=29453.328755, test/accuracy=0.518900, test/loss=2.141903, test/num_examples=10000, total_duration=31748.261181, train/accuracy=0.693418, train/loss=1.244779, validation/accuracy=0.639940, validation/loss=1.487150, validation/num_examples=50000
I0302 19:56:29.077954 139881799980800 logging_writer.py:48] [67200] global_step=67200, grad_norm=1.1328380107879639, loss=3.031125068664551
I0302 19:57:12.942006 139881808373504 logging_writer.py:48] [67300] global_step=67300, grad_norm=1.2949020862579346, loss=2.989302635192871
I0302 19:57:57.483119 139881799980800 logging_writer.py:48] [67400] global_step=67400, grad_norm=1.2856894731521606, loss=2.095684766769409
I0302 19:58:41.684832 139881808373504 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.146872639656067, loss=4.885295391082764
I0302 19:59:25.842334 139881799980800 logging_writer.py:48] [67600] global_step=67600, grad_norm=1.3023701906204224, loss=2.2443594932556152
I0302 20:00:10.432893 139881808373504 logging_writer.py:48] [67700] global_step=67700, grad_norm=1.3767513036727905, loss=2.517253875732422
I0302 20:00:54.834313 139881799980800 logging_writer.py:48] [67800] global_step=67800, grad_norm=1.2021888494491577, loss=3.138693332672119
I0302 20:01:39.474388 139881808373504 logging_writer.py:48] [67900] global_step=67900, grad_norm=1.2994492053985596, loss=2.2691783905029297
I0302 20:02:23.829302 139881799980800 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.3801546096801758, loss=2.2764978408813477
I0302 20:02:55.488453 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:03:05.663932 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:03:29.649144 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:03:31.226652 140077943854912 submission_runner.py:411] Time since start: 32204.03s, 	Step: 68073, 	{'train/accuracy': 0.7007812261581421, 'train/loss': 1.1957064867019653, 'validation/accuracy': 0.6473599672317505, 'validation/loss': 1.448695421218872, 'validation/num_examples': 50000, 'test/accuracy': 0.522599995136261, 'test/loss': 2.106295347213745, 'test/num_examples': 10000, 'score': 29873.27702856064, 'total_duration': 32204.031671524048, 'accumulated_submission_time': 29873.27702856064, 'accumulated_eval_time': 2324.6626167297363, 'accumulated_logging_time': 2.5216784477233887}
I0302 20:03:31.259577 139881808373504 logging_writer.py:48] [68073] accumulated_eval_time=2324.662617, accumulated_logging_time=2.521678, accumulated_submission_time=29873.277029, global_step=68073, preemption_count=0, score=29873.277029, test/accuracy=0.522600, test/loss=2.106295, test/num_examples=10000, total_duration=32204.031672, train/accuracy=0.700781, train/loss=1.195706, validation/accuracy=0.647360, validation/loss=1.448695, validation/num_examples=50000
I0302 20:03:42.179618 139881799980800 logging_writer.py:48] [68100] global_step=68100, grad_norm=1.2788482904434204, loss=2.5864689350128174
I0302 20:04:23.148566 139881808373504 logging_writer.py:48] [68200] global_step=68200, grad_norm=1.2941659688949585, loss=2.284447193145752
I0302 20:05:07.992668 139881799980800 logging_writer.py:48] [68300] global_step=68300, grad_norm=1.3509622812271118, loss=2.245997428894043
I0302 20:05:52.527202 139881808373504 logging_writer.py:48] [68400] global_step=68400, grad_norm=1.0916684865951538, loss=3.313985824584961
I0302 20:06:37.196944 139881799980800 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.3848440647125244, loss=2.270240068435669
I0302 20:07:21.850220 139881808373504 logging_writer.py:48] [68600] global_step=68600, grad_norm=1.1470175981521606, loss=4.311464786529541
I0302 20:08:06.312645 139881799980800 logging_writer.py:48] [68700] global_step=68700, grad_norm=1.088728904724121, loss=2.9690427780151367
I0302 20:08:50.962431 139881808373504 logging_writer.py:48] [68800] global_step=68800, grad_norm=1.1587297916412354, loss=4.349029064178467
I0302 20:09:35.441186 139881799980800 logging_writer.py:48] [68900] global_step=68900, grad_norm=1.1739143133163452, loss=3.389491081237793
I0302 20:10:19.743507 139881808373504 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.1691482067108154, loss=4.284396171569824
I0302 20:10:31.534435 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:10:41.632764 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:11:06.067668 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:11:07.647322 140077943854912 submission_runner.py:411] Time since start: 32660.45s, 	Step: 69028, 	{'train/accuracy': 0.7033398151397705, 'train/loss': 1.235210657119751, 'validation/accuracy': 0.6412999629974365, 'validation/loss': 1.5109248161315918, 'validation/num_examples': 50000, 'test/accuracy': 0.5178000330924988, 'test/loss': 2.1673731803894043, 'test/num_examples': 10000, 'score': 30293.492072343826, 'total_duration': 32660.452337503433, 'accumulated_submission_time': 30293.492072343826, 'accumulated_eval_time': 2360.7755336761475, 'accumulated_logging_time': 2.5654780864715576}
I0302 20:11:07.674396 139881799980800 logging_writer.py:48] [69028] accumulated_eval_time=2360.775534, accumulated_logging_time=2.565478, accumulated_submission_time=30293.492072, global_step=69028, preemption_count=0, score=30293.492072, test/accuracy=0.517800, test/loss=2.167373, test/num_examples=10000, total_duration=32660.452338, train/accuracy=0.703340, train/loss=1.235211, validation/accuracy=0.641300, validation/loss=1.510925, validation/num_examples=50000
I0302 20:11:36.195348 139881808373504 logging_writer.py:48] [69100] global_step=69100, grad_norm=1.3500912189483643, loss=3.6085612773895264
I0302 20:12:19.709873 139881799980800 logging_writer.py:48] [69200] global_step=69200, grad_norm=1.2097113132476807, loss=3.9888534545898438
I0302 20:13:04.385735 139881808373504 logging_writer.py:48] [69300] global_step=69300, grad_norm=1.1765495538711548, loss=3.172456979751587
I0302 20:13:48.644228 139881799980800 logging_writer.py:48] [69400] global_step=69400, grad_norm=1.3921947479248047, loss=2.187892436981201
I0302 20:14:32.894845 139881808373504 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.3619093894958496, loss=2.301544666290283
I0302 20:15:18.193370 139881799980800 logging_writer.py:48] [69600] global_step=69600, grad_norm=1.3171122074127197, loss=3.342613458633423
I0302 20:16:02.889940 139881808373504 logging_writer.py:48] [69700] global_step=69700, grad_norm=1.4395214319229126, loss=2.2761058807373047
I0302 20:16:47.402423 139881799980800 logging_writer.py:48] [69800] global_step=69800, grad_norm=1.3198988437652588, loss=2.72636342048645
I0302 20:17:32.089013 139881808373504 logging_writer.py:48] [69900] global_step=69900, grad_norm=1.2265238761901855, loss=3.9580702781677246
I0302 20:18:07.992180 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:18:18.262456 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:18:38.379385 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:18:39.965676 140077943854912 submission_runner.py:411] Time since start: 33112.77s, 	Step: 69982, 	{'train/accuracy': 0.7116405963897705, 'train/loss': 1.1737558841705322, 'validation/accuracy': 0.6464200019836426, 'validation/loss': 1.4845588207244873, 'validation/num_examples': 50000, 'test/accuracy': 0.5182000398635864, 'test/loss': 2.133967399597168, 'test/num_examples': 10000, 'score': 30713.74888730049, 'total_duration': 33112.77065825462, 'accumulated_submission_time': 30713.74888730049, 'accumulated_eval_time': 2392.7489824295044, 'accumulated_logging_time': 2.603192090988159}
I0302 20:18:40.001070 139881799980800 logging_writer.py:48] [69982] accumulated_eval_time=2392.748982, accumulated_logging_time=2.603192, accumulated_submission_time=30713.748887, global_step=69982, preemption_count=0, score=30713.748887, test/accuracy=0.518200, test/loss=2.133967, test/num_examples=10000, total_duration=33112.770658, train/accuracy=0.711641, train/loss=1.173756, validation/accuracy=0.646420, validation/loss=1.484559, validation/num_examples=50000
I0302 20:18:47.416591 139881808373504 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.1131794452667236, loss=2.92337703704834
I0302 20:19:29.092677 139881799980800 logging_writer.py:48] [70100] global_step=70100, grad_norm=1.3846935033798218, loss=2.268627405166626
I0302 20:20:13.443932 139881808373504 logging_writer.py:48] [70200] global_step=70200, grad_norm=1.2294039726257324, loss=2.6552813053131104
I0302 20:20:57.880003 139881799980800 logging_writer.py:48] [70300] global_step=70300, grad_norm=1.1554316282272339, loss=3.7831406593322754
I0302 20:21:42.486916 139881808373504 logging_writer.py:48] [70400] global_step=70400, grad_norm=1.3453688621520996, loss=2.2508907318115234
I0302 20:22:26.888636 139881799980800 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.1267800331115723, loss=4.0923357009887695
I0302 20:23:11.357989 139881808373504 logging_writer.py:48] [70600] global_step=70600, grad_norm=1.2707633972167969, loss=3.438994884490967
I0302 20:23:55.792357 139881799980800 logging_writer.py:48] [70700] global_step=70700, grad_norm=1.1098312139511108, loss=4.162008285522461
I0302 20:24:40.057031 139881808373504 logging_writer.py:48] [70800] global_step=70800, grad_norm=1.4081010818481445, loss=2.247295379638672
I0302 20:25:24.426381 139881799980800 logging_writer.py:48] [70900] global_step=70900, grad_norm=1.385711908340454, loss=4.639095783233643
I0302 20:25:40.030392 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:25:50.200438 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:26:13.531052 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:26:15.114110 140077943854912 submission_runner.py:411] Time since start: 33567.92s, 	Step: 70937, 	{'train/accuracy': 0.69447261095047, 'train/loss': 1.2243953943252563, 'validation/accuracy': 0.6431599855422974, 'validation/loss': 1.4684062004089355, 'validation/num_examples': 50000, 'test/accuracy': 0.5223000049591064, 'test/loss': 2.1306920051574707, 'test/num_examples': 10000, 'score': 31133.713386058807, 'total_duration': 33567.919130563736, 'accumulated_submission_time': 31133.713386058807, 'accumulated_eval_time': 2427.8326795101166, 'accumulated_logging_time': 2.6537318229675293}
I0302 20:26:15.144835 139881808373504 logging_writer.py:48] [70937] accumulated_eval_time=2427.832680, accumulated_logging_time=2.653732, accumulated_submission_time=31133.713386, global_step=70937, preemption_count=0, score=31133.713386, test/accuracy=0.522300, test/loss=2.130692, test/num_examples=10000, total_duration=33567.919131, train/accuracy=0.694473, train/loss=1.224395, validation/accuracy=0.643160, validation/loss=1.468406, validation/num_examples=50000
I0302 20:26:40.133814 139881799980800 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.29738187789917, loss=2.3611738681793213
I0302 20:27:23.072653 139881808373504 logging_writer.py:48] [71100] global_step=71100, grad_norm=1.3183525800704956, loss=4.172547340393066
I0302 20:28:07.363692 139881799980800 logging_writer.py:48] [71200] global_step=71200, grad_norm=1.1078122854232788, loss=4.194027900695801
I0302 20:28:52.044759 139881808373504 logging_writer.py:48] [71300] global_step=71300, grad_norm=1.1634842157363892, loss=4.448518753051758
I0302 20:29:36.897926 139881799980800 logging_writer.py:48] [71400] global_step=71400, grad_norm=1.3223023414611816, loss=2.239675998687744
I0302 20:30:21.803378 139881808373504 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.3467259407043457, loss=2.2984933853149414
I0302 20:31:06.548787 139881799980800 logging_writer.py:48] [71600] global_step=71600, grad_norm=1.3940174579620361, loss=2.2204439640045166
I0302 20:31:51.281933 139881808373504 logging_writer.py:48] [71700] global_step=71700, grad_norm=1.2552142143249512, loss=2.2641761302948
I0302 20:32:36.120027 139881799980800 logging_writer.py:48] [71800] global_step=71800, grad_norm=1.4005730152130127, loss=2.2786502838134766
I0302 20:33:15.166857 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:33:25.332042 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:33:48.760776 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:33:50.337283 140077943854912 submission_runner.py:411] Time since start: 34023.14s, 	Step: 71889, 	{'train/accuracy': 0.697460949420929, 'train/loss': 1.2218685150146484, 'validation/accuracy': 0.6411399841308594, 'validation/loss': 1.4857412576675415, 'validation/num_examples': 50000, 'test/accuracy': 0.5151000022888184, 'test/loss': 2.1532177925109863, 'test/num_examples': 10000, 'score': 31553.676849365234, 'total_duration': 34023.14230251312, 'accumulated_submission_time': 31553.676849365234, 'accumulated_eval_time': 2463.0030977725983, 'accumulated_logging_time': 2.694608211517334}
I0302 20:33:50.371453 139881808373504 logging_writer.py:48] [71889] accumulated_eval_time=2463.003098, accumulated_logging_time=2.694608, accumulated_submission_time=31553.676849, global_step=71889, preemption_count=0, score=31553.676849, test/accuracy=0.515100, test/loss=2.153218, test/num_examples=10000, total_duration=34023.142303, train/accuracy=0.697461, train/loss=1.221869, validation/accuracy=0.641140, validation/loss=1.485741, validation/num_examples=50000
I0302 20:33:55.048404 139881799980800 logging_writer.py:48] [71900] global_step=71900, grad_norm=1.3654956817626953, loss=2.200835704803467
I0302 20:34:35.131742 139881808373504 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.3604834079742432, loss=2.18495512008667
I0302 20:35:19.644230 139881799980800 logging_writer.py:48] [72100] global_step=72100, grad_norm=1.2700920104980469, loss=2.184691905975342
I0302 20:36:04.471602 139881808373504 logging_writer.py:48] [72200] global_step=72200, grad_norm=1.378528118133545, loss=2.2098121643066406
I0302 20:36:48.725151 139881799980800 logging_writer.py:48] [72300] global_step=72300, grad_norm=1.3507035970687866, loss=4.686122894287109
I0302 20:37:33.711951 139881808373504 logging_writer.py:48] [72400] global_step=72400, grad_norm=1.305657148361206, loss=2.3427553176879883
I0302 20:38:18.322892 139881799980800 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.3522648811340332, loss=2.181474447250366
I0302 20:39:02.429848 139881808373504 logging_writer.py:48] [72600] global_step=72600, grad_norm=1.227289080619812, loss=2.6705641746520996
I0302 20:39:46.773319 139881799980800 logging_writer.py:48] [72700] global_step=72700, grad_norm=1.493323802947998, loss=2.268082857131958
I0302 20:40:30.887855 139881808373504 logging_writer.py:48] [72800] global_step=72800, grad_norm=1.375260591506958, loss=2.1840882301330566
I0302 20:40:50.819082 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:41:01.247227 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:41:23.994345 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:41:25.577987 140077943854912 submission_runner.py:411] Time since start: 34478.38s, 	Step: 72846, 	{'train/accuracy': 0.7125195264816284, 'train/loss': 1.142621397972107, 'validation/accuracy': 0.650119960308075, 'validation/loss': 1.44003164768219, 'validation/num_examples': 50000, 'test/accuracy': 0.5228000283241272, 'test/loss': 2.113523483276367, 'test/num_examples': 10000, 'score': 31974.063121318817, 'total_duration': 34478.38299822807, 'accumulated_submission_time': 31974.063121318817, 'accumulated_eval_time': 2497.761979341507, 'accumulated_logging_time': 2.7404704093933105}
I0302 20:41:25.607604 139881799980800 logging_writer.py:48] [72846] accumulated_eval_time=2497.761979, accumulated_logging_time=2.740470, accumulated_submission_time=31974.063121, global_step=72846, preemption_count=0, score=31974.063121, test/accuracy=0.522800, test/loss=2.113523, test/num_examples=10000, total_duration=34478.382998, train/accuracy=0.712520, train/loss=1.142621, validation/accuracy=0.650120, validation/loss=1.440032, validation/num_examples=50000
I0302 20:41:47.077856 139881808373504 logging_writer.py:48] [72900] global_step=72900, grad_norm=1.3272795677185059, loss=2.265531539916992
I0302 20:42:29.439729 139881799980800 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.3944882154464722, loss=2.486307382583618
I0302 20:43:14.077945 139881808373504 logging_writer.py:48] [73100] global_step=73100, grad_norm=1.3908030986785889, loss=2.1465132236480713
I0302 20:43:58.321207 139881799980800 logging_writer.py:48] [73200] global_step=73200, grad_norm=1.19505774974823, loss=3.086442708969116
I0302 20:44:42.629245 139881808373504 logging_writer.py:48] [73300] global_step=73300, grad_norm=1.2875831127166748, loss=2.6502418518066406
I0302 20:45:27.076308 139881799980800 logging_writer.py:48] [73400] global_step=73400, grad_norm=1.1675971746444702, loss=2.8335752487182617
I0302 20:46:11.327396 139881808373504 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.3896387815475464, loss=2.244405508041382
I0302 20:46:56.019611 139881799980800 logging_writer.py:48] [73600] global_step=73600, grad_norm=1.3185222148895264, loss=4.714774131774902
I0302 20:47:40.327939 139881808373504 logging_writer.py:48] [73700] global_step=73700, grad_norm=1.29879629611969, loss=2.212778329849243
I0302 20:48:24.756377 139881799980800 logging_writer.py:48] [73800] global_step=73800, grad_norm=1.2582058906555176, loss=4.42341947555542
I0302 20:48:25.743568 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:48:35.790017 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:49:00.131428 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:49:01.715228 140077943854912 submission_runner.py:411] Time since start: 34934.52s, 	Step: 73804, 	{'train/accuracy': 0.699999988079071, 'train/loss': 1.2046812772750854, 'validation/accuracy': 0.6521199941635132, 'validation/loss': 1.4399217367172241, 'validation/num_examples': 50000, 'test/accuracy': 0.527999997138977, 'test/loss': 2.113095760345459, 'test/num_examples': 10000, 'score': 32394.138931512833, 'total_duration': 34934.52019953728, 'accumulated_submission_time': 32394.138931512833, 'accumulated_eval_time': 2533.733570098877, 'accumulated_logging_time': 2.7803633213043213}
I0302 20:49:01.759328 139881808373504 logging_writer.py:48] [73804] accumulated_eval_time=2533.733570, accumulated_logging_time=2.780363, accumulated_submission_time=32394.138932, global_step=73804, preemption_count=0, score=32394.138932, test/accuracy=0.528000, test/loss=2.113096, test/num_examples=10000, total_duration=34934.520200, train/accuracy=0.700000, train/loss=1.204681, validation/accuracy=0.652120, validation/loss=1.439922, validation/num_examples=50000
I0302 20:49:40.217371 139881799980800 logging_writer.py:48] [73900] global_step=73900, grad_norm=1.492903709411621, loss=2.1029443740844727
I0302 20:50:24.470077 139881808373504 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.2112843990325928, loss=2.6110010147094727
I0302 20:51:09.185750 139881799980800 logging_writer.py:48] [74100] global_step=74100, grad_norm=1.4201983213424683, loss=2.1877951622009277
I0302 20:51:53.361844 139881808373504 logging_writer.py:48] [74200] global_step=74200, grad_norm=1.4403741359710693, loss=2.3139970302581787
I0302 20:52:38.012780 139881799980800 logging_writer.py:48] [74300] global_step=74300, grad_norm=1.3310925960540771, loss=2.2060065269470215
I0302 20:53:22.253943 139881808373504 logging_writer.py:48] [74400] global_step=74400, grad_norm=1.3617371320724487, loss=2.0870444774627686
I0302 20:54:06.493900 139881799980800 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.3803926706314087, loss=2.1139392852783203
I0302 20:54:50.634956 139881808373504 logging_writer.py:48] [74600] global_step=74600, grad_norm=1.4479607343673706, loss=2.3097996711730957
I0302 20:55:34.893627 139881799980800 logging_writer.py:48] [74700] global_step=74700, grad_norm=1.2183318138122559, loss=2.331719160079956
I0302 20:56:01.945323 140077943854912 spec.py:321] Evaluating on the training split.
I0302 20:56:12.303884 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 20:56:35.641407 140077943854912 spec.py:349] Evaluating on the test split.
I0302 20:56:37.228406 140077943854912 submission_runner.py:411] Time since start: 35390.03s, 	Step: 74763, 	{'train/accuracy': 0.7062109112739563, 'train/loss': 1.1783642768859863, 'validation/accuracy': 0.6523199677467346, 'validation/loss': 1.4315232038497925, 'validation/num_examples': 50000, 'test/accuracy': 0.5234000086784363, 'test/loss': 2.103261709213257, 'test/num_examples': 10000, 'score': 32814.26351618767, 'total_duration': 35390.033418655396, 'accumulated_submission_time': 32814.26351618767, 'accumulated_eval_time': 2569.0166244506836, 'accumulated_logging_time': 2.8360533714294434}
I0302 20:56:37.255481 139881808373504 logging_writer.py:48] [74763] accumulated_eval_time=2569.016624, accumulated_logging_time=2.836053, accumulated_submission_time=32814.263516, global_step=74763, preemption_count=0, score=32814.263516, test/accuracy=0.523400, test/loss=2.103262, test/num_examples=10000, total_duration=35390.033419, train/accuracy=0.706211, train/loss=1.178364, validation/accuracy=0.652320, validation/loss=1.431523, validation/num_examples=50000
I0302 20:56:52.090633 139881799980800 logging_writer.py:48] [74800] global_step=74800, grad_norm=1.293821930885315, loss=2.045747756958008
I0302 20:57:33.950571 139881808373504 logging_writer.py:48] [74900] global_step=74900, grad_norm=1.3163384199142456, loss=2.389043092727661
I0302 20:58:18.375240 139881799980800 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.2521162033081055, loss=4.229336261749268
I0302 20:59:03.531381 139881808373504 logging_writer.py:48] [75100] global_step=75100, grad_norm=1.2302625179290771, loss=3.34753680229187
I0302 20:59:47.934436 139881799980800 logging_writer.py:48] [75200] global_step=75200, grad_norm=1.1945186853408813, loss=4.021246910095215
I0302 21:00:32.525652 139881808373504 logging_writer.py:48] [75300] global_step=75300, grad_norm=1.3001418113708496, loss=2.2517008781433105
I0302 21:01:16.856632 139881799980800 logging_writer.py:48] [75400] global_step=75400, grad_norm=1.4679101705551147, loss=2.1712076663970947
I0302 21:02:01.331008 139881808373504 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.3218134641647339, loss=2.1714372634887695
I0302 21:02:45.902860 139881799980800 logging_writer.py:48] [75600] global_step=75600, grad_norm=1.3600443601608276, loss=2.18270206451416
I0302 21:03:30.514925 139881808373504 logging_writer.py:48] [75700] global_step=75700, grad_norm=1.2488560676574707, loss=2.7801804542541504
I0302 21:03:37.354356 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:03:47.733575 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:04:10.803664 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:04:12.389271 140077943854912 submission_runner.py:411] Time since start: 35845.19s, 	Step: 75717, 	{'train/accuracy': 0.7077734470367432, 'train/loss': 1.1573503017425537, 'validation/accuracy': 0.6542999744415283, 'validation/loss': 1.419303297996521, 'validation/num_examples': 50000, 'test/accuracy': 0.5235000252723694, 'test/loss': 2.121488332748413, 'test/num_examples': 10000, 'score': 33234.302689790726, 'total_duration': 35845.19429016113, 'accumulated_submission_time': 33234.302689790726, 'accumulated_eval_time': 2604.0515208244324, 'accumulated_logging_time': 2.8736648559570312}
I0302 21:04:12.417213 139881799980800 logging_writer.py:48] [75717] accumulated_eval_time=2604.051521, accumulated_logging_time=2.873665, accumulated_submission_time=33234.302690, global_step=75717, preemption_count=0, score=33234.302690, test/accuracy=0.523500, test/loss=2.121488, test/num_examples=10000, total_duration=35845.194290, train/accuracy=0.707773, train/loss=1.157350, validation/accuracy=0.654300, validation/loss=1.419303, validation/num_examples=50000
I0302 21:04:45.217374 139881808373504 logging_writer.py:48] [75800] global_step=75800, grad_norm=1.1603028774261475, loss=4.679593563079834
I0302 21:05:29.566408 139881799980800 logging_writer.py:48] [75900] global_step=75900, grad_norm=1.403542399406433, loss=2.1880874633789062
I0302 21:06:14.127376 139881808373504 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.622959852218628, loss=2.1854350566864014
I0302 21:06:58.520209 139881799980800 logging_writer.py:48] [76100] global_step=76100, grad_norm=1.3912200927734375, loss=2.071655750274658
I0302 21:07:42.966391 139881808373504 logging_writer.py:48] [76200] global_step=76200, grad_norm=1.2840226888656616, loss=4.559516429901123
I0302 21:08:27.370334 139881799980800 logging_writer.py:48] [76300] global_step=76300, grad_norm=1.3964990377426147, loss=2.115007162094116
I0302 21:09:12.056676 139881808373504 logging_writer.py:48] [76400] global_step=76400, grad_norm=1.3218942880630493, loss=2.208965301513672
I0302 21:09:56.258258 139881799980800 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.2412430047988892, loss=3.1647095680236816
I0302 21:10:40.589646 139881808373504 logging_writer.py:48] [76600] global_step=76600, grad_norm=1.2285550832748413, loss=2.3303022384643555
I0302 21:11:12.647388 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:11:22.887272 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:11:47.289760 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:11:48.869420 140077943854912 submission_runner.py:411] Time since start: 36301.67s, 	Step: 76674, 	{'train/accuracy': 0.7352538704872131, 'train/loss': 1.0566195249557495, 'validation/accuracy': 0.6536200046539307, 'validation/loss': 1.416456937789917, 'validation/num_examples': 50000, 'test/accuracy': 0.5303000211715698, 'test/loss': 2.0822157859802246, 'test/num_examples': 10000, 'score': 33654.46897649765, 'total_duration': 36301.674439907074, 'accumulated_submission_time': 33654.46897649765, 'accumulated_eval_time': 2640.2735633850098, 'accumulated_logging_time': 2.9117650985717773}
I0302 21:11:48.899688 139881799980800 logging_writer.py:48] [76674] accumulated_eval_time=2640.273563, accumulated_logging_time=2.911765, accumulated_submission_time=33654.468976, global_step=76674, preemption_count=0, score=33654.468976, test/accuracy=0.530300, test/loss=2.082216, test/num_examples=10000, total_duration=36301.674440, train/accuracy=0.735254, train/loss=1.056620, validation/accuracy=0.653620, validation/loss=1.416457, validation/num_examples=50000
I0302 21:11:59.444235 139881808373504 logging_writer.py:48] [76700] global_step=76700, grad_norm=1.2533482313156128, loss=4.301381587982178
I0302 21:12:40.422108 139881799980800 logging_writer.py:48] [76800] global_step=76800, grad_norm=1.2075998783111572, loss=2.9631025791168213
I0302 21:13:24.889386 139881808373504 logging_writer.py:48] [76900] global_step=76900, grad_norm=1.4012954235076904, loss=2.089789628982544
I0302 21:14:09.300820 139881799980800 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.230318307876587, loss=2.2132768630981445
I0302 21:14:53.581633 139881808373504 logging_writer.py:48] [77100] global_step=77100, grad_norm=1.2928041219711304, loss=3.268317699432373
I0302 21:15:37.908643 139881799980800 logging_writer.py:48] [77200] global_step=77200, grad_norm=1.2704288959503174, loss=4.10066556930542
I0302 21:16:22.315108 139881808373504 logging_writer.py:48] [77300] global_step=77300, grad_norm=1.4614304304122925, loss=2.0873165130615234
I0302 21:17:06.950971 139881799980800 logging_writer.py:48] [77400] global_step=77400, grad_norm=1.5003981590270996, loss=2.296034336090088
I0302 21:17:50.883737 139881808373504 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.3045445680618286, loss=3.425295352935791
I0302 21:18:35.194309 139881799980800 logging_writer.py:48] [77600] global_step=77600, grad_norm=1.4800912141799927, loss=2.5620203018188477
I0302 21:18:49.335977 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:18:59.412405 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:19:22.814604 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:19:24.394576 140077943854912 submission_runner.py:411] Time since start: 36757.20s, 	Step: 77634, 	{'train/accuracy': 0.7109179496765137, 'train/loss': 1.169638752937317, 'validation/accuracy': 0.6612199544906616, 'validation/loss': 1.404836654663086, 'validation/num_examples': 50000, 'test/accuracy': 0.5340999960899353, 'test/loss': 2.075775384902954, 'test/num_examples': 10000, 'score': 34074.84289550781, 'total_duration': 36757.19959259033, 'accumulated_submission_time': 34074.84289550781, 'accumulated_eval_time': 2675.3321437835693, 'accumulated_logging_time': 2.9543845653533936}
I0302 21:19:24.421466 139881808373504 logging_writer.py:48] [77634] accumulated_eval_time=2675.332144, accumulated_logging_time=2.954385, accumulated_submission_time=34074.842896, global_step=77634, preemption_count=0, score=34074.842896, test/accuracy=0.534100, test/loss=2.075775, test/num_examples=10000, total_duration=36757.199593, train/accuracy=0.710918, train/loss=1.169639, validation/accuracy=0.661220, validation/loss=1.404837, validation/num_examples=50000
I0302 21:19:50.590605 139881799980800 logging_writer.py:48] [77700] global_step=77700, grad_norm=1.4116755723953247, loss=2.131887674331665
I0302 21:20:33.640576 139881808373504 logging_writer.py:48] [77800] global_step=77800, grad_norm=1.475233554840088, loss=2.1386241912841797
I0302 21:21:18.144020 139881799980800 logging_writer.py:48] [77900] global_step=77900, grad_norm=1.3742079734802246, loss=2.1744017601013184
I0302 21:22:02.564865 139881808373504 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.3093491792678833, loss=2.0398709774017334
I0302 21:22:46.768191 139881799980800 logging_writer.py:48] [78100] global_step=78100, grad_norm=1.1893553733825684, loss=3.586369037628174
I0302 21:23:31.055697 139881808373504 logging_writer.py:48] [78200] global_step=78200, grad_norm=1.5300095081329346, loss=4.6297736167907715
I0302 21:24:15.613802 139881799980800 logging_writer.py:48] [78300] global_step=78300, grad_norm=1.3161410093307495, loss=4.27150821685791
I0302 21:24:59.839579 139881808373504 logging_writer.py:48] [78400] global_step=78400, grad_norm=1.2082009315490723, loss=3.823961019515991
I0302 21:25:44.119998 139881799980800 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.2774978876113892, loss=1.8934102058410645
I0302 21:26:24.433537 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:26:34.454070 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:27:00.155298 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:27:01.743812 140077943854912 submission_runner.py:411] Time since start: 37214.55s, 	Step: 78592, 	{'train/accuracy': 0.7156835794448853, 'train/loss': 1.1127052307128906, 'validation/accuracy': 0.662559986114502, 'validation/loss': 1.369977593421936, 'validation/num_examples': 50000, 'test/accuracy': 0.5379000306129456, 'test/loss': 2.034130811691284, 'test/num_examples': 10000, 'score': 34494.79498171806, 'total_duration': 37214.548818826675, 'accumulated_submission_time': 34494.79498171806, 'accumulated_eval_time': 2712.6424124240875, 'accumulated_logging_time': 2.9909353256225586}
I0302 21:27:01.785322 139881808373504 logging_writer.py:48] [78592] accumulated_eval_time=2712.642412, accumulated_logging_time=2.990935, accumulated_submission_time=34494.794982, global_step=78592, preemption_count=0, score=34494.794982, test/accuracy=0.537900, test/loss=2.034131, test/num_examples=10000, total_duration=37214.548819, train/accuracy=0.715684, train/loss=1.112705, validation/accuracy=0.662560, validation/loss=1.369978, validation/num_examples=50000
I0302 21:27:05.311663 139881799980800 logging_writer.py:48] [78600] global_step=78600, grad_norm=1.295469880104065, loss=2.240715265274048
I0302 21:27:45.303933 139881808373504 logging_writer.py:48] [78700] global_step=78700, grad_norm=1.238741159439087, loss=3.984164237976074
I0302 21:28:29.268394 139881799980800 logging_writer.py:48] [78800] global_step=78800, grad_norm=1.2124626636505127, loss=3.4050211906433105
I0302 21:29:14.137258 139881808373504 logging_writer.py:48] [78900] global_step=78900, grad_norm=1.2877811193466187, loss=2.4527454376220703
I0302 21:29:58.659386 139881799980800 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.2569397687911987, loss=2.280106782913208
I0302 21:30:43.156612 139881808373504 logging_writer.py:48] [79100] global_step=79100, grad_norm=1.4432783126831055, loss=2.2538528442382812
I0302 21:31:27.768364 139881799980800 logging_writer.py:48] [79200] global_step=79200, grad_norm=1.4166100025177002, loss=2.2308309078216553
I0302 21:32:12.331687 139881808373504 logging_writer.py:48] [79300] global_step=79300, grad_norm=1.319995403289795, loss=3.408749580383301
I0302 21:32:56.451925 139881799980800 logging_writer.py:48] [79400] global_step=79400, grad_norm=1.3530895709991455, loss=2.1956064701080322
I0302 21:33:40.964041 139881808373504 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.3514091968536377, loss=4.8046183586120605
I0302 21:34:01.786546 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:34:12.002205 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:34:35.242216 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:34:36.831156 140077943854912 submission_runner.py:411] Time since start: 37669.64s, 	Step: 79548, 	{'train/accuracy': 0.7233788967132568, 'train/loss': 1.1037510633468628, 'validation/accuracy': 0.659280002117157, 'validation/loss': 1.397465705871582, 'validation/num_examples': 50000, 'test/accuracy': 0.5356000065803528, 'test/loss': 2.0531795024871826, 'test/num_examples': 10000, 'score': 34914.722329854965, 'total_duration': 37669.63617515564, 'accumulated_submission_time': 34914.722329854965, 'accumulated_eval_time': 2747.6870136260986, 'accumulated_logging_time': 3.0444273948669434}
I0302 21:34:36.858679 139881799980800 logging_writer.py:48] [79548] accumulated_eval_time=2747.687014, accumulated_logging_time=3.044427, accumulated_submission_time=34914.722330, global_step=79548, preemption_count=0, score=34914.722330, test/accuracy=0.535600, test/loss=2.053180, test/num_examples=10000, total_duration=37669.636175, train/accuracy=0.723379, train/loss=1.103751, validation/accuracy=0.659280, validation/loss=1.397466, validation/num_examples=50000
I0302 21:34:57.556388 139881808373504 logging_writer.py:48] [79600] global_step=79600, grad_norm=1.2121756076812744, loss=4.4317827224731445
I0302 21:35:39.707530 139881799980800 logging_writer.py:48] [79700] global_step=79700, grad_norm=1.4071316719055176, loss=2.420017719268799
I0302 21:36:24.307678 139881808373504 logging_writer.py:48] [79800] global_step=79800, grad_norm=1.3853442668914795, loss=2.1697254180908203
I0302 21:37:08.991488 139881799980800 logging_writer.py:48] [79900] global_step=79900, grad_norm=1.246535301208496, loss=2.668130397796631
I0302 21:37:52.990188 139881808373504 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.1931368112564087, loss=2.9088382720947266
I0302 21:38:37.467737 139881799980800 logging_writer.py:48] [80100] global_step=80100, grad_norm=1.3396615982055664, loss=3.562840223312378
I0302 21:39:22.104272 139881808373504 logging_writer.py:48] [80200] global_step=80200, grad_norm=1.4502493143081665, loss=3.3700053691864014
I0302 21:40:06.627325 139881799980800 logging_writer.py:48] [80300] global_step=80300, grad_norm=1.1733351945877075, loss=4.543157577514648
I0302 21:40:50.933287 139881808373504 logging_writer.py:48] [80400] global_step=80400, grad_norm=1.2213685512542725, loss=4.179051876068115
I0302 21:41:35.543435 139881799980800 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.2973932027816772, loss=2.365058422088623
I0302 21:41:37.001902 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:41:47.577182 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:42:11.035629 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:42:12.615403 140077943854912 submission_runner.py:411] Time since start: 38125.42s, 	Step: 80505, 	{'train/accuracy': 0.7168163657188416, 'train/loss': 1.1397818326950073, 'validation/accuracy': 0.6624999642372131, 'validation/loss': 1.3918650150299072, 'validation/num_examples': 50000, 'test/accuracy': 0.5367000102996826, 'test/loss': 2.0481276512145996, 'test/num_examples': 10000, 'score': 35334.804896593094, 'total_duration': 38125.42041826248, 'accumulated_submission_time': 35334.804896593094, 'accumulated_eval_time': 2783.3004961013794, 'accumulated_logging_time': 3.0824363231658936}
I0302 21:42:12.643308 139881808373504 logging_writer.py:48] [80505] accumulated_eval_time=2783.300496, accumulated_logging_time=3.082436, accumulated_submission_time=35334.804897, global_step=80505, preemption_count=0, score=35334.804897, test/accuracy=0.536700, test/loss=2.048128, test/num_examples=10000, total_duration=38125.420418, train/accuracy=0.716816, train/loss=1.139782, validation/accuracy=0.662500, validation/loss=1.391865, validation/num_examples=50000
I0302 21:42:50.635689 139881799980800 logging_writer.py:48] [80600] global_step=80600, grad_norm=1.373713731765747, loss=2.008209705352783
I0302 21:43:34.659784 139881808373504 logging_writer.py:48] [80700] global_step=80700, grad_norm=1.4862993955612183, loss=2.138040065765381
I0302 21:44:19.188190 139881799980800 logging_writer.py:48] [80800] global_step=80800, grad_norm=1.286494255065918, loss=2.639641284942627
I0302 21:45:03.394483 139881808373504 logging_writer.py:48] [80900] global_step=80900, grad_norm=1.3143110275268555, loss=2.2557244300842285
I0302 21:45:48.190870 139881799980800 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.4152398109436035, loss=2.0939221382141113
I0302 21:46:33.019851 139881808373504 logging_writer.py:48] [81100] global_step=81100, grad_norm=1.1873388290405273, loss=4.535324573516846
I0302 21:47:17.419660 139881799980800 logging_writer.py:48] [81200] global_step=81200, grad_norm=1.3118035793304443, loss=3.357128858566284
I0302 21:48:01.455223 139881808373504 logging_writer.py:48] [81300] global_step=81300, grad_norm=1.3804011344909668, loss=2.2516276836395264
I0302 21:48:45.981834 139881799980800 logging_writer.py:48] [81400] global_step=81400, grad_norm=1.2783986330032349, loss=4.713822841644287
I0302 21:49:12.825892 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:49:22.984405 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:49:47.200136 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:49:48.783613 140077943854912 submission_runner.py:411] Time since start: 38581.59s, 	Step: 81462, 	{'train/accuracy': 0.7132421731948853, 'train/loss': 1.1469886302947998, 'validation/accuracy': 0.6568199992179871, 'validation/loss': 1.4000229835510254, 'validation/num_examples': 50000, 'test/accuracy': 0.526199996471405, 'test/loss': 2.0777854919433594, 'test/num_examples': 10000, 'score': 35754.91748666763, 'total_duration': 38581.588628053665, 'accumulated_submission_time': 35754.91748666763, 'accumulated_eval_time': 2819.2582035064697, 'accumulated_logging_time': 3.1309750080108643}
I0302 21:49:48.815569 139881808373504 logging_writer.py:48] [81462] accumulated_eval_time=2819.258204, accumulated_logging_time=3.130975, accumulated_submission_time=35754.917487, global_step=81462, preemption_count=0, score=35754.917487, test/accuracy=0.526200, test/loss=2.077785, test/num_examples=10000, total_duration=38581.588628, train/accuracy=0.713242, train/loss=1.146989, validation/accuracy=0.656820, validation/loss=1.400023, validation/num_examples=50000
I0302 21:50:04.022016 139881799980800 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.3013629913330078, loss=4.136373043060303
I0302 21:50:45.434070 139881808373504 logging_writer.py:48] [81600] global_step=81600, grad_norm=1.2474873065948486, loss=3.4195961952209473
I0302 21:51:29.926784 139881799980800 logging_writer.py:48] [81700] global_step=81700, grad_norm=1.2514846324920654, loss=2.264305591583252
I0302 21:52:14.430836 139881808373504 logging_writer.py:48] [81800] global_step=81800, grad_norm=1.3300931453704834, loss=3.8909807205200195
I0302 21:52:58.592875 139881799980800 logging_writer.py:48] [81900] global_step=81900, grad_norm=1.483230710029602, loss=1.984851360321045
I0302 21:53:42.905797 139881808373504 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.1603339910507202, loss=4.220789909362793
I0302 21:54:27.139599 139881799980800 logging_writer.py:48] [82100] global_step=82100, grad_norm=1.5642279386520386, loss=2.165907382965088
I0302 21:55:11.441023 139881808373504 logging_writer.py:48] [82200] global_step=82200, grad_norm=1.6228678226470947, loss=2.1934971809387207
I0302 21:55:55.544926 139881799980800 logging_writer.py:48] [82300] global_step=82300, grad_norm=1.3695716857910156, loss=4.646786212921143
I0302 21:56:40.350963 139881808373504 logging_writer.py:48] [82400] global_step=82400, grad_norm=1.3160789012908936, loss=2.0273842811584473
I0302 21:56:48.862814 140077943854912 spec.py:321] Evaluating on the training split.
I0302 21:56:59.341059 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 21:57:21.330024 140077943854912 spec.py:349] Evaluating on the test split.
I0302 21:57:22.909564 140077943854912 submission_runner.py:411] Time since start: 39035.71s, 	Step: 82421, 	{'train/accuracy': 0.7280859351158142, 'train/loss': 1.0940496921539307, 'validation/accuracy': 0.6650399565696716, 'validation/loss': 1.375693678855896, 'validation/num_examples': 50000, 'test/accuracy': 0.5421000123023987, 'test/loss': 2.0170681476593018, 'test/num_examples': 10000, 'score': 36174.90492129326, 'total_duration': 39035.7145614624, 'accumulated_submission_time': 36174.90492129326, 'accumulated_eval_time': 2853.3048980236053, 'accumulated_logging_time': 3.1728460788726807}
I0302 21:57:22.937862 139881799980800 logging_writer.py:48] [82421] accumulated_eval_time=2853.304898, accumulated_logging_time=3.172846, accumulated_submission_time=36174.904921, global_step=82421, preemption_count=0, score=36174.904921, test/accuracy=0.542100, test/loss=2.017068, test/num_examples=10000, total_duration=39035.714561, train/accuracy=0.728086, train/loss=1.094050, validation/accuracy=0.665040, validation/loss=1.375694, validation/num_examples=50000
I0302 21:57:54.191798 139881808373504 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.2705068588256836, loss=2.4884326457977295
I0302 21:58:38.356425 139881799980800 logging_writer.py:48] [82600] global_step=82600, grad_norm=1.3352820873260498, loss=2.0276384353637695
I0302 21:59:22.782398 139881808373504 logging_writer.py:48] [82700] global_step=82700, grad_norm=1.2186915874481201, loss=2.595503568649292
I0302 22:00:07.225380 139881799980800 logging_writer.py:48] [82800] global_step=82800, grad_norm=1.487924575805664, loss=2.1262266635894775
I0302 22:00:51.426769 139881808373504 logging_writer.py:48] [82900] global_step=82900, grad_norm=1.3469223976135254, loss=3.5916123390197754
I0302 22:01:35.613831 139881799980800 logging_writer.py:48] [83000] global_step=83000, grad_norm=1.420986294746399, loss=2.0953288078308105
I0302 22:02:19.928527 139881808373504 logging_writer.py:48] [83100] global_step=83100, grad_norm=1.2871434688568115, loss=2.689647674560547
I0302 22:03:04.230230 139881799980800 logging_writer.py:48] [83200] global_step=83200, grad_norm=1.3610635995864868, loss=2.1369524002075195
I0302 22:03:48.424996 139881808373504 logging_writer.py:48] [83300] global_step=83300, grad_norm=1.2891640663146973, loss=2.1043646335601807
I0302 22:04:23.094647 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:04:33.880628 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:04:56.978235 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:04:58.596958 140077943854912 submission_runner.py:411] Time since start: 39491.40s, 	Step: 83380, 	{'train/accuracy': 0.7390820384025574, 'train/loss': 1.0498539209365845, 'validation/accuracy': 0.6658599972724915, 'validation/loss': 1.3794326782226562, 'validation/num_examples': 50000, 'test/accuracy': 0.5343000292778015, 'test/loss': 2.052915334701538, 'test/num_examples': 10000, 'score': 36595.001002788544, 'total_duration': 39491.40196967125, 'accumulated_submission_time': 36595.001002788544, 'accumulated_eval_time': 2888.807193994522, 'accumulated_logging_time': 3.2124273777008057}
I0302 22:04:58.627950 139881799980800 logging_writer.py:48] [83380] accumulated_eval_time=2888.807194, accumulated_logging_time=3.212427, accumulated_submission_time=36595.001003, global_step=83380, preemption_count=0, score=36595.001003, test/accuracy=0.534300, test/loss=2.052915, test/num_examples=10000, total_duration=39491.401970, train/accuracy=0.739082, train/loss=1.049854, validation/accuracy=0.665860, validation/loss=1.379433, validation/num_examples=50000
I0302 22:05:06.830358 139881808373504 logging_writer.py:48] [83400] global_step=83400, grad_norm=1.3233696222305298, loss=2.3076839447021484
I0302 22:05:47.612329 139881799980800 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.3932547569274902, loss=2.9425437450408936
I0302 22:06:32.351259 139881808373504 logging_writer.py:48] [83600] global_step=83600, grad_norm=1.3108298778533936, loss=3.2480008602142334
I0302 22:07:17.055149 139881799980800 logging_writer.py:48] [83700] global_step=83700, grad_norm=1.423769474029541, loss=2.137768268585205
I0302 22:08:00.973483 139881808373504 logging_writer.py:48] [83800] global_step=83800, grad_norm=1.4766141176223755, loss=2.0474929809570312
I0302 22:08:45.372087 139881799980800 logging_writer.py:48] [83900] global_step=83900, grad_norm=1.3707271814346313, loss=2.04280948638916
I0302 22:09:29.543991 139881808373504 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.4122110605239868, loss=2.069180965423584
I0302 22:10:13.867223 139881799980800 logging_writer.py:48] [84100] global_step=84100, grad_norm=1.4913344383239746, loss=2.4015588760375977
I0302 22:10:57.881646 139881808373504 logging_writer.py:48] [84200] global_step=84200, grad_norm=1.4600776433944702, loss=3.2638208866119385
I0302 22:11:42.327637 139881799980800 logging_writer.py:48] [84300] global_step=84300, grad_norm=1.3641103506088257, loss=1.9169623851776123
I0302 22:11:58.952778 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:12:09.382258 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:12:32.289411 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:12:33.872670 140077943854912 submission_runner.py:411] Time since start: 39946.68s, 	Step: 84339, 	{'train/accuracy': 0.7233007550239563, 'train/loss': 1.0985373258590698, 'validation/accuracy': 0.668720006942749, 'validation/loss': 1.3489693403244019, 'validation/num_examples': 50000, 'test/accuracy': 0.5428000092506409, 'test/loss': 1.9996387958526611, 'test/num_examples': 10000, 'score': 37015.265879392624, 'total_duration': 39946.677662849426, 'accumulated_submission_time': 37015.265879392624, 'accumulated_eval_time': 2923.7270460128784, 'accumulated_logging_time': 3.254138708114624}
I0302 22:12:33.903265 139881808373504 logging_writer.py:48] [84339] accumulated_eval_time=2923.727046, accumulated_logging_time=3.254139, accumulated_submission_time=37015.265879, global_step=84339, preemption_count=0, score=37015.265879, test/accuracy=0.542800, test/loss=1.999639, test/num_examples=10000, total_duration=39946.677663, train/accuracy=0.723301, train/loss=1.098537, validation/accuracy=0.668720, validation/loss=1.348969, validation/num_examples=50000
I0302 22:12:58.128587 139881799980800 logging_writer.py:48] [84400] global_step=84400, grad_norm=1.4278652667999268, loss=1.9585597515106201
I0302 22:13:41.149510 139881808373504 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.391892671585083, loss=2.072132110595703
I0302 22:14:25.572238 139881799980800 logging_writer.py:48] [84600] global_step=84600, grad_norm=1.6024481058120728, loss=2.262582778930664
I0302 22:15:09.848653 139881808373504 logging_writer.py:48] [84700] global_step=84700, grad_norm=1.3636622428894043, loss=1.9999438524246216
I0302 22:15:53.950120 139881799980800 logging_writer.py:48] [84800] global_step=84800, grad_norm=1.450085163116455, loss=2.1223089694976807
I0302 22:16:38.639005 139881808373504 logging_writer.py:48] [84900] global_step=84900, grad_norm=1.2912155389785767, loss=3.0017354488372803
I0302 22:17:22.934059 139881799980800 logging_writer.py:48] [85000] global_step=85000, grad_norm=1.3056273460388184, loss=4.450986385345459
I0302 22:18:07.521341 139881808373504 logging_writer.py:48] [85100] global_step=85100, grad_norm=1.290349006652832, loss=2.8034801483154297
I0302 22:18:51.563686 139881799980800 logging_writer.py:48] [85200] global_step=85200, grad_norm=1.5249987840652466, loss=2.1511988639831543
I0302 22:19:34.315832 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:19:44.886978 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:20:08.254008 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:20:09.840768 140077943854912 submission_runner.py:411] Time since start: 40402.65s, 	Step: 85298, 	{'train/accuracy': 0.7191796898841858, 'train/loss': 1.1635682582855225, 'validation/accuracy': 0.6645399928092957, 'validation/loss': 1.4133321046829224, 'validation/num_examples': 50000, 'test/accuracy': 0.5355000495910645, 'test/loss': 2.0667412281036377, 'test/num_examples': 10000, 'score': 37435.61778759956, 'total_duration': 40402.64578437805, 'accumulated_submission_time': 37435.61778759956, 'accumulated_eval_time': 2959.251959323883, 'accumulated_logging_time': 3.2952709197998047}
I0302 22:20:09.871572 139881808373504 logging_writer.py:48] [85298] accumulated_eval_time=2959.251959, accumulated_logging_time=3.295271, accumulated_submission_time=37435.617788, global_step=85298, preemption_count=0, score=37435.617788, test/accuracy=0.535500, test/loss=2.066741, test/num_examples=10000, total_duration=40402.645784, train/accuracy=0.719180, train/loss=1.163568, validation/accuracy=0.664540, validation/loss=1.413332, validation/num_examples=50000
I0302 22:20:11.047629 139881799980800 logging_writer.py:48] [85300] global_step=85300, grad_norm=1.346114158630371, loss=2.85605525970459
I0302 22:20:50.608923 139881808373504 logging_writer.py:48] [85400] global_step=85400, grad_norm=1.4988963603973389, loss=2.049020767211914
I0302 22:21:34.920504 139881799980800 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.390754222869873, loss=2.0109357833862305
I0302 22:22:19.406171 139881808373504 logging_writer.py:48] [85600] global_step=85600, grad_norm=1.5829375982284546, loss=2.035694122314453
I0302 22:23:03.505983 139881799980800 logging_writer.py:48] [85700] global_step=85700, grad_norm=1.4199804067611694, loss=1.972145438194275
I0302 22:23:47.784169 139881808373504 logging_writer.py:48] [85800] global_step=85800, grad_norm=1.2360285520553589, loss=3.642089366912842
I0302 22:24:31.919111 139881799980800 logging_writer.py:48] [85900] global_step=85900, grad_norm=1.4060313701629639, loss=2.3306949138641357
I0302 22:25:16.147882 139881808373504 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.1822052001953125, loss=2.955092430114746
I0302 22:26:00.572046 139881799980800 logging_writer.py:48] [86100] global_step=86100, grad_norm=1.2634083032608032, loss=2.73655104637146
I0302 22:26:44.789959 139881808373504 logging_writer.py:48] [86200] global_step=86200, grad_norm=1.5194872617721558, loss=1.9745726585388184
I0302 22:27:10.060341 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:27:20.001096 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:27:39.937321 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:27:41.531899 140077943854912 submission_runner.py:411] Time since start: 40854.34s, 	Step: 86259, 	{'train/accuracy': 0.7269921898841858, 'train/loss': 1.1259955167770386, 'validation/accuracy': 0.6650800108909607, 'validation/loss': 1.396593451499939, 'validation/num_examples': 50000, 'test/accuracy': 0.5408000349998474, 'test/loss': 2.054095506668091, 'test/num_examples': 10000, 'score': 37855.74568748474, 'total_duration': 40854.33689212799, 'accumulated_submission_time': 37855.74568748474, 'accumulated_eval_time': 2990.723461866379, 'accumulated_logging_time': 3.3366193771362305}
I0302 22:27:41.569170 139881799980800 logging_writer.py:48] [86259] accumulated_eval_time=2990.723462, accumulated_logging_time=3.336619, accumulated_submission_time=37855.745687, global_step=86259, preemption_count=0, score=37855.745687, test/accuracy=0.540800, test/loss=2.054096, test/num_examples=10000, total_duration=40854.336892, train/accuracy=0.726992, train/loss=1.125996, validation/accuracy=0.665080, validation/loss=1.396593, validation/num_examples=50000
I0302 22:27:57.965511 139881808373504 logging_writer.py:48] [86300] global_step=86300, grad_norm=1.3047451972961426, loss=3.983051061630249
I0302 22:28:40.253514 139881799980800 logging_writer.py:48] [86400] global_step=86400, grad_norm=1.3086539506912231, loss=4.43765926361084
I0302 22:29:24.467661 139881808373504 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.5792555809020996, loss=2.240689516067505
I0302 22:30:09.081289 139881799980800 logging_writer.py:48] [86600] global_step=86600, grad_norm=1.3170803785324097, loss=2.6253607273101807
I0302 22:30:53.138776 139881808373504 logging_writer.py:48] [86700] global_step=86700, grad_norm=1.1942877769470215, loss=3.908402919769287
I0302 22:31:37.685215 139881799980800 logging_writer.py:48] [86800] global_step=86800, grad_norm=1.3399910926818848, loss=2.583164930343628
I0302 22:32:22.153455 139881808373504 logging_writer.py:48] [86900] global_step=86900, grad_norm=1.2951116561889648, loss=4.487061023712158
I0302 22:33:06.413588 139881799980800 logging_writer.py:48] [87000] global_step=87000, grad_norm=1.2626608610153198, loss=2.791728973388672
I0302 22:33:50.510595 139881808373504 logging_writer.py:48] [87100] global_step=87100, grad_norm=1.4371436834335327, loss=2.3604869842529297
I0302 22:34:34.932501 139881799980800 logging_writer.py:48] [87200] global_step=87200, grad_norm=1.258646845817566, loss=3.7599587440490723
I0302 22:34:41.684399 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:34:51.959574 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:35:12.267287 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:35:13.852357 140077943854912 submission_runner.py:411] Time since start: 41306.66s, 	Step: 87217, 	{'train/accuracy': 0.7546288967132568, 'train/loss': 0.9544236660003662, 'validation/accuracy': 0.6703999638557434, 'validation/loss': 1.32748544216156, 'validation/num_examples': 50000, 'test/accuracy': 0.5439000129699707, 'test/loss': 1.98435378074646, 'test/num_examples': 10000, 'score': 38275.79717183113, 'total_duration': 41306.657376527786, 'accumulated_submission_time': 38275.79717183113, 'accumulated_eval_time': 3022.891412258148, 'accumulated_logging_time': 3.387751340866089}
I0302 22:35:13.884402 139881808373504 logging_writer.py:48] [87217] accumulated_eval_time=3022.891412, accumulated_logging_time=3.387751, accumulated_submission_time=38275.797172, global_step=87217, preemption_count=0, score=38275.797172, test/accuracy=0.543900, test/loss=1.984354, test/num_examples=10000, total_duration=41306.657377, train/accuracy=0.754629, train/loss=0.954424, validation/accuracy=0.670400, validation/loss=1.327485, validation/num_examples=50000
I0302 22:35:46.705710 139881799980800 logging_writer.py:48] [87300] global_step=87300, grad_norm=1.3425487279891968, loss=2.69338321685791
I0302 22:36:30.991812 139881808373504 logging_writer.py:48] [87400] global_step=87400, grad_norm=1.3487545251846313, loss=2.112464427947998
I0302 22:37:15.467337 139881799980800 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.5106008052825928, loss=4.5160441398620605
I0302 22:38:00.303687 139881808373504 logging_writer.py:48] [87600] global_step=87600, grad_norm=1.3607884645462036, loss=2.0051429271698
I0302 22:38:44.765956 139881799980800 logging_writer.py:48] [87700] global_step=87700, grad_norm=1.2582848072052002, loss=2.768887996673584
I0302 22:39:29.143150 139881808373504 logging_writer.py:48] [87800] global_step=87800, grad_norm=1.5636669397354126, loss=2.1012704372406006
I0302 22:40:13.843617 139881799980800 logging_writer.py:48] [87900] global_step=87900, grad_norm=1.2699718475341797, loss=4.109259128570557
I0302 22:40:58.033777 139881808373504 logging_writer.py:48] [88000] global_step=88000, grad_norm=1.6436340808868408, loss=2.054792881011963
I0302 22:41:42.345582 139881799980800 logging_writer.py:48] [88100] global_step=88100, grad_norm=1.6017372608184814, loss=4.667608261108398
I0302 22:42:13.868810 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:42:23.975538 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:42:45.795253 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:42:47.374667 140077943854912 submission_runner.py:411] Time since start: 41760.18s, 	Step: 88173, 	{'train/accuracy': 0.7283398509025574, 'train/loss': 1.082810401916504, 'validation/accuracy': 0.6726599931716919, 'validation/loss': 1.337311029434204, 'validation/num_examples': 50000, 'test/accuracy': 0.5463000535964966, 'test/loss': 1.9775358438491821, 'test/num_examples': 10000, 'score': 38695.72180867195, 'total_duration': 41760.179690122604, 'accumulated_submission_time': 38695.72180867195, 'accumulated_eval_time': 3056.3972618579865, 'accumulated_logging_time': 3.430220603942871}
I0302 22:42:47.403174 139881808373504 logging_writer.py:48] [88173] accumulated_eval_time=3056.397262, accumulated_logging_time=3.430221, accumulated_submission_time=38695.721809, global_step=88173, preemption_count=0, score=38695.721809, test/accuracy=0.546300, test/loss=1.977536, test/num_examples=10000, total_duration=41760.179690, train/accuracy=0.728340, train/loss=1.082810, validation/accuracy=0.672660, validation/loss=1.337311, validation/num_examples=50000
I0302 22:42:58.331538 139881799980800 logging_writer.py:48] [88200] global_step=88200, grad_norm=1.3841801881790161, loss=2.099036693572998
I0302 22:43:39.299098 139881808373504 logging_writer.py:48] [88300] global_step=88300, grad_norm=1.326072096824646, loss=4.5862016677856445
I0302 22:44:23.640044 139881799980800 logging_writer.py:48] [88400] global_step=88400, grad_norm=1.4064602851867676, loss=2.070075511932373
I0302 22:45:08.382968 139881808373504 logging_writer.py:48] [88500] global_step=88500, grad_norm=1.5096091032028198, loss=2.149932622909546
I0302 22:45:52.663488 139881799980800 logging_writer.py:48] [88600] global_step=88600, grad_norm=1.4850529432296753, loss=2.2913033962249756
I0302 22:46:37.445784 139881808373504 logging_writer.py:48] [88700] global_step=88700, grad_norm=1.2856801748275757, loss=3.092911958694458
I0302 22:47:21.423158 139881799980800 logging_writer.py:48] [88800] global_step=88800, grad_norm=1.2834573984146118, loss=3.5900025367736816
I0302 22:48:05.976934 139881808373504 logging_writer.py:48] [88900] global_step=88900, grad_norm=1.4270265102386475, loss=2.2108867168426514
I0302 22:48:50.315206 139881799980800 logging_writer.py:48] [89000] global_step=89000, grad_norm=1.3693516254425049, loss=2.092331886291504
I0302 22:49:34.850933 139881808373504 logging_writer.py:48] [89100] global_step=89100, grad_norm=1.407612681388855, loss=2.0171003341674805
I0302 22:49:47.838240 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:49:57.956079 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:50:22.451447 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:50:24.028796 140077943854912 submission_runner.py:411] Time since start: 42216.83s, 	Step: 89131, 	{'train/accuracy': 0.7352343797683716, 'train/loss': 1.056477427482605, 'validation/accuracy': 0.671779990196228, 'validation/loss': 1.3395153284072876, 'validation/num_examples': 50000, 'test/accuracy': 0.5505000352859497, 'test/loss': 1.975814938545227, 'test/num_examples': 10000, 'score': 39116.09435725212, 'total_duration': 42216.833818912506, 'accumulated_submission_time': 39116.09435725212, 'accumulated_eval_time': 3092.5877900123596, 'accumulated_logging_time': 3.471376419067383}
I0302 22:50:24.059979 139881799980800 logging_writer.py:48] [89131] accumulated_eval_time=3092.587790, accumulated_logging_time=3.471376, accumulated_submission_time=39116.094357, global_step=89131, preemption_count=0, score=39116.094357, test/accuracy=0.550500, test/loss=1.975815, test/num_examples=10000, total_duration=42216.833819, train/accuracy=0.735234, train/loss=1.056477, validation/accuracy=0.671780, validation/loss=1.339515, validation/num_examples=50000
I0302 22:50:51.397928 139881808373504 logging_writer.py:48] [89200] global_step=89200, grad_norm=1.451187014579773, loss=2.0344953536987305
I0302 22:51:34.660921 139881799980800 logging_writer.py:48] [89300] global_step=89300, grad_norm=1.538804531097412, loss=2.1277148723602295
I0302 22:52:19.020718 139881808373504 logging_writer.py:48] [89400] global_step=89400, grad_norm=1.3649840354919434, loss=4.633152008056641
I0302 22:53:03.343830 139881799980800 logging_writer.py:48] [89500] global_step=89500, grad_norm=1.3411295413970947, loss=2.872276544570923
I0302 22:53:47.673033 139881808373504 logging_writer.py:48] [89600] global_step=89600, grad_norm=1.222973346710205, loss=3.1529839038848877
I0302 22:54:31.802611 139881799980800 logging_writer.py:48] [89700] global_step=89700, grad_norm=1.3406939506530762, loss=2.8582520484924316
I0302 22:55:16.211588 139881808373504 logging_writer.py:48] [89800] global_step=89800, grad_norm=1.2026880979537964, loss=3.3200840950012207
I0302 22:56:00.555863 139881799980800 logging_writer.py:48] [89900] global_step=89900, grad_norm=1.3432092666625977, loss=4.640018463134766
I0302 22:56:44.699151 139881808373504 logging_writer.py:48] [90000] global_step=90000, grad_norm=1.357891321182251, loss=3.903923988342285
I0302 22:57:24.385114 140077943854912 spec.py:321] Evaluating on the training split.
I0302 22:57:34.446481 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 22:58:04.252697 140077943854912 spec.py:349] Evaluating on the test split.
I0302 22:58:05.830543 140077943854912 submission_runner.py:411] Time since start: 42678.64s, 	Step: 90091, 	{'train/accuracy': 0.7414257526397705, 'train/loss': 1.0378321409225464, 'validation/accuracy': 0.6741200089454651, 'validation/loss': 1.3346014022827148, 'validation/num_examples': 50000, 'test/accuracy': 0.5543000102043152, 'test/loss': 1.976184606552124, 'test/num_examples': 10000, 'score': 39536.358402490616, 'total_duration': 42678.63556289673, 'accumulated_submission_time': 39536.358402490616, 'accumulated_eval_time': 3134.03320145607, 'accumulated_logging_time': 3.513042688369751}
I0302 22:58:05.860046 139881799980800 logging_writer.py:48] [90091] accumulated_eval_time=3134.033201, accumulated_logging_time=3.513043, accumulated_submission_time=39536.358402, global_step=90091, preemption_count=0, score=39536.358402, test/accuracy=0.554300, test/loss=1.976185, test/num_examples=10000, total_duration=42678.635563, train/accuracy=0.741426, train/loss=1.037832, validation/accuracy=0.674120, validation/loss=1.334601, validation/num_examples=50000
I0302 22:58:09.751711 139881808373504 logging_writer.py:48] [90100] global_step=90100, grad_norm=1.4816920757293701, loss=2.010296106338501
I0302 22:58:50.069355 139881799980800 logging_writer.py:48] [90200] global_step=90200, grad_norm=1.3976961374282837, loss=2.4062299728393555
I0302 22:59:34.384604 139881808373504 logging_writer.py:48] [90300] global_step=90300, grad_norm=1.3494606018066406, loss=4.178902626037598
I0302 23:00:18.995988 139881799980800 logging_writer.py:48] [90400] global_step=90400, grad_norm=1.3103936910629272, loss=2.5004982948303223
I0302 23:01:03.216051 139881808373504 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.4595664739608765, loss=2.2422947883605957
I0302 23:01:47.578010 139881799980800 logging_writer.py:48] [90600] global_step=90600, grad_norm=1.4284523725509644, loss=2.0321383476257324
I0302 23:02:31.849489 139881808373504 logging_writer.py:48] [90700] global_step=90700, grad_norm=1.3152228593826294, loss=4.559638023376465
I0302 23:03:16.510147 139881799980800 logging_writer.py:48] [90800] global_step=90800, grad_norm=1.2725450992584229, loss=2.788071393966675
I0302 23:04:00.872895 139881808373504 logging_writer.py:48] [90900] global_step=90900, grad_norm=1.3718335628509521, loss=3.678643226623535
I0302 23:04:45.250053 139881799980800 logging_writer.py:48] [91000] global_step=91000, grad_norm=1.418006420135498, loss=2.194786310195923
I0302 23:05:05.960853 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:05:16.029145 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:05:41.777299 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:05:43.351605 140077943854912 submission_runner.py:411] Time since start: 43136.16s, 	Step: 91048, 	{'train/accuracy': 0.7334179282188416, 'train/loss': 1.0601955652236938, 'validation/accuracy': 0.6719399690628052, 'validation/loss': 1.3371931314468384, 'validation/num_examples': 50000, 'test/accuracy': 0.5467000007629395, 'test/loss': 1.9848815202713013, 'test/num_examples': 10000, 'score': 39956.39900755882, 'total_duration': 43136.15661621094, 'accumulated_submission_time': 39956.39900755882, 'accumulated_eval_time': 3171.4239320755005, 'accumulated_logging_time': 3.5524487495422363}
I0302 23:05:43.383676 139881808373504 logging_writer.py:48] [91048] accumulated_eval_time=3171.423932, accumulated_logging_time=3.552449, accumulated_submission_time=39956.399008, global_step=91048, preemption_count=0, score=39956.399008, test/accuracy=0.546700, test/loss=1.984882, test/num_examples=10000, total_duration=43136.156616, train/accuracy=0.733418, train/loss=1.060196, validation/accuracy=0.671940, validation/loss=1.337193, validation/num_examples=50000
I0302 23:06:04.078898 139881799980800 logging_writer.py:48] [91100] global_step=91100, grad_norm=1.3482909202575684, loss=2.699509620666504
I0302 23:06:46.841792 139881808373504 logging_writer.py:48] [91200] global_step=91200, grad_norm=1.5822511911392212, loss=4.622669219970703
I0302 23:07:31.128715 139881799980800 logging_writer.py:48] [91300] global_step=91300, grad_norm=1.5544615983963013, loss=2.206087589263916
I0302 23:08:15.761645 139881808373504 logging_writer.py:48] [91400] global_step=91400, grad_norm=1.3158854246139526, loss=4.236248970031738
I0302 23:08:59.854954 139881799980800 logging_writer.py:48] [91500] global_step=91500, grad_norm=1.4444087743759155, loss=2.0968821048736572
I0302 23:09:44.601261 139881808373504 logging_writer.py:48] [91600] global_step=91600, grad_norm=1.580580711364746, loss=4.587179183959961
I0302 23:10:29.236329 139881799980800 logging_writer.py:48] [91700] global_step=91700, grad_norm=1.4559367895126343, loss=2.0123863220214844
I0302 23:11:13.497138 139881808373504 logging_writer.py:48] [91800] global_step=91800, grad_norm=1.3367316722869873, loss=2.3710172176361084
I0302 23:11:57.951895 139881799980800 logging_writer.py:48] [91900] global_step=91900, grad_norm=1.4741326570510864, loss=2.023787260055542
I0302 23:12:42.324865 139881808373504 logging_writer.py:48] [92000] global_step=92000, grad_norm=1.2917776107788086, loss=4.227817058563232
I0302 23:12:43.705486 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:12:54.103282 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:13:22.308135 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:13:23.885488 140077943854912 submission_runner.py:411] Time since start: 43596.69s, 	Step: 92005, 	{'train/accuracy': 0.732128918170929, 'train/loss': 1.0990062952041626, 'validation/accuracy': 0.6755799651145935, 'validation/loss': 1.3497874736785889, 'validation/num_examples': 50000, 'test/accuracy': 0.5501000285148621, 'test/loss': 2.014688491821289, 'test/num_examples': 10000, 'score': 40376.65997195244, 'total_duration': 43596.69050884247, 'accumulated_submission_time': 40376.65997195244, 'accumulated_eval_time': 3211.6039159297943, 'accumulated_logging_time': 3.5961568355560303}
I0302 23:13:23.915556 139881799980800 logging_writer.py:48] [92005] accumulated_eval_time=3211.603916, accumulated_logging_time=3.596157, accumulated_submission_time=40376.659972, global_step=92005, preemption_count=0, score=40376.659972, test/accuracy=0.550100, test/loss=2.014688, test/num_examples=10000, total_duration=43596.690509, train/accuracy=0.732129, train/loss=1.099006, validation/accuracy=0.675580, validation/loss=1.349787, validation/num_examples=50000
I0302 23:14:01.866186 139881808373504 logging_writer.py:48] [92100] global_step=92100, grad_norm=1.533097743988037, loss=2.0060112476348877
I0302 23:14:46.184622 139881799980800 logging_writer.py:48] [92200] global_step=92200, grad_norm=1.3140493631362915, loss=3.979637384414673
I0302 23:15:30.769574 139881808373504 logging_writer.py:48] [92300] global_step=92300, grad_norm=1.418748140335083, loss=2.2683920860290527
I0302 23:16:15.200836 139881799980800 logging_writer.py:48] [92400] global_step=92400, grad_norm=1.4916741847991943, loss=2.1163604259490967
I0302 23:16:59.474113 139881808373504 logging_writer.py:48] [92500] global_step=92500, grad_norm=1.6199781894683838, loss=2.030308961868286
I0302 23:17:44.209298 139881799980800 logging_writer.py:48] [92600] global_step=92600, grad_norm=1.5179415941238403, loss=2.110407829284668
I0302 23:18:28.325516 139881808373504 logging_writer.py:48] [92700] global_step=92700, grad_norm=1.30205500125885, loss=3.0204391479492188
I0302 23:19:12.843600 139881799980800 logging_writer.py:48] [92800] global_step=92800, grad_norm=1.562703013420105, loss=4.278313159942627
I0302 23:19:57.114881 139881808373504 logging_writer.py:48] [92900] global_step=92900, grad_norm=1.45352041721344, loss=4.6161909103393555
I0302 23:20:23.920834 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:20:34.120747 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:20:57.172959 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:20:58.752887 140077943854912 submission_runner.py:411] Time since start: 44051.56s, 	Step: 92962, 	{'train/accuracy': 0.7373241782188416, 'train/loss': 1.0257611274719238, 'validation/accuracy': 0.6764799952507019, 'validation/loss': 1.3098903894424438, 'validation/num_examples': 50000, 'test/accuracy': 0.5496000051498413, 'test/loss': 1.969154953956604, 'test/num_examples': 10000, 'score': 40796.6041162014, 'total_duration': 44051.557891607285, 'accumulated_submission_time': 40796.6041162014, 'accumulated_eval_time': 3246.4359505176544, 'accumulated_logging_time': 3.63786244392395}
I0302 23:20:58.783450 139881799980800 logging_writer.py:48] [92962] accumulated_eval_time=3246.435951, accumulated_logging_time=3.637862, accumulated_submission_time=40796.604116, global_step=92962, preemption_count=0, score=40796.604116, test/accuracy=0.549600, test/loss=1.969155, test/num_examples=10000, total_duration=44051.557892, train/accuracy=0.737324, train/loss=1.025761, validation/accuracy=0.676480, validation/loss=1.309890, validation/num_examples=50000
I0302 23:21:14.003549 139881808373504 logging_writer.py:48] [93000] global_step=93000, grad_norm=1.634232521057129, loss=2.1133015155792236
I0302 23:21:55.347718 139881799980800 logging_writer.py:48] [93100] global_step=93100, grad_norm=1.5672017335891724, loss=2.1659367084503174
I0302 23:22:39.859367 139881808373504 logging_writer.py:48] [93200] global_step=93200, grad_norm=1.5492405891418457, loss=2.0267624855041504
I0302 23:23:24.084280 139881799980800 logging_writer.py:48] [93300] global_step=93300, grad_norm=1.2852377891540527, loss=3.7703516483306885
I0302 23:24:08.238224 139881808373504 logging_writer.py:48] [93400] global_step=93400, grad_norm=1.4915688037872314, loss=4.046957492828369
I0302 23:24:52.544432 139881799980800 logging_writer.py:48] [93500] global_step=93500, grad_norm=1.3775157928466797, loss=3.4687888622283936
I0302 23:25:36.537461 139881808373504 logging_writer.py:48] [93600] global_step=93600, grad_norm=1.3834562301635742, loss=2.537076473236084
I0302 23:26:21.038339 139881799980800 logging_writer.py:48] [93700] global_step=93700, grad_norm=1.5154261589050293, loss=1.989905595779419
I0302 23:27:05.159991 139881808373504 logging_writer.py:48] [93800] global_step=93800, grad_norm=1.3234881162643433, loss=3.7049951553344727
I0302 23:27:49.611559 139881799980800 logging_writer.py:48] [93900] global_step=93900, grad_norm=1.4541817903518677, loss=2.638272762298584
I0302 23:27:59.101239 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:28:09.684541 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:28:34.146924 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:28:35.723520 140077943854912 submission_runner.py:411] Time since start: 44508.53s, 	Step: 93923, 	{'train/accuracy': 0.74916011095047, 'train/loss': 0.9873992800712585, 'validation/accuracy': 0.6765999794006348, 'validation/loss': 1.3194611072540283, 'validation/num_examples': 50000, 'test/accuracy': 0.5472000241279602, 'test/loss': 1.9758864641189575, 'test/num_examples': 10000, 'score': 41216.86024641991, 'total_duration': 44508.528537750244, 'accumulated_submission_time': 41216.86024641991, 'accumulated_eval_time': 3283.058206319809, 'accumulated_logging_time': 3.6801745891571045}
I0302 23:28:35.753199 139881808373504 logging_writer.py:48] [93923] accumulated_eval_time=3283.058206, accumulated_logging_time=3.680175, accumulated_submission_time=41216.860246, global_step=93923, preemption_count=0, score=41216.860246, test/accuracy=0.547200, test/loss=1.975886, test/num_examples=10000, total_duration=44508.528538, train/accuracy=0.749160, train/loss=0.987399, validation/accuracy=0.676600, validation/loss=1.319461, validation/num_examples=50000
I0302 23:29:06.221684 139881799980800 logging_writer.py:48] [94000] global_step=94000, grad_norm=1.346553087234497, loss=1.9822025299072266
I0302 23:29:50.072251 139881808373504 logging_writer.py:48] [94100] global_step=94100, grad_norm=1.5201621055603027, loss=2.2083027362823486
I0302 23:30:34.754555 139881799980800 logging_writer.py:48] [94200] global_step=94200, grad_norm=1.423133373260498, loss=1.9995391368865967
I0302 23:31:18.862356 139881808373504 logging_writer.py:48] [94300] global_step=94300, grad_norm=1.3799958229064941, loss=4.333172798156738
I0302 23:32:03.236093 139881799980800 logging_writer.py:48] [94400] global_step=94400, grad_norm=1.5575355291366577, loss=2.003669500350952
I0302 23:32:47.205210 139881808373504 logging_writer.py:48] [94500] global_step=94500, grad_norm=1.5088168382644653, loss=2.2756667137145996
I0302 23:33:31.437712 139881799980800 logging_writer.py:48] [94600] global_step=94600, grad_norm=1.6546565294265747, loss=4.525063991546631
I0302 23:34:15.792406 139881808373504 logging_writer.py:48] [94700] global_step=94700, grad_norm=1.551426887512207, loss=2.086225748062134
I0302 23:34:59.883303 139881799980800 logging_writer.py:48] [94800] global_step=94800, grad_norm=1.4276031255722046, loss=3.2942469120025635
I0302 23:35:36.091975 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:35:46.188926 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:36:11.826797 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:36:13.399721 140077943854912 submission_runner.py:411] Time since start: 44966.20s, 	Step: 94883, 	{'train/accuracy': 0.740917980670929, 'train/loss': 1.0271331071853638, 'validation/accuracy': 0.6797199845314026, 'validation/loss': 1.3003922700881958, 'validation/num_examples': 50000, 'test/accuracy': 0.553600013256073, 'test/loss': 1.94719660282135, 'test/num_examples': 10000, 'score': 41637.13806056976, 'total_duration': 44966.204736709595, 'accumulated_submission_time': 41637.13806056976, 'accumulated_eval_time': 3320.365930557251, 'accumulated_logging_time': 3.7214975357055664}
I0302 23:36:13.431751 139881808373504 logging_writer.py:48] [94883] accumulated_eval_time=3320.365931, accumulated_logging_time=3.721498, accumulated_submission_time=41637.138061, global_step=94883, preemption_count=0, score=41637.138061, test/accuracy=0.553600, test/loss=1.947197, test/num_examples=10000, total_duration=44966.204737, train/accuracy=0.740918, train/loss=1.027133, validation/accuracy=0.679720, validation/loss=1.300392, validation/num_examples=50000
I0302 23:36:20.452394 139881799980800 logging_writer.py:48] [94900] global_step=94900, grad_norm=1.4157663583755493, loss=3.981670379638672
I0302 23:37:01.185091 139881808373504 logging_writer.py:48] [95000] global_step=95000, grad_norm=1.2599732875823975, loss=3.8212904930114746
I0302 23:37:45.720265 139881799980800 logging_writer.py:48] [95100] global_step=95100, grad_norm=1.7228527069091797, loss=2.0569982528686523
I0302 23:38:30.390656 139881808373504 logging_writer.py:48] [95200] global_step=95200, grad_norm=1.3494983911514282, loss=4.298367500305176
I0302 23:39:15.014413 139881799980800 logging_writer.py:48] [95300] global_step=95300, grad_norm=1.721483588218689, loss=1.9709224700927734
I0302 23:39:59.228820 139881808373504 logging_writer.py:48] [95400] global_step=95400, grad_norm=1.3410297632217407, loss=2.3674802780151367
I0302 23:40:43.807974 139881799980800 logging_writer.py:48] [95500] global_step=95500, grad_norm=1.3908761739730835, loss=1.9311645030975342
I0302 23:41:28.228046 139881808373504 logging_writer.py:48] [95600] global_step=95600, grad_norm=1.4584672451019287, loss=4.481081008911133
I0302 23:42:12.846066 139881799980800 logging_writer.py:48] [95700] global_step=95700, grad_norm=1.3129228353500366, loss=3.3286008834838867
I0302 23:42:57.246049 139881808373504 logging_writer.py:48] [95800] global_step=95800, grad_norm=1.5025361776351929, loss=2.1106526851654053
I0302 23:43:13.400214 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:43:23.468871 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:43:55.165915 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:43:56.749939 140077943854912 submission_runner.py:411] Time since start: 45429.55s, 	Step: 95838, 	{'train/accuracy': 0.7427148222923279, 'train/loss': 1.0067245960235596, 'validation/accuracy': 0.6803999543190002, 'validation/loss': 1.2884384393692017, 'validation/num_examples': 50000, 'test/accuracy': 0.5525000095367432, 'test/loss': 1.9437371492385864, 'test/num_examples': 10000, 'score': 42057.04630446434, 'total_duration': 45429.554921388626, 'accumulated_submission_time': 42057.04630446434, 'accumulated_eval_time': 3363.7155849933624, 'accumulated_logging_time': 3.7645370960235596}
I0302 23:43:56.784521 139881799980800 logging_writer.py:48] [95838] accumulated_eval_time=3363.715585, accumulated_logging_time=3.764537, accumulated_submission_time=42057.046304, global_step=95838, preemption_count=0, score=42057.046304, test/accuracy=0.552500, test/loss=1.943737, test/num_examples=10000, total_duration=45429.554921, train/accuracy=0.742715, train/loss=1.006725, validation/accuracy=0.680400, validation/loss=1.288438, validation/num_examples=50000
I0302 23:44:21.460486 139881808373504 logging_writer.py:48] [95900] global_step=95900, grad_norm=1.3901498317718506, loss=2.077089309692383
I0302 23:45:04.714482 139881799980800 logging_writer.py:48] [96000] global_step=96000, grad_norm=1.3278334140777588, loss=3.45004940032959
I0302 23:45:49.455570 139881808373504 logging_writer.py:48] [96100] global_step=96100, grad_norm=1.340721845626831, loss=4.5474066734313965
I0302 23:46:33.928640 139881799980800 logging_writer.py:48] [96200] global_step=96200, grad_norm=1.4863594770431519, loss=2.0139782428741455
I0302 23:47:18.225225 139881808373504 logging_writer.py:48] [96300] global_step=96300, grad_norm=1.2797003984451294, loss=2.8265540599823
I0302 23:48:02.831495 139881799980800 logging_writer.py:48] [96400] global_step=96400, grad_norm=1.3858469724655151, loss=1.7561362981796265
I0302 23:48:47.107036 139881808373504 logging_writer.py:48] [96500] global_step=96500, grad_norm=1.2691060304641724, loss=3.3257992267608643
I0302 23:49:31.594960 139881799980800 logging_writer.py:48] [96600] global_step=96600, grad_norm=1.299460530281067, loss=4.301977157592773
I0302 23:50:15.920943 139881808373504 logging_writer.py:48] [96700] global_step=96700, grad_norm=1.527726173400879, loss=2.028707981109619
I0302 23:50:56.780311 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:51:06.902924 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:51:34.326881 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:51:35.906764 140077943854912 submission_runner.py:411] Time since start: 45888.71s, 	Step: 96794, 	{'train/accuracy': 0.7479296922683716, 'train/loss': 0.9932562112808228, 'validation/accuracy': 0.6821199655532837, 'validation/loss': 1.2954468727111816, 'validation/num_examples': 50000, 'test/accuracy': 0.5600000023841858, 'test/loss': 1.9353830814361572, 'test/num_examples': 10000, 'score': 42476.98233127594, 'total_duration': 45888.711784124374, 'accumulated_submission_time': 42476.98233127594, 'accumulated_eval_time': 3402.8420236110687, 'accumulated_logging_time': 3.8099939823150635}
I0302 23:51:35.939949 139881799980800 logging_writer.py:48] [96794] accumulated_eval_time=3402.842024, accumulated_logging_time=3.809994, accumulated_submission_time=42476.982331, global_step=96794, preemption_count=0, score=42476.982331, test/accuracy=0.560000, test/loss=1.935383, test/num_examples=10000, total_duration=45888.711784, train/accuracy=0.747930, train/loss=0.993256, validation/accuracy=0.682120, validation/loss=1.295447, validation/num_examples=50000
I0302 23:51:38.672082 139881808373504 logging_writer.py:48] [96800] global_step=96800, grad_norm=1.4020452499389648, loss=2.0460493564605713
I0302 23:52:18.884797 139881799980800 logging_writer.py:48] [96900] global_step=96900, grad_norm=1.4495925903320312, loss=1.8777724504470825
I0302 23:53:03.197677 139881808373504 logging_writer.py:48] [97000] global_step=97000, grad_norm=1.437458872795105, loss=4.169096946716309
I0302 23:53:47.694921 139881799980800 logging_writer.py:48] [97100] global_step=97100, grad_norm=1.4300810098648071, loss=4.324710369110107
I0302 23:54:31.786462 139881808373504 logging_writer.py:48] [97200] global_step=97200, grad_norm=1.479657530784607, loss=2.1661570072174072
I0302 23:55:16.129397 139881799980800 logging_writer.py:48] [97300] global_step=97300, grad_norm=1.4407072067260742, loss=1.9016094207763672
I0302 23:56:00.400913 139881808373504 logging_writer.py:48] [97400] global_step=97400, grad_norm=1.5565749406814575, loss=1.9192688465118408
I0302 23:56:44.916965 139881799980800 logging_writer.py:48] [97500] global_step=97500, grad_norm=1.4491218328475952, loss=1.8186769485473633
I0302 23:57:29.416818 139881808373504 logging_writer.py:48] [97600] global_step=97600, grad_norm=1.4146056175231934, loss=2.4328126907348633
I0302 23:58:13.793883 139881799980800 logging_writer.py:48] [97700] global_step=97700, grad_norm=1.6408888101577759, loss=1.9419946670532227
I0302 23:58:36.089204 140077943854912 spec.py:321] Evaluating on the training split.
I0302 23:58:46.491062 140077943854912 spec.py:333] Evaluating on the validation split.
I0302 23:59:16.406473 140077943854912 spec.py:349] Evaluating on the test split.
I0302 23:59:17.987034 140077943854912 submission_runner.py:411] Time since start: 46350.79s, 	Step: 97752, 	{'train/accuracy': 0.7708593606948853, 'train/loss': 0.9360008239746094, 'validation/accuracy': 0.6833399534225464, 'validation/loss': 1.3163715600967407, 'validation/num_examples': 50000, 'test/accuracy': 0.5525000095367432, 'test/loss': 1.9546915292739868, 'test/num_examples': 10000, 'score': 42897.07012176514, 'total_duration': 46350.79205417633, 'accumulated_submission_time': 42897.07012176514, 'accumulated_eval_time': 3444.739847421646, 'accumulated_logging_time': 3.8551173210144043}
I0302 23:59:18.020231 139881808373504 logging_writer.py:48] [97752] accumulated_eval_time=3444.739847, accumulated_logging_time=3.855117, accumulated_submission_time=42897.070122, global_step=97752, preemption_count=0, score=42897.070122, test/accuracy=0.552500, test/loss=1.954692, test/num_examples=10000, total_duration=46350.792054, train/accuracy=0.770859, train/loss=0.936001, validation/accuracy=0.683340, validation/loss=1.316372, validation/num_examples=50000
I0302 23:59:37.134379 139881799980800 logging_writer.py:48] [97800] global_step=97800, grad_norm=1.4595235586166382, loss=4.3274736404418945
I0303 00:00:19.897717 139881808373504 logging_writer.py:48] [97900] global_step=97900, grad_norm=1.2313506603240967, loss=3.023912191390991
I0303 00:01:04.836159 139881799980800 logging_writer.py:48] [98000] global_step=98000, grad_norm=1.4013570547103882, loss=3.0673816204071045
I0303 00:01:49.494837 139881808373504 logging_writer.py:48] [98100] global_step=98100, grad_norm=1.5292400121688843, loss=2.074749231338501
I0303 00:02:34.075396 139881799980800 logging_writer.py:48] [98200] global_step=98200, grad_norm=1.6570342779159546, loss=2.026700735092163
I0303 00:03:18.803401 139881808373504 logging_writer.py:48] [98300] global_step=98300, grad_norm=1.412197232246399, loss=2.433293342590332
I0303 00:04:03.101268 139881799980800 logging_writer.py:48] [98400] global_step=98400, grad_norm=1.3405916690826416, loss=2.350714683532715
I0303 00:04:47.258050 139881808373504 logging_writer.py:48] [98500] global_step=98500, grad_norm=1.3553987741470337, loss=3.7837400436401367
I0303 00:05:31.566636 139881799980800 logging_writer.py:48] [98600] global_step=98600, grad_norm=1.339727520942688, loss=3.386211395263672
I0303 00:06:15.755301 139881808373504 logging_writer.py:48] [98700] global_step=98700, grad_norm=1.4603837728500366, loss=4.1811723709106445
I0303 00:06:18.073188 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:06:28.121169 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 00:06:51.595123 140077943854912 spec.py:349] Evaluating on the test split.
I0303 00:06:53.173860 140077943854912 submission_runner.py:411] Time since start: 46805.98s, 	Step: 98707, 	{'train/accuracy': 0.7409374713897705, 'train/loss': 1.0260651111602783, 'validation/accuracy': 0.6859999895095825, 'validation/loss': 1.2778408527374268, 'validation/num_examples': 50000, 'test/accuracy': 0.5577000379562378, 'test/loss': 1.93332839012146, 'test/num_examples': 10000, 'score': 43317.06185436249, 'total_duration': 46805.97884583473, 'accumulated_submission_time': 43317.06185436249, 'accumulated_eval_time': 3479.8404698371887, 'accumulated_logging_time': 3.900003433227539}
I0303 00:06:53.206258 139881799980800 logging_writer.py:48] [98707] accumulated_eval_time=3479.840470, accumulated_logging_time=3.900003, accumulated_submission_time=43317.061854, global_step=98707, preemption_count=0, score=43317.061854, test/accuracy=0.557700, test/loss=1.933328, test/num_examples=10000, total_duration=46805.978846, train/accuracy=0.740937, train/loss=1.026065, validation/accuracy=0.686000, validation/loss=1.277841, validation/num_examples=50000
I0303 00:07:30.343180 139881808373504 logging_writer.py:48] [98800] global_step=98800, grad_norm=1.279931902885437, loss=3.862557888031006
I0303 00:08:14.842307 139881799980800 logging_writer.py:48] [98900] global_step=98900, grad_norm=1.4989454746246338, loss=1.9713236093521118
I0303 00:08:59.289457 139881808373504 logging_writer.py:48] [99000] global_step=99000, grad_norm=1.517816185951233, loss=1.9726471900939941
I0303 00:09:43.825134 139881799980800 logging_writer.py:48] [99100] global_step=99100, grad_norm=1.5289536714553833, loss=2.7393994331359863
I0303 00:10:28.419586 139881808373504 logging_writer.py:48] [99200] global_step=99200, grad_norm=1.5196990966796875, loss=1.8244071006774902
I0303 00:11:12.773613 139881799980800 logging_writer.py:48] [99300] global_step=99300, grad_norm=1.3593064546585083, loss=1.9430736303329468
I0303 00:11:56.876270 139881808373504 logging_writer.py:48] [99400] global_step=99400, grad_norm=1.3588182926177979, loss=4.0098419189453125
I0303 00:12:41.426889 139881799980800 logging_writer.py:48] [99500] global_step=99500, grad_norm=1.5094605684280396, loss=2.047083616256714
I0303 00:13:25.798552 139881808373504 logging_writer.py:48] [99600] global_step=99600, grad_norm=1.4290162324905396, loss=1.9647859334945679
I0303 00:13:53.260081 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:14:03.540699 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 00:14:27.897923 140077943854912 spec.py:349] Evaluating on the test split.
I0303 00:14:29.476141 140077943854912 submission_runner.py:411] Time since start: 47262.28s, 	Step: 99664, 	{'train/accuracy': 0.7491015195846558, 'train/loss': 0.9865267872810364, 'validation/accuracy': 0.6865599751472473, 'validation/loss': 1.276195764541626, 'validation/num_examples': 50000, 'test/accuracy': 0.5599000453948975, 'test/loss': 1.931175708770752, 'test/num_examples': 10000, 'score': 43737.05564260483, 'total_duration': 47262.28113818169, 'accumulated_submission_time': 43737.05564260483, 'accumulated_eval_time': 3516.056496620178, 'accumulated_logging_time': 3.943291664123535}
I0303 00:14:29.510468 139881799980800 logging_writer.py:48] [99664] accumulated_eval_time=3516.056497, accumulated_logging_time=3.943292, accumulated_submission_time=43737.055643, global_step=99664, preemption_count=0, score=43737.055643, test/accuracy=0.559900, test/loss=1.931176, test/num_examples=10000, total_duration=47262.281138, train/accuracy=0.749102, train/loss=0.986527, validation/accuracy=0.686560, validation/loss=1.276196, validation/num_examples=50000
I0303 00:14:43.944147 139881808373504 logging_writer.py:48] [99700] global_step=99700, grad_norm=1.6275811195373535, loss=4.356719493865967
I0303 00:15:25.649583 139881799980800 logging_writer.py:48] [99800] global_step=99800, grad_norm=1.374825119972229, loss=2.6405413150787354
I0303 00:16:10.310221 139881808373504 logging_writer.py:48] [99900] global_step=99900, grad_norm=1.6089569330215454, loss=2.0568342208862305
I0303 00:16:55.043978 139881799980800 logging_writer.py:48] [100000] global_step=100000, grad_norm=1.5166749954223633, loss=1.837566614151001
I0303 00:17:39.459463 139881808373504 logging_writer.py:48] [100100] global_step=100100, grad_norm=1.5074222087860107, loss=2.1898717880249023
I0303 00:18:23.635795 139881799980800 logging_writer.py:48] [100200] global_step=100200, grad_norm=1.4961789846420288, loss=1.9007177352905273
I0303 00:19:07.816632 139881808373504 logging_writer.py:48] [100300] global_step=100300, grad_norm=1.3378859758377075, loss=3.1336073875427246
I0303 00:19:51.913207 139881799980800 logging_writer.py:48] [100400] global_step=100400, grad_norm=1.5269619226455688, loss=2.7515928745269775
I0303 00:20:36.184226 139881808373504 logging_writer.py:48] [100500] global_step=100500, grad_norm=1.545762062072754, loss=1.9587719440460205
I0303 00:21:20.372773 139881799980800 logging_writer.py:48] [100600] global_step=100600, grad_norm=1.3513696193695068, loss=3.1512420177459717
I0303 00:21:29.791078 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:21:40.110928 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 00:22:03.498127 140077943854912 spec.py:349] Evaluating on the test split.
I0303 00:22:05.080933 140077943854912 submission_runner.py:411] Time since start: 47717.89s, 	Step: 100623, 	{'train/accuracy': 0.7603319883346558, 'train/loss': 0.9452508091926575, 'validation/accuracy': 0.6875, 'validation/loss': 1.2674585580825806, 'validation/num_examples': 50000, 'test/accuracy': 0.5639000535011292, 'test/loss': 1.9013869762420654, 'test/num_examples': 10000, 'score': 44157.274961948395, 'total_duration': 47717.88592863083, 'accumulated_submission_time': 44157.274961948395, 'accumulated_eval_time': 3551.346296310425, 'accumulated_logging_time': 3.98929500579834}
I0303 00:22:05.120775 139881808373504 logging_writer.py:48] [100623] accumulated_eval_time=3551.346296, accumulated_logging_time=3.989295, accumulated_submission_time=44157.274962, global_step=100623, preemption_count=0, score=44157.274962, test/accuracy=0.563900, test/loss=1.901387, test/num_examples=10000, total_duration=47717.885929, train/accuracy=0.760332, train/loss=0.945251, validation/accuracy=0.687500, validation/loss=1.267459, validation/num_examples=50000
I0303 00:22:35.567007 139881799980800 logging_writer.py:48] [100700] global_step=100700, grad_norm=1.4140211343765259, loss=2.4988861083984375
I0303 00:23:19.066429 139881808373504 logging_writer.py:48] [100800] global_step=100800, grad_norm=1.3883496522903442, loss=3.114849328994751
I0303 00:24:03.246360 139881799980800 logging_writer.py:48] [100900] global_step=100900, grad_norm=1.410900592803955, loss=2.9554007053375244
I0303 00:24:47.227887 139881808373504 logging_writer.py:48] [101000] global_step=101000, grad_norm=1.402566909790039, loss=3.610856294631958
I0303 00:25:31.744038 139881799980800 logging_writer.py:48] [101100] global_step=101100, grad_norm=1.3625352382659912, loss=2.431474447250366
I0303 00:26:15.674262 139881808373504 logging_writer.py:48] [101200] global_step=101200, grad_norm=1.5332187414169312, loss=1.9325535297393799
I0303 00:26:59.920385 139881799980800 logging_writer.py:48] [101300] global_step=101300, grad_norm=1.5378628969192505, loss=2.0246260166168213
I0303 00:27:44.500381 139881808373504 logging_writer.py:48] [101400] global_step=101400, grad_norm=1.440266728401184, loss=1.9780166149139404
I0303 00:28:28.464888 139881799980800 logging_writer.py:48] [101500] global_step=101500, grad_norm=1.3447221517562866, loss=2.9935379028320312
I0303 00:29:05.245251 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:29:15.466795 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 00:29:39.873378 140077943854912 spec.py:349] Evaluating on the test split.
I0303 00:29:41.452512 140077943854912 submission_runner.py:411] Time since start: 48174.26s, 	Step: 101584, 	{'train/accuracy': 0.7491992115974426, 'train/loss': 1.0066653490066528, 'validation/accuracy': 0.6896399855613708, 'validation/loss': 1.2784479856491089, 'validation/num_examples': 50000, 'test/accuracy': 0.562000036239624, 'test/loss': 1.9139764308929443, 'test/num_examples': 10000, 'score': 44577.33863568306, 'total_duration': 48174.25753450394, 'accumulated_submission_time': 44577.33863568306, 'accumulated_eval_time': 3587.5535452365875, 'accumulated_logging_time': 4.040088415145874}
I0303 00:29:41.492494 139881808373504 logging_writer.py:48] [101584] accumulated_eval_time=3587.553545, accumulated_logging_time=4.040088, accumulated_submission_time=44577.338636, global_step=101584, preemption_count=0, score=44577.338636, test/accuracy=0.562000, test/loss=1.913976, test/num_examples=10000, total_duration=48174.257535, train/accuracy=0.749199, train/loss=1.006665, validation/accuracy=0.689640, validation/loss=1.278448, validation/num_examples=50000
I0303 00:29:48.117586 139881799980800 logging_writer.py:48] [101600] global_step=101600, grad_norm=1.3530486822128296, loss=2.5062811374664307
I0303 00:30:28.973685 139881808373504 logging_writer.py:48] [101700] global_step=101700, grad_norm=1.524549126625061, loss=2.7447011470794678
I0303 00:31:13.367197 139881799980800 logging_writer.py:48] [101800] global_step=101800, grad_norm=1.4125924110412598, loss=3.565047025680542
I0303 00:31:57.590076 139881808373504 logging_writer.py:48] [101900] global_step=101900, grad_norm=1.4495792388916016, loss=3.1887404918670654
I0303 00:32:42.069915 139881799980800 logging_writer.py:48] [102000] global_step=102000, grad_norm=1.4573811292648315, loss=2.14471435546875
I0303 00:33:26.634581 139881808373504 logging_writer.py:48] [102100] global_step=102100, grad_norm=1.3213680982589722, loss=4.4444074630737305
I0303 00:34:10.870519 139881799980800 logging_writer.py:48] [102200] global_step=102200, grad_norm=1.5644041299819946, loss=1.8876628875732422
I0303 00:34:55.081873 139881808373504 logging_writer.py:48] [102300] global_step=102300, grad_norm=1.4539856910705566, loss=4.0728325843811035
I0303 00:35:39.556587 139881799980800 logging_writer.py:48] [102400] global_step=102400, grad_norm=1.5103378295898438, loss=2.4426095485687256
I0303 00:36:24.273648 139881808373504 logging_writer.py:48] [102500] global_step=102500, grad_norm=1.7851276397705078, loss=1.9376404285430908
I0303 00:36:41.479356 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:36:51.834391 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 00:37:12.096163 140077943854912 spec.py:349] Evaluating on the test split.
I0303 00:37:13.703588 140077943854912 submission_runner.py:411] Time since start: 48626.51s, 	Step: 102541, 	{'train/accuracy': 0.7575390338897705, 'train/loss': 0.9742467999458313, 'validation/accuracy': 0.694920003414154, 'validation/loss': 1.2482126951217651, 'validation/num_examples': 50000, 'test/accuracy': 0.5687000155448914, 'test/loss': 1.8900020122528076, 'test/num_examples': 10000, 'score': 44997.26434326172, 'total_duration': 48626.508607149124, 'accumulated_submission_time': 44997.26434326172, 'accumulated_eval_time': 3619.7777602672577, 'accumulated_logging_time': 4.091718912124634}
I0303 00:37:13.737894 139881799980800 logging_writer.py:48] [102541] accumulated_eval_time=3619.777760, accumulated_logging_time=4.091719, accumulated_submission_time=44997.264343, global_step=102541, preemption_count=0, score=44997.264343, test/accuracy=0.568700, test/loss=1.890002, test/num_examples=10000, total_duration=48626.508607, train/accuracy=0.757539, train/loss=0.974247, validation/accuracy=0.694920, validation/loss=1.248213, validation/num_examples=50000
I0303 00:37:37.145985 139881808373504 logging_writer.py:48] [102600] global_step=102600, grad_norm=1.4974052906036377, loss=1.9677084684371948
I0303 00:38:20.232910 139881799980800 logging_writer.py:48] [102700] global_step=102700, grad_norm=1.4826160669326782, loss=1.8169645071029663
I0303 00:39:04.735191 139881808373504 logging_writer.py:48] [102800] global_step=102800, grad_norm=1.4011036157608032, loss=4.3018012046813965
I0303 00:39:49.133593 139881799980800 logging_writer.py:48] [102900] global_step=102900, grad_norm=1.4283548593521118, loss=3.898123025894165
I0303 00:40:33.446046 139881808373504 logging_writer.py:48] [103000] global_step=103000, grad_norm=1.4573612213134766, loss=2.500171422958374
I0303 00:41:17.865005 139881799980800 logging_writer.py:48] [103100] global_step=103100, grad_norm=1.444227695465088, loss=2.0303335189819336
I0303 00:42:01.637742 139881808373504 logging_writer.py:48] [103200] global_step=103200, grad_norm=1.5165736675262451, loss=2.016517400741577
I0303 00:42:46.089138 139881799980800 logging_writer.py:48] [103300] global_step=103300, grad_norm=1.8840168714523315, loss=1.9710328578948975
I0303 00:43:30.365505 139881808373504 logging_writer.py:48] [103400] global_step=103400, grad_norm=1.5214767456054688, loss=2.102418899536133
I0303 00:44:13.893185 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:44:23.865296 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 00:44:48.589624 140077943854912 spec.py:349] Evaluating on the test split.
I0303 00:44:50.178618 140077943854912 submission_runner.py:411] Time since start: 49082.98s, 	Step: 103500, 	{'train/accuracy': 0.7555859088897705, 'train/loss': 0.9570018649101257, 'validation/accuracy': 0.6918999552726746, 'validation/loss': 1.2508394718170166, 'validation/num_examples': 50000, 'test/accuracy': 0.563800036907196, 'test/loss': 1.9133514165878296, 'test/num_examples': 10000, 'score': 45417.35946679115, 'total_duration': 49082.983598947525, 'accumulated_submission_time': 45417.35946679115, 'accumulated_eval_time': 3656.0631535053253, 'accumulated_logging_time': 4.135879993438721}
I0303 00:44:50.214788 139881799980800 logging_writer.py:48] [103500] accumulated_eval_time=3656.063154, accumulated_logging_time=4.135880, accumulated_submission_time=45417.359467, global_step=103500, preemption_count=0, score=45417.359467, test/accuracy=0.563800, test/loss=1.913351, test/num_examples=10000, total_duration=49082.983599, train/accuracy=0.755586, train/loss=0.957002, validation/accuracy=0.691900, validation/loss=1.250839, validation/num_examples=50000
I0303 00:44:50.608844 139881808373504 logging_writer.py:48] [103500] global_step=103500, grad_norm=1.4537713527679443, loss=3.809372663497925
I0303 00:45:30.594229 139881799980800 logging_writer.py:48] [103600] global_step=103600, grad_norm=1.5490251779556274, loss=1.8573788404464722
I0303 00:46:14.686953 139881808373504 logging_writer.py:48] [103700] global_step=103700, grad_norm=1.358191967010498, loss=2.7638041973114014
I0303 00:46:58.996969 139881799980800 logging_writer.py:48] [103800] global_step=103800, grad_norm=1.598291277885437, loss=1.8033456802368164
I0303 00:47:43.671427 139881808373504 logging_writer.py:48] [103900] global_step=103900, grad_norm=1.432742953300476, loss=2.3152847290039062
I0303 00:48:27.620684 139881799980800 logging_writer.py:48] [104000] global_step=104000, grad_norm=1.4372854232788086, loss=2.609226942062378
I0303 00:49:12.047266 139881808373504 logging_writer.py:48] [104100] global_step=104100, grad_norm=1.4988633394241333, loss=2.080796241760254
I0303 00:49:56.347929 139881799980800 logging_writer.py:48] [104200] global_step=104200, grad_norm=1.4639467000961304, loss=2.2222900390625
I0303 00:50:40.363988 139881808373504 logging_writer.py:48] [104300] global_step=104300, grad_norm=1.5423331260681152, loss=2.0859897136688232
I0303 00:51:24.740822 139881799980800 logging_writer.py:48] [104400] global_step=104400, grad_norm=1.69705331325531, loss=1.8346587419509888
I0303 00:51:50.442128 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:52:00.738350 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 00:52:24.868924 140077943854912 spec.py:349] Evaluating on the test split.
I0303 00:52:26.455446 140077943854912 submission_runner.py:411] Time since start: 49539.26s, 	Step: 104460, 	{'train/accuracy': 0.7704687118530273, 'train/loss': 0.9185051321983337, 'validation/accuracy': 0.6934799551963806, 'validation/loss': 1.2655454874038696, 'validation/num_examples': 50000, 'test/accuracy': 0.5600000023841858, 'test/loss': 1.9212124347686768, 'test/num_examples': 10000, 'score': 45837.52560162544, 'total_duration': 49539.26046657562, 'accumulated_submission_time': 45837.52560162544, 'accumulated_eval_time': 3692.0764961242676, 'accumulated_logging_time': 4.183363676071167}
I0303 00:52:26.490354 139881808373504 logging_writer.py:48] [104460] accumulated_eval_time=3692.076496, accumulated_logging_time=4.183364, accumulated_submission_time=45837.525602, global_step=104460, preemption_count=0, score=45837.525602, test/accuracy=0.560000, test/loss=1.921212, test/num_examples=10000, total_duration=49539.260467, train/accuracy=0.770469, train/loss=0.918505, validation/accuracy=0.693480, validation/loss=1.265545, validation/num_examples=50000
I0303 00:52:42.723013 139881799980800 logging_writer.py:48] [104500] global_step=104500, grad_norm=1.5851539373397827, loss=2.179537773132324
I0303 00:53:24.158240 139881808373504 logging_writer.py:48] [104600] global_step=104600, grad_norm=1.5304396152496338, loss=3.424746513366699
I0303 00:54:08.346563 139881799980800 logging_writer.py:48] [104700] global_step=104700, grad_norm=1.4795342683792114, loss=4.205735206604004
I0303 00:54:52.646070 139881808373504 logging_writer.py:48] [104800] global_step=104800, grad_norm=1.4076342582702637, loss=2.800812244415283
I0303 00:55:36.919094 139881799980800 logging_writer.py:48] [104900] global_step=104900, grad_norm=1.6112756729125977, loss=2.250842332839966
I0303 00:56:20.983409 139881808373504 logging_writer.py:48] [105000] global_step=105000, grad_norm=1.5226894617080688, loss=3.5792789459228516
I0303 00:57:05.623526 139881799980800 logging_writer.py:48] [105100] global_step=105100, grad_norm=1.5777232646942139, loss=1.9174269437789917
I0303 00:57:49.718945 139881808373504 logging_writer.py:48] [105200] global_step=105200, grad_norm=1.5303733348846436, loss=2.0120697021484375
I0303 00:58:33.958560 139881799980800 logging_writer.py:48] [105300] global_step=105300, grad_norm=1.3613734245300293, loss=3.8274388313293457
I0303 00:59:18.170297 139881808373504 logging_writer.py:48] [105400] global_step=105400, grad_norm=1.4863090515136719, loss=1.7633475065231323
I0303 00:59:26.757833 140077943854912 spec.py:321] Evaluating on the training split.
I0303 00:59:37.190171 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:00:00.976460 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:00:02.575031 140077943854912 submission_runner.py:411] Time since start: 49995.38s, 	Step: 105421, 	{'train/accuracy': 0.7509570121765137, 'train/loss': 0.986622154712677, 'validation/accuracy': 0.6902799606323242, 'validation/loss': 1.2532689571380615, 'validation/num_examples': 50000, 'test/accuracy': 0.5672000050544739, 'test/loss': 1.8987038135528564, 'test/num_examples': 10000, 'score': 46257.731426239014, 'total_duration': 49995.38002538681, 'accumulated_submission_time': 46257.731426239014, 'accumulated_eval_time': 3727.893661260605, 'accumulated_logging_time': 4.22884464263916}
I0303 01:00:02.615760 139881799980800 logging_writer.py:48] [105421] accumulated_eval_time=3727.893661, accumulated_logging_time=4.228845, accumulated_submission_time=46257.731426, global_step=105421, preemption_count=0, score=46257.731426, test/accuracy=0.567200, test/loss=1.898704, test/num_examples=10000, total_duration=49995.380025, train/accuracy=0.750957, train/loss=0.986622, validation/accuracy=0.690280, validation/loss=1.253269, validation/num_examples=50000
I0303 01:00:33.914801 139881808373504 logging_writer.py:48] [105500] global_step=105500, grad_norm=1.404679775238037, loss=4.279130458831787
I0303 01:01:18.064497 139881799980800 logging_writer.py:48] [105600] global_step=105600, grad_norm=1.594110131263733, loss=1.7279317378997803
I0303 01:02:02.511862 139881808373504 logging_writer.py:48] [105700] global_step=105700, grad_norm=1.5890027284622192, loss=2.0027220249176025
I0303 01:02:46.602826 139881799980800 logging_writer.py:48] [105800] global_step=105800, grad_norm=1.523247480392456, loss=1.9113314151763916
I0303 01:03:31.026053 139881808373504 logging_writer.py:48] [105900] global_step=105900, grad_norm=1.48429274559021, loss=2.095144748687744
I0303 01:04:15.072966 139881799980800 logging_writer.py:48] [106000] global_step=106000, grad_norm=1.493887186050415, loss=1.7338478565216064
I0303 01:04:59.058869 139881808373504 logging_writer.py:48] [106100] global_step=106100, grad_norm=1.4746816158294678, loss=4.08132266998291
I0303 01:05:43.334141 139881799980800 logging_writer.py:48] [106200] global_step=106200, grad_norm=1.480246901512146, loss=2.0292294025421143
I0303 01:06:27.712938 139881808373504 logging_writer.py:48] [106300] global_step=106300, grad_norm=1.649841070175171, loss=1.9579782485961914
I0303 01:07:02.611381 140077943854912 spec.py:321] Evaluating on the training split.
I0303 01:07:12.652540 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:07:46.626331 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:07:48.220318 140077943854912 submission_runner.py:411] Time since start: 50461.03s, 	Step: 106380, 	{'train/accuracy': 0.7627343535423279, 'train/loss': 0.9351568222045898, 'validation/accuracy': 0.6969799995422363, 'validation/loss': 1.2286380529403687, 'validation/num_examples': 50000, 'test/accuracy': 0.5681000351905823, 'test/loss': 1.871907353401184, 'test/num_examples': 10000, 'score': 46677.664197683334, 'total_duration': 50461.02531313896, 'accumulated_submission_time': 46677.664197683334, 'accumulated_eval_time': 3773.5025522708893, 'accumulated_logging_time': 4.281575441360474}
I0303 01:07:48.255607 139881799980800 logging_writer.py:48] [106380] accumulated_eval_time=3773.502552, accumulated_logging_time=4.281575, accumulated_submission_time=46677.664198, global_step=106380, preemption_count=0, score=46677.664198, test/accuracy=0.568100, test/loss=1.871907, test/num_examples=10000, total_duration=50461.025313, train/accuracy=0.762734, train/loss=0.935157, validation/accuracy=0.696980, validation/loss=1.228638, validation/num_examples=50000
I0303 01:07:56.446507 139881808373504 logging_writer.py:48] [106400] global_step=106400, grad_norm=1.3833651542663574, loss=3.642092227935791
I0303 01:08:37.444716 139881799980800 logging_writer.py:48] [106500] global_step=106500, grad_norm=1.5841407775878906, loss=1.8601170778274536
I0303 01:09:22.258756 139881808373504 logging_writer.py:48] [106600] global_step=106600, grad_norm=1.6294445991516113, loss=1.9187291860580444
I0303 01:10:06.823502 139881799980800 logging_writer.py:48] [106700] global_step=106700, grad_norm=1.5807485580444336, loss=1.8012194633483887
I0303 01:10:51.182661 139881808373504 logging_writer.py:48] [106800] global_step=106800, grad_norm=1.562447428703308, loss=2.098130226135254
I0303 01:11:35.790271 139881799980800 logging_writer.py:48] [106900] global_step=106900, grad_norm=1.6383004188537598, loss=1.9185528755187988
I0303 01:12:20.067364 139881808373504 logging_writer.py:48] [107000] global_step=107000, grad_norm=1.4073976278305054, loss=3.117166757583618
I0303 01:13:04.504467 139881799980800 logging_writer.py:48] [107100] global_step=107100, grad_norm=1.7039226293563843, loss=1.8854323625564575
I0303 01:13:48.697959 139881808373504 logging_writer.py:48] [107200] global_step=107200, grad_norm=1.5931472778320312, loss=2.0736117362976074
I0303 01:14:33.168505 139881799980800 logging_writer.py:48] [107300] global_step=107300, grad_norm=1.4056960344314575, loss=2.917078733444214
I0303 01:14:48.515255 140077943854912 spec.py:321] Evaluating on the training split.
I0303 01:14:58.632645 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:15:25.906367 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:15:27.501518 140077943854912 submission_runner.py:411] Time since start: 50920.31s, 	Step: 107336, 	{'train/accuracy': 0.7720312476158142, 'train/loss': 0.901677131652832, 'validation/accuracy': 0.6996600031852722, 'validation/loss': 1.2177472114562988, 'validation/num_examples': 50000, 'test/accuracy': 0.5746000409126282, 'test/loss': 1.867994785308838, 'test/num_examples': 10000, 'score': 47097.86094522476, 'total_duration': 50920.306520462036, 'accumulated_submission_time': 47097.86094522476, 'accumulated_eval_time': 3812.488776922226, 'accumulated_logging_time': 4.329556226730347}
I0303 01:15:27.540112 139881808373504 logging_writer.py:48] [107336] accumulated_eval_time=3812.488777, accumulated_logging_time=4.329556, accumulated_submission_time=47097.860945, global_step=107336, preemption_count=0, score=47097.860945, test/accuracy=0.574600, test/loss=1.867995, test/num_examples=10000, total_duration=50920.306520, train/accuracy=0.772031, train/loss=0.901677, validation/accuracy=0.699660, validation/loss=1.217747, validation/num_examples=50000
I0303 01:15:52.916796 139881799980800 logging_writer.py:48] [107400] global_step=107400, grad_norm=1.835801362991333, loss=1.9313963651657104
I0303 01:16:36.480291 139881808373504 logging_writer.py:48] [107500] global_step=107500, grad_norm=1.6680032014846802, loss=1.9927072525024414
I0303 01:17:21.067251 139881799980800 logging_writer.py:48] [107600] global_step=107600, grad_norm=1.4989358186721802, loss=3.1598458290100098
I0303 01:18:06.012860 139881808373504 logging_writer.py:48] [107700] global_step=107700, grad_norm=1.4846993684768677, loss=2.154458999633789
I0303 01:18:50.185594 139881799980800 logging_writer.py:48] [107800] global_step=107800, grad_norm=1.6121163368225098, loss=1.8728073835372925
I0303 01:19:34.581200 139881808373504 logging_writer.py:48] [107900] global_step=107900, grad_norm=1.498081088066101, loss=1.9705668687820435
I0303 01:20:18.989299 139881799980800 logging_writer.py:48] [108000] global_step=108000, grad_norm=1.6617180109024048, loss=1.7867094278335571
I0303 01:21:03.564707 139881808373504 logging_writer.py:48] [108100] global_step=108100, grad_norm=1.5014830827713013, loss=3.269286632537842
I0303 01:21:48.114408 139881799980800 logging_writer.py:48] [108200] global_step=108200, grad_norm=1.586251974105835, loss=4.3681135177612305
I0303 01:22:27.898542 140077943854912 spec.py:321] Evaluating on the training split.
I0303 01:22:38.198931 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:23:10.732134 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:23:12.313544 140077943854912 submission_runner.py:411] Time since start: 51385.12s, 	Step: 108291, 	{'train/accuracy': 0.7859960794448853, 'train/loss': 0.8419576287269592, 'validation/accuracy': 0.6972599625587463, 'validation/loss': 1.2124354839324951, 'validation/num_examples': 50000, 'test/accuracy': 0.5742000341415405, 'test/loss': 1.8423296213150024, 'test/num_examples': 10000, 'score': 47518.158441782, 'total_duration': 51385.118559122086, 'accumulated_submission_time': 47518.158441782, 'accumulated_eval_time': 3856.9037647247314, 'accumulated_logging_time': 4.379816055297852}
I0303 01:23:12.347103 139881808373504 logging_writer.py:48] [108291] accumulated_eval_time=3856.903765, accumulated_logging_time=4.379816, accumulated_submission_time=47518.158442, global_step=108291, preemption_count=0, score=47518.158442, test/accuracy=0.574200, test/loss=1.842330, test/num_examples=10000, total_duration=51385.118559, train/accuracy=0.785996, train/loss=0.841958, validation/accuracy=0.697260, validation/loss=1.212435, validation/num_examples=50000
I0303 01:23:16.245820 139881799980800 logging_writer.py:48] [108300] global_step=108300, grad_norm=1.5422660112380981, loss=4.219735622406006
I0303 01:23:56.910215 139881808373504 logging_writer.py:48] [108400] global_step=108400, grad_norm=1.5668971538543701, loss=3.2609498500823975
I0303 01:24:41.252341 139881799980800 logging_writer.py:48] [108500] global_step=108500, grad_norm=1.6052939891815186, loss=1.878566026687622
I0303 01:25:26.065053 139881808373504 logging_writer.py:48] [108600] global_step=108600, grad_norm=1.4772952795028687, loss=4.3558783531188965
I0303 01:26:10.514080 139881799980800 logging_writer.py:48] [108700] global_step=108700, grad_norm=1.5111950635910034, loss=3.202589988708496
I0303 01:26:54.978368 139881808373504 logging_writer.py:48] [108800] global_step=108800, grad_norm=1.4514715671539307, loss=3.3606905937194824
I0303 01:27:39.714501 139881799980800 logging_writer.py:48] [108900] global_step=108900, grad_norm=1.6252169609069824, loss=1.9654954671859741
I0303 01:28:23.977824 139881808373504 logging_writer.py:48] [109000] global_step=109000, grad_norm=1.644298791885376, loss=1.8745222091674805
I0303 01:29:08.408935 139881799980800 logging_writer.py:48] [109100] global_step=109100, grad_norm=1.446857213973999, loss=3.5525200366973877
I0303 01:29:52.710342 139881808373504 logging_writer.py:48] [109200] global_step=109200, grad_norm=1.4356141090393066, loss=3.5954625606536865
I0303 01:30:12.495097 140077943854912 spec.py:321] Evaluating on the training split.
I0303 01:30:22.684644 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:30:55.028093 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:30:56.612186 140077943854912 submission_runner.py:411] Time since start: 51849.42s, 	Step: 109246, 	{'train/accuracy': 0.7622460722923279, 'train/loss': 0.9467803835868835, 'validation/accuracy': 0.6993599534034729, 'validation/loss': 1.227556586265564, 'validation/num_examples': 50000, 'test/accuracy': 0.5749000310897827, 'test/loss': 1.8697477579116821, 'test/num_examples': 10000, 'score': 47938.24389958382, 'total_duration': 51849.41720533371, 'accumulated_submission_time': 47938.24389958382, 'accumulated_eval_time': 3901.020851612091, 'accumulated_logging_time': 4.426162004470825}
I0303 01:30:56.648771 139881799980800 logging_writer.py:48] [109246] accumulated_eval_time=3901.020852, accumulated_logging_time=4.426162, accumulated_submission_time=47938.243900, global_step=109246, preemption_count=0, score=47938.243900, test/accuracy=0.574900, test/loss=1.869748, test/num_examples=10000, total_duration=51849.417205, train/accuracy=0.762246, train/loss=0.946780, validation/accuracy=0.699360, validation/loss=1.227557, validation/num_examples=50000
I0303 01:31:18.113444 139881808373504 logging_writer.py:48] [109300] global_step=109300, grad_norm=1.7059553861618042, loss=1.8269331455230713
I0303 01:32:01.022862 139881799980800 logging_writer.py:48] [109400] global_step=109400, grad_norm=1.7380921840667725, loss=1.7585811614990234
I0303 01:32:45.893060 139881808373504 logging_writer.py:48] [109500] global_step=109500, grad_norm=1.5803707838058472, loss=1.8351852893829346
I0303 01:33:30.455523 139881799980800 logging_writer.py:48] [109600] global_step=109600, grad_norm=1.5556546449661255, loss=1.949229121208191
I0303 01:34:14.677990 139881808373504 logging_writer.py:48] [109700] global_step=109700, grad_norm=1.4246348142623901, loss=1.8690135478973389
I0303 01:34:59.101421 139881799980800 logging_writer.py:48] [109800] global_step=109800, grad_norm=1.7928978204727173, loss=1.8567970991134644
I0303 01:35:43.465325 139881808373504 logging_writer.py:48] [109900] global_step=109900, grad_norm=1.6793380975723267, loss=1.957927942276001
I0303 01:36:27.979088 139881799980800 logging_writer.py:48] [110000] global_step=110000, grad_norm=1.7201001644134521, loss=1.7065448760986328
I0303 01:37:12.560142 139881808373504 logging_writer.py:48] [110100] global_step=110100, grad_norm=1.7228375673294067, loss=1.8752092123031616
I0303 01:37:56.857223 139881799980800 logging_writer.py:48] [110200] global_step=110200, grad_norm=1.5953246355056763, loss=2.231229066848755
I0303 01:37:56.871659 140077943854912 spec.py:321] Evaluating on the training split.
I0303 01:38:07.180775 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:38:36.561585 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:38:38.158841 140077943854912 submission_runner.py:411] Time since start: 52310.96s, 	Step: 110201, 	{'train/accuracy': 0.7684179544448853, 'train/loss': 0.9048970341682434, 'validation/accuracy': 0.7038999795913696, 'validation/loss': 1.196832299232483, 'validation/num_examples': 50000, 'test/accuracy': 0.5772000551223755, 'test/loss': 1.8481879234313965, 'test/num_examples': 10000, 'score': 48358.40622162819, 'total_duration': 52310.96383190155, 'accumulated_submission_time': 48358.40622162819, 'accumulated_eval_time': 3942.307982444763, 'accumulated_logging_time': 4.472722053527832}
I0303 01:38:38.197892 139881808373504 logging_writer.py:48] [110201] accumulated_eval_time=3942.307982, accumulated_logging_time=4.472722, accumulated_submission_time=48358.406222, global_step=110201, preemption_count=0, score=48358.406222, test/accuracy=0.577200, test/loss=1.848188, test/num_examples=10000, total_duration=52310.963832, train/accuracy=0.768418, train/loss=0.904897, validation/accuracy=0.703900, validation/loss=1.196832, validation/num_examples=50000
I0303 01:39:18.171402 139881799980800 logging_writer.py:48] [110300] global_step=110300, grad_norm=1.5103569030761719, loss=4.15495491027832
I0303 01:40:02.361598 139881808373504 logging_writer.py:48] [110400] global_step=110400, grad_norm=1.7709662914276123, loss=1.8778746128082275
I0303 01:40:46.871871 139881799980800 logging_writer.py:48] [110500] global_step=110500, grad_norm=1.5959142446517944, loss=1.865639090538025
I0303 01:41:31.409979 139881808373504 logging_writer.py:48] [110600] global_step=110600, grad_norm=1.420947551727295, loss=2.605417251586914
I0303 01:42:16.128035 139881799980800 logging_writer.py:48] [110700] global_step=110700, grad_norm=1.5906404256820679, loss=2.0685460567474365
I0303 01:43:00.457851 139881808373504 logging_writer.py:48] [110800] global_step=110800, grad_norm=1.6396677494049072, loss=2.084934949874878
I0303 01:43:44.643633 139881799980800 logging_writer.py:48] [110900] global_step=110900, grad_norm=1.5107719898223877, loss=2.2431252002716064
I0303 01:44:28.973410 139881808373504 logging_writer.py:48] [111000] global_step=111000, grad_norm=1.5505203008651733, loss=1.8284984827041626
I0303 01:45:13.516058 139881799980800 logging_writer.py:48] [111100] global_step=111100, grad_norm=1.6264592409133911, loss=1.8405158519744873
I0303 01:45:38.491220 140077943854912 spec.py:321] Evaluating on the training split.
I0303 01:45:48.832634 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:46:18.961932 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:46:20.556561 140077943854912 submission_runner.py:411] Time since start: 52773.36s, 	Step: 111158, 	{'train/accuracy': 0.7777343392372131, 'train/loss': 0.8578104972839355, 'validation/accuracy': 0.7034199833869934, 'validation/loss': 1.197596788406372, 'validation/num_examples': 50000, 'test/accuracy': 0.5800999999046326, 'test/loss': 1.8331900835037231, 'test/num_examples': 10000, 'score': 48778.63722419739, 'total_duration': 52773.361548900604, 'accumulated_submission_time': 48778.63722419739, 'accumulated_eval_time': 3984.3732771873474, 'accumulated_logging_time': 4.523653030395508}
I0303 01:46:20.594510 139881808373504 logging_writer.py:48] [111158] accumulated_eval_time=3984.373277, accumulated_logging_time=4.523653, accumulated_submission_time=48778.637224, global_step=111158, preemption_count=0, score=48778.637224, test/accuracy=0.580100, test/loss=1.833190, test/num_examples=10000, total_duration=52773.361549, train/accuracy=0.777734, train/loss=0.857810, validation/accuracy=0.703420, validation/loss=1.197597, validation/num_examples=50000
I0303 01:46:37.390335 139881799980800 logging_writer.py:48] [111200] global_step=111200, grad_norm=1.3920005559921265, loss=2.352212429046631
I0303 01:47:19.791436 139881808373504 logging_writer.py:48] [111300] global_step=111300, grad_norm=1.419718623161316, loss=2.652076244354248
I0303 01:48:04.229880 139881799980800 logging_writer.py:48] [111400] global_step=111400, grad_norm=1.7116574048995972, loss=4.286584854125977
I0303 01:48:48.575423 139881808373504 logging_writer.py:48] [111500] global_step=111500, grad_norm=1.6544629335403442, loss=1.7234644889831543
I0303 01:49:33.134278 139881799980800 logging_writer.py:48] [111600] global_step=111600, grad_norm=1.7760452032089233, loss=1.786060094833374
I0303 01:50:17.856196 139881808373504 logging_writer.py:48] [111700] global_step=111700, grad_norm=1.7357264757156372, loss=2.297427177429199
I0303 01:51:02.324238 139881799980800 logging_writer.py:48] [111800] global_step=111800, grad_norm=1.6678677797317505, loss=4.2720136642456055
I0303 01:51:46.671654 139881808373504 logging_writer.py:48] [111900] global_step=111900, grad_norm=1.7463573217391968, loss=1.9264662265777588
I0303 01:52:31.213550 139881799980800 logging_writer.py:48] [112000] global_step=112000, grad_norm=1.4925498962402344, loss=2.1893157958984375
I0303 01:53:15.825109 139881808373504 logging_writer.py:48] [112100] global_step=112100, grad_norm=1.72720205783844, loss=1.7684303522109985
I0303 01:53:20.823183 140077943854912 spec.py:321] Evaluating on the training split.
I0303 01:53:31.358162 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 01:53:59.223185 140077943854912 spec.py:349] Evaluating on the test split.
I0303 01:54:00.809114 140077943854912 submission_runner.py:411] Time since start: 53233.61s, 	Step: 112113, 	{'train/accuracy': 0.7675976157188416, 'train/loss': 0.9133527278900146, 'validation/accuracy': 0.7023599743843079, 'validation/loss': 1.210939884185791, 'validation/num_examples': 50000, 'test/accuracy': 0.5842000246047974, 'test/loss': 1.8372535705566406, 'test/num_examples': 10000, 'score': 49198.80200004578, 'total_duration': 53233.61412191391, 'accumulated_submission_time': 49198.80200004578, 'accumulated_eval_time': 4024.359180688858, 'accumulated_logging_time': 4.575310945510864}
I0303 01:54:00.851070 139881799980800 logging_writer.py:48] [112113] accumulated_eval_time=4024.359181, accumulated_logging_time=4.575311, accumulated_submission_time=49198.802000, global_step=112113, preemption_count=0, score=49198.802000, test/accuracy=0.584200, test/loss=1.837254, test/num_examples=10000, total_duration=53233.614122, train/accuracy=0.767598, train/loss=0.913353, validation/accuracy=0.702360, validation/loss=1.210940, validation/num_examples=50000
I0303 01:54:35.753859 139881808373504 logging_writer.py:48] [112200] global_step=112200, grad_norm=1.6065787076950073, loss=2.5818254947662354
I0303 01:55:19.911070 139881799980800 logging_writer.py:48] [112300] global_step=112300, grad_norm=1.715574860572815, loss=1.8825886249542236
I0303 01:56:04.750567 139881808373504 logging_writer.py:48] [112400] global_step=112400, grad_norm=1.69749116897583, loss=1.849364995956421
I0303 01:56:49.263622 139881799980800 logging_writer.py:48] [112500] global_step=112500, grad_norm=1.5723885297775269, loss=1.8328512907028198
I0303 01:57:33.713884 139881808373504 logging_writer.py:48] [112600] global_step=112600, grad_norm=1.700377106666565, loss=1.729296088218689
I0303 01:58:18.469885 139881799980800 logging_writer.py:48] [112700] global_step=112700, grad_norm=1.467273235321045, loss=3.2207326889038086
I0303 01:59:02.921018 139881808373504 logging_writer.py:48] [112800] global_step=112800, grad_norm=1.8726539611816406, loss=1.9384535551071167
I0303 01:59:47.146801 139881799980800 logging_writer.py:48] [112900] global_step=112900, grad_norm=1.6567169427871704, loss=1.7389246225357056
I0303 02:00:31.688420 139881808373504 logging_writer.py:48] [113000] global_step=113000, grad_norm=1.6962738037109375, loss=1.806105136871338
I0303 02:01:01.168865 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:01:11.830355 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:01:39.609169 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:01:41.201583 140077943854912 submission_runner.py:411] Time since start: 53694.01s, 	Step: 113068, 	{'train/accuracy': 0.76917964220047, 'train/loss': 0.9122159481048584, 'validation/accuracy': 0.703819990158081, 'validation/loss': 1.2008824348449707, 'validation/num_examples': 50000, 'test/accuracy': 0.5800000429153442, 'test/loss': 1.843191146850586, 'test/num_examples': 10000, 'score': 49619.058660030365, 'total_duration': 53694.006588459015, 'accumulated_submission_time': 49619.058660030365, 'accumulated_eval_time': 4064.391876220703, 'accumulated_logging_time': 4.628418207168579}
I0303 02:01:41.246227 139881799980800 logging_writer.py:48] [113068] accumulated_eval_time=4064.391876, accumulated_logging_time=4.628418, accumulated_submission_time=49619.058660, global_step=113068, preemption_count=0, score=49619.058660, test/accuracy=0.580000, test/loss=1.843191, test/num_examples=10000, total_duration=53694.006588, train/accuracy=0.769180, train/loss=0.912216, validation/accuracy=0.703820, validation/loss=1.200882, validation/num_examples=50000
I0303 02:01:54.148397 139881808373504 logging_writer.py:48] [113100] global_step=113100, grad_norm=1.3989006280899048, loss=2.884605884552002
I0303 02:02:37.312780 139881799980800 logging_writer.py:48] [113200] global_step=113200, grad_norm=1.5337982177734375, loss=2.6939921379089355
I0303 02:03:21.976458 139881808373504 logging_writer.py:48] [113300] global_step=113300, grad_norm=1.6806297302246094, loss=1.8922076225280762
I0303 02:04:06.334205 139881799980800 logging_writer.py:48] [113400] global_step=113400, grad_norm=1.5518797636032104, loss=3.3411500453948975
I0303 02:04:50.489556 139881808373504 logging_writer.py:48] [113500] global_step=113500, grad_norm=1.6676526069641113, loss=3.1904866695404053
I0303 02:05:35.389238 139881799980800 logging_writer.py:48] [113600] global_step=113600, grad_norm=1.5354098081588745, loss=3.8667171001434326
I0303 02:06:20.086242 139881808373504 logging_writer.py:48] [113700] global_step=113700, grad_norm=1.55772864818573, loss=1.72437584400177
I0303 02:07:04.590486 139881799980800 logging_writer.py:48] [113800] global_step=113800, grad_norm=1.6318734884262085, loss=2.359130859375
I0303 02:07:48.938094 139881808373504 logging_writer.py:48] [113900] global_step=113900, grad_norm=1.7096587419509888, loss=2.059140682220459
I0303 02:08:33.252977 139881799980800 logging_writer.py:48] [114000] global_step=114000, grad_norm=1.6786106824874878, loss=2.9357354640960693
I0303 02:08:41.262032 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:08:51.566266 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:09:21.673819 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:09:23.250603 140077943854912 submission_runner.py:411] Time since start: 54156.06s, 	Step: 114020, 	{'train/accuracy': 0.77685546875, 'train/loss': 0.8710706830024719, 'validation/accuracy': 0.707539975643158, 'validation/loss': 1.1852104663848877, 'validation/num_examples': 50000, 'test/accuracy': 0.5845000147819519, 'test/loss': 1.8225212097167969, 'test/num_examples': 10000, 'score': 50039.012590408325, 'total_duration': 54156.05561089516, 'accumulated_submission_time': 50039.012590408325, 'accumulated_eval_time': 4106.380417108536, 'accumulated_logging_time': 4.684727907180786}
I0303 02:09:23.287050 139881808373504 logging_writer.py:48] [114020] accumulated_eval_time=4106.380417, accumulated_logging_time=4.684728, accumulated_submission_time=50039.012590, global_step=114020, preemption_count=0, score=50039.012590, test/accuracy=0.584500, test/loss=1.822521, test/num_examples=10000, total_duration=54156.055611, train/accuracy=0.776855, train/loss=0.871071, validation/accuracy=0.707540, validation/loss=1.185210, validation/num_examples=50000
I0303 02:09:54.892976 139881799980800 logging_writer.py:48] [114100] global_step=114100, grad_norm=1.8043609857559204, loss=1.8710635900497437
I0303 02:10:38.975317 139881808373504 logging_writer.py:48] [114200] global_step=114200, grad_norm=1.560341477394104, loss=2.700446128845215
I0303 02:11:23.604047 139881799980800 logging_writer.py:48] [114300] global_step=114300, grad_norm=1.6373586654663086, loss=1.739790439605713
I0303 02:12:07.799712 139881808373504 logging_writer.py:48] [114400] global_step=114400, grad_norm=1.510813593864441, loss=3.3731634616851807
I0303 02:12:52.153072 139881799980800 logging_writer.py:48] [114500] global_step=114500, grad_norm=1.830075979232788, loss=4.286706924438477
I0303 02:13:36.537392 139881808373504 logging_writer.py:48] [114600] global_step=114600, grad_norm=1.6844302415847778, loss=1.8024778366088867
I0303 02:14:21.174770 139881799980800 logging_writer.py:48] [114700] global_step=114700, grad_norm=1.5964573621749878, loss=1.8641712665557861
I0303 02:15:05.426278 139881808373504 logging_writer.py:48] [114800] global_step=114800, grad_norm=1.512426495552063, loss=3.302971839904785
I0303 02:15:49.568222 139881799980800 logging_writer.py:48] [114900] global_step=114900, grad_norm=1.5540443658828735, loss=4.233129501342773
I0303 02:16:23.606487 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:16:34.155405 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:16:58.240933 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:16:59.830422 140077943854912 submission_runner.py:411] Time since start: 54612.64s, 	Step: 114978, 	{'train/accuracy': 0.7953710556030273, 'train/loss': 0.8017292022705078, 'validation/accuracy': 0.7105000019073486, 'validation/loss': 1.1759315729141235, 'validation/num_examples': 50000, 'test/accuracy': 0.5812000036239624, 'test/loss': 1.831921935081482, 'test/num_examples': 10000, 'score': 50459.272194862366, 'total_duration': 54612.635430812836, 'accumulated_submission_time': 50459.272194862366, 'accumulated_eval_time': 4142.604337930679, 'accumulated_logging_time': 4.731132507324219}
I0303 02:16:59.870245 139881808373504 logging_writer.py:48] [114978] accumulated_eval_time=4142.604338, accumulated_logging_time=4.731133, accumulated_submission_time=50459.272195, global_step=114978, preemption_count=0, score=50459.272195, test/accuracy=0.581200, test/loss=1.831922, test/num_examples=10000, total_duration=54612.635431, train/accuracy=0.795371, train/loss=0.801729, validation/accuracy=0.710500, validation/loss=1.175932, validation/num_examples=50000
I0303 02:17:08.851043 139881799980800 logging_writer.py:48] [115000] global_step=115000, grad_norm=1.7034342288970947, loss=4.135502815246582
I0303 02:17:50.569366 139881808373504 logging_writer.py:48] [115100] global_step=115100, grad_norm=1.8656960725784302, loss=1.7730000019073486
I0303 02:18:34.962584 139881799980800 logging_writer.py:48] [115200] global_step=115200, grad_norm=1.611216425895691, loss=1.7954890727996826
I0303 02:19:19.332179 139881808373504 logging_writer.py:48] [115300] global_step=115300, grad_norm=1.7839223146438599, loss=1.7992479801177979
I0303 02:20:03.749208 139881799980800 logging_writer.py:48] [115400] global_step=115400, grad_norm=1.5710588693618774, loss=1.6781542301177979
I0303 02:20:48.334847 139881808373504 logging_writer.py:48] [115500] global_step=115500, grad_norm=1.7278131246566772, loss=1.7835824489593506
I0303 02:21:32.645793 139881799980800 logging_writer.py:48] [115600] global_step=115600, grad_norm=1.579564094543457, loss=1.806563138961792
I0303 02:22:17.322965 139881808373504 logging_writer.py:48] [115700] global_step=115700, grad_norm=1.8612600564956665, loss=4.121461391448975
I0303 02:23:01.739588 139881799980800 logging_writer.py:48] [115800] global_step=115800, grad_norm=1.675959587097168, loss=1.845304250717163
I0303 02:23:46.425400 139881808373504 logging_writer.py:48] [115900] global_step=115900, grad_norm=1.6678383350372314, loss=3.9514095783233643
I0303 02:24:00.212779 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:24:10.929208 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:24:44.647081 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:24:46.232699 140077943854912 submission_runner.py:411] Time since start: 55079.04s, 	Step: 115933, 	{'train/accuracy': 0.775097668170929, 'train/loss': 0.878689169883728, 'validation/accuracy': 0.7120400071144104, 'validation/loss': 1.159434199333191, 'validation/num_examples': 50000, 'test/accuracy': 0.5839000344276428, 'test/loss': 1.8186765909194946, 'test/num_examples': 10000, 'score': 50879.5531334877, 'total_duration': 55079.03768348694, 'accumulated_submission_time': 50879.5531334877, 'accumulated_eval_time': 4188.624214410782, 'accumulated_logging_time': 4.783179759979248}
I0303 02:24:46.265285 139881799980800 logging_writer.py:48] [115933] accumulated_eval_time=4188.624214, accumulated_logging_time=4.783180, accumulated_submission_time=50879.553133, global_step=115933, preemption_count=0, score=50879.553133, test/accuracy=0.583900, test/loss=1.818677, test/num_examples=10000, total_duration=55079.037683, train/accuracy=0.775098, train/loss=0.878689, validation/accuracy=0.712040, validation/loss=1.159434, validation/num_examples=50000
I0303 02:25:12.809798 139881808373504 logging_writer.py:48] [116000] global_step=116000, grad_norm=1.9332712888717651, loss=1.9361149072647095
I0303 02:25:56.165785 139881799980800 logging_writer.py:48] [116100] global_step=116100, grad_norm=1.8285889625549316, loss=1.7324447631835938
I0303 02:26:40.951221 139881808373504 logging_writer.py:48] [116200] global_step=116200, grad_norm=1.694807767868042, loss=1.7192935943603516
I0303 02:27:25.546183 139881799980800 logging_writer.py:48] [116300] global_step=116300, grad_norm=1.485511064529419, loss=2.7366561889648438
I0303 02:28:10.056555 139881808373504 logging_writer.py:48] [116400] global_step=116400, grad_norm=1.550471305847168, loss=2.712297201156616
I0303 02:28:54.363109 139881799980800 logging_writer.py:48] [116500] global_step=116500, grad_norm=1.749503493309021, loss=1.755725383758545
I0303 02:29:38.666690 139881808373504 logging_writer.py:48] [116600] global_step=116600, grad_norm=1.731963872909546, loss=1.8141255378723145
I0303 02:30:23.304794 139881799980800 logging_writer.py:48] [116700] global_step=116700, grad_norm=1.6307648420333862, loss=1.6767079830169678
I0303 02:31:07.953525 139881808373504 logging_writer.py:48] [116800] global_step=116800, grad_norm=1.6776328086853027, loss=2.0315849781036377
I0303 02:31:46.754507 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:31:56.894939 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:32:28.193314 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:32:29.768977 140077943854912 submission_runner.py:411] Time since start: 55542.57s, 	Step: 116889, 	{'train/accuracy': 0.7811132669448853, 'train/loss': 0.8491606712341309, 'validation/accuracy': 0.712119996547699, 'validation/loss': 1.1562445163726807, 'validation/num_examples': 50000, 'test/accuracy': 0.5835000276565552, 'test/loss': 1.794126033782959, 'test/num_examples': 10000, 'score': 51299.98179316521, 'total_duration': 55542.57398247719, 'accumulated_submission_time': 51299.98179316521, 'accumulated_eval_time': 4231.638665437698, 'accumulated_logging_time': 4.826200723648071}
I0303 02:32:29.806521 139881799980800 logging_writer.py:48] [116889] accumulated_eval_time=4231.638665, accumulated_logging_time=4.826201, accumulated_submission_time=51299.981793, global_step=116889, preemption_count=0, score=51299.981793, test/accuracy=0.583500, test/loss=1.794126, test/num_examples=10000, total_duration=55542.573982, train/accuracy=0.781113, train/loss=0.849161, validation/accuracy=0.712120, validation/loss=1.156245, validation/num_examples=50000
I0303 02:32:34.474598 139881808373504 logging_writer.py:48] [116900] global_step=116900, grad_norm=1.7815680503845215, loss=1.8220925331115723
I0303 02:33:14.929569 139881799980800 logging_writer.py:48] [117000] global_step=117000, grad_norm=1.9948253631591797, loss=1.757308006286621
I0303 02:33:59.207607 139881808373504 logging_writer.py:48] [117100] global_step=117100, grad_norm=1.7331750392913818, loss=4.13334846496582
I0303 02:34:43.640848 139881799980800 logging_writer.py:48] [117200] global_step=117200, grad_norm=1.7204327583312988, loss=3.01163387298584
I0303 02:35:27.927169 139881808373504 logging_writer.py:48] [117300] global_step=117300, grad_norm=1.764028549194336, loss=3.1426806449890137
I0303 02:36:12.278282 139881799980800 logging_writer.py:48] [117400] global_step=117400, grad_norm=1.6807705163955688, loss=1.7734192609786987
I0303 02:36:56.660846 139881808373504 logging_writer.py:48] [117500] global_step=117500, grad_norm=1.68784499168396, loss=1.702479362487793
I0303 02:37:41.133508 139881799980800 logging_writer.py:48] [117600] global_step=117600, grad_norm=1.6376142501831055, loss=2.1046390533447266
I0303 02:38:25.621639 139881808373504 logging_writer.py:48] [117700] global_step=117700, grad_norm=1.8151037693023682, loss=1.8030431270599365
I0303 02:39:10.093230 139881799980800 logging_writer.py:48] [117800] global_step=117800, grad_norm=1.6133240461349487, loss=3.1626172065734863
I0303 02:39:30.083693 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:39:40.319396 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:40:06.450313 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:40:08.036999 140077943854912 submission_runner.py:411] Time since start: 56000.84s, 	Step: 117847, 	{'train/accuracy': 0.78822261095047, 'train/loss': 0.8326475620269775, 'validation/accuracy': 0.710919976234436, 'validation/loss': 1.1654090881347656, 'validation/num_examples': 50000, 'test/accuracy': 0.5782000422477722, 'test/loss': 1.8094024658203125, 'test/num_examples': 10000, 'score': 51720.195872306824, 'total_duration': 56000.84201049805, 'accumulated_submission_time': 51720.195872306824, 'accumulated_eval_time': 4269.591933727264, 'accumulated_logging_time': 4.876907825469971}
I0303 02:40:08.070465 139881808373504 logging_writer.py:48] [117847] accumulated_eval_time=4269.591934, accumulated_logging_time=4.876908, accumulated_submission_time=51720.195872, global_step=117847, preemption_count=0, score=51720.195872, test/accuracy=0.578200, test/loss=1.809402, test/num_examples=10000, total_duration=56000.842010, train/accuracy=0.788223, train/loss=0.832648, validation/accuracy=0.710920, validation/loss=1.165409, validation/num_examples=50000
I0303 02:40:29.153852 139881799980800 logging_writer.py:48] [117900] global_step=117900, grad_norm=1.795235276222229, loss=1.7385348081588745
I0303 02:41:11.833573 139881808373504 logging_writer.py:48] [118000] global_step=118000, grad_norm=1.6646175384521484, loss=1.7639379501342773
I0303 02:41:56.353409 139881799980800 logging_writer.py:48] [118100] global_step=118100, grad_norm=1.82893967628479, loss=1.7434428930282593
I0303 02:42:40.667325 139881808373504 logging_writer.py:48] [118200] global_step=118200, grad_norm=1.6517184972763062, loss=1.786840796470642
I0303 02:43:25.058873 139881799980800 logging_writer.py:48] [118300] global_step=118300, grad_norm=1.5466182231903076, loss=2.370914936065674
I0303 02:44:09.508215 139881808373504 logging_writer.py:48] [118400] global_step=118400, grad_norm=1.90911865234375, loss=1.7712788581848145
I0303 02:44:53.658401 139881799980800 logging_writer.py:48] [118500] global_step=118500, grad_norm=1.7293522357940674, loss=4.143601417541504
I0303 02:45:38.376454 139881808373504 logging_writer.py:48] [118600] global_step=118600, grad_norm=1.738155484199524, loss=3.4690022468566895
I0303 02:46:22.687803 139881799980800 logging_writer.py:48] [118700] global_step=118700, grad_norm=1.8019211292266846, loss=1.7343292236328125
I0303 02:47:06.993557 139881808373504 logging_writer.py:48] [118800] global_step=118800, grad_norm=1.750182867050171, loss=1.673654556274414
I0303 02:47:08.463738 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:47:18.768624 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:47:47.134413 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:47:48.727844 140077943854912 submission_runner.py:411] Time since start: 56461.53s, 	Step: 118805, 	{'train/accuracy': 0.7870702743530273, 'train/loss': 0.817166268825531, 'validation/accuracy': 0.7132399678230286, 'validation/loss': 1.1419477462768555, 'validation/num_examples': 50000, 'test/accuracy': 0.5823000073432922, 'test/loss': 1.7990473508834839, 'test/num_examples': 10000, 'score': 52140.52798819542, 'total_duration': 56461.532861709595, 'accumulated_submission_time': 52140.52798819542, 'accumulated_eval_time': 4309.85601067543, 'accumulated_logging_time': 4.921182155609131}
I0303 02:47:48.765034 139881799980800 logging_writer.py:48] [118805] accumulated_eval_time=4309.856011, accumulated_logging_time=4.921182, accumulated_submission_time=52140.527988, global_step=118805, preemption_count=0, score=52140.527988, test/accuracy=0.582300, test/loss=1.799047, test/num_examples=10000, total_duration=56461.532862, train/accuracy=0.787070, train/loss=0.817166, validation/accuracy=0.713240, validation/loss=1.141948, validation/num_examples=50000
I0303 02:48:27.161742 139881808373504 logging_writer.py:48] [118900] global_step=118900, grad_norm=1.817175269126892, loss=2.005117416381836
I0303 02:49:11.488028 139881799980800 logging_writer.py:48] [119000] global_step=119000, grad_norm=1.61945641040802, loss=2.2070112228393555
I0303 02:49:55.698892 139881808373504 logging_writer.py:48] [119100] global_step=119100, grad_norm=1.8757777214050293, loss=1.7460203170776367
I0303 02:50:39.929907 139881799980800 logging_writer.py:48] [119200] global_step=119200, grad_norm=1.8902183771133423, loss=4.048196792602539
I0303 02:51:24.165031 139881808373504 logging_writer.py:48] [119300] global_step=119300, grad_norm=1.4777395725250244, loss=3.216024875640869
I0303 02:52:08.620070 139881799980800 logging_writer.py:48] [119400] global_step=119400, grad_norm=1.854500651359558, loss=1.7831751108169556
I0303 02:52:52.722511 139881808373504 logging_writer.py:48] [119500] global_step=119500, grad_norm=1.6438432931900024, loss=1.901547908782959
I0303 02:53:37.034545 139881799980800 logging_writer.py:48] [119600] global_step=119600, grad_norm=1.7472140789031982, loss=3.409428834915161
I0303 02:54:21.395911 139881808373504 logging_writer.py:48] [119700] global_step=119700, grad_norm=1.6365399360656738, loss=3.866115093231201
I0303 02:54:48.844480 140077943854912 spec.py:321] Evaluating on the training split.
I0303 02:54:59.179751 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 02:55:26.991957 140077943854912 spec.py:349] Evaluating on the test split.
I0303 02:55:28.580220 140077943854912 submission_runner.py:411] Time since start: 56921.39s, 	Step: 119764, 	{'train/accuracy': 0.7832226157188416, 'train/loss': 0.831150472164154, 'validation/accuracy': 0.7125399708747864, 'validation/loss': 1.1509326696395874, 'validation/num_examples': 50000, 'test/accuracy': 0.5859000086784363, 'test/loss': 1.8054711818695068, 'test/num_examples': 10000, 'score': 52560.545924663544, 'total_duration': 56921.385232687, 'accumulated_submission_time': 52560.545924663544, 'accumulated_eval_time': 4349.591715335846, 'accumulated_logging_time': 4.970265626907349}
I0303 02:55:28.622799 139881799980800 logging_writer.py:48] [119764] accumulated_eval_time=4349.591715, accumulated_logging_time=4.970266, accumulated_submission_time=52560.545925, global_step=119764, preemption_count=0, score=52560.545925, test/accuracy=0.585900, test/loss=1.805471, test/num_examples=10000, total_duration=56921.385233, train/accuracy=0.783223, train/loss=0.831150, validation/accuracy=0.712540, validation/loss=1.150933, validation/num_examples=50000
I0303 02:55:43.063651 139881808373504 logging_writer.py:48] [119800] global_step=119800, grad_norm=1.7142341136932373, loss=2.721912384033203
I0303 02:56:25.587657 139881799980800 logging_writer.py:48] [119900] global_step=119900, grad_norm=1.6935622692108154, loss=3.8170604705810547
I0303 02:57:10.285482 139881808373504 logging_writer.py:48] [120000] global_step=120000, grad_norm=1.77556312084198, loss=3.7967658042907715
I0303 02:57:54.919903 139881799980800 logging_writer.py:48] [120100] global_step=120100, grad_norm=1.556588888168335, loss=2.5418882369995117
I0303 02:58:39.492104 139881808373504 logging_writer.py:48] [120200] global_step=120200, grad_norm=1.5970629453659058, loss=3.3753414154052734
I0303 02:59:24.058673 139881799980800 logging_writer.py:48] [120300] global_step=120300, grad_norm=1.7305982112884521, loss=2.9544520378112793
I0303 03:00:08.727465 139881808373504 logging_writer.py:48] [120400] global_step=120400, grad_norm=1.5014185905456543, loss=2.5675406455993652
I0303 03:00:53.115917 139881799980800 logging_writer.py:48] [120500] global_step=120500, grad_norm=1.9623316526412964, loss=3.6944916248321533
I0303 03:01:37.794826 139881808373504 logging_writer.py:48] [120600] global_step=120600, grad_norm=1.8499208688735962, loss=1.8248440027236938
I0303 03:02:22.399081 139881799980800 logging_writer.py:48] [120700] global_step=120700, grad_norm=1.8990318775177002, loss=1.7508814334869385
I0303 03:02:28.764337 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:02:38.967362 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:03:08.532674 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:03:10.114558 140077943854912 submission_runner.py:411] Time since start: 57382.92s, 	Step: 120716, 	{'train/accuracy': 0.7913867235183716, 'train/loss': 0.8026143312454224, 'validation/accuracy': 0.7174599766731262, 'validation/loss': 1.1281665563583374, 'validation/num_examples': 50000, 'test/accuracy': 0.5871000289916992, 'test/loss': 1.7703475952148438, 'test/num_examples': 10000, 'score': 52980.626074790955, 'total_duration': 57382.91956567764, 'accumulated_submission_time': 52980.626074790955, 'accumulated_eval_time': 4390.941907405853, 'accumulated_logging_time': 5.0248682498931885}
I0303 03:03:10.155806 139881808373504 logging_writer.py:48] [120716] accumulated_eval_time=4390.941907, accumulated_logging_time=5.024868, accumulated_submission_time=52980.626075, global_step=120716, preemption_count=0, score=52980.626075, test/accuracy=0.587100, test/loss=1.770348, test/num_examples=10000, total_duration=57382.919566, train/accuracy=0.791387, train/loss=0.802614, validation/accuracy=0.717460, validation/loss=1.128167, validation/num_examples=50000
I0303 03:03:43.637956 139881799980800 logging_writer.py:48] [120800] global_step=120800, grad_norm=1.6879972219467163, loss=2.25246262550354
I0303 03:04:27.945994 139881808373504 logging_writer.py:48] [120900] global_step=120900, grad_norm=1.6514976024627686, loss=2.63150691986084
I0303 03:05:12.629969 139881799980800 logging_writer.py:48] [121000] global_step=121000, grad_norm=1.6616929769515991, loss=1.7503796815872192
I0303 03:05:56.937827 139881808373504 logging_writer.py:48] [121100] global_step=121100, grad_norm=1.6289665699005127, loss=2.336155414581299
I0303 03:06:41.700690 139881799980800 logging_writer.py:48] [121200] global_step=121200, grad_norm=1.7952139377593994, loss=1.759043574333191
I0303 03:07:25.848850 139881808373504 logging_writer.py:48] [121300] global_step=121300, grad_norm=1.746397852897644, loss=2.6328537464141846
I0303 03:08:10.350132 139881799980800 logging_writer.py:48] [121400] global_step=121400, grad_norm=1.657698392868042, loss=1.7501239776611328
I0303 03:08:54.723898 139881808373504 logging_writer.py:48] [121500] global_step=121500, grad_norm=1.726706862449646, loss=1.732471227645874
I0303 03:09:39.111353 139881799980800 logging_writer.py:48] [121600] global_step=121600, grad_norm=1.7689950466156006, loss=1.8220131397247314
I0303 03:10:10.431432 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:10:20.642431 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:10:50.062957 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:10:51.647337 140077943854912 submission_runner.py:411] Time since start: 57844.45s, 	Step: 121672, 	{'train/accuracy': 0.7996289134025574, 'train/loss': 0.7926232814788818, 'validation/accuracy': 0.7188000082969666, 'validation/loss': 1.1456674337387085, 'validation/num_examples': 50000, 'test/accuracy': 0.5902000069618225, 'test/loss': 1.784095048904419, 'test/num_examples': 10000, 'score': 53400.83889579773, 'total_duration': 57844.45234084129, 'accumulated_submission_time': 53400.83889579773, 'accumulated_eval_time': 4432.157784461975, 'accumulated_logging_time': 5.077365398406982}
I0303 03:10:51.692896 139881808373504 logging_writer.py:48] [121672] accumulated_eval_time=4432.157784, accumulated_logging_time=5.077365, accumulated_submission_time=53400.838896, global_step=121672, preemption_count=0, score=53400.838896, test/accuracy=0.590200, test/loss=1.784095, test/num_examples=10000, total_duration=57844.452341, train/accuracy=0.799629, train/loss=0.792623, validation/accuracy=0.718800, validation/loss=1.145667, validation/num_examples=50000
I0303 03:11:03.000901 139881799980800 logging_writer.py:48] [121700] global_step=121700, grad_norm=1.8482812643051147, loss=1.7910091876983643
I0303 03:11:44.580639 139881808373504 logging_writer.py:48] [121800] global_step=121800, grad_norm=1.675108790397644, loss=3.214961051940918
I0303 03:12:29.108028 139881799980800 logging_writer.py:48] [121900] global_step=121900, grad_norm=1.8178129196166992, loss=1.7027286291122437
I0303 03:13:13.995990 139881808373504 logging_writer.py:48] [122000] global_step=122000, grad_norm=1.7115037441253662, loss=3.2912535667419434
I0303 03:13:58.053987 139881799980800 logging_writer.py:48] [122100] global_step=122100, grad_norm=1.7075077295303345, loss=2.842921018600464
I0303 03:14:42.519521 139881808373504 logging_writer.py:48] [122200] global_step=122200, grad_norm=1.579291820526123, loss=2.265810489654541
I0303 03:15:27.277461 139881799980800 logging_writer.py:48] [122300] global_step=122300, grad_norm=1.5918313264846802, loss=2.5770034790039062
I0303 03:16:11.977061 139881808373504 logging_writer.py:48] [122400] global_step=122400, grad_norm=2.084536552429199, loss=4.24463415145874
I0303 03:16:56.687007 139881799980800 logging_writer.py:48] [122500] global_step=122500, grad_norm=1.6981165409088135, loss=3.573437213897705
I0303 03:17:41.290536 139881808373504 logging_writer.py:48] [122600] global_step=122600, grad_norm=1.7591267824172974, loss=3.225426197052002
I0303 03:17:51.661135 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:18:01.999108 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:18:28.512271 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:18:30.091744 140077943854912 submission_runner.py:411] Time since start: 58302.90s, 	Step: 122625, 	{'train/accuracy': 0.7887304425239563, 'train/loss': 0.8185681104660034, 'validation/accuracy': 0.7198799848556519, 'validation/loss': 1.1269749402999878, 'validation/num_examples': 50000, 'test/accuracy': 0.5949000120162964, 'test/loss': 1.749130368232727, 'test/num_examples': 10000, 'score': 53820.74506020546, 'total_duration': 58302.89676403999, 'accumulated_submission_time': 53820.74506020546, 'accumulated_eval_time': 4470.588375091553, 'accumulated_logging_time': 5.134720325469971}
I0303 03:18:30.125842 139881799980800 logging_writer.py:48] [122625] accumulated_eval_time=4470.588375, accumulated_logging_time=5.134720, accumulated_submission_time=53820.745060, global_step=122625, preemption_count=0, score=53820.745060, test/accuracy=0.594900, test/loss=1.749130, test/num_examples=10000, total_duration=58302.896764, train/accuracy=0.788730, train/loss=0.818568, validation/accuracy=0.719880, validation/loss=1.126975, validation/num_examples=50000
I0303 03:18:59.803723 139881808373504 logging_writer.py:48] [122700] global_step=122700, grad_norm=1.5924314260482788, loss=2.4603328704833984
I0303 03:19:43.858273 139881799980800 logging_writer.py:48] [122800] global_step=122800, grad_norm=1.5492075681686401, loss=2.699084758758545
I0303 03:20:28.615641 139881808373504 logging_writer.py:48] [122900] global_step=122900, grad_norm=1.7620456218719482, loss=1.627167820930481
I0303 03:21:13.075245 139881799980800 logging_writer.py:48] [123000] global_step=123000, grad_norm=1.7565404176712036, loss=1.8206032514572144
I0303 03:21:57.287772 139881808373504 logging_writer.py:48] [123100] global_step=123100, grad_norm=1.8627002239227295, loss=1.614676833152771
I0303 03:22:41.771923 139881799980800 logging_writer.py:48] [123200] global_step=123200, grad_norm=1.7494478225708008, loss=2.093777894973755
I0303 03:23:26.467137 139881808373504 logging_writer.py:48] [123300] global_step=123300, grad_norm=1.6783337593078613, loss=1.977704644203186
I0303 03:24:11.007567 139881799980800 logging_writer.py:48] [123400] global_step=123400, grad_norm=1.8195595741271973, loss=1.7545831203460693
I0303 03:24:55.317984 139881808373504 logging_writer.py:48] [123500] global_step=123500, grad_norm=1.884615421295166, loss=4.15688943862915
I0303 03:25:30.415522 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:25:41.464909 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:26:09.649639 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:26:11.243950 140077943854912 submission_runner.py:411] Time since start: 58764.05s, 	Step: 123580, 	{'train/accuracy': 0.7926952838897705, 'train/loss': 0.8255926966667175, 'validation/accuracy': 0.7219199538230896, 'validation/loss': 1.1399753093719482, 'validation/num_examples': 50000, 'test/accuracy': 0.598300039768219, 'test/loss': 1.7739555835723877, 'test/num_examples': 10000, 'score': 54240.97389984131, 'total_duration': 58764.0489218235, 'accumulated_submission_time': 54240.97389984131, 'accumulated_eval_time': 4511.416751623154, 'accumulated_logging_time': 5.179789066314697}
I0303 03:26:11.284134 139881799980800 logging_writer.py:48] [123580] accumulated_eval_time=4511.416752, accumulated_logging_time=5.179789, accumulated_submission_time=54240.973900, global_step=123580, preemption_count=0, score=54240.973900, test/accuracy=0.598300, test/loss=1.773956, test/num_examples=10000, total_duration=58764.048922, train/accuracy=0.792695, train/loss=0.825593, validation/accuracy=0.721920, validation/loss=1.139975, validation/num_examples=50000
I0303 03:26:19.472783 139881808373504 logging_writer.py:48] [123600] global_step=123600, grad_norm=1.9576228857040405, loss=1.6898528337478638
I0303 03:27:00.492265 139881799980800 logging_writer.py:48] [123700] global_step=123700, grad_norm=1.5972000360488892, loss=1.9428536891937256
I0303 03:27:44.921881 139881808373504 logging_writer.py:48] [123800] global_step=123800, grad_norm=1.6407005786895752, loss=2.028937578201294
I0303 03:28:29.835129 139881799980800 logging_writer.py:48] [123900] global_step=123900, grad_norm=1.9947559833526611, loss=1.6532279253005981
I0303 03:29:14.460396 139881808373504 logging_writer.py:48] [124000] global_step=124000, grad_norm=1.802893042564392, loss=1.6119271516799927
I0303 03:29:58.877230 139881799980800 logging_writer.py:48] [124100] global_step=124100, grad_norm=1.838473916053772, loss=1.7401821613311768
I0303 03:30:43.383696 139881808373504 logging_writer.py:48] [124200] global_step=124200, grad_norm=1.902449607849121, loss=4.027767181396484
I0303 03:31:28.118330 139881799980800 logging_writer.py:48] [124300] global_step=124300, grad_norm=1.6266776323318481, loss=2.953273296356201
I0303 03:32:12.460927 139881808373504 logging_writer.py:48] [124400] global_step=124400, grad_norm=2.0449235439300537, loss=1.568105697631836
I0303 03:32:56.782081 139881799980800 logging_writer.py:48] [124500] global_step=124500, grad_norm=1.6504096984863281, loss=2.336831569671631
I0303 03:33:11.257631 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:33:21.468555 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:33:46.953047 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:33:48.530431 140077943854912 submission_runner.py:411] Time since start: 59221.34s, 	Step: 124534, 	{'train/accuracy': 0.7994140386581421, 'train/loss': 0.7840669751167297, 'validation/accuracy': 0.7232399582862854, 'validation/loss': 1.110971450805664, 'validation/num_examples': 50000, 'test/accuracy': 0.5958999991416931, 'test/loss': 1.755924940109253, 'test/num_examples': 10000, 'score': 54660.88675928116, 'total_duration': 59221.33545231819, 'accumulated_submission_time': 54660.88675928116, 'accumulated_eval_time': 4548.689545869827, 'accumulated_logging_time': 5.231285095214844}
I0303 03:33:48.566707 139881808373504 logging_writer.py:48] [124534] accumulated_eval_time=4548.689546, accumulated_logging_time=5.231285, accumulated_submission_time=54660.886759, global_step=124534, preemption_count=0, score=54660.886759, test/accuracy=0.595900, test/loss=1.755925, test/num_examples=10000, total_duration=59221.335452, train/accuracy=0.799414, train/loss=0.784067, validation/accuracy=0.723240, validation/loss=1.110971, validation/num_examples=50000
I0303 03:34:14.707883 139881799980800 logging_writer.py:48] [124600] global_step=124600, grad_norm=1.652084469795227, loss=2.5693886280059814
I0303 03:34:57.916912 139881808373504 logging_writer.py:48] [124700] global_step=124700, grad_norm=1.8258428573608398, loss=1.8089475631713867
I0303 03:35:42.611791 139881799980800 logging_writer.py:48] [124800] global_step=124800, grad_norm=1.7199532985687256, loss=1.6398109197616577
I0303 03:36:27.397109 139881808373504 logging_writer.py:48] [124900] global_step=124900, grad_norm=1.5962860584259033, loss=2.34810209274292
I0303 03:37:11.812973 139881799980800 logging_writer.py:48] [125000] global_step=125000, grad_norm=1.9345324039459229, loss=1.934289574623108
I0303 03:37:56.291518 139881808373504 logging_writer.py:48] [125100] global_step=125100, grad_norm=1.8834890127182007, loss=1.8118550777435303
I0303 03:38:40.681397 139881799980800 logging_writer.py:48] [125200] global_step=125200, grad_norm=1.832659125328064, loss=1.8360100984573364
I0303 03:39:25.080963 139881808373504 logging_writer.py:48] [125300] global_step=125300, grad_norm=1.813361644744873, loss=3.108645439147949
I0303 03:40:09.701560 139881799980800 logging_writer.py:48] [125400] global_step=125400, grad_norm=1.6324604749679565, loss=2.8404879570007324
I0303 03:40:48.710041 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:40:59.021498 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:41:25.739229 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:41:27.326242 140077943854912 submission_runner.py:411] Time since start: 59680.13s, 	Step: 125490, 	{'train/accuracy': 0.8218359351158142, 'train/loss': 0.6901920437812805, 'validation/accuracy': 0.7267999649047852, 'validation/loss': 1.1000694036483765, 'validation/num_examples': 50000, 'test/accuracy': 0.6070000529289246, 'test/loss': 1.718909502029419, 'test/num_examples': 10000, 'score': 55080.96838617325, 'total_duration': 59680.131251335144, 'accumulated_submission_time': 55080.96838617325, 'accumulated_eval_time': 4587.305732250214, 'accumulated_logging_time': 5.2786900997161865}
I0303 03:41:27.371489 139881808373504 logging_writer.py:48] [125490] accumulated_eval_time=4587.305732, accumulated_logging_time=5.278690, accumulated_submission_time=55080.968386, global_step=125490, preemption_count=0, score=55080.968386, test/accuracy=0.607000, test/loss=1.718910, test/num_examples=10000, total_duration=59680.131251, train/accuracy=0.821836, train/loss=0.690192, validation/accuracy=0.726800, validation/loss=1.100069, validation/num_examples=50000
I0303 03:41:31.692419 139881799980800 logging_writer.py:48] [125500] global_step=125500, grad_norm=1.7728257179260254, loss=1.7631107568740845
I0303 03:42:12.698999 139881808373504 logging_writer.py:48] [125600] global_step=125600, grad_norm=1.7433209419250488, loss=2.1331498622894287
I0303 03:42:56.855038 139881799980800 logging_writer.py:48] [125700] global_step=125700, grad_norm=1.8935763835906982, loss=1.5974512100219727
I0303 03:43:41.447674 139881808373504 logging_writer.py:48] [125800] global_step=125800, grad_norm=1.756199836730957, loss=1.5390511751174927
I0303 03:44:25.650208 139881799980800 logging_writer.py:48] [125900] global_step=125900, grad_norm=1.7996017932891846, loss=1.7740426063537598
I0303 03:45:10.148964 139881808373504 logging_writer.py:48] [126000] global_step=126000, grad_norm=1.7510249614715576, loss=2.0011415481567383
I0303 03:45:54.357381 139881799980800 logging_writer.py:48] [126100] global_step=126100, grad_norm=1.8136321306228638, loss=1.641077995300293
I0303 03:46:39.204704 139881808373504 logging_writer.py:48] [126200] global_step=126200, grad_norm=1.7643522024154663, loss=1.9014861583709717
I0303 03:47:23.545397 139881799980800 logging_writer.py:48] [126300] global_step=126300, grad_norm=1.6236382722854614, loss=3.020031690597534
I0303 03:48:08.235223 139881808373504 logging_writer.py:48] [126400] global_step=126400, grad_norm=1.861079454421997, loss=1.6707253456115723
I0303 03:48:27.524937 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:48:37.917203 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:49:09.695866 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:49:11.288300 140077943854912 submission_runner.py:411] Time since start: 60144.09s, 	Step: 126445, 	{'train/accuracy': 0.79296875, 'train/loss': 0.8103262782096863, 'validation/accuracy': 0.7235199809074402, 'validation/loss': 1.1214704513549805, 'validation/num_examples': 50000, 'test/accuracy': 0.5904000401496887, 'test/loss': 1.757405400276184, 'test/num_examples': 10000, 'score': 55501.05866575241, 'total_duration': 60144.09332036972, 'accumulated_submission_time': 55501.05866575241, 'accumulated_eval_time': 4631.0690796375275, 'accumulated_logging_time': 5.3379082679748535}
I0303 03:49:11.326466 139881799980800 logging_writer.py:48] [126445] accumulated_eval_time=4631.069080, accumulated_logging_time=5.337908, accumulated_submission_time=55501.058666, global_step=126445, preemption_count=0, score=55501.058666, test/accuracy=0.590400, test/loss=1.757405, test/num_examples=10000, total_duration=60144.093320, train/accuracy=0.792969, train/loss=0.810326, validation/accuracy=0.723520, validation/loss=1.121470, validation/num_examples=50000
I0303 03:49:33.153799 139881808373504 logging_writer.py:48] [126500] global_step=126500, grad_norm=1.904571771621704, loss=1.5717250108718872
I0303 03:50:15.838628 139881799980800 logging_writer.py:48] [126600] global_step=126600, grad_norm=1.8869117498397827, loss=1.6735782623291016
I0303 03:51:00.362625 139881808373504 logging_writer.py:48] [126700] global_step=126700, grad_norm=1.8815847635269165, loss=1.792580246925354
I0303 03:51:44.899354 139881799980800 logging_writer.py:48] [126800] global_step=126800, grad_norm=1.9047080278396606, loss=1.6623742580413818
I0303 03:52:29.303040 139881808373504 logging_writer.py:48] [126900] global_step=126900, grad_norm=2.05696439743042, loss=4.030125617980957
I0303 03:53:13.629539 139881799980800 logging_writer.py:48] [127000] global_step=127000, grad_norm=2.1924028396606445, loss=3.863938570022583
I0303 03:53:57.880749 139881808373504 logging_writer.py:48] [127100] global_step=127100, grad_norm=1.8392995595932007, loss=2.145622730255127
I0303 03:54:42.171009 139881799980800 logging_writer.py:48] [127200] global_step=127200, grad_norm=1.9276750087738037, loss=1.573594570159912
I0303 03:55:26.753854 139881808373504 logging_writer.py:48] [127300] global_step=127300, grad_norm=1.9329439401626587, loss=1.898607850074768
I0303 03:56:10.941854 139881799980800 logging_writer.py:48] [127400] global_step=127400, grad_norm=1.955475926399231, loss=1.894838571548462
I0303 03:56:11.483798 140077943854912 spec.py:321] Evaluating on the training split.
I0303 03:56:22.005648 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 03:56:54.641628 140077943854912 spec.py:349] Evaluating on the test split.
I0303 03:56:56.228832 140077943854912 submission_runner.py:411] Time since start: 60609.03s, 	Step: 127403, 	{'train/accuracy': 0.80140620470047, 'train/loss': 0.7748098373413086, 'validation/accuracy': 0.7250999808311462, 'validation/loss': 1.1140674352645874, 'validation/num_examples': 50000, 'test/accuracy': 0.600100040435791, 'test/loss': 1.7393742799758911, 'test/num_examples': 10000, 'score': 55921.156155347824, 'total_duration': 60609.03382444382, 'accumulated_submission_time': 55921.156155347824, 'accumulated_eval_time': 4675.814074754715, 'accumulated_logging_time': 5.386435270309448}
I0303 03:56:56.272734 139881808373504 logging_writer.py:48] [127403] accumulated_eval_time=4675.814075, accumulated_logging_time=5.386435, accumulated_submission_time=55921.156155, global_step=127403, preemption_count=0, score=55921.156155, test/accuracy=0.600100, test/loss=1.739374, test/num_examples=10000, total_duration=60609.033824, train/accuracy=0.801406, train/loss=0.774810, validation/accuracy=0.725100, validation/loss=1.114067, validation/num_examples=50000
I0303 03:57:35.272221 139881799980800 logging_writer.py:48] [127500] global_step=127500, grad_norm=2.0090925693511963, loss=4.104970932006836
I0303 03:58:19.474159 139881808373504 logging_writer.py:48] [127600] global_step=127600, grad_norm=1.86416757106781, loss=1.6306244134902954
I0303 03:59:03.704948 139881799980800 logging_writer.py:48] [127700] global_step=127700, grad_norm=1.7968597412109375, loss=1.8550645112991333
I0303 03:59:48.408938 139881808373504 logging_writer.py:48] [127800] global_step=127800, grad_norm=1.6974992752075195, loss=1.7553796768188477
I0303 04:00:32.744889 139881799980800 logging_writer.py:48] [127900] global_step=127900, grad_norm=1.7049379348754883, loss=2.3408851623535156
I0303 04:01:17.144663 139881808373504 logging_writer.py:48] [128000] global_step=128000, grad_norm=1.8534629344940186, loss=2.2659239768981934
I0303 04:02:01.462560 139881799980800 logging_writer.py:48] [128100] global_step=128100, grad_norm=1.9899832010269165, loss=1.6752219200134277
I0303 04:02:45.622432 139881808373504 logging_writer.py:48] [128200] global_step=128200, grad_norm=1.9646236896514893, loss=3.665090560913086
I0303 04:03:29.845514 139881799980800 logging_writer.py:48] [128300] global_step=128300, grad_norm=1.9069738388061523, loss=1.7169568538665771
I0303 04:03:56.513298 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:04:07.067981 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:04:39.769546 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:04:41.364027 140077943854912 submission_runner.py:411] Time since start: 61074.17s, 	Step: 128362, 	{'train/accuracy': 0.808886706829071, 'train/loss': 0.7777705192565918, 'validation/accuracy': 0.7276399731636047, 'validation/loss': 1.1254874467849731, 'validation/num_examples': 50000, 'test/accuracy': 0.6046000123023987, 'test/loss': 1.7480357885360718, 'test/num_examples': 10000, 'score': 56341.335579156876, 'total_duration': 61074.16904568672, 'accumulated_submission_time': 56341.335579156876, 'accumulated_eval_time': 4720.664792776108, 'accumulated_logging_time': 5.441857099533081}
I0303 04:04:41.400668 139881808373504 logging_writer.py:48] [128362] accumulated_eval_time=4720.664793, accumulated_logging_time=5.441857, accumulated_submission_time=56341.335579, global_step=128362, preemption_count=0, score=56341.335579, test/accuracy=0.604600, test/loss=1.748036, test/num_examples=10000, total_duration=61074.169046, train/accuracy=0.808887, train/loss=0.777771, validation/accuracy=0.727640, validation/loss=1.125487, validation/num_examples=50000
I0303 04:04:56.597448 139881799980800 logging_writer.py:48] [128400] global_step=128400, grad_norm=1.8417608737945557, loss=2.3359861373901367
I0303 04:05:38.564471 139881808373504 logging_writer.py:48] [128500] global_step=128500, grad_norm=1.831535816192627, loss=3.0866239070892334
I0303 04:06:22.967718 139881799980800 logging_writer.py:48] [128600] global_step=128600, grad_norm=1.9629071950912476, loss=1.8924560546875
I0303 04:07:07.712299 139881808373504 logging_writer.py:48] [128700] global_step=128700, grad_norm=2.0668764114379883, loss=1.5176377296447754
I0303 04:07:51.779881 139881799980800 logging_writer.py:48] [128800] global_step=128800, grad_norm=1.7597013711929321, loss=2.352175235748291
I0303 04:08:36.358627 139881808373504 logging_writer.py:48] [128900] global_step=128900, grad_norm=1.9559653997421265, loss=1.733309030532837
I0303 04:09:20.931945 139881799980800 logging_writer.py:48] [129000] global_step=129000, grad_norm=1.8532744646072388, loss=1.541306734085083
I0303 04:10:05.340865 139881808373504 logging_writer.py:48] [129100] global_step=129100, grad_norm=1.9868155717849731, loss=3.7159957885742188
I0303 04:10:49.639477 139881799980800 logging_writer.py:48] [129200] global_step=129200, grad_norm=1.9069443941116333, loss=1.6222878694534302
I0303 04:11:33.947096 139881808373504 logging_writer.py:48] [129300] global_step=129300, grad_norm=1.8377714157104492, loss=1.7520325183868408
I0303 04:11:41.568516 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:11:52.020677 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:12:25.702980 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:12:27.292816 140077943854912 submission_runner.py:411] Time since start: 61540.10s, 	Step: 129319, 	{'train/accuracy': 0.8020898103713989, 'train/loss': 0.7728776335716248, 'validation/accuracy': 0.7276600003242493, 'validation/loss': 1.092849850654602, 'validation/num_examples': 50000, 'test/accuracy': 0.6008000373840332, 'test/loss': 1.7313231229782104, 'test/num_examples': 10000, 'score': 56761.44100022316, 'total_duration': 61540.09782385826, 'accumulated_submission_time': 56761.44100022316, 'accumulated_eval_time': 4766.3890652656555, 'accumulated_logging_time': 5.490319013595581}
I0303 04:12:27.331012 139881799980800 logging_writer.py:48] [129319] accumulated_eval_time=4766.389065, accumulated_logging_time=5.490319, accumulated_submission_time=56761.441000, global_step=129319, preemption_count=0, score=56761.441000, test/accuracy=0.600800, test/loss=1.731323, test/num_examples=10000, total_duration=61540.097824, train/accuracy=0.802090, train/loss=0.772878, validation/accuracy=0.727660, validation/loss=1.092850, validation/num_examples=50000
I0303 04:12:59.536413 139881808373504 logging_writer.py:48] [129400] global_step=129400, grad_norm=1.7690714597702026, loss=1.5215280055999756
I0303 04:13:43.878157 139881799980800 logging_writer.py:48] [129500] global_step=129500, grad_norm=1.7837086915969849, loss=2.0462963581085205
I0303 04:14:28.615189 139881808373504 logging_writer.py:48] [129600] global_step=129600, grad_norm=1.978301763534546, loss=3.7500433921813965
I0303 04:15:12.874042 139881799980800 logging_writer.py:48] [129700] global_step=129700, grad_norm=1.7512755393981934, loss=1.705161213874817
I0303 04:15:57.349739 139881808373504 logging_writer.py:48] [129800] global_step=129800, grad_norm=1.8595597743988037, loss=1.9204720258712769
I0303 04:16:42.172832 139881799980800 logging_writer.py:48] [129900] global_step=129900, grad_norm=1.6917332410812378, loss=2.5714876651763916
I0303 04:17:26.719159 139881808373504 logging_writer.py:48] [130000] global_step=130000, grad_norm=1.6809109449386597, loss=3.320739269256592
I0303 04:18:11.096133 139881799980800 logging_writer.py:48] [130100] global_step=130100, grad_norm=1.805343508720398, loss=1.5822718143463135
I0303 04:18:55.929179 139881808373504 logging_writer.py:48] [130200] global_step=130200, grad_norm=1.878260850906372, loss=1.5467900037765503
I0303 04:19:27.390956 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:19:37.699624 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:20:09.361003 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:20:10.947525 140077943854912 submission_runner.py:411] Time since start: 62003.75s, 	Step: 130272, 	{'train/accuracy': 0.8078320026397705, 'train/loss': 0.7349570989608765, 'validation/accuracy': 0.7328199744224548, 'validation/loss': 1.0716028213500977, 'validation/num_examples': 50000, 'test/accuracy': 0.6047000288963318, 'test/loss': 1.7039539813995361, 'test/num_examples': 10000, 'score': 57181.441122055054, 'total_duration': 62003.752519369125, 'accumulated_submission_time': 57181.441122055054, 'accumulated_eval_time': 4809.945647716522, 'accumulated_logging_time': 5.539454460144043}
I0303 04:20:10.989166 139881799980800 logging_writer.py:48] [130272] accumulated_eval_time=4809.945648, accumulated_logging_time=5.539454, accumulated_submission_time=57181.441122, global_step=130272, preemption_count=0, score=57181.441122, test/accuracy=0.604700, test/loss=1.703954, test/num_examples=10000, total_duration=62003.752519, train/accuracy=0.807832, train/loss=0.734957, validation/accuracy=0.732820, validation/loss=1.071603, validation/num_examples=50000
I0303 04:20:22.304155 139881808373504 logging_writer.py:48] [130300] global_step=130300, grad_norm=2.0061936378479004, loss=1.5967482328414917
I0303 04:21:04.326337 139881799980800 logging_writer.py:48] [130400] global_step=130400, grad_norm=2.0367772579193115, loss=1.6265159845352173
I0303 04:21:48.847365 139881808373504 logging_writer.py:48] [130500] global_step=130500, grad_norm=1.9286011457443237, loss=2.502377510070801
I0303 04:22:33.817390 139881799980800 logging_writer.py:48] [130600] global_step=130600, grad_norm=2.0195443630218506, loss=1.600766897201538
I0303 04:23:18.391882 139881808373504 logging_writer.py:48] [130700] global_step=130700, grad_norm=1.9926546812057495, loss=3.7912869453430176
I0303 04:24:03.119842 139881799980800 logging_writer.py:48] [130800] global_step=130800, grad_norm=1.8903758525848389, loss=1.8402808904647827
I0303 04:24:47.485785 139881808373504 logging_writer.py:48] [130900] global_step=130900, grad_norm=1.8005139827728271, loss=1.813786268234253
I0303 04:25:32.124428 139881799980800 logging_writer.py:48] [131000] global_step=131000, grad_norm=2.0090065002441406, loss=1.5411672592163086
I0303 04:26:16.762016 139881808373504 logging_writer.py:48] [131100] global_step=131100, grad_norm=2.048473596572876, loss=1.7831475734710693
I0303 04:27:01.405512 139881799980800 logging_writer.py:48] [131200] global_step=131200, grad_norm=1.9274274110794067, loss=1.574146032333374
I0303 04:27:11.003179 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:27:21.156798 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:27:52.347852 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:27:53.926052 140077943854912 submission_runner.py:411] Time since start: 62466.73s, 	Step: 131223, 	{'train/accuracy': 0.81068354845047, 'train/loss': 0.7343043088912964, 'validation/accuracy': 0.734499990940094, 'validation/loss': 1.0711177587509155, 'validation/num_examples': 50000, 'test/accuracy': 0.6057000160217285, 'test/loss': 1.6870981454849243, 'test/num_examples': 10000, 'score': 57601.39503288269, 'total_duration': 62466.73106837273, 'accumulated_submission_time': 57601.39503288269, 'accumulated_eval_time': 4852.868507862091, 'accumulated_logging_time': 5.591620922088623}
I0303 04:27:53.964301 139881808373504 logging_writer.py:48] [131223] accumulated_eval_time=4852.868508, accumulated_logging_time=5.591621, accumulated_submission_time=57601.395033, global_step=131223, preemption_count=0, score=57601.395033, test/accuracy=0.605700, test/loss=1.687098, test/num_examples=10000, total_duration=62466.731068, train/accuracy=0.810684, train/loss=0.734304, validation/accuracy=0.734500, validation/loss=1.071118, validation/num_examples=50000
I0303 04:28:24.540360 139881799980800 logging_writer.py:48] [131300] global_step=131300, grad_norm=1.821698784828186, loss=3.476318597793579
I0303 04:29:08.805257 139881808373504 logging_writer.py:48] [131400] global_step=131400, grad_norm=2.031257390975952, loss=2.0284295082092285
I0303 04:29:53.257365 139881799980800 logging_writer.py:48] [131500] global_step=131500, grad_norm=2.005643844604492, loss=1.6243782043457031
I0303 04:30:37.994226 139881808373504 logging_writer.py:48] [131600] global_step=131600, grad_norm=1.6972311735153198, loss=2.5468411445617676
I0303 04:31:22.398785 139881799980800 logging_writer.py:48] [131700] global_step=131700, grad_norm=1.9269582033157349, loss=1.5615087747573853
I0303 04:32:06.936623 139881808373504 logging_writer.py:48] [131800] global_step=131800, grad_norm=2.0768988132476807, loss=4.037354469299316
I0303 04:32:51.445139 139881799980800 logging_writer.py:48] [131900] global_step=131900, grad_norm=2.017294406890869, loss=1.5698350667953491
I0303 04:33:35.829059 139881808373504 logging_writer.py:48] [132000] global_step=132000, grad_norm=2.0733680725097656, loss=3.815537929534912
I0303 04:34:20.483789 139881799980800 logging_writer.py:48] [132100] global_step=132100, grad_norm=2.0326120853424072, loss=3.9096336364746094
I0303 04:34:54.025092 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:35:04.265902 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:35:31.887796 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:35:33.476300 140077943854912 submission_runner.py:411] Time since start: 62926.28s, 	Step: 132177, 	{'train/accuracy': 0.8233007788658142, 'train/loss': 0.6953759789466858, 'validation/accuracy': 0.7353000044822693, 'validation/loss': 1.072637915611267, 'validation/num_examples': 50000, 'test/accuracy': 0.6094000339508057, 'test/loss': 1.702414870262146, 'test/num_examples': 10000, 'score': 58021.39619445801, 'total_duration': 62926.28131008148, 'accumulated_submission_time': 58021.39619445801, 'accumulated_eval_time': 4892.319691181183, 'accumulated_logging_time': 5.639818906784058}
I0303 04:35:33.523102 139881808373504 logging_writer.py:48] [132177] accumulated_eval_time=4892.319691, accumulated_logging_time=5.639819, accumulated_submission_time=58021.396194, global_step=132177, preemption_count=0, score=58021.396194, test/accuracy=0.609400, test/loss=1.702415, test/num_examples=10000, total_duration=62926.281310, train/accuracy=0.823301, train/loss=0.695376, validation/accuracy=0.735300, validation/loss=1.072638, validation/num_examples=50000
I0303 04:35:42.894294 139881799980800 logging_writer.py:48] [132200] global_step=132200, grad_norm=2.1428349018096924, loss=3.755422592163086
I0303 04:36:25.191614 139881808373504 logging_writer.py:48] [132300] global_step=132300, grad_norm=2.1019129753112793, loss=1.544266939163208
I0303 04:37:09.655759 139881799980800 logging_writer.py:48] [132400] global_step=132400, grad_norm=1.832152247428894, loss=1.5318342447280884
I0303 04:37:53.937313 139881808373504 logging_writer.py:48] [132500] global_step=132500, grad_norm=2.070024013519287, loss=3.836002826690674
I0303 04:38:38.304749 139881799980800 logging_writer.py:48] [132600] global_step=132600, grad_norm=2.0579161643981934, loss=1.5739012956619263
I0303 04:39:23.136175 139881808373504 logging_writer.py:48] [132700] global_step=132700, grad_norm=1.8083065748214722, loss=2.5779199600219727
I0303 04:40:07.709192 139881799980800 logging_writer.py:48] [132800] global_step=132800, grad_norm=1.9299311637878418, loss=1.8381643295288086
I0303 04:40:52.154501 139881808373504 logging_writer.py:48] [132900] global_step=132900, grad_norm=2.0046305656433105, loss=3.872736930847168
I0303 04:41:36.564816 139881799980800 logging_writer.py:48] [133000] global_step=133000, grad_norm=2.049558401107788, loss=1.588396668434143
I0303 04:42:21.161889 139881808373504 logging_writer.py:48] [133100] global_step=133100, grad_norm=1.942715048789978, loss=1.616773247718811
I0303 04:42:33.764237 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:42:44.125557 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:43:17.470995 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:43:19.047436 140077943854912 submission_runner.py:411] Time since start: 63391.85s, 	Step: 133130, 	{'train/accuracy': 0.8082226514816284, 'train/loss': 0.7451169490814209, 'validation/accuracy': 0.7351199984550476, 'validation/loss': 1.071921944618225, 'validation/num_examples': 50000, 'test/accuracy': 0.6080000400543213, 'test/loss': 1.6945815086364746, 'test/num_examples': 10000, 'score': 58441.57426691055, 'total_duration': 63391.852447748184, 'accumulated_submission_time': 58441.57426691055, 'accumulated_eval_time': 4937.602854728699, 'accumulated_logging_time': 5.699962615966797}
I0303 04:43:19.083109 139881799980800 logging_writer.py:48] [133130] accumulated_eval_time=4937.602855, accumulated_logging_time=5.699963, accumulated_submission_time=58441.574267, global_step=133130, preemption_count=0, score=58441.574267, test/accuracy=0.608000, test/loss=1.694582, test/num_examples=10000, total_duration=63391.852448, train/accuracy=0.808223, train/loss=0.745117, validation/accuracy=0.735120, validation/loss=1.071922, validation/num_examples=50000
I0303 04:43:46.780893 139881808373504 logging_writer.py:48] [133200] global_step=133200, grad_norm=1.9078651666641235, loss=1.6378668546676636
I0303 04:44:30.841716 139881799980800 logging_writer.py:48] [133300] global_step=133300, grad_norm=1.8210068941116333, loss=3.5971105098724365
I0303 04:45:15.597554 139881808373504 logging_writer.py:48] [133400] global_step=133400, grad_norm=1.9628148078918457, loss=1.8939435482025146
I0303 04:45:59.877054 139881799980800 logging_writer.py:48] [133500] global_step=133500, grad_norm=2.0110456943511963, loss=3.79280424118042
I0303 04:46:44.649034 139881808373504 logging_writer.py:48] [133600] global_step=133600, grad_norm=1.7682223320007324, loss=2.3528473377227783
I0303 04:47:29.324393 139881799980800 logging_writer.py:48] [133700] global_step=133700, grad_norm=2.1136767864227295, loss=1.5451375246047974
I0303 04:48:13.903891 139881808373504 logging_writer.py:48] [133800] global_step=133800, grad_norm=2.089254379272461, loss=3.971651077270508
I0303 04:48:58.671363 139881799980800 logging_writer.py:48] [133900] global_step=133900, grad_norm=2.1159682273864746, loss=1.552889108657837
I0303 04:49:43.143834 139881808373504 logging_writer.py:48] [134000] global_step=134000, grad_norm=2.02156400680542, loss=3.9134576320648193
I0303 04:50:19.263997 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:50:29.256486 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:51:03.599770 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:51:05.178330 140077943854912 submission_runner.py:411] Time since start: 63857.98s, 	Step: 134083, 	{'train/accuracy': 0.8153125047683716, 'train/loss': 0.7177433371543884, 'validation/accuracy': 0.7369799613952637, 'validation/loss': 1.052171230316162, 'validation/num_examples': 50000, 'test/accuracy': 0.6075000166893005, 'test/loss': 1.6868488788604736, 'test/num_examples': 10000, 'score': 58861.696504592896, 'total_duration': 63857.983344078064, 'accumulated_submission_time': 58861.696504592896, 'accumulated_eval_time': 4983.517159461975, 'accumulated_logging_time': 5.74588418006897}
I0303 04:51:05.217428 139881799980800 logging_writer.py:48] [134083] accumulated_eval_time=4983.517159, accumulated_logging_time=5.745884, accumulated_submission_time=58861.696505, global_step=134083, preemption_count=0, score=58861.696505, test/accuracy=0.607500, test/loss=1.686849, test/num_examples=10000, total_duration=63857.983344, train/accuracy=0.815313, train/loss=0.717743, validation/accuracy=0.736980, validation/loss=1.052171, validation/num_examples=50000
I0303 04:51:12.235321 139881808373504 logging_writer.py:48] [134100] global_step=134100, grad_norm=1.8913296461105347, loss=1.9461058378219604
I0303 04:51:52.976174 139881799980800 logging_writer.py:48] [134200] global_step=134200, grad_norm=2.0396487712860107, loss=2.711824417114258
I0303 04:52:37.436422 139881808373504 logging_writer.py:48] [134300] global_step=134300, grad_norm=2.1664414405822754, loss=1.492767095565796
I0303 04:53:22.000785 139881799980800 logging_writer.py:48] [134400] global_step=134400, grad_norm=1.8779758214950562, loss=2.421948194503784
I0303 04:54:06.367152 139881808373504 logging_writer.py:48] [134500] global_step=134500, grad_norm=1.9528001546859741, loss=3.409379482269287
I0303 04:54:50.849130 139881799980800 logging_writer.py:48] [134600] global_step=134600, grad_norm=1.93999445438385, loss=1.6662042140960693
I0303 04:55:35.074038 139881808373504 logging_writer.py:48] [134700] global_step=134700, grad_norm=1.8315458297729492, loss=1.728515386581421
I0303 04:56:19.571249 139881799980800 logging_writer.py:48] [134800] global_step=134800, grad_norm=1.9878877401351929, loss=1.5672762393951416
I0303 04:57:04.005484 139881808373504 logging_writer.py:48] [134900] global_step=134900, grad_norm=2.280529022216797, loss=3.9520859718322754
I0303 04:57:48.513102 139881799980800 logging_writer.py:48] [135000] global_step=135000, grad_norm=1.9556068181991577, loss=1.4812419414520264
I0303 04:58:05.196604 140077943854912 spec.py:321] Evaluating on the training split.
I0303 04:58:15.492700 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 04:58:48.142671 140077943854912 spec.py:349] Evaluating on the test split.
I0303 04:58:49.719135 140077943854912 submission_runner.py:411] Time since start: 64322.52s, 	Step: 135039, 	{'train/accuracy': 0.8215429782867432, 'train/loss': 0.6732996702194214, 'validation/accuracy': 0.7372199892997742, 'validation/loss': 1.0496302843093872, 'validation/num_examples': 50000, 'test/accuracy': 0.6113000512123108, 'test/loss': 1.669729232788086, 'test/num_examples': 10000, 'score': 59281.61557817459, 'total_duration': 64322.524144887924, 'accumulated_submission_time': 59281.61557817459, 'accumulated_eval_time': 5028.039650678635, 'accumulated_logging_time': 5.795482873916626}
I0303 04:58:49.755664 139881808373504 logging_writer.py:48] [135039] accumulated_eval_time=5028.039651, accumulated_logging_time=5.795483, accumulated_submission_time=59281.615578, global_step=135039, preemption_count=0, score=59281.615578, test/accuracy=0.611300, test/loss=1.669729, test/num_examples=10000, total_duration=64322.524145, train/accuracy=0.821543, train/loss=0.673300, validation/accuracy=0.737220, validation/loss=1.049630, validation/num_examples=50000
I0303 04:59:13.944683 139881799980800 logging_writer.py:48] [135100] global_step=135100, grad_norm=2.0730998516082764, loss=1.601860761642456
I0303 04:59:57.274061 139881808373504 logging_writer.py:48] [135200] global_step=135200, grad_norm=2.2342934608459473, loss=3.9354395866394043
I0303 05:00:41.704717 139881799980800 logging_writer.py:48] [135300] global_step=135300, grad_norm=2.2005388736724854, loss=3.421550750732422
I0303 05:01:26.250752 139881808373504 logging_writer.py:48] [135400] global_step=135400, grad_norm=1.9645376205444336, loss=1.5886285305023193
I0303 05:02:10.661255 139881799980800 logging_writer.py:48] [135500] global_step=135500, grad_norm=1.922465443611145, loss=2.3998169898986816
I0303 05:02:54.796070 139881808373504 logging_writer.py:48] [135600] global_step=135600, grad_norm=1.976672649383545, loss=3.282778024673462
I0303 05:03:39.212085 139881799980800 logging_writer.py:48] [135700] global_step=135700, grad_norm=1.956322193145752, loss=1.7909682989120483
I0303 05:04:23.706606 139881808373504 logging_writer.py:48] [135800] global_step=135800, grad_norm=2.2059712409973145, loss=3.772017240524292
I0303 05:05:08.180581 139881799980800 logging_writer.py:48] [135900] global_step=135900, grad_norm=1.8377552032470703, loss=1.7555001974105835
I0303 05:05:49.820247 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:05:59.897997 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 05:06:31.774724 140077943854912 spec.py:349] Evaluating on the test split.
I0303 05:06:33.351639 140077943854912 submission_runner.py:411] Time since start: 64786.16s, 	Step: 135996, 	{'train/accuracy': 0.8267382383346558, 'train/loss': 0.6621195673942566, 'validation/accuracy': 0.7412199974060059, 'validation/loss': 1.0311529636383057, 'validation/num_examples': 50000, 'test/accuracy': 0.6158000230789185, 'test/loss': 1.6552666425704956, 'test/num_examples': 10000, 'score': 59701.620468854904, 'total_duration': 64786.15665626526, 'accumulated_submission_time': 59701.620468854904, 'accumulated_eval_time': 5071.571031808853, 'accumulated_logging_time': 5.841874361038208}
I0303 05:06:33.388527 139881808373504 logging_writer.py:48] [135996] accumulated_eval_time=5071.571032, accumulated_logging_time=5.841874, accumulated_submission_time=59701.620469, global_step=135996, preemption_count=0, score=59701.620469, test/accuracy=0.615800, test/loss=1.655267, test/num_examples=10000, total_duration=64786.156656, train/accuracy=0.826738, train/loss=0.662120, validation/accuracy=0.741220, validation/loss=1.031153, validation/num_examples=50000
I0303 05:06:35.336564 139881799980800 logging_writer.py:48] [136000] global_step=136000, grad_norm=2.3031303882598877, loss=3.911379814147949
I0303 05:07:15.928295 139881808373504 logging_writer.py:48] [136100] global_step=136100, grad_norm=2.0649585723876953, loss=1.5770273208618164
I0303 05:08:00.292599 139881799980800 logging_writer.py:48] [136200] global_step=136200, grad_norm=1.9577714204788208, loss=2.846923589706421
I0303 05:08:45.030745 139881808373504 logging_writer.py:48] [136300] global_step=136300, grad_norm=1.871591329574585, loss=1.4256093502044678
I0303 05:09:30.271547 139881799980800 logging_writer.py:48] [136400] global_step=136400, grad_norm=2.271354913711548, loss=3.6106255054473877
I0303 05:10:14.589227 139881808373504 logging_writer.py:48] [136500] global_step=136500, grad_norm=2.0676310062408447, loss=1.6019126176834106
I0303 05:10:58.989834 139881799980800 logging_writer.py:48] [136600] global_step=136600, grad_norm=1.8910638093948364, loss=2.006197452545166
I0303 05:11:43.478221 139881808373504 logging_writer.py:48] [136700] global_step=136700, grad_norm=1.7523210048675537, loss=2.011385679244995
I0303 05:12:28.089926 139881799980800 logging_writer.py:48] [136800] global_step=136800, grad_norm=2.132927656173706, loss=1.8020834922790527
I0303 05:13:12.496341 139881808373504 logging_writer.py:48] [136900] global_step=136900, grad_norm=2.1036248207092285, loss=2.9702107906341553
I0303 05:13:33.394491 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:13:43.504686 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 05:14:18.474769 140077943854912 spec.py:349] Evaluating on the test split.
I0303 05:14:20.061235 140077943854912 submission_runner.py:411] Time since start: 65252.87s, 	Step: 136949, 	{'train/accuracy': 0.81689453125, 'train/loss': 0.7047690153121948, 'validation/accuracy': 0.7401599884033203, 'validation/loss': 1.0472062826156616, 'validation/num_examples': 50000, 'test/accuracy': 0.6136000156402588, 'test/loss': 1.6724987030029297, 'test/num_examples': 10000, 'score': 60121.56489992142, 'total_duration': 65252.8662545681, 'accumulated_submission_time': 60121.56489992142, 'accumulated_eval_time': 5118.237744569778, 'accumulated_logging_time': 5.8914642333984375}
I0303 05:14:20.097206 139881799980800 logging_writer.py:48] [136949] accumulated_eval_time=5118.237745, accumulated_logging_time=5.891464, accumulated_submission_time=60121.564900, global_step=136949, preemption_count=0, score=60121.564900, test/accuracy=0.613600, test/loss=1.672499, test/num_examples=10000, total_duration=65252.866255, train/accuracy=0.816895, train/loss=0.704769, validation/accuracy=0.740160, validation/loss=1.047206, validation/num_examples=50000
I0303 05:14:40.387902 139881808373504 logging_writer.py:48] [137000] global_step=137000, grad_norm=1.9997419118881226, loss=1.5083813667297363
I0303 05:15:23.347351 139881799980800 logging_writer.py:48] [137100] global_step=137100, grad_norm=1.9491597414016724, loss=2.003998041152954
I0303 05:16:07.699523 139881808373504 logging_writer.py:48] [137200] global_step=137200, grad_norm=2.0592172145843506, loss=3.489550828933716
I0303 05:16:52.310246 139881799980800 logging_writer.py:48] [137300] global_step=137300, grad_norm=2.0722219944000244, loss=2.993201971054077
I0303 05:17:36.909682 139881808373504 logging_writer.py:48] [137400] global_step=137400, grad_norm=1.9928991794586182, loss=2.570222854614258
I0303 05:18:21.283733 139881799980800 logging_writer.py:48] [137500] global_step=137500, grad_norm=1.9569206237792969, loss=1.8200809955596924
I0303 05:19:05.585678 139881808373504 logging_writer.py:48] [137600] global_step=137600, grad_norm=2.3111534118652344, loss=1.5874931812286377
I0303 05:19:50.099175 139881799980800 logging_writer.py:48] [137700] global_step=137700, grad_norm=2.0983850955963135, loss=2.2553648948669434
I0303 05:20:34.396708 139881808373504 logging_writer.py:48] [137800] global_step=137800, grad_norm=2.145638942718506, loss=1.477339267730713
I0303 05:21:18.872469 139881799980800 logging_writer.py:48] [137900] global_step=137900, grad_norm=2.013803243637085, loss=1.4780173301696777
I0303 05:21:20.363065 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:21:30.739186 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 05:21:56.290789 140077943854912 spec.py:349] Evaluating on the test split.
I0303 05:21:57.882042 140077943854912 submission_runner.py:411] Time since start: 65710.69s, 	Step: 137905, 	{'train/accuracy': 0.8246093392372131, 'train/loss': 0.6600923538208008, 'validation/accuracy': 0.7413600087165833, 'validation/loss': 1.0288509130477905, 'validation/num_examples': 50000, 'test/accuracy': 0.6154000163078308, 'test/loss': 1.6639049053192139, 'test/num_examples': 10000, 'score': 60541.76283168793, 'total_duration': 65710.68705844879, 'accumulated_submission_time': 60541.76283168793, 'accumulated_eval_time': 5155.756701231003, 'accumulated_logging_time': 5.945829391479492}
I0303 05:21:57.922572 139881808373504 logging_writer.py:48] [137905] accumulated_eval_time=5155.756701, accumulated_logging_time=5.945829, accumulated_submission_time=60541.762832, global_step=137905, preemption_count=0, score=60541.762832, test/accuracy=0.615400, test/loss=1.663905, test/num_examples=10000, total_duration=65710.687058, train/accuracy=0.824609, train/loss=0.660092, validation/accuracy=0.741360, validation/loss=1.028851, validation/num_examples=50000
I0303 05:22:36.281000 139881799980800 logging_writer.py:48] [138000] global_step=138000, grad_norm=2.015462875366211, loss=2.6099205017089844
I0303 05:23:20.603890 139881808373504 logging_writer.py:48] [138100] global_step=138100, grad_norm=1.8835725784301758, loss=3.3358044624328613
I0303 05:24:05.354607 139881799980800 logging_writer.py:48] [138200] global_step=138200, grad_norm=2.0498456954956055, loss=1.5733662843704224
I0303 05:24:49.832147 139881808373504 logging_writer.py:48] [138300] global_step=138300, grad_norm=2.0848050117492676, loss=1.6728706359863281
I0303 05:25:34.253939 139881799980800 logging_writer.py:48] [138400] global_step=138400, grad_norm=2.1404953002929688, loss=1.8141201734542847
I0303 05:26:18.778544 139881808373504 logging_writer.py:48] [138500] global_step=138500, grad_norm=2.042074680328369, loss=1.8189061880111694
I0303 05:27:03.336786 139881799980800 logging_writer.py:48] [138600] global_step=138600, grad_norm=2.077633857727051, loss=1.6268320083618164
I0303 05:27:47.880744 139881808373504 logging_writer.py:48] [138700] global_step=138700, grad_norm=2.027259111404419, loss=1.5714025497436523
I0303 05:28:32.339443 139881799980800 logging_writer.py:48] [138800] global_step=138800, grad_norm=2.033386707305908, loss=1.4783027172088623
I0303 05:28:58.276106 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:29:08.674159 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 05:29:36.818303 140077943854912 spec.py:349] Evaluating on the test split.
I0303 05:29:38.398226 140077943854912 submission_runner.py:411] Time since start: 66171.20s, 	Step: 138860, 	{'train/accuracy': 0.8321484327316284, 'train/loss': 0.6528514623641968, 'validation/accuracy': 0.7429599761962891, 'validation/loss': 1.038433313369751, 'validation/num_examples': 50000, 'test/accuracy': 0.6155000329017639, 'test/loss': 1.6657668352127075, 'test/num_examples': 10000, 'score': 60962.057092905045, 'total_duration': 66171.20323944092, 'accumulated_submission_time': 60962.057092905045, 'accumulated_eval_time': 5195.878809213638, 'accumulated_logging_time': 5.996556520462036}
I0303 05:29:38.434846 139881808373504 logging_writer.py:48] [138860] accumulated_eval_time=5195.878809, accumulated_logging_time=5.996557, accumulated_submission_time=60962.057093, global_step=138860, preemption_count=0, score=60962.057093, test/accuracy=0.615500, test/loss=1.665767, test/num_examples=10000, total_duration=66171.203239, train/accuracy=0.832148, train/loss=0.652851, validation/accuracy=0.742960, validation/loss=1.038433, validation/num_examples=50000
I0303 05:29:54.438161 139881799980800 logging_writer.py:48] [138900] global_step=138900, grad_norm=2.037747859954834, loss=1.6316380500793457
I0303 05:30:36.315464 139881808373504 logging_writer.py:48] [139000] global_step=139000, grad_norm=2.051459789276123, loss=1.4218894243240356
I0303 05:31:21.020852 139881799980800 logging_writer.py:48] [139100] global_step=139100, grad_norm=2.1475419998168945, loss=3.441762924194336
I0303 05:32:05.731637 139881808373504 logging_writer.py:48] [139200] global_step=139200, grad_norm=1.942327857017517, loss=2.335838794708252
I0303 05:32:50.183134 139881799980800 logging_writer.py:48] [139300] global_step=139300, grad_norm=1.9908469915390015, loss=2.472456932067871
I0303 05:33:34.489154 139881808373504 logging_writer.py:48] [139400] global_step=139400, grad_norm=2.215162515640259, loss=1.4304860830307007
I0303 05:34:19.120301 139881799980800 logging_writer.py:48] [139500] global_step=139500, grad_norm=2.1497480869293213, loss=1.6593754291534424
I0303 05:35:03.587667 139881808373504 logging_writer.py:48] [139600] global_step=139600, grad_norm=2.2095425128936768, loss=3.402813196182251
I0303 05:35:47.703603 139881799980800 logging_writer.py:48] [139700] global_step=139700, grad_norm=2.130948066711426, loss=1.6357603073120117
I0303 05:36:32.192960 139881808373504 logging_writer.py:48] [139800] global_step=139800, grad_norm=2.0987703800201416, loss=1.4993987083435059
I0303 05:36:38.590152 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:36:48.856181 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 05:37:19.486152 140077943854912 spec.py:349] Evaluating on the test split.
I0303 05:37:21.069070 140077943854912 submission_runner.py:411] Time since start: 66633.87s, 	Step: 139816, 	{'train/accuracy': 0.8234570026397705, 'train/loss': 0.6648285388946533, 'validation/accuracy': 0.7445200085639954, 'validation/loss': 1.0157908201217651, 'validation/num_examples': 50000, 'test/accuracy': 0.6185000538825989, 'test/loss': 1.6386992931365967, 'test/num_examples': 10000, 'score': 61382.15120720863, 'total_duration': 66633.87408804893, 'accumulated_submission_time': 61382.15120720863, 'accumulated_eval_time': 5238.357710123062, 'accumulated_logging_time': 6.045234203338623}
I0303 05:37:21.109877 139881799980800 logging_writer.py:48] [139816] accumulated_eval_time=5238.357710, accumulated_logging_time=6.045234, accumulated_submission_time=61382.151207, global_step=139816, preemption_count=0, score=61382.151207, test/accuracy=0.618500, test/loss=1.638699, test/num_examples=10000, total_duration=66633.874088, train/accuracy=0.823457, train/loss=0.664829, validation/accuracy=0.744520, validation/loss=1.015791, validation/num_examples=50000
I0303 05:37:54.332594 139881808373504 logging_writer.py:48] [139900] global_step=139900, grad_norm=2.017911434173584, loss=1.5326578617095947
I0303 05:38:38.574533 139881799980800 logging_writer.py:48] [140000] global_step=140000, grad_norm=2.08113956451416, loss=2.988739252090454
I0303 05:39:22.855015 139881808373504 logging_writer.py:48] [140100] global_step=140100, grad_norm=2.0268805027008057, loss=2.444550037384033
I0303 05:40:07.359477 139881799980800 logging_writer.py:48] [140200] global_step=140200, grad_norm=2.3324074745178223, loss=3.411353826522827
I0303 05:40:51.496783 139881808373504 logging_writer.py:48] [140300] global_step=140300, grad_norm=2.152042865753174, loss=1.8800959587097168
I0303 05:41:36.169557 139881799980800 logging_writer.py:48] [140400] global_step=140400, grad_norm=2.13038969039917, loss=1.6858396530151367
I0303 05:42:20.461458 139881808373504 logging_writer.py:48] [140500] global_step=140500, grad_norm=2.187002658843994, loss=1.5039327144622803
I0303 05:43:05.021774 139881799980800 logging_writer.py:48] [140600] global_step=140600, grad_norm=2.3035218715667725, loss=1.493882656097412
I0303 05:43:49.377204 139881808373504 logging_writer.py:48] [140700] global_step=140700, grad_norm=2.4072206020355225, loss=1.57802152633667
I0303 05:44:21.456203 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:44:31.643850 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 05:44:58.569018 140077943854912 spec.py:349] Evaluating on the test split.
I0303 05:45:00.151551 140077943854912 submission_runner.py:411] Time since start: 67092.96s, 	Step: 140773, 	{'train/accuracy': 0.8301171660423279, 'train/loss': 0.6384050846099854, 'validation/accuracy': 0.7467399835586548, 'validation/loss': 1.0131675004959106, 'validation/num_examples': 50000, 'test/accuracy': 0.6203000545501709, 'test/loss': 1.6408082246780396, 'test/num_examples': 10000, 'score': 61802.4379234314, 'total_duration': 67092.95656824112, 'accumulated_submission_time': 61802.4379234314, 'accumulated_eval_time': 5277.053035020828, 'accumulated_logging_time': 6.096495151519775}
I0303 05:45:00.189256 139881799980800 logging_writer.py:48] [140773] accumulated_eval_time=5277.053035, accumulated_logging_time=6.096495, accumulated_submission_time=61802.437923, global_step=140773, preemption_count=0, score=61802.437923, test/accuracy=0.620300, test/loss=1.640808, test/num_examples=10000, total_duration=67092.956568, train/accuracy=0.830117, train/loss=0.638405, validation/accuracy=0.746740, validation/loss=1.013168, validation/num_examples=50000
I0303 05:45:11.115920 139881808373504 logging_writer.py:48] [140800] global_step=140800, grad_norm=2.181689500808716, loss=1.4869214296340942
I0303 05:45:52.533090 139881799980800 logging_writer.py:48] [140900] global_step=140900, grad_norm=2.303734064102173, loss=3.7317216396331787
I0303 05:46:37.004913 139881808373504 logging_writer.py:48] [141000] global_step=141000, grad_norm=2.134465456008911, loss=1.7070562839508057
I0303 05:47:21.640031 139881799980800 logging_writer.py:48] [141100] global_step=141100, grad_norm=2.025275230407715, loss=1.6274230480194092
I0303 05:48:05.792395 139881808373504 logging_writer.py:48] [141200] global_step=141200, grad_norm=2.019702672958374, loss=2.246107339859009
I0303 05:48:50.124717 139881799980800 logging_writer.py:48] [141300] global_step=141300, grad_norm=1.991369366645813, loss=2.4070279598236084
I0303 05:49:34.713042 139881808373504 logging_writer.py:48] [141400] global_step=141400, grad_norm=2.1797401905059814, loss=1.6066920757293701
I0303 05:50:19.166447 139881799980800 logging_writer.py:48] [141500] global_step=141500, grad_norm=1.9919463396072388, loss=1.3915115594863892
I0303 05:51:03.888257 139881808373504 logging_writer.py:48] [141600] global_step=141600, grad_norm=2.167212724685669, loss=1.5093512535095215
I0303 05:51:48.317912 139881799980800 logging_writer.py:48] [141700] global_step=141700, grad_norm=2.010711908340454, loss=1.8688217401504517
I0303 05:52:00.345195 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:52:10.840556 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 05:52:42.251387 140077943854912 spec.py:349] Evaluating on the test split.
I0303 05:52:43.842322 140077943854912 submission_runner.py:411] Time since start: 67556.65s, 	Step: 141729, 	{'train/accuracy': 0.8341015577316284, 'train/loss': 0.6274772882461548, 'validation/accuracy': 0.7470999956130981, 'validation/loss': 1.0052226781845093, 'validation/num_examples': 50000, 'test/accuracy': 0.6189000010490417, 'test/loss': 1.641674518585205, 'test/num_examples': 10000, 'score': 62222.53354215622, 'total_duration': 67556.64731407166, 'accumulated_submission_time': 62222.53354215622, 'accumulated_eval_time': 5320.5501408576965, 'accumulated_logging_time': 6.1448814868927}
I0303 05:52:43.888034 139881808373504 logging_writer.py:48] [141729] accumulated_eval_time=5320.550141, accumulated_logging_time=6.144881, accumulated_submission_time=62222.533542, global_step=141729, preemption_count=0, score=62222.533542, test/accuracy=0.618900, test/loss=1.641675, test/num_examples=10000, total_duration=67556.647314, train/accuracy=0.834102, train/loss=0.627477, validation/accuracy=0.747100, validation/loss=1.005223, validation/num_examples=50000
I0303 05:53:11.987093 139881799980800 logging_writer.py:48] [141800] global_step=141800, grad_norm=2.202913284301758, loss=3.2422780990600586
I0303 05:53:55.747119 139881808373504 logging_writer.py:48] [141900] global_step=141900, grad_norm=2.3883492946624756, loss=3.610060453414917
I0303 05:54:40.458457 139881799980800 logging_writer.py:48] [142000] global_step=142000, grad_norm=2.247283935546875, loss=1.5392861366271973
I0303 05:55:24.643630 139881808373504 logging_writer.py:48] [142100] global_step=142100, grad_norm=2.1150600910186768, loss=1.477198839187622
I0303 05:56:09.145341 139881799980800 logging_writer.py:48] [142200] global_step=142200, grad_norm=1.9543596506118774, loss=2.1278796195983887
I0303 05:56:53.528500 139881808373504 logging_writer.py:48] [142300] global_step=142300, grad_norm=2.1166539192199707, loss=2.9992401599884033
I0303 05:57:38.188626 139881799980800 logging_writer.py:48] [142400] global_step=142400, grad_norm=2.1068947315216064, loss=2.932380199432373
I0303 05:58:22.749495 139881808373504 logging_writer.py:48] [142500] global_step=142500, grad_norm=2.3508665561676025, loss=3.3292388916015625
I0303 05:59:07.346118 139881799980800 logging_writer.py:48] [142600] global_step=142600, grad_norm=2.30908203125, loss=1.371453881263733
I0303 05:59:43.877419 140077943854912 spec.py:321] Evaluating on the training split.
I0303 05:59:54.011165 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:00:27.861075 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:00:29.440109 140077943854912 submission_runner.py:411] Time since start: 68022.25s, 	Step: 142683, 	{'train/accuracy': 0.8469530940055847, 'train/loss': 0.5803266167640686, 'validation/accuracy': 0.749239981174469, 'validation/loss': 0.993854284286499, 'validation/num_examples': 50000, 'test/accuracy': 0.6233000159263611, 'test/loss': 1.6336963176727295, 'test/num_examples': 10000, 'score': 62642.4606757164, 'total_duration': 68022.24512600899, 'accumulated_submission_time': 62642.4606757164, 'accumulated_eval_time': 5366.112824201584, 'accumulated_logging_time': 6.20355749130249}
I0303 06:00:29.479588 139881808373504 logging_writer.py:48] [142683] accumulated_eval_time=5366.112824, accumulated_logging_time=6.203557, accumulated_submission_time=62642.460676, global_step=142683, preemption_count=0, score=62642.460676, test/accuracy=0.623300, test/loss=1.633696, test/num_examples=10000, total_duration=68022.245126, train/accuracy=0.846953, train/loss=0.580327, validation/accuracy=0.749240, validation/loss=0.993854, validation/num_examples=50000
I0303 06:00:36.479406 139881799980800 logging_writer.py:48] [142700] global_step=142700, grad_norm=2.8829760551452637, loss=3.7410783767700195
I0303 06:01:17.239943 139881808373504 logging_writer.py:48] [142800] global_step=142800, grad_norm=2.138472318649292, loss=3.0751161575317383
I0303 06:02:01.656967 139881799980800 logging_writer.py:48] [142900] global_step=142900, grad_norm=2.12536883354187, loss=1.6306589841842651
I0303 06:02:46.300815 139881808373504 logging_writer.py:48] [143000] global_step=143000, grad_norm=2.3872761726379395, loss=3.664504289627075
I0303 06:03:30.483747 139881799980800 logging_writer.py:48] [143100] global_step=143100, grad_norm=2.064042329788208, loss=2.0011723041534424
I0303 06:04:14.896247 139881808373504 logging_writer.py:48] [143200] global_step=143200, grad_norm=2.153925657272339, loss=2.611299514770508
I0303 06:04:59.050051 139881799980800 logging_writer.py:48] [143300] global_step=143300, grad_norm=2.170889139175415, loss=1.5215866565704346
I0303 06:05:43.379492 139881808373504 logging_writer.py:48] [143400] global_step=143400, grad_norm=2.2220571041107178, loss=1.573272943496704
I0303 06:06:27.953258 139881799980800 logging_writer.py:48] [143500] global_step=143500, grad_norm=2.463831663131714, loss=3.4275569915771484
I0303 06:07:12.407305 139881808373504 logging_writer.py:48] [143600] global_step=143600, grad_norm=2.143902063369751, loss=3.399467706680298
I0303 06:07:29.851752 140077943854912 spec.py:321] Evaluating on the training split.
I0303 06:07:40.086325 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:08:09.972521 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:08:11.566561 140077943854912 submission_runner.py:411] Time since start: 68484.37s, 	Step: 143641, 	{'train/accuracy': 0.8289452791213989, 'train/loss': 0.6445606350898743, 'validation/accuracy': 0.7488399744033813, 'validation/loss': 0.999646782875061, 'validation/num_examples': 50000, 'test/accuracy': 0.6241000294685364, 'test/loss': 1.6271873712539673, 'test/num_examples': 10000, 'score': 63062.7713201046, 'total_duration': 68484.37150168419, 'accumulated_submission_time': 63062.7713201046, 'accumulated_eval_time': 5407.827532052994, 'accumulated_logging_time': 6.254222393035889}
I0303 06:08:11.638203 139881799980800 logging_writer.py:48] [143641] accumulated_eval_time=5407.827532, accumulated_logging_time=6.254222, accumulated_submission_time=63062.771320, global_step=143641, preemption_count=0, score=63062.771320, test/accuracy=0.624100, test/loss=1.627187, test/num_examples=10000, total_duration=68484.371502, train/accuracy=0.828945, train/loss=0.644561, validation/accuracy=0.748840, validation/loss=0.999647, validation/num_examples=50000
I0303 06:08:35.041168 139881808373504 logging_writer.py:48] [143700] global_step=143700, grad_norm=2.066972494125366, loss=1.4507304430007935
I0303 06:09:18.359539 139881799980800 logging_writer.py:48] [143800] global_step=143800, grad_norm=2.0793399810791016, loss=1.5485049486160278
I0303 06:10:02.542119 139881808373504 logging_writer.py:48] [143900] global_step=143900, grad_norm=2.297154664993286, loss=1.953434705734253
I0303 06:10:47.100403 139881799980800 logging_writer.py:48] [144000] global_step=144000, grad_norm=2.25972580909729, loss=1.5240384340286255
I0303 06:11:31.655583 139881808373504 logging_writer.py:48] [144100] global_step=144100, grad_norm=2.132218837738037, loss=1.3990832567214966
I0303 06:12:16.372454 139881799980800 logging_writer.py:48] [144200] global_step=144200, grad_norm=2.3609020709991455, loss=1.5044386386871338
I0303 06:13:00.719581 139881808373504 logging_writer.py:48] [144300] global_step=144300, grad_norm=2.413395643234253, loss=3.2470643520355225
I0303 06:13:45.210828 139881799980800 logging_writer.py:48] [144400] global_step=144400, grad_norm=2.3110852241516113, loss=1.3325486183166504
I0303 06:14:29.678636 139881808373504 logging_writer.py:48] [144500] global_step=144500, grad_norm=2.2360777854919434, loss=1.5453166961669922
I0303 06:15:11.718769 140077943854912 spec.py:321] Evaluating on the training split.
I0303 06:15:22.028648 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:15:51.745040 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:15:53.334950 140077943854912 submission_runner.py:411] Time since start: 68946.14s, 	Step: 144596, 	{'train/accuracy': 0.8374804258346558, 'train/loss': 0.6231352686882019, 'validation/accuracy': 0.7511799931526184, 'validation/loss': 0.9905893206596375, 'validation/num_examples': 50000, 'test/accuracy': 0.6246000528335571, 'test/loss': 1.6112269163131714, 'test/num_examples': 10000, 'score': 63482.79140949249, 'total_duration': 68946.13994860649, 'accumulated_submission_time': 63482.79140949249, 'accumulated_eval_time': 5449.443675994873, 'accumulated_logging_time': 6.337775707244873}
I0303 06:15:53.384291 139881799980800 logging_writer.py:48] [144596] accumulated_eval_time=5449.443676, accumulated_logging_time=6.337776, accumulated_submission_time=63482.791409, global_step=144596, preemption_count=0, score=63482.791409, test/accuracy=0.624600, test/loss=1.611227, test/num_examples=10000, total_duration=68946.139949, train/accuracy=0.837480, train/loss=0.623135, validation/accuracy=0.751180, validation/loss=0.990589, validation/num_examples=50000
I0303 06:15:55.369011 139881808373504 logging_writer.py:48] [144600] global_step=144600, grad_norm=2.3078200817108154, loss=1.8826172351837158
I0303 06:16:36.324122 139881799980800 logging_writer.py:48] [144700] global_step=144700, grad_norm=2.3881428241729736, loss=3.511035919189453
I0303 06:17:20.709114 139881808373504 logging_writer.py:48] [144800] global_step=144800, grad_norm=2.395995616912842, loss=1.4050896167755127
I0303 06:18:05.414746 139881799980800 logging_writer.py:48] [144900] global_step=144900, grad_norm=2.308406352996826, loss=1.4217429161071777
I0303 06:18:49.696866 139881808373504 logging_writer.py:48] [145000] global_step=145000, grad_norm=2.3650710582733154, loss=1.4365297555923462
I0303 06:19:34.061443 139881799980800 logging_writer.py:48] [145100] global_step=145100, grad_norm=2.123516798019409, loss=1.508435606956482
I0303 06:20:18.704315 139881808373504 logging_writer.py:48] [145200] global_step=145200, grad_norm=2.1347644329071045, loss=1.8031967878341675
I0303 06:21:03.049218 139881799980800 logging_writer.py:48] [145300] global_step=145300, grad_norm=2.411886215209961, loss=1.468390703201294
I0303 06:21:47.425926 139881808373504 logging_writer.py:48] [145400] global_step=145400, grad_norm=2.2165749073028564, loss=2.884230375289917
I0303 06:22:31.891825 139881799980800 logging_writer.py:48] [145500] global_step=145500, grad_norm=2.3511078357696533, loss=1.4814369678497314
I0303 06:22:53.672090 140077943854912 spec.py:321] Evaluating on the training split.
I0303 06:23:04.079822 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:23:39.599225 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:23:41.181309 140077943854912 submission_runner.py:411] Time since start: 69413.99s, 	Step: 145551, 	{'train/accuracy': 0.842578113079071, 'train/loss': 0.6011013984680176, 'validation/accuracy': 0.7515400052070618, 'validation/loss': 0.997151792049408, 'validation/num_examples': 50000, 'test/accuracy': 0.6222000122070312, 'test/loss': 1.6284139156341553, 'test/num_examples': 10000, 'score': 63903.018033504486, 'total_duration': 69413.98632764816, 'accumulated_submission_time': 63903.018033504486, 'accumulated_eval_time': 5496.952882766724, 'accumulated_logging_time': 6.3996031284332275}
I0303 06:23:41.218778 139881808373504 logging_writer.py:48] [145551] accumulated_eval_time=5496.952883, accumulated_logging_time=6.399603, accumulated_submission_time=63903.018034, global_step=145551, preemption_count=0, score=63903.018034, test/accuracy=0.622200, test/loss=1.628414, test/num_examples=10000, total_duration=69413.986328, train/accuracy=0.842578, train/loss=0.601101, validation/accuracy=0.751540, validation/loss=0.997152, validation/num_examples=50000
I0303 06:24:00.727423 139881799980800 logging_writer.py:48] [145600] global_step=145600, grad_norm=2.220283031463623, loss=3.093435525894165
I0303 06:24:43.580700 139881808373504 logging_writer.py:48] [145700] global_step=145700, grad_norm=2.1344635486602783, loss=1.3826661109924316
I0303 06:25:28.091281 139881799980800 logging_writer.py:48] [145800] global_step=145800, grad_norm=2.267979621887207, loss=1.558459758758545
I0303 06:26:12.485161 139881808373504 logging_writer.py:48] [145900] global_step=145900, grad_norm=2.169198513031006, loss=1.395936369895935
I0303 06:26:56.973077 139881799980800 logging_writer.py:48] [146000] global_step=146000, grad_norm=2.5722339153289795, loss=3.2224035263061523
I0303 06:27:41.336495 139881808373504 logging_writer.py:48] [146100] global_step=146100, grad_norm=2.1212568283081055, loss=1.4648940563201904
I0303 06:28:25.653122 139881799980800 logging_writer.py:48] [146200] global_step=146200, grad_norm=2.308781147003174, loss=1.6190279722213745
I0303 06:29:09.969565 139881808373504 logging_writer.py:48] [146300] global_step=146300, grad_norm=2.2201972007751465, loss=1.84171724319458
I0303 06:29:54.711323 139881799980800 logging_writer.py:48] [146400] global_step=146400, grad_norm=2.1943445205688477, loss=1.3712289333343506
I0303 06:30:39.050441 139881808373504 logging_writer.py:48] [146500] global_step=146500, grad_norm=2.293543577194214, loss=3.3869235515594482
I0303 06:30:41.389134 140077943854912 spec.py:321] Evaluating on the training split.
I0303 06:30:51.288732 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:31:22.497431 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:31:24.088201 140077943854912 submission_runner.py:411] Time since start: 69876.89s, 	Step: 146507, 	{'train/accuracy': 0.8387304544448853, 'train/loss': 0.6057491898536682, 'validation/accuracy': 0.7545599937438965, 'validation/loss': 0.975864589214325, 'validation/num_examples': 50000, 'test/accuracy': 0.6258000135421753, 'test/loss': 1.6044663190841675, 'test/num_examples': 10000, 'score': 64323.128088235855, 'total_duration': 69876.89319229126, 'accumulated_submission_time': 64323.128088235855, 'accumulated_eval_time': 5539.651907920837, 'accumulated_logging_time': 6.44763708114624}
I0303 06:31:24.135439 139881799980800 logging_writer.py:48] [146507] accumulated_eval_time=5539.651908, accumulated_logging_time=6.447637, accumulated_submission_time=64323.128088, global_step=146507, preemption_count=0, score=64323.128088, test/accuracy=0.625800, test/loss=1.604466, test/num_examples=10000, total_duration=69876.893192, train/accuracy=0.838730, train/loss=0.605749, validation/accuracy=0.754560, validation/loss=0.975865, validation/num_examples=50000
I0303 06:32:01.570205 139881808373504 logging_writer.py:48] [146600] global_step=146600, grad_norm=2.267911911010742, loss=1.4799214601516724
I0303 06:32:45.902551 139881799980800 logging_writer.py:48] [146700] global_step=146700, grad_norm=2.142381429672241, loss=3.2597594261169434
I0303 06:33:30.478718 139881808373504 logging_writer.py:48] [146800] global_step=146800, grad_norm=2.322819948196411, loss=2.028061628341675
I0303 06:34:14.679682 139881799980800 logging_writer.py:48] [146900] global_step=146900, grad_norm=2.4029688835144043, loss=1.5290203094482422
I0303 06:34:59.272968 139881808373504 logging_writer.py:48] [147000] global_step=147000, grad_norm=2.4436824321746826, loss=1.5609372854232788
I0303 06:35:43.879970 139881799980800 logging_writer.py:48] [147100] global_step=147100, grad_norm=2.3341331481933594, loss=2.0342652797698975
I0303 06:36:28.454473 139881808373504 logging_writer.py:48] [147200] global_step=147200, grad_norm=2.3239808082580566, loss=1.4737635850906372
I0303 06:37:12.782868 139881799980800 logging_writer.py:48] [147300] global_step=147300, grad_norm=2.6379611492156982, loss=3.630406618118286
I0303 06:37:57.084045 139881808373504 logging_writer.py:48] [147400] global_step=147400, grad_norm=2.5666611194610596, loss=3.514662265777588
I0303 06:38:24.106235 140077943854912 spec.py:321] Evaluating on the training split.
I0303 06:38:34.194241 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:38:59.573013 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:39:01.161732 140077943854912 submission_runner.py:411] Time since start: 70333.97s, 	Step: 147462, 	{'train/accuracy': 0.8384374976158142, 'train/loss': 0.630463719367981, 'validation/accuracy': 0.7534799575805664, 'validation/loss': 0.9893783330917358, 'validation/num_examples': 50000, 'test/accuracy': 0.6244000196456909, 'test/loss': 1.6166449785232544, 'test/num_examples': 10000, 'score': 64743.03775429726, 'total_duration': 70333.96669006348, 'accumulated_submission_time': 64743.03775429726, 'accumulated_eval_time': 5576.7073402404785, 'accumulated_logging_time': 6.506728172302246}
I0303 06:39:01.209981 139881799980800 logging_writer.py:48] [147462] accumulated_eval_time=5576.707340, accumulated_logging_time=6.506728, accumulated_submission_time=64743.037754, global_step=147462, preemption_count=0, score=64743.037754, test/accuracy=0.624400, test/loss=1.616645, test/num_examples=10000, total_duration=70333.966690, train/accuracy=0.838437, train/loss=0.630464, validation/accuracy=0.753480, validation/loss=0.989378, validation/num_examples=50000
I0303 06:39:16.431996 139881808373504 logging_writer.py:48] [147500] global_step=147500, grad_norm=2.4280307292938232, loss=3.236302375793457
I0303 06:39:58.465158 139881799980800 logging_writer.py:48] [147600] global_step=147600, grad_norm=2.4206185340881348, loss=1.574375033378601
I0303 06:40:42.929300 139881808373504 logging_writer.py:48] [147700] global_step=147700, grad_norm=2.449497938156128, loss=3.5146944522857666
I0303 06:41:27.179919 139881799980800 logging_writer.py:48] [147800] global_step=147800, grad_norm=2.215383529663086, loss=2.7533533573150635
I0303 06:42:11.364247 139881808373504 logging_writer.py:48] [147900] global_step=147900, grad_norm=2.7726171016693115, loss=1.5384047031402588
I0303 06:42:55.578928 139881799980800 logging_writer.py:48] [148000] global_step=148000, grad_norm=2.185845375061035, loss=1.8083906173706055
I0303 06:43:39.665000 139881808373504 logging_writer.py:48] [148100] global_step=148100, grad_norm=2.756728410720825, loss=2.8807356357574463
I0303 06:44:24.280277 139881799980800 logging_writer.py:48] [148200] global_step=148200, grad_norm=2.208078622817993, loss=1.4357051849365234
I0303 06:45:08.612787 139881808373504 logging_writer.py:48] [148300] global_step=148300, grad_norm=2.2378153800964355, loss=2.07159161567688
I0303 06:45:52.904628 139881799980800 logging_writer.py:48] [148400] global_step=148400, grad_norm=2.068162202835083, loss=2.5116360187530518
I0303 06:46:01.395166 140077943854912 spec.py:321] Evaluating on the training split.
I0303 06:46:11.753333 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:46:41.779206 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:46:43.355138 140077943854912 submission_runner.py:411] Time since start: 70796.16s, 	Step: 148421, 	{'train/accuracy': 0.8456249833106995, 'train/loss': 0.5935382843017578, 'validation/accuracy': 0.7538999915122986, 'validation/loss': 0.9789702296257019, 'validation/num_examples': 50000, 'test/accuracy': 0.6320000290870667, 'test/loss': 1.5996073484420776, 'test/num_examples': 10000, 'score': 65163.15673828125, 'total_duration': 70796.16014623642, 'accumulated_submission_time': 65163.15673828125, 'accumulated_eval_time': 5618.667296886444, 'accumulated_logging_time': 6.567543268203735}
I0303 06:46:43.394131 139881808373504 logging_writer.py:48] [148421] accumulated_eval_time=5618.667297, accumulated_logging_time=6.567543, accumulated_submission_time=65163.156738, global_step=148421, preemption_count=0, score=65163.156738, test/accuracy=0.632000, test/loss=1.599607, test/num_examples=10000, total_duration=70796.160146, train/accuracy=0.845625, train/loss=0.593538, validation/accuracy=0.753900, validation/loss=0.978970, validation/num_examples=50000
I0303 06:47:14.628492 139881799980800 logging_writer.py:48] [148500] global_step=148500, grad_norm=2.302860736846924, loss=1.4412105083465576
I0303 06:47:58.635639 139881808373504 logging_writer.py:48] [148600] global_step=148600, grad_norm=2.1344711780548096, loss=2.157452344894409
I0303 06:48:43.092603 139881799980800 logging_writer.py:48] [148700] global_step=148700, grad_norm=2.769000768661499, loss=3.7053415775299072
I0303 06:49:27.345023 139881808373504 logging_writer.py:48] [148800] global_step=148800, grad_norm=2.2762978076934814, loss=3.177408218383789
I0303 06:50:12.105675 139881799980800 logging_writer.py:48] [148900] global_step=148900, grad_norm=2.2549803256988525, loss=1.4644235372543335
I0303 06:50:56.558089 139881808373504 logging_writer.py:48] [149000] global_step=149000, grad_norm=2.3851640224456787, loss=3.359740734100342
I0303 06:51:40.793581 139881799980800 logging_writer.py:48] [149100] global_step=149100, grad_norm=2.379960775375366, loss=1.4021382331848145
I0303 06:52:25.449869 139881808373504 logging_writer.py:48] [149200] global_step=149200, grad_norm=2.6668310165405273, loss=3.1928529739379883
I0303 06:53:10.003561 139881799980800 logging_writer.py:48] [149300] global_step=149300, grad_norm=2.4713006019592285, loss=2.758146047592163
I0303 06:53:43.806924 140077943854912 spec.py:321] Evaluating on the training split.
I0303 06:53:53.943425 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 06:54:23.681977 140077943854912 spec.py:349] Evaluating on the test split.
I0303 06:54:25.260381 140077943854912 submission_runner.py:411] Time since start: 71258.07s, 	Step: 149378, 	{'train/accuracy': 0.8524218797683716, 'train/loss': 0.5529924035072327, 'validation/accuracy': 0.7565799951553345, 'validation/loss': 0.9650366306304932, 'validation/num_examples': 50000, 'test/accuracy': 0.6299000382423401, 'test/loss': 1.5885131359100342, 'test/num_examples': 10000, 'score': 65583.5103931427, 'total_duration': 71258.06540131569, 'accumulated_submission_time': 65583.5103931427, 'accumulated_eval_time': 5660.120743513107, 'accumulated_logging_time': 6.616364240646362}
I0303 06:54:25.298837 139881808373504 logging_writer.py:48] [149378] accumulated_eval_time=5660.120744, accumulated_logging_time=6.616364, accumulated_submission_time=65583.510393, global_step=149378, preemption_count=0, score=65583.510393, test/accuracy=0.629900, test/loss=1.588513, test/num_examples=10000, total_duration=71258.065401, train/accuracy=0.852422, train/loss=0.552992, validation/accuracy=0.756580, validation/loss=0.965037, validation/num_examples=50000
I0303 06:54:34.266948 139881799980800 logging_writer.py:48] [149400] global_step=149400, grad_norm=2.3889596462249756, loss=1.8376367092132568
I0303 06:55:15.490731 139881808373504 logging_writer.py:48] [149500] global_step=149500, grad_norm=2.6686689853668213, loss=1.46907377243042
I0303 06:55:59.833717 139881799980800 logging_writer.py:48] [149600] global_step=149600, grad_norm=2.571521520614624, loss=3.7258176803588867
I0303 06:56:44.743002 139881808373504 logging_writer.py:48] [149700] global_step=149700, grad_norm=2.332894802093506, loss=1.3896769285202026
I0303 06:57:29.109126 139881799980800 logging_writer.py:48] [149800] global_step=149800, grad_norm=2.3505589962005615, loss=1.368310809135437
I0303 06:58:13.411045 139881808373504 logging_writer.py:48] [149900] global_step=149900, grad_norm=2.482602596282959, loss=1.4362256526947021
I0303 06:58:57.646492 139881799980800 logging_writer.py:48] [150000] global_step=150000, grad_norm=2.2362072467803955, loss=1.3245210647583008
I0303 06:59:41.994026 139881808373504 logging_writer.py:48] [150100] global_step=150100, grad_norm=2.5730769634246826, loss=1.3409219980239868
I0303 07:00:26.558257 139881799980800 logging_writer.py:48] [150200] global_step=150200, grad_norm=2.481285572052002, loss=2.100099563598633
I0303 07:01:11.176688 139881808373504 logging_writer.py:48] [150300] global_step=150300, grad_norm=2.40706205368042, loss=1.381101131439209
I0303 07:01:25.613741 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:01:35.784756 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:02:11.758195 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:02:13.336319 140077943854912 submission_runner.py:411] Time since start: 71726.14s, 	Step: 150334, 	{'train/accuracy': 0.8441210985183716, 'train/loss': 0.5873963832855225, 'validation/accuracy': 0.7583999633789062, 'validation/loss': 0.9608394503593445, 'validation/num_examples': 50000, 'test/accuracy': 0.6344000101089478, 'test/loss': 1.5788832902908325, 'test/num_examples': 10000, 'score': 66003.76546001434, 'total_duration': 71726.14133667946, 'accumulated_submission_time': 66003.76546001434, 'accumulated_eval_time': 5707.843321084976, 'accumulated_logging_time': 6.665755748748779}
I0303 07:02:13.377206 139881799980800 logging_writer.py:48] [150334] accumulated_eval_time=5707.843321, accumulated_logging_time=6.665756, accumulated_submission_time=66003.765460, global_step=150334, preemption_count=0, score=66003.765460, test/accuracy=0.634400, test/loss=1.578883, test/num_examples=10000, total_duration=71726.141337, train/accuracy=0.844121, train/loss=0.587396, validation/accuracy=0.758400, validation/loss=0.960839, validation/num_examples=50000
I0303 07:02:39.515796 139881808373504 logging_writer.py:48] [150400] global_step=150400, grad_norm=2.315042495727539, loss=1.3453046083450317
I0303 07:03:22.824818 139881799980800 logging_writer.py:48] [150500] global_step=150500, grad_norm=2.4407095909118652, loss=1.4648401737213135
I0303 07:04:07.301911 139881808373504 logging_writer.py:48] [150600] global_step=150600, grad_norm=2.6048989295959473, loss=1.4054622650146484
I0303 07:04:51.539029 139881799980800 logging_writer.py:48] [150700] global_step=150700, grad_norm=2.300354242324829, loss=1.455750823020935
I0303 07:05:36.008537 139881808373504 logging_writer.py:48] [150800] global_step=150800, grad_norm=2.520775318145752, loss=1.2954617738723755
I0303 07:06:20.540577 139881799980800 logging_writer.py:48] [150900] global_step=150900, grad_norm=2.8110361099243164, loss=3.636579990386963
I0303 07:07:05.325518 139881808373504 logging_writer.py:48] [151000] global_step=151000, grad_norm=2.7245991230010986, loss=3.130462169647217
I0303 07:07:49.786559 139881799980800 logging_writer.py:48] [151100] global_step=151100, grad_norm=2.3178601264953613, loss=1.629897117614746
I0303 07:08:34.505414 139881808373504 logging_writer.py:48] [151200] global_step=151200, grad_norm=2.2902908325195312, loss=1.4613075256347656
I0303 07:09:13.773839 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:09:24.128380 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:09:58.128413 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:09:59.707161 140077943854912 submission_runner.py:411] Time since start: 72192.51s, 	Step: 151290, 	{'train/accuracy': 0.8487499952316284, 'train/loss': 0.5678128004074097, 'validation/accuracy': 0.7597799897193909, 'validation/loss': 0.949147641658783, 'validation/num_examples': 50000, 'test/accuracy': 0.6296000480651855, 'test/loss': 1.5756335258483887, 'test/num_examples': 10000, 'score': 66424.10148477554, 'total_duration': 72192.51217556, 'accumulated_submission_time': 66424.10148477554, 'accumulated_eval_time': 5753.7766098976135, 'accumulated_logging_time': 6.717709302902222}
I0303 07:09:59.749047 139881799980800 logging_writer.py:48] [151290] accumulated_eval_time=5753.776610, accumulated_logging_time=6.717709, accumulated_submission_time=66424.101485, global_step=151290, preemption_count=0, score=66424.101485, test/accuracy=0.629600, test/loss=1.575634, test/num_examples=10000, total_duration=72192.512176, train/accuracy=0.848750, train/loss=0.567813, validation/accuracy=0.759780, validation/loss=0.949148, validation/num_examples=50000
I0303 07:10:04.026200 139881808373504 logging_writer.py:48] [151300] global_step=151300, grad_norm=2.3362834453582764, loss=2.1783735752105713
I0303 07:10:45.050762 139881799980800 logging_writer.py:48] [151400] global_step=151400, grad_norm=3.121887683868408, loss=3.604145050048828
I0303 07:11:29.204258 139881808373504 logging_writer.py:48] [151500] global_step=151500, grad_norm=2.8137753009796143, loss=3.5957119464874268
I0303 07:12:13.795368 139881799980800 logging_writer.py:48] [151600] global_step=151600, grad_norm=2.359064817428589, loss=1.4645724296569824
I0303 07:12:57.872040 139881808373504 logging_writer.py:48] [151700] global_step=151700, grad_norm=2.507233142852783, loss=3.5769028663635254
I0303 07:13:42.506388 139881799980800 logging_writer.py:48] [151800] global_step=151800, grad_norm=2.679264545440674, loss=3.3486063480377197
I0303 07:14:27.006792 139881808373504 logging_writer.py:48] [151900] global_step=151900, grad_norm=2.3693976402282715, loss=1.4184116125106812
I0303 07:15:11.362131 139881799980800 logging_writer.py:48] [152000] global_step=152000, grad_norm=2.466010570526123, loss=2.783299684524536
I0303 07:15:55.723082 139881808373504 logging_writer.py:48] [152100] global_step=152100, grad_norm=2.181213140487671, loss=1.980973720550537
I0303 07:16:40.197993 139881799980800 logging_writer.py:48] [152200] global_step=152200, grad_norm=2.3480143547058105, loss=2.7322020530700684
I0303 07:16:59.858251 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:17:10.144437 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:17:37.651299 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:17:39.232489 140077943854912 submission_runner.py:411] Time since start: 72652.04s, 	Step: 152246, 	{'train/accuracy': 0.8516015410423279, 'train/loss': 0.5689120888710022, 'validation/accuracy': 0.7590599656105042, 'validation/loss': 0.9657217860221863, 'validation/num_examples': 50000, 'test/accuracy': 0.6332000494003296, 'test/loss': 1.5770167112350464, 'test/num_examples': 10000, 'score': 66844.15052103996, 'total_duration': 72652.03750824928, 'accumulated_submission_time': 66844.15052103996, 'accumulated_eval_time': 5793.150819063187, 'accumulated_logging_time': 6.770383834838867}
I0303 07:17:39.271130 139881808373504 logging_writer.py:48] [152246] accumulated_eval_time=5793.150819, accumulated_logging_time=6.770384, accumulated_submission_time=66844.150521, global_step=152246, preemption_count=0, score=66844.150521, test/accuracy=0.633200, test/loss=1.577017, test/num_examples=10000, total_duration=72652.037508, train/accuracy=0.851602, train/loss=0.568912, validation/accuracy=0.759060, validation/loss=0.965722, validation/num_examples=50000
I0303 07:18:00.718125 139881799980800 logging_writer.py:48] [152300] global_step=152300, grad_norm=2.4935667514801025, loss=3.134371042251587
I0303 07:18:43.744566 139881808373504 logging_writer.py:48] [152400] global_step=152400, grad_norm=2.351919651031494, loss=2.210826873779297
I0303 07:19:28.325557 139881799980800 logging_writer.py:48] [152500] global_step=152500, grad_norm=2.6110332012176514, loss=1.3142836093902588
I0303 07:20:13.153287 139881808373504 logging_writer.py:48] [152600] global_step=152600, grad_norm=2.1972827911376953, loss=2.5821797847747803
I0303 07:20:57.752185 139881799980800 logging_writer.py:48] [152700] global_step=152700, grad_norm=2.365633010864258, loss=1.3048375844955444
I0303 07:21:42.246865 139881808373504 logging_writer.py:48] [152800] global_step=152800, grad_norm=2.551595687866211, loss=1.444556713104248
I0303 07:22:26.697441 139881799980800 logging_writer.py:48] [152900] global_step=152900, grad_norm=2.34633731842041, loss=1.6666011810302734
I0303 07:23:11.011837 139881808373504 logging_writer.py:48] [153000] global_step=153000, grad_norm=2.536871910095215, loss=1.6470375061035156
I0303 07:23:55.559320 139881799980800 logging_writer.py:48] [153100] global_step=153100, grad_norm=2.288107395172119, loss=1.557585597038269
I0303 07:24:39.280268 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:24:50.094346 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:25:18.801002 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:25:20.391715 140077943854912 submission_runner.py:411] Time since start: 73113.20s, 	Step: 153200, 	{'train/accuracy': 0.8597851395606995, 'train/loss': 0.5119295120239258, 'validation/accuracy': 0.7633399963378906, 'validation/loss': 0.9361425638198853, 'validation/num_examples': 50000, 'test/accuracy': 0.638700008392334, 'test/loss': 1.5545070171356201, 'test/num_examples': 10000, 'score': 67264.09875321388, 'total_duration': 73113.19673418999, 'accumulated_submission_time': 67264.09875321388, 'accumulated_eval_time': 5834.262246847153, 'accumulated_logging_time': 6.820079565048218}
I0303 07:25:20.435540 139881808373504 logging_writer.py:48] [153200] accumulated_eval_time=5834.262247, accumulated_logging_time=6.820080, accumulated_submission_time=67264.098753, global_step=153200, preemption_count=0, score=67264.098753, test/accuracy=0.638700, test/loss=1.554507, test/num_examples=10000, total_duration=73113.196734, train/accuracy=0.859785, train/loss=0.511930, validation/accuracy=0.763340, validation/loss=0.936143, validation/num_examples=50000
I0303 07:25:20.827424 139881799980800 logging_writer.py:48] [153200] global_step=153200, grad_norm=2.648202657699585, loss=1.3478792905807495
I0303 07:26:00.691955 139881808373504 logging_writer.py:48] [153300] global_step=153300, grad_norm=2.400726079940796, loss=1.3733139038085938
I0303 07:26:45.268532 139881799980800 logging_writer.py:48] [153400] global_step=153400, grad_norm=2.26541805267334, loss=2.3161251544952393
I0303 07:27:30.192355 139881808373504 logging_writer.py:48] [153500] global_step=153500, grad_norm=2.75673770904541, loss=1.3112281560897827
I0303 07:28:14.872991 139881799980800 logging_writer.py:48] [153600] global_step=153600, grad_norm=2.4027955532073975, loss=1.3733141422271729
I0303 07:28:59.502041 139881808373504 logging_writer.py:48] [153700] global_step=153700, grad_norm=2.353288173675537, loss=2.446037530899048
I0303 07:29:43.926652 139881799980800 logging_writer.py:48] [153800] global_step=153800, grad_norm=2.557786226272583, loss=1.3974881172180176
I0303 07:30:28.651037 139881808373504 logging_writer.py:48] [153900] global_step=153900, grad_norm=2.6232666969299316, loss=2.972836494445801
I0303 07:31:13.015562 139881799980800 logging_writer.py:48] [154000] global_step=154000, grad_norm=2.3974761962890625, loss=2.1908228397369385
I0303 07:31:57.406965 139881808373504 logging_writer.py:48] [154100] global_step=154100, grad_norm=2.590893507003784, loss=1.3467447757720947
I0303 07:32:20.692953 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:32:30.865683 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:33:00.652895 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:33:02.249384 140077943854912 submission_runner.py:411] Time since start: 73575.05s, 	Step: 154154, 	{'train/accuracy': 0.8531835675239563, 'train/loss': 0.5538952350616455, 'validation/accuracy': 0.7621200084686279, 'validation/loss': 0.9444466233253479, 'validation/num_examples': 50000, 'test/accuracy': 0.6413000226020813, 'test/loss': 1.5551538467407227, 'test/num_examples': 10000, 'score': 67684.29598784447, 'total_duration': 73575.05439019203, 'accumulated_submission_time': 67684.29598784447, 'accumulated_eval_time': 5875.818645477295, 'accumulated_logging_time': 6.8744797706604}
I0303 07:33:02.296853 139881799980800 logging_writer.py:48] [154154] accumulated_eval_time=5875.818645, accumulated_logging_time=6.874480, accumulated_submission_time=67684.295988, global_step=154154, preemption_count=0, score=67684.295988, test/accuracy=0.641300, test/loss=1.555154, test/num_examples=10000, total_duration=73575.054390, train/accuracy=0.853184, train/loss=0.553895, validation/accuracy=0.762120, validation/loss=0.944447, validation/num_examples=50000
I0303 07:33:20.799064 139881808373504 logging_writer.py:48] [154200] global_step=154200, grad_norm=2.6324849128723145, loss=1.3884586095809937
I0303 07:34:03.336579 139881799980800 logging_writer.py:48] [154300] global_step=154300, grad_norm=2.4179062843322754, loss=1.415671944618225
I0303 07:34:47.678025 139881808373504 logging_writer.py:48] [154400] global_step=154400, grad_norm=2.7607717514038086, loss=1.5948272943496704
I0303 07:35:32.091204 139881799980800 logging_writer.py:48] [154500] global_step=154500, grad_norm=2.505045175552368, loss=1.4165260791778564
I0303 07:36:16.136866 139881808373504 logging_writer.py:48] [154600] global_step=154600, grad_norm=2.4648892879486084, loss=1.4028990268707275
I0303 07:37:00.422456 139881799980800 logging_writer.py:48] [154700] global_step=154700, grad_norm=2.2951056957244873, loss=1.3223601579666138
I0303 07:37:44.870261 139881808373504 logging_writer.py:48] [154800] global_step=154800, grad_norm=2.723180055618286, loss=1.4922678470611572
I0303 07:38:29.291099 139881799980800 logging_writer.py:48] [154900] global_step=154900, grad_norm=2.495997905731201, loss=1.367963194847107
I0303 07:39:13.624977 139881808373504 logging_writer.py:48] [155000] global_step=155000, grad_norm=2.539036989212036, loss=1.2990977764129639
I0303 07:39:57.639992 139881799980800 logging_writer.py:48] [155100] global_step=155100, grad_norm=2.57431697845459, loss=2.201900005340576
I0303 07:40:02.356342 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:40:12.759611 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:40:44.044227 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:40:45.630673 140077943854912 submission_runner.py:411] Time since start: 74038.44s, 	Step: 155112, 	{'train/accuracy': 0.8586328029632568, 'train/loss': 0.5334701538085938, 'validation/accuracy': 0.7653200030326843, 'validation/loss': 0.9409710168838501, 'validation/num_examples': 50000, 'test/accuracy': 0.6392000317573547, 'test/loss': 1.5500725507736206, 'test/num_examples': 10000, 'score': 68104.2943456173, 'total_duration': 74038.43568396568, 'accumulated_submission_time': 68104.2943456173, 'accumulated_eval_time': 5919.092953443527, 'accumulated_logging_time': 6.933387756347656}
I0303 07:40:45.669538 139881808373504 logging_writer.py:48] [155112] accumulated_eval_time=5919.092953, accumulated_logging_time=6.933388, accumulated_submission_time=68104.294346, global_step=155112, preemption_count=0, score=68104.294346, test/accuracy=0.639200, test/loss=1.550073, test/num_examples=10000, total_duration=74038.435684, train/accuracy=0.858633, train/loss=0.533470, validation/accuracy=0.765320, validation/loss=0.940971, validation/num_examples=50000
I0303 07:41:20.709675 139881799980800 logging_writer.py:48] [155200] global_step=155200, grad_norm=2.482189416885376, loss=2.712794542312622
I0303 07:42:04.802166 139881808373504 logging_writer.py:48] [155300] global_step=155300, grad_norm=2.4079771041870117, loss=1.2334105968475342
I0303 07:42:49.520547 139881799980800 logging_writer.py:48] [155400] global_step=155400, grad_norm=2.4405152797698975, loss=1.25290846824646
I0303 07:43:33.944478 139881808373504 logging_writer.py:48] [155500] global_step=155500, grad_norm=2.573922872543335, loss=1.3844560384750366
I0303 07:44:18.368364 139881799980800 logging_writer.py:48] [155600] global_step=155600, grad_norm=2.5864319801330566, loss=1.2911124229431152
I0303 07:45:02.921274 139881808373504 logging_writer.py:48] [155700] global_step=155700, grad_norm=2.4727513790130615, loss=1.3218085765838623
I0303 07:45:47.048614 139881799980800 logging_writer.py:48] [155800] global_step=155800, grad_norm=2.917445421218872, loss=3.5294671058654785
I0303 07:46:31.600795 139881808373504 logging_writer.py:48] [155900] global_step=155900, grad_norm=2.2015891075134277, loss=2.2719852924346924
I0303 07:47:16.329829 139881799980800 logging_writer.py:48] [156000] global_step=156000, grad_norm=2.690369129180908, loss=1.4369316101074219
I0303 07:47:45.912541 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:47:56.314978 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:48:26.315245 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:48:27.899830 140077943854912 submission_runner.py:411] Time since start: 74500.70s, 	Step: 156069, 	{'train/accuracy': 0.8615820407867432, 'train/loss': 0.5220953822135925, 'validation/accuracy': 0.7646399736404419, 'validation/loss': 0.9310302138328552, 'validation/num_examples': 50000, 'test/accuracy': 0.6394000053405762, 'test/loss': 1.5504746437072754, 'test/num_examples': 10000, 'score': 68524.47574973106, 'total_duration': 74500.70484685898, 'accumulated_submission_time': 68524.47574973106, 'accumulated_eval_time': 5961.080224990845, 'accumulated_logging_time': 6.984781265258789}
I0303 07:48:27.942749 139881808373504 logging_writer.py:48] [156069] accumulated_eval_time=5961.080225, accumulated_logging_time=6.984781, accumulated_submission_time=68524.475750, global_step=156069, preemption_count=0, score=68524.475750, test/accuracy=0.639400, test/loss=1.550475, test/num_examples=10000, total_duration=74500.704847, train/accuracy=0.861582, train/loss=0.522095, validation/accuracy=0.764640, validation/loss=0.931030, validation/num_examples=50000
I0303 07:48:40.413921 139881799980800 logging_writer.py:48] [156100] global_step=156100, grad_norm=2.5949456691741943, loss=1.227463960647583
I0303 07:49:22.183773 139881808373504 logging_writer.py:48] [156200] global_step=156200, grad_norm=2.4982829093933105, loss=1.2362849712371826
I0303 07:50:06.424935 139881799980800 logging_writer.py:48] [156300] global_step=156300, grad_norm=2.4330620765686035, loss=1.459195613861084
I0303 07:50:50.863204 139881808373504 logging_writer.py:48] [156400] global_step=156400, grad_norm=2.2985100746154785, loss=2.4269211292266846
I0303 07:51:35.243246 139881799980800 logging_writer.py:48] [156500] global_step=156500, grad_norm=2.793793201446533, loss=1.2494609355926514
I0303 07:52:19.614541 139881808373504 logging_writer.py:48] [156600] global_step=156600, grad_norm=2.7532927989959717, loss=3.069544792175293
I0303 07:53:04.029902 139881799980800 logging_writer.py:48] [156700] global_step=156700, grad_norm=2.740722894668579, loss=3.2381703853607178
I0303 07:53:48.409162 139881808373504 logging_writer.py:48] [156800] global_step=156800, grad_norm=2.671635150909424, loss=1.4190497398376465
I0303 07:54:33.023932 139881799980800 logging_writer.py:48] [156900] global_step=156900, grad_norm=2.6740145683288574, loss=1.5697823762893677
I0303 07:55:17.500734 139881808373504 logging_writer.py:48] [157000] global_step=157000, grad_norm=2.535999298095703, loss=1.2497689723968506
I0303 07:55:28.182126 140077943854912 spec.py:321] Evaluating on the training split.
I0303 07:55:38.187473 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 07:56:07.237764 140077943854912 spec.py:349] Evaluating on the test split.
I0303 07:56:08.822403 140077943854912 submission_runner.py:411] Time since start: 74961.63s, 	Step: 157026, 	{'train/accuracy': 0.8561913967132568, 'train/loss': 0.5413217544555664, 'validation/accuracy': 0.7650399804115295, 'validation/loss': 0.9309642910957336, 'validation/num_examples': 50000, 'test/accuracy': 0.6401000022888184, 'test/loss': 1.5474493503570557, 'test/num_examples': 10000, 'score': 68944.65562939644, 'total_duration': 74961.62737870216, 'accumulated_submission_time': 68944.65562939644, 'accumulated_eval_time': 6001.720447778702, 'accumulated_logging_time': 7.037832736968994}
I0303 07:56:08.873942 139881799980800 logging_writer.py:48] [157026] accumulated_eval_time=6001.720448, accumulated_logging_time=7.037833, accumulated_submission_time=68944.655629, global_step=157026, preemption_count=0, score=68944.655629, test/accuracy=0.640100, test/loss=1.547449, test/num_examples=10000, total_duration=74961.627379, train/accuracy=0.856191, train/loss=0.541322, validation/accuracy=0.765040, validation/loss=0.930964, validation/num_examples=50000
I0303 07:56:39.003062 139881808373504 logging_writer.py:48] [157100] global_step=157100, grad_norm=2.578415870666504, loss=1.2917940616607666
I0303 07:57:23.253041 139881799980800 logging_writer.py:48] [157200] global_step=157200, grad_norm=2.7712349891662598, loss=1.2949180603027344
I0303 07:58:08.082113 139881808373504 logging_writer.py:48] [157300] global_step=157300, grad_norm=2.7226336002349854, loss=2.257952928543091
I0303 07:58:52.630473 139881799980800 logging_writer.py:48] [157400] global_step=157400, grad_norm=2.495594024658203, loss=1.2834692001342773
I0303 07:59:36.914443 139881808373504 logging_writer.py:48] [157500] global_step=157500, grad_norm=2.5466792583465576, loss=1.277982234954834
I0303 08:00:21.192312 139881799980800 logging_writer.py:48] [157600] global_step=157600, grad_norm=2.2728078365325928, loss=1.2253340482711792
I0303 08:01:05.885355 139881808373504 logging_writer.py:48] [157700] global_step=157700, grad_norm=2.473740816116333, loss=2.2579498291015625
I0303 08:01:50.208752 139881799980800 logging_writer.py:48] [157800] global_step=157800, grad_norm=2.7344555854797363, loss=1.3898180723190308
I0303 08:02:34.815458 139881808373504 logging_writer.py:48] [157900] global_step=157900, grad_norm=2.740065097808838, loss=1.4848604202270508
I0303 08:03:09.208591 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:03:19.555854 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:03:47.806848 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:03:49.405315 140077943854912 submission_runner.py:411] Time since start: 75422.21s, 	Step: 157979, 	{'train/accuracy': 0.8600585460662842, 'train/loss': 0.5279272794723511, 'validation/accuracy': 0.7641599774360657, 'validation/loss': 0.9306029677391052, 'validation/num_examples': 50000, 'test/accuracy': 0.6416000127792358, 'test/loss': 1.5486117601394653, 'test/num_examples': 10000, 'score': 69364.08955550194, 'total_duration': 75422.21031832695, 'accumulated_submission_time': 69364.08955550194, 'accumulated_eval_time': 6041.917126655579, 'accumulated_logging_time': 7.940981864929199}
I0303 08:03:49.454591 139881799980800 logging_writer.py:48] [157979] accumulated_eval_time=6041.917127, accumulated_logging_time=7.940982, accumulated_submission_time=69364.089556, global_step=157979, preemption_count=0, score=69364.089556, test/accuracy=0.641600, test/loss=1.548612, test/num_examples=10000, total_duration=75422.210318, train/accuracy=0.860059, train/loss=0.527927, validation/accuracy=0.764160, validation/loss=0.930603, validation/num_examples=50000
I0303 08:03:58.049448 139881808373504 logging_writer.py:48] [158000] global_step=158000, grad_norm=2.4568655490875244, loss=1.2647738456726074
I0303 08:04:39.511384 139881799980800 logging_writer.py:48] [158100] global_step=158100, grad_norm=2.5738930702209473, loss=2.046886444091797
I0303 08:05:24.134735 139881808373504 logging_writer.py:48] [158200] global_step=158200, grad_norm=2.5209357738494873, loss=3.0649609565734863
I0303 08:06:08.424258 139881799980800 logging_writer.py:48] [158300] global_step=158300, grad_norm=2.7309787273406982, loss=2.0131301879882812
I0303 08:06:52.664784 139881808373504 logging_writer.py:48] [158400] global_step=158400, grad_norm=2.415097951889038, loss=2.796893358230591
I0303 08:07:36.983729 139881799980800 logging_writer.py:48] [158500] global_step=158500, grad_norm=2.401911497116089, loss=1.6681098937988281
I0303 08:08:21.393582 139881808373504 logging_writer.py:48] [158600] global_step=158600, grad_norm=2.392643451690674, loss=1.7684006690979004
I0303 08:09:06.034370 139881799980800 logging_writer.py:48] [158700] global_step=158700, grad_norm=3.5229315757751465, loss=3.539619207382202
I0303 08:09:49.939765 139881808373504 logging_writer.py:48] [158800] global_step=158800, grad_norm=2.570298194885254, loss=1.7346723079681396
I0303 08:10:34.406099 139881799980800 logging_writer.py:48] [158900] global_step=158900, grad_norm=2.4542627334594727, loss=1.3566615581512451
I0303 08:10:49.578579 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:10:59.842976 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:11:31.421102 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:11:33.008953 140077943854912 submission_runner.py:411] Time since start: 75885.81s, 	Step: 158936, 	{'train/accuracy': 0.8643164038658142, 'train/loss': 0.5127362608909607, 'validation/accuracy': 0.768619954586029, 'validation/loss': 0.9249874949455261, 'validation/num_examples': 50000, 'test/accuracy': 0.6457000374794006, 'test/loss': 1.527753233909607, 'test/num_examples': 10000, 'score': 69784.15007662773, 'total_duration': 75885.81394910812, 'accumulated_submission_time': 69784.15007662773, 'accumulated_eval_time': 6085.347447156906, 'accumulated_logging_time': 8.00169324874878}
I0303 08:11:33.058191 139881808373504 logging_writer.py:48] [158936] accumulated_eval_time=6085.347447, accumulated_logging_time=8.001693, accumulated_submission_time=69784.150077, global_step=158936, preemption_count=0, score=69784.150077, test/accuracy=0.645700, test/loss=1.527753, test/num_examples=10000, total_duration=75885.813949, train/accuracy=0.864316, train/loss=0.512736, validation/accuracy=0.768620, validation/loss=0.924987, validation/num_examples=50000
I0303 08:11:58.457843 139881799980800 logging_writer.py:48] [159000] global_step=159000, grad_norm=2.7597765922546387, loss=2.9325027465820312
I0303 08:12:42.170840 139881808373504 logging_writer.py:48] [159100] global_step=159100, grad_norm=2.6736643314361572, loss=1.2657498121261597
I0303 08:13:27.055986 139881799980800 logging_writer.py:48] [159200] global_step=159200, grad_norm=2.433544158935547, loss=2.0576367378234863
I0303 08:14:11.507216 139881808373504 logging_writer.py:48] [159300] global_step=159300, grad_norm=2.6269659996032715, loss=1.290763258934021
I0303 08:14:55.925384 139881799980800 logging_writer.py:48] [159400] global_step=159400, grad_norm=2.593074083328247, loss=1.276130199432373
I0303 08:15:40.521038 139881808373504 logging_writer.py:48] [159500] global_step=159500, grad_norm=2.6078925132751465, loss=1.2363288402557373
I0303 08:16:24.910301 139881799980800 logging_writer.py:48] [159600] global_step=159600, grad_norm=2.584266424179077, loss=1.8406013250350952
I0303 08:17:09.332361 139881808373504 logging_writer.py:48] [159700] global_step=159700, grad_norm=2.6736900806427, loss=1.358264684677124
I0303 08:17:53.800430 139881799980800 logging_writer.py:48] [159800] global_step=159800, grad_norm=2.772331953048706, loss=3.2818973064422607
I0303 08:18:33.400495 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:18:43.737833 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:19:14.307265 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:19:15.907337 140077943854912 submission_runner.py:411] Time since start: 76348.71s, 	Step: 159891, 	{'train/accuracy': 0.8702148199081421, 'train/loss': 0.484088271856308, 'validation/accuracy': 0.7680000066757202, 'validation/loss': 0.9140318632125854, 'validation/num_examples': 50000, 'test/accuracy': 0.6384000182151794, 'test/loss': 1.5375657081604004, 'test/num_examples': 10000, 'score': 70204.42936730385, 'total_duration': 76348.71235513687, 'accumulated_submission_time': 70204.42936730385, 'accumulated_eval_time': 6127.854299068451, 'accumulated_logging_time': 8.064128637313843}
I0303 08:19:15.950062 139881808373504 logging_writer.py:48] [159891] accumulated_eval_time=6127.854299, accumulated_logging_time=8.064129, accumulated_submission_time=70204.429367, global_step=159891, preemption_count=0, score=70204.429367, test/accuracy=0.638400, test/loss=1.537566, test/num_examples=10000, total_duration=76348.712355, train/accuracy=0.870215, train/loss=0.484088, validation/accuracy=0.768000, validation/loss=0.914032, validation/num_examples=50000
I0303 08:19:19.844361 139881799980800 logging_writer.py:48] [159900] global_step=159900, grad_norm=2.7025115489959717, loss=2.580702066421509
I0303 08:20:00.514919 139881808373504 logging_writer.py:48] [160000] global_step=160000, grad_norm=3.930030107498169, loss=3.599353313446045
I0303 08:20:44.572565 139881799980800 logging_writer.py:48] [160100] global_step=160100, grad_norm=3.208364725112915, loss=3.1239144802093506
I0303 08:21:29.095098 139881808373504 logging_writer.py:48] [160200] global_step=160200, grad_norm=3.0973198413848877, loss=1.8265442848205566
I0303 08:22:13.467064 139881799980800 logging_writer.py:48] [160300] global_step=160300, grad_norm=2.4341938495635986, loss=1.2198619842529297
I0303 08:22:57.774080 139881808373504 logging_writer.py:48] [160400] global_step=160400, grad_norm=3.981651544570923, loss=3.525908946990967
I0303 08:23:42.548864 139881799980800 logging_writer.py:48] [160500] global_step=160500, grad_norm=2.542057514190674, loss=1.1673855781555176
I0303 08:24:26.884718 139881808373504 logging_writer.py:48] [160600] global_step=160600, grad_norm=2.9872822761535645, loss=2.4753010272979736
I0303 08:25:11.342219 139881799980800 logging_writer.py:48] [160700] global_step=160700, grad_norm=2.8030619621276855, loss=1.3504128456115723
I0303 08:25:55.790753 139881808373504 logging_writer.py:48] [160800] global_step=160800, grad_norm=2.727017641067505, loss=2.1815474033355713
I0303 08:26:16.124025 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:26:26.917242 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:27:02.088852 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:27:03.671227 140077943854912 submission_runner.py:411] Time since start: 76816.48s, 	Step: 160847, 	{'train/accuracy': 0.8659570217132568, 'train/loss': 0.5069062113761902, 'validation/accuracy': 0.7679399847984314, 'validation/loss': 0.9168761372566223, 'validation/num_examples': 50000, 'test/accuracy': 0.64410001039505, 'test/loss': 1.5222582817077637, 'test/num_examples': 10000, 'score': 70624.54157876968, 'total_duration': 76816.47623872757, 'accumulated_submission_time': 70624.54157876968, 'accumulated_eval_time': 6175.40148806572, 'accumulated_logging_time': 8.118890523910522}
I0303 08:27:03.714804 139881799980800 logging_writer.py:48] [160847] accumulated_eval_time=6175.401488, accumulated_logging_time=8.118891, accumulated_submission_time=70624.541579, global_step=160847, preemption_count=0, score=70624.541579, test/accuracy=0.644100, test/loss=1.522258, test/num_examples=10000, total_duration=76816.476239, train/accuracy=0.865957, train/loss=0.506906, validation/accuracy=0.767940, validation/loss=0.916876, validation/num_examples=50000
I0303 08:27:24.770550 139881808373504 logging_writer.py:48] [160900] global_step=160900, grad_norm=3.217221736907959, loss=3.635425090789795
I0303 08:28:07.655551 139881799980800 logging_writer.py:48] [161000] global_step=161000, grad_norm=2.8057146072387695, loss=1.2779806852340698
I0303 08:28:51.991951 139881808373504 logging_writer.py:48] [161100] global_step=161100, grad_norm=2.957099676132202, loss=1.2582223415374756
I0303 08:29:36.496839 139881799980800 logging_writer.py:48] [161200] global_step=161200, grad_norm=2.6661765575408936, loss=1.6218236684799194
I0303 08:30:20.887634 139881808373504 logging_writer.py:48] [161300] global_step=161300, grad_norm=2.6218137741088867, loss=1.3413710594177246
I0303 08:31:05.534039 139881799980800 logging_writer.py:48] [161400] global_step=161400, grad_norm=3.816972494125366, loss=3.2767229080200195
I0303 08:31:49.980641 139881808373504 logging_writer.py:48] [161500] global_step=161500, grad_norm=2.837172746658325, loss=1.3201322555541992
I0303 08:32:34.549957 139881799980800 logging_writer.py:48] [161600] global_step=161600, grad_norm=2.585813522338867, loss=1.1748034954071045
I0303 08:33:19.107538 139881808373504 logging_writer.py:48] [161700] global_step=161700, grad_norm=2.7060842514038086, loss=2.4550728797912598
I0303 08:34:03.924641 139881799980800 logging_writer.py:48] [161800] global_step=161800, grad_norm=2.984851121902466, loss=3.0303757190704346
I0303 08:34:03.938987 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:34:14.320876 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:34:48.176937 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:34:49.754783 140077943854912 submission_runner.py:411] Time since start: 77282.56s, 	Step: 161801, 	{'train/accuracy': 0.8662499785423279, 'train/loss': 0.4994567334651947, 'validation/accuracy': 0.7704600095748901, 'validation/loss': 0.9088558554649353, 'validation/num_examples': 50000, 'test/accuracy': 0.6473000049591064, 'test/loss': 1.5221868753433228, 'test/num_examples': 10000, 'score': 71044.70680117607, 'total_duration': 77282.55980610847, 'accumulated_submission_time': 71044.70680117607, 'accumulated_eval_time': 6221.217273712158, 'accumulated_logging_time': 8.172521114349365}
I0303 08:34:49.794874 139881808373504 logging_writer.py:48] [161801] accumulated_eval_time=6221.217274, accumulated_logging_time=8.172521, accumulated_submission_time=71044.706801, global_step=161801, preemption_count=0, score=71044.706801, test/accuracy=0.647300, test/loss=1.522187, test/num_examples=10000, total_duration=77282.559806, train/accuracy=0.866250, train/loss=0.499457, validation/accuracy=0.770460, validation/loss=0.908856, validation/num_examples=50000
I0303 08:35:29.926194 139881799980800 logging_writer.py:48] [161900] global_step=161900, grad_norm=3.125391960144043, loss=3.0692126750946045
I0303 08:36:14.360984 139881808373504 logging_writer.py:48] [162000] global_step=162000, grad_norm=2.7786238193511963, loss=1.3420064449310303
I0303 08:36:58.862898 139881799980800 logging_writer.py:48] [162100] global_step=162100, grad_norm=4.1926188468933105, loss=3.391669750213623
I0303 08:37:43.323209 139881808373504 logging_writer.py:48] [162200] global_step=162200, grad_norm=2.5165317058563232, loss=1.1657769680023193
I0303 08:38:27.713634 139881799980800 logging_writer.py:48] [162300] global_step=162300, grad_norm=2.62096905708313, loss=1.3734323978424072
I0303 08:39:12.099789 139881808373504 logging_writer.py:48] [162400] global_step=162400, grad_norm=2.583965539932251, loss=1.6539374589920044
I0303 08:39:56.604462 139881799980800 logging_writer.py:48] [162500] global_step=162500, grad_norm=2.6637730598449707, loss=1.2511104345321655
I0303 08:40:40.775763 139881808373504 logging_writer.py:48] [162600] global_step=162600, grad_norm=3.31315541267395, loss=3.2306103706359863
I0303 08:41:25.370459 139881799980800 logging_writer.py:48] [162700] global_step=162700, grad_norm=2.6295862197875977, loss=1.6430580615997314
I0303 08:41:49.802532 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:42:00.046504 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:42:32.456627 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:42:34.038225 140077943854912 submission_runner.py:411] Time since start: 77746.84s, 	Step: 162757, 	{'train/accuracy': 0.8711718320846558, 'train/loss': 0.479285329580307, 'validation/accuracy': 0.7711199522018433, 'validation/loss': 0.9005151987075806, 'validation/num_examples': 50000, 'test/accuracy': 0.6461000442504883, 'test/loss': 1.5066665410995483, 'test/num_examples': 10000, 'score': 71464.65548014641, 'total_duration': 77746.84324288368, 'accumulated_submission_time': 71464.65548014641, 'accumulated_eval_time': 6265.452960968018, 'accumulated_logging_time': 8.222732543945312}
I0303 08:42:34.082428 139881808373504 logging_writer.py:48] [162757] accumulated_eval_time=6265.452961, accumulated_logging_time=8.222733, accumulated_submission_time=71464.655480, global_step=162757, preemption_count=0, score=71464.655480, test/accuracy=0.646100, test/loss=1.506667, test/num_examples=10000, total_duration=77746.843243, train/accuracy=0.871172, train/loss=0.479285, validation/accuracy=0.771120, validation/loss=0.900515, validation/num_examples=50000
I0303 08:42:51.241030 139881799980800 logging_writer.py:48] [162800] global_step=162800, grad_norm=2.5144126415252686, loss=1.5346691608428955
I0303 08:43:33.742598 139881808373504 logging_writer.py:48] [162900] global_step=162900, grad_norm=2.4320850372314453, loss=2.081076145172119
I0303 08:44:18.220337 139881799980800 logging_writer.py:48] [163000] global_step=163000, grad_norm=2.8329861164093018, loss=1.1969578266143799
I0303 08:45:02.731364 139881808373504 logging_writer.py:48] [163100] global_step=163100, grad_norm=2.779738187789917, loss=1.3336232900619507
I0303 08:45:46.882641 139881799980800 logging_writer.py:48] [163200] global_step=163200, grad_norm=2.587973117828369, loss=2.0918946266174316
I0303 08:46:31.709439 139881808373504 logging_writer.py:48] [163300] global_step=163300, grad_norm=2.818337917327881, loss=2.701596736907959
I0303 08:47:16.266922 139881799980800 logging_writer.py:48] [163400] global_step=163400, grad_norm=2.9185738563537598, loss=1.244269847869873
I0303 08:48:00.764267 139881808373504 logging_writer.py:48] [163500] global_step=163500, grad_norm=2.8055858612060547, loss=1.3428913354873657
I0303 08:48:45.248986 139881799980800 logging_writer.py:48] [163600] global_step=163600, grad_norm=2.767643690109253, loss=1.5760776996612549
I0303 08:49:29.960531 139881808373504 logging_writer.py:48] [163700] global_step=163700, grad_norm=2.6740095615386963, loss=1.3657118082046509
I0303 08:49:34.114801 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:49:44.311850 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:50:13.128999 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:50:14.716984 140077943854912 submission_runner.py:411] Time since start: 78207.52s, 	Step: 163711, 	{'train/accuracy': 0.87451171875, 'train/loss': 0.48026999831199646, 'validation/accuracy': 0.7723999619483948, 'validation/loss': 0.9044002890586853, 'validation/num_examples': 50000, 'test/accuracy': 0.6484000086784363, 'test/loss': 1.5175144672393799, 'test/num_examples': 10000, 'score': 71884.6285545826, 'total_duration': 78207.52199673653, 'accumulated_submission_time': 71884.6285545826, 'accumulated_eval_time': 6306.055119752884, 'accumulated_logging_time': 8.277120113372803}
I0303 08:50:14.758955 139881799980800 logging_writer.py:48] [163711] accumulated_eval_time=6306.055120, accumulated_logging_time=8.277120, accumulated_submission_time=71884.628555, global_step=163711, preemption_count=0, score=71884.628555, test/accuracy=0.648400, test/loss=1.517514, test/num_examples=10000, total_duration=78207.521997, train/accuracy=0.874512, train/loss=0.480270, validation/accuracy=0.772400, validation/loss=0.904400, validation/num_examples=50000
I0303 08:50:50.317485 139881808373504 logging_writer.py:48] [163800] global_step=163800, grad_norm=3.0864293575286865, loss=2.1658148765563965
I0303 08:51:34.864627 139881799980800 logging_writer.py:48] [163900] global_step=163900, grad_norm=3.306037664413452, loss=3.2505898475646973
I0303 08:52:19.262864 139881808373504 logging_writer.py:48] [164000] global_step=164000, grad_norm=3.107426643371582, loss=1.3046185970306396
I0303 08:53:03.773488 139881799980800 logging_writer.py:48] [164100] global_step=164100, grad_norm=2.6574859619140625, loss=1.2336857318878174
I0303 08:53:47.904007 139881808373504 logging_writer.py:48] [164200] global_step=164200, grad_norm=2.887169599533081, loss=1.2359812259674072
I0303 08:54:32.420211 139881799980800 logging_writer.py:48] [164300] global_step=164300, grad_norm=3.219125986099243, loss=1.4660437107086182
I0303 08:55:16.831827 139881808373504 logging_writer.py:48] [164400] global_step=164400, grad_norm=2.7182083129882812, loss=1.173122525215149
I0303 08:56:01.038416 139881799980800 logging_writer.py:48] [164500] global_step=164500, grad_norm=3.125243663787842, loss=3.052845001220703
I0303 08:56:45.723104 139881808373504 logging_writer.py:48] [164600] global_step=164600, grad_norm=3.1679837703704834, loss=3.484300136566162
I0303 08:57:14.719390 140077943854912 spec.py:321] Evaluating on the training split.
I0303 08:57:24.814724 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 08:57:54.339276 140077943854912 spec.py:349] Evaluating on the test split.
I0303 08:57:55.930263 140077943854912 submission_runner.py:411] Time since start: 78668.74s, 	Step: 164667, 	{'train/accuracy': 0.8724218606948853, 'train/loss': 0.4697950780391693, 'validation/accuracy': 0.774679958820343, 'validation/loss': 0.8892613053321838, 'validation/num_examples': 50000, 'test/accuracy': 0.6477000117301941, 'test/loss': 1.507075309753418, 'test/num_examples': 10000, 'score': 72304.52912330627, 'total_duration': 78668.73527359962, 'accumulated_submission_time': 72304.52912330627, 'accumulated_eval_time': 6347.265980482101, 'accumulated_logging_time': 8.328987121582031}
I0303 08:57:55.975720 139881799980800 logging_writer.py:48] [164667] accumulated_eval_time=6347.265980, accumulated_logging_time=8.328987, accumulated_submission_time=72304.529123, global_step=164667, preemption_count=0, score=72304.529123, test/accuracy=0.647700, test/loss=1.507075, test/num_examples=10000, total_duration=78668.735274, train/accuracy=0.872422, train/loss=0.469795, validation/accuracy=0.774680, validation/loss=0.889261, validation/num_examples=50000
I0303 08:58:09.227117 139881808373504 logging_writer.py:48] [164700] global_step=164700, grad_norm=3.0600123405456543, loss=1.2713563442230225
I0303 08:58:51.082902 139881799980800 logging_writer.py:48] [164800] global_step=164800, grad_norm=3.565455675125122, loss=3.425457715988159
I0303 08:59:35.608183 139881808373504 logging_writer.py:48] [164900] global_step=164900, grad_norm=2.7187039852142334, loss=1.6531343460083008
I0303 09:00:20.151099 139881799980800 logging_writer.py:48] [165000] global_step=165000, grad_norm=3.1025044918060303, loss=1.2610573768615723
I0303 09:01:04.083370 139881808373504 logging_writer.py:48] [165100] global_step=165100, grad_norm=2.751115560531616, loss=1.4422447681427002
I0303 09:01:48.645248 139881799980800 logging_writer.py:48] [165200] global_step=165200, grad_norm=2.604902744293213, loss=1.867713451385498
I0303 09:02:33.360990 139881808373504 logging_writer.py:48] [165300] global_step=165300, grad_norm=3.342850685119629, loss=1.3179292678833008
I0303 09:03:17.764082 139881799980800 logging_writer.py:48] [165400] global_step=165400, grad_norm=2.671051502227783, loss=1.464174747467041
I0303 09:04:02.151375 139881808373504 logging_writer.py:48] [165500] global_step=165500, grad_norm=3.4054934978485107, loss=1.197396159172058
I0303 09:04:46.582342 139881799980800 logging_writer.py:48] [165600] global_step=165600, grad_norm=3.0536365509033203, loss=1.2384564876556396
I0303 09:04:56.168864 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:05:06.815562 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:05:36.398008 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:05:37.982302 140077943854912 submission_runner.py:411] Time since start: 79130.79s, 	Step: 165623, 	{'train/accuracy': 0.8748242259025574, 'train/loss': 0.47568559646606445, 'validation/accuracy': 0.7743600010871887, 'validation/loss': 0.8956592679023743, 'validation/num_examples': 50000, 'test/accuracy': 0.650600016117096, 'test/loss': 1.5049769878387451, 'test/num_examples': 10000, 'score': 72724.6625881195, 'total_duration': 79130.78731393814, 'accumulated_submission_time': 72724.6625881195, 'accumulated_eval_time': 6389.079388380051, 'accumulated_logging_time': 8.3844153881073}
I0303 09:05:38.033485 139881808373504 logging_writer.py:48] [165623] accumulated_eval_time=6389.079388, accumulated_logging_time=8.384415, accumulated_submission_time=72724.662588, global_step=165623, preemption_count=0, score=72724.662588, test/accuracy=0.650600, test/loss=1.504977, test/num_examples=10000, total_duration=79130.787314, train/accuracy=0.874824, train/loss=0.475686, validation/accuracy=0.774360, validation/loss=0.895659, validation/num_examples=50000
I0303 09:06:08.626459 139881799980800 logging_writer.py:48] [165700] global_step=165700, grad_norm=3.2574615478515625, loss=3.2707431316375732
I0303 09:06:53.035698 139881808373504 logging_writer.py:48] [165800] global_step=165800, grad_norm=3.1061694622039795, loss=2.304403305053711
I0303 09:07:37.558950 139881799980800 logging_writer.py:48] [165900] global_step=165900, grad_norm=2.56756854057312, loss=1.1664330959320068
I0303 09:08:21.977710 139881808373504 logging_writer.py:48] [166000] global_step=166000, grad_norm=3.4144930839538574, loss=3.48563814163208
I0303 09:09:06.326812 139881799980800 logging_writer.py:48] [166100] global_step=166100, grad_norm=3.1241672039031982, loss=3.058875322341919
I0303 09:09:50.715698 139881808373504 logging_writer.py:48] [166200] global_step=166200, grad_norm=2.7615809440612793, loss=2.9088802337646484
I0303 09:10:35.056714 139881799980800 logging_writer.py:48] [166300] global_step=166300, grad_norm=3.125960350036621, loss=2.485339641571045
I0303 09:11:19.953480 139881808373504 logging_writer.py:48] [166400] global_step=166400, grad_norm=3.1983773708343506, loss=3.085139751434326
I0303 09:12:04.405833 139881799980800 logging_writer.py:48] [166500] global_step=166500, grad_norm=2.902116060256958, loss=1.1921947002410889
I0303 09:12:38.233316 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:12:48.287016 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:13:20.465788 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:13:22.044714 140077943854912 submission_runner.py:411] Time since start: 79594.85s, 	Step: 166577, 	{'train/accuracy': 0.8760351538658142, 'train/loss': 0.4655555188655853, 'validation/accuracy': 0.7749999761581421, 'validation/loss': 0.8960703611373901, 'validation/num_examples': 50000, 'test/accuracy': 0.6516000032424927, 'test/loss': 1.505468726158142, 'test/num_examples': 10000, 'score': 73144.80176186562, 'total_duration': 79594.84973239899, 'accumulated_submission_time': 73144.80176186562, 'accumulated_eval_time': 6432.890777826309, 'accumulated_logging_time': 8.447266101837158}
I0303 09:13:22.086252 139881808373504 logging_writer.py:48] [166577] accumulated_eval_time=6432.890778, accumulated_logging_time=8.447266, accumulated_submission_time=73144.801762, global_step=166577, preemption_count=0, score=73144.801762, test/accuracy=0.651600, test/loss=1.505469, test/num_examples=10000, total_duration=79594.849732, train/accuracy=0.876035, train/loss=0.465556, validation/accuracy=0.775000, validation/loss=0.896070, validation/num_examples=50000
I0303 09:13:31.452088 139881799980800 logging_writer.py:48] [166600] global_step=166600, grad_norm=2.7070565223693848, loss=1.1768581867218018
I0303 09:14:12.618498 139881808373504 logging_writer.py:48] [166700] global_step=166700, grad_norm=2.690493106842041, loss=1.1309943199157715
I0303 09:14:56.795851 139881799980800 logging_writer.py:48] [166800] global_step=166800, grad_norm=2.7392349243164062, loss=2.6228299140930176
I0303 09:15:41.122521 139881808373504 logging_writer.py:48] [166900] global_step=166900, grad_norm=2.854799509048462, loss=1.2368077039718628
I0303 09:16:25.418245 139881799980800 logging_writer.py:48] [167000] global_step=167000, grad_norm=2.7628121376037598, loss=1.357757806777954
I0303 09:17:09.825111 139881808373504 logging_writer.py:48] [167100] global_step=167100, grad_norm=3.484785556793213, loss=3.273656129837036
I0303 09:17:53.964831 139881799980800 logging_writer.py:48] [167200] global_step=167200, grad_norm=3.1795437335968018, loss=1.223909616470337
I0303 09:18:38.206390 139881808373504 logging_writer.py:48] [167300] global_step=167300, grad_norm=2.5588748455047607, loss=1.5531666278839111
I0303 09:19:22.932112 139881799980800 logging_writer.py:48] [167400] global_step=167400, grad_norm=2.5258467197418213, loss=2.0892040729522705
I0303 09:20:07.137984 139881808373504 logging_writer.py:48] [167500] global_step=167500, grad_norm=2.7809784412384033, loss=1.7111775875091553
I0303 09:20:22.342496 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:20:32.345361 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:21:04.026903 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:21:05.607222 140077943854912 submission_runner.py:411] Time since start: 80058.41s, 	Step: 167536, 	{'train/accuracy': 0.8737109303474426, 'train/loss': 0.4756890833377838, 'validation/accuracy': 0.7744999527931213, 'validation/loss': 0.8931192755699158, 'validation/num_examples': 50000, 'test/accuracy': 0.6520000100135803, 'test/loss': 1.4951791763305664, 'test/num_examples': 10000, 'score': 73564.99614834785, 'total_duration': 80058.41223526001, 'accumulated_submission_time': 73564.99614834785, 'accumulated_eval_time': 6476.155483722687, 'accumulated_logging_time': 8.500588655471802}
I0303 09:21:05.652920 139881799980800 logging_writer.py:48] [167536] accumulated_eval_time=6476.155484, accumulated_logging_time=8.500589, accumulated_submission_time=73564.996148, global_step=167536, preemption_count=0, score=73564.996148, test/accuracy=0.652000, test/loss=1.495179, test/num_examples=10000, total_duration=80058.412235, train/accuracy=0.873711, train/loss=0.475689, validation/accuracy=0.774500, validation/loss=0.893119, validation/num_examples=50000
I0303 09:21:31.010895 139881808373504 logging_writer.py:48] [167600] global_step=167600, grad_norm=2.7938199043273926, loss=1.1913820505142212
I0303 09:22:14.620903 139881799980800 logging_writer.py:48] [167700] global_step=167700, grad_norm=2.8731789588928223, loss=1.892397403717041
I0303 09:22:58.950536 139881808373504 logging_writer.py:48] [167800] global_step=167800, grad_norm=2.934885263442993, loss=2.577409505844116
I0303 09:23:43.693378 139881799980800 logging_writer.py:48] [167900] global_step=167900, grad_norm=3.2655959129333496, loss=1.2818691730499268
I0303 09:24:28.070995 139881808373504 logging_writer.py:48] [168000] global_step=168000, grad_norm=2.8239808082580566, loss=1.1603059768676758
I0303 09:25:12.383978 139881799980800 logging_writer.py:48] [168100] global_step=168100, grad_norm=2.925018072128296, loss=1.2745686769485474
I0303 09:25:56.775915 139881808373504 logging_writer.py:48] [168200] global_step=168200, grad_norm=3.4010329246520996, loss=3.380836009979248
I0303 09:26:41.550277 139881799980800 logging_writer.py:48] [168300] global_step=168300, grad_norm=2.939026355743408, loss=2.093325614929199
I0303 09:27:25.676224 139881808373504 logging_writer.py:48] [168400] global_step=168400, grad_norm=3.6026062965393066, loss=3.2511470317840576
I0303 09:28:05.758420 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:28:15.849647 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:28:51.749045 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:28:53.334180 140077943854912 submission_runner.py:411] Time since start: 80526.14s, 	Step: 168492, 	{'train/accuracy': 0.8785156011581421, 'train/loss': 0.45429205894470215, 'validation/accuracy': 0.776479959487915, 'validation/loss': 0.885757565498352, 'validation/num_examples': 50000, 'test/accuracy': 0.653700053691864, 'test/loss': 1.4894458055496216, 'test/num_examples': 10000, 'score': 73985.04015851021, 'total_duration': 80526.1391685009, 'accumulated_submission_time': 73985.04015851021, 'accumulated_eval_time': 6523.7312026023865, 'accumulated_logging_time': 8.55799913406372}
I0303 09:28:53.386666 139881799980800 logging_writer.py:48] [168492] accumulated_eval_time=6523.731203, accumulated_logging_time=8.557999, accumulated_submission_time=73985.040159, global_step=168492, preemption_count=0, score=73985.040159, test/accuracy=0.653700, test/loss=1.489446, test/num_examples=10000, total_duration=80526.139169, train/accuracy=0.878516, train/loss=0.454292, validation/accuracy=0.776480, validation/loss=0.885758, validation/num_examples=50000
I0303 09:28:56.898575 139881808373504 logging_writer.py:48] [168500] global_step=168500, grad_norm=2.7733144760131836, loss=1.6986522674560547
I0303 09:29:37.572721 139881799980800 logging_writer.py:48] [168600] global_step=168600, grad_norm=2.8258895874023438, loss=1.2195367813110352
I0303 09:30:22.054304 139881808373504 logging_writer.py:48] [168700] global_step=168700, grad_norm=2.837653398513794, loss=2.8323278427124023
I0303 09:31:06.467508 139881799980800 logging_writer.py:48] [168800] global_step=168800, grad_norm=2.862683057785034, loss=2.451308488845825
I0303 09:31:53.959372 139881808373504 logging_writer.py:48] [168900] global_step=168900, grad_norm=3.449540615081787, loss=1.1964101791381836
I0303 09:32:53.471185 139881799980800 logging_writer.py:48] [169000] global_step=169000, grad_norm=3.0331614017486572, loss=2.564100980758667
I0303 09:33:38.158255 139881808373504 logging_writer.py:48] [169100] global_step=169100, grad_norm=3.28720760345459, loss=3.340723991394043
I0303 09:34:23.270165 139881799980800 logging_writer.py:48] [169200] global_step=169200, grad_norm=3.034386396408081, loss=1.322349190711975
I0303 09:35:08.084660 139881808373504 logging_writer.py:48] [169300] global_step=169300, grad_norm=3.7141671180725098, loss=3.297708034515381
I0303 09:35:52.566339 139881799980800 logging_writer.py:48] [169400] global_step=169400, grad_norm=3.3440849781036377, loss=2.9019734859466553
I0303 09:35:53.621394 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:36:04.225643 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:36:31.431377 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:36:33.017190 140077943854912 submission_runner.py:411] Time since start: 80985.82s, 	Step: 169404, 	{'train/accuracy': 0.8810546398162842, 'train/loss': 0.4524443447589874, 'validation/accuracy': 0.7756399512290955, 'validation/loss': 0.8834952712059021, 'validation/num_examples': 50000, 'test/accuracy': 0.6568000316619873, 'test/loss': 1.4942373037338257, 'test/num_examples': 10000, 'score': 74405.21560502052, 'total_duration': 80985.82221055031, 'accumulated_submission_time': 74405.21560502052, 'accumulated_eval_time': 6563.126978397369, 'accumulated_logging_time': 8.622390508651733}
I0303 09:36:33.061759 139881808373504 logging_writer.py:48] [169404] accumulated_eval_time=6563.126978, accumulated_logging_time=8.622391, accumulated_submission_time=74405.215605, global_step=169404, preemption_count=0, score=74405.215605, test/accuracy=0.656800, test/loss=1.494237, test/num_examples=10000, total_duration=80985.822211, train/accuracy=0.881055, train/loss=0.452444, validation/accuracy=0.775640, validation/loss=0.883495, validation/num_examples=50000
I0303 09:37:12.064200 139881799980800 logging_writer.py:48] [169500] global_step=169500, grad_norm=2.6112778186798096, loss=1.4081703424453735
I0303 09:37:56.430694 139881808373504 logging_writer.py:48] [169600] global_step=169600, grad_norm=3.349666118621826, loss=1.1970282793045044
I0303 09:38:41.162206 139881799980800 logging_writer.py:48] [169700] global_step=169700, grad_norm=2.9114015102386475, loss=1.2863950729370117
I0303 09:39:25.780764 139881808373504 logging_writer.py:48] [169800] global_step=169800, grad_norm=2.9512410163879395, loss=1.851165771484375
I0303 09:40:10.271740 139881799980800 logging_writer.py:48] [169900] global_step=169900, grad_norm=2.9093551635742188, loss=1.1082533597946167
I0303 09:40:55.021120 139881808373504 logging_writer.py:48] [170000] global_step=170000, grad_norm=2.8239188194274902, loss=1.155601978302002
I0303 09:41:39.598084 139881799980800 logging_writer.py:48] [170100] global_step=170100, grad_norm=2.977055788040161, loss=1.2333701848983765
I0303 09:42:24.458350 139881808373504 logging_writer.py:48] [170200] global_step=170200, grad_norm=3.3938426971435547, loss=1.2543965578079224
I0303 09:43:09.025879 139881799980800 logging_writer.py:48] [170300] global_step=170300, grad_norm=3.464101791381836, loss=3.4067792892456055
I0303 09:43:33.139832 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:43:43.365627 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:44:14.545009 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:44:16.132453 140077943854912 submission_runner.py:411] Time since start: 81448.94s, 	Step: 170356, 	{'train/accuracy': 0.8832812309265137, 'train/loss': 0.43398892879486084, 'validation/accuracy': 0.7788199782371521, 'validation/loss': 0.870005190372467, 'validation/num_examples': 50000, 'test/accuracy': 0.6581000089645386, 'test/loss': 1.4730889797210693, 'test/num_examples': 10000, 'score': 74825.23263335228, 'total_duration': 81448.93747091293, 'accumulated_submission_time': 74825.23263335228, 'accumulated_eval_time': 6606.119580030441, 'accumulated_logging_time': 8.677473068237305}
I0303 09:44:16.174621 139881808373504 logging_writer.py:48] [170356] accumulated_eval_time=6606.119580, accumulated_logging_time=8.677473, accumulated_submission_time=74825.232633, global_step=170356, preemption_count=0, score=74825.232633, test/accuracy=0.658100, test/loss=1.473089, test/num_examples=10000, total_duration=81448.937471, train/accuracy=0.883281, train/loss=0.433989, validation/accuracy=0.778820, validation/loss=0.870005, validation/num_examples=50000
I0303 09:44:33.898993 139881799980800 logging_writer.py:48] [170400] global_step=170400, grad_norm=3.7925121784210205, loss=3.344275951385498
I0303 09:45:16.307571 139881808373504 logging_writer.py:48] [170500] global_step=170500, grad_norm=2.739227294921875, loss=1.1586315631866455
I0303 09:46:00.659018 139881799980800 logging_writer.py:48] [170600] global_step=170600, grad_norm=2.8215279579162598, loss=1.2459971904754639
I0303 09:46:45.559405 139881808373504 logging_writer.py:48] [170700] global_step=170700, grad_norm=2.86106014251709, loss=1.7581064701080322
I0303 09:47:29.967803 139881799980800 logging_writer.py:48] [170800] global_step=170800, grad_norm=2.934558391571045, loss=2.7364675998687744
I0303 09:48:14.499156 139881808373504 logging_writer.py:48] [170900] global_step=170900, grad_norm=3.0341665744781494, loss=2.534607410430908
I0303 09:48:58.847654 139881799980800 logging_writer.py:48] [171000] global_step=171000, grad_norm=3.666404962539673, loss=2.601757049560547
I0303 09:49:43.450908 139881808373504 logging_writer.py:48] [171100] global_step=171100, grad_norm=2.9224002361297607, loss=1.9380487203598022
I0303 09:50:27.814170 139881799980800 logging_writer.py:48] [171200] global_step=171200, grad_norm=2.9977636337280273, loss=1.3112252950668335
I0303 09:51:12.494462 139881808373504 logging_writer.py:48] [171300] global_step=171300, grad_norm=3.5120747089385986, loss=3.3464198112487793
I0303 09:51:16.538882 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:51:26.674796 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:51:54.646915 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:51:56.224540 140077943854912 submission_runner.py:411] Time since start: 81909.03s, 	Step: 171311, 	{'train/accuracy': 0.8805468678474426, 'train/loss': 0.44784343242645264, 'validation/accuracy': 0.7775999903678894, 'validation/loss': 0.8766506314277649, 'validation/num_examples': 50000, 'test/accuracy': 0.6554000377655029, 'test/loss': 1.4801712036132812, 'test/num_examples': 10000, 'score': 75245.5376894474, 'total_duration': 81909.02955842018, 'accumulated_submission_time': 75245.5376894474, 'accumulated_eval_time': 6645.805203676224, 'accumulated_logging_time': 8.72992992401123}
I0303 09:51:56.265686 139881799980800 logging_writer.py:48] [171311] accumulated_eval_time=6645.805204, accumulated_logging_time=8.729930, accumulated_submission_time=75245.537689, global_step=171311, preemption_count=0, score=75245.537689, test/accuracy=0.655400, test/loss=1.480171, test/num_examples=10000, total_duration=81909.029558, train/accuracy=0.880547, train/loss=0.447843, validation/accuracy=0.777600, validation/loss=0.876651, validation/num_examples=50000
I0303 09:52:32.303206 139881808373504 logging_writer.py:48] [171400] global_step=171400, grad_norm=2.7918457984924316, loss=1.1452622413635254
I0303 09:53:16.295087 139881799980800 logging_writer.py:48] [171500] global_step=171500, grad_norm=3.005211114883423, loss=1.149361252784729
I0303 09:54:00.716414 139881808373504 logging_writer.py:48] [171600] global_step=171600, grad_norm=2.9255805015563965, loss=1.9855360984802246
I0303 09:54:45.388173 139881799980800 logging_writer.py:48] [171700] global_step=171700, grad_norm=3.028446912765503, loss=1.2828235626220703
I0303 09:55:29.650250 139881808373504 logging_writer.py:48] [171800] global_step=171800, grad_norm=6.579780578613281, loss=1.2368391752243042
I0303 09:56:14.234831 139881799980800 logging_writer.py:48] [171900] global_step=171900, grad_norm=2.9584336280822754, loss=1.2021007537841797
I0303 09:56:58.649805 139881808373504 logging_writer.py:48] [172000] global_step=172000, grad_norm=3.125422477722168, loss=1.2332587242126465
I0303 09:57:43.343457 139881799980800 logging_writer.py:48] [172100] global_step=172100, grad_norm=3.40863037109375, loss=3.209355354309082
I0303 09:58:27.925111 139881808373504 logging_writer.py:48] [172200] global_step=172200, grad_norm=3.370468854904175, loss=3.217233419418335
I0303 09:58:56.532940 140077943854912 spec.py:321] Evaluating on the training split.
I0303 09:59:07.058755 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 09:59:37.664691 140077943854912 spec.py:349] Evaluating on the test split.
I0303 09:59:39.258218 140077943854912 submission_runner.py:411] Time since start: 82372.06s, 	Step: 172266, 	{'train/accuracy': 0.8803319931030273, 'train/loss': 0.4448411166667938, 'validation/accuracy': 0.7797999978065491, 'validation/loss': 0.8689996600151062, 'validation/num_examples': 50000, 'test/accuracy': 0.6565000414848328, 'test/loss': 1.4745608568191528, 'test/num_examples': 10000, 'score': 75665.74482417107, 'total_duration': 82372.0632212162, 'accumulated_submission_time': 75665.74482417107, 'accumulated_eval_time': 6688.530457019806, 'accumulated_logging_time': 8.78211498260498}
I0303 09:59:39.311304 139881799980800 logging_writer.py:48] [172266] accumulated_eval_time=6688.530457, accumulated_logging_time=8.782115, accumulated_submission_time=75665.744824, global_step=172266, preemption_count=0, score=75665.744824, test/accuracy=0.656500, test/loss=1.474561, test/num_examples=10000, total_duration=82372.063221, train/accuracy=0.880332, train/loss=0.444841, validation/accuracy=0.779800, validation/loss=0.869000, validation/num_examples=50000
I0303 09:59:52.957065 139881808373504 logging_writer.py:48] [172300] global_step=172300, grad_norm=2.793361186981201, loss=1.3537096977233887
I0303 10:00:35.202385 139881799980800 logging_writer.py:48] [172400] global_step=172400, grad_norm=2.9471027851104736, loss=2.3242177963256836
I0303 10:01:19.854671 139881808373504 logging_writer.py:48] [172500] global_step=172500, grad_norm=2.794684648513794, loss=1.1104371547698975
I0303 10:02:04.717435 139881799980800 logging_writer.py:48] [172600] global_step=172600, grad_norm=3.1498310565948486, loss=1.5510879755020142
I0303 10:02:49.395014 139881808373504 logging_writer.py:48] [172700] global_step=172700, grad_norm=3.008995294570923, loss=1.2899527549743652
I0303 10:03:33.909465 139881799980800 logging_writer.py:48] [172800] global_step=172800, grad_norm=2.8266685009002686, loss=1.1766209602355957
I0303 10:04:18.601366 139881808373504 logging_writer.py:48] [172900] global_step=172900, grad_norm=2.8430914878845215, loss=2.0479776859283447
I0303 10:05:03.112114 139881799980800 logging_writer.py:48] [173000] global_step=173000, grad_norm=2.9174695014953613, loss=1.246309518814087
I0303 10:05:47.454198 139881808373504 logging_writer.py:48] [173100] global_step=173100, grad_norm=3.7111623287200928, loss=3.3996999263763428
I0303 10:06:32.053977 139881799980800 logging_writer.py:48] [173200] global_step=173200, grad_norm=3.4620087146759033, loss=1.2256605625152588
I0303 10:06:39.336121 140077943854912 spec.py:321] Evaluating on the training split.
I0303 10:06:50.117995 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 10:07:20.880481 140077943854912 spec.py:349] Evaluating on the test split.
I0303 10:07:22.458679 140077943854912 submission_runner.py:411] Time since start: 82835.26s, 	Step: 173218, 	{'train/accuracy': 0.8841796517372131, 'train/loss': 0.430279940366745, 'validation/accuracy': 0.7793799638748169, 'validation/loss': 0.8702945709228516, 'validation/num_examples': 50000, 'test/accuracy': 0.656000018119812, 'test/loss': 1.4745509624481201, 'test/num_examples': 10000, 'score': 76085.70857977867, 'total_duration': 82835.26369142532, 'accumulated_submission_time': 76085.70857977867, 'accumulated_eval_time': 6731.652981758118, 'accumulated_logging_time': 8.847268104553223}
I0303 10:07:22.501778 139881808373504 logging_writer.py:48] [173218] accumulated_eval_time=6731.652982, accumulated_logging_time=8.847268, accumulated_submission_time=76085.708580, global_step=173218, preemption_count=0, score=76085.708580, test/accuracy=0.656000, test/loss=1.474551, test/num_examples=10000, total_duration=82835.263691, train/accuracy=0.884180, train/loss=0.430280, validation/accuracy=0.779380, validation/loss=0.870295, validation/num_examples=50000
I0303 10:07:55.098520 139881799980800 logging_writer.py:48] [173300] global_step=173300, grad_norm=3.2060306072235107, loss=2.7815704345703125
I0303 10:08:39.480501 139881808373504 logging_writer.py:48] [173400] global_step=173400, grad_norm=2.970341444015503, loss=1.1509851217269897
I0303 10:09:24.324621 139881799980800 logging_writer.py:48] [173500] global_step=173500, grad_norm=3.0333428382873535, loss=2.413811683654785
I0303 10:10:08.587117 139881808373504 logging_writer.py:48] [173600] global_step=173600, grad_norm=2.6481688022613525, loss=1.4571073055267334
I0303 10:10:52.975491 139881799980800 logging_writer.py:48] [173700] global_step=173700, grad_norm=2.915306806564331, loss=1.2188979387283325
I0303 10:11:37.252702 139881808373504 logging_writer.py:48] [173800] global_step=173800, grad_norm=3.025787830352783, loss=1.8394594192504883
I0303 10:12:21.761891 139881799980800 logging_writer.py:48] [173900] global_step=173900, grad_norm=3.0120630264282227, loss=1.1215347051620483
I0303 10:13:06.192183 139881808373504 logging_writer.py:48] [174000] global_step=174000, grad_norm=2.8656058311462402, loss=1.6538798809051514
I0303 10:13:50.266866 139881799980800 logging_writer.py:48] [174100] global_step=174100, grad_norm=3.1129531860351562, loss=1.1121121644973755
I0303 10:14:22.654922 140077943854912 spec.py:321] Evaluating on the training split.
I0303 10:14:32.851291 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 10:15:02.046146 140077943854912 spec.py:349] Evaluating on the test split.
I0303 10:15:03.625197 140077943854912 submission_runner.py:411] Time since start: 83296.43s, 	Step: 174174, 	{'train/accuracy': 0.8836718797683716, 'train/loss': 0.43221935629844666, 'validation/accuracy': 0.7788800001144409, 'validation/loss': 0.8668044805526733, 'validation/num_examples': 50000, 'test/accuracy': 0.6546000242233276, 'test/loss': 1.47637140750885, 'test/num_examples': 10000, 'score': 76505.80146336555, 'total_duration': 83296.43021583557, 'accumulated_submission_time': 76505.80146336555, 'accumulated_eval_time': 6772.623242139816, 'accumulated_logging_time': 8.900946855545044}
I0303 10:15:03.671785 139881808373504 logging_writer.py:48] [174174] accumulated_eval_time=6772.623242, accumulated_logging_time=8.900947, accumulated_submission_time=76505.801463, global_step=174174, preemption_count=0, score=76505.801463, test/accuracy=0.654600, test/loss=1.476371, test/num_examples=10000, total_duration=83296.430216, train/accuracy=0.883672, train/loss=0.432219, validation/accuracy=0.778880, validation/loss=0.866804, validation/num_examples=50000
I0303 10:15:14.194294 139881799980800 logging_writer.py:48] [174200] global_step=174200, grad_norm=3.1049087047576904, loss=1.1791480779647827
I0303 10:15:55.436180 139881808373504 logging_writer.py:48] [174300] global_step=174300, grad_norm=3.260533332824707, loss=3.163358688354492
I0303 10:16:39.895823 139881799980800 logging_writer.py:48] [174400] global_step=174400, grad_norm=3.3940980434417725, loss=2.9892477989196777
I0303 10:17:24.392697 139881808373504 logging_writer.py:48] [174500] global_step=174500, grad_norm=3.0744922161102295, loss=1.242061734199524
I0303 10:18:08.859508 139881799980800 logging_writer.py:48] [174600] global_step=174600, grad_norm=2.880333662033081, loss=1.9462376832962036
I0303 10:18:53.158285 139881808373504 logging_writer.py:48] [174700] global_step=174700, grad_norm=3.0116124153137207, loss=1.2810138463974
I0303 10:19:37.474581 139881799980800 logging_writer.py:48] [174800] global_step=174800, grad_norm=3.321749210357666, loss=1.6416288614273071
I0303 10:20:22.003414 139881808373504 logging_writer.py:48] [174900] global_step=174900, grad_norm=3.132894992828369, loss=1.149812936782837
I0303 10:21:06.490866 139881799980800 logging_writer.py:48] [175000] global_step=175000, grad_norm=3.9591903686523438, loss=3.1709280014038086
I0303 10:21:50.931336 139881808373504 logging_writer.py:48] [175100] global_step=175100, grad_norm=2.8768742084503174, loss=1.2069408893585205
I0303 10:22:03.926754 140077943854912 spec.py:321] Evaluating on the training split.
I0303 10:22:13.927833 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 10:22:44.854446 140077943854912 spec.py:349] Evaluating on the test split.
I0303 10:22:46.437391 140077943854912 submission_runner.py:411] Time since start: 83759.24s, 	Step: 175131, 	{'train/accuracy': 0.8831640481948853, 'train/loss': 0.4393573999404907, 'validation/accuracy': 0.781059980392456, 'validation/loss': 0.8640338778495789, 'validation/num_examples': 50000, 'test/accuracy': 0.6604000329971313, 'test/loss': 1.4671146869659424, 'test/num_examples': 10000, 'score': 76925.99597835541, 'total_duration': 83759.2424018383, 'accumulated_submission_time': 76925.99597835541, 'accumulated_eval_time': 6815.133854389191, 'accumulated_logging_time': 8.958553314208984}
I0303 10:22:46.480659 139881799980800 logging_writer.py:48] [175131] accumulated_eval_time=6815.133854, accumulated_logging_time=8.958553, accumulated_submission_time=76925.995978, global_step=175131, preemption_count=0, score=76925.995978, test/accuracy=0.660400, test/loss=1.467115, test/num_examples=10000, total_duration=83759.242402, train/accuracy=0.883164, train/loss=0.439357, validation/accuracy=0.781060, validation/loss=0.864034, validation/num_examples=50000
I0303 10:23:13.816396 139881808373504 logging_writer.py:48] [175200] global_step=175200, grad_norm=2.9074747562408447, loss=1.8003811836242676
I0303 10:23:57.660436 139881799980800 logging_writer.py:48] [175300] global_step=175300, grad_norm=3.0746872425079346, loss=1.207707166671753
I0303 10:24:42.246835 139881808373504 logging_writer.py:48] [175400] global_step=175400, grad_norm=3.084930181503296, loss=2.53847599029541
I0303 10:25:26.704771 139881799980800 logging_writer.py:48] [175500] global_step=175500, grad_norm=2.7350709438323975, loss=1.7188645601272583
I0303 10:26:11.567217 139881808373504 logging_writer.py:48] [175600] global_step=175600, grad_norm=3.3929190635681152, loss=3.0309879779815674
I0303 10:26:56.055160 139881799980800 logging_writer.py:48] [175700] global_step=175700, grad_norm=3.2471094131469727, loss=2.407982349395752
I0303 10:27:40.821393 139881808373504 logging_writer.py:48] [175800] global_step=175800, grad_norm=3.1453118324279785, loss=1.2969635725021362
I0303 10:28:25.547102 139881799980800 logging_writer.py:48] [175900] global_step=175900, grad_norm=2.919832944869995, loss=1.1425594091415405
I0303 10:29:10.072292 139881808373504 logging_writer.py:48] [176000] global_step=176000, grad_norm=3.141927480697632, loss=1.7875347137451172
I0303 10:29:46.635154 140077943854912 spec.py:321] Evaluating on the training split.
I0303 10:29:57.032251 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 10:30:28.334898 140077943854912 spec.py:349] Evaluating on the test split.
I0303 10:30:29.910307 140077943854912 submission_runner.py:411] Time since start: 84222.72s, 	Step: 176084, 	{'train/accuracy': 0.8835546970367432, 'train/loss': 0.43164560198783875, 'validation/accuracy': 0.7802599668502808, 'validation/loss': 0.8601840138435364, 'validation/num_examples': 50000, 'test/accuracy': 0.6589000225067139, 'test/loss': 1.4714841842651367, 'test/num_examples': 10000, 'score': 77346.0910449028, 'total_duration': 84222.7153236866, 'accumulated_submission_time': 77346.0910449028, 'accumulated_eval_time': 6858.408992290497, 'accumulated_logging_time': 9.01213812828064}
I0303 10:30:29.953610 139881799980800 logging_writer.py:48] [176084] accumulated_eval_time=6858.408992, accumulated_logging_time=9.012138, accumulated_submission_time=77346.091045, global_step=176084, preemption_count=0, score=77346.091045, test/accuracy=0.658900, test/loss=1.471484, test/num_examples=10000, total_duration=84222.715324, train/accuracy=0.883555, train/loss=0.431646, validation/accuracy=0.780260, validation/loss=0.860184, validation/num_examples=50000
I0303 10:30:36.569974 139881808373504 logging_writer.py:48] [176100] global_step=176100, grad_norm=3.586165189743042, loss=3.2228081226348877
I0303 10:31:17.741400 139881799980800 logging_writer.py:48] [176200] global_step=176200, grad_norm=3.5916035175323486, loss=2.3331186771392822
I0303 10:32:02.081770 139881808373504 logging_writer.py:48] [176300] global_step=176300, grad_norm=2.9450790882110596, loss=1.4560258388519287
I0303 10:32:46.699396 139881799980800 logging_writer.py:48] [176400] global_step=176400, grad_norm=2.9648492336273193, loss=1.4939426183700562
I0303 10:33:31.243801 139881808373504 logging_writer.py:48] [176500] global_step=176500, grad_norm=3.381925344467163, loss=2.6268563270568848
I0303 10:34:15.484101 139881799980800 logging_writer.py:48] [176600] global_step=176600, grad_norm=3.3246867656707764, loss=2.085359811782837
I0303 10:34:59.666308 139881808373504 logging_writer.py:48] [176700] global_step=176700, grad_norm=3.0582408905029297, loss=1.7483223676681519
I0303 10:35:43.938300 139881799980800 logging_writer.py:48] [176800] global_step=176800, grad_norm=3.180649757385254, loss=2.6894783973693848
I0303 10:36:28.606733 139881808373504 logging_writer.py:48] [176900] global_step=176900, grad_norm=3.2803969383239746, loss=1.0495432615280151
I0303 10:37:12.967459 139881799980800 logging_writer.py:48] [177000] global_step=177000, grad_norm=3.1616973876953125, loss=1.4686625003814697
I0303 10:37:30.315665 140077943854912 spec.py:321] Evaluating on the training split.
I0303 10:37:40.271284 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 10:38:10.529158 140077943854912 spec.py:349] Evaluating on the test split.
I0303 10:38:12.108914 140077943854912 submission_runner.py:411] Time since start: 84684.91s, 	Step: 177041, 	{'train/accuracy': 0.8862109184265137, 'train/loss': 0.4194622039794922, 'validation/accuracy': 0.780739963054657, 'validation/loss': 0.8591325283050537, 'validation/num_examples': 50000, 'test/accuracy': 0.6598000526428223, 'test/loss': 1.4636272192001343, 'test/num_examples': 10000, 'score': 77766.39183497429, 'total_duration': 84684.91393399239, 'accumulated_submission_time': 77766.39183497429, 'accumulated_eval_time': 6900.202219963074, 'accumulated_logging_time': 9.065497159957886}
I0303 10:38:12.155039 139881808373504 logging_writer.py:48] [177041] accumulated_eval_time=6900.202220, accumulated_logging_time=9.065497, accumulated_submission_time=77766.391835, global_step=177041, preemption_count=0, score=77766.391835, test/accuracy=0.659800, test/loss=1.463627, test/num_examples=10000, total_duration=84684.913934, train/accuracy=0.886211, train/loss=0.419462, validation/accuracy=0.780740, validation/loss=0.859133, validation/num_examples=50000
I0303 10:38:35.580856 139881799980800 logging_writer.py:48] [177100] global_step=177100, grad_norm=3.081928014755249, loss=1.1590214967727661
I0303 10:39:19.092466 139881808373504 logging_writer.py:48] [177200] global_step=177200, grad_norm=3.054389238357544, loss=2.3788208961486816
I0303 10:40:03.406255 139881799980800 logging_writer.py:48] [177300] global_step=177300, grad_norm=3.0495407581329346, loss=1.14424467086792
I0303 10:40:47.722035 139881808373504 logging_writer.py:48] [177400] global_step=177400, grad_norm=2.9560680389404297, loss=1.0600820779800415
I0303 10:41:32.190887 139881799980800 logging_writer.py:48] [177500] global_step=177500, grad_norm=3.529134750366211, loss=2.8950233459472656
I0303 10:42:16.675833 139881808373504 logging_writer.py:48] [177600] global_step=177600, grad_norm=3.0145485401153564, loss=2.1078920364379883
I0303 10:43:01.166487 139881799980800 logging_writer.py:48] [177700] global_step=177700, grad_norm=3.8603837490081787, loss=3.139984607696533
I0303 10:43:45.533772 139881808373504 logging_writer.py:48] [177800] global_step=177800, grad_norm=2.9441511631011963, loss=1.387786626815796
I0303 10:44:29.979055 139881799980800 logging_writer.py:48] [177900] global_step=177900, grad_norm=3.174856662750244, loss=1.1971091032028198
I0303 10:45:12.231052 140077943854912 spec.py:321] Evaluating on the training split.
I0303 10:45:22.535604 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 10:45:50.704502 140077943854912 spec.py:349] Evaluating on the test split.
I0303 10:45:52.287141 140077943854912 submission_runner.py:411] Time since start: 85145.09s, 	Step: 177997, 	{'train/accuracy': 0.8862695097923279, 'train/loss': 0.4204770624637604, 'validation/accuracy': 0.7815799713134766, 'validation/loss': 0.8558434247970581, 'validation/num_examples': 50000, 'test/accuracy': 0.6583000421524048, 'test/loss': 1.4628018140792847, 'test/num_examples': 10000, 'score': 78186.408213377, 'total_duration': 85145.09214758873, 'accumulated_submission_time': 78186.408213377, 'accumulated_eval_time': 6940.258265972137, 'accumulated_logging_time': 9.121346712112427}
I0303 10:45:52.343450 139881808373504 logging_writer.py:48] [177997] accumulated_eval_time=6940.258266, accumulated_logging_time=9.121347, accumulated_submission_time=78186.408213, global_step=177997, preemption_count=0, score=78186.408213, test/accuracy=0.658300, test/loss=1.462802, test/num_examples=10000, total_duration=85145.092148, train/accuracy=0.886270, train/loss=0.420477, validation/accuracy=0.781580, validation/loss=0.855843, validation/num_examples=50000
I0303 10:45:53.913850 139881799980800 logging_writer.py:48] [178000] global_step=178000, grad_norm=3.0130014419555664, loss=1.1343095302581787
I0303 10:46:34.658432 139881808373504 logging_writer.py:48] [178100] global_step=178100, grad_norm=3.2956833839416504, loss=1.3402553796768188
I0303 10:47:19.074845 139881799980800 logging_writer.py:48] [178200] global_step=178200, grad_norm=3.1659724712371826, loss=2.52530574798584
I0303 10:48:03.431617 139881808373504 logging_writer.py:48] [178300] global_step=178300, grad_norm=3.191394329071045, loss=1.219094157218933
I0303 10:48:47.978866 139881799980800 logging_writer.py:48] [178400] global_step=178400, grad_norm=3.475505828857422, loss=3.003033399581909
I0303 10:49:32.261287 139881808373504 logging_writer.py:48] [178500] global_step=178500, grad_norm=3.71008038520813, loss=3.298316478729248
I0303 10:50:16.451986 139881799980800 logging_writer.py:48] [178600] global_step=178600, grad_norm=5.188756465911865, loss=3.285778284072876
I0303 10:51:00.713369 139881808373504 logging_writer.py:48] [178700] global_step=178700, grad_norm=2.749478340148926, loss=1.6581166982650757
I0303 10:51:45.138207 139881799980800 logging_writer.py:48] [178800] global_step=178800, grad_norm=3.6564218997955322, loss=3.0690371990203857
I0303 10:52:29.691157 139881808373504 logging_writer.py:48] [178900] global_step=178900, grad_norm=5.09224796295166, loss=1.0921199321746826
I0303 10:52:52.385930 140077943854912 spec.py:321] Evaluating on the training split.
I0303 10:53:02.746249 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 10:53:39.829378 140077943854912 spec.py:349] Evaluating on the test split.
I0303 10:53:41.411347 140077943854912 submission_runner.py:411] Time since start: 85614.22s, 	Step: 178953, 	{'train/accuracy': 0.8860937356948853, 'train/loss': 0.4298219084739685, 'validation/accuracy': 0.7818399667739868, 'validation/loss': 0.8621166944503784, 'validation/num_examples': 50000, 'test/accuracy': 0.6598000526428223, 'test/loss': 1.461968183517456, 'test/num_examples': 10000, 'score': 78606.38973283768, 'total_duration': 85614.21636533737, 'accumulated_submission_time': 78606.38973283768, 'accumulated_eval_time': 6989.28365111351, 'accumulated_logging_time': 9.188668251037598}
I0303 10:53:41.455563 139881799980800 logging_writer.py:48] [178953] accumulated_eval_time=6989.283651, accumulated_logging_time=9.188668, accumulated_submission_time=78606.389733, global_step=178953, preemption_count=0, score=78606.389733, test/accuracy=0.659800, test/loss=1.461968, test/num_examples=10000, total_duration=85614.216365, train/accuracy=0.886094, train/loss=0.429822, validation/accuracy=0.781840, validation/loss=0.862117, validation/num_examples=50000
I0303 10:54:00.171403 139881808373504 logging_writer.py:48] [179000] global_step=179000, grad_norm=3.137035369873047, loss=1.1555238962173462
I0303 10:54:42.256607 139881799980800 logging_writer.py:48] [179100] global_step=179100, grad_norm=3.2746033668518066, loss=2.9066720008850098
I0303 10:55:26.903702 139881808373504 logging_writer.py:48] [179200] global_step=179200, grad_norm=3.1349709033966064, loss=1.1735491752624512
I0303 10:56:11.484173 139881799980800 logging_writer.py:48] [179300] global_step=179300, grad_norm=3.129067897796631, loss=1.5477731227874756
I0303 10:56:55.933075 139881808373504 logging_writer.py:48] [179400] global_step=179400, grad_norm=3.18023943901062, loss=1.1953940391540527
I0303 10:57:40.376181 139881799980800 logging_writer.py:48] [179500] global_step=179500, grad_norm=3.502514123916626, loss=3.074653148651123
I0303 10:58:24.750737 139881808373504 logging_writer.py:48] [179600] global_step=179600, grad_norm=2.9796323776245117, loss=1.1594880819320679
I0303 10:59:08.944924 139881799980800 logging_writer.py:48] [179700] global_step=179700, grad_norm=3.4056899547576904, loss=3.0361666679382324
I0303 10:59:52.930878 139881808373504 logging_writer.py:48] [179800] global_step=179800, grad_norm=3.070708990097046, loss=1.6550772190093994
I0303 11:00:37.369811 139881799980800 logging_writer.py:48] [179900] global_step=179900, grad_norm=2.9002439975738525, loss=1.1317847967147827
I0303 11:00:41.547661 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:00:51.520359 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:01:22.626885 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:01:24.205285 140077943854912 submission_runner.py:411] Time since start: 86077.01s, 	Step: 179911, 	{'train/accuracy': 0.8874218463897705, 'train/loss': 0.41679367423057556, 'validation/accuracy': 0.7824999690055847, 'validation/loss': 0.8534600734710693, 'validation/num_examples': 50000, 'test/accuracy': 0.6611000299453735, 'test/loss': 1.4549766778945923, 'test/num_examples': 10000, 'score': 79026.4203722477, 'total_duration': 86077.0102751255, 'accumulated_submission_time': 79026.4203722477, 'accumulated_eval_time': 7031.9412133693695, 'accumulated_logging_time': 9.244869709014893}
I0303 11:01:24.251601 139881808373504 logging_writer.py:48] [179911] accumulated_eval_time=7031.941213, accumulated_logging_time=9.244870, accumulated_submission_time=79026.420372, global_step=179911, preemption_count=0, score=79026.420372, test/accuracy=0.661100, test/loss=1.454977, test/num_examples=10000, total_duration=86077.010275, train/accuracy=0.887422, train/loss=0.416794, validation/accuracy=0.782500, validation/loss=0.853460, validation/num_examples=50000
I0303 11:01:59.840665 139881799980800 logging_writer.py:48] [180000] global_step=180000, grad_norm=3.2985010147094727, loss=1.125144600868225
I0303 11:02:43.850754 139881808373504 logging_writer.py:48] [180100] global_step=180100, grad_norm=3.045928478240967, loss=1.227933406829834
I0303 11:03:28.262762 139881799980800 logging_writer.py:48] [180200] global_step=180200, grad_norm=4.70909309387207, loss=1.141321063041687
I0303 11:04:12.670564 139881808373504 logging_writer.py:48] [180300] global_step=180300, grad_norm=3.0586259365081787, loss=1.0711655616760254
I0303 11:04:56.846028 139881799980800 logging_writer.py:48] [180400] global_step=180400, grad_norm=3.2967536449432373, loss=1.131594181060791
I0303 11:05:41.563551 139881808373504 logging_writer.py:48] [180500] global_step=180500, grad_norm=2.9124088287353516, loss=1.0584068298339844
I0303 11:06:26.052640 139881799980800 logging_writer.py:48] [180600] global_step=180600, grad_norm=3.536581516265869, loss=1.8369128704071045
I0303 11:07:10.295317 139881808373504 logging_writer.py:48] [180700] global_step=180700, grad_norm=3.4605135917663574, loss=1.2351319789886475
I0303 11:07:54.370661 139881799980800 logging_writer.py:48] [180800] global_step=180800, grad_norm=3.0677483081817627, loss=1.9509825706481934
I0303 11:08:24.433411 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:08:34.860186 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:09:08.745156 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:09:10.320254 140077943854912 submission_runner.py:411] Time since start: 86543.13s, 	Step: 180869, 	{'train/accuracy': 0.8839648365974426, 'train/loss': 0.43049442768096924, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8545869588851929, 'validation/num_examples': 50000, 'test/accuracy': 0.661300003528595, 'test/loss': 1.4536794424057007, 'test/num_examples': 10000, 'score': 79446.53990650177, 'total_duration': 86543.125269413, 'accumulated_submission_time': 79446.53990650177, 'accumulated_eval_time': 7077.8280510902405, 'accumulated_logging_time': 9.303065538406372}
I0303 11:09:10.367732 139881808373504 logging_writer.py:48] [180869] accumulated_eval_time=7077.828051, accumulated_logging_time=9.303066, accumulated_submission_time=79446.539907, global_step=180869, preemption_count=0, score=79446.539907, test/accuracy=0.661300, test/loss=1.453679, test/num_examples=10000, total_duration=86543.125269, train/accuracy=0.883965, train/loss=0.430494, validation/accuracy=0.782940, validation/loss=0.854587, validation/num_examples=50000
I0303 11:09:22.841240 139881799980800 logging_writer.py:48] [180900] global_step=180900, grad_norm=3.378199577331543, loss=1.0958247184753418
I0303 11:10:04.511609 139881808373504 logging_writer.py:48] [181000] global_step=181000, grad_norm=2.9043800830841064, loss=1.2067855596542358
I0303 11:10:48.871923 139881799980800 logging_writer.py:48] [181100] global_step=181100, grad_norm=3.0901241302490234, loss=1.121116042137146
I0303 11:11:33.533328 139881808373504 logging_writer.py:48] [181200] global_step=181200, grad_norm=3.3125648498535156, loss=2.9449167251586914
I0303 11:12:17.809298 139881799980800 logging_writer.py:48] [181300] global_step=181300, grad_norm=3.160262107849121, loss=1.136193871498108
I0303 11:13:02.341277 139881808373504 logging_writer.py:48] [181400] global_step=181400, grad_norm=3.1419973373413086, loss=1.2237293720245361
I0303 11:13:46.869061 139881799980800 logging_writer.py:48] [181500] global_step=181500, grad_norm=2.8702638149261475, loss=1.292749285697937
I0303 11:14:31.213476 139881808373504 logging_writer.py:48] [181600] global_step=181600, grad_norm=2.878556489944458, loss=1.3121919631958008
I0303 11:15:15.843699 139881799980800 logging_writer.py:48] [181700] global_step=181700, grad_norm=3.085493564605713, loss=1.9492262601852417
I0303 11:16:00.424594 139881808373504 logging_writer.py:48] [181800] global_step=181800, grad_norm=4.102033615112305, loss=3.2355923652648926
I0303 11:16:10.426032 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:16:20.977243 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:16:54.583598 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:16:56.164503 140077943854912 submission_runner.py:411] Time since start: 87008.97s, 	Step: 181824, 	{'train/accuracy': 0.885546863079071, 'train/loss': 0.4214950501918793, 'validation/accuracy': 0.782480001449585, 'validation/loss': 0.8549716472625732, 'validation/num_examples': 50000, 'test/accuracy': 0.6606000065803528, 'test/loss': 1.4558229446411133, 'test/num_examples': 10000, 'score': 79866.53466320038, 'total_duration': 87008.9695174694, 'accumulated_submission_time': 79866.53466320038, 'accumulated_eval_time': 7123.566502571106, 'accumulated_logging_time': 9.364516973495483}
I0303 11:16:56.210258 139881799980800 logging_writer.py:48] [181824] accumulated_eval_time=7123.566503, accumulated_logging_time=9.364517, accumulated_submission_time=79866.534663, global_step=181824, preemption_count=0, score=79866.534663, test/accuracy=0.660600, test/loss=1.455823, test/num_examples=10000, total_duration=87008.969517, train/accuracy=0.885547, train/loss=0.421495, validation/accuracy=0.782480, validation/loss=0.854972, validation/num_examples=50000
I0303 11:17:26.273765 139881808373504 logging_writer.py:48] [181900] global_step=181900, grad_norm=3.262253999710083, loss=1.2175687551498413
I0303 11:18:10.544948 139881799980800 logging_writer.py:48] [182000] global_step=182000, grad_norm=3.093940019607544, loss=1.1720046997070312
I0303 11:18:54.981242 139881808373504 logging_writer.py:48] [182100] global_step=182100, grad_norm=3.6639761924743652, loss=3.1842041015625
I0303 11:19:39.450285 139881799980800 logging_writer.py:48] [182200] global_step=182200, grad_norm=3.721956253051758, loss=3.179058790206909
I0303 11:20:23.982093 139881808373504 logging_writer.py:48] [182300] global_step=182300, grad_norm=3.351073980331421, loss=1.2366409301757812
I0303 11:21:08.407277 139881799980800 logging_writer.py:48] [182400] global_step=182400, grad_norm=3.2711119651794434, loss=1.1566017866134644
I0303 11:21:52.868566 139881808373504 logging_writer.py:48] [182500] global_step=182500, grad_norm=2.963674783706665, loss=1.5535070896148682
I0303 11:22:37.249825 139881799980800 logging_writer.py:48] [182600] global_step=182600, grad_norm=3.053260326385498, loss=2.5088584423065186
I0303 11:23:21.715708 139881808373504 logging_writer.py:48] [182700] global_step=182700, grad_norm=3.1527059078216553, loss=1.0535491704940796
I0303 11:23:56.170503 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:24:06.662708 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:24:43.945627 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:24:45.522965 140077943854912 submission_runner.py:411] Time since start: 87478.33s, 	Step: 182779, 	{'train/accuracy': 0.8897070288658142, 'train/loss': 0.411954402923584, 'validation/accuracy': 0.7824400067329407, 'validation/loss': 0.8548983931541443, 'validation/num_examples': 50000, 'test/accuracy': 0.660800039768219, 'test/loss': 1.4561413526535034, 'test/num_examples': 10000, 'score': 80286.43485283852, 'total_duration': 87478.32796931267, 'accumulated_submission_time': 80286.43485283852, 'accumulated_eval_time': 7172.918921947479, 'accumulated_logging_time': 9.42094874382019}
I0303 11:24:45.568378 139881799980800 logging_writer.py:48] [182779] accumulated_eval_time=7172.918922, accumulated_logging_time=9.420949, accumulated_submission_time=80286.434853, global_step=182779, preemption_count=0, score=80286.434853, test/accuracy=0.660800, test/loss=1.456141, test/num_examples=10000, total_duration=87478.327969, train/accuracy=0.889707, train/loss=0.411954, validation/accuracy=0.782440, validation/loss=0.854898, validation/num_examples=50000
I0303 11:24:54.146409 139881808373504 logging_writer.py:48] [182800] global_step=182800, grad_norm=3.1304237842559814, loss=2.812934637069702
I0303 11:25:35.391309 139881799980800 logging_writer.py:48] [182900] global_step=182900, grad_norm=3.1625640392303467, loss=1.9135003089904785
I0303 11:26:19.997711 139881808373504 logging_writer.py:48] [183000] global_step=183000, grad_norm=3.359342575073242, loss=2.8645362854003906
I0303 11:27:04.708662 139881799980800 logging_writer.py:48] [183100] global_step=183100, grad_norm=3.2541539669036865, loss=1.147077202796936
I0303 11:27:48.799683 139881808373504 logging_writer.py:48] [183200] global_step=183200, grad_norm=3.1220638751983643, loss=1.9352290630340576
I0303 11:28:33.172149 139881799980800 logging_writer.py:48] [183300] global_step=183300, grad_norm=3.0886456966400146, loss=2.158834457397461
I0303 11:29:17.555472 139881808373504 logging_writer.py:48] [183400] global_step=183400, grad_norm=3.073420763015747, loss=1.3131823539733887
I0303 11:30:02.024174 139881799980800 logging_writer.py:48] [183500] global_step=183500, grad_norm=3.517423629760742, loss=1.9484871625900269
I0303 11:30:46.243957 139881808373504 logging_writer.py:48] [183600] global_step=183600, grad_norm=3.5536513328552246, loss=2.2249460220336914
I0303 11:31:30.830563 139881799980800 logging_writer.py:48] [183700] global_step=183700, grad_norm=2.982647657394409, loss=1.8061549663543701
I0303 11:31:45.652396 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:31:55.913310 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:32:25.047892 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:32:26.619679 140077943854912 submission_runner.py:411] Time since start: 87939.42s, 	Step: 183735, 	{'train/accuracy': 0.8878905773162842, 'train/loss': 0.4117888808250427, 'validation/accuracy': 0.782759964466095, 'validation/loss': 0.852722704410553, 'validation/num_examples': 50000, 'test/accuracy': 0.6620000600814819, 'test/loss': 1.4533320665359497, 'test/num_examples': 10000, 'score': 80706.45871520042, 'total_duration': 87939.42469787598, 'accumulated_submission_time': 80706.45871520042, 'accumulated_eval_time': 7213.88618850708, 'accumulated_logging_time': 9.477174997329712}
I0303 11:32:26.670335 139881808373504 logging_writer.py:48] [183735] accumulated_eval_time=7213.886189, accumulated_logging_time=9.477175, accumulated_submission_time=80706.458715, global_step=183735, preemption_count=0, score=80706.458715, test/accuracy=0.662000, test/loss=1.453332, test/num_examples=10000, total_duration=87939.424698, train/accuracy=0.887891, train/loss=0.411789, validation/accuracy=0.782760, validation/loss=0.852723, validation/num_examples=50000
I0303 11:32:52.424473 139881799980800 logging_writer.py:48] [183800] global_step=183800, grad_norm=3.122802734375, loss=1.0928387641906738
I0303 11:33:36.332454 139881808373504 logging_writer.py:48] [183900] global_step=183900, grad_norm=3.114100933074951, loss=1.1217535734176636
I0303 11:34:20.859335 139881799980800 logging_writer.py:48] [184000] global_step=184000, grad_norm=3.101254463195801, loss=2.3233823776245117
I0303 11:35:05.272989 139881808373504 logging_writer.py:48] [184100] global_step=184100, grad_norm=3.108661651611328, loss=1.0842652320861816
I0303 11:35:49.643754 139881799980800 logging_writer.py:48] [184200] global_step=184200, grad_norm=2.7687478065490723, loss=1.51348078250885
I0303 11:36:34.487262 139881808373504 logging_writer.py:48] [184300] global_step=184300, grad_norm=3.165379285812378, loss=1.0647073984146118
I0303 11:37:19.154310 139881799980800 logging_writer.py:48] [184400] global_step=184400, grad_norm=3.1746327877044678, loss=2.2829720973968506
I0303 11:38:03.748509 139881808373504 logging_writer.py:48] [184500] global_step=184500, grad_norm=2.994776725769043, loss=1.200049877166748
I0303 11:38:48.036861 139881799980800 logging_writer.py:48] [184600] global_step=184600, grad_norm=3.347867727279663, loss=2.4608876705169678
I0303 11:39:27.012160 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:39:37.305187 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:40:12.152361 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:40:13.730375 140077943854912 submission_runner.py:411] Time since start: 88406.54s, 	Step: 184689, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.4206721782684326, 'validation/accuracy': 0.7829999923706055, 'validation/loss': 0.8523223400115967, 'validation/num_examples': 50000, 'test/accuracy': 0.6610000133514404, 'test/loss': 1.4538012742996216, 'test/num_examples': 10000, 'score': 81126.73969316483, 'total_duration': 88406.53539347649, 'accumulated_submission_time': 81126.73969316483, 'accumulated_eval_time': 7260.604390859604, 'accumulated_logging_time': 9.539127111434937}
I0303 11:40:13.777404 139881808373504 logging_writer.py:48] [184689] accumulated_eval_time=7260.604391, accumulated_logging_time=9.539127, accumulated_submission_time=81126.739693, global_step=184689, preemption_count=0, score=81126.739693, test/accuracy=0.661000, test/loss=1.453801, test/num_examples=10000, total_duration=88406.535393, train/accuracy=0.887461, train/loss=0.420672, validation/accuracy=0.783000, validation/loss=0.852322, validation/num_examples=50000
I0303 11:40:18.444192 139881799980800 logging_writer.py:48] [184700] global_step=184700, grad_norm=3.244854211807251, loss=1.140905737876892
I0303 11:40:59.164157 139881808373504 logging_writer.py:48] [184800] global_step=184800, grad_norm=3.005535364151001, loss=2.177351951599121
I0303 11:41:43.451603 139881799980800 logging_writer.py:48] [184900] global_step=184900, grad_norm=2.9855101108551025, loss=1.077185034751892
I0303 11:42:28.134998 139881808373504 logging_writer.py:48] [185000] global_step=185000, grad_norm=3.60336971282959, loss=3.0779449939727783
I0303 11:43:12.336742 139881799980800 logging_writer.py:48] [185100] global_step=185100, grad_norm=3.0094478130340576, loss=1.1187363862991333
I0303 11:43:56.698538 139881808373504 logging_writer.py:48] [185200] global_step=185200, grad_norm=3.1835567951202393, loss=2.6966726779937744
I0303 11:44:41.170668 139881799980800 logging_writer.py:48] [185300] global_step=185300, grad_norm=3.102168083190918, loss=2.723278284072876
I0303 11:45:25.495498 139881808373504 logging_writer.py:48] [185400] global_step=185400, grad_norm=3.2114810943603516, loss=1.9356838464736938
I0303 11:46:09.925837 139881799980800 logging_writer.py:48] [185500] global_step=185500, grad_norm=3.0314455032348633, loss=1.076419472694397
I0303 11:46:54.423355 139881808373504 logging_writer.py:48] [185600] global_step=185600, grad_norm=2.9952340126037598, loss=1.116930603981018
I0303 11:47:13.767447 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:47:24.076483 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:47:51.981037 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:47:53.568043 140077943854912 submission_runner.py:411] Time since start: 88866.37s, 	Step: 185645, 	{'train/accuracy': 0.8898437023162842, 'train/loss': 0.4111132025718689, 'validation/accuracy': 0.7829999923706055, 'validation/loss': 0.8524206280708313, 'validation/num_examples': 50000, 'test/accuracy': 0.6612000465393066, 'test/loss': 1.4538347721099854, 'test/num_examples': 10000, 'score': 81546.66754245758, 'total_duration': 88866.37303447723, 'accumulated_submission_time': 81546.66754245758, 'accumulated_eval_time': 7300.4049389362335, 'accumulated_logging_time': 9.598478078842163}
I0303 11:47:53.620859 139881799980800 logging_writer.py:48] [185645] accumulated_eval_time=7300.404939, accumulated_logging_time=9.598478, accumulated_submission_time=81546.667542, global_step=185645, preemption_count=0, score=81546.667542, test/accuracy=0.661200, test/loss=1.453835, test/num_examples=10000, total_duration=88866.373034, train/accuracy=0.889844, train/loss=0.411113, validation/accuracy=0.783000, validation/loss=0.852421, validation/num_examples=50000
I0303 11:48:15.490334 139881808373504 logging_writer.py:48] [185700] global_step=185700, grad_norm=3.203946352005005, loss=1.4061858654022217
I0303 11:48:59.211877 139881799980800 logging_writer.py:48] [185800] global_step=185800, grad_norm=3.323230028152466, loss=1.1765868663787842
I0303 11:49:43.750471 139881808373504 logging_writer.py:48] [185900] global_step=185900, grad_norm=2.938988208770752, loss=1.0578198432922363
I0303 11:50:28.185410 139881799980800 logging_writer.py:48] [186000] global_step=186000, grad_norm=3.055798292160034, loss=1.4874433279037476
I0303 11:51:12.552874 139881808373504 logging_writer.py:48] [186100] global_step=186100, grad_norm=3.0237460136413574, loss=2.2281599044799805
I0303 11:51:57.074235 139881799980800 logging_writer.py:48] [186200] global_step=186200, grad_norm=3.3918204307556152, loss=2.1344306468963623
I0303 11:52:41.477646 139881808373504 logging_writer.py:48] [186300] global_step=186300, grad_norm=3.148068904876709, loss=1.1857141256332397
I0303 11:53:25.728117 139881799980800 logging_writer.py:48] [186400] global_step=186400, grad_norm=3.3448879718780518, loss=1.1195483207702637
I0303 11:54:10.655115 139881808373504 logging_writer.py:48] [186500] global_step=186500, grad_norm=2.916518211364746, loss=1.3962663412094116
I0303 11:54:53.898334 140077943854912 spec.py:321] Evaluating on the training split.
I0303 11:55:04.242461 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 11:55:36.424406 140077943854912 spec.py:349] Evaluating on the test split.
I0303 11:55:38.017629 140077943854912 submission_runner.py:411] Time since start: 89330.82s, 	Step: 186599, 	{'train/accuracy': 0.8867577910423279, 'train/loss': 0.4253540337085724, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.4538928270339966, 'test/num_examples': 10000, 'score': 81966.87752747536, 'total_duration': 89330.82261490822, 'accumulated_submission_time': 81966.87752747536, 'accumulated_eval_time': 7344.524179458618, 'accumulated_logging_time': 9.663646221160889}
I0303 11:55:38.074678 139881799980800 logging_writer.py:48] [186599] accumulated_eval_time=7344.524179, accumulated_logging_time=9.663646, accumulated_submission_time=81966.877527, global_step=186599, preemption_count=0, score=81966.877527, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=89330.822615, train/accuracy=0.886758, train/loss=0.425354, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 11:55:38.878933 139881808373504 logging_writer.py:48] [186600] global_step=186600, grad_norm=3.4597504138946533, loss=1.466264247894287
I0303 11:56:19.848452 139881799980800 logging_writer.py:48] [186700] global_step=186700, grad_norm=2.9988372325897217, loss=1.2226208448410034
I0303 11:57:04.604630 139881808373504 logging_writer.py:48] [186800] global_step=186800, grad_norm=3.716844081878662, loss=3.1355652809143066
I0303 11:57:49.118891 139881799980800 logging_writer.py:48] [186900] global_step=186900, grad_norm=3.038681745529175, loss=1.3580288887023926
I0303 11:58:33.622562 139881808373504 logging_writer.py:48] [187000] global_step=187000, grad_norm=3.142448663711548, loss=2.671271324157715
I0303 11:59:18.244418 139881799980800 logging_writer.py:48] [187100] global_step=187100, grad_norm=3.1720731258392334, loss=2.2651607990264893
I0303 12:00:02.812917 139881808373504 logging_writer.py:48] [187200] global_step=187200, grad_norm=3.091332197189331, loss=1.1279979944229126
I0303 12:00:47.099732 139881799980800 logging_writer.py:48] [187300] global_step=187300, grad_norm=2.964263439178467, loss=1.0578205585479736
I0303 12:01:31.775151 139881808373504 logging_writer.py:48] [187400] global_step=187400, grad_norm=3.145329713821411, loss=1.20296311378479
I0303 12:02:16.680315 139881799980800 logging_writer.py:48] [187500] global_step=187500, grad_norm=3.0286996364593506, loss=1.1482762098312378
I0303 12:02:38.244137 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:02:48.895254 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:03:23.922104 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:03:25.525350 140077943854912 submission_runner.py:411] Time since start: 89798.33s, 	Step: 187550, 	{'train/accuracy': 0.8905078172683716, 'train/loss': 0.4123665988445282, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 82386.98583173752, 'total_duration': 89798.33035802841, 'accumulated_submission_time': 82386.98583173752, 'accumulated_eval_time': 7391.805383205414, 'accumulated_logging_time': 9.732877016067505}
I0303 12:03:25.573008 139881808373504 logging_writer.py:48] [187550] accumulated_eval_time=7391.805383, accumulated_logging_time=9.732877, accumulated_submission_time=82386.985832, global_step=187550, preemption_count=0, score=82386.985832, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=89798.330358, train/accuracy=0.890508, train/loss=0.412367, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:03:45.459492 139881799980800 logging_writer.py:48] [187600] global_step=187600, grad_norm=3.3495655059814453, loss=1.0648266077041626
I0303 12:04:28.147325 139881808373504 logging_writer.py:48] [187700] global_step=187700, grad_norm=3.515258550643921, loss=2.896082639694214
I0303 12:05:12.370168 139881799980800 logging_writer.py:48] [187800] global_step=187800, grad_norm=3.027324914932251, loss=1.7679319381713867
I0303 12:05:57.047845 139881808373504 logging_writer.py:48] [187900] global_step=187900, grad_norm=3.2499754428863525, loss=1.457014799118042
I0303 12:06:41.727427 139881799980800 logging_writer.py:48] [188000] global_step=188000, grad_norm=3.1088716983795166, loss=1.0621840953826904
I0303 12:07:26.023030 139881808373504 logging_writer.py:48] [188100] global_step=188100, grad_norm=3.2165019512176514, loss=1.1793628931045532
I0303 12:08:10.240104 139881799980800 logging_writer.py:48] [188200] global_step=188200, grad_norm=3.2561519145965576, loss=2.354780435562134
I0303 12:08:54.409036 139881808373504 logging_writer.py:48] [188300] global_step=188300, grad_norm=3.552615165710449, loss=1.1245789527893066
I0303 12:09:39.030715 139881799980800 logging_writer.py:48] [188400] global_step=188400, grad_norm=4.021005630493164, loss=3.2396047115325928
I0303 12:10:23.375429 139881808373504 logging_writer.py:48] [188500] global_step=188500, grad_norm=4.386741638183594, loss=3.1702890396118164
I0303 12:10:25.726864 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:10:35.819330 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:11:02.796855 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:11:04.372037 140077943854912 submission_runner.py:411] Time since start: 90257.18s, 	Step: 188507, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.4162900745868683, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 82807.08119153976, 'total_duration': 90257.17705130577, 'accumulated_submission_time': 82807.08119153976, 'accumulated_eval_time': 7430.450542926788, 'accumulated_logging_time': 9.789993047714233}
I0303 12:11:04.421938 139881799980800 logging_writer.py:48] [188507] accumulated_eval_time=7430.450543, accumulated_logging_time=9.789993, accumulated_submission_time=82807.081192, global_step=188507, preemption_count=0, score=82807.081192, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=90257.177051, train/accuracy=0.886738, train/loss=0.416290, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:11:41.542820 139881808373504 logging_writer.py:48] [188600] global_step=188600, grad_norm=3.0187265872955322, loss=1.4940881729125977
I0303 12:12:25.916058 139881799980800 logging_writer.py:48] [188700] global_step=188700, grad_norm=3.5668842792510986, loss=1.162638545036316
I0303 12:13:10.410809 139881808373504 logging_writer.py:48] [188800] global_step=188800, grad_norm=3.1980676651000977, loss=1.0669910907745361
I0303 12:13:54.533036 139881799980800 logging_writer.py:48] [188900] global_step=188900, grad_norm=2.7679426670074463, loss=1.249314785003662
I0303 12:14:39.136352 139881808373504 logging_writer.py:48] [189000] global_step=189000, grad_norm=3.2182228565216064, loss=1.167879581451416
I0303 12:15:23.391335 139881799980800 logging_writer.py:48] [189100] global_step=189100, grad_norm=3.099769353866577, loss=1.299716591835022
I0303 12:16:07.704788 139881808373504 logging_writer.py:48] [189200] global_step=189200, grad_norm=3.302367925643921, loss=2.6386380195617676
I0303 12:16:52.172825 139881799980800 logging_writer.py:48] [189300] global_step=189300, grad_norm=3.2339396476745605, loss=1.603219985961914
I0303 12:17:36.408097 139881808373504 logging_writer.py:48] [189400] global_step=189400, grad_norm=3.1756513118743896, loss=1.8776254653930664
I0303 12:18:04.505825 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:18:14.820324 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:18:48.079311 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:18:49.669254 140077943854912 submission_runner.py:411] Time since start: 90722.47s, 	Step: 189465, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.415896475315094, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 83227.10395240784, 'total_duration': 90722.47425937653, 'accumulated_submission_time': 83227.10395240784, 'accumulated_eval_time': 7475.613933086395, 'accumulated_logging_time': 9.851112365722656}
I0303 12:18:49.724344 139881799980800 logging_writer.py:48] [189465] accumulated_eval_time=7475.613933, accumulated_logging_time=9.851112, accumulated_submission_time=83227.103952, global_step=189465, preemption_count=0, score=83227.103952, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=90722.474259, train/accuracy=0.888144, train/loss=0.415896, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:19:03.815585 139881808373504 logging_writer.py:48] [189500] global_step=189500, grad_norm=3.748964548110962, loss=3.2058162689208984
I0303 12:19:45.676181 139881799980800 logging_writer.py:48] [189600] global_step=189600, grad_norm=3.174060106277466, loss=1.1955435276031494
I0303 12:20:29.998125 139881808373504 logging_writer.py:48] [189700] global_step=189700, grad_norm=3.0649654865264893, loss=2.2059316635131836
I0303 12:21:14.781752 139881799980800 logging_writer.py:48] [189800] global_step=189800, grad_norm=3.2700252532958984, loss=2.4862101078033447
I0303 12:21:59.016514 139881808373504 logging_writer.py:48] [189900] global_step=189900, grad_norm=3.347022294998169, loss=1.2179611921310425
I0303 12:22:43.559321 139881799980800 logging_writer.py:48] [190000] global_step=190000, grad_norm=2.8126180171966553, loss=2.125131130218506
I0303 12:23:27.906557 139881808373504 logging_writer.py:48] [190100] global_step=190100, grad_norm=3.1042401790618896, loss=1.964497447013855
I0303 12:24:12.605090 139881799980800 logging_writer.py:48] [190200] global_step=190200, grad_norm=3.2769055366516113, loss=2.845175266265869
I0303 12:24:56.998877 139881808373504 logging_writer.py:48] [190300] global_step=190300, grad_norm=3.5251479148864746, loss=1.172544002532959
I0303 12:25:41.092470 139881799980800 logging_writer.py:48] [190400] global_step=190400, grad_norm=2.8902792930603027, loss=0.9896028637886047
I0303 12:25:49.675046 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:25:59.980445 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:26:29.488198 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:26:31.064729 140077943854912 submission_runner.py:411] Time since start: 91183.87s, 	Step: 190421, 	{'train/accuracy': 0.8898632526397705, 'train/loss': 0.4129151701927185, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 83646.99283194542, 'total_duration': 91183.86973595619, 'accumulated_submission_time': 83646.99283194542, 'accumulated_eval_time': 7517.003622770309, 'accumulated_logging_time': 9.918134927749634}
I0303 12:26:31.112409 139881808373504 logging_writer.py:48] [190421] accumulated_eval_time=7517.003623, accumulated_logging_time=9.918135, accumulated_submission_time=83646.992832, global_step=190421, preemption_count=0, score=83646.992832, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=91183.869736, train/accuracy=0.889863, train/loss=0.412915, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:27:02.342196 139881799980800 logging_writer.py:48] [190500] global_step=190500, grad_norm=3.384758234024048, loss=0.9560254216194153
I0303 12:27:46.446851 139881808373504 logging_writer.py:48] [190600] global_step=190600, grad_norm=3.2288925647735596, loss=1.1064300537109375
I0303 12:28:31.206850 139881799980800 logging_writer.py:48] [190700] global_step=190700, grad_norm=3.730963706970215, loss=2.985898494720459
I0303 12:29:15.624573 139881808373504 logging_writer.py:48] [190800] global_step=190800, grad_norm=2.9195926189422607, loss=1.41464364528656
I0303 12:29:59.860502 139881799980800 logging_writer.py:48] [190900] global_step=190900, grad_norm=3.2033121585845947, loss=1.2305890321731567
I0303 12:30:44.414154 139881808373504 logging_writer.py:48] [191000] global_step=191000, grad_norm=3.3384411334991455, loss=1.2353407144546509
I0303 12:31:28.902094 139881799980800 logging_writer.py:48] [191100] global_step=191100, grad_norm=3.1859660148620605, loss=1.1992601156234741
I0303 12:32:13.631008 139881808373504 logging_writer.py:48] [191200] global_step=191200, grad_norm=3.19706392288208, loss=2.424957752227783
I0303 12:32:57.927711 139881799980800 logging_writer.py:48] [191300] global_step=191300, grad_norm=3.118776559829712, loss=1.8815035820007324
I0303 12:33:31.116549 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:33:41.340567 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:34:10.088323 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:34:11.668701 140077943854912 submission_runner.py:411] Time since start: 91644.47s, 	Step: 191376, 	{'train/accuracy': 0.8852733969688416, 'train/loss': 0.41861826181411743, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 84066.93710017204, 'total_duration': 91644.47371864319, 'accumulated_submission_time': 84066.93710017204, 'accumulated_eval_time': 7557.5557742118835, 'accumulated_logging_time': 9.97598123550415}
I0303 12:34:11.714968 139881808373504 logging_writer.py:48] [191376] accumulated_eval_time=7557.555774, accumulated_logging_time=9.975981, accumulated_submission_time=84066.937100, global_step=191376, preemption_count=0, score=84066.937100, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=91644.473719, train/accuracy=0.885273, train/loss=0.418618, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:34:21.457349 139881799980800 logging_writer.py:48] [191400] global_step=191400, grad_norm=3.074369192123413, loss=2.690232276916504
I0303 12:35:03.059232 139881808373504 logging_writer.py:48] [191500] global_step=191500, grad_norm=3.121530532836914, loss=1.192140817642212
I0303 12:35:47.285339 139881799980800 logging_writer.py:48] [191600] global_step=191600, grad_norm=3.5708022117614746, loss=2.4779114723205566
I0303 12:36:31.761775 139881808373504 logging_writer.py:48] [191700] global_step=191700, grad_norm=2.9435622692108154, loss=2.27156400680542
I0303 12:37:16.157556 139881799980800 logging_writer.py:48] [191800] global_step=191800, grad_norm=3.5485167503356934, loss=3.0088284015655518
I0303 12:38:00.589685 139881808373504 logging_writer.py:48] [191900] global_step=191900, grad_norm=3.227952480316162, loss=1.601821780204773
I0303 12:38:45.009387 139881799980800 logging_writer.py:48] [192000] global_step=192000, grad_norm=3.2788093090057373, loss=1.1382735967636108
I0303 12:39:29.366268 139881808373504 logging_writer.py:48] [192100] global_step=192100, grad_norm=2.8630902767181396, loss=1.7055374383926392
I0303 12:40:13.560537 139881799980800 logging_writer.py:48] [192200] global_step=192200, grad_norm=3.060361862182617, loss=1.1808979511260986
I0303 12:40:57.749908 139881808373504 logging_writer.py:48] [192300] global_step=192300, grad_norm=3.67514967918396, loss=3.163262367248535
I0303 12:41:11.711848 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:41:22.008670 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:41:50.645334 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:41:52.235972 140077943854912 submission_runner.py:411] Time since start: 92105.04s, 	Step: 192333, 	{'train/accuracy': 0.8894140720367432, 'train/loss': 0.415103018283844, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 84486.87456440926, 'total_duration': 92105.04097628593, 'accumulated_submission_time': 84486.87456440926, 'accumulated_eval_time': 7598.079861402512, 'accumulated_logging_time': 10.03218388557434}
I0303 12:41:52.293387 139881799980800 logging_writer.py:48] [192333] accumulated_eval_time=7598.079861, accumulated_logging_time=10.032184, accumulated_submission_time=84486.874564, global_step=192333, preemption_count=0, score=84486.874564, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=92105.040976, train/accuracy=0.889414, train/loss=0.415103, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:42:18.834460 139881808373504 logging_writer.py:48] [192400] global_step=192400, grad_norm=3.5166070461273193, loss=2.925734758377075
I0303 12:43:02.842405 139881799980800 logging_writer.py:48] [192500] global_step=192500, grad_norm=3.0716168880462646, loss=1.0706846714019775
I0303 12:43:47.058208 139881808373504 logging_writer.py:48] [192600] global_step=192600, grad_norm=3.5644400119781494, loss=3.082423448562622
I0303 12:44:31.919843 139881799980800 logging_writer.py:48] [192700] global_step=192700, grad_norm=3.0245063304901123, loss=1.2638517618179321
I0303 12:45:16.236342 139881808373504 logging_writer.py:48] [192800] global_step=192800, grad_norm=3.306135654449463, loss=2.785616636276245
I0303 12:46:00.578945 139881799980800 logging_writer.py:48] [192900] global_step=192900, grad_norm=3.2419888973236084, loss=1.1530451774597168
I0303 12:46:45.271268 139881808373504 logging_writer.py:48] [193000] global_step=193000, grad_norm=3.3129212856292725, loss=1.1098551750183105
I0303 12:47:29.691860 139881799980800 logging_writer.py:48] [193100] global_step=193100, grad_norm=3.546851634979248, loss=2.714337110519409
I0303 12:48:14.104601 139881808373504 logging_writer.py:48] [193200] global_step=193200, grad_norm=3.4386210441589355, loss=1.2075560092926025
I0303 12:48:52.357912 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:49:02.437614 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:49:29.096704 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:49:30.693331 140077943854912 submission_runner.py:411] Time since start: 92563.50s, 	Step: 193288, 	{'train/accuracy': 0.8891796469688416, 'train/loss': 0.4154730439186096, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 84906.87883043289, 'total_duration': 92563.49833774567, 'accumulated_submission_time': 84906.87883043289, 'accumulated_eval_time': 7636.415265798569, 'accumulated_logging_time': 10.100399255752563}
I0303 12:49:30.755527 139881799980800 logging_writer.py:48] [193288] accumulated_eval_time=7636.415266, accumulated_logging_time=10.100399, accumulated_submission_time=84906.878830, global_step=193288, preemption_count=0, score=84906.878830, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=92563.498338, train/accuracy=0.889180, train/loss=0.415473, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:49:35.847795 139881808373504 logging_writer.py:48] [193300] global_step=193300, grad_norm=2.882966995239258, loss=1.117538571357727
I0303 12:50:17.358087 139881799980800 logging_writer.py:48] [193400] global_step=193400, grad_norm=3.353384494781494, loss=1.3414932489395142
I0303 12:51:01.732954 139881808373504 logging_writer.py:48] [193500] global_step=193500, grad_norm=3.1594958305358887, loss=1.240649700164795
I0303 12:51:46.351749 139881799980800 logging_writer.py:48] [193600] global_step=193600, grad_norm=3.09001088142395, loss=1.621884822845459
I0303 12:52:30.834123 139881808373504 logging_writer.py:48] [193700] global_step=193700, grad_norm=2.9658095836639404, loss=1.3371334075927734
I0303 12:53:15.298783 139881799980800 logging_writer.py:48] [193800] global_step=193800, grad_norm=3.2799150943756104, loss=1.4941778182983398
I0303 12:53:59.589708 139881808373504 logging_writer.py:48] [193900] global_step=193900, grad_norm=2.8343162536621094, loss=1.5573134422302246
I0303 12:54:44.528717 139881799980800 logging_writer.py:48] [194000] global_step=194000, grad_norm=3.3451266288757324, loss=1.6068133115768433
I0303 12:55:28.896791 139881808373504 logging_writer.py:48] [194100] global_step=194100, grad_norm=4.4212422370910645, loss=3.009124279022217
I0303 12:56:13.341971 139881799980800 logging_writer.py:48] [194200] global_step=194200, grad_norm=2.979513645172119, loss=1.1975945234298706
I0303 12:56:31.005301 140077943854912 spec.py:321] Evaluating on the training split.
I0303 12:56:41.034653 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 12:57:18.811484 140077943854912 spec.py:349] Evaluating on the test split.
I0303 12:57:20.391590 140077943854912 submission_runner.py:411] Time since start: 93033.20s, 	Step: 194241, 	{'train/accuracy': 0.8891015648841858, 'train/loss': 0.41406816244125366, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 85327.06767630577, 'total_duration': 93033.19660949707, 'accumulated_submission_time': 85327.06767630577, 'accumulated_eval_time': 7685.801539182663, 'accumulated_logging_time': 10.174046993255615}
I0303 12:57:20.440691 139881808373504 logging_writer.py:48] [194241] accumulated_eval_time=7685.801539, accumulated_logging_time=10.174047, accumulated_submission_time=85327.067676, global_step=194241, preemption_count=0, score=85327.067676, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=93033.196609, train/accuracy=0.889102, train/loss=0.414068, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 12:57:43.831299 139881799980800 logging_writer.py:48] [194300] global_step=194300, grad_norm=3.055961847305298, loss=2.464218854904175
I0303 12:58:26.561321 139881808373504 logging_writer.py:48] [194400] global_step=194400, grad_norm=3.337679624557495, loss=1.139524221420288
I0303 12:59:11.002696 139881799980800 logging_writer.py:48] [194500] global_step=194500, grad_norm=3.14077091217041, loss=1.1627510786056519
I0303 12:59:55.090466 139881808373504 logging_writer.py:48] [194600] global_step=194600, grad_norm=3.067978620529175, loss=1.0441367626190186
I0303 13:00:39.425719 139881799980800 logging_writer.py:48] [194700] global_step=194700, grad_norm=3.2210347652435303, loss=1.16535484790802
I0303 13:01:23.821655 139881808373504 logging_writer.py:48] [194800] global_step=194800, grad_norm=2.9650464057922363, loss=1.1030067205429077
I0303 13:02:08.165328 139881799980800 logging_writer.py:48] [194900] global_step=194900, grad_norm=3.201996088027954, loss=1.0977486371994019
I0303 13:02:52.368912 139881808373504 logging_writer.py:48] [195000] global_step=195000, grad_norm=3.190086603164673, loss=1.108780860900879
I0303 13:03:36.723170 139881799980800 logging_writer.py:48] [195100] global_step=195100, grad_norm=3.070699453353882, loss=1.0713138580322266
I0303 13:04:20.411299 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:04:30.684248 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:05:02.263981 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:05:03.854038 140077943854912 submission_runner.py:411] Time since start: 93496.66s, 	Step: 195200, 	{'train/accuracy': 0.8866796493530273, 'train/loss': 0.4165627956390381, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 85746.978110075, 'total_duration': 93496.65905618668, 'accumulated_submission_time': 85746.978110075, 'accumulated_eval_time': 7729.244254589081, 'accumulated_logging_time': 10.232911586761475}
I0303 13:05:03.901244 139881808373504 logging_writer.py:48] [195200] accumulated_eval_time=7729.244255, accumulated_logging_time=10.232912, accumulated_submission_time=85746.978110, global_step=195200, preemption_count=0, score=85746.978110, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=93496.659056, train/accuracy=0.886680, train/loss=0.416563, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:05:04.295590 139881799980800 logging_writer.py:48] [195200] global_step=195200, grad_norm=3.2173824310302734, loss=1.2746164798736572
I0303 13:05:43.989489 139881808373504 logging_writer.py:48] [195300] global_step=195300, grad_norm=3.40543794631958, loss=1.1061550378799438
I0303 13:06:28.643268 139881799980800 logging_writer.py:48] [195400] global_step=195400, grad_norm=2.968657970428467, loss=1.0120058059692383
I0303 13:07:13.501464 139881808373504 logging_writer.py:48] [195500] global_step=195500, grad_norm=3.3579294681549072, loss=1.024258017539978
I0303 13:07:57.595675 139881799980800 logging_writer.py:48] [195600] global_step=195600, grad_norm=2.98307728767395, loss=2.287290096282959
I0303 13:08:42.246442 139881808373504 logging_writer.py:48] [195700] global_step=195700, grad_norm=3.3528339862823486, loss=1.1014699935913086
I0303 13:09:26.631438 139881799980800 logging_writer.py:48] [195800] global_step=195800, grad_norm=3.571190118789673, loss=3.269202709197998
I0303 13:10:10.992484 139881808373504 logging_writer.py:48] [195900] global_step=195900, grad_norm=3.2687716484069824, loss=1.0846397876739502
I0303 13:10:55.313012 139881799980800 logging_writer.py:48] [196000] global_step=196000, grad_norm=3.8189241886138916, loss=3.2431840896606445
I0303 13:11:39.770103 139881808373504 logging_writer.py:48] [196100] global_step=196100, grad_norm=3.1497066020965576, loss=1.1170299053192139
I0303 13:12:04.265777 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:12:14.531392 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:12:45.118833 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:12:46.700058 140077943854912 submission_runner.py:411] Time since start: 93959.51s, 	Step: 196157, 	{'train/accuracy': 0.8865429759025574, 'train/loss': 0.425489604473114, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 86167.28060626984, 'total_duration': 93959.50507903099, 'accumulated_submission_time': 86167.28060626984, 'accumulated_eval_time': 7771.67853140831, 'accumulated_logging_time': 10.292376279830933}
I0303 13:12:46.744883 139881799980800 logging_writer.py:48] [196157] accumulated_eval_time=7771.678531, accumulated_logging_time=10.292376, accumulated_submission_time=86167.280606, global_step=196157, preemption_count=0, score=86167.280606, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=93959.505079, train/accuracy=0.886543, train/loss=0.425490, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:13:03.910198 139881808373504 logging_writer.py:48] [196200] global_step=196200, grad_norm=3.2309274673461914, loss=2.453545093536377
I0303 13:13:46.477101 139881799980800 logging_writer.py:48] [196300] global_step=196300, grad_norm=2.9766530990600586, loss=1.1201125383377075
I0303 13:14:30.960401 139881808373504 logging_writer.py:48] [196400] global_step=196400, grad_norm=3.437991142272949, loss=2.936823606491089
I0303 13:15:16.054064 139881799980800 logging_writer.py:48] [196500] global_step=196500, grad_norm=3.4822890758514404, loss=3.0395092964172363
I0303 13:16:00.807291 139881808373504 logging_writer.py:48] [196600] global_step=196600, grad_norm=2.865154504776001, loss=0.9695374369621277
I0303 13:16:45.427956 139881799980800 logging_writer.py:48] [196700] global_step=196700, grad_norm=3.905625104904175, loss=3.0715160369873047
I0303 13:17:29.901146 139881808373504 logging_writer.py:48] [196800] global_step=196800, grad_norm=2.816720485687256, loss=1.48585844039917
I0303 13:18:14.415119 139881799980800 logging_writer.py:48] [196900] global_step=196900, grad_norm=3.3284897804260254, loss=2.8526644706726074
I0303 13:18:59.079527 139881808373504 logging_writer.py:48] [197000] global_step=197000, grad_norm=3.0359914302825928, loss=1.1653566360473633
I0303 13:19:43.657787 139881799980800 logging_writer.py:48] [197100] global_step=197100, grad_norm=3.6091270446777344, loss=2.8655800819396973
I0303 13:19:46.841124 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:19:57.204918 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:20:23.272984 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:20:24.869272 140077943854912 submission_runner.py:411] Time since start: 94417.67s, 	Step: 197109, 	{'train/accuracy': 0.8899609446525574, 'train/loss': 0.4093320369720459, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 86587.31809902191, 'total_duration': 94417.6742913723, 'accumulated_submission_time': 86587.31809902191, 'accumulated_eval_time': 7809.706657886505, 'accumulated_logging_time': 10.347052335739136}
I0303 13:20:24.915854 139881808373504 logging_writer.py:48] [197109] accumulated_eval_time=7809.706658, accumulated_logging_time=10.347052, accumulated_submission_time=86587.318099, global_step=197109, preemption_count=0, score=86587.318099, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=94417.674291, train/accuracy=0.889961, train/loss=0.409332, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:21:01.984526 139881799980800 logging_writer.py:48] [197200] global_step=197200, grad_norm=3.3285562992095947, loss=1.532938838005066
I0303 13:21:46.324584 139881808373504 logging_writer.py:48] [197300] global_step=197300, grad_norm=3.338609457015991, loss=1.200034737586975
I0303 13:22:31.079149 139881799980800 logging_writer.py:48] [197400] global_step=197400, grad_norm=2.9734818935394287, loss=1.729592204093933
I0303 13:23:15.673439 139881808373504 logging_writer.py:48] [197500] global_step=197500, grad_norm=3.3051936626434326, loss=1.1198309659957886
I0303 13:24:00.038328 139881799980800 logging_writer.py:48] [197600] global_step=197600, grad_norm=3.94332218170166, loss=3.0728161334991455
I0303 13:24:45.040876 139881808373504 logging_writer.py:48] [197700] global_step=197700, grad_norm=3.332221746444702, loss=1.1290249824523926
I0303 13:25:29.495591 139881799980800 logging_writer.py:48] [197800] global_step=197800, grad_norm=3.338487148284912, loss=2.298079013824463
I0303 13:26:14.072279 139881808373504 logging_writer.py:48] [197900] global_step=197900, grad_norm=2.977525234222412, loss=1.8815776109695435
I0303 13:26:58.646726 139881799980800 logging_writer.py:48] [198000] global_step=198000, grad_norm=3.0798850059509277, loss=1.1714831590652466
I0303 13:27:25.028287 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:27:35.027235 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:28:01.881735 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:28:03.472844 140077943854912 submission_runner.py:411] Time since start: 94876.28s, 	Step: 198061, 	{'train/accuracy': 0.8864452838897705, 'train/loss': 0.42235925793647766, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 87007.37144398689, 'total_duration': 94876.27783370018, 'accumulated_submission_time': 87007.37144398689, 'accumulated_eval_time': 7848.151168823242, 'accumulated_logging_time': 10.403776168823242}
I0303 13:28:03.536525 139881808373504 logging_writer.py:48] [198061] accumulated_eval_time=7848.151169, accumulated_logging_time=10.403776, accumulated_submission_time=87007.371444, global_step=198061, preemption_count=0, score=87007.371444, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=94876.277834, train/accuracy=0.886445, train/loss=0.422359, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:28:19.144707 139881799980800 logging_writer.py:48] [198100] global_step=198100, grad_norm=3.2848305702209473, loss=2.861828088760376
I0303 13:29:01.896581 139881808373504 logging_writer.py:48] [198200] global_step=198200, grad_norm=2.8869128227233887, loss=1.9748265743255615
I0303 13:29:46.179733 139881799980800 logging_writer.py:48] [198300] global_step=198300, grad_norm=3.0434963703155518, loss=1.1458446979522705
I0303 13:30:30.789118 139881808373504 logging_writer.py:48] [198400] global_step=198400, grad_norm=3.2641079425811768, loss=1.8241437673568726
I0303 13:31:15.210581 139881799980800 logging_writer.py:48] [198500] global_step=198500, grad_norm=3.1947007179260254, loss=2.307656764984131
I0303 13:31:59.610070 139881808373504 logging_writer.py:48] [198600] global_step=198600, grad_norm=3.218759536743164, loss=1.245939016342163
I0303 13:32:44.296344 139881799980800 logging_writer.py:48] [198700] global_step=198700, grad_norm=2.9733476638793945, loss=1.0684807300567627
I0303 13:33:29.013286 139881808373504 logging_writer.py:48] [198800] global_step=198800, grad_norm=3.483780860900879, loss=3.1634151935577393
I0303 13:34:13.599279 139881799980800 logging_writer.py:48] [198900] global_step=198900, grad_norm=2.941429376602173, loss=1.0992705821990967
I0303 13:34:58.160413 139881808373504 logging_writer.py:48] [199000] global_step=199000, grad_norm=3.4978578090667725, loss=1.1459819078445435
I0303 13:35:03.633753 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:35:13.801746 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:35:44.983715 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:35:46.571450 140077943854912 submission_runner.py:411] Time since start: 95339.38s, 	Step: 199014, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.4180936813354492, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 87427.40733599663, 'total_duration': 95339.37646174431, 'accumulated_submission_time': 87427.40733599663, 'accumulated_eval_time': 7891.088857412338, 'accumulated_logging_time': 10.479464530944824}
I0303 13:35:46.626821 139881799980800 logging_writer.py:48] [199014] accumulated_eval_time=7891.088857, accumulated_logging_time=10.479465, accumulated_submission_time=87427.407336, global_step=199014, preemption_count=0, score=87427.407336, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=95339.376462, train/accuracy=0.887910, train/loss=0.418094, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:36:21.383473 139881808373504 logging_writer.py:48] [199100] global_step=199100, grad_norm=3.214919328689575, loss=1.3033921718597412
I0303 13:37:05.768866 139881799980800 logging_writer.py:48] [199200] global_step=199200, grad_norm=2.9418067932128906, loss=2.4674549102783203
I0303 13:37:49.993857 139881808373504 logging_writer.py:48] [199300] global_step=199300, grad_norm=3.8404738903045654, loss=3.303615093231201
I0303 13:38:34.467195 139881799980800 logging_writer.py:48] [199400] global_step=199400, grad_norm=3.5987939834594727, loss=1.4160428047180176
I0303 13:39:18.757347 139881808373504 logging_writer.py:48] [199500] global_step=199500, grad_norm=3.0804283618927, loss=1.8096203804016113
I0303 13:40:02.961191 139881799980800 logging_writer.py:48] [199600] global_step=199600, grad_norm=3.2001352310180664, loss=1.139725685119629
I0303 13:40:47.410717 139881808373504 logging_writer.py:48] [199700] global_step=199700, grad_norm=3.2899367809295654, loss=2.362730026245117
I0303 13:41:31.863341 139881799980800 logging_writer.py:48] [199800] global_step=199800, grad_norm=3.2599546909332275, loss=1.17702317237854
I0303 13:42:16.364550 139881808373504 logging_writer.py:48] [199900] global_step=199900, grad_norm=4.337386131286621, loss=3.3127193450927734
I0303 13:42:46.690886 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:42:56.759569 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:43:30.038592 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:43:31.622877 140077943854912 submission_runner.py:411] Time since start: 95804.43s, 	Step: 199970, 	{'train/accuracy': 0.8871484398841858, 'train/loss': 0.41998371481895447, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 87847.40805268288, 'total_duration': 95804.42789506912, 'accumulated_submission_time': 87847.40805268288, 'accumulated_eval_time': 7936.020844221115, 'accumulated_logging_time': 10.547487020492554}
I0303 13:43:31.668346 139881799980800 logging_writer.py:48] [199970] accumulated_eval_time=7936.020844, accumulated_logging_time=10.547487, accumulated_submission_time=87847.408053, global_step=199970, preemption_count=0, score=87847.408053, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=95804.427895, train/accuracy=0.887148, train/loss=0.419984, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:43:43.750609 139881808373504 logging_writer.py:48] [200000] global_step=200000, grad_norm=3.826749563217163, loss=3.17016339302063
I0303 13:44:24.951799 139881799980800 logging_writer.py:48] [200100] global_step=200100, grad_norm=3.5762875080108643, loss=3.0108642578125
I0303 13:45:09.356230 139881808373504 logging_writer.py:48] [200200] global_step=200200, grad_norm=3.7159698009490967, loss=3.2993927001953125
I0303 13:45:53.928172 139881799980800 logging_writer.py:48] [200300] global_step=200300, grad_norm=3.1027708053588867, loss=1.1027190685272217
I0303 13:46:38.359354 139881808373504 logging_writer.py:48] [200400] global_step=200400, grad_norm=3.0136642456054688, loss=1.1721742153167725
I0303 13:47:22.894838 139881799980800 logging_writer.py:48] [200500] global_step=200500, grad_norm=3.3668277263641357, loss=1.0757722854614258
I0303 13:48:07.316658 139881808373504 logging_writer.py:48] [200600] global_step=200600, grad_norm=3.2481164932250977, loss=1.194935917854309
I0303 13:48:51.434453 139881799980800 logging_writer.py:48] [200700] global_step=200700, grad_norm=3.540187120437622, loss=3.185737133026123
I0303 13:49:36.004195 139881808373504 logging_writer.py:48] [200800] global_step=200800, grad_norm=3.1175169944763184, loss=2.613569974899292
I0303 13:50:20.480760 139881799980800 logging_writer.py:48] [200900] global_step=200900, grad_norm=3.310960054397583, loss=1.1789319515228271
I0303 13:50:31.624547 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:50:41.603084 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:51:06.099852 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:51:07.685817 140077943854912 submission_runner.py:411] Time since start: 96260.49s, 	Step: 200927, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.4186073839664459, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 88267.30465459824, 'total_duration': 96260.49082493782, 'accumulated_submission_time': 88267.30465459824, 'accumulated_eval_time': 7972.082072734833, 'accumulated_logging_time': 10.60279655456543}
I0303 13:51:07.745384 139881808373504 logging_writer.py:48] [200927] accumulated_eval_time=7972.082073, accumulated_logging_time=10.602797, accumulated_submission_time=88267.304655, global_step=200927, preemption_count=0, score=88267.304655, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=96260.490825, train/accuracy=0.888379, train/loss=0.418607, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:51:37.584787 139881799980800 logging_writer.py:48] [201000] global_step=201000, grad_norm=3.1751744747161865, loss=1.1827703714370728
I0303 13:52:21.785132 139881808373504 logging_writer.py:48] [201100] global_step=201100, grad_norm=3.010606527328491, loss=1.2449791431427002
I0303 13:53:06.547332 139881799980800 logging_writer.py:48] [201200] global_step=201200, grad_norm=3.1507434844970703, loss=2.8313281536102295
I0303 13:53:50.484399 139881808373504 logging_writer.py:48] [201300] global_step=201300, grad_norm=2.8662915229797363, loss=1.7012042999267578
I0303 13:54:34.723372 139881799980800 logging_writer.py:48] [201400] global_step=201400, grad_norm=2.807403087615967, loss=1.9101691246032715
I0303 13:55:19.340097 139881808373504 logging_writer.py:48] [201500] global_step=201500, grad_norm=3.6821818351745605, loss=3.2034897804260254
I0303 13:56:03.632368 139881799980800 logging_writer.py:48] [201600] global_step=201600, grad_norm=3.1486058235168457, loss=1.3780159950256348
I0303 13:56:48.210624 139881808373504 logging_writer.py:48] [201700] global_step=201700, grad_norm=3.136911392211914, loss=1.6299980878829956
I0303 13:57:32.714633 139881799980800 logging_writer.py:48] [201800] global_step=201800, grad_norm=3.8895103931427, loss=1.2104687690734863
I0303 13:58:07.947708 140077943854912 spec.py:321] Evaluating on the training split.
I0303 13:58:18.129142 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 13:58:45.924923 140077943854912 spec.py:349] Evaluating on the test split.
I0303 13:58:47.512413 140077943854912 submission_runner.py:411] Time since start: 96720.32s, 	Step: 201881, 	{'train/accuracy': 0.8891015648841858, 'train/loss': 0.40903109312057495, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 88686.67367577553, 'total_duration': 96720.31741762161, 'accumulated_submission_time': 88686.67367577553, 'accumulated_eval_time': 8011.646758794785, 'accumulated_logging_time': 11.446199417114258}
I0303 13:58:47.571849 139881808373504 logging_writer.py:48] [201881] accumulated_eval_time=8011.646759, accumulated_logging_time=11.446199, accumulated_submission_time=88686.673676, global_step=201881, preemption_count=0, score=88686.673676, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=96720.317418, train/accuracy=0.889102, train/loss=0.409031, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 13:58:55.368184 139881799980800 logging_writer.py:48] [201900] global_step=201900, grad_norm=3.2818994522094727, loss=1.136316180229187
I0303 13:59:36.349411 139881808373504 logging_writer.py:48] [202000] global_step=202000, grad_norm=3.165088415145874, loss=1.1293693780899048
I0303 14:00:20.724065 139881799980800 logging_writer.py:48] [202100] global_step=202100, grad_norm=3.418565511703491, loss=2.440183639526367
I0303 14:01:05.401853 139881808373504 logging_writer.py:48] [202200] global_step=202200, grad_norm=2.9326159954071045, loss=1.3882352113723755
I0303 14:01:49.377452 139881799980800 logging_writer.py:48] [202300] global_step=202300, grad_norm=3.0428788661956787, loss=1.415596604347229
I0303 14:02:33.789418 139881808373504 logging_writer.py:48] [202400] global_step=202400, grad_norm=4.012309551239014, loss=3.17720365524292
I0303 14:03:18.453682 139881799980800 logging_writer.py:48] [202500] global_step=202500, grad_norm=3.2934045791625977, loss=2.2477047443389893
I0303 14:04:02.671010 139881808373504 logging_writer.py:48] [202600] global_step=202600, grad_norm=3.394376754760742, loss=2.902500629425049
I0303 14:04:47.271418 139881799980800 logging_writer.py:48] [202700] global_step=202700, grad_norm=3.0173635482788086, loss=1.188240647315979
I0303 14:05:31.939411 139881808373504 logging_writer.py:48] [202800] global_step=202800, grad_norm=3.4549174308776855, loss=2.390451431274414
I0303 14:05:47.607463 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:05:57.636204 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:06:23.889818 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:06:25.477289 140077943854912 submission_runner.py:411] Time since start: 97178.28s, 	Step: 202837, 	{'train/accuracy': 0.88636714220047, 'train/loss': 0.4229801595211029, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 89106.6478202343, 'total_duration': 97178.28229618073, 'accumulated_submission_time': 89106.6478202343, 'accumulated_eval_time': 8049.51655459404, 'accumulated_logging_time': 11.518182754516602}
I0303 14:06:25.538337 139881799980800 logging_writer.py:48] [202837] accumulated_eval_time=8049.516555, accumulated_logging_time=11.518183, accumulated_submission_time=89106.647820, global_step=202837, preemption_count=0, score=89106.647820, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=97178.282296, train/accuracy=0.886367, train/loss=0.422980, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 14:06:50.539426 139881808373504 logging_writer.py:48] [202900] global_step=202900, grad_norm=3.2703258991241455, loss=1.180737018585205
I0303 14:07:34.536820 139881799980800 logging_writer.py:48] [203000] global_step=203000, grad_norm=3.3418848514556885, loss=1.1503604650497437
I0303 14:08:19.053859 139881808373504 logging_writer.py:48] [203100] global_step=203100, grad_norm=3.0662806034088135, loss=1.1602537631988525
I0303 14:09:03.806073 139881799980800 logging_writer.py:48] [203200] global_step=203200, grad_norm=3.77557635307312, loss=3.239988327026367
I0303 14:09:47.962563 139881808373504 logging_writer.py:48] [203300] global_step=203300, grad_norm=2.883010149002075, loss=1.0898821353912354
I0303 14:10:32.491947 139881799980800 logging_writer.py:48] [203400] global_step=203400, grad_norm=3.3749663829803467, loss=2.85670804977417
I0303 14:11:17.035705 139881808373504 logging_writer.py:48] [203500] global_step=203500, grad_norm=3.152655601501465, loss=1.6317381858825684
I0303 14:12:01.640100 139881799980800 logging_writer.py:48] [203600] global_step=203600, grad_norm=3.327342987060547, loss=1.1157176494598389
I0303 14:12:46.173125 139881808373504 logging_writer.py:48] [203700] global_step=203700, grad_norm=3.1154298782348633, loss=1.0285632610321045
I0303 14:13:25.888152 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:13:36.131423 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:14:02.513240 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:14:04.100349 140077943854912 submission_runner.py:411] Time since start: 97636.91s, 	Step: 203791, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.4164254367351532, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 89526.93627262115, 'total_duration': 97636.90535926819, 'accumulated_submission_time': 89526.93627262115, 'accumulated_eval_time': 8087.728713512421, 'accumulated_logging_time': 11.590760707855225}
I0303 14:14:04.158839 139881799980800 logging_writer.py:48] [203791] accumulated_eval_time=8087.728714, accumulated_logging_time=11.590761, accumulated_submission_time=89526.936273, global_step=203791, preemption_count=0, score=89526.936273, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=97636.905359, train/accuracy=0.888477, train/loss=0.416425, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 14:14:08.070268 139881808373504 logging_writer.py:48] [203800] global_step=203800, grad_norm=2.929730176925659, loss=1.1279844045639038
I0303 14:14:48.835464 139881799980800 logging_writer.py:48] [203900] global_step=203900, grad_norm=3.1542062759399414, loss=1.3780947923660278
I0303 14:15:33.293493 139881808373504 logging_writer.py:48] [204000] global_step=204000, grad_norm=3.219836473464966, loss=3.0275678634643555
I0303 14:16:17.772594 139881799980800 logging_writer.py:48] [204100] global_step=204100, grad_norm=3.1164987087249756, loss=1.1609573364257812
I0303 14:17:02.186170 139881808373504 logging_writer.py:48] [204200] global_step=204200, grad_norm=3.223705291748047, loss=1.2414960861206055
I0303 14:17:46.707878 139881799980800 logging_writer.py:48] [204300] global_step=204300, grad_norm=3.137251853942871, loss=1.283726692199707
I0303 14:18:31.114473 139881808373504 logging_writer.py:48] [204400] global_step=204400, grad_norm=3.175510883331299, loss=1.1118474006652832
I0303 14:19:15.618036 139881799980800 logging_writer.py:48] [204500] global_step=204500, grad_norm=2.8484835624694824, loss=1.5337094068527222
I0303 14:20:00.013885 139881808373504 logging_writer.py:48] [204600] global_step=204600, grad_norm=3.211026906967163, loss=2.680398941040039
I0303 14:20:44.474623 139881799980800 logging_writer.py:48] [204700] global_step=204700, grad_norm=2.9894020557403564, loss=1.2994109392166138
I0303 14:21:04.140547 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:21:14.045910 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:21:38.518524 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:21:40.111817 140077943854912 submission_runner.py:411] Time since start: 98092.92s, 	Step: 204745, 	{'train/accuracy': 0.8869921565055847, 'train/loss': 0.4216805696487427, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 89946.85517311096, 'total_duration': 98092.91681575775, 'accumulated_submission_time': 89946.85517311096, 'accumulated_eval_time': 8123.6999316215515, 'accumulated_logging_time': 11.662600040435791}
I0303 14:21:40.167587 139881808373504 logging_writer.py:48] [204745] accumulated_eval_time=8123.699932, accumulated_logging_time=11.662600, accumulated_submission_time=89946.855173, global_step=204745, preemption_count=0, score=89946.855173, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=98092.916816, train/accuracy=0.886992, train/loss=0.421681, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 14:22:02.034509 139881799980800 logging_writer.py:48] [204800] global_step=204800, grad_norm=3.107623338699341, loss=2.9109861850738525
I0303 14:22:45.795525 139881808373504 logging_writer.py:48] [204900] global_step=204900, grad_norm=2.75888729095459, loss=1.105239748954773
I0303 14:23:30.718268 139881799980800 logging_writer.py:48] [205000] global_step=205000, grad_norm=3.301492929458618, loss=1.2025818824768066
I0303 14:24:15.317331 139881808373504 logging_writer.py:48] [205100] global_step=205100, grad_norm=3.5072672367095947, loss=1.189915418624878
I0303 14:24:59.487776 139881799980800 logging_writer.py:48] [205200] global_step=205200, grad_norm=3.333829641342163, loss=2.246422052383423
I0303 14:25:44.188783 139881808373504 logging_writer.py:48] [205300] global_step=205300, grad_norm=3.6071012020111084, loss=1.292475700378418
I0303 14:26:28.817421 139881799980800 logging_writer.py:48] [205400] global_step=205400, grad_norm=3.0416452884674072, loss=1.1643025875091553
I0303 14:27:13.420620 139881808373504 logging_writer.py:48] [205500] global_step=205500, grad_norm=2.8357582092285156, loss=1.2381106615066528
I0303 14:27:57.804791 139881799980800 logging_writer.py:48] [205600] global_step=205600, grad_norm=2.9664201736450195, loss=1.0820566415786743
I0303 14:28:40.420666 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:28:50.367324 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:29:19.926146 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:29:21.541258 140077943854912 submission_runner.py:411] Time since start: 98554.35s, 	Step: 205697, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.42108798027038574, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 90367.04581069946, 'total_duration': 98554.3462498188, 'accumulated_submission_time': 90367.04581069946, 'accumulated_eval_time': 8164.820489406586, 'accumulated_logging_time': 11.730240821838379}
I0303 14:29:21.599890 139881808373504 logging_writer.py:48] [205697] accumulated_eval_time=8164.820489, accumulated_logging_time=11.730241, accumulated_submission_time=90367.045811, global_step=205697, preemption_count=0, score=90367.045811, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=98554.346250, train/accuracy=0.886738, train/loss=0.421088, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 14:29:23.159156 139881799980800 logging_writer.py:48] [205700] global_step=205700, grad_norm=3.055652141571045, loss=1.0979323387145996
I0303 14:30:02.692279 139881808373504 logging_writer.py:48] [205800] global_step=205800, grad_norm=2.9496090412139893, loss=1.1785576343536377
I0303 14:30:46.646975 139881799980800 logging_writer.py:48] [205900] global_step=205900, grad_norm=3.0714111328125, loss=1.2729544639587402
I0303 14:31:31.230343 139881808373504 logging_writer.py:48] [206000] global_step=206000, grad_norm=3.163975715637207, loss=1.0777528285980225
I0303 14:32:15.527452 139881799980800 logging_writer.py:48] [206100] global_step=206100, grad_norm=3.140897512435913, loss=2.7983200550079346
I0303 14:32:59.527320 139881808373504 logging_writer.py:48] [206200] global_step=206200, grad_norm=3.0918874740600586, loss=1.0698487758636475
I0303 14:33:44.013933 139881799980800 logging_writer.py:48] [206300] global_step=206300, grad_norm=3.5154895782470703, loss=1.5859097242355347
I0303 14:34:28.239044 139881808373504 logging_writer.py:48] [206400] global_step=206400, grad_norm=3.1833877563476562, loss=1.1521761417388916
I0303 14:35:12.933784 139881799980800 logging_writer.py:48] [206500] global_step=206500, grad_norm=4.327447891235352, loss=3.235963821411133
I0303 14:35:57.192283 139881808373504 logging_writer.py:48] [206600] global_step=206600, grad_norm=3.013780117034912, loss=1.238816499710083
I0303 14:36:22.055357 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:36:32.283797 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:36:52.848220 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:36:54.436531 140077943854912 submission_runner.py:411] Time since start: 99007.24s, 	Step: 206657, 	{'train/accuracy': 0.8891015648841858, 'train/loss': 0.4129902124404907, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 90787.44080162048, 'total_duration': 99007.24154257774, 'accumulated_submission_time': 90787.44080162048, 'accumulated_eval_time': 8197.201642036438, 'accumulated_logging_time': 11.799509048461914}
I0303 14:36:54.494146 139881799980800 logging_writer.py:48] [206657] accumulated_eval_time=8197.201642, accumulated_logging_time=11.799509, accumulated_submission_time=90787.440802, global_step=206657, preemption_count=0, score=90787.440802, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=99007.241543, train/accuracy=0.889102, train/loss=0.412990, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 14:37:11.659093 139881808373504 logging_writer.py:48] [206700] global_step=206700, grad_norm=3.2288148403167725, loss=1.0481795072555542
I0303 14:37:54.440577 139881799980800 logging_writer.py:48] [206800] global_step=206800, grad_norm=3.1542718410491943, loss=1.916727900505066
I0303 14:38:39.082531 139881808373504 logging_writer.py:48] [206900] global_step=206900, grad_norm=3.1337242126464844, loss=2.4590463638305664
I0303 14:39:23.831570 139881799980800 logging_writer.py:48] [207000] global_step=207000, grad_norm=3.101425886154175, loss=1.1603952646255493
I0303 14:40:08.238937 139881808373504 logging_writer.py:48] [207100] global_step=207100, grad_norm=3.823899984359741, loss=1.660784125328064
I0303 14:40:52.780989 139881799980800 logging_writer.py:48] [207200] global_step=207200, grad_norm=3.451392889022827, loss=1.3039311170578003
I0303 14:41:37.243449 139881808373504 logging_writer.py:48] [207300] global_step=207300, grad_norm=3.196260452270508, loss=1.0707122087478638
I0303 14:42:21.684600 139881799980800 logging_writer.py:48] [207400] global_step=207400, grad_norm=3.3799173831939697, loss=3.030104637145996
I0303 14:43:06.355672 139881808373504 logging_writer.py:48] [207500] global_step=207500, grad_norm=3.176398992538452, loss=1.999121069908142
I0303 14:43:50.857711 139881799980800 logging_writer.py:48] [207600] global_step=207600, grad_norm=3.385436534881592, loss=3.0224621295928955
I0303 14:43:54.886358 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:44:05.261734 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:44:27.851336 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:44:29.438759 140077943854912 submission_runner.py:411] Time since start: 99462.24s, 	Step: 207611, 	{'train/accuracy': 0.88818359375, 'train/loss': 0.4146837592124939, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 91207.7722082138, 'total_duration': 99462.24376773834, 'accumulated_submission_time': 91207.7722082138, 'accumulated_eval_time': 8231.754022359848, 'accumulated_logging_time': 11.868899822235107}
I0303 14:44:29.499557 139881808373504 logging_writer.py:48] [207611] accumulated_eval_time=8231.754022, accumulated_logging_time=11.868900, accumulated_submission_time=91207.772208, global_step=207611, preemption_count=0, score=91207.772208, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=99462.243768, train/accuracy=0.888184, train/loss=0.414684, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 14:45:06.160493 139881799980800 logging_writer.py:48] [207700] global_step=207700, grad_norm=2.889230489730835, loss=1.0477988719940186
I0303 14:45:50.241394 139881808373504 logging_writer.py:48] [207800] global_step=207800, grad_norm=3.1440882682800293, loss=1.025791049003601
I0303 14:46:34.905518 139881799980800 logging_writer.py:48] [207900] global_step=207900, grad_norm=3.2544729709625244, loss=1.1199270486831665
I0303 14:47:19.755306 139881808373504 logging_writer.py:48] [208000] global_step=208000, grad_norm=3.4373421669006348, loss=1.1721293926239014
I0303 14:48:04.116063 139881799980800 logging_writer.py:48] [208100] global_step=208100, grad_norm=3.0910985469818115, loss=1.2613896131515503
I0303 14:48:48.512935 139881808373504 logging_writer.py:48] [208200] global_step=208200, grad_norm=3.2183420658111572, loss=3.0212903022766113
I0303 14:49:33.199595 139881799980800 logging_writer.py:48] [208300] global_step=208300, grad_norm=3.168229818344116, loss=2.5258524417877197
I0303 14:50:17.569378 139881808373504 logging_writer.py:48] [208400] global_step=208400, grad_norm=3.281026840209961, loss=1.6786508560180664
I0303 14:51:02.121313 139881799980800 logging_writer.py:48] [208500] global_step=208500, grad_norm=3.89300537109375, loss=3.199836254119873
I0303 14:51:29.543096 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:51:39.528158 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:52:05.216675 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:52:06.811226 140077943854912 submission_runner.py:411] Time since start: 99919.62s, 	Step: 208563, 	{'train/accuracy': 0.8888476490974426, 'train/loss': 0.4169521927833557, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 91627.7535970211, 'total_duration': 99919.61623358727, 'accumulated_submission_time': 91627.7535970211, 'accumulated_eval_time': 8269.022126674652, 'accumulated_logging_time': 11.942992687225342}
I0303 14:52:06.873567 139881808373504 logging_writer.py:48] [208563] accumulated_eval_time=8269.022127, accumulated_logging_time=11.942993, accumulated_submission_time=91627.753597, global_step=208563, preemption_count=0, score=91627.753597, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=99919.616234, train/accuracy=0.888848, train/loss=0.416952, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 14:52:21.718911 139881799980800 logging_writer.py:48] [208600] global_step=208600, grad_norm=2.786567211151123, loss=1.6450655460357666
I0303 14:53:04.617286 139881808373504 logging_writer.py:48] [208700] global_step=208700, grad_norm=3.112541913986206, loss=1.3509867191314697
I0303 14:53:48.362638 139881799980800 logging_writer.py:48] [208800] global_step=208800, grad_norm=3.7667112350463867, loss=3.1097984313964844
I0303 14:54:32.898493 139881808373504 logging_writer.py:48] [208900] global_step=208900, grad_norm=3.154350519180298, loss=2.464552402496338
I0303 14:55:17.562211 139881799980800 logging_writer.py:48] [209000] global_step=209000, grad_norm=3.17378306388855, loss=2.5129547119140625
I0303 14:56:01.984194 139881808373504 logging_writer.py:48] [209100] global_step=209100, grad_norm=3.3712973594665527, loss=1.2568955421447754
I0303 14:56:46.714276 139881799980800 logging_writer.py:48] [209200] global_step=209200, grad_norm=2.8890509605407715, loss=1.2374062538146973
I0303 14:57:30.941125 139881808373504 logging_writer.py:48] [209300] global_step=209300, grad_norm=3.326411008834839, loss=1.3222559690475464
I0303 14:58:15.391884 139881799980800 logging_writer.py:48] [209400] global_step=209400, grad_norm=3.0081541538238525, loss=2.7577083110809326
I0303 14:58:59.689791 139881808373504 logging_writer.py:48] [209500] global_step=209500, grad_norm=3.2338778972625732, loss=1.20978844165802
I0303 14:59:06.966718 140077943854912 spec.py:321] Evaluating on the training split.
I0303 14:59:16.876894 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 14:59:51.778039 140077943854912 spec.py:349] Evaluating on the test split.
I0303 14:59:53.358698 140077943854912 submission_runner.py:411] Time since start: 100386.16s, 	Step: 209518, 	{'train/accuracy': 0.887011706829071, 'train/loss': 0.41652271151542664, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 92047.78227806091, 'total_duration': 100386.16372036934, 'accumulated_submission_time': 92047.78227806091, 'accumulated_eval_time': 8315.414091348648, 'accumulated_logging_time': 12.020440578460693}
I0303 14:59:53.405722 139881799980800 logging_writer.py:48] [209518] accumulated_eval_time=8315.414091, accumulated_logging_time=12.020441, accumulated_submission_time=92047.782278, global_step=209518, preemption_count=0, score=92047.782278, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=100386.163720, train/accuracy=0.887012, train/loss=0.416523, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:00:25.816872 139881808373504 logging_writer.py:48] [209600] global_step=209600, grad_norm=2.958098888397217, loss=1.665881633758545
I0303 15:01:09.115135 139881799980800 logging_writer.py:48] [209700] global_step=209700, grad_norm=2.9771690368652344, loss=1.1249650716781616
I0303 15:01:53.552817 139881808373504 logging_writer.py:48] [209800] global_step=209800, grad_norm=2.92728328704834, loss=1.8135838508605957
I0303 15:02:37.969501 139881808373504 logging_writer.py:48] [209900] global_step=209900, grad_norm=2.7754454612731934, loss=1.1529961824417114
I0303 15:03:22.243648 139881799980800 logging_writer.py:48] [210000] global_step=210000, grad_norm=3.3087775707244873, loss=1.0963436365127563
I0303 15:04:06.457404 139881808373504 logging_writer.py:48] [210100] global_step=210100, grad_norm=3.0792665481567383, loss=1.0646555423736572
I0303 15:04:50.752518 139881799980800 logging_writer.py:48] [210200] global_step=210200, grad_norm=2.9497201442718506, loss=1.2023423910140991
I0303 15:05:35.071877 139881808373504 logging_writer.py:48] [210300] global_step=210300, grad_norm=3.4229300022125244, loss=2.9551730155944824
I0303 15:06:19.248275 139881799980800 logging_writer.py:48] [210400] global_step=210400, grad_norm=4.467410564422607, loss=1.1141082048416138
I0303 15:06:53.712674 140077943854912 spec.py:321] Evaluating on the training split.
I0303 15:07:03.857169 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 15:07:29.026551 140077943854912 spec.py:349] Evaluating on the test split.
I0303 15:07:30.617290 140077943854912 submission_runner.py:411] Time since start: 100843.42s, 	Step: 210479, 	{'train/accuracy': 0.8866015672683716, 'train/loss': 0.42549705505371094, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 92468.02927017212, 'total_duration': 100843.42229747772, 'accumulated_submission_time': 92468.02927017212, 'accumulated_eval_time': 8352.31871843338, 'accumulated_logging_time': 12.077834129333496}
I0303 15:07:30.679854 139881808373504 logging_writer.py:48] [210479] accumulated_eval_time=8352.318718, accumulated_logging_time=12.077834, accumulated_submission_time=92468.029270, global_step=210479, preemption_count=0, score=92468.029270, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=100843.422297, train/accuracy=0.886602, train/loss=0.425497, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:07:39.402294 139881799980800 logging_writer.py:48] [210500] global_step=210500, grad_norm=3.1850531101226807, loss=1.1322722434997559
I0303 15:08:20.982139 139881808373504 logging_writer.py:48] [210600] global_step=210600, grad_norm=2.9776978492736816, loss=1.3145370483398438
I0303 15:09:05.250630 139881799980800 logging_writer.py:48] [210700] global_step=210700, grad_norm=2.904149293899536, loss=1.2432003021240234
I0303 15:09:49.381124 139881808373504 logging_writer.py:48] [210800] global_step=210800, grad_norm=2.922912359237671, loss=1.2626961469650269
I0303 15:10:33.739283 139881799980800 logging_writer.py:48] [210900] global_step=210900, grad_norm=3.268669366836548, loss=1.1227082014083862
I0303 15:11:18.028202 139881808373504 logging_writer.py:48] [211000] global_step=211000, grad_norm=2.782968759536743, loss=1.4665718078613281
I0303 15:12:02.274747 139881799980800 logging_writer.py:48] [211100] global_step=211100, grad_norm=3.186579465866089, loss=1.1028944253921509
I0303 15:12:46.933566 139881808373504 logging_writer.py:48] [211200] global_step=211200, grad_norm=3.0954861640930176, loss=1.2457871437072754
I0303 15:13:31.105881 139881799980800 logging_writer.py:48] [211300] global_step=211300, grad_norm=3.641962766647339, loss=1.1873363256454468
I0303 15:14:15.315259 139881808373504 logging_writer.py:48] [211400] global_step=211400, grad_norm=3.1719675064086914, loss=1.305215835571289
I0303 15:14:30.620504 140077943854912 spec.py:321] Evaluating on the training split.
I0303 15:14:40.975031 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 15:15:04.090306 140077943854912 spec.py:349] Evaluating on the test split.
I0303 15:15:05.681256 140077943854912 submission_runner.py:411] Time since start: 101298.49s, 	Step: 211435, 	{'train/accuracy': 0.8909765481948853, 'train/loss': 0.41114649176597595, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 92887.90784883499, 'total_duration': 101298.48625206947, 'accumulated_submission_time': 92887.90784883499, 'accumulated_eval_time': 8387.379422187805, 'accumulated_logging_time': 12.153021335601807}
I0303 15:15:05.740640 139881799980800 logging_writer.py:48] [211435] accumulated_eval_time=8387.379422, accumulated_logging_time=12.153021, accumulated_submission_time=92887.907849, global_step=211435, preemption_count=0, score=92887.907849, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=101298.486252, train/accuracy=0.890977, train/loss=0.411146, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:15:31.533874 139881808373504 logging_writer.py:48] [211500] global_step=211500, grad_norm=3.153902769088745, loss=1.9652774333953857
I0303 15:16:15.625755 139881799980800 logging_writer.py:48] [211600] global_step=211600, grad_norm=3.2635116577148438, loss=2.920053005218506
I0303 15:17:00.570602 139881808373504 logging_writer.py:48] [211700] global_step=211700, grad_norm=3.249000072479248, loss=1.1165322065353394
I0303 15:17:45.250147 139881799980800 logging_writer.py:48] [211800] global_step=211800, grad_norm=3.2818450927734375, loss=1.8535910844802856
I0303 15:18:29.747525 139881808373504 logging_writer.py:48] [211900] global_step=211900, grad_norm=3.5759165287017822, loss=2.994426965713501
I0303 15:19:14.303168 139881799980800 logging_writer.py:48] [212000] global_step=212000, grad_norm=3.238403558731079, loss=1.2036062479019165
I0303 15:19:58.680295 139881808373504 logging_writer.py:48] [212100] global_step=212100, grad_norm=3.3602664470672607, loss=1.2581645250320435
I0303 15:20:43.235496 139881799980800 logging_writer.py:48] [212200] global_step=212200, grad_norm=2.735136032104492, loss=1.2558319568634033
I0303 15:21:27.722050 139881808373504 logging_writer.py:48] [212300] global_step=212300, grad_norm=2.9256198406219482, loss=1.5481927394866943
I0303 15:22:05.820970 140077943854912 spec.py:321] Evaluating on the training split.
I0303 15:22:15.892710 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 15:22:38.998539 140077943854912 spec.py:349] Evaluating on the test split.
I0303 15:22:40.595098 140077943854912 submission_runner.py:411] Time since start: 101753.40s, 	Step: 212387, 	{'train/accuracy': 0.8878515362739563, 'train/loss': 0.4138557016849518, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 93307.92722892761, 'total_duration': 101753.40010499954, 'accumulated_submission_time': 93307.92722892761, 'accumulated_eval_time': 8422.15352678299, 'accumulated_logging_time': 12.22426986694336}
I0303 15:22:40.657373 139881799980800 logging_writer.py:48] [212387] accumulated_eval_time=8422.153527, accumulated_logging_time=12.224270, accumulated_submission_time=93307.927229, global_step=212387, preemption_count=0, score=93307.927229, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=101753.400105, train/accuracy=0.887852, train/loss=0.413856, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:22:46.161579 139881808373504 logging_writer.py:48] [212400] global_step=212400, grad_norm=3.481137990951538, loss=1.1835968494415283
I0303 15:23:27.238619 139881799980800 logging_writer.py:48] [212500] global_step=212500, grad_norm=3.1860527992248535, loss=1.1869052648544312
I0303 15:24:11.546596 139881808373504 logging_writer.py:48] [212600] global_step=212600, grad_norm=3.454730749130249, loss=3.0245649814605713
I0303 15:24:56.290629 139881799980800 logging_writer.py:48] [212700] global_step=212700, grad_norm=2.92077898979187, loss=1.1179721355438232
I0303 15:25:40.820978 139881808373504 logging_writer.py:48] [212800] global_step=212800, grad_norm=3.178196430206299, loss=2.642207145690918
I0303 15:26:25.231789 139881799980800 logging_writer.py:48] [212900] global_step=212900, grad_norm=3.0869452953338623, loss=1.864775538444519
I0303 15:27:09.854808 139881808373504 logging_writer.py:48] [213000] global_step=213000, grad_norm=2.9738504886627197, loss=2.236142635345459
I0303 15:27:54.072003 139881799980800 logging_writer.py:48] [213100] global_step=213100, grad_norm=3.0550146102905273, loss=1.123056411743164
I0303 15:28:38.434573 139881808373504 logging_writer.py:48] [213200] global_step=213200, grad_norm=3.46805477142334, loss=1.1947749853134155
I0303 15:29:22.923232 139881799980800 logging_writer.py:48] [213300] global_step=213300, grad_norm=2.924461841583252, loss=1.1457545757293701
I0303 15:29:40.847078 140077943854912 spec.py:321] Evaluating on the training split.
I0303 15:29:50.906965 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 15:30:25.559253 140077943854912 spec.py:349] Evaluating on the test split.
I0303 15:30:27.144102 140077943854912 submission_runner.py:411] Time since start: 102219.95s, 	Step: 213342, 	{'train/accuracy': 0.8890234231948853, 'train/loss': 0.41538408398628235, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 93728.0548722744, 'total_duration': 102219.9491224289, 'accumulated_submission_time': 93728.0548722744, 'accumulated_eval_time': 8468.450547218323, 'accumulated_logging_time': 12.29885721206665}
I0303 15:30:27.195593 139881808373504 logging_writer.py:48] [213342] accumulated_eval_time=8468.450547, accumulated_logging_time=12.298857, accumulated_submission_time=93728.054872, global_step=213342, preemption_count=0, score=93728.054872, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=102219.949122, train/accuracy=0.889023, train/loss=0.415384, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:30:50.211532 139881799980800 logging_writer.py:48] [213400] global_step=213400, grad_norm=3.0400123596191406, loss=1.1139211654663086
I0303 15:31:32.372576 139881808373504 logging_writer.py:48] [213500] global_step=213500, grad_norm=2.9377248287200928, loss=2.153172492980957
I0303 15:32:16.988203 139881799980800 logging_writer.py:48] [213600] global_step=213600, grad_norm=3.979796886444092, loss=3.199885845184326
I0303 15:33:01.388710 139881808373504 logging_writer.py:48] [213700] global_step=213700, grad_norm=3.4629247188568115, loss=2.881697416305542
I0303 15:33:45.725733 139881799980800 logging_writer.py:48] [213800] global_step=213800, grad_norm=3.1317379474639893, loss=1.8542613983154297
I0303 15:34:30.194152 139881808373504 logging_writer.py:48] [213900] global_step=213900, grad_norm=2.89778995513916, loss=1.1185564994812012
I0303 15:35:14.826884 139881799980800 logging_writer.py:48] [214000] global_step=214000, grad_norm=3.3477160930633545, loss=2.606276035308838
I0303 15:35:59.063024 139881808373504 logging_writer.py:48] [214100] global_step=214100, grad_norm=2.9087207317352295, loss=1.0421996116638184
I0303 15:36:43.519038 139881799980800 logging_writer.py:48] [214200] global_step=214200, grad_norm=2.95173978805542, loss=1.2148295640945435
I0303 15:37:27.208335 140077943854912 spec.py:321] Evaluating on the training split.
I0303 15:37:38.468932 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 15:38:00.925925 140077943854912 spec.py:349] Evaluating on the test split.
I0303 15:38:02.532051 140077943854912 submission_runner.py:411] Time since start: 102675.34s, 	Step: 214300, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.41216400265693665, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 94148.00626373291, 'total_duration': 102675.33705687523, 'accumulated_submission_time': 94148.00626373291, 'accumulated_eval_time': 8503.7742228508, 'accumulated_logging_time': 12.362093687057495}
I0303 15:38:02.595118 139881808373504 logging_writer.py:48] [214300] accumulated_eval_time=8503.774223, accumulated_logging_time=12.362094, accumulated_submission_time=94148.006264, global_step=214300, preemption_count=0, score=94148.006264, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=102675.337057, train/accuracy=0.888438, train/loss=0.412164, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:38:02.991940 139881799980800 logging_writer.py:48] [214300] global_step=214300, grad_norm=3.5324628353118896, loss=3.065530300140381
I0303 15:38:43.415265 139881808373504 logging_writer.py:48] [214400] global_step=214400, grad_norm=3.132309913635254, loss=1.465762734413147
I0303 15:39:27.797238 139881799980800 logging_writer.py:48] [214500] global_step=214500, grad_norm=3.3035528659820557, loss=1.687204122543335
I0303 15:40:12.142768 139881808373504 logging_writer.py:48] [214600] global_step=214600, grad_norm=3.4171762466430664, loss=1.1354427337646484
I0303 15:40:56.216849 139881799980800 logging_writer.py:48] [214700] global_step=214700, grad_norm=2.9906742572784424, loss=1.1123809814453125
I0303 15:41:40.526628 139881808373504 logging_writer.py:48] [214800] global_step=214800, grad_norm=3.5178496837615967, loss=1.077775239944458
I0303 15:42:24.726124 139881799980800 logging_writer.py:48] [214900] global_step=214900, grad_norm=3.839042901992798, loss=2.7417423725128174
I0303 15:43:09.208865 139881808373504 logging_writer.py:48] [215000] global_step=215000, grad_norm=3.4628968238830566, loss=2.6256303787231445
I0303 15:43:53.705171 139881799980800 logging_writer.py:48] [215100] global_step=215100, grad_norm=2.8741509914398193, loss=1.1409223079681396
I0303 15:44:38.204159 139881808373504 logging_writer.py:48] [215200] global_step=215200, grad_norm=3.0942158699035645, loss=1.1432275772094727
I0303 15:45:02.561765 140077943854912 spec.py:321] Evaluating on the training split.
I0303 15:45:13.007285 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 15:45:37.773947 140077943854912 spec.py:349] Evaluating on the test split.
I0303 15:45:39.361195 140077943854912 submission_runner.py:411] Time since start: 103132.17s, 	Step: 215256, 	{'train/accuracy': 0.8880078196525574, 'train/loss': 0.41702502965927124, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 94567.91206049919, 'total_duration': 103132.16620612144, 'accumulated_submission_time': 94567.91206049919, 'accumulated_eval_time': 8540.573637008667, 'accumulated_logging_time': 12.436352014541626}
I0303 15:45:39.421718 139881799980800 logging_writer.py:48] [215256] accumulated_eval_time=8540.573637, accumulated_logging_time=12.436352, accumulated_submission_time=94567.912060, global_step=215256, preemption_count=0, score=94567.912060, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=103132.166206, train/accuracy=0.888008, train/loss=0.417025, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:45:56.990262 139881808373504 logging_writer.py:48] [215300] global_step=215300, grad_norm=3.0854198932647705, loss=1.1105796098709106
I0303 15:46:40.668015 139881799980800 logging_writer.py:48] [215400] global_step=215400, grad_norm=2.951044797897339, loss=1.091113805770874
I0303 15:47:25.223835 139881808373504 logging_writer.py:48] [215500] global_step=215500, grad_norm=3.088747262954712, loss=2.1496806144714355
I0303 15:48:09.958270 139881799980800 logging_writer.py:48] [215600] global_step=215600, grad_norm=3.2034947872161865, loss=1.194885015487671
I0303 15:48:54.382442 139881808373504 logging_writer.py:48] [215700] global_step=215700, grad_norm=3.0625991821289062, loss=1.2330756187438965
I0303 15:49:38.885642 139881799980800 logging_writer.py:48] [215800] global_step=215800, grad_norm=3.0399134159088135, loss=1.2762277126312256
I0303 15:50:23.817361 139881808373504 logging_writer.py:48] [215900] global_step=215900, grad_norm=2.87294864654541, loss=1.8583879470825195
I0303 15:51:08.680212 139881799980800 logging_writer.py:48] [216000] global_step=216000, grad_norm=3.1917037963867188, loss=2.2645223140716553
I0303 15:51:53.037531 139881808373504 logging_writer.py:48] [216100] global_step=216100, grad_norm=3.2089388370513916, loss=2.7209084033966064
I0303 15:52:37.875498 139881799980800 logging_writer.py:48] [216200] global_step=216200, grad_norm=3.21915864944458, loss=1.2076573371887207
I0303 15:52:39.385563 140077943854912 spec.py:321] Evaluating on the training split.
I0303 15:52:49.419476 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 15:53:23.564346 140077943854912 spec.py:349] Evaluating on the test split.
I0303 15:53:25.141639 140077943854912 submission_runner.py:411] Time since start: 103597.95s, 	Step: 216205, 	{'train/accuracy': 0.8862890601158142, 'train/loss': 0.41875118017196655, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 94987.81290459633, 'total_duration': 103597.94665384293, 'accumulated_submission_time': 94987.81290459633, 'accumulated_eval_time': 8586.329691886902, 'accumulated_logging_time': 12.511003971099854}
I0303 15:53:25.195244 139881808373504 logging_writer.py:48] [216205] accumulated_eval_time=8586.329692, accumulated_logging_time=12.511004, accumulated_submission_time=94987.812905, global_step=216205, preemption_count=0, score=94987.812905, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=103597.946654, train/accuracy=0.886289, train/loss=0.418751, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 15:54:03.197510 139881799980800 logging_writer.py:48] [216300] global_step=216300, grad_norm=3.211317539215088, loss=1.3459392786026
I0303 15:54:47.430612 139881808373504 logging_writer.py:48] [216400] global_step=216400, grad_norm=3.231964588165283, loss=1.3525514602661133
I0303 15:55:32.162458 139881799980800 logging_writer.py:48] [216500] global_step=216500, grad_norm=3.0761830806732178, loss=1.1467139720916748
I0303 15:56:17.036151 139881808373504 logging_writer.py:48] [216600] global_step=216600, grad_norm=3.0764386653900146, loss=1.1400295495986938
I0303 15:57:01.364902 139881799980800 logging_writer.py:48] [216700] global_step=216700, grad_norm=3.373084783554077, loss=1.1551265716552734
I0303 15:57:45.959367 139881808373504 logging_writer.py:48] [216800] global_step=216800, grad_norm=2.9720683097839355, loss=1.1355540752410889
I0303 15:58:30.122399 139881799980800 logging_writer.py:48] [216900] global_step=216900, grad_norm=3.597012519836426, loss=1.3300518989562988
I0303 15:59:14.597455 139881808373504 logging_writer.py:48] [217000] global_step=217000, grad_norm=2.8810479640960693, loss=1.8572509288787842
I0303 15:59:58.842188 139881799980800 logging_writer.py:48] [217100] global_step=217100, grad_norm=3.100996971130371, loss=1.1695750951766968
I0303 16:00:25.251536 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:00:35.099670 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:00:55.098342 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:00:56.685932 140077943854912 submission_runner.py:411] Time since start: 104049.49s, 	Step: 217161, 	{'train/accuracy': 0.8904101252555847, 'train/loss': 0.40959882736206055, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 95407.80637645721, 'total_duration': 104049.49093866348, 'accumulated_submission_time': 95407.80637645721, 'accumulated_eval_time': 8617.764047384262, 'accumulated_logging_time': 12.574751377105713}
I0303 16:00:56.749848 139881808373504 logging_writer.py:48] [217161] accumulated_eval_time=8617.764047, accumulated_logging_time=12.574751, accumulated_submission_time=95407.806376, global_step=217161, preemption_count=0, score=95407.806376, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=104049.490939, train/accuracy=0.890410, train/loss=0.409599, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:01:12.386820 139881799980800 logging_writer.py:48] [217200] global_step=217200, grad_norm=3.348667860031128, loss=2.8943397998809814
I0303 16:01:55.649123 139881808373504 logging_writer.py:48] [217300] global_step=217300, grad_norm=3.7547757625579834, loss=3.070176362991333
I0303 16:02:39.907335 139881799980800 logging_writer.py:48] [217400] global_step=217400, grad_norm=3.1629250049591064, loss=1.7610548734664917
I0303 16:03:24.482217 139881808373504 logging_writer.py:48] [217500] global_step=217500, grad_norm=3.1608705520629883, loss=2.234866142272949
I0303 16:04:08.914036 139881799980800 logging_writer.py:48] [217600] global_step=217600, grad_norm=2.915456771850586, loss=1.3613574504852295
I0303 16:04:53.259665 139881808373504 logging_writer.py:48] [217700] global_step=217700, grad_norm=3.3671720027923584, loss=1.2751367092132568
I0303 16:05:37.713842 139881799980800 logging_writer.py:48] [217800] global_step=217800, grad_norm=4.224170684814453, loss=1.114326000213623
I0303 16:06:22.363653 139881808373504 logging_writer.py:48] [217900] global_step=217900, grad_norm=3.150963544845581, loss=1.2073911428451538
I0303 16:07:07.004552 139881799980800 logging_writer.py:48] [218000] global_step=218000, grad_norm=3.108612298965454, loss=2.0316665172576904
I0303 16:07:51.307318 139881808373504 logging_writer.py:48] [218100] global_step=218100, grad_norm=3.7759530544281006, loss=1.5767219066619873
I0303 16:07:56.815194 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:08:07.407344 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:08:43.416853 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:08:44.993865 140077943854912 submission_runner.py:411] Time since start: 104517.80s, 	Step: 218114, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.41770970821380615, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 95827.81059122086, 'total_duration': 104517.7988626957, 'accumulated_submission_time': 95827.81059122086, 'accumulated_eval_time': 8665.94267654419, 'accumulated_logging_time': 12.649450063705444}
I0303 16:08:45.050136 139881799980800 logging_writer.py:48] [218114] accumulated_eval_time=8665.942677, accumulated_logging_time=12.649450, accumulated_submission_time=95827.810591, global_step=218114, preemption_count=0, score=95827.810591, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=104517.798863, train/accuracy=0.888477, train/loss=0.417710, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:09:19.034814 139881808373504 logging_writer.py:48] [218200] global_step=218200, grad_norm=3.1191298961639404, loss=1.0915789604187012
I0303 16:10:02.984148 139881799980800 logging_writer.py:48] [218300] global_step=218300, grad_norm=3.2108919620513916, loss=1.344970703125
I0303 16:10:47.292794 139881808373504 logging_writer.py:48] [218400] global_step=218400, grad_norm=3.3855671882629395, loss=1.1380327939987183
I0303 16:11:31.837782 139881799980800 logging_writer.py:48] [218500] global_step=218500, grad_norm=3.2740511894226074, loss=1.5901730060577393
I0303 16:12:15.998042 139881808373504 logging_writer.py:48] [218600] global_step=218600, grad_norm=3.118424654006958, loss=1.669939398765564
I0303 16:13:00.221915 139881799980800 logging_writer.py:48] [218700] global_step=218700, grad_norm=3.007411003112793, loss=1.7379398345947266
I0303 16:13:44.639786 139881808373504 logging_writer.py:48] [218800] global_step=218800, grad_norm=2.924262762069702, loss=1.4283297061920166
I0303 16:14:29.265022 139881799980800 logging_writer.py:48] [218900] global_step=218900, grad_norm=3.2328073978424072, loss=1.3136839866638184
I0303 16:15:13.789081 139881808373504 logging_writer.py:48] [219000] global_step=219000, grad_norm=3.6111843585968018, loss=3.0449202060699463
I0303 16:15:45.345166 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:15:55.187006 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:16:25.833850 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:16:27.416329 140077943854912 submission_runner.py:411] Time since start: 104980.22s, 	Step: 219073, 	{'train/accuracy': 0.8863476514816284, 'train/loss': 0.4216277599334717, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 96248.04551506042, 'total_duration': 104980.22134375572, 'accumulated_submission_time': 96248.04551506042, 'accumulated_eval_time': 8708.01383304596, 'accumulated_logging_time': 12.715829849243164}
I0303 16:16:27.470205 139881799980800 logging_writer.py:48] [219073] accumulated_eval_time=8708.013833, accumulated_logging_time=12.715830, accumulated_submission_time=96248.045515, global_step=219073, preemption_count=0, score=96248.045515, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=104980.221344, train/accuracy=0.886348, train/loss=0.421628, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:16:38.388367 139881808373504 logging_writer.py:48] [219100] global_step=219100, grad_norm=3.684488296508789, loss=2.834744930267334
I0303 16:17:19.560814 139881799980800 logging_writer.py:48] [219200] global_step=219200, grad_norm=4.017938137054443, loss=3.234200954437256
I0303 16:18:03.990923 139881808373504 logging_writer.py:48] [219300] global_step=219300, grad_norm=2.9031803607940674, loss=1.3715429306030273
I0303 16:18:48.540965 139881799980800 logging_writer.py:48] [219400] global_step=219400, grad_norm=2.9849517345428467, loss=1.7987630367279053
I0303 16:19:32.912559 139881808373504 logging_writer.py:48] [219500] global_step=219500, grad_norm=3.022261619567871, loss=1.1221137046813965
I0303 16:20:17.405240 139881799980800 logging_writer.py:48] [219600] global_step=219600, grad_norm=3.2374227046966553, loss=1.1435242891311646
I0303 16:21:01.870204 139881808373504 logging_writer.py:48] [219700] global_step=219700, grad_norm=2.9986867904663086, loss=1.0870417356491089
I0303 16:21:46.266344 139881799980800 logging_writer.py:48] [219800] global_step=219800, grad_norm=3.5247082710266113, loss=1.0823185443878174
I0303 16:22:30.569561 139881808373504 logging_writer.py:48] [219900] global_step=219900, grad_norm=3.6504714488983154, loss=2.2907721996307373
I0303 16:23:15.214509 139881799980800 logging_writer.py:48] [220000] global_step=220000, grad_norm=3.1549293994903564, loss=1.0381425619125366
I0303 16:23:27.451826 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:23:38.111098 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:24:04.848106 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:24:06.429409 140077943854912 submission_runner.py:411] Time since start: 105439.23s, 	Step: 220029, 	{'train/accuracy': 0.8868749737739563, 'train/loss': 0.42275911569595337, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 96667.96599316597, 'total_duration': 105439.2344288826, 'accumulated_submission_time': 96667.96599316597, 'accumulated_eval_time': 8746.991399526596, 'accumulated_logging_time': 12.781568765640259}
I0303 16:24:06.487378 139881808373504 logging_writer.py:48] [220029] accumulated_eval_time=8746.991400, accumulated_logging_time=12.781569, accumulated_submission_time=96667.965993, global_step=220029, preemption_count=0, score=96667.965993, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=105439.234429, train/accuracy=0.886875, train/loss=0.422759, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:24:34.864937 139881799980800 logging_writer.py:48] [220100] global_step=220100, grad_norm=3.951268434524536, loss=3.2904322147369385
I0303 16:25:18.503137 139881808373504 logging_writer.py:48] [220200] global_step=220200, grad_norm=3.8644962310791016, loss=3.3049798011779785
I0303 16:26:03.010271 139881799980800 logging_writer.py:48] [220300] global_step=220300, grad_norm=3.2292673587799072, loss=1.213850736618042
I0303 16:26:47.589205 139881808373504 logging_writer.py:48] [220400] global_step=220400, grad_norm=3.418578624725342, loss=3.043610095977783
I0303 16:27:32.037782 139881799980800 logging_writer.py:48] [220500] global_step=220500, grad_norm=3.6694300174713135, loss=3.1437463760375977
I0303 16:28:16.708454 139881808373504 logging_writer.py:48] [220600] global_step=220600, grad_norm=3.0950136184692383, loss=1.5506048202514648
I0303 16:29:01.059047 139881799980800 logging_writer.py:48] [220700] global_step=220700, grad_norm=3.2889645099639893, loss=1.9175759553909302
I0303 16:29:45.455666 139881808373504 logging_writer.py:48] [220800] global_step=220800, grad_norm=3.2184860706329346, loss=1.1472015380859375
I0303 16:30:29.705302 139881799980800 logging_writer.py:48] [220900] global_step=220900, grad_norm=2.9298219680786133, loss=2.1894519329071045
I0303 16:31:06.655964 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:31:16.907961 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:31:42.917243 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:31:44.502053 140077943854912 submission_runner.py:411] Time since start: 105897.31s, 	Step: 220985, 	{'train/accuracy': 0.8891015648841858, 'train/loss': 0.4091844856739044, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 97088.07246875763, 'total_duration': 105897.30706262589, 'accumulated_submission_time': 97088.07246875763, 'accumulated_eval_time': 8784.837461471558, 'accumulated_logging_time': 12.851918935775757}
I0303 16:31:44.568682 139881808373504 logging_writer.py:48] [220985] accumulated_eval_time=8784.837461, accumulated_logging_time=12.851919, accumulated_submission_time=97088.072469, global_step=220985, preemption_count=0, score=97088.072469, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=105897.307063, train/accuracy=0.889102, train/loss=0.409184, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:31:50.816874 139881799980800 logging_writer.py:48] [221000] global_step=221000, grad_norm=2.9579038619995117, loss=1.1718332767486572
I0303 16:32:32.172017 139881808373504 logging_writer.py:48] [221100] global_step=221100, grad_norm=3.337338924407959, loss=1.3991711139678955
I0303 16:33:16.796066 139881799980800 logging_writer.py:48] [221200] global_step=221200, grad_norm=3.1946635246276855, loss=1.142573595046997
I0303 16:34:01.301926 139881808373504 logging_writer.py:48] [221300] global_step=221300, grad_norm=3.2047033309936523, loss=1.186623215675354
I0303 16:34:45.776077 139881799980800 logging_writer.py:48] [221400] global_step=221400, grad_norm=3.7556512355804443, loss=2.751314401626587
I0303 16:35:30.444355 139881808373504 logging_writer.py:48] [221500] global_step=221500, grad_norm=3.1569573879241943, loss=1.1466894149780273
I0303 16:36:14.879294 139881799980800 logging_writer.py:48] [221600] global_step=221600, grad_norm=3.2417614459991455, loss=1.089627742767334
I0303 16:36:59.152144 139881808373504 logging_writer.py:48] [221700] global_step=221700, grad_norm=4.298221111297607, loss=3.276806354522705
I0303 16:37:43.866557 139881799980800 logging_writer.py:48] [221800] global_step=221800, grad_norm=3.176201105117798, loss=1.0555527210235596
I0303 16:38:28.232357 139881808373504 logging_writer.py:48] [221900] global_step=221900, grad_norm=3.2757959365844727, loss=1.1927073001861572
I0303 16:38:44.755316 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:38:55.043277 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:39:26.602879 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:39:28.178501 140077943854912 submission_runner.py:411] Time since start: 106360.98s, 	Step: 221939, 	{'train/accuracy': 0.8893359303474426, 'train/loss': 0.4144483804702759, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 97508.19736647606, 'total_duration': 106360.98352241516, 'accumulated_submission_time': 97508.19736647606, 'accumulated_eval_time': 8828.260638713837, 'accumulated_logging_time': 12.930778980255127}
I0303 16:39:28.231438 139881799980800 logging_writer.py:48] [221939] accumulated_eval_time=8828.260639, accumulated_logging_time=12.930779, accumulated_submission_time=97508.197366, global_step=221939, preemption_count=0, score=97508.197366, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=106360.983522, train/accuracy=0.889336, train/loss=0.414448, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:39:52.446395 139881808373504 logging_writer.py:48] [222000] global_step=222000, grad_norm=2.9147887229919434, loss=1.3342608213424683
I0303 16:40:35.195131 139881799980800 logging_writer.py:48] [222100] global_step=222100, grad_norm=3.0521743297576904, loss=2.012345552444458
I0303 16:41:19.873978 139881808373504 logging_writer.py:48] [222200] global_step=222200, grad_norm=3.779694080352783, loss=1.1789846420288086
I0303 16:42:04.368688 139881799980800 logging_writer.py:48] [222300] global_step=222300, grad_norm=3.0558536052703857, loss=1.9683234691619873
I0303 16:42:48.532152 139881808373504 logging_writer.py:48] [222400] global_step=222400, grad_norm=3.049445152282715, loss=1.2146210670471191
I0303 16:43:32.841735 139881799980800 logging_writer.py:48] [222500] global_step=222500, grad_norm=2.9702556133270264, loss=1.0385410785675049
I0303 16:44:17.124713 139881808373504 logging_writer.py:48] [222600] global_step=222600, grad_norm=3.0417532920837402, loss=1.6791114807128906
I0303 16:45:01.691490 139881799980800 logging_writer.py:48] [222700] global_step=222700, grad_norm=2.8777916431427, loss=2.1235899925231934
I0303 16:45:46.047003 139881808373504 logging_writer.py:48] [222800] global_step=222800, grad_norm=3.2870378494262695, loss=2.221791982650757
I0303 16:46:28.508886 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:46:38.573832 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:47:03.052693 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:47:04.638683 140077943854912 submission_runner.py:411] Time since start: 106817.44s, 	Step: 222897, 	{'train/accuracy': 0.8866796493530273, 'train/loss': 0.4247627854347229, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 97928.41378474236, 'total_duration': 106817.44368696213, 'accumulated_submission_time': 97928.41378474236, 'accumulated_eval_time': 8864.390403270721, 'accumulated_logging_time': 12.995026588439941}
I0303 16:47:04.703960 139881799980800 logging_writer.py:48] [222897] accumulated_eval_time=8864.390403, accumulated_logging_time=12.995027, accumulated_submission_time=97928.413785, global_step=222897, preemption_count=0, score=97928.413785, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=106817.443687, train/accuracy=0.886680, train/loss=0.424763, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:47:06.270527 139881808373504 logging_writer.py:48] [222900] global_step=222900, grad_norm=3.0907392501831055, loss=1.1693575382232666
I0303 16:47:47.530087 139881799980800 logging_writer.py:48] [223000] global_step=223000, grad_norm=3.167612075805664, loss=1.4100180864334106
I0303 16:48:32.035532 139881808373504 logging_writer.py:48] [223100] global_step=223100, grad_norm=3.185004711151123, loss=1.1311061382293701
I0303 16:49:16.667337 139881799980800 logging_writer.py:48] [223200] global_step=223200, grad_norm=3.2147791385650635, loss=1.9538660049438477
I0303 16:50:01.194210 139881808373504 logging_writer.py:48] [223300] global_step=223300, grad_norm=3.0178799629211426, loss=1.226545810699463
I0303 16:50:46.016284 139881799980800 logging_writer.py:48] [223400] global_step=223400, grad_norm=3.138054370880127, loss=2.2138547897338867
I0303 16:51:30.435708 139881808373504 logging_writer.py:48] [223500] global_step=223500, grad_norm=2.9969887733459473, loss=1.0749335289001465
I0303 16:52:15.200248 139881799980800 logging_writer.py:48] [223600] global_step=223600, grad_norm=2.9970433712005615, loss=1.0831289291381836
I0303 16:52:59.597620 139881808373504 logging_writer.py:48] [223700] global_step=223700, grad_norm=3.4632132053375244, loss=3.026489734649658
I0303 16:53:44.805536 139881799980800 logging_writer.py:48] [223800] global_step=223800, grad_norm=3.1259779930114746, loss=1.216763973236084
I0303 16:54:04.731737 140077943854912 spec.py:321] Evaluating on the training split.
I0303 16:54:15.318831 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 16:54:37.722920 140077943854912 spec.py:349] Evaluating on the test split.
I0303 16:54:39.308754 140077943854912 submission_runner.py:411] Time since start: 107272.11s, 	Step: 223846, 	{'train/accuracy': 0.8874804377555847, 'train/loss': 0.4221131503582001, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 98348.38157367706, 'total_duration': 107272.11375570297, 'accumulated_submission_time': 98348.38157367706, 'accumulated_eval_time': 8898.96737408638, 'accumulated_logging_time': 13.071343421936035}
I0303 16:54:39.370070 139881808373504 logging_writer.py:48] [223846] accumulated_eval_time=8898.967374, accumulated_logging_time=13.071343, accumulated_submission_time=98348.381574, global_step=223846, preemption_count=0, score=98348.381574, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=107272.113756, train/accuracy=0.887480, train/loss=0.422113, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 16:55:00.848267 139881799980800 logging_writer.py:48] [223900] global_step=223900, grad_norm=3.4982199668884277, loss=2.697828769683838
I0303 16:55:44.736697 139881808373504 logging_writer.py:48] [224000] global_step=224000, grad_norm=3.3787999153137207, loss=1.8832780122756958
I0303 16:56:29.339764 139881799980800 logging_writer.py:48] [224100] global_step=224100, grad_norm=3.179894208908081, loss=1.1860127449035645
I0303 16:57:13.901946 139881808373504 logging_writer.py:48] [224200] global_step=224200, grad_norm=2.9980506896972656, loss=1.9371123313903809
I0303 16:57:58.349247 139881799980800 logging_writer.py:48] [224300] global_step=224300, grad_norm=3.185619354248047, loss=2.1328516006469727
I0303 16:58:42.917886 139881808373504 logging_writer.py:48] [224400] global_step=224400, grad_norm=3.381605863571167, loss=1.2159173488616943
I0303 16:59:27.603102 139881799980800 logging_writer.py:48] [224500] global_step=224500, grad_norm=3.526277542114258, loss=1.138131022453308
I0303 17:00:11.876102 139881808373504 logging_writer.py:48] [224600] global_step=224600, grad_norm=4.031432151794434, loss=3.2731173038482666
I0303 17:00:56.198174 139881799980800 logging_writer.py:48] [224700] global_step=224700, grad_norm=3.110548734664917, loss=1.3084067106246948
I0303 17:01:39.718059 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:01:49.649956 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:02:25.604906 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:02:27.182713 140077943854912 submission_runner.py:411] Time since start: 107739.99s, 	Step: 224799, 	{'train/accuracy': 0.8865624666213989, 'train/loss': 0.41656458377838135, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 98768.6687772274, 'total_duration': 107739.98773026466, 'accumulated_submission_time': 98768.6687772274, 'accumulated_eval_time': 8946.43201994896, 'accumulated_logging_time': 13.144215106964111}
I0303 17:02:27.236476 139881808373504 logging_writer.py:48] [224799] accumulated_eval_time=8946.432020, accumulated_logging_time=13.144215, accumulated_submission_time=98768.668777, global_step=224799, preemption_count=0, score=98768.668777, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=107739.987730, train/accuracy=0.886562, train/loss=0.416565, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:02:28.020221 139881799980800 logging_writer.py:48] [224800] global_step=224800, grad_norm=3.648742914199829, loss=3.0776915550231934
I0303 17:03:07.475055 139881808373504 logging_writer.py:48] [224900] global_step=224900, grad_norm=3.153006076812744, loss=1.5956276655197144
I0303 17:03:51.552750 139881799980800 logging_writer.py:48] [225000] global_step=225000, grad_norm=3.1102561950683594, loss=1.704077959060669
I0303 17:04:36.105094 139881808373504 logging_writer.py:48] [225100] global_step=225100, grad_norm=3.1604766845703125, loss=1.4433444738388062
I0303 17:05:20.616953 139881799980800 logging_writer.py:48] [225200] global_step=225200, grad_norm=3.056208848953247, loss=1.072649359703064
I0303 17:06:04.933810 139881808373504 logging_writer.py:48] [225300] global_step=225300, grad_norm=2.9953746795654297, loss=1.7720974683761597
I0303 17:06:49.568328 139881799980800 logging_writer.py:48] [225400] global_step=225400, grad_norm=3.4589977264404297, loss=2.750481128692627
I0303 17:07:33.881619 139881808373504 logging_writer.py:48] [225500] global_step=225500, grad_norm=3.4326212406158447, loss=1.1557692289352417
I0303 17:08:18.318577 139881799980800 logging_writer.py:48] [225600] global_step=225600, grad_norm=3.1040961742401123, loss=1.1279526948928833
I0303 17:09:03.028849 139881808373504 logging_writer.py:48] [225700] global_step=225700, grad_norm=4.622102737426758, loss=3.2821598052978516
I0303 17:09:27.613336 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:09:37.457718 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:09:58.170542 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:09:59.762543 140077943854912 submission_runner.py:411] Time since start: 108192.57s, 	Step: 225757, 	{'train/accuracy': 0.8892187476158142, 'train/loss': 0.41340669989585876, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 99188.98446559906, 'total_duration': 108192.5675497055, 'accumulated_submission_time': 99188.98446559906, 'accumulated_eval_time': 8978.581200838089, 'accumulated_logging_time': 13.209935903549194}
I0303 17:09:59.826338 139881799980800 logging_writer.py:48] [225757] accumulated_eval_time=8978.581201, accumulated_logging_time=13.209936, accumulated_submission_time=99188.984466, global_step=225757, preemption_count=0, score=99188.984466, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=108192.567550, train/accuracy=0.889219, train/loss=0.413407, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:10:17.027713 139881808373504 logging_writer.py:48] [225800] global_step=225800, grad_norm=2.9689600467681885, loss=1.1541147232055664
I0303 17:10:59.487945 139881799980800 logging_writer.py:48] [225900] global_step=225900, grad_norm=3.0964136123657227, loss=1.1358228921890259
I0303 17:11:43.853179 139881808373504 logging_writer.py:48] [226000] global_step=226000, grad_norm=3.1970911026000977, loss=1.2031681537628174
I0303 17:12:28.265313 139881799980800 logging_writer.py:48] [226100] global_step=226100, grad_norm=3.085689067840576, loss=1.1672241687774658
I0303 17:13:12.530186 139881808373504 logging_writer.py:48] [226200] global_step=226200, grad_norm=3.123577356338501, loss=1.4130538702011108
I0303 17:13:57.013601 139881799980800 logging_writer.py:48] [226300] global_step=226300, grad_norm=3.0794897079467773, loss=1.1552541255950928
I0303 17:14:41.452159 139881808373504 logging_writer.py:48] [226400] global_step=226400, grad_norm=3.19364070892334, loss=2.5446527004241943
I0303 17:15:25.773992 139881799980800 logging_writer.py:48] [226500] global_step=226500, grad_norm=3.299030303955078, loss=1.1563197374343872
I0303 17:16:10.382785 139881808373504 logging_writer.py:48] [226600] global_step=226600, grad_norm=3.2901394367218018, loss=2.147616386413574
I0303 17:16:54.787027 139881799980800 logging_writer.py:48] [226700] global_step=226700, grad_norm=3.4619781970977783, loss=1.5762813091278076
I0303 17:16:59.809556 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:17:10.259063 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:17:49.303979 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:17:50.885624 140077943854912 submission_runner.py:411] Time since start: 108663.69s, 	Step: 226713, 	{'train/accuracy': 0.8882030844688416, 'train/loss': 0.4167915880680084, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 99608.90122461319, 'total_duration': 108663.69064497948, 'accumulated_submission_time': 99608.90122461319, 'accumulated_eval_time': 9029.657244682312, 'accumulated_logging_time': 13.288574695587158}
I0303 17:17:50.934608 139881808373504 logging_writer.py:48] [226713] accumulated_eval_time=9029.657245, accumulated_logging_time=13.288575, accumulated_submission_time=99608.901225, global_step=226713, preemption_count=0, score=99608.901225, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=108663.690645, train/accuracy=0.888203, train/loss=0.416792, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:18:25.273903 139881799980800 logging_writer.py:48] [226800] global_step=226800, grad_norm=3.298487424850464, loss=1.0516159534454346
I0303 17:19:09.352298 139881808373504 logging_writer.py:48] [226900] global_step=226900, grad_norm=2.9473519325256348, loss=1.3738160133361816
I0303 17:19:53.941658 139881799980800 logging_writer.py:48] [227000] global_step=227000, grad_norm=3.369044303894043, loss=1.32973313331604
I0303 17:20:38.145646 139881808373504 logging_writer.py:48] [227100] global_step=227100, grad_norm=3.2728922367095947, loss=1.9804065227508545
I0303 17:21:22.635873 139881799980800 logging_writer.py:48] [227200] global_step=227200, grad_norm=3.6003541946411133, loss=1.286351203918457
I0303 17:22:07.069448 139881808373504 logging_writer.py:48] [227300] global_step=227300, grad_norm=2.745854616165161, loss=1.910561203956604
I0303 17:22:51.186923 139881799980800 logging_writer.py:48] [227400] global_step=227400, grad_norm=3.2918598651885986, loss=1.1182585954666138
I0303 17:23:35.728001 139881808373504 logging_writer.py:48] [227500] global_step=227500, grad_norm=3.1967716217041016, loss=1.088727355003357
I0303 17:24:20.271570 139881799980800 logging_writer.py:48] [227600] global_step=227600, grad_norm=3.1490628719329834, loss=1.2784278392791748
I0303 17:24:51.172256 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:25:00.836291 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:25:35.474352 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:25:37.053135 140077943854912 submission_runner.py:411] Time since start: 109129.86s, 	Step: 227672, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.4202496111392975, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 100029.07903766632, 'total_duration': 109129.8581469059, 'accumulated_submission_time': 100029.07903766632, 'accumulated_eval_time': 9075.538096427917, 'accumulated_logging_time': 13.347972631454468}
I0303 17:25:37.106006 139881808373504 logging_writer.py:48] [227672] accumulated_eval_time=9075.538096, accumulated_logging_time=13.347973, accumulated_submission_time=100029.079038, global_step=227672, preemption_count=0, score=100029.079038, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=109129.858147, train/accuracy=0.887383, train/loss=0.420250, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:25:48.417582 139881799980800 logging_writer.py:48] [227700] global_step=227700, grad_norm=3.1664927005767822, loss=1.1584446430206299
I0303 17:26:29.971159 139881808373504 logging_writer.py:48] [227800] global_step=227800, grad_norm=3.1701769828796387, loss=2.309746503829956
I0303 17:27:14.174284 139881799980800 logging_writer.py:48] [227900] global_step=227900, grad_norm=3.309061288833618, loss=2.359417676925659
I0303 17:27:58.587838 139881808373504 logging_writer.py:48] [228000] global_step=228000, grad_norm=3.05258846282959, loss=1.752403736114502
I0303 17:28:42.975193 139881799980800 logging_writer.py:48] [228100] global_step=228100, grad_norm=2.949730634689331, loss=1.050053596496582
I0303 17:29:27.488767 139881808373504 logging_writer.py:48] [228200] global_step=228200, grad_norm=3.0447311401367188, loss=1.1646703481674194
I0303 17:30:11.715594 139881799980800 logging_writer.py:48] [228300] global_step=228300, grad_norm=3.0116827487945557, loss=1.2803022861480713
I0303 17:30:55.971622 139881808373504 logging_writer.py:48] [228400] global_step=228400, grad_norm=3.348857879638672, loss=2.0249578952789307
I0303 17:31:39.997805 139881799980800 logging_writer.py:48] [228500] global_step=228500, grad_norm=3.1079049110412598, loss=2.23583722114563
I0303 17:32:24.322701 139881808373504 logging_writer.py:48] [228600] global_step=228600, grad_norm=3.0609939098358154, loss=2.3779447078704834
I0303 17:32:37.354031 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:32:47.634499 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:33:10.183345 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:33:11.775926 140077943854912 submission_runner.py:411] Time since start: 109584.58s, 	Step: 228631, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.4214226305484772, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 100449.26325941086, 'total_duration': 109584.58092451096, 'accumulated_submission_time': 100449.26325941086, 'accumulated_eval_time': 9109.95995593071, 'accumulated_logging_time': 13.414387702941895}
I0303 17:33:11.841269 139881799980800 logging_writer.py:48] [228631] accumulated_eval_time=9109.959956, accumulated_logging_time=13.414388, accumulated_submission_time=100449.263259, global_step=228631, preemption_count=0, score=100449.263259, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=109584.580925, train/accuracy=0.886465, train/loss=0.421423, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:33:39.622335 139881808373504 logging_writer.py:48] [228700] global_step=228700, grad_norm=3.1088011264801025, loss=2.28792667388916
I0303 17:34:23.984455 139881799980800 logging_writer.py:48] [228800] global_step=228800, grad_norm=3.0978879928588867, loss=2.640270471572876
I0303 17:35:08.258457 139881808373504 logging_writer.py:48] [228900] global_step=228900, grad_norm=3.1201462745666504, loss=1.0625745058059692
I0303 17:35:52.973488 139881799980800 logging_writer.py:48] [229000] global_step=229000, grad_norm=2.8000447750091553, loss=1.3704766035079956
I0303 17:36:37.273595 139881808373504 logging_writer.py:48] [229100] global_step=229100, grad_norm=3.318835973739624, loss=1.1159729957580566
I0303 17:37:21.756948 139881799980800 logging_writer.py:48] [229200] global_step=229200, grad_norm=3.48199462890625, loss=1.2837121486663818
I0303 17:38:06.349576 139881808373504 logging_writer.py:48] [229300] global_step=229300, grad_norm=3.47326397895813, loss=1.0434224605560303
I0303 17:38:50.740076 139881799980800 logging_writer.py:48] [229400] global_step=229400, grad_norm=3.644441843032837, loss=1.0332703590393066
I0303 17:39:35.389056 139881808373504 logging_writer.py:48] [229500] global_step=229500, grad_norm=3.108098268508911, loss=2.514071464538574
I0303 17:40:12.098814 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:40:22.658235 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:40:48.932563 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:40:50.523393 140077943854912 submission_runner.py:411] Time since start: 110043.33s, 	Step: 229584, 	{'train/accuracy': 0.8885351419448853, 'train/loss': 0.4174453616142273, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 100869.45522499084, 'total_duration': 110043.32839989662, 'accumulated_submission_time': 100869.45522499084, 'accumulated_eval_time': 9148.38451385498, 'accumulated_logging_time': 13.495585680007935}
I0303 17:40:50.613422 139881799980800 logging_writer.py:48] [229584] accumulated_eval_time=9148.384514, accumulated_logging_time=13.495586, accumulated_submission_time=100869.455225, global_step=229584, preemption_count=0, score=100869.455225, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=110043.328400, train/accuracy=0.888535, train/loss=0.417445, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:40:57.258281 139881808373504 logging_writer.py:48] [229600] global_step=229600, grad_norm=3.7010183334350586, loss=3.204012632369995
I0303 17:41:38.939542 139881799980800 logging_writer.py:48] [229700] global_step=229700, grad_norm=3.010835647583008, loss=1.1343021392822266
I0303 17:42:23.561549 139881808373504 logging_writer.py:48] [229800] global_step=229800, grad_norm=3.1217942237854004, loss=1.1724185943603516
I0303 17:43:08.566316 139881799980800 logging_writer.py:48] [229900] global_step=229900, grad_norm=2.9076855182647705, loss=1.0771660804748535
I0303 17:43:53.138915 139881808373504 logging_writer.py:48] [230000] global_step=230000, grad_norm=2.801056385040283, loss=1.5097929239273071
I0303 17:44:37.766835 139881799980800 logging_writer.py:48] [230100] global_step=230100, grad_norm=4.080771446228027, loss=3.2103288173675537
I0303 17:45:22.612246 139881808373504 logging_writer.py:48] [230200] global_step=230200, grad_norm=3.236785411834717, loss=1.2683316469192505
I0303 17:46:07.380401 139881799980800 logging_writer.py:48] [230300] global_step=230300, grad_norm=3.103597402572632, loss=1.6512742042541504
I0303 17:46:51.946064 139881808373504 logging_writer.py:48] [230400] global_step=230400, grad_norm=3.0092551708221436, loss=1.0668907165527344
I0303 17:47:36.697930 139881799980800 logging_writer.py:48] [230500] global_step=230500, grad_norm=3.127403497695923, loss=2.802363872528076
I0303 17:47:50.960163 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:48:00.672452 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:48:24.703797 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:48:26.292898 140077943854912 submission_runner.py:411] Time since start: 110499.10s, 	Step: 230534, 	{'train/accuracy': 0.8880273103713989, 'train/loss': 0.4105813503265381, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 101289.73925161362, 'total_duration': 110499.09790325165, 'accumulated_submission_time': 101289.73925161362, 'accumulated_eval_time': 9183.717219114304, 'accumulated_logging_time': 13.598756313323975}
I0303 17:48:26.354382 139881808373504 logging_writer.py:48] [230534] accumulated_eval_time=9183.717219, accumulated_logging_time=13.598756, accumulated_submission_time=101289.739252, global_step=230534, preemption_count=0, score=101289.739252, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=110499.097903, train/accuracy=0.888027, train/loss=0.410581, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:48:52.514649 139881799980800 logging_writer.py:48] [230600] global_step=230600, grad_norm=3.383131742477417, loss=1.0613155364990234
I0303 17:49:36.421313 139881808373504 logging_writer.py:48] [230700] global_step=230700, grad_norm=3.137131690979004, loss=1.095719337463379
I0303 17:50:20.837286 139881799980800 logging_writer.py:48] [230800] global_step=230800, grad_norm=2.8593733310699463, loss=1.2316418886184692
I0303 17:51:05.228805 139881808373504 logging_writer.py:48] [230900] global_step=230900, grad_norm=3.1273934841156006, loss=2.4994187355041504
I0303 17:51:49.333178 139881799980800 logging_writer.py:48] [231000] global_step=231000, grad_norm=3.0092430114746094, loss=1.1368842124938965
I0303 17:52:33.743673 139881808373504 logging_writer.py:48] [231100] global_step=231100, grad_norm=3.1022284030914307, loss=1.0451583862304688
I0303 17:53:18.102932 139881799980800 logging_writer.py:48] [231200] global_step=231200, grad_norm=3.055948495864868, loss=1.2063324451446533
I0303 17:54:02.526299 139881808373504 logging_writer.py:48] [231300] global_step=231300, grad_norm=3.0345990657806396, loss=1.143670678138733
I0303 17:54:47.030542 139881799980800 logging_writer.py:48] [231400] global_step=231400, grad_norm=3.4205572605133057, loss=1.477168083190918
I0303 17:55:26.383416 140077943854912 spec.py:321] Evaluating on the training split.
I0303 17:55:36.390963 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 17:56:03.525132 140077943854912 spec.py:349] Evaluating on the test split.
I0303 17:56:05.105754 140077943854912 submission_runner.py:411] Time since start: 110957.91s, 	Step: 231490, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.4188116490840912, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 101709.70796656609, 'total_duration': 110957.91074514389, 'accumulated_submission_time': 101709.70796656609, 'accumulated_eval_time': 9222.439522743225, 'accumulated_logging_time': 13.67095160484314}
I0303 17:56:05.172329 139881808373504 logging_writer.py:48] [231490] accumulated_eval_time=9222.439523, accumulated_logging_time=13.670952, accumulated_submission_time=101709.707967, global_step=231490, preemption_count=0, score=101709.707967, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=110957.910745, train/accuracy=0.887500, train/loss=0.418812, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 17:56:09.480434 139881799980800 logging_writer.py:48] [231500] global_step=231500, grad_norm=3.315052032470703, loss=1.446128249168396
I0303 17:56:50.399108 139881808373504 logging_writer.py:48] [231600] global_step=231600, grad_norm=3.214582920074463, loss=1.102899432182312
I0303 17:57:34.906840 139881799980800 logging_writer.py:48] [231700] global_step=231700, grad_norm=3.3601717948913574, loss=2.8109400272369385
I0303 17:58:19.632287 139881808373504 logging_writer.py:48] [231800] global_step=231800, grad_norm=3.0534849166870117, loss=1.4083250761032104
I0303 17:59:03.916781 139881799980800 logging_writer.py:48] [231900] global_step=231900, grad_norm=3.9900548458099365, loss=3.2913284301757812
I0303 17:59:48.152984 139881808373504 logging_writer.py:48] [232000] global_step=232000, grad_norm=3.50537109375, loss=1.1210401058197021
I0303 18:00:32.636780 139881799980800 logging_writer.py:48] [232100] global_step=232100, grad_norm=3.45628023147583, loss=1.4839041233062744
I0303 18:01:16.850985 139881808373504 logging_writer.py:48] [232200] global_step=232200, grad_norm=3.066072702407837, loss=2.401625633239746
I0303 18:02:00.994915 139881799980800 logging_writer.py:48] [232300] global_step=232300, grad_norm=3.125776767730713, loss=1.2967778444290161
I0303 18:02:45.375005 139881808373504 logging_writer.py:48] [232400] global_step=232400, grad_norm=2.9052212238311768, loss=1.989917278289795
I0303 18:03:05.155801 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:03:15.109170 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:03:41.126618 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:03:42.717784 140077943854912 submission_runner.py:411] Time since start: 111415.52s, 	Step: 232446, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.4167661666870117, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 102129.62954187393, 'total_duration': 111415.52277565002, 'accumulated_submission_time': 102129.62954187393, 'accumulated_eval_time': 9260.00146317482, 'accumulated_logging_time': 13.750562906265259}
I0303 18:03:42.783597 139881799980800 logging_writer.py:48] [232446] accumulated_eval_time=9260.001463, accumulated_logging_time=13.750563, accumulated_submission_time=102129.629542, global_step=232446, preemption_count=0, score=102129.629542, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=111415.522776, train/accuracy=0.888730, train/loss=0.416766, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:04:04.328228 139881808373504 logging_writer.py:48] [232500] global_step=232500, grad_norm=3.6883723735809326, loss=3.2099153995513916
I0303 18:04:47.484396 139881799980800 logging_writer.py:48] [232600] global_step=232600, grad_norm=2.981726884841919, loss=1.0378875732421875
I0303 18:05:32.163756 139881808373504 logging_writer.py:48] [232700] global_step=232700, grad_norm=3.2528607845306396, loss=1.1452593803405762
I0303 18:06:17.002341 139881799980800 logging_writer.py:48] [232800] global_step=232800, grad_norm=3.3706884384155273, loss=1.1285741329193115
I0303 18:07:01.535272 139881808373504 logging_writer.py:48] [232900] global_step=232900, grad_norm=3.2018964290618896, loss=1.161404013633728
I0303 18:07:45.939621 139881799980800 logging_writer.py:48] [233000] global_step=233000, grad_norm=4.024102210998535, loss=3.4001822471618652
I0303 18:08:30.531211 139881808373504 logging_writer.py:48] [233100] global_step=233100, grad_norm=3.8303141593933105, loss=3.2863988876342773
I0303 18:09:15.070292 139881799980800 logging_writer.py:48] [233200] global_step=233200, grad_norm=3.269444465637207, loss=1.1972030401229858
I0303 18:09:59.305238 139881808373504 logging_writer.py:48] [233300] global_step=233300, grad_norm=2.83575439453125, loss=1.7495638132095337
I0303 18:10:42.813074 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:10:52.665626 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:11:21.352536 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:11:22.947210 140077943854912 submission_runner.py:411] Time since start: 111875.75s, 	Step: 233400, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.4170728921890259, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 102549.59725284576, 'total_duration': 111875.75222849846, 'accumulated_submission_time': 102549.59725284576, 'accumulated_eval_time': 9300.135597705841, 'accumulated_logging_time': 13.828028678894043}
I0303 18:11:23.000349 139881799980800 logging_writer.py:48] [233400] accumulated_eval_time=9300.135598, accumulated_logging_time=13.828029, accumulated_submission_time=102549.597253, global_step=233400, preemption_count=0, score=102549.597253, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=111875.752228, train/accuracy=0.887500, train/loss=0.417073, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:11:23.393578 139881808373504 logging_writer.py:48] [233400] global_step=233400, grad_norm=2.9002883434295654, loss=1.0885193347930908
I0303 18:12:02.727248 139881799980800 logging_writer.py:48] [233500] global_step=233500, grad_norm=2.8883025646209717, loss=2.0312154293060303
I0303 18:12:46.803368 139881808373504 logging_writer.py:48] [233600] global_step=233600, grad_norm=3.7946527004241943, loss=1.167073130607605
I0303 18:13:31.536437 139881799980800 logging_writer.py:48] [233700] global_step=233700, grad_norm=3.3155202865600586, loss=1.1254658699035645
I0303 18:14:15.822503 139881808373504 logging_writer.py:48] [233800] global_step=233800, grad_norm=3.122671604156494, loss=1.1051974296569824
I0303 18:15:00.019207 139881799980800 logging_writer.py:48] [233900] global_step=233900, grad_norm=2.836052656173706, loss=1.8175581693649292
I0303 18:15:44.397964 139881808373504 logging_writer.py:48] [234000] global_step=234000, grad_norm=3.469064950942993, loss=3.130272626876831
I0303 18:16:28.894787 139881799980800 logging_writer.py:48] [234100] global_step=234100, grad_norm=3.20973801612854, loss=1.2394378185272217
I0303 18:17:13.297929 139881808373504 logging_writer.py:48] [234200] global_step=234200, grad_norm=4.126125335693359, loss=1.0822851657867432
I0303 18:17:57.319906 139881799980800 logging_writer.py:48] [234300] global_step=234300, grad_norm=3.093825578689575, loss=1.1542339324951172
I0303 18:18:23.157686 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:18:32.990617 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:19:02.176210 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:19:03.763530 140077943854912 submission_runner.py:411] Time since start: 112336.57s, 	Step: 234360, 	{'train/accuracy': 0.8882030844688416, 'train/loss': 0.4220650792121887, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 102969.69378328323, 'total_duration': 112336.56853604317, 'accumulated_submission_time': 102969.69378328323, 'accumulated_eval_time': 9340.741424560547, 'accumulated_logging_time': 13.89189600944519}
I0303 18:19:03.830034 139881808373504 logging_writer.py:48] [234360] accumulated_eval_time=9340.741425, accumulated_logging_time=13.891896, accumulated_submission_time=102969.693783, global_step=234360, preemption_count=0, score=102969.693783, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=112336.568536, train/accuracy=0.888203, train/loss=0.422065, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:19:19.837901 139881799980800 logging_writer.py:48] [234400] global_step=234400, grad_norm=3.204272747039795, loss=1.1080389022827148
I0303 18:20:01.962791 139881808373504 logging_writer.py:48] [234500] global_step=234500, grad_norm=3.0297486782073975, loss=1.1855995655059814
I0303 18:20:46.493211 139881799980800 logging_writer.py:48] [234600] global_step=234600, grad_norm=3.0613722801208496, loss=1.3156888484954834
I0303 18:21:30.694213 139881808373504 logging_writer.py:48] [234700] global_step=234700, grad_norm=3.194782257080078, loss=1.6416611671447754
I0303 18:22:14.921371 139881799980800 logging_writer.py:48] [234800] global_step=234800, grad_norm=3.09352970123291, loss=2.3751559257507324
I0303 18:22:59.100854 139881808373504 logging_writer.py:48] [234900] global_step=234900, grad_norm=3.01672625541687, loss=2.299504280090332
I0303 18:23:43.522381 139881799980800 logging_writer.py:48] [235000] global_step=235000, grad_norm=3.5481038093566895, loss=2.8433501720428467
I0303 18:24:27.902533 139881808373504 logging_writer.py:48] [235100] global_step=235100, grad_norm=3.0488595962524414, loss=1.071182370185852
I0303 18:25:12.384320 139881799980800 logging_writer.py:48] [235200] global_step=235200, grad_norm=3.140895366668701, loss=1.1146690845489502
I0303 18:25:56.617828 139881808373504 logging_writer.py:48] [235300] global_step=235300, grad_norm=3.0930306911468506, loss=1.136863112449646
I0303 18:26:04.009769 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:26:14.401664 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:26:41.978701 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:26:43.565165 140077943854912 submission_runner.py:411] Time since start: 112796.37s, 	Step: 235318, 	{'train/accuracy': 0.88818359375, 'train/loss': 0.4170994460582733, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 103389.81013679504, 'total_duration': 112796.37017011642, 'accumulated_submission_time': 103389.81013679504, 'accumulated_eval_time': 9380.29682302475, 'accumulated_logging_time': 13.971137523651123}
I0303 18:26:43.628134 139881799980800 logging_writer.py:48] [235318] accumulated_eval_time=9380.296823, accumulated_logging_time=13.971138, accumulated_submission_time=103389.810137, global_step=235318, preemption_count=0, score=103389.810137, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=112796.370170, train/accuracy=0.888184, train/loss=0.417099, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:27:16.842544 139881808373504 logging_writer.py:48] [235400] global_step=235400, grad_norm=4.69944429397583, loss=1.1287046670913696
I0303 18:28:01.065061 139881799980800 logging_writer.py:48] [235500] global_step=235500, grad_norm=2.9825198650360107, loss=1.2307565212249756
I0303 18:28:45.882177 139881808373504 logging_writer.py:48] [235600] global_step=235600, grad_norm=2.9931061267852783, loss=1.1195456981658936
I0303 18:29:30.513008 139881799980800 logging_writer.py:48] [235700] global_step=235700, grad_norm=3.3376402854919434, loss=2.684288263320923
I0303 18:30:14.860982 139881808373504 logging_writer.py:48] [235800] global_step=235800, grad_norm=3.4903018474578857, loss=2.2233588695526123
I0303 18:30:59.214352 139881799980800 logging_writer.py:48] [235900] global_step=235900, grad_norm=3.6979246139526367, loss=3.061286211013794
I0303 18:31:43.571194 139881808373504 logging_writer.py:48] [236000] global_step=236000, grad_norm=3.479358196258545, loss=1.1657962799072266
I0303 18:32:27.896321 139881799980800 logging_writer.py:48] [236100] global_step=236100, grad_norm=3.2195160388946533, loss=1.123582363128662
I0303 18:33:12.437950 139881808373504 logging_writer.py:48] [236200] global_step=236200, grad_norm=2.9858574867248535, loss=1.6192156076431274
I0303 18:33:43.686260 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:33:53.784847 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:34:30.561589 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:34:32.135594 140077943854912 submission_runner.py:411] Time since start: 113264.94s, 	Step: 236272, 	{'train/accuracy': 0.888671875, 'train/loss': 0.4124659597873688, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 103809.80734848976, 'total_duration': 113264.9406042099, 'accumulated_submission_time': 103809.80734848976, 'accumulated_eval_time': 9428.746124267578, 'accumulated_logging_time': 14.04552173614502}
I0303 18:34:32.186819 139881799980800 logging_writer.py:48] [236272] accumulated_eval_time=9428.746124, accumulated_logging_time=14.045522, accumulated_submission_time=103809.807348, global_step=236272, preemption_count=0, score=103809.807348, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=113264.940604, train/accuracy=0.888672, train/loss=0.412466, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:34:43.717030 139881808373504 logging_writer.py:48] [236300] global_step=236300, grad_norm=3.6471996307373047, loss=2.942282199859619
I0303 18:35:24.749465 139881799980800 logging_writer.py:48] [236400] global_step=236400, grad_norm=3.1968464851379395, loss=1.2302870750427246
I0303 18:36:09.119408 139881808373504 logging_writer.py:48] [236500] global_step=236500, grad_norm=3.5324273109436035, loss=3.077875852584839
I0303 18:36:53.496725 139881799980800 logging_writer.py:48] [236600] global_step=236600, grad_norm=2.8249237537384033, loss=1.0786473751068115
I0303 18:37:37.791601 139881808373504 logging_writer.py:48] [236700] global_step=236700, grad_norm=3.246222734451294, loss=1.6730945110321045
I0303 18:38:22.405945 139881799980800 logging_writer.py:48] [236800] global_step=236800, grad_norm=3.0649166107177734, loss=1.1170737743377686
I0303 18:39:07.268542 139881808373504 logging_writer.py:48] [236900] global_step=236900, grad_norm=4.288969993591309, loss=3.2417919635772705
I0303 18:39:51.429078 139881799980800 logging_writer.py:48] [237000] global_step=237000, grad_norm=3.0717406272888184, loss=2.2139358520507812
I0303 18:40:35.980926 139881808373504 logging_writer.py:48] [237100] global_step=237100, grad_norm=3.675906181335449, loss=3.1684443950653076
I0303 18:41:20.437098 139881799980800 logging_writer.py:48] [237200] global_step=237200, grad_norm=3.046818733215332, loss=1.0236608982086182
I0303 18:41:32.523939 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:41:42.530229 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:42:10.892177 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:42:12.486528 140077943854912 submission_runner.py:411] Time since start: 113725.29s, 	Step: 237229, 	{'train/accuracy': 0.8904492259025574, 'train/loss': 0.4119705855846405, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 104230.0831682682, 'total_duration': 113725.29149913788, 'accumulated_submission_time': 104230.0831682682, 'accumulated_eval_time': 9468.708633422852, 'accumulated_logging_time': 14.108554124832153}
I0303 18:42:12.594326 139881808373504 logging_writer.py:48] [237229] accumulated_eval_time=9468.708633, accumulated_logging_time=14.108554, accumulated_submission_time=104230.083168, global_step=237229, preemption_count=0, score=104230.083168, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=113725.291499, train/accuracy=0.890449, train/loss=0.411971, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:42:40.737857 139881799980800 logging_writer.py:48] [237300] global_step=237300, grad_norm=2.919177770614624, loss=1.1537226438522339
I0303 18:43:24.662514 139881808373504 logging_writer.py:48] [237400] global_step=237400, grad_norm=3.2380104064941406, loss=1.1162258386611938
I0303 18:44:09.437359 139881799980800 logging_writer.py:48] [237500] global_step=237500, grad_norm=3.426734447479248, loss=2.4407782554626465
I0303 18:44:53.844718 139881808373504 logging_writer.py:48] [237600] global_step=237600, grad_norm=3.7524523735046387, loss=1.1955558061599731
I0303 18:45:38.080601 139881799980800 logging_writer.py:48] [237700] global_step=237700, grad_norm=3.052826404571533, loss=1.080713152885437
I0303 18:46:22.457947 139881808373504 logging_writer.py:48] [237800] global_step=237800, grad_norm=3.5336575508117676, loss=1.1732276678085327
I0303 18:47:06.934037 139881799980800 logging_writer.py:48] [237900] global_step=237900, grad_norm=2.959926128387451, loss=1.4262887239456177
I0303 18:47:51.045058 139881808373504 logging_writer.py:48] [238000] global_step=238000, grad_norm=4.150340557098389, loss=1.5161434412002563
I0303 18:48:35.452929 139881799980800 logging_writer.py:48] [238100] global_step=238100, grad_norm=3.451615571975708, loss=1.1166952848434448
I0303 18:49:12.868497 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:49:24.447058 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:49:58.711391 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:50:00.309115 140077943854912 submission_runner.py:411] Time since start: 114193.11s, 	Step: 238186, 	{'train/accuracy': 0.8873632550239563, 'train/loss': 0.4150916635990143, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 104650.29148387909, 'total_duration': 114193.11408925056, 'accumulated_submission_time': 104650.29148387909, 'accumulated_eval_time': 9516.149178743362, 'accumulated_logging_time': 14.232004404067993}
I0303 18:50:00.373269 139881808373504 logging_writer.py:48] [238186] accumulated_eval_time=9516.149179, accumulated_logging_time=14.232004, accumulated_submission_time=104650.291484, global_step=238186, preemption_count=0, score=104650.291484, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=114193.114089, train/accuracy=0.887363, train/loss=0.415092, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:50:06.216112 139881799980800 logging_writer.py:48] [238200] global_step=238200, grad_norm=3.1513068675994873, loss=1.127600073814392
I0303 18:50:46.813332 139881808373504 logging_writer.py:48] [238300] global_step=238300, grad_norm=2.9541611671447754, loss=1.6485801935195923
I0303 18:51:30.823645 139881799980800 logging_writer.py:48] [238400] global_step=238400, grad_norm=3.0965964794158936, loss=1.7873951196670532
I0303 18:52:15.751217 139881808373504 logging_writer.py:48] [238500] global_step=238500, grad_norm=3.0999364852905273, loss=1.1017266511917114
I0303 18:52:59.754420 139881799980800 logging_writer.py:48] [238600] global_step=238600, grad_norm=3.6885008811950684, loss=3.108062505722046
I0303 18:53:44.065995 139881808373504 logging_writer.py:48] [238700] global_step=238700, grad_norm=3.016469717025757, loss=1.081275224685669
I0303 18:54:28.380606 139881799980800 logging_writer.py:48] [238800] global_step=238800, grad_norm=2.9894866943359375, loss=1.1541759967803955
I0303 18:55:12.830611 139881808373504 logging_writer.py:48] [238900] global_step=238900, grad_norm=2.9535374641418457, loss=1.0494738817214966
I0303 18:55:57.434856 139881799980800 logging_writer.py:48] [239000] global_step=239000, grad_norm=3.106757879257202, loss=1.0222382545471191
I0303 18:56:42.021166 139881808373504 logging_writer.py:48] [239100] global_step=239100, grad_norm=3.237504243850708, loss=1.3766241073608398
I0303 18:57:00.411535 140077943854912 spec.py:321] Evaluating on the training split.
I0303 18:57:11.073308 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 18:57:36.290079 140077943854912 spec.py:349] Evaluating on the test split.
I0303 18:57:37.880972 140077943854912 submission_runner.py:411] Time since start: 114650.69s, 	Step: 239143, 	{'train/accuracy': 0.8875585794448853, 'train/loss': 0.4165133833885193, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 105070.2694966793, 'total_duration': 114650.68592834473, 'accumulated_submission_time': 105070.2694966793, 'accumulated_eval_time': 9553.618543624878, 'accumulated_logging_time': 14.30665922164917}
I0303 18:57:37.947619 139881799980800 logging_writer.py:48] [239143] accumulated_eval_time=9553.618544, accumulated_logging_time=14.306659, accumulated_submission_time=105070.269497, global_step=239143, preemption_count=0, score=105070.269497, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=114650.685928, train/accuracy=0.887559, train/loss=0.416513, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 18:58:00.593950 139881808373504 logging_writer.py:48] [239200] global_step=239200, grad_norm=2.927370548248291, loss=2.0175843238830566
I0303 18:58:44.313397 139881799980800 logging_writer.py:48] [239300] global_step=239300, grad_norm=3.2643535137176514, loss=2.818765878677368
I0303 18:59:28.958831 139881808373504 logging_writer.py:48] [239400] global_step=239400, grad_norm=3.3414554595947266, loss=1.2622458934783936
I0303 19:00:13.547847 139881799980800 logging_writer.py:48] [239500] global_step=239500, grad_norm=3.3041818141937256, loss=1.0484704971313477
I0303 19:00:57.724714 139881808373504 logging_writer.py:48] [239600] global_step=239600, grad_norm=3.2108709812164307, loss=1.9956804513931274
I0303 19:01:42.190532 139881799980800 logging_writer.py:48] [239700] global_step=239700, grad_norm=3.2785074710845947, loss=1.1708104610443115
I0303 19:02:26.709739 139881808373504 logging_writer.py:48] [239800] global_step=239800, grad_norm=3.1769936084747314, loss=2.2573294639587402
I0303 19:03:11.290343 139881799980800 logging_writer.py:48] [239900] global_step=239900, grad_norm=4.130311965942383, loss=3.055392265319824
I0303 19:03:55.818499 139881808373504 logging_writer.py:48] [240000] global_step=240000, grad_norm=3.110992670059204, loss=2.11918306350708
I0303 19:04:37.996535 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:04:48.487138 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:05:13.345393 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:05:14.965534 140077943854912 submission_runner.py:411] Time since start: 115107.77s, 	Step: 240097, 	{'train/accuracy': 0.8878905773162842, 'train/loss': 0.41631102561950684, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 105490.25032567978, 'total_duration': 115107.77051401138, 'accumulated_submission_time': 105490.25032567978, 'accumulated_eval_time': 9590.587503671646, 'accumulated_logging_time': 14.38660478591919}
I0303 19:05:15.074788 139881799980800 logging_writer.py:48] [240097] accumulated_eval_time=9590.587504, accumulated_logging_time=14.386605, accumulated_submission_time=105490.250326, global_step=240097, preemption_count=0, score=105490.250326, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=115107.770514, train/accuracy=0.887891, train/loss=0.416311, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:05:16.677995 139881808373504 logging_writer.py:48] [240100] global_step=240100, grad_norm=3.459507942199707, loss=2.8867859840393066
I0303 19:05:56.789814 139881799980800 logging_writer.py:48] [240200] global_step=240200, grad_norm=3.4766805171966553, loss=1.2260053157806396
I0303 19:06:41.595548 139881808373504 logging_writer.py:48] [240300] global_step=240300, grad_norm=3.746629238128662, loss=3.150562047958374
I0303 19:07:26.235339 139881799980800 logging_writer.py:48] [240400] global_step=240400, grad_norm=3.2725989818573, loss=1.1727427244186401
I0303 19:08:10.833806 139881808373504 logging_writer.py:48] [240500] global_step=240500, grad_norm=3.10626482963562, loss=2.0398056507110596
I0303 19:08:55.068598 139881799980800 logging_writer.py:48] [240600] global_step=240600, grad_norm=2.9137532711029053, loss=1.292776346206665
I0303 19:09:39.671571 139881808373504 logging_writer.py:48] [240700] global_step=240700, grad_norm=4.046710014343262, loss=3.046914577484131
I0303 19:10:24.213592 139881799980800 logging_writer.py:48] [240800] global_step=240800, grad_norm=3.2253072261810303, loss=1.4054752588272095
I0303 19:11:08.592787 139881808373504 logging_writer.py:48] [240900] global_step=240900, grad_norm=3.414198637008667, loss=1.933948040008545
I0303 19:11:53.232308 139881799980800 logging_writer.py:48] [241000] global_step=241000, grad_norm=3.7268431186676025, loss=3.1274607181549072
I0303 19:12:15.181867 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:12:25.402580 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:12:52.095126 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:12:53.696284 140077943854912 submission_runner.py:411] Time since start: 115566.50s, 	Step: 241051, 	{'train/accuracy': 0.8893749713897705, 'train/loss': 0.416501522064209, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 105910.28881311417, 'total_duration': 115566.50127744675, 'accumulated_submission_time': 105910.28881311417, 'accumulated_eval_time': 9629.101864814758, 'accumulated_logging_time': 14.51517915725708}
I0303 19:12:53.758164 139881808373504 logging_writer.py:48] [241051] accumulated_eval_time=9629.101865, accumulated_logging_time=14.515179, accumulated_submission_time=105910.288813, global_step=241051, preemption_count=0, score=105910.288813, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=115566.501277, train/accuracy=0.889375, train/loss=0.416502, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:13:13.274229 139881799980800 logging_writer.py:48] [241100] global_step=241100, grad_norm=3.633457899093628, loss=1.4388397932052612
I0303 19:13:56.869545 139881808373504 logging_writer.py:48] [241200] global_step=241200, grad_norm=3.6032910346984863, loss=3.140805959701538
I0303 19:14:41.153237 139881799980800 logging_writer.py:48] [241300] global_step=241300, grad_norm=3.049861192703247, loss=1.198448896408081
I0303 19:15:25.575520 139881808373504 logging_writer.py:48] [241400] global_step=241400, grad_norm=3.2705488204956055, loss=2.1018128395080566
I0303 19:16:10.442712 139881799980800 logging_writer.py:48] [241500] global_step=241500, grad_norm=3.180152177810669, loss=1.140496015548706
I0303 19:16:54.926980 139881808373504 logging_writer.py:48] [241600] global_step=241600, grad_norm=3.7009167671203613, loss=3.277742624282837
I0303 19:17:39.686913 139881799980800 logging_writer.py:48] [241700] global_step=241700, grad_norm=3.276371479034424, loss=1.1333930492401123
I0303 19:18:24.092134 139881808373504 logging_writer.py:48] [241800] global_step=241800, grad_norm=3.0772721767425537, loss=1.1575031280517578
I0303 19:19:08.441943 139881799980800 logging_writer.py:48] [241900] global_step=241900, grad_norm=3.0151355266571045, loss=1.2273716926574707
I0303 19:19:53.103396 139881808373504 logging_writer.py:48] [242000] global_step=242000, grad_norm=3.0388875007629395, loss=1.0670243501663208
I0303 19:19:53.725797 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:20:04.061359 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:20:31.993238 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:20:33.587160 140077943854912 submission_runner.py:411] Time since start: 116026.39s, 	Step: 242003, 	{'train/accuracy': 0.8878124952316284, 'train/loss': 0.4150179922580719, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 106330.19357085228, 'total_duration': 116026.39215540886, 'accumulated_submission_time': 106330.19357085228, 'accumulated_eval_time': 9668.963171720505, 'accumulated_logging_time': 14.59090256690979}
I0303 19:20:33.651409 139881799980800 logging_writer.py:48] [242003] accumulated_eval_time=9668.963172, accumulated_logging_time=14.590903, accumulated_submission_time=106330.193571, global_step=242003, preemption_count=0, score=106330.193571, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=116026.392155, train/accuracy=0.887812, train/loss=0.415018, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:21:13.458255 139881808373504 logging_writer.py:48] [242100] global_step=242100, grad_norm=3.2455856800079346, loss=1.1691763401031494
I0303 19:21:57.783584 139881799980800 logging_writer.py:48] [242200] global_step=242200, grad_norm=3.6210474967956543, loss=3.025085926055908
I0303 19:22:42.483498 139881808373504 logging_writer.py:48] [242300] global_step=242300, grad_norm=2.9914281368255615, loss=1.2036837339401245
I0303 19:23:27.012208 139881799980800 logging_writer.py:48] [242400] global_step=242400, grad_norm=3.1655771732330322, loss=1.3275463581085205
I0303 19:24:11.515957 139881808373504 logging_writer.py:48] [242500] global_step=242500, grad_norm=3.061469316482544, loss=1.9191348552703857
I0303 19:24:55.926270 139881799980800 logging_writer.py:48] [242600] global_step=242600, grad_norm=3.2058305740356445, loss=2.862316131591797
I0303 19:25:40.342008 139881808373504 logging_writer.py:48] [242700] global_step=242700, grad_norm=3.3410110473632812, loss=1.1123074293136597
I0303 19:26:24.996216 139881799980800 logging_writer.py:48] [242800] global_step=242800, grad_norm=3.066105365753174, loss=0.9949696660041809
I0303 19:27:09.380039 139881808373504 logging_writer.py:48] [242900] global_step=242900, grad_norm=4.519300937652588, loss=3.360623359680176
I0303 19:27:33.854420 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:27:44.050718 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:28:08.835700 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:28:10.421728 140077943854912 submission_runner.py:411] Time since start: 116483.23s, 	Step: 242957, 	{'train/accuracy': 0.8879687190055847, 'train/loss': 0.41571155190467834, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 106750.33529853821, 'total_duration': 116483.22671723366, 'accumulated_submission_time': 106750.33529853821, 'accumulated_eval_time': 9705.530426979065, 'accumulated_logging_time': 14.666574001312256}
I0303 19:28:10.485959 139881799980800 logging_writer.py:48] [242957] accumulated_eval_time=9705.530427, accumulated_logging_time=14.666574, accumulated_submission_time=106750.335299, global_step=242957, preemption_count=0, score=106750.335299, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=116483.226717, train/accuracy=0.887969, train/loss=0.415712, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:28:27.650558 139881808373504 logging_writer.py:48] [243000] global_step=243000, grad_norm=3.526291608810425, loss=2.6047229766845703
I0303 19:29:10.659652 139881799980800 logging_writer.py:48] [243100] global_step=243100, grad_norm=3.9365720748901367, loss=1.191421389579773
I0303 19:29:55.063485 139881808373504 logging_writer.py:48] [243200] global_step=243200, grad_norm=3.2668039798736572, loss=2.6448941230773926
I0303 19:30:39.631356 139881799980800 logging_writer.py:48] [243300] global_step=243300, grad_norm=3.156604528427124, loss=1.1356902122497559
I0303 19:31:24.155307 139881808373504 logging_writer.py:48] [243400] global_step=243400, grad_norm=3.4869346618652344, loss=2.1136720180511475
I0303 19:32:08.833791 139881799980800 logging_writer.py:48] [243500] global_step=243500, grad_norm=3.3325765132904053, loss=1.1852288246154785
I0303 19:32:53.171825 139881808373504 logging_writer.py:48] [243600] global_step=243600, grad_norm=3.0022575855255127, loss=1.0513659715652466
I0303 19:33:37.498339 139881799980800 logging_writer.py:48] [243700] global_step=243700, grad_norm=3.332879066467285, loss=2.9419162273406982
I0303 19:34:22.059397 139881808373504 logging_writer.py:48] [243800] global_step=243800, grad_norm=2.904716730117798, loss=1.1291916370391846
I0303 19:35:06.598345 139881799980800 logging_writer.py:48] [243900] global_step=243900, grad_norm=3.1771914958953857, loss=2.6281208992004395
I0303 19:35:10.744929 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:35:20.686680 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:35:56.044881 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:35:57.624086 140077943854912 submission_runner.py:411] Time since start: 116950.43s, 	Step: 243911, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.4220549166202545, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 107170.53363466263, 'total_duration': 116950.42909789085, 'accumulated_submission_time': 107170.53363466263, 'accumulated_eval_time': 9752.409542560577, 'accumulated_logging_time': 14.741652011871338}
I0303 19:35:57.678970 139881808373504 logging_writer.py:48] [243911] accumulated_eval_time=9752.409543, accumulated_logging_time=14.741652, accumulated_submission_time=107170.533635, global_step=243911, preemption_count=0, score=107170.533635, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=116950.429098, train/accuracy=0.887598, train/loss=0.422055, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:36:32.803889 139881799980800 logging_writer.py:48] [244000] global_step=244000, grad_norm=3.375788927078247, loss=1.1284902095794678
I0303 19:37:16.840567 139881808373504 logging_writer.py:48] [244100] global_step=244100, grad_norm=2.782336950302124, loss=1.572168231010437
I0303 19:38:01.725988 139881799980800 logging_writer.py:48] [244200] global_step=244200, grad_norm=3.039109945297241, loss=1.1059885025024414
I0303 19:38:46.154121 139881808373504 logging_writer.py:48] [244300] global_step=244300, grad_norm=2.9682796001434326, loss=1.1381354331970215
I0303 19:39:30.435765 139881799980800 logging_writer.py:48] [244400] global_step=244400, grad_norm=3.6036503314971924, loss=3.348658800125122
I0303 19:40:14.778624 139881808373504 logging_writer.py:48] [244500] global_step=244500, grad_norm=2.840658187866211, loss=1.2827539443969727
I0303 19:40:59.047093 139881799980800 logging_writer.py:48] [244600] global_step=244600, grad_norm=3.896348714828491, loss=1.1340388059616089
I0303 19:41:44.406280 139881808373504 logging_writer.py:48] [244700] global_step=244700, grad_norm=2.8996918201446533, loss=2.0556154251098633
I0303 19:42:28.895182 139881799980800 logging_writer.py:48] [244800] global_step=244800, grad_norm=2.9650754928588867, loss=1.5440759658813477
I0303 19:42:57.746036 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:43:08.089401 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:43:39.691515 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:43:41.275031 140077943854912 submission_runner.py:411] Time since start: 117414.08s, 	Step: 244867, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.41346442699432373, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 107590.54052233696, 'total_duration': 117414.08001947403, 'accumulated_submission_time': 107590.54052233696, 'accumulated_eval_time': 9795.938479661942, 'accumulated_logging_time': 14.807200908660889}
I0303 19:43:41.337293 139881808373504 logging_writer.py:48] [244867] accumulated_eval_time=9795.938480, accumulated_logging_time=14.807201, accumulated_submission_time=107590.540522, global_step=244867, preemption_count=0, score=107590.540522, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=117414.080019, train/accuracy=0.888730, train/loss=0.413464, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:43:54.588622 139881799980800 logging_writer.py:48] [244900] global_step=244900, grad_norm=3.1621992588043213, loss=1.385394811630249
I0303 19:44:35.665957 139881808373504 logging_writer.py:48] [245000] global_step=245000, grad_norm=3.079517364501953, loss=1.240899682044983
I0303 19:45:19.904275 139881799980800 logging_writer.py:48] [245100] global_step=245100, grad_norm=3.2427256107330322, loss=1.1645331382751465
I0303 19:46:04.504851 139881808373504 logging_writer.py:48] [245200] global_step=245200, grad_norm=3.2218387126922607, loss=2.7893693447113037
I0303 19:46:49.181372 139881799980800 logging_writer.py:48] [245300] global_step=245300, grad_norm=3.0326449871063232, loss=1.0688127279281616
I0303 19:47:33.379788 139881808373504 logging_writer.py:48] [245400] global_step=245400, grad_norm=3.233259439468384, loss=1.1463947296142578
I0303 19:48:18.011376 139881799980800 logging_writer.py:48] [245500] global_step=245500, grad_norm=3.1415648460388184, loss=1.2260289192199707
I0303 19:49:02.146624 139881808373504 logging_writer.py:48] [245600] global_step=245600, grad_norm=3.2437922954559326, loss=1.1642252206802368
I0303 19:49:46.549003 139881799980800 logging_writer.py:48] [245700] global_step=245700, grad_norm=3.4122729301452637, loss=1.9682120084762573
I0303 19:50:31.050377 139881808373504 logging_writer.py:48] [245800] global_step=245800, grad_norm=3.2043159008026123, loss=2.0182583332061768
I0303 19:50:41.608545 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:50:52.171201 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:51:19.348047 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:51:20.929600 140077943854912 submission_runner.py:411] Time since start: 117873.73s, 	Step: 245826, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.41320082545280457, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 108010.750831604, 'total_duration': 117873.73462128639, 'accumulated_submission_time': 108010.750831604, 'accumulated_eval_time': 9835.25951552391, 'accumulated_logging_time': 14.880392789840698}
I0303 19:51:20.984965 139881799980800 logging_writer.py:48] [245826] accumulated_eval_time=9835.259516, accumulated_logging_time=14.880393, accumulated_submission_time=108010.750832, global_step=245826, preemption_count=0, score=108010.750832, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=117873.734621, train/accuracy=0.888730, train/loss=0.413201, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:51:50.276266 139881808373504 logging_writer.py:48] [245900] global_step=245900, grad_norm=3.5386440753936768, loss=2.6882808208465576
I0303 19:52:34.367009 139881799980800 logging_writer.py:48] [246000] global_step=246000, grad_norm=3.99992036819458, loss=3.251939535140991
I0303 19:53:18.908827 139881808373504 logging_writer.py:48] [246100] global_step=246100, grad_norm=3.0037875175476074, loss=1.099905014038086
I0303 19:54:03.673290 139881799980800 logging_writer.py:48] [246200] global_step=246200, grad_norm=3.2440574169158936, loss=1.3136242628097534
I0303 19:54:47.880398 139881808373504 logging_writer.py:48] [246300] global_step=246300, grad_norm=3.072626829147339, loss=1.1333979368209839
I0303 19:55:32.509527 139881799980800 logging_writer.py:48] [246400] global_step=246400, grad_norm=3.0871024131774902, loss=1.3297990560531616
I0303 19:56:17.245516 139881808373504 logging_writer.py:48] [246500] global_step=246500, grad_norm=3.2703049182891846, loss=2.078105926513672
I0303 19:57:01.900102 139881799980800 logging_writer.py:48] [246600] global_step=246600, grad_norm=3.5951220989227295, loss=3.015017032623291
I0303 19:57:46.578761 139881808373504 logging_writer.py:48] [246700] global_step=246700, grad_norm=3.460926055908203, loss=1.1947978734970093
I0303 19:58:21.155999 140077943854912 spec.py:321] Evaluating on the training split.
I0303 19:58:31.449798 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 19:59:05.833022 140077943854912 spec.py:349] Evaluating on the test split.
I0303 19:59:07.412918 140077943854912 submission_runner.py:411] Time since start: 118340.22s, 	Step: 246779, 	{'train/accuracy': 0.88685542345047, 'train/loss': 0.4224175214767456, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 108430.8633108139, 'total_duration': 118340.21789956093, 'accumulated_submission_time': 108430.8633108139, 'accumulated_eval_time': 9881.516390562057, 'accumulated_logging_time': 14.945569515228271}
I0303 19:59:07.476236 139881799980800 logging_writer.py:48] [246779] accumulated_eval_time=9881.516391, accumulated_logging_time=14.945570, accumulated_submission_time=108430.863311, global_step=246779, preemption_count=0, score=108430.863311, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=118340.217900, train/accuracy=0.886855, train/loss=0.422418, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 19:59:16.046554 139881808373504 logging_writer.py:48] [246800] global_step=246800, grad_norm=3.2057297229766846, loss=1.1111228466033936
I0303 19:59:57.149246 139881799980800 logging_writer.py:48] [246900] global_step=246900, grad_norm=3.4131219387054443, loss=1.9345688819885254
I0303 20:00:41.680912 139881808373504 logging_writer.py:48] [247000] global_step=247000, grad_norm=3.0867793560028076, loss=1.1601145267486572
I0303 20:01:26.155834 139881799980800 logging_writer.py:48] [247100] global_step=247100, grad_norm=3.0071682929992676, loss=1.1198451519012451
I0303 20:02:10.579030 139881808373504 logging_writer.py:48] [247200] global_step=247200, grad_norm=3.389791250228882, loss=1.4421260356903076
I0303 20:02:55.154235 139881799980800 logging_writer.py:48] [247300] global_step=247300, grad_norm=3.3525726795196533, loss=1.7349965572357178
I0303 20:03:39.549018 139881808373504 logging_writer.py:48] [247400] global_step=247400, grad_norm=3.48337459564209, loss=2.883646011352539
I0303 20:04:23.920927 139881799980800 logging_writer.py:48] [247500] global_step=247500, grad_norm=3.6566860675811768, loss=3.1857481002807617
I0303 20:05:08.435894 139881808373504 logging_writer.py:48] [247600] global_step=247600, grad_norm=3.254795551300049, loss=2.7233753204345703
I0303 20:05:52.770999 139881799980800 logging_writer.py:48] [247700] global_step=247700, grad_norm=3.0958478450775146, loss=1.0934005975723267
I0303 20:06:07.546046 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:06:17.897842 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 20:06:46.985881 140077943854912 spec.py:349] Evaluating on the test split.
I0303 20:06:48.575930 140077943854912 submission_runner.py:411] Time since start: 118801.38s, 	Step: 247734, 	{'train/accuracy': 0.8893359303474426, 'train/loss': 0.4157688319683075, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 108850.87331867218, 'total_duration': 118801.3809273243, 'accumulated_submission_time': 108850.87331867218, 'accumulated_eval_time': 9922.546244859695, 'accumulated_logging_time': 15.019672870635986}
I0303 20:06:48.640238 139881808373504 logging_writer.py:48] [247734] accumulated_eval_time=9922.546245, accumulated_logging_time=15.019673, accumulated_submission_time=108850.873319, global_step=247734, preemption_count=0, score=108850.873319, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=118801.380927, train/accuracy=0.889336, train/loss=0.415769, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 20:07:14.812678 139881799980800 logging_writer.py:48] [247800] global_step=247800, grad_norm=4.038684844970703, loss=3.241488456726074
I0303 20:07:58.548788 139881808373504 logging_writer.py:48] [247900] global_step=247900, grad_norm=3.7360146045684814, loss=3.216170310974121
I0303 20:08:42.929368 139881799980800 logging_writer.py:48] [248000] global_step=248000, grad_norm=3.6419339179992676, loss=3.1184022426605225
I0303 20:09:27.649601 139881808373504 logging_writer.py:48] [248100] global_step=248100, grad_norm=3.1754610538482666, loss=1.2445588111877441
I0303 20:10:12.138226 139881799980800 logging_writer.py:48] [248200] global_step=248200, grad_norm=3.1412534713745117, loss=1.4760173559188843
I0303 20:10:56.394651 139881808373504 logging_writer.py:48] [248300] global_step=248300, grad_norm=3.201045274734497, loss=1.1559779644012451
I0303 20:11:40.944394 139881799980800 logging_writer.py:48] [248400] global_step=248400, grad_norm=3.108981132507324, loss=2.2804157733917236
I0303 20:12:25.333934 139881808373504 logging_writer.py:48] [248500] global_step=248500, grad_norm=2.9769973754882812, loss=1.7605159282684326
I0303 20:13:09.933006 139881799980800 logging_writer.py:48] [248600] global_step=248600, grad_norm=3.016986846923828, loss=1.3214136362075806
I0303 20:13:48.924559 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:13:59.341492 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 20:14:26.378837 140077943854912 spec.py:349] Evaluating on the test split.
I0303 20:14:27.967115 140077943854912 submission_runner.py:411] Time since start: 119260.77s, 	Step: 248690, 	{'train/accuracy': 0.8864257335662842, 'train/loss': 0.4195002615451813, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 109271.09632349014, 'total_duration': 119260.77212262154, 'accumulated_submission_time': 109271.09632349014, 'accumulated_eval_time': 9961.588781833649, 'accumulated_logging_time': 15.095571517944336}
I0303 20:14:28.035588 139881808373504 logging_writer.py:48] [248690] accumulated_eval_time=9961.588782, accumulated_logging_time=15.095572, accumulated_submission_time=109271.096323, global_step=248690, preemption_count=0, score=109271.096323, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=119260.772123, train/accuracy=0.886426, train/loss=0.419500, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 20:14:32.344733 139881799980800 logging_writer.py:48] [248700] global_step=248700, grad_norm=3.368168354034424, loss=1.5189117193222046
I0303 20:15:13.850340 139881808373504 logging_writer.py:48] [248800] global_step=248800, grad_norm=3.009986639022827, loss=2.259608507156372
I0303 20:15:58.278892 139881799980800 logging_writer.py:48] [248900] global_step=248900, grad_norm=3.044903516769409, loss=1.459151268005371
I0303 20:16:43.236331 139881808373504 logging_writer.py:48] [249000] global_step=249000, grad_norm=3.2980613708496094, loss=1.0945289134979248
I0303 20:17:27.647682 139881799980800 logging_writer.py:48] [249100] global_step=249100, grad_norm=3.2551612854003906, loss=1.1362361907958984
I0303 20:18:12.023328 139881808373504 logging_writer.py:48] [249200] global_step=249200, grad_norm=3.091621160507202, loss=1.664009928703308
I0303 20:18:56.503495 139881799980800 logging_writer.py:48] [249300] global_step=249300, grad_norm=3.609346628189087, loss=3.00028133392334
I0303 20:19:41.146078 139881808373504 logging_writer.py:48] [249400] global_step=249400, grad_norm=3.312612295150757, loss=2.4524664878845215
I0303 20:20:25.495283 139881799980800 logging_writer.py:48] [249500] global_step=249500, grad_norm=3.01340389251709, loss=2.027686595916748
I0303 20:21:09.910995 139881808373504 logging_writer.py:48] [249600] global_step=249600, grad_norm=3.1263327598571777, loss=1.1128766536712646
I0303 20:21:28.398741 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:21:38.682365 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 20:22:04.161029 140077943854912 spec.py:349] Evaluating on the test split.
I0303 20:22:05.745114 140077943854912 submission_runner.py:411] Time since start: 119718.55s, 	Step: 249643, 	{'train/accuracy': 0.8881640434265137, 'train/loss': 0.41439196467399597, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 109691.39629292488, 'total_duration': 119718.55010271072, 'accumulated_submission_time': 109691.39629292488, 'accumulated_eval_time': 9998.935094356537, 'accumulated_logging_time': 15.17807126045227}
I0303 20:22:05.810496 139881799980800 logging_writer.py:48] [249643] accumulated_eval_time=9998.935094, accumulated_logging_time=15.178071, accumulated_submission_time=109691.396293, global_step=249643, preemption_count=0, score=109691.396293, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=119718.550103, train/accuracy=0.888164, train/loss=0.414392, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 20:22:28.483674 139881808373504 logging_writer.py:48] [249700] global_step=249700, grad_norm=3.2597270011901855, loss=1.0716876983642578
I0303 20:23:11.927002 139881799980800 logging_writer.py:48] [249800] global_step=249800, grad_norm=2.9510703086853027, loss=1.0627790689468384
I0303 20:23:56.215347 139881808373504 logging_writer.py:48] [249900] global_step=249900, grad_norm=3.1476423740386963, loss=1.1603506803512573
I0303 20:24:40.906767 139881799980800 logging_writer.py:48] [250000] global_step=250000, grad_norm=2.90645694732666, loss=2.2251410484313965
I0303 20:25:25.369655 139881808373504 logging_writer.py:48] [250100] global_step=250100, grad_norm=4.000373363494873, loss=3.1410248279571533
I0303 20:26:09.691907 139881799980800 logging_writer.py:48] [250200] global_step=250200, grad_norm=3.066951036453247, loss=1.1223409175872803
I0303 20:26:54.508923 139881808373504 logging_writer.py:48] [250300] global_step=250300, grad_norm=3.081198215484619, loss=1.2044000625610352
I0303 20:27:38.939981 139881799980800 logging_writer.py:48] [250400] global_step=250400, grad_norm=3.1358556747436523, loss=1.1587812900543213
I0303 20:28:23.147244 139881808373504 logging_writer.py:48] [250500] global_step=250500, grad_norm=3.3266403675079346, loss=2.2849440574645996
I0303 20:29:05.957018 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:29:15.967493 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 20:29:42.489648 140077943854912 spec.py:349] Evaluating on the test split.
I0303 20:29:44.076269 140077943854912 submission_runner.py:411] Time since start: 120176.88s, 	Step: 250598, 	{'train/accuracy': 0.8877539038658142, 'train/loss': 0.41761747002601624, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 110111.48210144043, 'total_duration': 120176.88127589226, 'accumulated_submission_time': 110111.48210144043, 'accumulated_eval_time': 10037.054334640503, 'accumulated_logging_time': 15.254687309265137}
I0303 20:29:44.146191 139881799980800 logging_writer.py:48] [250598] accumulated_eval_time=10037.054335, accumulated_logging_time=15.254687, accumulated_submission_time=110111.482101, global_step=250598, preemption_count=0, score=110111.482101, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=120176.881276, train/accuracy=0.887754, train/loss=0.417617, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 20:29:45.327529 139881808373504 logging_writer.py:48] [250600] global_step=250600, grad_norm=3.4414150714874268, loss=2.2010579109191895
I0303 20:30:25.938173 139881799980800 logging_writer.py:48] [250700] global_step=250700, grad_norm=3.4081549644470215, loss=1.1611254215240479
I0303 20:31:10.390292 139881808373504 logging_writer.py:48] [250800] global_step=250800, grad_norm=3.069185733795166, loss=1.228576421737671
I0303 20:31:54.882862 139881799980800 logging_writer.py:48] [250900] global_step=250900, grad_norm=3.2626209259033203, loss=1.5511608123779297
I0303 20:32:39.293502 139881808373504 logging_writer.py:48] [251000] global_step=251000, grad_norm=3.06718111038208, loss=1.0703480243682861
I0303 20:33:23.819175 139881799980800 logging_writer.py:48] [251100] global_step=251100, grad_norm=3.095712423324585, loss=1.1872434616088867
I0303 20:34:08.305010 139881808373504 logging_writer.py:48] [251200] global_step=251200, grad_norm=2.9885990619659424, loss=1.3130773305892944
I0303 20:34:52.505771 139881799980800 logging_writer.py:48] [251300] global_step=251300, grad_norm=3.0951590538024902, loss=2.2503623962402344
I0303 20:35:37.172623 139881808373504 logging_writer.py:48] [251400] global_step=251400, grad_norm=3.0245680809020996, loss=1.0845487117767334
I0303 20:36:21.913786 139881799980800 logging_writer.py:48] [251500] global_step=251500, grad_norm=3.1520657539367676, loss=2.3941550254821777
I0303 20:36:44.205524 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:36:54.223500 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 20:37:23.175991 140077943854912 spec.py:349] Evaluating on the test split.
I0303 20:37:24.772775 140077943854912 submission_runner.py:411] Time since start: 120637.58s, 	Step: 251552, 	{'train/accuracy': 0.8870507478713989, 'train/loss': 0.42200735211372375, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 110531.47845578194, 'total_duration': 120637.57777690887, 'accumulated_submission_time': 110531.47845578194, 'accumulated_eval_time': 10077.62155175209, 'accumulated_logging_time': 15.338451147079468}
I0303 20:37:24.832866 139881808373504 logging_writer.py:48] [251552] accumulated_eval_time=10077.621552, accumulated_logging_time=15.338451, accumulated_submission_time=110531.478456, global_step=251552, preemption_count=0, score=110531.478456, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=120637.577777, train/accuracy=0.887051, train/loss=0.422007, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 20:37:43.940418 139881799980800 logging_writer.py:48] [251600] global_step=251600, grad_norm=2.9170665740966797, loss=1.147533655166626
I0303 20:38:25.776391 139881808373504 logging_writer.py:48] [251700] global_step=251700, grad_norm=3.875730514526367, loss=3.2986090183258057
I0303 20:39:10.495722 139881799980800 logging_writer.py:48] [251800] global_step=251800, grad_norm=3.0006721019744873, loss=1.6586140394210815
I0303 20:39:55.023665 139881808373504 logging_writer.py:48] [251900] global_step=251900, grad_norm=3.597158670425415, loss=3.256772041320801
I0303 20:40:39.322489 139881799980800 logging_writer.py:48] [252000] global_step=252000, grad_norm=3.041372537612915, loss=1.463136076927185
I0303 20:41:23.713801 139881808373504 logging_writer.py:48] [252100] global_step=252100, grad_norm=2.9941515922546387, loss=1.3254079818725586
I0303 20:42:08.020926 139881799980800 logging_writer.py:48] [252200] global_step=252200, grad_norm=3.132953643798828, loss=1.1725168228149414
I0303 20:42:52.252277 139881808373504 logging_writer.py:48] [252300] global_step=252300, grad_norm=3.000760078430176, loss=1.5655746459960938
I0303 20:43:36.496479 139881799980800 logging_writer.py:48] [252400] global_step=252400, grad_norm=3.215031385421753, loss=1.131374716758728
I0303 20:44:20.971524 139881808373504 logging_writer.py:48] [252500] global_step=252500, grad_norm=3.253788709640503, loss=1.1331267356872559
I0303 20:44:25.097064 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:44:35.388084 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 20:45:05.464252 140077943854912 spec.py:349] Evaluating on the test split.
I0303 20:45:07.053508 140077943854912 submission_runner.py:411] Time since start: 121099.86s, 	Step: 252511, 	{'train/accuracy': 0.8853319883346558, 'train/loss': 0.42397886514663696, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 110951.68130636215, 'total_duration': 121099.85851335526, 'accumulated_submission_time': 110951.68130636215, 'accumulated_eval_time': 10119.577965021133, 'accumulated_logging_time': 15.408671617507935}
I0303 20:45:07.122305 139881799980800 logging_writer.py:48] [252511] accumulated_eval_time=10119.577965, accumulated_logging_time=15.408672, accumulated_submission_time=110951.681306, global_step=252511, preemption_count=0, score=110951.681306, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=121099.858513, train/accuracy=0.885332, train/loss=0.423979, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 20:45:42.446508 139881808373504 logging_writer.py:48] [252600] global_step=252600, grad_norm=3.018054962158203, loss=1.7375849485397339
I0303 20:46:26.563011 139881799980800 logging_writer.py:48] [252700] global_step=252700, grad_norm=3.285480499267578, loss=1.1121985912322998
I0303 20:47:11.146749 139881808373504 logging_writer.py:48] [252800] global_step=252800, grad_norm=3.3575074672698975, loss=1.167807936668396
I0303 20:47:55.757667 139881799980800 logging_writer.py:48] [252900] global_step=252900, grad_norm=3.073928117752075, loss=1.0942777395248413
I0303 20:48:39.935588 139881808373504 logging_writer.py:48] [253000] global_step=253000, grad_norm=3.1951887607574463, loss=1.1170746088027954
I0303 20:49:24.187974 139881799980800 logging_writer.py:48] [253100] global_step=253100, grad_norm=3.4157638549804688, loss=1.1524934768676758
I0303 20:50:08.591414 139881808373504 logging_writer.py:48] [253200] global_step=253200, grad_norm=3.3355934619903564, loss=2.7600741386413574
I0303 20:50:52.819091 139881799980800 logging_writer.py:48] [253300] global_step=253300, grad_norm=3.2651422023773193, loss=1.3280856609344482
I0303 20:51:37.315292 139881808373504 logging_writer.py:48] [253400] global_step=253400, grad_norm=3.0156495571136475, loss=1.4187917709350586
I0303 20:52:07.092446 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:52:17.255344 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 20:52:47.525081 140077943854912 spec.py:349] Evaluating on the test split.
I0303 20:52:49.103181 140077943854912 submission_runner.py:411] Time since start: 121561.91s, 	Step: 253469, 	{'train/accuracy': 0.88671875, 'train/loss': 0.42145392298698425, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 111371.58928275108, 'total_duration': 121561.9081993103, 'accumulated_submission_time': 111371.58928275108, 'accumulated_eval_time': 10161.588672876358, 'accumulated_logging_time': 15.490390062332153}
I0303 20:52:49.159991 139881799980800 logging_writer.py:48] [253469] accumulated_eval_time=10161.588673, accumulated_logging_time=15.490390, accumulated_submission_time=111371.589283, global_step=253469, preemption_count=0, score=111371.589283, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=121561.908199, train/accuracy=0.886719, train/loss=0.421454, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 20:53:01.642703 139881808373504 logging_writer.py:48] [253500] global_step=253500, grad_norm=3.1838693618774414, loss=1.220475196838379
I0303 20:53:43.114421 139881799980800 logging_writer.py:48] [253600] global_step=253600, grad_norm=3.0738940238952637, loss=2.5581750869750977
I0303 20:54:27.580845 139881808373504 logging_writer.py:48] [253700] global_step=253700, grad_norm=3.2291884422302246, loss=1.6029196977615356
I0303 20:55:12.527884 139881799980800 logging_writer.py:48] [253800] global_step=253800, grad_norm=3.0580382347106934, loss=2.3223276138305664
I0303 20:55:56.827512 139881808373504 logging_writer.py:48] [253900] global_step=253900, grad_norm=2.9831480979919434, loss=1.127548336982727
I0303 20:56:41.530353 139881799980800 logging_writer.py:48] [254000] global_step=254000, grad_norm=3.0166053771972656, loss=1.5056065320968628
I0303 20:57:26.055701 139881808373504 logging_writer.py:48] [254100] global_step=254100, grad_norm=3.809175968170166, loss=3.26871395111084
I0303 20:58:10.490436 139881799980800 logging_writer.py:48] [254200] global_step=254200, grad_norm=3.25958514213562, loss=1.6507632732391357
I0303 20:58:55.404670 139881808373504 logging_writer.py:48] [254300] global_step=254300, grad_norm=3.803701877593994, loss=3.0126826763153076
I0303 20:59:39.688718 139881799980800 logging_writer.py:48] [254400] global_step=254400, grad_norm=3.4515204429626465, loss=3.087308406829834
I0303 20:59:49.163483 140077943854912 spec.py:321] Evaluating on the training split.
I0303 20:59:59.432210 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:00:25.106091 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:00:26.702792 140077943854912 submission_runner.py:411] Time since start: 122019.51s, 	Step: 254423, 	{'train/accuracy': 0.8893554210662842, 'train/loss': 0.4129403531551361, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 111791.53270983696, 'total_duration': 122019.50779938698, 'accumulated_submission_time': 111791.53270983696, 'accumulated_eval_time': 10199.127958536148, 'accumulated_logging_time': 15.558288812637329}
I0303 21:00:26.771444 139881808373504 logging_writer.py:48] [254423] accumulated_eval_time=10199.127959, accumulated_logging_time=15.558289, accumulated_submission_time=111791.532710, global_step=254423, preemption_count=0, score=111791.532710, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=122019.507799, train/accuracy=0.889355, train/loss=0.412940, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:00:57.429965 139881799980800 logging_writer.py:48] [254500] global_step=254500, grad_norm=3.239258050918579, loss=1.9291218519210815
I0303 21:01:41.672614 139881808373504 logging_writer.py:48] [254600] global_step=254600, grad_norm=3.8024587631225586, loss=3.3853859901428223
I0303 21:02:26.261970 139881799980800 logging_writer.py:48] [254700] global_step=254700, grad_norm=3.388263463973999, loss=2.977753162384033
I0303 21:03:10.789602 139881808373504 logging_writer.py:48] [254800] global_step=254800, grad_norm=3.5296084880828857, loss=1.1309703588485718
I0303 21:03:54.785195 139881799980800 logging_writer.py:48] [254900] global_step=254900, grad_norm=3.083587169647217, loss=1.254350185394287
I0303 21:04:39.351151 139881808373504 logging_writer.py:48] [255000] global_step=255000, grad_norm=3.1225028038024902, loss=2.0259459018707275
I0303 21:05:23.761266 139881799980800 logging_writer.py:48] [255100] global_step=255100, grad_norm=2.898693323135376, loss=1.9595248699188232
I0303 21:06:08.157799 139881808373504 logging_writer.py:48] [255200] global_step=255200, grad_norm=3.3880109786987305, loss=1.150375247001648
I0303 21:06:52.874068 139881799980800 logging_writer.py:48] [255300] global_step=255300, grad_norm=3.8000338077545166, loss=2.0195345878601074
I0303 21:07:26.936574 140077943854912 spec.py:321] Evaluating on the training split.
I0303 21:07:37.397255 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:08:14.624061 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:08:16.216241 140077943854912 submission_runner.py:411] Time since start: 122489.02s, 	Step: 255378, 	{'train/accuracy': 0.8873632550239563, 'train/loss': 0.41600844264030457, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 112211.63786792755, 'total_duration': 122489.02125787735, 'accumulated_submission_time': 112211.63786792755, 'accumulated_eval_time': 10248.407604455948, 'accumulated_logging_time': 15.638772964477539}
I0303 21:08:16.270229 139881808373504 logging_writer.py:48] [255378] accumulated_eval_time=10248.407604, accumulated_logging_time=15.638773, accumulated_submission_time=112211.637868, global_step=255378, preemption_count=0, score=112211.637868, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=122489.021258, train/accuracy=0.887363, train/loss=0.416008, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:08:25.234293 139881799980800 logging_writer.py:48] [255400] global_step=255400, grad_norm=4.426786422729492, loss=3.384850025177002
I0303 21:09:06.445918 139881808373504 logging_writer.py:48] [255500] global_step=255500, grad_norm=2.8308663368225098, loss=2.1906089782714844
I0303 21:09:50.743841 139881799980800 logging_writer.py:48] [255600] global_step=255600, grad_norm=3.231442928314209, loss=1.8172032833099365
I0303 21:10:35.267076 139881808373504 logging_writer.py:48] [255700] global_step=255700, grad_norm=3.0057570934295654, loss=1.195691704750061
I0303 21:11:19.547562 139881799980800 logging_writer.py:48] [255800] global_step=255800, grad_norm=4.136733055114746, loss=3.1193416118621826
I0303 21:12:03.943067 139881808373504 logging_writer.py:48] [255900] global_step=255900, grad_norm=2.8214778900146484, loss=1.3983830213546753
I0303 21:12:48.217680 139881799980800 logging_writer.py:48] [256000] global_step=256000, grad_norm=3.068192958831787, loss=1.0393720865249634
I0303 21:13:32.391653 139881808373504 logging_writer.py:48] [256100] global_step=256100, grad_norm=3.312140464782715, loss=2.766634941101074
I0303 21:14:16.830194 139881799980800 logging_writer.py:48] [256200] global_step=256200, grad_norm=3.1742684841156006, loss=1.0915262699127197
I0303 21:15:00.947492 139881808373504 logging_writer.py:48] [256300] global_step=256300, grad_norm=3.0150766372680664, loss=1.2625415325164795
I0303 21:15:16.401781 140077943854912 spec.py:321] Evaluating on the training split.
I0303 21:15:26.802616 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:15:48.678484 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:15:50.266485 140077943854912 submission_runner.py:411] Time since start: 122943.07s, 	Step: 256336, 	{'train/accuracy': 0.8903515338897705, 'train/loss': 0.4116775095462799, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 112631.70882320404, 'total_duration': 122943.07149362564, 'accumulated_submission_time': 112631.70882320404, 'accumulated_eval_time': 10282.272267341614, 'accumulated_logging_time': 15.704032182693481}
I0303 21:15:50.334347 139881799980800 logging_writer.py:48] [256336] accumulated_eval_time=10282.272267, accumulated_logging_time=15.704032, accumulated_submission_time=112631.708823, global_step=256336, preemption_count=0, score=112631.708823, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=122943.071494, train/accuracy=0.890352, train/loss=0.411678, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:16:15.723059 139881808373504 logging_writer.py:48] [256400] global_step=256400, grad_norm=4.054638385772705, loss=3.009060859680176
I0303 21:17:00.294337 139881799980800 logging_writer.py:48] [256500] global_step=256500, grad_norm=3.2675516605377197, loss=1.104264736175537
I0303 21:17:44.424344 139881808373504 logging_writer.py:48] [256600] global_step=256600, grad_norm=3.130526542663574, loss=1.3914984464645386
I0303 21:18:28.663654 139881799980800 logging_writer.py:48] [256700] global_step=256700, grad_norm=3.0327951908111572, loss=1.205344796180725
I0303 21:19:13.000206 139881808373504 logging_writer.py:48] [256800] global_step=256800, grad_norm=3.260132312774658, loss=2.1076669692993164
I0303 21:19:57.400238 139881799980800 logging_writer.py:48] [256900] global_step=256900, grad_norm=3.320481061935425, loss=1.1104580163955688
I0303 21:20:42.183481 139881808373504 logging_writer.py:48] [257000] global_step=257000, grad_norm=3.1442337036132812, loss=1.4919086694717407
I0303 21:21:26.754732 139881799980800 logging_writer.py:48] [257100] global_step=257100, grad_norm=3.0701675415039062, loss=1.0666040182113647
I0303 21:22:11.478697 139881808373504 logging_writer.py:48] [257200] global_step=257200, grad_norm=3.193284034729004, loss=2.76007080078125
I0303 21:22:50.698438 140077943854912 spec.py:321] Evaluating on the training split.
I0303 21:23:00.718553 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:23:39.554203 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:23:41.131455 140077943854912 submission_runner.py:411] Time since start: 123413.94s, 	Step: 257290, 	{'train/accuracy': 0.8877929449081421, 'train/loss': 0.4188413619995117, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 113052.01241707802, 'total_duration': 123413.93646836281, 'accumulated_submission_time': 113052.01241707802, 'accumulated_eval_time': 10332.705268383026, 'accumulated_logging_time': 15.78389596939087}
I0303 21:23:41.187045 139881799980800 logging_writer.py:48] [257290] accumulated_eval_time=10332.705268, accumulated_logging_time=15.783896, accumulated_submission_time=113052.012417, global_step=257290, preemption_count=0, score=113052.012417, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=123413.936468, train/accuracy=0.887793, train/loss=0.418841, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:23:45.475786 139881808373504 logging_writer.py:48] [257300] global_step=257300, grad_norm=3.1394050121307373, loss=1.2104010581970215
I0303 21:24:26.113341 139881799980800 logging_writer.py:48] [257400] global_step=257400, grad_norm=3.3777313232421875, loss=1.1473926305770874
I0303 21:25:10.645527 139881808373504 logging_writer.py:48] [257500] global_step=257500, grad_norm=3.0689663887023926, loss=1.1879652738571167
I0303 21:25:55.141958 139881799980800 logging_writer.py:48] [257600] global_step=257600, grad_norm=3.2115793228149414, loss=2.480158805847168
I0303 21:26:39.662498 139881808373504 logging_writer.py:48] [257700] global_step=257700, grad_norm=3.1729650497436523, loss=1.990816593170166
I0303 21:27:24.079316 139881799980800 logging_writer.py:48] [257800] global_step=257800, grad_norm=2.920564651489258, loss=2.081808567047119
I0303 21:28:08.369727 139881808373504 logging_writer.py:48] [257900] global_step=257900, grad_norm=3.122340440750122, loss=1.3871259689331055
I0303 21:28:52.555118 139881799980800 logging_writer.py:48] [258000] global_step=258000, grad_norm=3.1791653633117676, loss=1.1515452861785889
I0303 21:29:36.965686 139881808373504 logging_writer.py:48] [258100] global_step=258100, grad_norm=2.9754867553710938, loss=1.109121561050415
I0303 21:30:21.506423 139881799980800 logging_writer.py:48] [258200] global_step=258200, grad_norm=3.3429362773895264, loss=1.9598746299743652
I0303 21:30:41.179530 140077943854912 spec.py:321] Evaluating on the training split.
I0303 21:30:51.672404 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:31:20.276422 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:31:21.878465 140077943854912 submission_runner.py:411] Time since start: 123874.68s, 	Step: 258246, 	{'train/accuracy': 0.8865820169448853, 'train/loss': 0.42418745160102844, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 113471.94405174255, 'total_duration': 123874.68347358704, 'accumulated_submission_time': 113471.94405174255, 'accumulated_eval_time': 10373.404185056686, 'accumulated_logging_time': 15.850019216537476}
I0303 21:31:21.932974 139881808373504 logging_writer.py:48] [258246] accumulated_eval_time=10373.404185, accumulated_logging_time=15.850019, accumulated_submission_time=113471.944052, global_step=258246, preemption_count=0, score=113471.944052, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=123874.683474, train/accuracy=0.886582, train/loss=0.424187, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:31:43.446927 139881799980800 logging_writer.py:48] [258300] global_step=258300, grad_norm=3.147707939147949, loss=2.1842715740203857
I0303 21:32:26.072643 139881808373504 logging_writer.py:48] [258400] global_step=258400, grad_norm=3.326047420501709, loss=1.1151273250579834
I0303 21:33:10.505704 139881799980800 logging_writer.py:48] [258500] global_step=258500, grad_norm=3.2691822052001953, loss=2.559337854385376
I0303 21:33:55.017968 139881808373504 logging_writer.py:48] [258600] global_step=258600, grad_norm=3.09857177734375, loss=1.213271975517273
I0303 21:34:39.403949 139881799980800 logging_writer.py:48] [258700] global_step=258700, grad_norm=3.126385450363159, loss=0.9952290058135986
I0303 21:35:24.095499 139881808373504 logging_writer.py:48] [258800] global_step=258800, grad_norm=3.2901461124420166, loss=1.2643346786499023
I0303 21:36:08.547109 139881799980800 logging_writer.py:48] [258900] global_step=258900, grad_norm=3.0902481079101562, loss=1.0791453123092651
I0303 21:36:53.173063 139881808373504 logging_writer.py:48] [259000] global_step=259000, grad_norm=3.9201908111572266, loss=3.3495280742645264
I0303 21:37:37.802820 139881799980800 logging_writer.py:48] [259100] global_step=259100, grad_norm=3.2016196250915527, loss=1.2672922611236572
I0303 21:38:22.338006 139881808373504 logging_writer.py:48] [259200] global_step=259200, grad_norm=3.0804195404052734, loss=1.160355806350708
I0303 21:38:22.351477 140077943854912 spec.py:321] Evaluating on the training split.
I0303 21:38:32.660965 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:38:59.519367 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:39:01.109247 140077943854912 submission_runner.py:411] Time since start: 124333.91s, 	Step: 259201, 	{'train/accuracy': 0.8890624642372131, 'train/loss': 0.415942519903183, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 113892.2898645401, 'total_duration': 124333.91425085068, 'accumulated_submission_time': 113892.2898645401, 'accumulated_eval_time': 10412.161917448044, 'accumulated_logging_time': 15.914101839065552}
I0303 21:39:01.189474 139881799980800 logging_writer.py:48] [259201] accumulated_eval_time=10412.161917, accumulated_logging_time=15.914102, accumulated_submission_time=113892.289865, global_step=259201, preemption_count=0, score=113892.289865, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=124333.914251, train/accuracy=0.889062, train/loss=0.415943, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:39:42.582001 139881808373504 logging_writer.py:48] [259300] global_step=259300, grad_norm=3.3381621837615967, loss=2.528090476989746
I0303 21:40:27.287613 139881799980800 logging_writer.py:48] [259400] global_step=259400, grad_norm=3.3526759147644043, loss=2.5425240993499756
I0303 21:41:12.067410 139881808373504 logging_writer.py:48] [259500] global_step=259500, grad_norm=3.6542279720306396, loss=3.0723061561584473
I0303 21:41:56.538583 139881799980800 logging_writer.py:48] [259600] global_step=259600, grad_norm=2.7766242027282715, loss=1.9337990283966064
I0303 21:42:41.489021 139881808373504 logging_writer.py:48] [259700] global_step=259700, grad_norm=3.678201675415039, loss=3.1987524032592773
I0303 21:43:26.360363 139881799980800 logging_writer.py:48] [259800] global_step=259800, grad_norm=2.913548231124878, loss=1.2904925346374512
I0303 21:44:11.571642 139881808373504 logging_writer.py:48] [259900] global_step=259900, grad_norm=3.0103323459625244, loss=1.4527608156204224
I0303 21:44:56.375166 139881799980800 logging_writer.py:48] [260000] global_step=260000, grad_norm=2.898496389389038, loss=1.82012939453125
I0303 21:45:41.328444 139881808373504 logging_writer.py:48] [260100] global_step=260100, grad_norm=3.0583670139312744, loss=1.0820775032043457
I0303 21:46:01.460051 140077943854912 spec.py:321] Evaluating on the training split.
I0303 21:46:11.780780 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:46:42.197454 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:46:43.787029 140077943854912 submission_runner.py:411] Time since start: 124796.59s, 	Step: 260147, 	{'train/accuracy': 0.8899999856948853, 'train/loss': 0.407744437456131, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 114312.50053668022, 'total_duration': 124796.59203076363, 'accumulated_submission_time': 114312.50053668022, 'accumulated_eval_time': 10454.48885679245, 'accumulated_logging_time': 16.005540370941162}
I0303 21:46:43.858445 139881799980800 logging_writer.py:48] [260147] accumulated_eval_time=10454.488857, accumulated_logging_time=16.005540, accumulated_submission_time=114312.500537, global_step=260147, preemption_count=0, score=114312.500537, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=124796.592031, train/accuracy=0.890000, train/loss=0.407744, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:47:04.927147 139881808373504 logging_writer.py:48] [260200] global_step=260200, grad_norm=3.6410670280456543, loss=2.3720784187316895
I0303 21:47:48.531735 139881799980800 logging_writer.py:48] [260300] global_step=260300, grad_norm=3.8458597660064697, loss=3.157106876373291
I0303 21:48:33.253554 139881808373504 logging_writer.py:48] [260400] global_step=260400, grad_norm=3.259185552597046, loss=2.3581342697143555
I0303 21:49:18.494746 139881799980800 logging_writer.py:48] [260500] global_step=260500, grad_norm=3.044771671295166, loss=1.2693226337432861
I0303 21:50:02.898678 139881808373504 logging_writer.py:48] [260600] global_step=260600, grad_norm=3.047545909881592, loss=2.049265146255493
I0303 21:50:47.500088 139881799980800 logging_writer.py:48] [260700] global_step=260700, grad_norm=3.8833372592926025, loss=3.423593521118164
I0303 21:51:32.197153 139881808373504 logging_writer.py:48] [260800] global_step=260800, grad_norm=3.632857084274292, loss=2.9230175018310547
I0303 21:52:16.680187 139881799980800 logging_writer.py:48] [260900] global_step=260900, grad_norm=3.696838617324829, loss=1.2083187103271484
I0303 21:53:01.212650 139881808373504 logging_writer.py:48] [261000] global_step=261000, grad_norm=3.3774607181549072, loss=2.0820324420928955
I0303 21:53:44.091386 140077943854912 spec.py:321] Evaluating on the training split.
I0303 21:53:54.280761 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 21:54:20.794440 140077943854912 spec.py:349] Evaluating on the test split.
I0303 21:54:22.405797 140077943854912 submission_runner.py:411] Time since start: 125255.21s, 	Step: 261098, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.41530200839042664, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 114732.67173314095, 'total_duration': 125255.21079921722, 'accumulated_submission_time': 114732.67173314095, 'accumulated_eval_time': 10492.803237915039, 'accumulated_logging_time': 16.09019136428833}
I0303 21:54:22.467600 139881799980800 logging_writer.py:48] [261098] accumulated_eval_time=10492.803238, accumulated_logging_time=16.090191, accumulated_submission_time=114732.671733, global_step=261098, preemption_count=0, score=114732.671733, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=125255.210799, train/accuracy=0.888418, train/loss=0.415302, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 21:54:23.639698 139881808373504 logging_writer.py:48] [261100] global_step=261100, grad_norm=3.1038055419921875, loss=2.9518849849700928
I0303 21:55:03.828317 139881799980800 logging_writer.py:48] [261200] global_step=261200, grad_norm=3.068866014480591, loss=0.9785455465316772
I0303 21:55:48.033264 139881808373504 logging_writer.py:48] [261300] global_step=261300, grad_norm=3.0234358310699463, loss=1.387063980102539
I0303 21:56:32.671859 139881799980800 logging_writer.py:48] [261400] global_step=261400, grad_norm=3.2392961978912354, loss=1.142881989479065
I0303 21:57:17.612049 139881808373504 logging_writer.py:48] [261500] global_step=261500, grad_norm=3.463418960571289, loss=3.161698579788208
I0303 21:58:01.887704 139881799980800 logging_writer.py:48] [261600] global_step=261600, grad_norm=3.373115301132202, loss=1.5342121124267578
I0303 21:58:46.703308 139881808373504 logging_writer.py:48] [261700] global_step=261700, grad_norm=3.2803714275360107, loss=2.621230125427246
I0303 21:59:31.056588 139881799980800 logging_writer.py:48] [261800] global_step=261800, grad_norm=2.93131422996521, loss=1.7078508138656616
I0303 22:00:15.659143 139881808373504 logging_writer.py:48] [261900] global_step=261900, grad_norm=3.341839551925659, loss=1.1171579360961914
I0303 22:01:00.071072 139881799980800 logging_writer.py:48] [262000] global_step=262000, grad_norm=3.8072526454925537, loss=1.27053964138031
I0303 22:01:22.460079 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:01:33.314369 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:01:57.902849 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:01:59.493141 140077943854912 submission_runner.py:411] Time since start: 125712.30s, 	Step: 262052, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.41666048765182495, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 115152.60396766663, 'total_duration': 125712.29814648628, 'accumulated_submission_time': 115152.60396766663, 'accumulated_eval_time': 10529.83626651764, 'accumulated_logging_time': 16.163026809692383}
I0303 22:01:59.565530 139881808373504 logging_writer.py:48] [262052] accumulated_eval_time=10529.836267, accumulated_logging_time=16.163027, accumulated_submission_time=115152.603968, global_step=262052, preemption_count=0, score=115152.603968, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=125712.298146, train/accuracy=0.888340, train/loss=0.416660, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:02:18.691229 139881799980800 logging_writer.py:48] [262100] global_step=262100, grad_norm=3.017960548400879, loss=1.1269497871398926
I0303 22:03:01.910991 139881808373504 logging_writer.py:48] [262200] global_step=262200, grad_norm=3.028660774230957, loss=2.0275938510894775
I0303 22:03:46.083457 139881799980800 logging_writer.py:48] [262300] global_step=262300, grad_norm=3.3612887859344482, loss=1.1274731159210205
I0303 22:04:30.504001 139881808373504 logging_writer.py:48] [262400] global_step=262400, grad_norm=2.9792428016662598, loss=1.1865684986114502
I0303 22:05:15.035743 139881799980800 logging_writer.py:48] [262500] global_step=262500, grad_norm=3.4002068042755127, loss=2.6136395931243896
I0303 22:05:59.677421 139881808373504 logging_writer.py:48] [262600] global_step=262600, grad_norm=3.3388092517852783, loss=2.5991647243499756
I0303 22:06:44.339715 139881799980800 logging_writer.py:48] [262700] global_step=262700, grad_norm=3.091169595718384, loss=1.099306344985962
I0303 22:07:29.069561 139881808373504 logging_writer.py:48] [262800] global_step=262800, grad_norm=3.9029884338378906, loss=3.3048336505889893
I0303 22:08:13.644791 139881799980800 logging_writer.py:48] [262900] global_step=262900, grad_norm=3.2186737060546875, loss=1.2162647247314453
I0303 22:08:57.948817 139881808373504 logging_writer.py:48] [263000] global_step=263000, grad_norm=3.034876585006714, loss=1.6406116485595703
I0303 22:08:59.797930 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:09:10.248668 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:09:45.884284 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:09:47.461643 140077943854912 submission_runner.py:411] Time since start: 126180.27s, 	Step: 263006, 	{'train/accuracy': 0.8867968320846558, 'train/loss': 0.4171631932258606, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 115572.77207779884, 'total_duration': 126180.26666045189, 'accumulated_submission_time': 115572.77207779884, 'accumulated_eval_time': 10577.499941587448, 'accumulated_logging_time': 16.24975323677063}
I0303 22:09:47.518245 139881799980800 logging_writer.py:48] [263006] accumulated_eval_time=10577.499942, accumulated_logging_time=16.249753, accumulated_submission_time=115572.772078, global_step=263006, preemption_count=0, score=115572.772078, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=126180.266660, train/accuracy=0.886797, train/loss=0.417163, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:10:25.131328 139881808373504 logging_writer.py:48] [263100] global_step=263100, grad_norm=3.439753532409668, loss=2.211911678314209
I0303 22:11:09.171742 139881799980800 logging_writer.py:48] [263200] global_step=263200, grad_norm=3.1725594997406006, loss=1.2905631065368652
I0303 22:11:53.357240 139881808373504 logging_writer.py:48] [263300] global_step=263300, grad_norm=3.154998779296875, loss=1.1072582006454468
I0303 22:12:37.903814 139881799980800 logging_writer.py:48] [263400] global_step=263400, grad_norm=3.257202386856079, loss=2.632460117340088
I0303 22:13:22.358998 139881808373504 logging_writer.py:48] [263500] global_step=263500, grad_norm=2.9302616119384766, loss=1.064046859741211
I0303 22:14:06.774860 139881799980800 logging_writer.py:48] [263600] global_step=263600, grad_norm=3.069477081298828, loss=2.0549309253692627
I0303 22:14:50.925381 139881808373504 logging_writer.py:48] [263700] global_step=263700, grad_norm=3.94565749168396, loss=2.297825574874878
I0303 22:15:35.383112 139881799980800 logging_writer.py:48] [263800] global_step=263800, grad_norm=3.540786027908325, loss=2.7550384998321533
I0303 22:16:19.659980 139881808373504 logging_writer.py:48] [263900] global_step=263900, grad_norm=3.047333002090454, loss=1.090348243713379
I0303 22:16:47.775922 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:16:57.658414 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:17:27.312781 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:17:28.904515 140077943854912 submission_runner.py:411] Time since start: 126641.71s, 	Step: 263965, 	{'train/accuracy': 0.8879296779632568, 'train/loss': 0.41934168338775635, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 115992.9700987339, 'total_duration': 126641.70953035355, 'accumulated_submission_time': 115992.9700987339, 'accumulated_eval_time': 10618.628512144089, 'accumulated_logging_time': 16.316112995147705}
I0303 22:17:28.963032 139881799980800 logging_writer.py:48] [263965] accumulated_eval_time=10618.628512, accumulated_logging_time=16.316113, accumulated_submission_time=115992.970099, global_step=263965, preemption_count=0, score=115992.970099, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=126641.709530, train/accuracy=0.887930, train/loss=0.419342, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:17:43.000451 139881808373504 logging_writer.py:48] [264000] global_step=264000, grad_norm=3.0574965476989746, loss=1.1837395429611206
I0303 22:18:24.716007 139881799980800 logging_writer.py:48] [264100] global_step=264100, grad_norm=3.335895299911499, loss=1.085758924484253
I0303 22:19:09.113776 139881808373504 logging_writer.py:48] [264200] global_step=264200, grad_norm=3.647796869277954, loss=1.540107011795044
I0303 22:19:53.967458 139881799980800 logging_writer.py:48] [264300] global_step=264300, grad_norm=2.8567864894866943, loss=1.6258363723754883
I0303 22:20:38.216709 139881808373504 logging_writer.py:48] [264400] global_step=264400, grad_norm=3.0407657623291016, loss=1.6134270429611206
I0303 22:21:22.929447 139881799980800 logging_writer.py:48] [264500] global_step=264500, grad_norm=2.9062366485595703, loss=1.0779670476913452
I0303 22:22:07.660517 139881808373504 logging_writer.py:48] [264600] global_step=264600, grad_norm=3.2193360328674316, loss=1.160430669784546
I0303 22:22:51.714599 139881799980800 logging_writer.py:48] [264700] global_step=264700, grad_norm=3.0755765438079834, loss=1.302375316619873
I0303 22:23:36.163573 139881808373504 logging_writer.py:48] [264800] global_step=264800, grad_norm=3.009823799133301, loss=1.1783100366592407
I0303 22:24:20.749653 139881799980800 logging_writer.py:48] [264900] global_step=264900, grad_norm=3.1527440547943115, loss=1.114810824394226
I0303 22:24:28.945684 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:24:39.212521 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:25:04.488819 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:25:06.084644 140077943854912 submission_runner.py:411] Time since start: 127098.89s, 	Step: 264920, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.4095839560031891, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 116412.89240884781, 'total_duration': 127098.88965320587, 'accumulated_submission_time': 116412.89240884781, 'accumulated_eval_time': 10655.76745057106, 'accumulated_logging_time': 16.38568639755249}
I0303 22:25:06.154426 139881808373504 logging_writer.py:48] [264920] accumulated_eval_time=10655.767451, accumulated_logging_time=16.385686, accumulated_submission_time=116412.892409, global_step=264920, preemption_count=0, score=116412.892409, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=127098.889653, train/accuracy=0.889570, train/loss=0.409584, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:25:38.703089 139881799980800 logging_writer.py:48] [265000] global_step=265000, grad_norm=3.118377447128296, loss=1.3654985427856445
I0303 22:26:23.393745 139881808373504 logging_writer.py:48] [265100] global_step=265100, grad_norm=3.2172179222106934, loss=1.1773892641067505
I0303 22:27:07.937333 139881799980800 logging_writer.py:48] [265200] global_step=265200, grad_norm=3.105743646621704, loss=1.1107012033462524
I0303 22:27:52.482632 139881808373504 logging_writer.py:48] [265300] global_step=265300, grad_norm=2.9758012294769287, loss=1.9187719821929932
I0303 22:28:36.797626 139881799980800 logging_writer.py:48] [265400] global_step=265400, grad_norm=3.0069825649261475, loss=1.1350693702697754
I0303 22:29:21.219208 139881808373504 logging_writer.py:48] [265500] global_step=265500, grad_norm=2.9296369552612305, loss=1.6378974914550781
I0303 22:30:05.661622 139881799980800 logging_writer.py:48] [265600] global_step=265600, grad_norm=3.9445152282714844, loss=1.1838082075119019
I0303 22:30:49.849380 139881808373504 logging_writer.py:48] [265700] global_step=265700, grad_norm=3.0101380348205566, loss=1.2302535772323608
I0303 22:31:34.148812 139881799980800 logging_writer.py:48] [265800] global_step=265800, grad_norm=3.3861048221588135, loss=3.0645864009857178
I0303 22:32:06.281545 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:32:16.435209 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:32:50.993444 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:32:52.580914 140077943854912 submission_runner.py:411] Time since start: 127565.39s, 	Step: 265874, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.41824257373809814, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 116832.95955109596, 'total_duration': 127565.38592290878, 'accumulated_submission_time': 116832.95955109596, 'accumulated_eval_time': 10702.066796064377, 'accumulated_logging_time': 16.466209650039673}
I0303 22:32:52.646454 139881808373504 logging_writer.py:48] [265874] accumulated_eval_time=10702.066796, accumulated_logging_time=16.466210, accumulated_submission_time=116832.959551, global_step=265874, preemption_count=0, score=116832.959551, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=127565.385923, train/accuracy=0.888398, train/loss=0.418243, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:33:03.169055 139881799980800 logging_writer.py:48] [265900] global_step=265900, grad_norm=3.8681299686431885, loss=3.1789815425872803
I0303 22:33:44.210667 139881808373504 logging_writer.py:48] [266000] global_step=266000, grad_norm=3.135057210922241, loss=2.119687080383301
I0303 22:34:28.652405 139881799980800 logging_writer.py:48] [266100] global_step=266100, grad_norm=3.0016162395477295, loss=1.07119619846344
I0303 22:35:13.143486 139881808373504 logging_writer.py:48] [266200] global_step=266200, grad_norm=3.2675302028656006, loss=2.160078525543213
I0303 22:35:57.370638 139881799980800 logging_writer.py:48] [266300] global_step=266300, grad_norm=3.1245522499084473, loss=1.1367560625076294
I0303 22:36:42.088158 139881808373504 logging_writer.py:48] [266400] global_step=266400, grad_norm=3.6166200637817383, loss=3.320281982421875
I0303 22:37:26.638765 139881799980800 logging_writer.py:48] [266500] global_step=266500, grad_norm=3.57133150100708, loss=1.3083763122558594
I0303 22:38:11.020036 139881808373504 logging_writer.py:48] [266600] global_step=266600, grad_norm=3.1105997562408447, loss=2.421445608139038
I0303 22:38:55.288892 139881799980800 logging_writer.py:48] [266700] global_step=266700, grad_norm=3.311723232269287, loss=2.74996018409729
I0303 22:39:39.541938 139881808373504 logging_writer.py:48] [266800] global_step=266800, grad_norm=3.3170814514160156, loss=2.4458506107330322
I0303 22:39:52.972862 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:40:03.148531 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:40:26.479446 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:40:28.065299 140077943854912 submission_runner.py:411] Time since start: 128020.87s, 	Step: 266832, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.4178032875061035, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 117253.22350525856, 'total_duration': 128020.87030768394, 'accumulated_submission_time': 117253.22350525856, 'accumulated_eval_time': 10737.159190177917, 'accumulated_logging_time': 16.54511594772339}
I0303 22:40:28.135532 139881799980800 logging_writer.py:48] [266832] accumulated_eval_time=10737.159190, accumulated_logging_time=16.545116, accumulated_submission_time=117253.223505, global_step=266832, preemption_count=0, score=117253.223505, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=128020.870308, train/accuracy=0.886738, train/loss=0.417803, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:40:55.325879 139881808373504 logging_writer.py:48] [266900] global_step=266900, grad_norm=3.274911642074585, loss=1.1273391246795654
I0303 22:41:39.759259 139881799980800 logging_writer.py:48] [267000] global_step=267000, grad_norm=3.628638744354248, loss=1.1898417472839355
I0303 22:42:24.090635 139881808373504 logging_writer.py:48] [267100] global_step=267100, grad_norm=3.098881721496582, loss=1.1556029319763184
I0303 22:43:08.508657 139881799980800 logging_writer.py:48] [267200] global_step=267200, grad_norm=2.980457067489624, loss=1.0959633588790894
I0303 22:43:52.842850 139881808373504 logging_writer.py:48] [267300] global_step=267300, grad_norm=3.2772467136383057, loss=1.1084063053131104
I0303 22:44:37.218788 139881799980800 logging_writer.py:48] [267400] global_step=267400, grad_norm=3.3041746616363525, loss=1.7996872663497925
I0303 22:45:21.679045 139881808373504 logging_writer.py:48] [267500] global_step=267500, grad_norm=3.4552273750305176, loss=1.2718631029129028
I0303 22:46:06.150825 139881799980800 logging_writer.py:48] [267600] global_step=267600, grad_norm=2.9077727794647217, loss=2.4525766372680664
I0303 22:46:50.666615 139881808373504 logging_writer.py:48] [267700] global_step=267700, grad_norm=3.297740936279297, loss=1.1763700246810913
I0303 22:47:28.283497 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:47:38.394188 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:48:05.630455 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:48:07.221247 140077943854912 submission_runner.py:411] Time since start: 128480.03s, 	Step: 267786, 	{'train/accuracy': 0.8861132860183716, 'train/loss': 0.4290775954723358, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 117673.31190681458, 'total_duration': 128480.02625536919, 'accumulated_submission_time': 117673.31190681458, 'accumulated_eval_time': 10776.096898555756, 'accumulated_logging_time': 16.626272678375244}
I0303 22:48:07.290773 139881799980800 logging_writer.py:48] [267786] accumulated_eval_time=10776.096899, accumulated_logging_time=16.626273, accumulated_submission_time=117673.311907, global_step=267786, preemption_count=0, score=117673.311907, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=128480.026255, train/accuracy=0.886113, train/loss=0.429078, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:48:13.158257 139881808373504 logging_writer.py:48] [267800] global_step=267800, grad_norm=3.233673095703125, loss=1.122156023979187
I0303 22:48:54.741009 139881799980800 logging_writer.py:48] [267900] global_step=267900, grad_norm=3.1695547103881836, loss=2.4050021171569824
I0303 22:49:39.425097 139881808373504 logging_writer.py:48] [268000] global_step=268000, grad_norm=3.1518564224243164, loss=1.3764300346374512
I0303 22:50:24.019260 139881799980800 logging_writer.py:48] [268100] global_step=268100, grad_norm=2.9490609169006348, loss=1.0309971570968628
I0303 22:51:08.493609 139881808373504 logging_writer.py:48] [268200] global_step=268200, grad_norm=2.868173360824585, loss=1.4346957206726074
I0303 22:51:52.732638 139881799980800 logging_writer.py:48] [268300] global_step=268300, grad_norm=3.004692554473877, loss=1.517129898071289
I0303 22:52:37.410313 139881808373504 logging_writer.py:48] [268400] global_step=268400, grad_norm=3.221343517303467, loss=1.0472631454467773
I0303 22:53:21.932243 139881799980800 logging_writer.py:48] [268500] global_step=268500, grad_norm=3.020559310913086, loss=1.0257750749588013
I0303 22:54:06.355464 139881808373504 logging_writer.py:48] [268600] global_step=268600, grad_norm=3.2585818767547607, loss=1.8742294311523438
I0303 22:54:50.774265 139881799980800 logging_writer.py:48] [268700] global_step=268700, grad_norm=3.065164804458618, loss=1.6960563659667969
I0303 22:55:07.513013 140077943854912 spec.py:321] Evaluating on the training split.
I0303 22:55:17.482790 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 22:55:44.620112 140077943854912 spec.py:349] Evaluating on the test split.
I0303 22:55:46.209177 140077943854912 submission_runner.py:411] Time since start: 128939.01s, 	Step: 268739, 	{'train/accuracy': 0.8898437023162842, 'train/loss': 0.4073122441768646, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 118093.4741909504, 'total_duration': 128939.01418423653, 'accumulated_submission_time': 118093.4741909504, 'accumulated_eval_time': 10814.793027639389, 'accumulated_logging_time': 16.707128047943115}
I0303 22:55:46.279415 139881808373504 logging_writer.py:48] [268739] accumulated_eval_time=10814.793028, accumulated_logging_time=16.707128, accumulated_submission_time=118093.474191, global_step=268739, preemption_count=0, score=118093.474191, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=128939.014184, train/accuracy=0.889844, train/loss=0.407312, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 22:56:10.494461 139881799980800 logging_writer.py:48] [268800] global_step=268800, grad_norm=2.992924213409424, loss=1.2277857065200806
I0303 22:56:54.229382 139881808373504 logging_writer.py:48] [268900] global_step=268900, grad_norm=3.0122761726379395, loss=1.7379930019378662
I0303 22:57:38.657985 139881799980800 logging_writer.py:48] [269000] global_step=269000, grad_norm=3.546485424041748, loss=1.3290538787841797
I0303 22:58:22.951146 139881808373504 logging_writer.py:48] [269100] global_step=269100, grad_norm=2.7797577381134033, loss=1.9011151790618896
I0303 22:59:07.396094 139881799980800 logging_writer.py:48] [269200] global_step=269200, grad_norm=3.2476344108581543, loss=2.8365540504455566
I0303 22:59:51.193283 139881808373504 logging_writer.py:48] [269300] global_step=269300, grad_norm=3.35067081451416, loss=1.160525918006897
I0303 23:00:35.624752 139881799980800 logging_writer.py:48] [269400] global_step=269400, grad_norm=2.923246383666992, loss=1.7266268730163574
I0303 23:01:19.976136 139881808373504 logging_writer.py:48] [269500] global_step=269500, grad_norm=2.854566812515259, loss=1.6245205402374268
I0303 23:02:04.276297 139881799980800 logging_writer.py:48] [269600] global_step=269600, grad_norm=3.294799327850342, loss=1.2602131366729736
I0303 23:02:46.451105 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:02:56.542571 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:03:26.573021 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:03:28.151308 140077943854912 submission_runner.py:411] Time since start: 129400.96s, 	Step: 269697, 	{'train/accuracy': 0.8878124952316284, 'train/loss': 0.41410017013549805, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 118513.58444952965, 'total_duration': 129400.95628118515, 'accumulated_submission_time': 118513.58444952965, 'accumulated_eval_time': 10856.493202209473, 'accumulated_logging_time': 16.789478540420532}
I0303 23:03:28.223126 139881808373504 logging_writer.py:48] [269697] accumulated_eval_time=10856.493202, accumulated_logging_time=16.789479, accumulated_submission_time=118513.584450, global_step=269697, preemption_count=0, score=118513.584450, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=129400.956281, train/accuracy=0.887812, train/loss=0.414100, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:03:29.784919 139881799980800 logging_writer.py:48] [269700] global_step=269700, grad_norm=3.3923139572143555, loss=2.691328287124634
I0303 23:04:09.254951 139881808373504 logging_writer.py:48] [269800] global_step=269800, grad_norm=2.89338755607605, loss=1.6439934968948364
I0303 23:04:53.294832 139881799980800 logging_writer.py:48] [269900] global_step=269900, grad_norm=3.4600419998168945, loss=1.1193194389343262
I0303 23:05:37.752793 139881808373504 logging_writer.py:48] [270000] global_step=270000, grad_norm=3.453483819961548, loss=2.9979636669158936
I0303 23:06:22.395046 139881799980800 logging_writer.py:48] [270100] global_step=270100, grad_norm=3.303863286972046, loss=2.1050455570220947
I0303 23:07:06.938911 139881808373504 logging_writer.py:48] [270200] global_step=270200, grad_norm=3.194835901260376, loss=2.470438003540039
I0303 23:07:51.450507 139881799980800 logging_writer.py:48] [270300] global_step=270300, grad_norm=3.6147501468658447, loss=1.1925722360610962
I0303 23:08:35.886090 139881808373504 logging_writer.py:48] [270400] global_step=270400, grad_norm=3.0699000358581543, loss=1.121443748474121
I0303 23:09:20.387354 139881799980800 logging_writer.py:48] [270500] global_step=270500, grad_norm=3.7221624851226807, loss=3.1299750804901123
I0303 23:10:04.976660 139881808373504 logging_writer.py:48] [270600] global_step=270600, grad_norm=3.0140843391418457, loss=1.559714436531067
I0303 23:10:28.527340 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:10:38.398740 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:11:01.655654 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:11:03.250282 140077943854912 submission_runner.py:411] Time since start: 129856.06s, 	Step: 270655, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.4185597002506256, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 118933.8285355568, 'total_duration': 129856.05528616905, 'accumulated_submission_time': 118933.8285355568, 'accumulated_eval_time': 10891.216101408005, 'accumulated_logging_time': 16.87260341644287}
I0303 23:11:03.323154 139881799980800 logging_writer.py:48] [270655] accumulated_eval_time=10891.216101, accumulated_logging_time=16.872603, accumulated_submission_time=118933.828536, global_step=270655, preemption_count=0, score=118933.828536, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=129856.055286, train/accuracy=0.888438, train/loss=0.418560, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:11:21.262504 139881808373504 logging_writer.py:48] [270700] global_step=270700, grad_norm=3.2067654132843018, loss=1.9106634855270386
I0303 23:12:03.868791 139881799980800 logging_writer.py:48] [270800] global_step=270800, grad_norm=2.9100868701934814, loss=1.220548391342163
I0303 23:12:48.211046 139881808373504 logging_writer.py:48] [270900] global_step=270900, grad_norm=2.999204635620117, loss=2.025839328765869
I0303 23:13:32.738324 139881799980800 logging_writer.py:48] [271000] global_step=271000, grad_norm=3.314685106277466, loss=2.8104820251464844
I0303 23:14:16.980895 139881808373504 logging_writer.py:48] [271100] global_step=271100, grad_norm=3.2583162784576416, loss=1.1058303117752075
I0303 23:15:01.265300 139881799980800 logging_writer.py:48] [271200] global_step=271200, grad_norm=3.000836133956909, loss=1.0582826137542725
I0303 23:15:45.962372 139881808373504 logging_writer.py:48] [271300] global_step=271300, grad_norm=3.6920065879821777, loss=1.7089526653289795
I0303 23:16:30.086601 139881799980800 logging_writer.py:48] [271400] global_step=271400, grad_norm=3.2059500217437744, loss=1.8433845043182373
I0303 23:17:14.542475 139881808373504 logging_writer.py:48] [271500] global_step=271500, grad_norm=3.906378746032715, loss=3.170279026031494
I0303 23:17:59.089007 139881799980800 logging_writer.py:48] [271600] global_step=271600, grad_norm=3.148329019546509, loss=1.214174747467041
I0303 23:18:03.295792 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:18:13.589102 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:18:38.127226 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:18:39.713359 140077943854912 submission_runner.py:411] Time since start: 130312.52s, 	Step: 271611, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.4192695617675781, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 119353.74111104012, 'total_duration': 130312.51836848259, 'accumulated_submission_time': 119353.74111104012, 'accumulated_eval_time': 10927.63363814354, 'accumulated_logging_time': 16.95663595199585}
I0303 23:18:39.784440 139881808373504 logging_writer.py:48] [271611] accumulated_eval_time=10927.633638, accumulated_logging_time=16.956636, accumulated_submission_time=119353.741111, global_step=271611, preemption_count=0, score=119353.741111, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=130312.518368, train/accuracy=0.887734, train/loss=0.419270, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:19:16.033382 139881799980800 logging_writer.py:48] [271700] global_step=271700, grad_norm=3.0641136169433594, loss=1.2035069465637207
I0303 23:20:00.241764 139881808373504 logging_writer.py:48] [271800] global_step=271800, grad_norm=2.9508676528930664, loss=1.3206387758255005
I0303 23:20:44.609069 139881799980800 logging_writer.py:48] [271900] global_step=271900, grad_norm=3.6709463596343994, loss=1.1423465013504028
I0303 23:21:29.128825 139881808373504 logging_writer.py:48] [272000] global_step=272000, grad_norm=3.055635690689087, loss=1.3518965244293213
I0303 23:22:13.489915 139881799980800 logging_writer.py:48] [272100] global_step=272100, grad_norm=3.4712393283843994, loss=1.0409367084503174
I0303 23:22:57.983318 139881808373504 logging_writer.py:48] [272200] global_step=272200, grad_norm=3.137472152709961, loss=1.1570647954940796
I0303 23:23:42.569357 139881799980800 logging_writer.py:48] [272300] global_step=272300, grad_norm=3.511155128479004, loss=2.9552557468414307
I0303 23:24:26.900106 139881808373504 logging_writer.py:48] [272400] global_step=272400, grad_norm=2.9909579753875732, loss=1.4648330211639404
I0303 23:25:11.322915 139881799980800 logging_writer.py:48] [272500] global_step=272500, grad_norm=2.5885114669799805, loss=1.6987061500549316
I0303 23:25:39.816423 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:25:49.647525 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:26:18.778047 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:26:20.380743 140077943854912 submission_runner.py:411] Time since start: 130773.19s, 	Step: 272566, 	{'train/accuracy': 0.8866015672683716, 'train/loss': 0.4227052330970764, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 119773.71231675148, 'total_duration': 130773.18575668335, 'accumulated_submission_time': 119773.71231675148, 'accumulated_eval_time': 10968.197939157486, 'accumulated_logging_time': 17.039021015167236}
I0303 23:26:20.436704 139881808373504 logging_writer.py:48] [272566] accumulated_eval_time=10968.197939, accumulated_logging_time=17.039021, accumulated_submission_time=119773.712317, global_step=272566, preemption_count=0, score=119773.712317, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=130773.185757, train/accuracy=0.886602, train/loss=0.422705, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:26:34.091699 139881799980800 logging_writer.py:48] [272600] global_step=272600, grad_norm=3.3288516998291016, loss=1.1028233766555786
I0303 23:27:15.361411 139881808373504 logging_writer.py:48] [272700] global_step=272700, grad_norm=3.192493200302124, loss=1.6106340885162354
I0303 23:27:59.671564 139881799980800 logging_writer.py:48] [272800] global_step=272800, grad_norm=3.5211193561553955, loss=1.1097102165222168
I0303 23:28:44.120543 139881808373504 logging_writer.py:48] [272900] global_step=272900, grad_norm=3.1491825580596924, loss=1.087618350982666
I0303 23:29:28.550536 139881799980800 logging_writer.py:48] [273000] global_step=273000, grad_norm=3.5197863578796387, loss=2.8818037509918213
I0303 23:30:13.009593 139881808373504 logging_writer.py:48] [273100] global_step=273100, grad_norm=3.092620849609375, loss=1.7354648113250732
I0303 23:30:57.376737 139881799980800 logging_writer.py:48] [273200] global_step=273200, grad_norm=3.373169422149658, loss=3.1845805644989014
I0303 23:31:41.668626 139881808373504 logging_writer.py:48] [273300] global_step=273300, grad_norm=2.8936381340026855, loss=1.7036734819412231
I0303 23:32:25.917852 139881799980800 logging_writer.py:48] [273400] global_step=273400, grad_norm=2.9927306175231934, loss=1.181368112564087
I0303 23:33:10.312060 139881808373504 logging_writer.py:48] [273500] global_step=273500, grad_norm=3.0834450721740723, loss=2.5359432697296143
I0303 23:33:20.709950 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:33:30.784801 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:34:07.615596 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:34:09.194900 140077943854912 submission_runner.py:411] Time since start: 131242.00s, 	Step: 273525, 	{'train/accuracy': 0.8893554210662842, 'train/loss': 0.41083723306655884, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 120193.92505979538, 'total_duration': 131241.99991846085, 'accumulated_submission_time': 120193.92505979538, 'accumulated_eval_time': 11016.682899475098, 'accumulated_logging_time': 17.105791568756104}
I0303 23:34:09.253113 139881799980800 logging_writer.py:48] [273525] accumulated_eval_time=11016.682899, accumulated_logging_time=17.105792, accumulated_submission_time=120193.925060, global_step=273525, preemption_count=0, score=120193.925060, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=131241.999918, train/accuracy=0.889355, train/loss=0.410837, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:34:38.900052 139881808373504 logging_writer.py:48] [273600] global_step=273600, grad_norm=3.731386423110962, loss=3.264910936355591
I0303 23:35:22.152825 139881799980800 logging_writer.py:48] [273700] global_step=273700, grad_norm=2.888547897338867, loss=1.2640632390975952
I0303 23:36:06.710900 139881808373504 logging_writer.py:48] [273800] global_step=273800, grad_norm=3.154496192932129, loss=2.666558027267456
I0303 23:36:51.406487 139881799980800 logging_writer.py:48] [273900] global_step=273900, grad_norm=3.1874945163726807, loss=1.1557646989822388
I0303 23:37:35.859945 139881808373504 logging_writer.py:48] [274000] global_step=274000, grad_norm=3.484800338745117, loss=1.2333613634109497
I0303 23:38:20.137207 139881799980800 logging_writer.py:48] [274100] global_step=274100, grad_norm=2.8612265586853027, loss=1.63975191116333
I0303 23:39:04.526359 139881808373504 logging_writer.py:48] [274200] global_step=274200, grad_norm=3.1479909420013428, loss=1.023226261138916
I0303 23:39:48.582152 139881799980800 logging_writer.py:48] [274300] global_step=274300, grad_norm=3.1131367683410645, loss=1.1239349842071533
I0303 23:40:32.893949 139881808373504 logging_writer.py:48] [274400] global_step=274400, grad_norm=3.130110502243042, loss=2.4493494033813477
I0303 23:41:09.707914 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:41:20.106716 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:41:49.338605 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:41:50.913836 140077943854912 submission_runner.py:411] Time since start: 131703.72s, 	Step: 274484, 	{'train/accuracy': 0.8886327743530273, 'train/loss': 0.4180715084075928, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 120614.32047319412, 'total_duration': 131703.71882891655, 'accumulated_submission_time': 120614.32047319412, 'accumulated_eval_time': 11057.888793230057, 'accumulated_logging_time': 17.17463517189026}
I0303 23:41:50.975936 139881799980800 logging_writer.py:48] [274484] accumulated_eval_time=11057.888793, accumulated_logging_time=17.174635, accumulated_submission_time=120614.320473, global_step=274484, preemption_count=0, score=120614.320473, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=131703.718829, train/accuracy=0.888633, train/loss=0.418072, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:41:57.596222 139881808373504 logging_writer.py:48] [274500] global_step=274500, grad_norm=3.033836841583252, loss=1.1419800519943237
I0303 23:42:38.569875 139881799980800 logging_writer.py:48] [274600] global_step=274600, grad_norm=3.301008939743042, loss=1.0925859212875366
I0303 23:43:22.817747 139881808373504 logging_writer.py:48] [274700] global_step=274700, grad_norm=3.5205137729644775, loss=2.962883710861206
I0303 23:44:07.780820 139881799980800 logging_writer.py:48] [274800] global_step=274800, grad_norm=3.0105741024017334, loss=1.9946352243423462
I0303 23:44:51.905264 139881808373504 logging_writer.py:48] [274900] global_step=274900, grad_norm=3.1579408645629883, loss=1.1321030855178833
I0303 23:45:36.281517 139881799980800 logging_writer.py:48] [275000] global_step=275000, grad_norm=2.975151300430298, loss=1.241798996925354
I0303 23:46:20.702618 139881808373504 logging_writer.py:48] [275100] global_step=275100, grad_norm=3.3712477684020996, loss=2.7036423683166504
I0303 23:47:05.113279 139881799980800 logging_writer.py:48] [275200] global_step=275200, grad_norm=3.334883689880371, loss=1.1664918661117554
I0303 23:47:49.496277 139881808373504 logging_writer.py:48] [275300] global_step=275300, grad_norm=3.4511311054229736, loss=2.979997396469116
I0303 23:48:34.336483 139881799980800 logging_writer.py:48] [275400] global_step=275400, grad_norm=3.186950922012329, loss=1.3682706356048584
I0303 23:48:51.280698 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:49:01.631153 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:49:28.331804 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:49:29.922369 140077943854912 submission_runner.py:411] Time since start: 132162.73s, 	Step: 275441, 	{'train/accuracy': 0.8881054520606995, 'train/loss': 0.4140663146972656, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 121034.56578993797, 'total_duration': 132162.7273669243, 'accumulated_submission_time': 121034.56578993797, 'accumulated_eval_time': 11096.530444145203, 'accumulated_logging_time': 17.246686697006226}
I0303 23:49:29.997525 139881808373504 logging_writer.py:48] [275441] accumulated_eval_time=11096.530444, accumulated_logging_time=17.246687, accumulated_submission_time=121034.565790, global_step=275441, preemption_count=0, score=121034.565790, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=132162.727367, train/accuracy=0.888105, train/loss=0.414066, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:49:53.537618 139881799980800 logging_writer.py:48] [275500] global_step=275500, grad_norm=3.248964786529541, loss=1.333013653755188
I0303 23:50:38.464178 139881808373504 logging_writer.py:48] [275600] global_step=275600, grad_norm=3.5253007411956787, loss=2.8447649478912354
I0303 23:51:23.262524 139881799980800 logging_writer.py:48] [275700] global_step=275700, grad_norm=3.6320066452026367, loss=3.318251132965088
I0303 23:52:08.225728 139881808373504 logging_writer.py:48] [275800] global_step=275800, grad_norm=3.1406140327453613, loss=1.1569533348083496
I0303 23:52:53.279888 139881799980800 logging_writer.py:48] [275900] global_step=275900, grad_norm=3.2286155223846436, loss=1.26376473903656
I0303 23:53:38.228029 139881808373504 logging_writer.py:48] [276000] global_step=276000, grad_norm=3.2066867351531982, loss=1.1869488954544067
I0303 23:54:23.145777 139881799980800 logging_writer.py:48] [276100] global_step=276100, grad_norm=2.918800115585327, loss=2.043640375137329
I0303 23:55:08.517880 139881808373504 logging_writer.py:48] [276200] global_step=276200, grad_norm=3.350740432739258, loss=2.3466310501098633
I0303 23:55:53.534301 139881799980800 logging_writer.py:48] [276300] global_step=276300, grad_norm=3.315804958343506, loss=1.1601052284240723
I0303 23:56:30.039840 140077943854912 spec.py:321] Evaluating on the training split.
I0303 23:56:40.281720 140077943854912 spec.py:333] Evaluating on the validation split.
I0303 23:57:01.432739 140077943854912 spec.py:349] Evaluating on the test split.
I0303 23:57:03.027803 140077943854912 submission_runner.py:411] Time since start: 132615.83s, 	Step: 276382, 	{'train/accuracy': 0.8871874809265137, 'train/loss': 0.4224247932434082, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 121454.5478489399, 'total_duration': 132615.83280420303, 'accumulated_submission_time': 121454.5478489399, 'accumulated_eval_time': 11129.518389940262, 'accumulated_logging_time': 17.333673238754272}
I0303 23:57:03.098138 139881808373504 logging_writer.py:48] [276382] accumulated_eval_time=11129.518390, accumulated_logging_time=17.333673, accumulated_submission_time=121454.547849, global_step=276382, preemption_count=0, score=121454.547849, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=132615.832804, train/accuracy=0.887187, train/loss=0.422425, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0303 23:57:10.505822 139881799980800 logging_writer.py:48] [276400] global_step=276400, grad_norm=3.4674861431121826, loss=1.4181673526763916
I0303 23:57:53.052577 139881808373504 logging_writer.py:48] [276500] global_step=276500, grad_norm=3.87605357170105, loss=3.2299623489379883
I0303 23:58:37.561584 139881799980800 logging_writer.py:48] [276600] global_step=276600, grad_norm=2.921684503555298, loss=1.281770944595337
I0303 23:59:22.415244 139881808373504 logging_writer.py:48] [276700] global_step=276700, grad_norm=3.1538753509521484, loss=1.1026734113693237
I0304 00:00:07.657535 139881799980800 logging_writer.py:48] [276800] global_step=276800, grad_norm=4.1206817626953125, loss=3.2378218173980713
I0304 00:00:52.405337 139881808373504 logging_writer.py:48] [276900] global_step=276900, grad_norm=3.4470131397247314, loss=1.45816171169281
I0304 00:01:37.636780 139881799980800 logging_writer.py:48] [277000] global_step=277000, grad_norm=3.419381618499756, loss=1.377523422241211
I0304 00:02:22.665901 139881808373504 logging_writer.py:48] [277100] global_step=277100, grad_norm=3.016479015350342, loss=1.7954450845718384
I0304 00:03:07.548382 139881799980800 logging_writer.py:48] [277200] global_step=277200, grad_norm=3.3597381114959717, loss=2.2285056114196777
I0304 00:03:52.219559 139881808373504 logging_writer.py:48] [277300] global_step=277300, grad_norm=3.5230519771575928, loss=2.9565494060516357
I0304 00:04:03.257792 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:04:13.509450 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:04:37.792058 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:04:39.388106 140077943854912 submission_runner.py:411] Time since start: 133072.19s, 	Step: 277326, 	{'train/accuracy': 0.8856640458106995, 'train/loss': 0.4246830940246582, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 121874.64784169197, 'total_duration': 133072.1931116581, 'accumulated_submission_time': 121874.64784169197, 'accumulated_eval_time': 11165.648698568344, 'accumulated_logging_time': 17.41505718231201}
I0304 00:04:39.464653 139881799980800 logging_writer.py:48] [277326] accumulated_eval_time=11165.648699, accumulated_logging_time=17.415057, accumulated_submission_time=121874.647842, global_step=277326, preemption_count=0, score=121874.647842, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=133072.193112, train/accuracy=0.885664, train/loss=0.424683, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:05:09.300343 139881808373504 logging_writer.py:48] [277400] global_step=277400, grad_norm=3.2851603031158447, loss=1.1032342910766602
I0304 00:05:53.327753 139881799980800 logging_writer.py:48] [277500] global_step=277500, grad_norm=4.064488410949707, loss=3.3452062606811523
I0304 00:06:38.161392 139881808373504 logging_writer.py:48] [277600] global_step=277600, grad_norm=3.285750389099121, loss=2.8349783420562744
I0304 00:07:22.784277 139881799980800 logging_writer.py:48] [277700] global_step=277700, grad_norm=3.030019998550415, loss=2.349601984024048
I0304 00:08:07.537097 139881808373504 logging_writer.py:48] [277800] global_step=277800, grad_norm=3.105710744857788, loss=2.126126527786255
I0304 00:08:51.741331 139881799980800 logging_writer.py:48] [277900] global_step=277900, grad_norm=3.7113943099975586, loss=3.0886785984039307
I0304 00:09:36.233883 139881808373504 logging_writer.py:48] [278000] global_step=278000, grad_norm=2.8998754024505615, loss=1.2384480237960815
I0304 00:10:20.940272 139881799980800 logging_writer.py:48] [278100] global_step=278100, grad_norm=4.479276657104492, loss=3.2805404663085938
I0304 00:11:05.412086 139881808373504 logging_writer.py:48] [278200] global_step=278200, grad_norm=3.250519275665283, loss=1.1105706691741943
I0304 00:11:39.756314 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:11:49.529086 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:12:17.405542 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:12:19.013743 140077943854912 submission_runner.py:411] Time since start: 133531.82s, 	Step: 278279, 	{'train/accuracy': 0.8876367211341858, 'train/loss': 0.41545364260673523, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 122294.87970471382, 'total_duration': 133531.81871771812, 'accumulated_submission_time': 122294.87970471382, 'accumulated_eval_time': 11204.90605711937, 'accumulated_logging_time': 17.502548217773438}
I0304 00:12:19.071529 139881799980800 logging_writer.py:48] [278279] accumulated_eval_time=11204.906057, accumulated_logging_time=17.502548, accumulated_submission_time=122294.879705, global_step=278279, preemption_count=0, score=122294.879705, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=133531.818718, train/accuracy=0.887637, train/loss=0.415454, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:12:27.641289 139881808373504 logging_writer.py:48] [278300] global_step=278300, grad_norm=3.2058796882629395, loss=1.21962308883667
I0304 00:13:08.175285 139881799980800 logging_writer.py:48] [278400] global_step=278400, grad_norm=2.9569106101989746, loss=1.2071971893310547
I0304 00:13:52.433552 139881808373504 logging_writer.py:48] [278500] global_step=278500, grad_norm=3.0417468547821045, loss=2.0611624717712402
I0304 00:14:37.012136 139881799980800 logging_writer.py:48] [278600] global_step=278600, grad_norm=3.279904365539551, loss=2.78271746635437
I0304 00:15:21.353269 139881808373504 logging_writer.py:48] [278700] global_step=278700, grad_norm=3.245561361312866, loss=1.1667264699935913
I0304 00:16:06.006104 139881799980800 logging_writer.py:48] [278800] global_step=278800, grad_norm=3.1291797161102295, loss=2.149700403213501
I0304 00:16:50.434166 139881808373504 logging_writer.py:48] [278900] global_step=278900, grad_norm=3.126786470413208, loss=1.1041319370269775
I0304 00:17:34.838323 139881799980800 logging_writer.py:48] [279000] global_step=279000, grad_norm=3.409536361694336, loss=3.0716941356658936
I0304 00:18:19.266269 139881808373504 logging_writer.py:48] [279100] global_step=279100, grad_norm=2.941969156265259, loss=1.7160431146621704
I0304 00:19:03.989027 139881799980800 logging_writer.py:48] [279200] global_step=279200, grad_norm=3.150803565979004, loss=2.3710200786590576
I0304 00:19:19.368593 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:19:29.322037 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:19:55.918071 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:19:57.504407 140077943854912 submission_runner.py:411] Time since start: 133990.31s, 	Step: 279237, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.41426387429237366, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 122715.11296343803, 'total_duration': 133990.30941224098, 'accumulated_submission_time': 122715.11296343803, 'accumulated_eval_time': 11243.041862249374, 'accumulated_logging_time': 17.574153184890747}
I0304 00:19:57.576600 139881808373504 logging_writer.py:48] [279237] accumulated_eval_time=11243.041862, accumulated_logging_time=17.574153, accumulated_submission_time=122715.112963, global_step=279237, preemption_count=0, score=122715.112963, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=133990.309412, train/accuracy=0.888320, train/loss=0.414264, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:20:22.565608 139881799980800 logging_writer.py:48] [279300] global_step=279300, grad_norm=3.117872714996338, loss=1.1577820777893066
I0304 00:21:06.109582 139881808373504 logging_writer.py:48] [279400] global_step=279400, grad_norm=3.3507561683654785, loss=2.7328121662139893
I0304 00:21:50.506700 139881799980800 logging_writer.py:48] [279500] global_step=279500, grad_norm=2.8449559211730957, loss=1.2430633306503296
I0304 00:22:34.943320 139881808373504 logging_writer.py:48] [279600] global_step=279600, grad_norm=3.219207763671875, loss=1.194819688796997
I0304 00:23:19.584469 139881799980800 logging_writer.py:48] [279700] global_step=279700, grad_norm=3.1277449131011963, loss=2.557343006134033
I0304 00:24:03.582315 139881808373504 logging_writer.py:48] [279800] global_step=279800, grad_norm=3.943037509918213, loss=3.281789779663086
I0304 00:24:47.862510 139881799980800 logging_writer.py:48] [279900] global_step=279900, grad_norm=3.1367199420928955, loss=1.6760057210922241
I0304 00:25:32.534980 139881808373504 logging_writer.py:48] [280000] global_step=280000, grad_norm=3.2375338077545166, loss=1.5723426342010498
I0304 00:26:17.125006 139881799980800 logging_writer.py:48] [280100] global_step=280100, grad_norm=3.6156320571899414, loss=3.3084473609924316
I0304 00:26:57.551813 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:27:08.027292 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:27:26.951838 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:27:28.542270 140077943854912 submission_runner.py:411] Time since start: 134441.35s, 	Step: 280193, 	{'train/accuracy': 0.8883007764816284, 'train/loss': 0.4194623529911041, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 123135.0280020237, 'total_duration': 134441.34727716446, 'accumulated_submission_time': 123135.0280020237, 'accumulated_eval_time': 11274.032299041748, 'accumulated_logging_time': 17.657609224319458}
I0304 00:27:28.612870 139881808373504 logging_writer.py:48] [280193] accumulated_eval_time=11274.032299, accumulated_logging_time=17.657609, accumulated_submission_time=123135.028002, global_step=280193, preemption_count=0, score=123135.028002, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=134441.347277, train/accuracy=0.888301, train/loss=0.419462, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:27:31.758292 139881799980800 logging_writer.py:48] [280200] global_step=280200, grad_norm=3.1796584129333496, loss=1.0940392017364502
I0304 00:28:13.026613 139881808373504 logging_writer.py:48] [280300] global_step=280300, grad_norm=3.2422149181365967, loss=2.840714931488037
I0304 00:28:57.408752 139881799980800 logging_writer.py:48] [280400] global_step=280400, grad_norm=3.440631628036499, loss=2.1789932250976562
I0304 00:29:41.468137 139881808373504 logging_writer.py:48] [280500] global_step=280500, grad_norm=3.2585508823394775, loss=1.1860250234603882
I0304 00:30:25.927543 139881799980800 logging_writer.py:48] [280600] global_step=280600, grad_norm=3.197458505630493, loss=2.1698920726776123
I0304 00:31:10.089792 139881808373504 logging_writer.py:48] [280700] global_step=280700, grad_norm=3.242781400680542, loss=1.141380786895752
I0304 00:31:54.569609 139881799980800 logging_writer.py:48] [280800] global_step=280800, grad_norm=2.910001516342163, loss=1.1885236501693726
I0304 00:32:39.102658 139881808373504 logging_writer.py:48] [280900] global_step=280900, grad_norm=4.046328544616699, loss=3.2673230171203613
I0304 00:33:23.514257 139881799980800 logging_writer.py:48] [281000] global_step=281000, grad_norm=2.873598098754883, loss=1.5534694194793701
I0304 00:34:08.143898 139881808373504 logging_writer.py:48] [281100] global_step=281100, grad_norm=3.182178020477295, loss=1.2893688678741455
I0304 00:34:28.721160 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:34:38.904490 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:35:12.784800 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:35:14.378001 140077943854912 submission_runner.py:411] Time since start: 134907.18s, 	Step: 281148, 	{'train/accuracy': 0.8873046636581421, 'train/loss': 0.41618582606315613, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 123555.07653808594, 'total_duration': 134907.18300938606, 'accumulated_submission_time': 123555.07653808594, 'accumulated_eval_time': 11319.689100265503, 'accumulated_logging_time': 17.738707065582275}
I0304 00:35:14.436986 139881799980800 logging_writer.py:48] [281148] accumulated_eval_time=11319.689100, accumulated_logging_time=17.738707, accumulated_submission_time=123555.076538, global_step=281148, preemption_count=0, score=123555.076538, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=134907.183009, train/accuracy=0.887305, train/loss=0.416186, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:35:35.130994 139881808373504 logging_writer.py:48] [281200] global_step=281200, grad_norm=3.3104004859924316, loss=1.1600295305252075
I0304 00:36:17.195445 139881799980800 logging_writer.py:48] [281300] global_step=281300, grad_norm=2.937836170196533, loss=1.6084429025650024
I0304 00:37:01.757683 139881808373504 logging_writer.py:48] [281400] global_step=281400, grad_norm=2.9760332107543945, loss=1.442197561264038
I0304 00:37:46.729304 139881799980800 logging_writer.py:48] [281500] global_step=281500, grad_norm=2.9809389114379883, loss=1.6707285642623901
I0304 00:38:31.151467 139881808373504 logging_writer.py:48] [281600] global_step=281600, grad_norm=3.3521125316619873, loss=0.9633674621582031
I0304 00:39:16.131426 139881799980800 logging_writer.py:48] [281700] global_step=281700, grad_norm=3.265901803970337, loss=2.0526137351989746
I0304 00:39:59.896197 139881808373504 logging_writer.py:48] [281800] global_step=281800, grad_norm=3.490762948989868, loss=2.583193778991699
I0304 00:40:44.600847 139881799980800 logging_writer.py:48] [281900] global_step=281900, grad_norm=3.425907850265503, loss=1.1187353134155273
I0304 00:41:29.243264 139881808373504 logging_writer.py:48] [282000] global_step=282000, grad_norm=3.558121681213379, loss=1.1564881801605225
I0304 00:42:13.527664 139881799980800 logging_writer.py:48] [282100] global_step=282100, grad_norm=3.0342915058135986, loss=1.1846234798431396
I0304 00:42:14.588650 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:42:24.394763 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:42:50.101945 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:42:51.689251 140077943854912 submission_runner.py:411] Time since start: 135364.49s, 	Step: 282104, 	{'train/accuracy': 0.8891406059265137, 'train/loss': 0.4142415225505829, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 123975.168166399, 'total_duration': 135364.49425768852, 'accumulated_submission_time': 123975.168166399, 'accumulated_eval_time': 11356.789668560028, 'accumulated_logging_time': 17.809013605117798}
I0304 00:42:51.761212 139881808373504 logging_writer.py:48] [282104] accumulated_eval_time=11356.789669, accumulated_logging_time=17.809014, accumulated_submission_time=123975.168166, global_step=282104, preemption_count=0, score=123975.168166, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=135364.494258, train/accuracy=0.889141, train/loss=0.414242, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:43:31.015567 139881799980800 logging_writer.py:48] [282200] global_step=282200, grad_norm=3.2014031410217285, loss=1.1720788478851318
I0304 00:44:15.408924 139881808373504 logging_writer.py:48] [282300] global_step=282300, grad_norm=3.0815489292144775, loss=1.1192861795425415
I0304 00:44:59.810302 139881799980800 logging_writer.py:48] [282400] global_step=282400, grad_norm=3.042959213256836, loss=1.8321243524551392
I0304 00:45:44.347230 139881808373504 logging_writer.py:48] [282500] global_step=282500, grad_norm=3.975259780883789, loss=3.3190627098083496
I0304 00:46:28.801274 139881799980800 logging_writer.py:48] [282600] global_step=282600, grad_norm=3.273808240890503, loss=1.776890516281128
I0304 00:47:13.320846 139881808373504 logging_writer.py:48] [282700] global_step=282700, grad_norm=3.3513989448547363, loss=2.302055835723877
I0304 00:47:57.867604 139881799980800 logging_writer.py:48] [282800] global_step=282800, grad_norm=3.430006742477417, loss=2.669757843017578
I0304 00:48:42.459583 139881808373504 logging_writer.py:48] [282900] global_step=282900, grad_norm=3.2238330841064453, loss=1.2692824602127075
I0304 00:49:26.932388 139881799980800 logging_writer.py:48] [283000] global_step=283000, grad_norm=3.1185061931610107, loss=1.421150803565979
I0304 00:49:51.804984 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:50:02.060696 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:50:34.063521 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:50:35.654535 140077943854912 submission_runner.py:411] Time since start: 135828.46s, 	Step: 283058, 	{'train/accuracy': 0.8882812261581421, 'train/loss': 0.4211524426937103, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 124395.1518342495, 'total_duration': 135828.45954036713, 'accumulated_submission_time': 124395.1518342495, 'accumulated_eval_time': 11400.639189958572, 'accumulated_logging_time': 17.891976594924927}
I0304 00:50:35.725855 139881808373504 logging_writer.py:48] [283058] accumulated_eval_time=11400.639190, accumulated_logging_time=17.891977, accumulated_submission_time=124395.151834, global_step=283058, preemption_count=0, score=124395.151834, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=135828.459540, train/accuracy=0.888281, train/loss=0.421152, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:50:52.488999 139881799980800 logging_writer.py:48] [283100] global_step=283100, grad_norm=3.021195411682129, loss=1.0816209316253662
I0304 00:51:35.113909 139881808373504 logging_writer.py:48] [283200] global_step=283200, grad_norm=2.947148561477661, loss=1.3819996118545532
I0304 00:52:19.675617 139881799980800 logging_writer.py:48] [283300] global_step=283300, grad_norm=3.430859327316284, loss=2.948627233505249
I0304 00:53:04.430438 139881808373504 logging_writer.py:48] [283400] global_step=283400, grad_norm=3.985051393508911, loss=3.2625701427459717
I0304 00:53:48.823152 139881799980800 logging_writer.py:48] [283500] global_step=283500, grad_norm=3.246317148208618, loss=1.0903724431991577
I0304 00:54:33.276049 139881808373504 logging_writer.py:48] [283600] global_step=283600, grad_norm=3.2387869358062744, loss=1.2067230939865112
I0304 00:55:17.772628 139881799980800 logging_writer.py:48] [283700] global_step=283700, grad_norm=2.876098155975342, loss=1.4737207889556885
I0304 00:56:02.269977 139881808373504 logging_writer.py:48] [283800] global_step=283800, grad_norm=3.0554490089416504, loss=1.4891406297683716
I0304 00:56:46.727178 139881799980800 logging_writer.py:48] [283900] global_step=283900, grad_norm=3.127305030822754, loss=1.2147204875946045
I0304 00:57:31.505783 139881808373504 logging_writer.py:48] [284000] global_step=284000, grad_norm=3.0302958488464355, loss=1.1542069911956787
I0304 00:57:36.062809 140077943854912 spec.py:321] Evaluating on the training split.
I0304 00:57:45.978134 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 00:58:14.154700 140077943854912 spec.py:349] Evaluating on the test split.
I0304 00:58:15.754504 140077943854912 submission_runner.py:411] Time since start: 136288.56s, 	Step: 284012, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.41234084963798523, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 124815.4282989502, 'total_duration': 136288.5594909191, 'accumulated_submission_time': 124815.4282989502, 'accumulated_eval_time': 11440.330829620361, 'accumulated_logging_time': 17.974778175354004}
I0304 00:58:15.833263 139881799980800 logging_writer.py:48] [284012] accumulated_eval_time=11440.330830, accumulated_logging_time=17.974778, accumulated_submission_time=124815.428299, global_step=284012, preemption_count=0, score=124815.428299, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=136288.559491, train/accuracy=0.888730, train/loss=0.412341, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 00:58:50.836773 139881808373504 logging_writer.py:48] [284100] global_step=284100, grad_norm=3.1285898685455322, loss=2.7126047611236572
I0304 00:59:35.033981 139881799980800 logging_writer.py:48] [284200] global_step=284200, grad_norm=3.825674533843994, loss=3.337461233139038
I0304 01:00:19.675045 139881808373504 logging_writer.py:48] [284300] global_step=284300, grad_norm=3.02839732170105, loss=1.5103850364685059
I0304 01:01:04.176663 139881799980800 logging_writer.py:48] [284400] global_step=284400, grad_norm=3.528860569000244, loss=2.0696659088134766
I0304 01:01:48.787159 139881808373504 logging_writer.py:48] [284500] global_step=284500, grad_norm=3.090650796890259, loss=1.1510403156280518
I0304 01:02:33.302263 139881799980800 logging_writer.py:48] [284600] global_step=284600, grad_norm=2.983820676803589, loss=1.795748233795166
I0304 01:03:18.068097 139881808373504 logging_writer.py:48] [284700] global_step=284700, grad_norm=3.112387180328369, loss=1.077697515487671
I0304 01:04:02.684939 139881799980800 logging_writer.py:48] [284800] global_step=284800, grad_norm=3.7131991386413574, loss=3.29470157623291
I0304 01:04:47.151531 139881808373504 logging_writer.py:48] [284900] global_step=284900, grad_norm=3.022679567337036, loss=1.5318149328231812
I0304 01:05:15.859675 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:05:26.180254 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:05:50.210119 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:05:51.793406 140077943854912 submission_runner.py:411] Time since start: 136744.60s, 	Step: 284966, 	{'train/accuracy': 0.8908007740974426, 'train/loss': 0.41067397594451904, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 125235.39047026634, 'total_duration': 136744.59841275215, 'accumulated_submission_time': 125235.39047026634, 'accumulated_eval_time': 11476.264526367188, 'accumulated_logging_time': 18.068246841430664}
I0304 01:05:51.865170 139881799980800 logging_writer.py:48] [284966] accumulated_eval_time=11476.264526, accumulated_logging_time=18.068247, accumulated_submission_time=125235.390470, global_step=284966, preemption_count=0, score=125235.390470, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=136744.598413, train/accuracy=0.890801, train/loss=0.410674, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:06:05.527777 139881808373504 logging_writer.py:48] [285000] global_step=285000, grad_norm=3.2038486003875732, loss=2.6829683780670166
I0304 01:06:48.835396 139881799980800 logging_writer.py:48] [285100] global_step=285100, grad_norm=2.9564871788024902, loss=1.016403079032898
I0304 01:07:33.304788 139881808373504 logging_writer.py:48] [285200] global_step=285200, grad_norm=3.2066779136657715, loss=1.0335941314697266
I0304 01:08:18.113126 139881799980800 logging_writer.py:48] [285300] global_step=285300, grad_norm=3.1138222217559814, loss=1.0165555477142334
I0304 01:09:02.565575 139881808373504 logging_writer.py:48] [285400] global_step=285400, grad_norm=3.3114945888519287, loss=2.1005301475524902
I0304 01:09:47.502056 139881799980800 logging_writer.py:48] [285500] global_step=285500, grad_norm=3.7912611961364746, loss=1.084281086921692
I0304 01:10:32.084563 139881808373504 logging_writer.py:48] [285600] global_step=285600, grad_norm=3.00569224357605, loss=1.0761082172393799
I0304 01:11:16.850966 139881799980800 logging_writer.py:48] [285700] global_step=285700, grad_norm=3.3040030002593994, loss=1.4715206623077393
I0304 01:12:01.406231 139881808373504 logging_writer.py:48] [285800] global_step=285800, grad_norm=3.162447452545166, loss=1.1506242752075195
I0304 01:12:45.978355 139881799980800 logging_writer.py:48] [285900] global_step=285900, grad_norm=3.4167706966400146, loss=1.2545186281204224
I0304 01:12:51.915060 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:13:03.075556 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:13:33.782051 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:13:35.369001 140077943854912 submission_runner.py:411] Time since start: 137208.17s, 	Step: 285915, 	{'train/accuracy': 0.8874804377555847, 'train/loss': 0.4160492718219757, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 125655.38073897362, 'total_duration': 137208.1740090847, 'accumulated_submission_time': 125655.38073897362, 'accumulated_eval_time': 11519.718435525894, 'accumulated_logging_time': 18.15044403076172}
I0304 01:13:35.443813 139881808373504 logging_writer.py:48] [285915] accumulated_eval_time=11519.718436, accumulated_logging_time=18.150444, accumulated_submission_time=125655.380739, global_step=285915, preemption_count=0, score=125655.380739, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=137208.174009, train/accuracy=0.887480, train/loss=0.416049, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:14:09.606585 139881799980800 logging_writer.py:48] [286000] global_step=286000, grad_norm=3.158303737640381, loss=1.1675825119018555
I0304 01:14:53.900540 139881808373504 logging_writer.py:48] [286100] global_step=286100, grad_norm=3.062986373901367, loss=1.079390048980713
I0304 01:15:38.459218 139881799980800 logging_writer.py:48] [286200] global_step=286200, grad_norm=3.1266372203826904, loss=1.1096807718276978
I0304 01:16:22.925909 139881808373504 logging_writer.py:48] [286300] global_step=286300, grad_norm=3.2470083236694336, loss=1.6393392086029053
I0304 01:17:07.185580 139881799980800 logging_writer.py:48] [286400] global_step=286400, grad_norm=2.7985100746154785, loss=1.7912003993988037
I0304 01:17:51.600946 139881808373504 logging_writer.py:48] [286500] global_step=286500, grad_norm=3.3828675746917725, loss=1.0049842596054077
I0304 01:18:35.898858 139881799980800 logging_writer.py:48] [286600] global_step=286600, grad_norm=4.029036521911621, loss=1.437875509262085
I0304 01:19:20.176104 139881808373504 logging_writer.py:48] [286700] global_step=286700, grad_norm=3.2352659702301025, loss=1.6225075721740723
I0304 01:20:04.747866 139881799980800 logging_writer.py:48] [286800] global_step=286800, grad_norm=3.861374855041504, loss=3.331956386566162
I0304 01:20:35.379607 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:20:45.404561 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:21:12.002396 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:21:13.600730 140077943854912 submission_runner.py:411] Time since start: 137666.41s, 	Step: 286871, 	{'train/accuracy': 0.88623046875, 'train/loss': 0.41971343755722046, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 126075.25695848465, 'total_duration': 137666.40572619438, 'accumulated_submission_time': 126075.25695848465, 'accumulated_eval_time': 11557.939510822296, 'accumulated_logging_time': 18.236321210861206}
I0304 01:21:13.691807 139881808373504 logging_writer.py:48] [286871] accumulated_eval_time=11557.939511, accumulated_logging_time=18.236321, accumulated_submission_time=126075.256958, global_step=286871, preemption_count=0, score=126075.256958, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=137666.405726, train/accuracy=0.886230, train/loss=0.419713, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:21:25.439739 139881799980800 logging_writer.py:48] [286900] global_step=286900, grad_norm=2.900423288345337, loss=1.295565128326416
I0304 01:22:06.999621 139881808373504 logging_writer.py:48] [287000] global_step=287000, grad_norm=3.3648345470428467, loss=2.8933253288269043
I0304 01:22:51.232594 139881799980800 logging_writer.py:48] [287100] global_step=287100, grad_norm=3.3306963443756104, loss=1.2418220043182373
I0304 01:23:36.190312 139881808373504 logging_writer.py:48] [287200] global_step=287200, grad_norm=3.129507064819336, loss=1.13266921043396
I0304 01:24:20.597217 139881799980800 logging_writer.py:48] [287300] global_step=287300, grad_norm=4.077969074249268, loss=1.2005250453948975
I0304 01:25:05.259873 139881808373504 logging_writer.py:48] [287400] global_step=287400, grad_norm=2.947310447692871, loss=1.636277198791504
I0304 01:25:49.658362 139881799980800 logging_writer.py:48] [287500] global_step=287500, grad_norm=3.364818572998047, loss=2.1959292888641357
I0304 01:26:34.478312 139881808373504 logging_writer.py:48] [287600] global_step=287600, grad_norm=2.9868884086608887, loss=1.1486237049102783
I0304 01:27:18.622052 139881799980800 logging_writer.py:48] [287700] global_step=287700, grad_norm=2.952162027359009, loss=1.2489477396011353
I0304 01:28:02.951196 139881808373504 logging_writer.py:48] [287800] global_step=287800, grad_norm=4.243384838104248, loss=3.473217010498047
I0304 01:28:13.721112 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:28:23.820361 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:28:50.086344 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:28:51.673439 140077943854912 submission_runner.py:411] Time since start: 138124.48s, 	Step: 287826, 	{'train/accuracy': 0.8890624642372131, 'train/loss': 0.41220623254776, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 126495.22283816338, 'total_duration': 138124.47844481468, 'accumulated_submission_time': 126495.22283816338, 'accumulated_eval_time': 11595.891792058945, 'accumulated_logging_time': 18.340837240219116}
I0304 01:28:51.746634 139881799980800 logging_writer.py:48] [287826] accumulated_eval_time=11595.891792, accumulated_logging_time=18.340837, accumulated_submission_time=126495.222838, global_step=287826, preemption_count=0, score=126495.222838, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=138124.478445, train/accuracy=0.889062, train/loss=0.412206, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:29:21.568507 139881808373504 logging_writer.py:48] [287900] global_step=287900, grad_norm=3.4380991458892822, loss=3.1273717880249023
I0304 01:30:06.139967 139881799980800 logging_writer.py:48] [288000] global_step=288000, grad_norm=3.7558486461639404, loss=3.0864977836608887
I0304 01:30:50.703709 139881808373504 logging_writer.py:48] [288100] global_step=288100, grad_norm=3.148085117340088, loss=1.5642129182815552
I0304 01:31:35.495409 139881799980800 logging_writer.py:48] [288200] global_step=288200, grad_norm=3.2160606384277344, loss=1.1017236709594727
I0304 01:32:20.262184 139881808373504 logging_writer.py:48] [288300] global_step=288300, grad_norm=3.46315860748291, loss=2.999746084213257
I0304 01:33:06.011682 139881799980800 logging_writer.py:48] [288400] global_step=288400, grad_norm=2.9413774013519287, loss=1.966994047164917
I0304 01:33:50.382228 139881808373504 logging_writer.py:48] [288500] global_step=288500, grad_norm=3.0960288047790527, loss=1.0955449342727661
I0304 01:34:35.075761 139881799980800 logging_writer.py:48] [288600] global_step=288600, grad_norm=3.2291529178619385, loss=1.0990350246429443
I0304 01:35:19.640935 139881808373504 logging_writer.py:48] [288700] global_step=288700, grad_norm=3.247000217437744, loss=1.1602683067321777
I0304 01:35:52.066762 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:36:02.366491 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:36:30.669220 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:36:32.257076 140077943854912 submission_runner.py:411] Time since start: 138585.06s, 	Step: 288774, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.4183759093284607, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 126915.48208451271, 'total_duration': 138585.06207585335, 'accumulated_submission_time': 126915.48208451271, 'accumulated_eval_time': 11636.082073688507, 'accumulated_logging_time': 18.42564058303833}
I0304 01:36:32.331929 139881799980800 logging_writer.py:48] [288774] accumulated_eval_time=11636.082074, accumulated_logging_time=18.425641, accumulated_submission_time=126915.482085, global_step=288774, preemption_count=0, score=126915.482085, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=138585.062076, train/accuracy=0.887598, train/loss=0.418376, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:36:42.865156 139881808373504 logging_writer.py:48] [288800] global_step=288800, grad_norm=3.013484477996826, loss=1.3056279420852661
I0304 01:37:24.897035 139881799980800 logging_writer.py:48] [288900] global_step=288900, grad_norm=2.9427497386932373, loss=1.1306134462356567
I0304 01:38:09.743122 139881808373504 logging_writer.py:48] [289000] global_step=289000, grad_norm=3.0958821773529053, loss=1.0693944692611694
I0304 01:38:54.298472 139881799980800 logging_writer.py:48] [289100] global_step=289100, grad_norm=3.2659080028533936, loss=1.1711702346801758
I0304 01:39:38.618246 139881808373504 logging_writer.py:48] [289200] global_step=289200, grad_norm=3.088181734085083, loss=1.0887563228607178
I0304 01:40:23.067054 139881799980800 logging_writer.py:48] [289300] global_step=289300, grad_norm=3.5640997886657715, loss=3.0419235229492188
I0304 01:41:07.476300 139881808373504 logging_writer.py:48] [289400] global_step=289400, grad_norm=3.271153450012207, loss=1.1246719360351562
I0304 01:41:51.853797 139881799980800 logging_writer.py:48] [289500] global_step=289500, grad_norm=3.0186989307403564, loss=1.0546808242797852
I0304 01:42:36.478237 139881808373504 logging_writer.py:48] [289600] global_step=289600, grad_norm=3.655388355255127, loss=3.234933853149414
I0304 01:43:20.985094 139881799980800 logging_writer.py:48] [289700] global_step=289700, grad_norm=3.549743413925171, loss=2.1525909900665283
I0304 01:43:32.613343 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:43:42.527983 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:44:10.585584 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:44:12.174138 140077943854912 submission_runner.py:411] Time since start: 139044.98s, 	Step: 289728, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.41436517238616943, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 127335.69866418839, 'total_duration': 139044.97914934158, 'accumulated_submission_time': 127335.69866418839, 'accumulated_eval_time': 11675.6428399086, 'accumulated_logging_time': 18.515563011169434}
I0304 01:44:12.247369 139881808373504 logging_writer.py:48] [289728] accumulated_eval_time=11675.642840, accumulated_logging_time=18.515563, accumulated_submission_time=127335.698664, global_step=289728, preemption_count=0, score=127335.698664, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=139044.979149, train/accuracy=0.889570, train/loss=0.414365, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:44:40.838166 139881799980800 logging_writer.py:48] [289800] global_step=289800, grad_norm=2.980631113052368, loss=1.0916492938995361
I0304 01:45:25.045331 139881808373504 logging_writer.py:48] [289900] global_step=289900, grad_norm=3.0025739669799805, loss=1.1663827896118164
I0304 01:46:09.449990 139881799980800 logging_writer.py:48] [290000] global_step=290000, grad_norm=3.075429677963257, loss=1.048463225364685
I0304 01:46:53.854407 139881808373504 logging_writer.py:48] [290100] global_step=290100, grad_norm=3.2576425075531006, loss=1.2914782762527466
I0304 01:47:38.244547 139881799980800 logging_writer.py:48] [290200] global_step=290200, grad_norm=3.475027561187744, loss=2.799602508544922
I0304 01:48:23.208428 139881808373504 logging_writer.py:48] [290300] global_step=290300, grad_norm=3.2205660343170166, loss=1.0569556951522827
I0304 01:49:07.779361 139881799980800 logging_writer.py:48] [290400] global_step=290400, grad_norm=3.0811057090759277, loss=1.145603060722351
I0304 01:49:52.185308 139881808373504 logging_writer.py:48] [290500] global_step=290500, grad_norm=3.7116997241973877, loss=3.2207674980163574
I0304 01:50:36.702302 139881799980800 logging_writer.py:48] [290600] global_step=290600, grad_norm=3.149761438369751, loss=1.2081815004348755
I0304 01:51:12.435342 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:51:22.359700 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:51:53.801247 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:51:55.388296 140077943854912 submission_runner.py:411] Time since start: 139508.19s, 	Step: 290682, 	{'train/accuracy': 0.884765625, 'train/loss': 0.42412203550338745, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 127755.82724237442, 'total_duration': 139508.1933040619, 'accumulated_submission_time': 127755.82724237442, 'accumulated_eval_time': 11718.595754623413, 'accumulated_logging_time': 18.59935998916626}
I0304 01:51:55.463690 139881808373504 logging_writer.py:48] [290682] accumulated_eval_time=11718.595755, accumulated_logging_time=18.599360, accumulated_submission_time=127755.827242, global_step=290682, preemption_count=0, score=127755.827242, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=139508.193304, train/accuracy=0.884766, train/loss=0.424122, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:52:02.884320 139881799980800 logging_writer.py:48] [290700] global_step=290700, grad_norm=3.1176273822784424, loss=1.1922214031219482
I0304 01:52:43.683914 139881808373504 logging_writer.py:48] [290800] global_step=290800, grad_norm=3.1987295150756836, loss=1.2383606433868408
I0304 01:53:28.140282 139881799980800 logging_writer.py:48] [290900] global_step=290900, grad_norm=3.0186173915863037, loss=1.4131512641906738
I0304 01:54:12.725181 139881808373504 logging_writer.py:48] [291000] global_step=291000, grad_norm=3.295884132385254, loss=1.2368409633636475
I0304 01:54:56.595890 139881799980800 logging_writer.py:48] [291100] global_step=291100, grad_norm=3.2102737426757812, loss=1.372984528541565
I0304 01:55:40.784236 139881808373504 logging_writer.py:48] [291200] global_step=291200, grad_norm=2.9430885314941406, loss=1.1285737752914429
I0304 01:56:25.426662 139881799980800 logging_writer.py:48] [291300] global_step=291300, grad_norm=3.5081734657287598, loss=2.6199045181274414
I0304 01:57:10.172826 139881808373504 logging_writer.py:48] [291400] global_step=291400, grad_norm=3.4382615089416504, loss=2.798753261566162
I0304 01:57:54.811389 139881799980800 logging_writer.py:48] [291500] global_step=291500, grad_norm=2.994636297225952, loss=1.0090793371200562
I0304 01:58:39.637020 139881808373504 logging_writer.py:48] [291600] global_step=291600, grad_norm=3.081170082092285, loss=0.9972866177558899
I0304 01:58:55.798885 140077943854912 spec.py:321] Evaluating on the training split.
I0304 01:59:06.402917 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 01:59:32.472489 140077943854912 spec.py:349] Evaluating on the test split.
I0304 01:59:34.054477 140077943854912 submission_runner.py:411] Time since start: 139966.86s, 	Step: 291638, 	{'train/accuracy': 0.8886523246765137, 'train/loss': 0.417254239320755, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 128176.1004807949, 'total_duration': 139966.8594853878, 'accumulated_submission_time': 128176.1004807949, 'accumulated_eval_time': 11756.851325035095, 'accumulated_logging_time': 18.68771505355835}
I0304 01:59:34.128770 139881799980800 logging_writer.py:48] [291638] accumulated_eval_time=11756.851325, accumulated_logging_time=18.687715, accumulated_submission_time=128176.100481, global_step=291638, preemption_count=0, score=128176.100481, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=139966.859485, train/accuracy=0.888652, train/loss=0.417254, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 01:59:58.710690 139881808373504 logging_writer.py:48] [291700] global_step=291700, grad_norm=3.841688394546509, loss=3.1643550395965576
I0304 02:00:42.397953 139881799980800 logging_writer.py:48] [291800] global_step=291800, grad_norm=2.8318443298339844, loss=1.6120113134384155
I0304 02:01:27.124181 139881808373504 logging_writer.py:48] [291900] global_step=291900, grad_norm=3.144170045852661, loss=1.156563639640808
I0304 02:02:11.785197 139881799980800 logging_writer.py:48] [292000] global_step=292000, grad_norm=3.299386978149414, loss=1.5893144607543945
I0304 02:02:56.117814 139881808373504 logging_writer.py:48] [292100] global_step=292100, grad_norm=2.9231724739074707, loss=1.1466128826141357
I0304 02:03:40.509526 139881799980800 logging_writer.py:48] [292200] global_step=292200, grad_norm=3.7672998905181885, loss=3.19779634475708
I0304 02:04:24.843276 139881808373504 logging_writer.py:48] [292300] global_step=292300, grad_norm=3.1829633712768555, loss=1.2289025783538818
I0304 02:05:09.273834 139881799980800 logging_writer.py:48] [292400] global_step=292400, grad_norm=3.366382598876953, loss=2.623175859451294
I0304 02:05:53.499358 139881808373504 logging_writer.py:48] [292500] global_step=292500, grad_norm=3.0465073585510254, loss=1.9554526805877686
I0304 02:06:34.369220 140077943854912 spec.py:321] Evaluating on the training split.
I0304 02:06:44.659061 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 02:07:13.442917 140077943854912 spec.py:349] Evaluating on the test split.
I0304 02:07:15.045611 140077943854912 submission_runner.py:411] Time since start: 140427.85s, 	Step: 292593, 	{'train/accuracy': 0.8885546922683716, 'train/loss': 0.41340816020965576, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 128596.28019595146, 'total_duration': 140427.85061454773, 'accumulated_submission_time': 128596.28019595146, 'accumulated_eval_time': 11797.527698516846, 'accumulated_logging_time': 18.773333311080933}
I0304 02:07:15.124382 139881799980800 logging_writer.py:48] [292593] accumulated_eval_time=11797.527699, accumulated_logging_time=18.773333, accumulated_submission_time=128596.280196, global_step=292593, preemption_count=0, score=128596.280196, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=140427.850615, train/accuracy=0.888555, train/loss=0.413408, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 02:07:18.257274 139881808373504 logging_writer.py:48] [292600] global_step=292600, grad_norm=3.0085625648498535, loss=1.1175825595855713
I0304 02:07:58.855392 139881799980800 logging_writer.py:48] [292700] global_step=292700, grad_norm=3.025453805923462, loss=1.114871621131897
I0304 02:08:43.246850 139881808373504 logging_writer.py:48] [292800] global_step=292800, grad_norm=3.177009105682373, loss=1.9331040382385254
I0304 02:09:27.599540 139881799980800 logging_writer.py:48] [292900] global_step=292900, grad_norm=3.275383710861206, loss=1.109752893447876
I0304 02:10:12.105412 139881808373504 logging_writer.py:48] [293000] global_step=293000, grad_norm=3.0509023666381836, loss=1.1029285192489624
I0304 02:10:56.516907 139881799980800 logging_writer.py:48] [293100] global_step=293100, grad_norm=2.843738555908203, loss=1.1730293035507202
I0304 02:11:41.013554 139881808373504 logging_writer.py:48] [293200] global_step=293200, grad_norm=3.0972743034362793, loss=1.154615879058838
I0304 02:12:25.440146 139881799980800 logging_writer.py:48] [293300] global_step=293300, grad_norm=3.0926358699798584, loss=1.5753015279769897
I0304 02:13:09.817533 139881808373504 logging_writer.py:48] [293400] global_step=293400, grad_norm=3.035388231277466, loss=2.7867488861083984
I0304 02:13:54.058101 139881799980800 logging_writer.py:48] [293500] global_step=293500, grad_norm=3.0017523765563965, loss=1.088297963142395
I0304 02:14:15.159300 140077943854912 spec.py:321] Evaluating on the training split.
I0304 02:14:25.609452 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 02:14:51.951424 140077943854912 spec.py:349] Evaluating on the test split.
I0304 02:14:53.539242 140077943854912 submission_runner.py:411] Time since start: 140886.34s, 	Step: 293549, 	{'train/accuracy': 0.8882030844688416, 'train/loss': 0.4148542284965515, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 129016.2508816719, 'total_duration': 140886.34425234795, 'accumulated_submission_time': 129016.2508816719, 'accumulated_eval_time': 11835.907625436783, 'accumulated_logging_time': 18.867294311523438}
I0304 02:14:53.615764 139881808373504 logging_writer.py:48] [293549] accumulated_eval_time=11835.907625, accumulated_logging_time=18.867294, accumulated_submission_time=129016.250882, global_step=293549, preemption_count=0, score=129016.250882, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=140886.344252, train/accuracy=0.888203, train/loss=0.414854, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 02:15:13.907006 139881799980800 logging_writer.py:48] [293600] global_step=293600, grad_norm=3.3446335792541504, loss=1.1578229665756226
I0304 02:15:57.034066 139881808373504 logging_writer.py:48] [293700] global_step=293700, grad_norm=3.9244821071624756, loss=3.1606674194335938
I0304 02:16:41.850249 139881799980800 logging_writer.py:48] [293800] global_step=293800, grad_norm=3.1694250106811523, loss=1.4366302490234375
I0304 02:17:26.504431 139881808373504 logging_writer.py:48] [293900] global_step=293900, grad_norm=3.176274538040161, loss=2.7213943004608154
I0304 02:18:11.011410 139881799980800 logging_writer.py:48] [294000] global_step=294000, grad_norm=3.043572425842285, loss=1.4682248830795288
I0304 02:18:55.305035 139881808373504 logging_writer.py:48] [294100] global_step=294100, grad_norm=3.6732981204986572, loss=1.556243896484375
I0304 02:19:39.849174 139881799980800 logging_writer.py:48] [294200] global_step=294200, grad_norm=2.9668262004852295, loss=1.471787691116333
I0304 02:20:24.564645 139881808373504 logging_writer.py:48] [294300] global_step=294300, grad_norm=3.1842751502990723, loss=2.62522029876709
I0304 02:21:09.249636 139881799980800 logging_writer.py:48] [294400] global_step=294400, grad_norm=3.153923511505127, loss=1.131284475326538
I0304 02:21:53.738965 139881808373504 logging_writer.py:48] [294500] global_step=294500, grad_norm=3.1653103828430176, loss=1.0834909677505493
I0304 02:21:53.753361 140077943854912 spec.py:321] Evaluating on the training split.
I0304 02:22:04.378381 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 02:22:29.976175 140077943854912 spec.py:349] Evaluating on the test split.
I0304 02:22:31.562429 140077943854912 submission_runner.py:411] Time since start: 141344.37s, 	Step: 294501, 	{'train/accuracy': 0.8893749713897705, 'train/loss': 0.41485342383384705, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 129436.32824611664, 'total_duration': 141344.36743688583, 'accumulated_submission_time': 129436.32824611664, 'accumulated_eval_time': 11873.716660499573, 'accumulated_logging_time': 18.954487562179565}
I0304 02:22:31.638963 139881799980800 logging_writer.py:48] [294501] accumulated_eval_time=11873.716660, accumulated_logging_time=18.954488, accumulated_submission_time=129436.328246, global_step=294501, preemption_count=0, score=129436.328246, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=141344.367437, train/accuracy=0.889375, train/loss=0.414853, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 02:23:12.432315 139881808373504 logging_writer.py:48] [294600] global_step=294600, grad_norm=3.2063605785369873, loss=1.1150202751159668
I0304 02:23:57.014283 139881799980800 logging_writer.py:48] [294700] global_step=294700, grad_norm=3.1666462421417236, loss=1.1776753664016724
I0304 02:24:41.524911 139881808373504 logging_writer.py:48] [294800] global_step=294800, grad_norm=3.008181095123291, loss=1.3924927711486816
I0304 02:25:26.045623 139881799980800 logging_writer.py:48] [294900] global_step=294900, grad_norm=3.055905818939209, loss=1.131311058998108
I0304 02:26:10.720621 139881808373504 logging_writer.py:48] [295000] global_step=295000, grad_norm=3.4364004135131836, loss=2.8953468799591064
I0304 02:26:55.437506 139881799980800 logging_writer.py:48] [295100] global_step=295100, grad_norm=2.965644359588623, loss=1.6862961053848267
I0304 02:27:39.895298 139881808373504 logging_writer.py:48] [295200] global_step=295200, grad_norm=3.3020031452178955, loss=1.112260103225708
I0304 02:28:24.482399 139881799980800 logging_writer.py:48] [295300] global_step=295300, grad_norm=3.30505108833313, loss=2.344289541244507
I0304 02:29:09.223016 139881808373504 logging_writer.py:48] [295400] global_step=295400, grad_norm=3.7231881618499756, loss=3.037642002105713
I0304 02:29:31.963449 140077943854912 spec.py:321] Evaluating on the training split.
I0304 02:29:42.490103 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 02:30:10.704187 140077943854912 spec.py:349] Evaluating on the test split.
I0304 02:30:12.297962 140077943854912 submission_runner.py:411] Time since start: 141805.10s, 	Step: 295453, 	{'train/accuracy': 0.88929682970047, 'train/loss': 0.4171392321586609, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 129856.59120893478, 'total_duration': 141805.1029598713, 'accumulated_submission_time': 129856.59120893478, 'accumulated_eval_time': 11914.05112528801, 'accumulated_logging_time': 19.04377579689026}
I0304 02:30:12.371977 139881799980800 logging_writer.py:48] [295453] accumulated_eval_time=11914.051125, accumulated_logging_time=19.043776, accumulated_submission_time=129856.591209, global_step=295453, preemption_count=0, score=129856.591209, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=141805.102960, train/accuracy=0.889297, train/loss=0.417139, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 02:30:31.090168 139881808373504 logging_writer.py:48] [295500] global_step=295500, grad_norm=3.08600115776062, loss=2.382328987121582
I0304 02:31:14.252974 139881799980800 logging_writer.py:48] [295600] global_step=295600, grad_norm=3.023610830307007, loss=1.0743541717529297
I0304 02:31:58.521957 139881808373504 logging_writer.py:48] [295700] global_step=295700, grad_norm=4.136632919311523, loss=3.284679889678955
I0304 02:32:43.129977 139881799980800 logging_writer.py:48] [295800] global_step=295800, grad_norm=3.151250123977661, loss=1.1597037315368652
I0304 02:33:27.631850 139881808373504 logging_writer.py:48] [295900] global_step=295900, grad_norm=3.5972845554351807, loss=1.1529204845428467
I0304 02:34:12.285290 139881799980800 logging_writer.py:48] [296000] global_step=296000, grad_norm=3.6420392990112305, loss=3.1007423400878906
I0304 02:34:56.479892 139881808373504 logging_writer.py:48] [296100] global_step=296100, grad_norm=3.381466865539551, loss=1.1214957237243652
I0304 02:35:40.772993 139881799980800 logging_writer.py:48] [296200] global_step=296200, grad_norm=3.23654842376709, loss=1.0823802947998047
I0304 02:36:25.432253 139881808373504 logging_writer.py:48] [296300] global_step=296300, grad_norm=3.0670595169067383, loss=1.0226494073867798
I0304 02:37:09.790067 139881799980800 logging_writer.py:48] [296400] global_step=296400, grad_norm=3.269351005554199, loss=1.319397211074829
I0304 02:37:12.635911 140077943854912 spec.py:321] Evaluating on the training split.
I0304 02:37:22.660510 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 02:37:58.558347 140077943854912 spec.py:349] Evaluating on the test split.
I0304 02:38:00.141512 140077943854912 submission_runner.py:411] Time since start: 142272.95s, 	Step: 296408, 	{'train/accuracy': 0.8854687213897705, 'train/loss': 0.4234060049057007, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 130276.79239630699, 'total_duration': 142272.9465227127, 'accumulated_submission_time': 130276.79239630699, 'accumulated_eval_time': 11961.55670619011, 'accumulated_logging_time': 19.131915807724}
I0304 02:38:00.201477 139881808373504 logging_writer.py:48] [296408] accumulated_eval_time=11961.556706, accumulated_logging_time=19.131916, accumulated_submission_time=130276.792396, global_step=296408, preemption_count=0, score=130276.792396, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=142272.946523, train/accuracy=0.885469, train/loss=0.423406, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 02:38:36.542459 139881799980800 logging_writer.py:48] [296500] global_step=296500, grad_norm=3.260479688644409, loss=1.1056084632873535
I0304 02:39:20.697415 139881808373504 logging_writer.py:48] [296600] global_step=296600, grad_norm=3.119274854660034, loss=1.1359199285507202
I0304 02:40:04.980650 139881799980800 logging_writer.py:48] [296700] global_step=296700, grad_norm=3.3866941928863525, loss=1.211869239807129
I0304 02:40:49.224233 139881808373504 logging_writer.py:48] [296800] global_step=296800, grad_norm=3.7766427993774414, loss=3.068725824356079
I0304 02:41:33.435529 139881799980800 logging_writer.py:48] [296900] global_step=296900, grad_norm=3.4093334674835205, loss=3.051542282104492
I0304 02:42:17.919237 139881808373504 logging_writer.py:48] [297000] global_step=297000, grad_norm=3.3060710430145264, loss=1.2365901470184326
I0304 02:43:01.940055 139881799980800 logging_writer.py:48] [297100] global_step=297100, grad_norm=3.1770105361938477, loss=1.5626955032348633
I0304 02:43:46.216205 139881808373504 logging_writer.py:48] [297200] global_step=297200, grad_norm=3.4805843830108643, loss=1.107006549835205
I0304 02:44:30.625779 139881799980800 logging_writer.py:48] [297300] global_step=297300, grad_norm=3.546138286590576, loss=3.2201929092407227
I0304 02:45:00.236892 140077943854912 spec.py:321] Evaluating on the training split.
I0304 02:45:10.380560 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 02:45:44.356838 140077943854912 spec.py:349] Evaluating on the test split.
I0304 02:45:45.944630 140077943854912 submission_runner.py:411] Time since start: 142738.75s, 	Step: 297369, 	{'train/accuracy': 0.8866601586341858, 'train/loss': 0.4202454388141632, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 130696.7673239708, 'total_duration': 142738.7496433258, 'accumulated_submission_time': 130696.7673239708, 'accumulated_eval_time': 12007.264422655106, 'accumulated_logging_time': 19.20346760749817}
I0304 02:45:46.013081 139881808373504 logging_writer.py:48] [297369] accumulated_eval_time=12007.264423, accumulated_logging_time=19.203468, accumulated_submission_time=130696.767324, global_step=297369, preemption_count=0, score=130696.767324, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=142738.749643, train/accuracy=0.886660, train/loss=0.420245, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 02:45:58.489167 139881799980800 logging_writer.py:48] [297400] global_step=297400, grad_norm=3.7038958072662354, loss=3.171121597290039
I0304 02:46:40.025436 139881808373504 logging_writer.py:48] [297500] global_step=297500, grad_norm=3.3363189697265625, loss=1.153470516204834
I0304 02:47:24.141147 139881799980800 logging_writer.py:48] [297600] global_step=297600, grad_norm=3.164374589920044, loss=1.1423925161361694
I0304 02:48:08.805616 139881808373504 logging_writer.py:48] [297700] global_step=297700, grad_norm=2.7846524715423584, loss=1.974289894104004
I0304 02:48:53.057123 139881799980800 logging_writer.py:48] [297800] global_step=297800, grad_norm=3.229259729385376, loss=1.7762906551361084
I0304 02:49:37.384178 139881808373504 logging_writer.py:48] [297900] global_step=297900, grad_norm=3.7801361083984375, loss=1.161769151687622
I0304 02:50:21.838600 139881799980800 logging_writer.py:48] [298000] global_step=298000, grad_norm=2.9139299392700195, loss=1.7974209785461426
I0304 02:51:06.100584 139881808373504 logging_writer.py:48] [298100] global_step=298100, grad_norm=3.189242124557495, loss=1.5991536378860474
I0304 02:51:50.245418 139881799980800 logging_writer.py:48] [298200] global_step=298200, grad_norm=3.224533796310425, loss=2.7956037521362305
I0304 02:52:34.605319 139881808373504 logging_writer.py:48] [298300] global_step=298300, grad_norm=3.0947136878967285, loss=1.0736674070358276
I0304 02:52:46.224056 140077943854912 spec.py:321] Evaluating on the training split.
I0304 02:52:56.695383 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 02:53:29.859307 140077943854912 spec.py:349] Evaluating on the test split.
I0304 02:53:31.443336 140077943854912 submission_runner.py:411] Time since start: 143204.25s, 	Step: 298328, 	{'train/accuracy': 0.8893163800239563, 'train/loss': 0.41478225588798523, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 131116.9161388874, 'total_duration': 143204.24835014343, 'accumulated_submission_time': 131116.9161388874, 'accumulated_eval_time': 12052.48368382454, 'accumulated_logging_time': 19.283127307891846}
I0304 02:53:31.505803 139881799980800 logging_writer.py:48] [298328] accumulated_eval_time=12052.483684, accumulated_logging_time=19.283127, accumulated_submission_time=131116.916139, global_step=298328, preemption_count=0, score=131116.916139, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=143204.248350, train/accuracy=0.889316, train/loss=0.414782, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 02:53:59.976855 139881808373504 logging_writer.py:48] [298400] global_step=298400, grad_norm=5.357099533081055, loss=2.6278767585754395
I0304 02:54:43.640662 139881799980800 logging_writer.py:48] [298500] global_step=298500, grad_norm=3.102219820022583, loss=1.0940287113189697
I0304 02:55:28.243438 139881808373504 logging_writer.py:48] [298600] global_step=298600, grad_norm=3.03301739692688, loss=1.095134973526001
I0304 02:56:13.007845 139881799980800 logging_writer.py:48] [298700] global_step=298700, grad_norm=3.3840749263763428, loss=1.45737886428833
I0304 02:56:57.452190 139881808373504 logging_writer.py:48] [298800] global_step=298800, grad_norm=2.8882837295532227, loss=1.0488128662109375
I0304 02:57:42.045669 139881799980800 logging_writer.py:48] [298900] global_step=298900, grad_norm=3.159290075302124, loss=1.138753056526184
I0304 02:58:26.648131 139881808373504 logging_writer.py:48] [299000] global_step=299000, grad_norm=3.311307430267334, loss=2.3266196250915527
I0304 02:59:11.106902 139881799980800 logging_writer.py:48] [299100] global_step=299100, grad_norm=3.1708877086639404, loss=2.691634178161621
I0304 02:59:55.823275 139881808373504 logging_writer.py:48] [299200] global_step=299200, grad_norm=2.9726481437683105, loss=1.1993917226791382
I0304 03:00:31.793072 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:00:42.141329 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:01:08.845728 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:01:10.439621 140077943854912 submission_runner.py:411] Time since start: 143663.24s, 	Step: 299282, 	{'train/accuracy': 0.8881054520606995, 'train/loss': 0.4154012203216553, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 131537.1429643631, 'total_duration': 143663.2446167469, 'accumulated_submission_time': 131537.1429643631, 'accumulated_eval_time': 12091.130192756653, 'accumulated_logging_time': 19.356364011764526}
I0304 03:01:10.516136 139881799980800 logging_writer.py:48] [299282] accumulated_eval_time=12091.130193, accumulated_logging_time=19.356364, accumulated_submission_time=131537.142964, global_step=299282, preemption_count=0, score=131537.142964, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=143663.244617, train/accuracy=0.888105, train/loss=0.415401, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:01:17.927370 139881808373504 logging_writer.py:48] [299300] global_step=299300, grad_norm=3.2493669986724854, loss=1.2203119993209839
I0304 03:02:00.248141 139881799980800 logging_writer.py:48] [299400] global_step=299400, grad_norm=3.1159658432006836, loss=2.918761968612671
I0304 03:02:45.006697 139881808373504 logging_writer.py:48] [299500] global_step=299500, grad_norm=3.3108277320861816, loss=1.0590035915374756
I0304 03:03:30.036891 139881799980800 logging_writer.py:48] [299600] global_step=299600, grad_norm=2.9322123527526855, loss=1.7371402978897095
I0304 03:04:14.758306 139881808373504 logging_writer.py:48] [299700] global_step=299700, grad_norm=3.0934693813323975, loss=1.0926839113235474
I0304 03:04:59.589789 139881799980800 logging_writer.py:48] [299800] global_step=299800, grad_norm=3.1299073696136475, loss=2.4721505641937256
I0304 03:05:44.557400 139881808373504 logging_writer.py:48] [299900] global_step=299900, grad_norm=3.095221519470215, loss=1.5053986310958862
I0304 03:06:29.783432 139881799980800 logging_writer.py:48] [300000] global_step=300000, grad_norm=3.0995848178863525, loss=1.1415640115737915
I0304 03:07:15.057175 139881808373504 logging_writer.py:48] [300100] global_step=300100, grad_norm=3.2940638065338135, loss=1.1819077730178833
I0304 03:07:59.772040 139881799980800 logging_writer.py:48] [300200] global_step=300200, grad_norm=3.5684549808502197, loss=1.2177859544754028
I0304 03:08:10.792222 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:08:21.296365 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:08:46.132336 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:08:47.715237 140077943854912 submission_runner.py:411] Time since start: 144120.52s, 	Step: 300226, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.41987326741218567, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 131957.35796141624, 'total_duration': 144120.52024149895, 'accumulated_submission_time': 131957.35796141624, 'accumulated_eval_time': 12128.053198814392, 'accumulated_logging_time': 19.444679021835327}
I0304 03:08:47.789360 139881808373504 logging_writer.py:48] [300226] accumulated_eval_time=12128.053199, accumulated_logging_time=19.444679, accumulated_submission_time=131957.357961, global_step=300226, preemption_count=0, score=131957.357961, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=144120.520241, train/accuracy=0.887676, train/loss=0.419873, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:09:17.492245 139881799980800 logging_writer.py:48] [300300] global_step=300300, grad_norm=3.685948371887207, loss=1.573744773864746
I0304 03:10:01.800107 139881808373504 logging_writer.py:48] [300400] global_step=300400, grad_norm=3.055128335952759, loss=1.1372932195663452
I0304 03:10:46.592837 139881799980800 logging_writer.py:48] [300500] global_step=300500, grad_norm=4.307096481323242, loss=3.2527060508728027
I0304 03:11:31.301048 139881808373504 logging_writer.py:48] [300600] global_step=300600, grad_norm=3.1395599842071533, loss=1.6505839824676514
I0304 03:12:15.684101 139881799980800 logging_writer.py:48] [300700] global_step=300700, grad_norm=3.223223924636841, loss=1.5632833242416382
I0304 03:13:00.150154 139881808373504 logging_writer.py:48] [300800] global_step=300800, grad_norm=3.604871988296509, loss=2.987360715866089
I0304 03:13:44.612440 139881799980800 logging_writer.py:48] [300900] global_step=300900, grad_norm=3.1945714950561523, loss=1.146337866783142
I0304 03:14:29.150587 139881808373504 logging_writer.py:48] [301000] global_step=301000, grad_norm=3.2002933025360107, loss=1.5604547262191772
I0304 03:15:13.592141 139881799980800 logging_writer.py:48] [301100] global_step=301100, grad_norm=3.039248466491699, loss=1.0387601852416992
I0304 03:15:48.034169 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:15:57.802253 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:16:27.902038 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:16:29.492281 140077943854912 submission_runner.py:411] Time since start: 144582.30s, 	Step: 301179, 	{'train/accuracy': 0.88636714220047, 'train/loss': 0.4219211935997009, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 132377.5421822071, 'total_duration': 144582.29728770256, 'accumulated_submission_time': 132377.5421822071, 'accumulated_eval_time': 12169.511289596558, 'accumulated_logging_time': 19.53000783920288}
I0304 03:16:29.568848 139881808373504 logging_writer.py:48] [301179] accumulated_eval_time=12169.511290, accumulated_logging_time=19.530008, accumulated_submission_time=132377.542182, global_step=301179, preemption_count=0, score=132377.542182, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=144582.297288, train/accuracy=0.886367, train/loss=0.421921, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:16:38.141535 139881799980800 logging_writer.py:48] [301200] global_step=301200, grad_norm=4.7979254722595215, loss=1.2363152503967285
I0304 03:17:20.041530 139881808373504 logging_writer.py:48] [301300] global_step=301300, grad_norm=3.073507785797119, loss=2.223829746246338
I0304 03:18:04.414979 139881799980800 logging_writer.py:48] [301400] global_step=301400, grad_norm=3.389889717102051, loss=1.6542558670043945
I0304 03:18:48.930467 139881808373504 logging_writer.py:48] [301500] global_step=301500, grad_norm=3.009596586227417, loss=1.156275987625122
I0304 03:19:33.615813 139881799980800 logging_writer.py:48] [301600] global_step=301600, grad_norm=3.9392940998077393, loss=3.2030043601989746
I0304 03:20:17.986116 139881808373504 logging_writer.py:48] [301700] global_step=301700, grad_norm=2.9873416423797607, loss=1.7831262350082397
I0304 03:21:02.372014 139881799980800 logging_writer.py:48] [301800] global_step=301800, grad_norm=3.146813154220581, loss=1.900515079498291
I0304 03:21:46.959817 139881808373504 logging_writer.py:48] [301900] global_step=301900, grad_norm=2.949049472808838, loss=1.8249262571334839
I0304 03:22:31.625094 139881799980800 logging_writer.py:48] [302000] global_step=302000, grad_norm=3.4840087890625, loss=1.185755968093872
I0304 03:23:16.144148 139881808373504 logging_writer.py:48] [302100] global_step=302100, grad_norm=3.165111541748047, loss=1.3835597038269043
I0304 03:23:29.556649 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:23:39.633426 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:24:06.208488 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:24:07.800660 140077943854912 submission_runner.py:411] Time since start: 145040.61s, 	Step: 302132, 	{'train/accuracy': 0.8879687190055847, 'train/loss': 0.41664552688598633, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 132797.46908450127, 'total_duration': 145040.6056535244, 'accumulated_submission_time': 132797.46908450127, 'accumulated_eval_time': 12207.755256175995, 'accumulated_logging_time': 19.618409633636475}
I0304 03:24:07.885346 139881799980800 logging_writer.py:48] [302132] accumulated_eval_time=12207.755256, accumulated_logging_time=19.618410, accumulated_submission_time=132797.469085, global_step=302132, preemption_count=0, score=132797.469085, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=145040.605654, train/accuracy=0.887969, train/loss=0.416646, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:24:34.907417 139881808373504 logging_writer.py:48] [302200] global_step=302200, grad_norm=3.5494730472564697, loss=2.570460557937622
I0304 03:25:19.089421 139881799980800 logging_writer.py:48] [302300] global_step=302300, grad_norm=3.1090993881225586, loss=1.1124073266983032
I0304 03:26:03.782099 139881808373504 logging_writer.py:48] [302400] global_step=302400, grad_norm=2.8748443126678467, loss=1.5317776203155518
I0304 03:26:48.190942 139881799980800 logging_writer.py:48] [302500] global_step=302500, grad_norm=3.364217758178711, loss=1.3927013874053955
I0304 03:27:32.480314 139881808373504 logging_writer.py:48] [302600] global_step=302600, grad_norm=2.850226879119873, loss=1.3470253944396973
I0304 03:28:16.831940 139881799980800 logging_writer.py:48] [302700] global_step=302700, grad_norm=3.2852249145507812, loss=1.148811936378479
I0304 03:29:01.400924 139881808373504 logging_writer.py:48] [302800] global_step=302800, grad_norm=3.269521474838257, loss=1.4331704378128052
I0304 03:29:45.882406 139881799980800 logging_writer.py:48] [302900] global_step=302900, grad_norm=2.9070072174072266, loss=1.3560690879821777
I0304 03:30:30.263540 139881808373504 logging_writer.py:48] [303000] global_step=303000, grad_norm=3.124042272567749, loss=2.4989945888519287
I0304 03:31:08.237029 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:31:18.644022 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:31:50.434392 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:31:52.023739 140077943854912 submission_runner.py:411] Time since start: 145504.83s, 	Step: 303087, 	{'train/accuracy': 0.8862499594688416, 'train/loss': 0.41859519481658936, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 133217.7573838234, 'total_duration': 145504.82874035835, 'accumulated_submission_time': 133217.7573838234, 'accumulated_eval_time': 12251.54194355011, 'accumulated_logging_time': 19.716617345809937}
I0304 03:31:52.099272 139881799980800 logging_writer.py:48] [303087] accumulated_eval_time=12251.541944, accumulated_logging_time=19.716617, accumulated_submission_time=133217.757384, global_step=303087, preemption_count=0, score=133217.757384, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=145504.828740, train/accuracy=0.886250, train/loss=0.418595, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:31:57.567753 139881808373504 logging_writer.py:48] [303100] global_step=303100, grad_norm=3.089879274368286, loss=1.1391150951385498
I0304 03:32:37.772475 139881799980800 logging_writer.py:48] [303200] global_step=303200, grad_norm=3.8265130519866943, loss=3.3288331031799316
I0304 03:33:21.943655 139881808373504 logging_writer.py:48] [303300] global_step=303300, grad_norm=3.0925791263580322, loss=1.861207365989685
I0304 03:34:06.760462 139881799980800 logging_writer.py:48] [303400] global_step=303400, grad_norm=3.0396902561187744, loss=1.1404677629470825
I0304 03:34:51.048139 139881808373504 logging_writer.py:48] [303500] global_step=303500, grad_norm=3.599365234375, loss=3.2223398685455322
I0304 03:35:35.470458 139881799980800 logging_writer.py:48] [303600] global_step=303600, grad_norm=3.8006083965301514, loss=2.404646873474121
I0304 03:36:19.998575 139881808373504 logging_writer.py:48] [303700] global_step=303700, grad_norm=3.0332188606262207, loss=2.4155375957489014
I0304 03:37:04.401146 139881799980800 logging_writer.py:48] [303800] global_step=303800, grad_norm=3.2353405952453613, loss=1.2694356441497803
I0304 03:37:48.574430 139881808373504 logging_writer.py:48] [303900] global_step=303900, grad_norm=3.07795786857605, loss=1.7775497436523438
I0304 03:38:32.722622 139881799980800 logging_writer.py:48] [304000] global_step=304000, grad_norm=3.01315975189209, loss=1.169594407081604
I0304 03:38:52.187705 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:39:02.448615 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:39:29.499743 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:39:31.085633 140077943854912 submission_runner.py:411] Time since start: 145963.89s, 	Step: 304045, 	{'train/accuracy': 0.8896093368530273, 'train/loss': 0.4145287573337555, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 133637.78238511086, 'total_duration': 145963.89064216614, 'accumulated_submission_time': 133637.78238511086, 'accumulated_eval_time': 12290.439830303192, 'accumulated_logging_time': 19.80525302886963}
I0304 03:39:31.162119 139881808373504 logging_writer.py:48] [304045] accumulated_eval_time=12290.439830, accumulated_logging_time=19.805253, accumulated_submission_time=133637.782385, global_step=304045, preemption_count=0, score=133637.782385, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=145963.890642, train/accuracy=0.889609, train/loss=0.414529, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:39:53.015586 139881799980800 logging_writer.py:48] [304100] global_step=304100, grad_norm=3.2642781734466553, loss=1.0922120809555054
I0304 03:40:36.194095 139881808373504 logging_writer.py:48] [304200] global_step=304200, grad_norm=3.8370306491851807, loss=3.3076486587524414
I0304 03:41:20.843102 139881799980800 logging_writer.py:48] [304300] global_step=304300, grad_norm=4.4889326095581055, loss=3.308436632156372
I0304 03:42:05.701922 139881808373504 logging_writer.py:48] [304400] global_step=304400, grad_norm=2.9149060249328613, loss=1.1453336477279663
I0304 03:42:50.079898 139881799980800 logging_writer.py:48] [304500] global_step=304500, grad_norm=3.0064399242401123, loss=1.2702527046203613
I0304 03:43:34.860211 139881808373504 logging_writer.py:48] [304600] global_step=304600, grad_norm=3.4992282390594482, loss=1.1679867506027222
I0304 03:44:19.132878 139881799980800 logging_writer.py:48] [304700] global_step=304700, grad_norm=3.346216917037964, loss=1.10856294631958
I0304 03:45:03.578734 139881808373504 logging_writer.py:48] [304800] global_step=304800, grad_norm=3.216858386993408, loss=1.3630526065826416
I0304 03:45:47.909587 139881799980800 logging_writer.py:48] [304900] global_step=304900, grad_norm=3.233654022216797, loss=1.326625108718872
I0304 03:46:31.500191 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:46:42.175164 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:47:10.323850 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:47:11.903750 140077943854912 submission_runner.py:411] Time since start: 146424.71s, 	Step: 305000, 	{'train/accuracy': 0.8884570002555847, 'train/loss': 0.4126504063606262, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 134058.0566318035, 'total_duration': 146424.70875573158, 'accumulated_submission_time': 134058.0566318035, 'accumulated_eval_time': 12330.843381643295, 'accumulated_logging_time': 19.895825386047363}
I0304 03:47:11.979802 139881808373504 logging_writer.py:48] [305000] accumulated_eval_time=12330.843382, accumulated_logging_time=19.895825, accumulated_submission_time=134058.056632, global_step=305000, preemption_count=0, score=134058.056632, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=146424.708756, train/accuracy=0.888457, train/loss=0.412650, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:47:12.384751 139881799980800 logging_writer.py:48] [305000] global_step=305000, grad_norm=3.5172016620635986, loss=2.0215814113616943
I0304 03:47:53.073833 139881808373504 logging_writer.py:48] [305100] global_step=305100, grad_norm=3.142598867416382, loss=1.1335543394088745
I0304 03:48:37.193775 139881799980800 logging_writer.py:48] [305200] global_step=305200, grad_norm=3.0725505352020264, loss=1.6649898290634155
I0304 03:49:21.948730 139881808373504 logging_writer.py:48] [305300] global_step=305300, grad_norm=3.1113054752349854, loss=1.4429675340652466
I0304 03:50:06.739156 139881799980800 logging_writer.py:48] [305400] global_step=305400, grad_norm=2.881335973739624, loss=1.0629361867904663
I0304 03:50:50.948690 139881808373504 logging_writer.py:48] [305500] global_step=305500, grad_norm=2.974331855773926, loss=1.4025108814239502
I0304 03:51:35.271767 139881799980800 logging_writer.py:48] [305600] global_step=305600, grad_norm=3.1082186698913574, loss=1.2624704837799072
I0304 03:52:19.605457 139881808373504 logging_writer.py:48] [305700] global_step=305700, grad_norm=2.7813408374786377, loss=1.2980482578277588
I0304 03:53:04.331613 139881799980800 logging_writer.py:48] [305800] global_step=305800, grad_norm=3.0039851665496826, loss=1.52286696434021
I0304 03:53:48.644739 139881808373504 logging_writer.py:48] [305900] global_step=305900, grad_norm=3.995445489883423, loss=3.2540252208709717
I0304 03:54:12.250629 140077943854912 spec.py:321] Evaluating on the training split.
I0304 03:54:22.435854 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 03:54:56.595193 140077943854912 spec.py:349] Evaluating on the test split.
I0304 03:54:58.183756 140077943854912 submission_runner.py:411] Time since start: 146890.99s, 	Step: 305955, 	{'train/accuracy': 0.88783198595047, 'train/loss': 0.42415672540664673, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 134478.2640724182, 'total_duration': 146890.98871064186, 'accumulated_submission_time': 134478.2640724182, 'accumulated_eval_time': 12376.776423931122, 'accumulated_logging_time': 19.98555564880371}
I0304 03:54:58.262322 139881799980800 logging_writer.py:48] [305955] accumulated_eval_time=12376.776424, accumulated_logging_time=19.985556, accumulated_submission_time=134478.264072, global_step=305955, preemption_count=0, score=134478.264072, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=146890.988711, train/accuracy=0.887832, train/loss=0.424157, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 03:55:16.200623 139881808373504 logging_writer.py:48] [306000] global_step=306000, grad_norm=3.2598042488098145, loss=1.2270526885986328
I0304 03:55:58.096839 139881799980800 logging_writer.py:48] [306100] global_step=306100, grad_norm=3.1292777061462402, loss=2.19252610206604
I0304 03:56:42.550268 139881808373504 logging_writer.py:48] [306200] global_step=306200, grad_norm=3.0938358306884766, loss=1.1837373971939087
I0304 03:57:27.269800 139881799980800 logging_writer.py:48] [306300] global_step=306300, grad_norm=3.208616256713867, loss=1.1119905710220337
I0304 03:58:11.597829 139881808373504 logging_writer.py:48] [306400] global_step=306400, grad_norm=3.05405855178833, loss=1.6595678329467773
I0304 03:58:56.072797 139881799980800 logging_writer.py:48] [306500] global_step=306500, grad_norm=3.376868486404419, loss=1.0417656898498535
I0304 03:59:40.718766 139881808373504 logging_writer.py:48] [306600] global_step=306600, grad_norm=3.2753403186798096, loss=1.0573105812072754
I0304 04:00:25.079666 139881799980800 logging_writer.py:48] [306700] global_step=306700, grad_norm=3.3441686630249023, loss=1.278299331665039
I0304 04:01:09.469614 139881808373504 logging_writer.py:48] [306800] global_step=306800, grad_norm=3.7422327995300293, loss=3.189157724380493
I0304 04:01:53.700291 139881799980800 logging_writer.py:48] [306900] global_step=306900, grad_norm=3.055788993835449, loss=2.3392698764801025
I0304 04:01:58.190736 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:02:08.653001 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:02:34.502131 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:02:36.090741 140077943854912 submission_runner.py:411] Time since start: 147348.90s, 	Step: 306912, 	{'train/accuracy': 0.8887695074081421, 'train/loss': 0.4157889485359192, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 134898.1319179535, 'total_duration': 147348.89574956894, 'accumulated_submission_time': 134898.1319179535, 'accumulated_eval_time': 12414.676441431046, 'accumulated_logging_time': 20.075188636779785}
I0304 04:02:36.174270 139881808373504 logging_writer.py:48] [306912] accumulated_eval_time=12414.676441, accumulated_logging_time=20.075189, accumulated_submission_time=134898.131918, global_step=306912, preemption_count=0, score=134898.131918, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=147348.895750, train/accuracy=0.888770, train/loss=0.415789, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:03:12.093317 139881799980800 logging_writer.py:48] [307000] global_step=307000, grad_norm=5.057618141174316, loss=3.201977491378784
I0304 04:03:56.115453 139881808373504 logging_writer.py:48] [307100] global_step=307100, grad_norm=3.0251007080078125, loss=1.1098769903182983
I0304 04:04:40.597943 139881799980800 logging_writer.py:48] [307200] global_step=307200, grad_norm=3.1648411750793457, loss=1.1483376026153564
I0304 04:05:24.823378 139881808373504 logging_writer.py:48] [307300] global_step=307300, grad_norm=3.2078351974487305, loss=2.595097780227661
I0304 04:06:09.487056 139881799980800 logging_writer.py:48] [307400] global_step=307400, grad_norm=2.867771863937378, loss=2.2358908653259277
I0304 04:06:53.894042 139881808373504 logging_writer.py:48] [307500] global_step=307500, grad_norm=3.1433112621307373, loss=2.0856549739837646
I0304 04:07:38.407387 139881799980800 logging_writer.py:48] [307600] global_step=307600, grad_norm=3.1527249813079834, loss=2.046419620513916
I0304 04:08:22.727716 139881808373504 logging_writer.py:48] [307700] global_step=307700, grad_norm=3.064779758453369, loss=1.5756539106369019
I0304 04:09:07.401171 139881799980800 logging_writer.py:48] [307800] global_step=307800, grad_norm=3.7145652770996094, loss=3.230564594268799
I0304 04:09:36.231863 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:09:46.780413 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:10:13.667012 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:10:15.286950 140077943854912 submission_runner.py:411] Time since start: 147808.09s, 	Step: 307867, 	{'train/accuracy': 0.8900195360183716, 'train/loss': 0.4082540273666382, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 135318.12880396843, 'total_duration': 147808.09196567535, 'accumulated_submission_time': 135318.12880396843, 'accumulated_eval_time': 12453.731521844864, 'accumulated_logging_time': 20.169724941253662}
I0304 04:10:15.349394 139881808373504 logging_writer.py:48] [307867] accumulated_eval_time=12453.731522, accumulated_logging_time=20.169725, accumulated_submission_time=135318.128804, global_step=307867, preemption_count=0, score=135318.128804, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=147808.091966, train/accuracy=0.890020, train/loss=0.408254, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:10:28.602053 139881799980800 logging_writer.py:48] [307900] global_step=307900, grad_norm=3.0317840576171875, loss=1.8566020727157593
I0304 04:11:10.241494 139881808373504 logging_writer.py:48] [308000] global_step=308000, grad_norm=3.026191234588623, loss=2.147963047027588
I0304 04:11:54.475475 139881799980800 logging_writer.py:48] [308100] global_step=308100, grad_norm=3.029204845428467, loss=1.4453821182250977
I0304 04:12:39.195056 139881808373504 logging_writer.py:48] [308200] global_step=308200, grad_norm=2.8822855949401855, loss=2.0185632705688477
I0304 04:13:23.472361 139881799980800 logging_writer.py:48] [308300] global_step=308300, grad_norm=3.0480594635009766, loss=2.2493326663970947
I0304 04:14:08.084193 139881808373504 logging_writer.py:48] [308400] global_step=308400, grad_norm=3.0774035453796387, loss=1.6627368927001953
I0304 04:14:52.230352 139881799980800 logging_writer.py:48] [308500] global_step=308500, grad_norm=3.090695381164551, loss=1.256393313407898
I0304 04:15:36.416676 139881808373504 logging_writer.py:48] [308600] global_step=308600, grad_norm=2.8525896072387695, loss=1.1339495182037354
I0304 04:16:20.992627 139881799980800 logging_writer.py:48] [308700] global_step=308700, grad_norm=3.3900089263916016, loss=2.910546064376831
I0304 04:17:05.643054 139881808373504 logging_writer.py:48] [308800] global_step=308800, grad_norm=3.301262855529785, loss=1.1226707696914673
I0304 04:17:15.397516 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:17:25.597539 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:17:50.215455 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:17:51.817127 140077943854912 submission_runner.py:411] Time since start: 148264.62s, 	Step: 308824, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.41900309920310974, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 135738.11697626114, 'total_duration': 148264.62213468552, 'accumulated_submission_time': 135738.11697626114, 'accumulated_eval_time': 12490.151092767715, 'accumulated_logging_time': 20.24302864074707}
I0304 04:17:51.894030 139881799980800 logging_writer.py:48] [308824] accumulated_eval_time=12490.151093, accumulated_logging_time=20.243029, accumulated_submission_time=135738.116976, global_step=308824, preemption_count=0, score=135738.116976, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=148264.622135, train/accuracy=0.887734, train/loss=0.419003, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:18:22.629587 139881808373504 logging_writer.py:48] [308900] global_step=308900, grad_norm=2.983125686645508, loss=1.5156210660934448
I0304 04:19:07.143146 139881799980800 logging_writer.py:48] [309000] global_step=309000, grad_norm=2.971468687057495, loss=1.201066017150879
I0304 04:19:51.628261 139881808373504 logging_writer.py:48] [309100] global_step=309100, grad_norm=2.8584513664245605, loss=1.8433493375778198
I0304 04:20:36.033885 139881799980800 logging_writer.py:48] [309200] global_step=309200, grad_norm=3.4082608222961426, loss=1.2317850589752197
I0304 04:21:20.558147 139881808373504 logging_writer.py:48] [309300] global_step=309300, grad_norm=3.4407875537872314, loss=1.0966678857803345
I0304 04:22:04.969884 139881799980800 logging_writer.py:48] [309400] global_step=309400, grad_norm=3.092806577682495, loss=2.579683303833008
I0304 04:22:49.383208 139881808373504 logging_writer.py:48] [309500] global_step=309500, grad_norm=3.12684965133667, loss=1.1691418886184692
I0304 04:23:33.845215 139881799980800 logging_writer.py:48] [309600] global_step=309600, grad_norm=3.109440326690674, loss=2.558452606201172
I0304 04:24:18.386673 139881808373504 logging_writer.py:48] [309700] global_step=309700, grad_norm=3.242583751678467, loss=2.8016433715820312
I0304 04:24:51.865918 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:25:02.865114 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:25:34.640097 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:25:36.223483 140077943854912 submission_runner.py:411] Time since start: 148729.03s, 	Step: 309777, 	{'train/accuracy': 0.8886523246765137, 'train/loss': 0.4138353765010834, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 136158.0286180973, 'total_duration': 148729.02848935127, 'accumulated_submission_time': 136158.0286180973, 'accumulated_eval_time': 12534.50862789154, 'accumulated_logging_time': 20.331170082092285}
I0304 04:25:36.308525 139881799980800 logging_writer.py:48] [309777] accumulated_eval_time=12534.508628, accumulated_logging_time=20.331170, accumulated_submission_time=136158.028618, global_step=309777, preemption_count=0, score=136158.028618, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=148729.028489, train/accuracy=0.888652, train/loss=0.413835, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:25:45.661673 139881808373504 logging_writer.py:48] [309800] global_step=309800, grad_norm=3.075083017349243, loss=2.496453285217285
I0304 04:26:27.147637 139881799980800 logging_writer.py:48] [309900] global_step=309900, grad_norm=3.450470209121704, loss=1.2314374446868896
I0304 04:27:11.608542 139881808373504 logging_writer.py:48] [310000] global_step=310000, grad_norm=2.9909167289733887, loss=1.76022207736969
I0304 04:27:56.436556 139881799980800 logging_writer.py:48] [310100] global_step=310100, grad_norm=3.715388774871826, loss=1.1469097137451172
I0304 04:28:40.892254 139881808373504 logging_writer.py:48] [310200] global_step=310200, grad_norm=3.0587613582611084, loss=1.139601469039917
I0304 04:29:25.408492 139881799980800 logging_writer.py:48] [310300] global_step=310300, grad_norm=3.049813985824585, loss=2.0367932319641113
I0304 04:30:09.910410 139881808373504 logging_writer.py:48] [310400] global_step=310400, grad_norm=3.0169224739074707, loss=1.7829129695892334
I0304 04:30:54.205875 139881799980800 logging_writer.py:48] [310500] global_step=310500, grad_norm=3.156283140182495, loss=1.6012572050094604
I0304 04:31:38.889297 139881808373504 logging_writer.py:48] [310600] global_step=310600, grad_norm=3.182084321975708, loss=1.5353840589523315
I0304 04:32:23.306130 139881799980800 logging_writer.py:48] [310700] global_step=310700, grad_norm=3.116013288497925, loss=1.1958009004592896
I0304 04:32:36.279827 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:32:46.221607 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:33:11.507452 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:33:13.089705 140077943854912 submission_runner.py:411] Time since start: 149185.89s, 	Step: 310731, 	{'train/accuracy': 0.8862695097923279, 'train/loss': 0.4201231002807617, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 136577.9388947487, 'total_duration': 149185.8946583271, 'accumulated_submission_time': 136577.9388947487, 'accumulated_eval_time': 12571.31841301918, 'accumulated_logging_time': 20.42776656150818}
I0304 04:33:13.179239 139881808373504 logging_writer.py:48] [310731] accumulated_eval_time=12571.318413, accumulated_logging_time=20.427767, accumulated_submission_time=136577.938895, global_step=310731, preemption_count=0, score=136577.938895, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=149185.894658, train/accuracy=0.886270, train/loss=0.420123, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:33:40.755091 139881799980800 logging_writer.py:48] [310800] global_step=310800, grad_norm=3.252283811569214, loss=1.735501766204834
I0304 04:34:24.818300 139881808373504 logging_writer.py:48] [310900] global_step=310900, grad_norm=3.0538344383239746, loss=1.0582857131958008
I0304 04:35:09.450381 139881799980800 logging_writer.py:48] [311000] global_step=311000, grad_norm=3.466449737548828, loss=1.6595712900161743
I0304 04:35:53.801049 139881808373504 logging_writer.py:48] [311100] global_step=311100, grad_norm=3.271730899810791, loss=2.6605968475341797
I0304 04:36:38.487080 139881799980800 logging_writer.py:48] [311200] global_step=311200, grad_norm=3.4336674213409424, loss=2.8952267169952393
I0304 04:37:23.002577 139881808373504 logging_writer.py:48] [311300] global_step=311300, grad_norm=3.025300979614258, loss=1.0455050468444824
I0304 04:38:07.505676 139881799980800 logging_writer.py:48] [311400] global_step=311400, grad_norm=3.0337772369384766, loss=1.131543517112732
I0304 04:38:51.762326 139881808373504 logging_writer.py:48] [311500] global_step=311500, grad_norm=3.126039505004883, loss=1.2499092817306519
I0304 04:39:36.428191 139881799980800 logging_writer.py:48] [311600] global_step=311600, grad_norm=3.052471876144409, loss=1.136455774307251
I0304 04:40:13.178672 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:40:23.371336 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:40:49.930144 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:40:51.514434 140077943854912 submission_runner.py:411] Time since start: 149644.32s, 	Step: 311684, 	{'train/accuracy': 0.8872851133346558, 'train/loss': 0.4167616665363312, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 136997.87422275543, 'total_duration': 149644.31943631172, 'accumulated_submission_time': 136997.87422275543, 'accumulated_eval_time': 12609.654133558273, 'accumulated_logging_time': 20.53228735923767}
I0304 04:40:51.590645 139881808373504 logging_writer.py:48] [311684] accumulated_eval_time=12609.654134, accumulated_logging_time=20.532287, accumulated_submission_time=136997.874223, global_step=311684, preemption_count=0, score=136997.874223, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=149644.319436, train/accuracy=0.887285, train/loss=0.416762, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:40:58.255146 139881799980800 logging_writer.py:48] [311700] global_step=311700, grad_norm=3.0834901332855225, loss=2.084681987762451
I0304 04:41:39.922985 139881808373504 logging_writer.py:48] [311800] global_step=311800, grad_norm=3.193448305130005, loss=1.1439886093139648
I0304 04:42:24.495486 139881799980800 logging_writer.py:48] [311900] global_step=311900, grad_norm=3.4902102947235107, loss=2.866786479949951
I0304 04:43:09.046022 139881808373504 logging_writer.py:48] [312000] global_step=312000, grad_norm=2.8643877506256104, loss=1.1443274021148682
I0304 04:43:53.045060 139881799980800 logging_writer.py:48] [312100] global_step=312100, grad_norm=3.3082754611968994, loss=2.891113758087158
I0304 04:44:37.591867 139881808373504 logging_writer.py:48] [312200] global_step=312200, grad_norm=2.9676425457000732, loss=1.3556643724441528
I0304 04:45:22.266977 139881799980800 logging_writer.py:48] [312300] global_step=312300, grad_norm=3.2328946590423584, loss=1.139876127243042
I0304 04:46:06.543407 139881808373504 logging_writer.py:48] [312400] global_step=312400, grad_norm=3.1666476726531982, loss=1.1234283447265625
I0304 04:46:50.912923 139881799980800 logging_writer.py:48] [312500] global_step=312500, grad_norm=3.2757749557495117, loss=1.5551599264144897
I0304 04:47:35.813863 139881808373504 logging_writer.py:48] [312600] global_step=312600, grad_norm=3.178280830383301, loss=1.4977819919586182
I0304 04:47:51.865625 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:48:02.530486 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:48:37.925743 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:48:39.497158 140077943854912 submission_runner.py:411] Time since start: 150112.30s, 	Step: 312638, 	{'train/accuracy': 0.8905078172683716, 'train/loss': 0.4076966643333435, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 137418.08788132668, 'total_duration': 150112.3021736145, 'accumulated_submission_time': 137418.08788132668, 'accumulated_eval_time': 12657.285651922226, 'accumulated_logging_time': 20.62012791633606}
I0304 04:48:39.561230 139881799980800 logging_writer.py:48] [312638] accumulated_eval_time=12657.285652, accumulated_logging_time=20.620128, accumulated_submission_time=137418.087881, global_step=312638, preemption_count=0, score=137418.087881, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=150112.302174, train/accuracy=0.890508, train/loss=0.407697, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:49:04.116280 139881808373504 logging_writer.py:48] [312700] global_step=312700, grad_norm=2.98142409324646, loss=1.1497697830200195
I0304 04:49:46.824478 139881799980800 logging_writer.py:48] [312800] global_step=312800, grad_norm=3.033993721008301, loss=1.1738132238388062
I0304 04:50:31.139339 139881808373504 logging_writer.py:48] [312900] global_step=312900, grad_norm=3.3576066493988037, loss=1.1281566619873047
I0304 04:51:15.558588 139881799980800 logging_writer.py:48] [313000] global_step=313000, grad_norm=3.0917716026306152, loss=1.338799238204956
I0304 04:51:59.942379 139881808373504 logging_writer.py:48] [313100] global_step=313100, grad_norm=2.900022029876709, loss=0.9721283912658691
I0304 04:52:44.595426 139881799980800 logging_writer.py:48] [313200] global_step=313200, grad_norm=3.0035717487335205, loss=1.1664234399795532
I0304 04:53:28.861404 139881808373504 logging_writer.py:48] [313300] global_step=313300, grad_norm=2.965117931365967, loss=2.113476514816284
I0304 04:54:13.218097 139881799980800 logging_writer.py:48] [313400] global_step=313400, grad_norm=3.108698844909668, loss=2.318575382232666
I0304 04:54:57.457617 139881808373504 logging_writer.py:48] [313500] global_step=313500, grad_norm=3.5886735916137695, loss=2.3655178546905518
I0304 04:55:39.722836 140077943854912 spec.py:321] Evaluating on the training split.
I0304 04:55:49.949086 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 04:56:18.296314 140077943854912 spec.py:349] Evaluating on the test split.
I0304 04:56:19.909463 140077943854912 submission_runner.py:411] Time since start: 150572.71s, 	Step: 313597, 	{'train/accuracy': 0.8882616758346558, 'train/loss': 0.41826385259628296, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 137838.1891798973, 'total_duration': 150572.7144780159, 'accumulated_submission_time': 137838.1891798973, 'accumulated_eval_time': 12697.472255945206, 'accumulated_logging_time': 20.69444990158081}
I0304 04:56:19.976347 139881799980800 logging_writer.py:48] [313597] accumulated_eval_time=12697.472256, accumulated_logging_time=20.694450, accumulated_submission_time=137838.189180, global_step=313597, preemption_count=0, score=137838.189180, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=150572.714478, train/accuracy=0.888262, train/loss=0.418264, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 04:56:21.541335 139881808373504 logging_writer.py:48] [313600] global_step=313600, grad_norm=2.824908971786499, loss=1.4504112005233765
I0304 04:57:01.502190 139881799980800 logging_writer.py:48] [313700] global_step=313700, grad_norm=3.121522903442383, loss=1.358711838722229
I0304 04:57:45.786588 139881808373504 logging_writer.py:48] [313800] global_step=313800, grad_norm=3.0528934001922607, loss=1.0596835613250732
I0304 04:58:30.402611 139881799980800 logging_writer.py:48] [313900] global_step=313900, grad_norm=3.8119730949401855, loss=1.1709399223327637
I0304 04:59:15.031409 139881808373504 logging_writer.py:48] [314000] global_step=314000, grad_norm=2.7847249507904053, loss=1.456662654876709
I0304 04:59:59.399347 139881799980800 logging_writer.py:48] [314100] global_step=314100, grad_norm=3.0316882133483887, loss=1.6909589767456055
I0304 05:00:43.739190 139881808373504 logging_writer.py:48] [314200] global_step=314200, grad_norm=3.306941509246826, loss=1.2187716960906982
I0304 05:01:28.221169 139881799980800 logging_writer.py:48] [314300] global_step=314300, grad_norm=3.0176775455474854, loss=1.3696876764297485
I0304 05:02:12.588034 139881808373504 logging_writer.py:48] [314400] global_step=314400, grad_norm=3.4209210872650146, loss=2.9007420539855957
I0304 05:02:57.063142 139881799980800 logging_writer.py:48] [314500] global_step=314500, grad_norm=3.194934844970703, loss=2.751295328140259
I0304 05:03:19.996813 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:03:30.619797 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:03:59.891968 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:04:01.476931 140077943854912 submission_runner.py:411] Time since start: 151034.28s, 	Step: 314553, 	{'train/accuracy': 0.8880859017372131, 'train/loss': 0.4185377359390259, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 138258.14862036705, 'total_duration': 151034.2818892002, 'accumulated_submission_time': 138258.14862036705, 'accumulated_eval_time': 12738.952292442322, 'accumulated_logging_time': 20.77275776863098}
I0304 05:04:01.554781 139881808373504 logging_writer.py:48] [314553] accumulated_eval_time=12738.952292, accumulated_logging_time=20.772758, accumulated_submission_time=138258.148620, global_step=314553, preemption_count=0, score=138258.148620, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=151034.281889, train/accuracy=0.888086, train/loss=0.418538, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:04:20.282394 139881799980800 logging_writer.py:48] [314600] global_step=314600, grad_norm=2.983250856399536, loss=1.1633646488189697
I0304 05:05:03.988655 139881808373504 logging_writer.py:48] [314700] global_step=314700, grad_norm=3.0738136768341064, loss=1.1413319110870361
I0304 05:05:48.359115 139881799980800 logging_writer.py:48] [314800] global_step=314800, grad_norm=3.266070604324341, loss=1.5173802375793457
I0304 05:06:32.848348 139881808373504 logging_writer.py:48] [314900] global_step=314900, grad_norm=2.901794672012329, loss=1.1890500783920288
I0304 05:07:17.562442 139881799980800 logging_writer.py:48] [315000] global_step=315000, grad_norm=3.092690944671631, loss=1.3107322454452515
I0304 05:08:02.198354 139881808373504 logging_writer.py:48] [315100] global_step=315100, grad_norm=3.23663330078125, loss=1.2042627334594727
I0304 05:08:46.634020 139881799980800 logging_writer.py:48] [315200] global_step=315200, grad_norm=3.3120861053466797, loss=1.1140084266662598
I0304 05:09:31.209116 139881808373504 logging_writer.py:48] [315300] global_step=315300, grad_norm=3.0582990646362305, loss=1.1290526390075684
I0304 05:10:15.798505 139881799980800 logging_writer.py:48] [315400] global_step=315400, grad_norm=3.002795934677124, loss=1.9188592433929443
I0304 05:11:00.247082 139881808373504 logging_writer.py:48] [315500] global_step=315500, grad_norm=3.1788504123687744, loss=1.0981570482254028
I0304 05:11:01.800647 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:11:12.128771 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:11:41.710976 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:11:43.294451 140077943854912 submission_runner.py:411] Time since start: 151496.10s, 	Step: 315505, 	{'train/accuracy': 0.8875390291213989, 'train/loss': 0.4202651381492615, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 138678.3341538906, 'total_duration': 151496.09946393967, 'accumulated_submission_time': 138678.3341538906, 'accumulated_eval_time': 12780.446078777313, 'accumulated_logging_time': 20.86136531829834}
I0304 05:11:43.371695 139881799980800 logging_writer.py:48] [315505] accumulated_eval_time=12780.446079, accumulated_logging_time=20.861365, accumulated_submission_time=138678.334154, global_step=315505, preemption_count=0, score=138678.334154, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=151496.099464, train/accuracy=0.887539, train/loss=0.420265, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:12:22.544828 139881808373504 logging_writer.py:48] [315600] global_step=315600, grad_norm=3.3663933277130127, loss=3.094958782196045
I0304 05:13:06.963353 139881799980800 logging_writer.py:48] [315700] global_step=315700, grad_norm=2.9512765407562256, loss=1.1372649669647217
I0304 05:13:51.774882 139881808373504 logging_writer.py:48] [315800] global_step=315800, grad_norm=2.957085132598877, loss=1.0824934244155884
I0304 05:14:36.495183 139881799980800 logging_writer.py:48] [315900] global_step=315900, grad_norm=2.953526020050049, loss=1.461167573928833
I0304 05:15:21.210703 139881808373504 logging_writer.py:48] [316000] global_step=316000, grad_norm=3.310600519180298, loss=2.82588267326355
I0304 05:16:06.151794 139881799980800 logging_writer.py:48] [316100] global_step=316100, grad_norm=3.075748920440674, loss=1.7896710634231567
I0304 05:16:50.825954 139881808373504 logging_writer.py:48] [316200] global_step=316200, grad_norm=3.353177547454834, loss=1.133665680885315
I0304 05:17:35.635747 139881799980800 logging_writer.py:48] [316300] global_step=316300, grad_norm=3.1755592823028564, loss=2.6625540256500244
I0304 05:18:20.266939 139881808373504 logging_writer.py:48] [316400] global_step=316400, grad_norm=3.0082309246063232, loss=2.525690793991089
I0304 05:18:43.512197 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:18:53.640775 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:19:30.600922 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:19:32.176459 140077943854912 submission_runner.py:411] Time since start: 151964.98s, 	Step: 316454, 	{'train/accuracy': 0.88671875, 'train/loss': 0.4202517867088318, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 139098.41466093063, 'total_duration': 151964.981477499, 'accumulated_submission_time': 139098.41466093063, 'accumulated_eval_time': 12829.110315561295, 'accumulated_logging_time': 20.949914693832397}
I0304 05:19:32.239606 139881799980800 logging_writer.py:48] [316454] accumulated_eval_time=12829.110316, accumulated_logging_time=20.949915, accumulated_submission_time=139098.414661, global_step=316454, preemption_count=0, score=139098.414661, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=151964.981477, train/accuracy=0.886719, train/loss=0.420252, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:19:50.556616 139881808373504 logging_writer.py:48] [316500] global_step=316500, grad_norm=3.1196718215942383, loss=1.1452281475067139
I0304 05:20:32.829480 139881799980800 logging_writer.py:48] [316600] global_step=316600, grad_norm=3.6995551586151123, loss=2.850616693496704
I0304 05:21:17.306244 139881808373504 logging_writer.py:48] [316700] global_step=316700, grad_norm=3.285569190979004, loss=2.596255302429199
I0304 05:22:01.790968 139881799980800 logging_writer.py:48] [316800] global_step=316800, grad_norm=3.1590054035186768, loss=1.829070806503296
I0304 05:22:46.295064 139881808373504 logging_writer.py:48] [316900] global_step=316900, grad_norm=2.98821759223938, loss=1.7036277055740356
I0304 05:23:30.679809 139881799980800 logging_writer.py:48] [317000] global_step=317000, grad_norm=3.952183485031128, loss=3.1344566345214844
I0304 05:24:15.122598 139881808373504 logging_writer.py:48] [317100] global_step=317100, grad_norm=3.1284101009368896, loss=1.1586635112762451
I0304 05:24:59.519959 139881799980800 logging_writer.py:48] [317200] global_step=317200, grad_norm=3.4269659519195557, loss=2.852019786834717
I0304 05:25:44.132588 139881808373504 logging_writer.py:48] [317300] global_step=317300, grad_norm=3.0258591175079346, loss=1.144539475440979
I0304 05:26:28.374515 139881799980800 logging_writer.py:48] [317400] global_step=317400, grad_norm=2.9394824504852295, loss=1.4666662216186523
I0304 05:26:32.488676 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:26:42.583525 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:27:13.757958 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:27:15.360954 140077943854912 submission_runner.py:411] Time since start: 152428.17s, 	Step: 317411, 	{'train/accuracy': 0.8899804353713989, 'train/loss': 0.40719282627105713, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 139518.60390734673, 'total_duration': 152428.16596484184, 'accumulated_submission_time': 139518.60390734673, 'accumulated_eval_time': 12871.982561588287, 'accumulated_logging_time': 21.023661851882935}
I0304 05:27:15.425141 139881808373504 logging_writer.py:48] [317411] accumulated_eval_time=12871.982562, accumulated_logging_time=21.023662, accumulated_submission_time=139518.603907, global_step=317411, preemption_count=0, score=139518.603907, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=152428.165965, train/accuracy=0.889980, train/loss=0.407193, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:27:50.853433 139881799980800 logging_writer.py:48] [317500] global_step=317500, grad_norm=2.932680606842041, loss=1.447939395904541
I0304 05:28:34.952969 139881808373504 logging_writer.py:48] [317600] global_step=317600, grad_norm=3.197695016860962, loss=1.6376252174377441
I0304 05:29:19.238939 139881799980800 logging_writer.py:48] [317700] global_step=317700, grad_norm=3.7717373371124268, loss=3.2627217769622803
I0304 05:30:04.103563 139881808373504 logging_writer.py:48] [317800] global_step=317800, grad_norm=2.9080841541290283, loss=1.08268404006958
I0304 05:30:48.607410 139881799980800 logging_writer.py:48] [317900] global_step=317900, grad_norm=2.9503800868988037, loss=1.3773396015167236
I0304 05:31:33.139383 139881808373504 logging_writer.py:48] [318000] global_step=318000, grad_norm=2.8754637241363525, loss=2.3094496726989746
I0304 05:32:17.544243 139881799980800 logging_writer.py:48] [318100] global_step=318100, grad_norm=2.830446243286133, loss=2.2448720932006836
I0304 05:33:01.878439 139881808373504 logging_writer.py:48] [318200] global_step=318200, grad_norm=3.036910057067871, loss=1.3013389110565186
I0304 05:33:46.360291 139881799980800 logging_writer.py:48] [318300] global_step=318300, grad_norm=2.900766134262085, loss=1.3179512023925781
I0304 05:34:15.550584 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:34:26.377787 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:34:52.774806 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:34:54.363202 140077943854912 submission_runner.py:411] Time since start: 152887.17s, 	Step: 318367, 	{'train/accuracy': 0.8865624666213989, 'train/loss': 0.4238818287849426, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 139938.67020440102, 'total_duration': 152887.1681947708, 'accumulated_submission_time': 139938.67020440102, 'accumulated_eval_time': 12910.795140266418, 'accumulated_logging_time': 21.09812617301941}
I0304 05:34:54.440899 139881808373504 logging_writer.py:48] [318367] accumulated_eval_time=12910.795140, accumulated_logging_time=21.098126, accumulated_submission_time=139938.670204, global_step=318367, preemption_count=0, score=139938.670204, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=152887.168195, train/accuracy=0.886562, train/loss=0.423882, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:35:07.902563 139881799980800 logging_writer.py:48] [318400] global_step=318400, grad_norm=3.006636381149292, loss=2.276034355163574
I0304 05:35:52.040209 139881808373504 logging_writer.py:48] [318500] global_step=318500, grad_norm=2.8179495334625244, loss=1.0492441654205322
I0304 05:36:37.284027 139881799980800 logging_writer.py:48] [318600] global_step=318600, grad_norm=3.2263805866241455, loss=1.1123905181884766
I0304 05:37:22.530370 139881808373504 logging_writer.py:48] [318700] global_step=318700, grad_norm=3.0079400539398193, loss=2.343818187713623
I0304 05:38:07.801874 139881799980800 logging_writer.py:48] [318800] global_step=318800, grad_norm=3.5233094692230225, loss=3.1974925994873047
I0304 05:38:52.930930 139881808373504 logging_writer.py:48] [318900] global_step=318900, grad_norm=2.8165078163146973, loss=1.081146478652954
I0304 05:39:37.959066 139881799980800 logging_writer.py:48] [319000] global_step=319000, grad_norm=3.254763603210449, loss=1.1681668758392334
I0304 05:40:23.266142 139881808373504 logging_writer.py:48] [319100] global_step=319100, grad_norm=4.07602596282959, loss=3.1300277709960938
I0304 05:41:08.647906 139881799980800 logging_writer.py:48] [319200] global_step=319200, grad_norm=3.1016223430633545, loss=1.7592943906784058
I0304 05:41:53.373554 139881808373504 logging_writer.py:48] [319300] global_step=319300, grad_norm=3.187188148498535, loss=1.104848861694336
I0304 05:41:54.390763 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:42:04.802083 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:42:33.493745 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:42:35.084230 140077943854912 submission_runner.py:411] Time since start: 153347.89s, 	Step: 319304, 	{'train/accuracy': 0.8884961009025574, 'train/loss': 0.4180271029472351, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 140358.56078743935, 'total_duration': 153347.8892352581, 'accumulated_submission_time': 140358.56078743935, 'accumulated_eval_time': 12951.488573789597, 'accumulated_logging_time': 21.18717908859253}
I0304 05:42:35.162477 139881799980800 logging_writer.py:48] [319304] accumulated_eval_time=12951.488574, accumulated_logging_time=21.187179, accumulated_submission_time=140358.560787, global_step=319304, preemption_count=0, score=140358.560787, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=153347.889235, train/accuracy=0.888496, train/loss=0.418027, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:43:14.470997 139881808373504 logging_writer.py:48] [319400] global_step=319400, grad_norm=3.1344690322875977, loss=1.3578238487243652
I0304 05:43:58.567543 139881799980800 logging_writer.py:48] [319500] global_step=319500, grad_norm=3.5428249835968018, loss=1.1551624536514282
I0304 05:44:43.346524 139881808373504 logging_writer.py:48] [319600] global_step=319600, grad_norm=3.2293319702148438, loss=1.7728064060211182
I0304 05:45:27.774828 139881799980800 logging_writer.py:48] [319700] global_step=319700, grad_norm=2.930515766143799, loss=1.233381748199463
I0304 05:46:12.098603 139881808373504 logging_writer.py:48] [319800] global_step=319800, grad_norm=3.149127960205078, loss=1.2436764240264893
I0304 05:46:56.909455 139881799980800 logging_writer.py:48] [319900] global_step=319900, grad_norm=3.1432178020477295, loss=1.6103689670562744
I0304 05:47:41.307898 139881808373504 logging_writer.py:48] [320000] global_step=320000, grad_norm=3.1749141216278076, loss=1.0566667318344116
I0304 05:48:26.122251 139881799980800 logging_writer.py:48] [320100] global_step=320100, grad_norm=3.653343677520752, loss=1.4844385385513306
I0304 05:49:10.519967 139881808373504 logging_writer.py:48] [320200] global_step=320200, grad_norm=3.988267183303833, loss=3.2038493156433105
I0304 05:49:35.496366 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:49:45.688135 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:50:12.528991 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:50:14.135160 140077943854912 submission_runner.py:411] Time since start: 153806.94s, 	Step: 320258, 	{'train/accuracy': 0.8869335651397705, 'train/loss': 0.419131875038147, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 140778.834120512, 'total_duration': 153806.9401268959, 'accumulated_submission_time': 140778.834120512, 'accumulated_eval_time': 12990.127300024033, 'accumulated_logging_time': 21.276575088500977}
I0304 05:50:14.263995 139881799980800 logging_writer.py:48] [320258] accumulated_eval_time=12990.127300, accumulated_logging_time=21.276575, accumulated_submission_time=140778.834121, global_step=320258, preemption_count=0, score=140778.834121, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=153806.940127, train/accuracy=0.886934, train/loss=0.419132, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:50:31.053415 139881808373504 logging_writer.py:48] [320300] global_step=320300, grad_norm=3.6268811225891113, loss=1.4445750713348389
I0304 05:51:13.442249 139881799980800 logging_writer.py:48] [320400] global_step=320400, grad_norm=3.029676914215088, loss=1.0325920581817627
I0304 05:51:57.730347 139881808373504 logging_writer.py:48] [320500] global_step=320500, grad_norm=3.096156120300293, loss=1.1042951345443726
I0304 05:52:42.507248 139881799980800 logging_writer.py:48] [320600] global_step=320600, grad_norm=3.090414524078369, loss=1.1621543169021606
I0304 05:53:26.756594 139881808373504 logging_writer.py:48] [320700] global_step=320700, grad_norm=3.2147834300994873, loss=1.1505025625228882
I0304 05:54:11.191082 139881799980800 logging_writer.py:48] [320800] global_step=320800, grad_norm=3.1036012172698975, loss=1.059908151626587
I0304 05:54:55.551193 139881808373504 logging_writer.py:48] [320900] global_step=320900, grad_norm=2.895472288131714, loss=1.0254701375961304
I0304 05:55:39.964608 139881799980800 logging_writer.py:48] [321000] global_step=321000, grad_norm=3.019587278366089, loss=1.7381703853607178
I0304 05:56:24.662940 139881808373504 logging_writer.py:48] [321100] global_step=321100, grad_norm=3.2434170246124268, loss=1.5915229320526123
I0304 05:57:09.136379 139881799980800 logging_writer.py:48] [321200] global_step=321200, grad_norm=3.0346314907073975, loss=1.3150660991668701
I0304 05:57:14.233930 140077943854912 spec.py:321] Evaluating on the training split.
I0304 05:57:24.467274 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 05:57:50.312272 140077943854912 spec.py:349] Evaluating on the test split.
I0304 05:57:51.899921 140077943854912 submission_runner.py:411] Time since start: 154264.70s, 	Step: 321213, 	{'train/accuracy': 0.8894921541213989, 'train/loss': 0.4086560010910034, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 141198.73992681503, 'total_duration': 154264.70492196083, 'accumulated_submission_time': 141198.73992681503, 'accumulated_eval_time': 13027.79325413704, 'accumulated_logging_time': 21.4208242893219}
I0304 05:57:51.979905 139881808373504 logging_writer.py:48] [321213] accumulated_eval_time=13027.793254, accumulated_logging_time=21.420824, accumulated_submission_time=141198.739927, global_step=321213, preemption_count=0, score=141198.739927, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=154264.704922, train/accuracy=0.889492, train/loss=0.408656, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 05:58:27.369015 139881799980800 logging_writer.py:48] [321300] global_step=321300, grad_norm=3.929727077484131, loss=3.059021472930908
I0304 05:59:11.881556 139881808373504 logging_writer.py:48] [321400] global_step=321400, grad_norm=3.08467435836792, loss=2.79426908493042
I0304 05:59:56.610891 139881799980800 logging_writer.py:48] [321500] global_step=321500, grad_norm=3.1466143131256104, loss=1.1808090209960938
I0304 06:00:41.572474 139881808373504 logging_writer.py:48] [321600] global_step=321600, grad_norm=3.055893659591675, loss=1.2396013736724854
I0304 06:01:26.154306 139881799980800 logging_writer.py:48] [321700] global_step=321700, grad_norm=2.9382221698760986, loss=1.1599355936050415
I0304 06:02:10.684317 139881808373504 logging_writer.py:48] [321800] global_step=321800, grad_norm=3.428602933883667, loss=1.170474886894226
I0304 06:02:55.216204 139881799980800 logging_writer.py:48] [321900] global_step=321900, grad_norm=2.9707252979278564, loss=2.3769490718841553
I0304 06:03:40.052634 139881808373504 logging_writer.py:48] [322000] global_step=322000, grad_norm=3.1355903148651123, loss=1.1504541635513306
I0304 06:04:24.408802 139881799980800 logging_writer.py:48] [322100] global_step=322100, grad_norm=3.1731841564178467, loss=2.049779176712036
I0304 06:04:52.375041 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:05:02.879570 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:05:29.865919 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:05:31.459573 140077943854912 submission_runner.py:411] Time since start: 154724.26s, 	Step: 322164, 	{'train/accuracy': 0.8868749737739563, 'train/loss': 0.4255317449569702, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 141619.0731432438, 'total_duration': 154724.26458621025, 'accumulated_submission_time': 141619.0731432438, 'accumulated_eval_time': 13066.877766132355, 'accumulated_logging_time': 21.51161813735962}
I0304 06:05:31.542759 139881808373504 logging_writer.py:48] [322164] accumulated_eval_time=13066.877766, accumulated_logging_time=21.511618, accumulated_submission_time=141619.073143, global_step=322164, preemption_count=0, score=141619.073143, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=154724.264586, train/accuracy=0.886875, train/loss=0.425532, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 06:05:45.987950 139881799980800 logging_writer.py:48] [322200] global_step=322200, grad_norm=3.3358209133148193, loss=1.1383291482925415
I0304 06:06:28.795535 139881808373504 logging_writer.py:48] [322300] global_step=322300, grad_norm=3.1467368602752686, loss=2.9569549560546875
I0304 06:07:13.281617 139881799980800 logging_writer.py:48] [322400] global_step=322400, grad_norm=3.4648561477661133, loss=2.785123348236084
I0304 06:07:57.597340 139881808373504 logging_writer.py:48] [322500] global_step=322500, grad_norm=3.048586368560791, loss=1.341850996017456
I0304 06:08:42.079916 139881799980800 logging_writer.py:48] [322600] global_step=322600, grad_norm=3.5667500495910645, loss=1.7148538827896118
I0304 06:09:26.369132 139881808373504 logging_writer.py:48] [322700] global_step=322700, grad_norm=3.2955496311187744, loss=1.13541579246521
I0304 06:10:11.054141 139881799980800 logging_writer.py:48] [322800] global_step=322800, grad_norm=3.073101758956909, loss=2.164762020111084
I0304 06:10:55.098563 139881808373504 logging_writer.py:48] [322900] global_step=322900, grad_norm=3.1020164489746094, loss=1.1211843490600586
I0304 06:11:39.473594 139881799980800 logging_writer.py:48] [323000] global_step=323000, grad_norm=3.266141891479492, loss=1.074376106262207
I0304 06:12:24.118467 139881808373504 logging_writer.py:48] [323100] global_step=323100, grad_norm=3.562656879425049, loss=2.9028167724609375
I0304 06:12:31.673063 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:12:41.818384 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:13:14.365929 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:13:15.976315 140077943854912 submission_runner.py:411] Time since start: 155188.78s, 	Step: 323119, 	{'train/accuracy': 0.8875390291213989, 'train/loss': 0.4166724681854248, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 142039.1426100731, 'total_duration': 155188.78133320808, 'accumulated_submission_time': 142039.1426100731, 'accumulated_eval_time': 13111.180988073349, 'accumulated_logging_time': 21.60645341873169}
I0304 06:13:16.043735 139881799980800 logging_writer.py:48] [323119] accumulated_eval_time=13111.180988, accumulated_logging_time=21.606453, accumulated_submission_time=142039.142610, global_step=323119, preemption_count=0, score=142039.142610, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=155188.781333, train/accuracy=0.887539, train/loss=0.416672, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 06:13:48.035264 139881808373504 logging_writer.py:48] [323200] global_step=323200, grad_norm=2.8898181915283203, loss=1.11918044090271
I0304 06:14:31.946937 139881799980800 logging_writer.py:48] [323300] global_step=323300, grad_norm=2.9920830726623535, loss=1.0759800672531128
I0304 06:15:16.654625 139881808373504 logging_writer.py:48] [323400] global_step=323400, grad_norm=3.524308204650879, loss=1.8067103624343872
I0304 06:16:00.976242 139881799980800 logging_writer.py:48] [323500] global_step=323500, grad_norm=3.1024820804595947, loss=1.1897307634353638
I0304 06:16:45.463312 139881808373504 logging_writer.py:48] [323600] global_step=323600, grad_norm=3.4765515327453613, loss=2.1204710006713867
I0304 06:17:29.720075 139881799980800 logging_writer.py:48] [323700] global_step=323700, grad_norm=3.2565770149230957, loss=1.5707242488861084
I0304 06:18:13.937160 139881808373504 logging_writer.py:48] [323800] global_step=323800, grad_norm=3.408113479614258, loss=1.0805891752243042
I0304 06:18:58.394700 139881799980800 logging_writer.py:48] [323900] global_step=323900, grad_norm=3.035269021987915, loss=1.1162006855010986
I0304 06:19:42.506009 139881808373504 logging_writer.py:48] [324000] global_step=324000, grad_norm=2.932155132293701, loss=1.2197651863098145
I0304 06:20:16.199980 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:20:26.253511 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:21:02.818618 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:21:04.395699 140077943854912 submission_runner.py:411] Time since start: 155657.20s, 	Step: 324077, 	{'train/accuracy': 0.88783198595047, 'train/loss': 0.4228438138961792, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 142459.23724484444, 'total_duration': 155657.20071411133, 'accumulated_submission_time': 142459.23724484444, 'accumulated_eval_time': 13159.376702070236, 'accumulated_logging_time': 21.686269760131836}
I0304 06:21:04.460669 139881799980800 logging_writer.py:48] [324077] accumulated_eval_time=13159.376702, accumulated_logging_time=21.686270, accumulated_submission_time=142459.237245, global_step=324077, preemption_count=0, score=142459.237245, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=155657.200714, train/accuracy=0.887832, train/loss=0.422844, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 06:21:13.820279 139881808373504 logging_writer.py:48] [324100] global_step=324100, grad_norm=3.4996001720428467, loss=1.1830177307128906
I0304 06:21:54.639438 139881799980800 logging_writer.py:48] [324200] global_step=324200, grad_norm=3.1233010292053223, loss=1.1080013513565063
I0304 06:22:39.278564 139881808373504 logging_writer.py:48] [324300] global_step=324300, grad_norm=3.1847546100616455, loss=2.0893499851226807
I0304 06:23:24.018586 139881799980800 logging_writer.py:48] [324400] global_step=324400, grad_norm=4.462976455688477, loss=3.279356002807617
I0304 06:24:08.373510 139881808373504 logging_writer.py:48] [324500] global_step=324500, grad_norm=3.0270133018493652, loss=2.0223560333251953
I0304 06:24:52.788340 139881799980800 logging_writer.py:48] [324600] global_step=324600, grad_norm=2.95064115524292, loss=1.1501166820526123
I0304 06:25:37.338006 139881808373504 logging_writer.py:48] [324700] global_step=324700, grad_norm=2.9195497035980225, loss=1.1776173114776611
I0304 06:26:21.734916 139881799980800 logging_writer.py:48] [324800] global_step=324800, grad_norm=3.3087310791015625, loss=1.3774842023849487
I0304 06:27:05.958148 139881808373504 logging_writer.py:48] [324900] global_step=324900, grad_norm=3.3629050254821777, loss=1.0979082584381104
I0304 06:27:50.265024 139881799980800 logging_writer.py:48] [325000] global_step=325000, grad_norm=3.024444341659546, loss=1.1588594913482666
I0304 06:28:04.613955 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:28:14.730978 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:28:51.627168 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:28:53.205377 140077943854912 submission_runner.py:411] Time since start: 156126.01s, 	Step: 325034, 	{'train/accuracy': 0.8855078220367432, 'train/loss': 0.4231415390968323, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 142879.33050012589, 'total_duration': 156126.01038050652, 'accumulated_submission_time': 142879.33050012589, 'accumulated_eval_time': 13207.968095541, 'accumulated_logging_time': 21.76215624809265}
I0304 06:28:53.270472 139881808373504 logging_writer.py:48] [325034] accumulated_eval_time=13207.968096, accumulated_logging_time=21.762156, accumulated_submission_time=142879.330500, global_step=325034, preemption_count=0, score=142879.330500, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=156126.010381, train/accuracy=0.885508, train/loss=0.423142, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 06:29:19.423342 139881799980800 logging_writer.py:48] [325100] global_step=325100, grad_norm=3.035269021987915, loss=1.1532254219055176
I0304 06:30:03.059348 139881808373504 logging_writer.py:48] [325200] global_step=325200, grad_norm=2.964608907699585, loss=1.034246802330017
I0304 06:30:47.682982 139881799980800 logging_writer.py:48] [325300] global_step=325300, grad_norm=2.8938376903533936, loss=1.665706992149353
I0304 06:31:32.166787 139881808373504 logging_writer.py:48] [325400] global_step=325400, grad_norm=3.10544753074646, loss=2.5186591148376465
I0304 06:32:16.639547 139881799980800 logging_writer.py:48] [325500] global_step=325500, grad_norm=3.2505698204040527, loss=1.2296912670135498
I0304 06:33:00.923145 139881808373504 logging_writer.py:48] [325600] global_step=325600, grad_norm=3.4655826091766357, loss=2.044494390487671
I0304 06:33:45.268286 139881799980800 logging_writer.py:48] [325700] global_step=325700, grad_norm=3.271260976791382, loss=1.1745542287826538
I0304 06:34:29.664273 139881808373504 logging_writer.py:48] [325800] global_step=325800, grad_norm=3.1591289043426514, loss=2.1781234741210938
I0304 06:35:14.132786 139881799980800 logging_writer.py:48] [325900] global_step=325900, grad_norm=3.0613245964050293, loss=1.3366215229034424
I0304 06:35:53.449178 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:36:03.945204 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:36:31.086210 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:36:32.672912 140077943854912 submission_runner.py:411] Time since start: 156585.48s, 	Step: 325990, 	{'train/accuracy': 0.8892773389816284, 'train/loss': 0.4138164818286896, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 143299.4483640194, 'total_duration': 156585.47791337967, 'accumulated_submission_time': 143299.4483640194, 'accumulated_eval_time': 13247.191797733307, 'accumulated_logging_time': 21.83880043029785}
I0304 06:36:32.754738 139881808373504 logging_writer.py:48] [325990] accumulated_eval_time=13247.191798, accumulated_logging_time=21.838800, accumulated_submission_time=143299.448364, global_step=325990, preemption_count=0, score=143299.448364, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=156585.477913, train/accuracy=0.889277, train/loss=0.413816, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 06:36:37.077936 139881799980800 logging_writer.py:48] [326000] global_step=326000, grad_norm=2.9781112670898438, loss=1.2946195602416992
I0304 06:37:19.035854 139881808373504 logging_writer.py:48] [326100] global_step=326100, grad_norm=2.9267995357513428, loss=1.1410024166107178
I0304 06:38:04.048328 139881799980800 logging_writer.py:48] [326200] global_step=326200, grad_norm=3.1442089080810547, loss=1.1205203533172607
I0304 06:38:48.910364 139881808373504 logging_writer.py:48] [326300] global_step=326300, grad_norm=3.0973923206329346, loss=1.3734151124954224
I0304 06:39:33.706145 139881799980800 logging_writer.py:48] [326400] global_step=326400, grad_norm=3.0457730293273926, loss=1.3243097066879272
I0304 06:40:18.676390 139881808373504 logging_writer.py:48] [326500] global_step=326500, grad_norm=3.2562897205352783, loss=2.364103317260742
I0304 06:41:03.641014 139881799980800 logging_writer.py:48] [326600] global_step=326600, grad_norm=3.1590487957000732, loss=1.1012334823608398
I0304 06:41:48.574200 139881808373504 logging_writer.py:48] [326700] global_step=326700, grad_norm=2.8791086673736572, loss=1.631205439567566
I0304 06:42:33.559521 139881799980800 logging_writer.py:48] [326800] global_step=326800, grad_norm=3.4111223220825195, loss=1.1734038591384888
I0304 06:43:18.153238 139881808373504 logging_writer.py:48] [326900] global_step=326900, grad_norm=4.085908889770508, loss=3.2981274127960205
I0304 06:43:32.958698 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:43:43.234399 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:44:20.860933 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:44:22.472604 140077943854912 submission_runner.py:411] Time since start: 157055.28s, 	Step: 326935, 	{'train/accuracy': 0.8871874809265137, 'train/loss': 0.4137941896915436, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 143719.5908768177, 'total_duration': 157055.27760457993, 'accumulated_submission_time': 143719.5908768177, 'accumulated_eval_time': 13296.705656290054, 'accumulated_logging_time': 21.93300485610962}
I0304 06:44:22.538533 139881799980800 logging_writer.py:48] [326935] accumulated_eval_time=13296.705656, accumulated_logging_time=21.933005, accumulated_submission_time=143719.590877, global_step=326935, preemption_count=0, score=143719.590877, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=157055.277605, train/accuracy=0.887187, train/loss=0.413794, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 06:44:48.298243 139881808373504 logging_writer.py:48] [327000] global_step=327000, grad_norm=3.8767120838165283, loss=3.2044591903686523
I0304 06:45:31.766154 139881799980800 logging_writer.py:48] [327100] global_step=327100, grad_norm=3.1856043338775635, loss=1.1774660348892212
I0304 06:46:16.440910 139881808373504 logging_writer.py:48] [327200] global_step=327200, grad_norm=2.8038268089294434, loss=1.4615362882614136
I0304 06:47:01.075407 139881799980800 logging_writer.py:48] [327300] global_step=327300, grad_norm=3.082990884780884, loss=1.1106359958648682
I0304 06:47:45.782265 139881808373504 logging_writer.py:48] [327400] global_step=327400, grad_norm=3.291180372238159, loss=1.4778871536254883
I0304 06:48:30.327704 139881799980800 logging_writer.py:48] [327500] global_step=327500, grad_norm=3.5588037967681885, loss=3.241525888442993
I0304 06:49:14.701500 139881808373504 logging_writer.py:48] [327600] global_step=327600, grad_norm=2.82867431640625, loss=1.2063305377960205
I0304 06:49:59.011313 139881799980800 logging_writer.py:48] [327700] global_step=327700, grad_norm=3.1045756340026855, loss=1.433836579322815
I0304 06:50:44.019595 139881808373504 logging_writer.py:48] [327800] global_step=327800, grad_norm=4.149274826049805, loss=2.2868943214416504
I0304 06:51:22.772687 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:51:33.061163 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:51:59.896178 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:52:01.498117 140077943854912 submission_runner.py:411] Time since start: 157514.30s, 	Step: 327889, 	{'train/accuracy': 0.8894726634025574, 'train/loss': 0.41528552770614624, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 144139.76654458046, 'total_duration': 157514.30312132835, 'accumulated_submission_time': 144139.76654458046, 'accumulated_eval_time': 13335.431085586548, 'accumulated_logging_time': 22.008670568466187}
I0304 06:52:01.597084 139881799980800 logging_writer.py:48] [327889] accumulated_eval_time=13335.431086, accumulated_logging_time=22.008671, accumulated_submission_time=144139.766545, global_step=327889, preemption_count=0, score=144139.766545, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=157514.303121, train/accuracy=0.889473, train/loss=0.415286, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 06:52:06.311949 139881808373504 logging_writer.py:48] [327900] global_step=327900, grad_norm=3.032005548477173, loss=1.7146780490875244
I0304 06:52:47.942989 139881799980800 logging_writer.py:48] [328000] global_step=328000, grad_norm=3.191115140914917, loss=2.8267087936401367
I0304 06:53:32.469602 139881808373504 logging_writer.py:48] [328100] global_step=328100, grad_norm=3.01334547996521, loss=1.286493182182312
I0304 06:54:17.053128 139881799980800 logging_writer.py:48] [328200] global_step=328200, grad_norm=3.1160409450531006, loss=1.1807200908660889
I0304 06:55:01.471102 139881808373504 logging_writer.py:48] [328300] global_step=328300, grad_norm=3.090606212615967, loss=1.2603081464767456
I0304 06:55:46.045024 139881799980800 logging_writer.py:48] [328400] global_step=328400, grad_norm=3.312448024749756, loss=2.8917717933654785
I0304 06:56:30.746727 139881808373504 logging_writer.py:48] [328500] global_step=328500, grad_norm=3.407395839691162, loss=2.5839667320251465
I0304 06:57:15.406214 139881799980800 logging_writer.py:48] [328600] global_step=328600, grad_norm=2.7887892723083496, loss=1.2175227403640747
I0304 06:57:59.755410 139881808373504 logging_writer.py:48] [328700] global_step=328700, grad_norm=3.1435623168945312, loss=1.0873520374298096
I0304 06:58:44.447887 139881799980800 logging_writer.py:48] [328800] global_step=328800, grad_norm=3.0639798641204834, loss=1.4792916774749756
I0304 06:59:02.019639 140077943854912 spec.py:321] Evaluating on the training split.
I0304 06:59:12.943123 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 06:59:40.676519 140077943854912 spec.py:349] Evaluating on the test split.
I0304 06:59:42.266041 140077943854912 submission_runner.py:411] Time since start: 157975.07s, 	Step: 328841, 	{'train/accuracy': 0.8877539038658142, 'train/loss': 0.41622817516326904, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 144560.12257027626, 'total_duration': 157975.0710504055, 'accumulated_submission_time': 144560.12257027626, 'accumulated_eval_time': 13375.67746925354, 'accumulated_logging_time': 22.125629425048828}
I0304 06:59:42.345275 139881808373504 logging_writer.py:48] [328841] accumulated_eval_time=13375.677469, accumulated_logging_time=22.125629, accumulated_submission_time=144560.122570, global_step=328841, preemption_count=0, score=144560.122570, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=157975.071050, train/accuracy=0.887754, train/loss=0.416228, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:00:05.872777 139881799980800 logging_writer.py:48] [328900] global_step=328900, grad_norm=3.362459421157837, loss=1.1955152750015259
I0304 07:00:50.632714 139881808373504 logging_writer.py:48] [329000] global_step=329000, grad_norm=3.262831687927246, loss=1.1070263385772705
I0304 07:01:35.814089 139881799980800 logging_writer.py:48] [329100] global_step=329100, grad_norm=3.872225284576416, loss=3.3695812225341797
I0304 07:02:20.548993 139881808373504 logging_writer.py:48] [329200] global_step=329200, grad_norm=2.949333429336548, loss=1.0732213258743286
I0304 07:03:05.509132 139881799980800 logging_writer.py:48] [329300] global_step=329300, grad_norm=3.1891071796417236, loss=1.055964708328247
I0304 07:03:50.594179 139881808373504 logging_writer.py:48] [329400] global_step=329400, grad_norm=3.4376473426818848, loss=1.1325609683990479
I0304 07:04:35.446195 139881799980800 logging_writer.py:48] [329500] global_step=329500, grad_norm=5.438138961791992, loss=1.1649903059005737
I0304 07:05:20.304415 139881808373504 logging_writer.py:48] [329600] global_step=329600, grad_norm=3.6575326919555664, loss=1.6330441236495972
I0304 07:06:05.024930 139881799980800 logging_writer.py:48] [329700] global_step=329700, grad_norm=2.930596113204956, loss=1.2467995882034302
I0304 07:06:42.343115 140077943854912 spec.py:321] Evaluating on the training split.
I0304 07:06:52.630710 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 07:07:24.838415 140077943854912 spec.py:349] Evaluating on the test split.
I0304 07:07:26.428724 140077943854912 submission_runner.py:411] Time since start: 158439.23s, 	Step: 329785, 	{'train/accuracy': 0.8871679306030273, 'train/loss': 0.41850805282592773, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 144980.0615439415, 'total_duration': 158439.23374319077, 'accumulated_submission_time': 144980.0615439415, 'accumulated_eval_time': 13419.763077259064, 'accumulated_logging_time': 22.216106176376343}
I0304 07:07:26.497854 139881808373504 logging_writer.py:48] [329785] accumulated_eval_time=13419.763077, accumulated_logging_time=22.216106, accumulated_submission_time=144980.061544, global_step=329785, preemption_count=0, score=144980.061544, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=158439.233743, train/accuracy=0.887168, train/loss=0.418508, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:07:32.724733 139881799980800 logging_writer.py:48] [329800] global_step=329800, grad_norm=3.6016275882720947, loss=3.127596616744995
I0304 07:08:13.409435 139881808373504 logging_writer.py:48] [329900] global_step=329900, grad_norm=2.9936492443084717, loss=1.5783836841583252
I0304 07:08:57.451914 139881799980800 logging_writer.py:48] [330000] global_step=330000, grad_norm=3.0860416889190674, loss=1.145386815071106
I0304 07:09:42.113769 139881808373504 logging_writer.py:48] [330100] global_step=330100, grad_norm=3.486176013946533, loss=1.2650729417800903
I0304 07:10:26.491397 139881799980800 logging_writer.py:48] [330200] global_step=330200, grad_norm=3.238091468811035, loss=1.1852333545684814
I0304 07:11:10.968107 139881808373504 logging_writer.py:48] [330300] global_step=330300, grad_norm=3.324916362762451, loss=1.111039638519287
I0304 07:11:55.312053 139881799980800 logging_writer.py:48] [330400] global_step=330400, grad_norm=3.2629518508911133, loss=2.4154067039489746
I0304 07:12:39.683639 139881808373504 logging_writer.py:48] [330500] global_step=330500, grad_norm=2.973536729812622, loss=1.012636661529541
I0304 07:13:24.041292 139881799980800 logging_writer.py:48] [330600] global_step=330600, grad_norm=3.782512664794922, loss=3.190551280975342
I0304 07:14:08.376668 139881808373504 logging_writer.py:48] [330700] global_step=330700, grad_norm=3.6850757598876953, loss=1.1644232273101807
I0304 07:14:26.749280 140077943854912 spec.py:321] Evaluating on the training split.
I0304 07:14:37.134568 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 07:15:03.770807 140077943854912 spec.py:349] Evaluating on the test split.
I0304 07:15:05.358191 140077943854912 submission_runner.py:411] Time since start: 158898.16s, 	Step: 330743, 	{'train/accuracy': 0.8885937333106995, 'train/loss': 0.4203934073448181, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 145400.25120687485, 'total_duration': 158898.16319799423, 'accumulated_submission_time': 145400.25120687485, 'accumulated_eval_time': 13458.372012853622, 'accumulated_logging_time': 22.297227382659912}
I0304 07:15:05.440680 139881799980800 logging_writer.py:48] [330743] accumulated_eval_time=13458.372013, accumulated_logging_time=22.297227, accumulated_submission_time=145400.251207, global_step=330743, preemption_count=0, score=145400.251207, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=158898.163198, train/accuracy=0.888594, train/loss=0.420393, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:15:28.074808 139881808373504 logging_writer.py:48] [330800] global_step=330800, grad_norm=3.1695730686187744, loss=1.1176058053970337
I0304 07:16:11.846115 139881799980800 logging_writer.py:48] [330900] global_step=330900, grad_norm=3.4698171615600586, loss=1.0643880367279053
I0304 07:16:56.307188 139881808373504 logging_writer.py:48] [331000] global_step=331000, grad_norm=3.06929874420166, loss=1.0278948545455933
I0304 07:17:40.906087 139881799980800 logging_writer.py:48] [331100] global_step=331100, grad_norm=3.1395530700683594, loss=1.1470588445663452
I0304 07:18:25.299649 139881808373504 logging_writer.py:48] [331200] global_step=331200, grad_norm=2.9188671112060547, loss=1.8256486654281616
I0304 07:19:09.868148 139881799980800 logging_writer.py:48] [331300] global_step=331300, grad_norm=3.047828197479248, loss=1.1422299146652222
I0304 07:19:54.191820 139881808373504 logging_writer.py:48] [331400] global_step=331400, grad_norm=3.140890598297119, loss=2.0631771087646484
I0304 07:20:38.669062 139881799980800 logging_writer.py:48] [331500] global_step=331500, grad_norm=3.0196456909179688, loss=1.113839864730835
I0304 07:21:23.196924 139881808373504 logging_writer.py:48] [331600] global_step=331600, grad_norm=3.1179442405700684, loss=1.7827192544937134
I0304 07:22:05.523799 140077943854912 spec.py:321] Evaluating on the training split.
I0304 07:22:15.743259 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 07:22:49.862733 140077943854912 spec.py:349] Evaluating on the test split.
I0304 07:22:51.441462 140077943854912 submission_runner.py:411] Time since start: 159364.25s, 	Step: 331697, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.4124229848384857, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 145820.2736287117, 'total_duration': 159364.24648237228, 'accumulated_submission_time': 145820.2736287117, 'accumulated_eval_time': 13504.289674520493, 'accumulated_logging_time': 22.39159369468689}
I0304 07:22:51.513931 139881799980800 logging_writer.py:48] [331697] accumulated_eval_time=13504.289675, accumulated_logging_time=22.391594, accumulated_submission_time=145820.273629, global_step=331697, preemption_count=0, score=145820.273629, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=159364.246482, train/accuracy=0.889570, train/loss=0.412423, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:22:53.074776 139881808373504 logging_writer.py:48] [331700] global_step=331700, grad_norm=3.173089027404785, loss=1.1604478359222412
I0304 07:23:33.221080 139881799980800 logging_writer.py:48] [331800] global_step=331800, grad_norm=3.132063627243042, loss=2.4240808486938477
I0304 07:24:17.503996 139881808373504 logging_writer.py:48] [331900] global_step=331900, grad_norm=2.9541444778442383, loss=1.9938490390777588
I0304 07:25:02.090111 139881799980800 logging_writer.py:48] [332000] global_step=332000, grad_norm=3.2517905235290527, loss=1.1338714361190796
I0304 07:25:47.573861 139881808373504 logging_writer.py:48] [332100] global_step=332100, grad_norm=3.7189316749572754, loss=3.299933671951294
I0304 07:26:32.158176 139881799980800 logging_writer.py:48] [332200] global_step=332200, grad_norm=3.259777307510376, loss=1.3734477758407593
I0304 07:27:16.801385 139881808373504 logging_writer.py:48] [332300] global_step=332300, grad_norm=2.942638635635376, loss=1.5741026401519775
I0304 07:28:00.934178 139881799980800 logging_writer.py:48] [332400] global_step=332400, grad_norm=3.106764793395996, loss=1.1757380962371826
I0304 07:28:45.230453 139881808373504 logging_writer.py:48] [332500] global_step=332500, grad_norm=3.0699758529663086, loss=1.290142297744751
I0304 07:29:29.716341 139881799980800 logging_writer.py:48] [332600] global_step=332600, grad_norm=3.282382011413574, loss=1.1986353397369385
I0304 07:29:51.635479 140077943854912 spec.py:321] Evaluating on the training split.
I0304 07:30:01.785977 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 07:30:37.008804 140077943854912 spec.py:349] Evaluating on the test split.
I0304 07:30:38.607758 140077943854912 submission_runner.py:411] Time since start: 159831.41s, 	Step: 332651, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.41325175762176514, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 146240.3351507187, 'total_duration': 159831.4127779007, 'accumulated_submission_time': 146240.3351507187, 'accumulated_eval_time': 13551.26194858551, 'accumulated_logging_time': 22.474181175231934}
I0304 07:30:38.674525 139881808373504 logging_writer.py:48] [332651] accumulated_eval_time=13551.261949, accumulated_logging_time=22.474181, accumulated_submission_time=146240.335151, global_step=332651, preemption_count=0, score=146240.335151, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=159831.412778, train/accuracy=0.888340, train/loss=0.413252, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:30:58.183726 139881799980800 logging_writer.py:48] [332700] global_step=332700, grad_norm=3.226206064224243, loss=2.1004316806793213
I0304 07:31:40.668903 139881808373504 logging_writer.py:48] [332800] global_step=332800, grad_norm=3.0850703716278076, loss=1.058729887008667
I0304 07:32:24.985271 139881799980800 logging_writer.py:48] [332900] global_step=332900, grad_norm=2.9241943359375, loss=1.8425123691558838
I0304 07:33:09.326575 139881808373504 logging_writer.py:48] [333000] global_step=333000, grad_norm=2.991316080093384, loss=1.1038057804107666
I0304 07:33:53.487167 139881799980800 logging_writer.py:48] [333100] global_step=333100, grad_norm=3.67191743850708, loss=3.256263256072998
I0304 07:34:37.850191 139881808373504 logging_writer.py:48] [333200] global_step=333200, grad_norm=3.2933404445648193, loss=1.1875654458999634
I0304 07:35:22.430644 139881799980800 logging_writer.py:48] [333300] global_step=333300, grad_norm=4.252702236175537, loss=3.194521427154541
I0304 07:36:07.242068 139881808373504 logging_writer.py:48] [333400] global_step=333400, grad_norm=3.146695852279663, loss=1.1368707418441772
I0304 07:36:51.513019 139881799980800 logging_writer.py:48] [333500] global_step=333500, grad_norm=3.3804385662078857, loss=2.608065366744995
I0304 07:37:35.737189 139881808373504 logging_writer.py:48] [333600] global_step=333600, grad_norm=3.0092554092407227, loss=2.359447479248047
I0304 07:37:38.943604 140077943854912 spec.py:321] Evaluating on the training split.
I0304 07:37:50.181802 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 07:38:23.978083 140077943854912 spec.py:349] Evaluating on the test split.
I0304 07:38:25.565613 140077943854912 submission_runner.py:411] Time since start: 160298.37s, 	Step: 333609, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.41458216309547424, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 146660.5423769951, 'total_duration': 160298.3706278801, 'accumulated_submission_time': 146660.5423769951, 'accumulated_eval_time': 13597.88392996788, 'accumulated_logging_time': 22.552911043167114}
I0304 07:38:25.630587 139881799980800 logging_writer.py:48] [333609] accumulated_eval_time=13597.883930, accumulated_logging_time=22.552911, accumulated_submission_time=146660.542377, global_step=333609, preemption_count=0, score=146660.542377, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=160298.370628, train/accuracy=0.888379, train/loss=0.414582, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:39:01.842311 139881808373504 logging_writer.py:48] [333700] global_step=333700, grad_norm=3.2878637313842773, loss=1.141481876373291
I0304 07:39:45.870309 139881799980800 logging_writer.py:48] [333800] global_step=333800, grad_norm=3.7706918716430664, loss=1.1948877573013306
I0304 07:40:30.331059 139881808373504 logging_writer.py:48] [333900] global_step=333900, grad_norm=3.3665695190429688, loss=1.1875011920928955
I0304 07:41:14.991098 139881799980800 logging_writer.py:48] [334000] global_step=334000, grad_norm=3.3721799850463867, loss=1.361053228378296
I0304 07:41:59.160090 139881808373504 logging_writer.py:48] [334100] global_step=334100, grad_norm=3.652707576751709, loss=3.2877187728881836
I0304 07:42:43.891428 139881799980800 logging_writer.py:48] [334200] global_step=334200, grad_norm=3.2248218059539795, loss=2.522022008895874
I0304 07:43:28.233344 139881808373504 logging_writer.py:48] [334300] global_step=334300, grad_norm=4.083005428314209, loss=1.1848868131637573
I0304 07:44:12.633538 139881799980800 logging_writer.py:48] [334400] global_step=334400, grad_norm=3.0838844776153564, loss=1.115321397781372
I0304 07:44:56.937324 139881808373504 logging_writer.py:48] [334500] global_step=334500, grad_norm=3.033816337585449, loss=1.2053769826889038
I0304 07:45:25.959191 140077943854912 spec.py:321] Evaluating on the training split.
I0304 07:45:36.415481 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 07:46:12.546658 140077943854912 spec.py:349] Evaluating on the test split.
I0304 07:46:14.125765 140077943854912 submission_runner.py:411] Time since start: 160766.93s, 	Step: 334567, 	{'train/accuracy': 0.8887499570846558, 'train/loss': 0.4145262539386749, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 147080.81252145767, 'total_duration': 160766.93076348305, 'accumulated_submission_time': 147080.81252145767, 'accumulated_eval_time': 13646.050462961197, 'accumulated_logging_time': 22.62759017944336}
I0304 07:46:14.194146 139881799980800 logging_writer.py:48] [334567] accumulated_eval_time=13646.050463, accumulated_logging_time=22.627590, accumulated_submission_time=147080.812521, global_step=334567, preemption_count=0, score=147080.812521, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=160766.930763, train/accuracy=0.888750, train/loss=0.414526, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:46:27.621918 139881808373504 logging_writer.py:48] [334600] global_step=334600, grad_norm=3.170318841934204, loss=1.0922338962554932
I0304 07:47:09.574708 139881799980800 logging_writer.py:48] [334700] global_step=334700, grad_norm=2.839839220046997, loss=1.3163349628448486
I0304 07:47:54.066408 139881808373504 logging_writer.py:48] [334800] global_step=334800, grad_norm=2.957477331161499, loss=1.547865867614746
I0304 07:48:38.803119 139881799980800 logging_writer.py:48] [334900] global_step=334900, grad_norm=2.90761661529541, loss=1.154998779296875
I0304 07:49:23.098988 139881808373504 logging_writer.py:48] [335000] global_step=335000, grad_norm=3.2670345306396484, loss=1.3514714241027832
I0304 07:50:07.560005 139881799980800 logging_writer.py:48] [335100] global_step=335100, grad_norm=3.227593421936035, loss=1.1693449020385742
I0304 07:50:51.923974 139881808373504 logging_writer.py:48] [335200] global_step=335200, grad_norm=3.0675299167633057, loss=1.042178750038147
I0304 07:51:36.633328 139881799980800 logging_writer.py:48] [335300] global_step=335300, grad_norm=3.323486566543579, loss=1.1211729049682617
I0304 07:52:21.242465 139881808373504 logging_writer.py:48] [335400] global_step=335400, grad_norm=3.321760416030884, loss=1.161765456199646
I0304 07:53:05.718168 139881799980800 logging_writer.py:48] [335500] global_step=335500, grad_norm=2.920668363571167, loss=1.0204582214355469
I0304 07:53:14.322054 140077943854912 spec.py:321] Evaluating on the training split.
I0304 07:53:24.683087 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 07:53:48.071327 140077943854912 spec.py:349] Evaluating on the test split.
I0304 07:53:49.660293 140077943854912 submission_runner.py:411] Time since start: 161222.47s, 	Step: 335521, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.4150673449039459, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 147500.88044071198, 'total_duration': 161222.46529269218, 'accumulated_submission_time': 147500.88044071198, 'accumulated_eval_time': 13681.3886988163, 'accumulated_logging_time': 22.70599865913391}
I0304 07:53:49.739799 139881808373504 logging_writer.py:48] [335521] accumulated_eval_time=13681.388699, accumulated_logging_time=22.705999, accumulated_submission_time=147500.880441, global_step=335521, preemption_count=0, score=147500.880441, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=161222.465293, train/accuracy=0.887734, train/loss=0.415067, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 07:54:22.542142 139881799980800 logging_writer.py:48] [335600] global_step=335600, grad_norm=2.9821743965148926, loss=1.0427497625350952
I0304 07:55:07.763733 139881808373504 logging_writer.py:48] [335700] global_step=335700, grad_norm=3.177664041519165, loss=1.5917528867721558
I0304 07:55:53.217571 139881799980800 logging_writer.py:48] [335800] global_step=335800, grad_norm=3.0884833335876465, loss=1.1276829242706299
I0304 07:56:38.592937 139881808373504 logging_writer.py:48] [335900] global_step=335900, grad_norm=3.059507131576538, loss=1.173819899559021
I0304 07:57:23.923351 139881799980800 logging_writer.py:48] [336000] global_step=336000, grad_norm=3.326840877532959, loss=1.1822696924209595
I0304 07:58:09.424590 139881808373504 logging_writer.py:48] [336100] global_step=336100, grad_norm=3.3282275199890137, loss=2.1941661834716797
I0304 07:58:54.580812 139881799980800 logging_writer.py:48] [336200] global_step=336200, grad_norm=4.088238716125488, loss=3.1732401847839355
I0304 07:59:39.907195 139881808373504 logging_writer.py:48] [336300] global_step=336300, grad_norm=3.4596474170684814, loss=3.061553716659546
I0304 08:00:25.457670 139881799980800 logging_writer.py:48] [336400] global_step=336400, grad_norm=3.0862717628479004, loss=1.1931365728378296
I0304 08:00:49.951648 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:01:00.746466 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:01:30.015933 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:01:31.598199 140077943854912 submission_runner.py:411] Time since start: 161684.40s, 	Step: 336456, 	{'train/accuracy': 0.8890820145606995, 'train/loss': 0.41309264302253723, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 147921.03347206116, 'total_duration': 161684.40320611, 'accumulated_submission_time': 147921.03347206116, 'accumulated_eval_time': 13723.035228729248, 'accumulated_logging_time': 22.796302795410156}
I0304 08:01:31.681074 139881808373504 logging_writer.py:48] [336456] accumulated_eval_time=13723.035229, accumulated_logging_time=22.796303, accumulated_submission_time=147921.033472, global_step=336456, preemption_count=0, score=147921.033472, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=161684.403206, train/accuracy=0.889082, train/loss=0.413093, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:01:49.311327 139881799980800 logging_writer.py:48] [336500] global_step=336500, grad_norm=3.129821538925171, loss=1.1933495998382568
I0304 08:02:32.705439 139881808373504 logging_writer.py:48] [336600] global_step=336600, grad_norm=3.7297136783599854, loss=2.6175081729888916
I0304 08:03:17.268990 139881799980800 logging_writer.py:48] [336700] global_step=336700, grad_norm=3.096050262451172, loss=1.4664232730865479
I0304 08:04:02.035570 139881808373504 logging_writer.py:48] [336800] global_step=336800, grad_norm=3.2645070552825928, loss=1.128575086593628
I0304 08:04:46.506197 139881799980800 logging_writer.py:48] [336900] global_step=336900, grad_norm=3.659574031829834, loss=3.2666494846343994
I0304 08:05:31.349000 139881808373504 logging_writer.py:48] [337000] global_step=337000, grad_norm=3.9430735111236572, loss=3.16776967048645
I0304 08:06:16.088557 139881799980800 logging_writer.py:48] [337100] global_step=337100, grad_norm=3.2634997367858887, loss=2.789928674697876
I0304 08:07:00.505464 139881808373504 logging_writer.py:48] [337200] global_step=337200, grad_norm=3.024360418319702, loss=2.4182865619659424
I0304 08:07:45.012953 139881799980800 logging_writer.py:48] [337300] global_step=337300, grad_norm=3.9369614124298096, loss=3.2934112548828125
I0304 08:08:29.517635 139881808373504 logging_writer.py:48] [337400] global_step=337400, grad_norm=3.5462265014648438, loss=3.197537660598755
I0304 08:08:31.825474 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:08:41.592344 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:09:11.693460 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:09:13.278672 140077943854912 submission_runner.py:411] Time since start: 162146.08s, 	Step: 337407, 	{'train/accuracy': 0.88671875, 'train/loss': 0.42383280396461487, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 148341.1167113781, 'total_duration': 162146.08368301392, 'accumulated_submission_time': 148341.1167113781, 'accumulated_eval_time': 13764.488429307938, 'accumulated_logging_time': 22.89143419265747}
I0304 08:09:13.361639 139881799980800 logging_writer.py:48] [337407] accumulated_eval_time=13764.488429, accumulated_logging_time=22.891434, accumulated_submission_time=148341.116711, global_step=337407, preemption_count=0, score=148341.116711, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=162146.083683, train/accuracy=0.886719, train/loss=0.423833, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:09:51.183726 139881808373504 logging_writer.py:48] [337500] global_step=337500, grad_norm=2.884321689605713, loss=1.0482475757598877
I0304 08:10:35.393530 139881799980800 logging_writer.py:48] [337600] global_step=337600, grad_norm=3.1686766147613525, loss=1.1051610708236694
I0304 08:11:19.781563 139881808373504 logging_writer.py:48] [337700] global_step=337700, grad_norm=3.1837470531463623, loss=2.480820655822754
I0304 08:12:04.704836 139881799980800 logging_writer.py:48] [337800] global_step=337800, grad_norm=3.2997608184814453, loss=1.1711232662200928
I0304 08:12:48.812881 139881808373504 logging_writer.py:48] [337900] global_step=337900, grad_norm=3.1171257495880127, loss=1.1888777017593384
I0304 08:13:33.171798 139881799980800 logging_writer.py:48] [338000] global_step=338000, grad_norm=3.3338420391082764, loss=2.6556830406188965
I0304 08:14:17.325438 139881808373504 logging_writer.py:48] [338100] global_step=338100, grad_norm=3.28238582611084, loss=1.0997611284255981
I0304 08:15:01.429207 139881799980800 logging_writer.py:48] [338200] global_step=338200, grad_norm=3.260145664215088, loss=1.224568247795105
I0304 08:15:46.151630 139881808373504 logging_writer.py:48] [338300] global_step=338300, grad_norm=3.2276837825775146, loss=1.1822584867477417
I0304 08:16:13.418878 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:16:23.585212 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:16:52.130963 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:16:53.720587 140077943854912 submission_runner.py:411] Time since start: 162606.53s, 	Step: 338363, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.41459426283836365, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 148761.1108095646, 'total_duration': 162606.52558994293, 'accumulated_submission_time': 148761.1108095646, 'accumulated_eval_time': 13804.790137529373, 'accumulated_logging_time': 22.987659454345703}
I0304 08:16:53.805616 139881799980800 logging_writer.py:48] [338363] accumulated_eval_time=13804.790138, accumulated_logging_time=22.987659, accumulated_submission_time=148761.110810, global_step=338363, preemption_count=0, score=148761.110810, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=162606.525590, train/accuracy=0.888320, train/loss=0.414594, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:17:08.707162 139881808373504 logging_writer.py:48] [338400] global_step=338400, grad_norm=3.174748182296753, loss=1.2238646745681763
I0304 08:17:51.337014 139881799980800 logging_writer.py:48] [338500] global_step=338500, grad_norm=3.355299949645996, loss=1.1342322826385498
I0304 08:18:35.659049 139881808373504 logging_writer.py:48] [338600] global_step=338600, grad_norm=3.201744556427002, loss=1.1634550094604492
I0304 08:19:20.315681 139881799980800 logging_writer.py:48] [338700] global_step=338700, grad_norm=3.3400185108184814, loss=1.3712351322174072
I0304 08:20:04.422869 139881808373504 logging_writer.py:48] [338800] global_step=338800, grad_norm=4.1008172035217285, loss=2.9262313842773438
I0304 08:20:48.886480 139881799980800 logging_writer.py:48] [338900] global_step=338900, grad_norm=3.2254788875579834, loss=1.124100923538208
I0304 08:21:33.513118 139881808373504 logging_writer.py:48] [339000] global_step=339000, grad_norm=3.081117868423462, loss=2.245910406112671
I0304 08:22:17.952342 139881799980800 logging_writer.py:48] [339100] global_step=339100, grad_norm=2.9151883125305176, loss=1.1262298822402954
I0304 08:23:02.522810 139881808373504 logging_writer.py:48] [339200] global_step=339200, grad_norm=3.0603201389312744, loss=1.0954759120941162
I0304 08:23:46.982685 139881799980800 logging_writer.py:48] [339300] global_step=339300, grad_norm=3.282278299331665, loss=2.884474754333496
I0304 08:23:53.739573 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:24:04.401489 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:24:33.636230 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:24:35.224674 140077943854912 submission_runner.py:411] Time since start: 163068.03s, 	Step: 339317, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.42129674553871155, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 149180.98473072052, 'total_duration': 163068.02965641022, 'accumulated_submission_time': 149180.98473072052, 'accumulated_eval_time': 13846.275179386139, 'accumulated_logging_time': 23.083512544631958}
I0304 08:24:35.336694 139881808373504 logging_writer.py:48] [339317] accumulated_eval_time=13846.275179, accumulated_logging_time=23.083513, accumulated_submission_time=149180.984731, global_step=339317, preemption_count=0, score=149180.984731, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=163068.029656, train/accuracy=0.887598, train/loss=0.421297, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:25:09.107837 139881799980800 logging_writer.py:48] [339400] global_step=339400, grad_norm=3.2371184825897217, loss=1.880647897720337
I0304 08:25:53.041760 139881808373504 logging_writer.py:48] [339500] global_step=339500, grad_norm=3.2034032344818115, loss=1.1744372844696045
I0304 08:26:37.825324 139881799980800 logging_writer.py:48] [339600] global_step=339600, grad_norm=3.069664716720581, loss=2.6746134757995605
I0304 08:27:22.169234 139881808373504 logging_writer.py:48] [339700] global_step=339700, grad_norm=2.9952406883239746, loss=2.1420352458953857
I0304 08:28:06.479121 139881799980800 logging_writer.py:48] [339800] global_step=339800, grad_norm=2.986638307571411, loss=1.5855095386505127
I0304 08:28:50.913100 139881808373504 logging_writer.py:48] [339900] global_step=339900, grad_norm=3.1074466705322266, loss=1.0613185167312622
I0304 08:29:35.211269 139881799980800 logging_writer.py:48] [340000] global_step=340000, grad_norm=3.318162441253662, loss=2.787374496459961
I0304 08:30:19.630984 139881808373504 logging_writer.py:48] [340100] global_step=340100, grad_norm=2.883197069168091, loss=1.0243223905563354
I0304 08:31:04.136758 139881799980800 logging_writer.py:48] [340200] global_step=340200, grad_norm=3.6459801197052, loss=3.206198215484619
I0304 08:31:35.338696 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:31:45.623715 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:32:11.525549 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:32:13.113303 140077943854912 submission_runner.py:411] Time since start: 163525.92s, 	Step: 340272, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.4158148467540741, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 149600.92562270164, 'total_duration': 163525.91829109192, 'accumulated_submission_time': 149600.92562270164, 'accumulated_eval_time': 13884.049741983414, 'accumulated_logging_time': 23.206378698349}
I0304 08:32:13.194644 139881808373504 logging_writer.py:48] [340272] accumulated_eval_time=13884.049742, accumulated_logging_time=23.206379, accumulated_submission_time=149600.925623, global_step=340272, preemption_count=0, score=149600.925623, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=163525.918291, train/accuracy=0.887676, train/loss=0.415815, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:32:24.515755 139881799980800 logging_writer.py:48] [340300] global_step=340300, grad_norm=3.6584665775299072, loss=3.0789194107055664
I0304 08:33:06.543713 139881808373504 logging_writer.py:48] [340400] global_step=340400, grad_norm=4.166897773742676, loss=3.2578587532043457
I0304 08:33:51.049956 139881799980800 logging_writer.py:48] [340500] global_step=340500, grad_norm=3.2102696895599365, loss=1.153583288192749
I0304 08:34:35.656910 139881808373504 logging_writer.py:48] [340600] global_step=340600, grad_norm=3.098297119140625, loss=2.4475173950195312
I0304 08:35:19.909537 139881799980800 logging_writer.py:48] [340700] global_step=340700, grad_norm=3.764840602874756, loss=2.7913129329681396
I0304 08:36:04.599620 139881808373504 logging_writer.py:48] [340800] global_step=340800, grad_norm=3.066194772720337, loss=1.0664703845977783
I0304 08:36:48.737011 139881799980800 logging_writer.py:48] [340900] global_step=340900, grad_norm=3.053377628326416, loss=1.1567976474761963
I0304 08:37:33.012926 139881808373504 logging_writer.py:48] [341000] global_step=341000, grad_norm=3.024766445159912, loss=1.3776721954345703
I0304 08:38:17.499562 139881799980800 logging_writer.py:48] [341100] global_step=341100, grad_norm=3.1597306728363037, loss=1.0778363943099976
I0304 08:39:02.074230 139881808373504 logging_writer.py:48] [341200] global_step=341200, grad_norm=3.079590320587158, loss=1.6606998443603516
I0304 08:39:13.393329 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:39:23.508370 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:39:53.926937 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:39:55.518265 140077943854912 submission_runner.py:411] Time since start: 163988.32s, 	Step: 341227, 	{'train/accuracy': 0.8883007764816284, 'train/loss': 0.4141983985900879, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 150021.06316399574, 'total_duration': 163988.32326960564, 'accumulated_submission_time': 150021.06316399574, 'accumulated_eval_time': 13926.174630880356, 'accumulated_logging_time': 23.29926109313965}
I0304 08:39:55.600795 139881799980800 logging_writer.py:48] [341227] accumulated_eval_time=13926.174631, accumulated_logging_time=23.299261, accumulated_submission_time=150021.063164, global_step=341227, preemption_count=0, score=150021.063164, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=163988.323270, train/accuracy=0.888301, train/loss=0.414198, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:40:24.518740 139881808373504 logging_writer.py:48] [341300] global_step=341300, grad_norm=3.1508398056030273, loss=1.220058798789978
I0304 08:41:08.630682 139881799980800 logging_writer.py:48] [341400] global_step=341400, grad_norm=3.1328125, loss=1.1382777690887451
I0304 08:41:53.180962 139881808373504 logging_writer.py:48] [341500] global_step=341500, grad_norm=3.0625650882720947, loss=0.9600744247436523
I0304 08:42:37.923012 139881799980800 logging_writer.py:48] [341600] global_step=341600, grad_norm=3.026970863342285, loss=1.5836637020111084
I0304 08:43:22.177870 139881808373504 logging_writer.py:48] [341700] global_step=341700, grad_norm=2.9389970302581787, loss=2.4385623931884766
I0304 08:44:06.692827 139881799980800 logging_writer.py:48] [341800] global_step=341800, grad_norm=3.775383710861206, loss=2.8811757564544678
I0304 08:44:50.904253 139881808373504 logging_writer.py:48] [341900] global_step=341900, grad_norm=3.2653417587280273, loss=2.2896273136138916
I0304 08:45:35.198261 139881799980800 logging_writer.py:48] [342000] global_step=342000, grad_norm=3.8174688816070557, loss=3.2338507175445557
I0304 08:46:19.770480 139881808373504 logging_writer.py:48] [342100] global_step=342100, grad_norm=3.565011739730835, loss=3.0367109775543213
I0304 08:46:55.736922 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:47:05.900920 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:47:34.859701 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:47:36.451745 140077943854912 submission_runner.py:411] Time since start: 164449.26s, 	Step: 342183, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.41547891497612, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 150441.1364018917, 'total_duration': 164449.25674581528, 'accumulated_submission_time': 150441.1364018917, 'accumulated_eval_time': 13966.889407157898, 'accumulated_logging_time': 23.39518094062805}
I0304 08:47:36.538059 139881799980800 logging_writer.py:48] [342183] accumulated_eval_time=13966.889407, accumulated_logging_time=23.395181, accumulated_submission_time=150441.136402, global_step=342183, preemption_count=0, score=150441.136402, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=164449.256746, train/accuracy=0.889570, train/loss=0.415479, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:47:43.576939 139881808373504 logging_writer.py:48] [342200] global_step=342200, grad_norm=3.013723611831665, loss=1.278071403503418
I0304 08:48:25.005706 139881799980800 logging_writer.py:48] [342300] global_step=342300, grad_norm=3.360812187194824, loss=1.170688509941101
I0304 08:49:09.149638 139881808373504 logging_writer.py:48] [342400] global_step=342400, grad_norm=3.219438076019287, loss=1.1378637552261353
I0304 08:49:53.479680 139881799980800 logging_writer.py:48] [342500] global_step=342500, grad_norm=3.290386438369751, loss=1.7723138332366943
I0304 08:50:38.036597 139881808373504 logging_writer.py:48] [342600] global_step=342600, grad_norm=3.1236538887023926, loss=1.1460039615631104
I0304 08:51:22.488796 139881799980800 logging_writer.py:48] [342700] global_step=342700, grad_norm=3.218397855758667, loss=1.0917861461639404
I0304 08:52:06.990171 139881808373504 logging_writer.py:48] [342800] global_step=342800, grad_norm=3.125690221786499, loss=2.5497398376464844
I0304 08:52:51.150703 139881799980800 logging_writer.py:48] [342900] global_step=342900, grad_norm=2.9075515270233154, loss=0.987183690071106
I0304 08:53:35.516515 139881808373504 logging_writer.py:48] [343000] global_step=343000, grad_norm=3.327979326248169, loss=1.1772139072418213
I0304 08:54:19.783919 139881799980800 logging_writer.py:48] [343100] global_step=343100, grad_norm=4.374722480773926, loss=3.2833099365234375
I0304 08:54:36.690510 140077943854912 spec.py:321] Evaluating on the training split.
I0304 08:54:46.855453 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 08:55:20.979896 140077943854912 spec.py:349] Evaluating on the test split.
I0304 08:55:22.573530 140077943854912 submission_runner.py:411] Time since start: 164915.38s, 	Step: 343140, 	{'train/accuracy': 0.8856054544448853, 'train/loss': 0.4266979992389679, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 150861.22448587418, 'total_duration': 164915.37854075432, 'accumulated_submission_time': 150861.22448587418, 'accumulated_eval_time': 14012.772404670715, 'accumulated_logging_time': 23.496416807174683}
I0304 08:55:22.643398 139881808373504 logging_writer.py:48] [343140] accumulated_eval_time=14012.772405, accumulated_logging_time=23.496417, accumulated_submission_time=150861.224486, global_step=343140, preemption_count=0, score=150861.224486, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=164915.378541, train/accuracy=0.885605, train/loss=0.426698, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 08:55:46.436002 139881799980800 logging_writer.py:48] [343200] global_step=343200, grad_norm=3.1010007858276367, loss=2.662296772003174
I0304 08:56:29.379464 139881808373504 logging_writer.py:48] [343300] global_step=343300, grad_norm=2.805666923522949, loss=1.4021532535552979
I0304 08:57:13.854820 139881799980800 logging_writer.py:48] [343400] global_step=343400, grad_norm=2.9319310188293457, loss=1.1431416273117065
I0304 08:57:58.316030 139881808373504 logging_writer.py:48] [343500] global_step=343500, grad_norm=3.083650588989258, loss=1.1245564222335815
I0304 08:58:42.407331 139881799980800 logging_writer.py:48] [343600] global_step=343600, grad_norm=2.97393536567688, loss=1.0562254190444946
I0304 08:59:26.883610 139881808373504 logging_writer.py:48] [343700] global_step=343700, grad_norm=3.384751796722412, loss=2.5917365550994873
I0304 09:00:11.404411 139881799980800 logging_writer.py:48] [343800] global_step=343800, grad_norm=3.0923573970794678, loss=1.1352332830429077
I0304 09:00:55.873274 139881808373504 logging_writer.py:48] [343900] global_step=343900, grad_norm=3.212247610092163, loss=2.6568400859832764
I0304 09:01:40.268956 139881799980800 logging_writer.py:48] [344000] global_step=344000, grad_norm=3.2960705757141113, loss=1.2082433700561523
I0304 09:02:22.779936 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:02:33.122894 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:02:59.582665 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:03:01.169118 140077943854912 submission_runner.py:411] Time since start: 165373.97s, 	Step: 344097, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.41987913846969604, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 151281.30113005638, 'total_duration': 165373.97410154343, 'accumulated_submission_time': 151281.30113005638, 'accumulated_eval_time': 14051.161545276642, 'accumulated_logging_time': 23.57652187347412}
I0304 09:03:01.251895 139881808373504 logging_writer.py:48] [344097] accumulated_eval_time=14051.161545, accumulated_logging_time=23.576522, accumulated_submission_time=151281.301130, global_step=344097, preemption_count=0, score=151281.301130, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=165373.974102, train/accuracy=0.886738, train/loss=0.419879, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:03:02.832686 139881799980800 logging_writer.py:48] [344100] global_step=344100, grad_norm=4.196565628051758, loss=1.1796398162841797
I0304 09:03:43.845923 139881808373504 logging_writer.py:48] [344200] global_step=344200, grad_norm=3.202854633331299, loss=1.1820018291473389
I0304 09:04:28.286033 139881799980800 logging_writer.py:48] [344300] global_step=344300, grad_norm=2.7333643436431885, loss=1.255750060081482
I0304 09:05:12.692485 139881808373504 logging_writer.py:48] [344400] global_step=344400, grad_norm=3.879368543624878, loss=3.115659236907959
I0304 09:05:56.865782 139881799980800 logging_writer.py:48] [344500] global_step=344500, grad_norm=3.010983943939209, loss=1.688026785850525
I0304 09:06:41.806113 139881808373504 logging_writer.py:48] [344600] global_step=344600, grad_norm=3.4125657081604004, loss=2.974763870239258
I0304 09:07:26.457404 139881799980800 logging_writer.py:48] [344700] global_step=344700, grad_norm=2.960549831390381, loss=1.1284819841384888
I0304 09:08:10.943712 139881808373504 logging_writer.py:48] [344800] global_step=344800, grad_norm=3.3485045433044434, loss=1.311332106590271
I0304 09:08:55.282016 139881799980800 logging_writer.py:48] [344900] global_step=344900, grad_norm=3.3812427520751953, loss=2.923269748687744
I0304 09:09:39.706373 139881808373504 logging_writer.py:48] [345000] global_step=345000, grad_norm=3.2013111114501953, loss=1.110430121421814
I0304 09:10:01.558439 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:10:12.123189 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:10:44.015825 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:10:45.606600 140077943854912 submission_runner.py:411] Time since start: 165838.41s, 	Step: 345051, 	{'train/accuracy': 0.8881250023841858, 'train/loss': 0.4131699800491333, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 151701.54492998123, 'total_duration': 165838.41160845757, 'accumulated_submission_time': 151701.54492998123, 'accumulated_eval_time': 14095.20967411995, 'accumulated_logging_time': 23.672836303710938}
I0304 09:10:45.691724 139881799980800 logging_writer.py:48] [345051] accumulated_eval_time=14095.209674, accumulated_logging_time=23.672836, accumulated_submission_time=151701.544930, global_step=345051, preemption_count=0, score=151701.544930, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=165838.411608, train/accuracy=0.888125, train/loss=0.413170, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:11:05.214140 139881808373504 logging_writer.py:48] [345100] global_step=345100, grad_norm=3.2738730907440186, loss=1.1590982675552368
I0304 09:11:48.368932 139881799980800 logging_writer.py:48] [345200] global_step=345200, grad_norm=3.0300986766815186, loss=1.3589876890182495
I0304 09:12:33.172442 139881808373504 logging_writer.py:48] [345300] global_step=345300, grad_norm=2.980487585067749, loss=2.3648226261138916
I0304 09:13:17.928208 139881799980800 logging_writer.py:48] [345400] global_step=345400, grad_norm=2.9546337127685547, loss=2.1011924743652344
I0304 09:14:02.174129 139881808373504 logging_writer.py:48] [345500] global_step=345500, grad_norm=4.409188270568848, loss=3.1899380683898926
I0304 09:14:46.714738 139881799980800 logging_writer.py:48] [345600] global_step=345600, grad_norm=3.370163679122925, loss=1.1486327648162842
I0304 09:15:31.279749 139881808373504 logging_writer.py:48] [345700] global_step=345700, grad_norm=3.157578706741333, loss=1.123134732246399
I0304 09:16:16.044460 139881799980800 logging_writer.py:48] [345800] global_step=345800, grad_norm=4.089359760284424, loss=3.1324586868286133
I0304 09:17:00.845752 139881808373504 logging_writer.py:48] [345900] global_step=345900, grad_norm=3.0685245990753174, loss=1.1141139268875122
I0304 09:17:45.726528 139881799980800 logging_writer.py:48] [346000] global_step=346000, grad_norm=3.7583138942718506, loss=2.7145655155181885
I0304 09:17:45.745187 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:17:55.805739 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:18:27.896953 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:18:29.492054 140077943854912 submission_runner.py:411] Time since start: 166302.30s, 	Step: 346001, 	{'train/accuracy': 0.8878905773162842, 'train/loss': 0.41522708535194397, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 152121.5381603241, 'total_duration': 166302.2970738411, 'accumulated_submission_time': 152121.5381603241, 'accumulated_eval_time': 14138.956525087357, 'accumulated_logging_time': 23.768434286117554}
I0304 09:18:29.560152 139881808373504 logging_writer.py:48] [346001] accumulated_eval_time=14138.956525, accumulated_logging_time=23.768434, accumulated_submission_time=152121.538160, global_step=346001, preemption_count=0, score=152121.538160, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=166302.297074, train/accuracy=0.887891, train/loss=0.415227, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:19:09.481222 139881799980800 logging_writer.py:48] [346100] global_step=346100, grad_norm=3.4513165950775146, loss=1.6578071117401123
I0304 09:19:53.611872 139881808373504 logging_writer.py:48] [346200] global_step=346200, grad_norm=3.2663443088531494, loss=2.8021278381347656
I0304 09:20:38.454413 139881799980800 logging_writer.py:48] [346300] global_step=346300, grad_norm=3.2261252403259277, loss=1.4708799123764038
I0304 09:21:23.113769 139881808373504 logging_writer.py:48] [346400] global_step=346400, grad_norm=3.1942925453186035, loss=2.568565845489502
I0304 09:22:07.476688 139881799980800 logging_writer.py:48] [346500] global_step=346500, grad_norm=3.2657341957092285, loss=1.222963809967041
I0304 09:22:51.920052 139881808373504 logging_writer.py:48] [346600] global_step=346600, grad_norm=3.2578561305999756, loss=1.0516523122787476
I0304 09:23:36.490671 139881799980800 logging_writer.py:48] [346700] global_step=346700, grad_norm=3.007587194442749, loss=1.8365586996078491
I0304 09:24:20.792760 139881808373504 logging_writer.py:48] [346800] global_step=346800, grad_norm=3.0622975826263428, loss=1.1723482608795166
I0304 09:25:05.481241 139881799980800 logging_writer.py:48] [346900] global_step=346900, grad_norm=3.0599803924560547, loss=1.5263004302978516
I0304 09:25:29.634798 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:25:39.685168 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:26:03.361518 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:26:04.957782 140077943854912 submission_runner.py:411] Time since start: 166757.76s, 	Step: 346956, 	{'train/accuracy': 0.8885155916213989, 'train/loss': 0.42009979486465454, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 152541.55381274223, 'total_duration': 166757.76275634766, 'accumulated_submission_time': 152541.55381274223, 'accumulated_eval_time': 14174.279473781586, 'accumulated_logging_time': 23.846048831939697}
I0304 09:26:05.041910 139881808373504 logging_writer.py:48] [346956] accumulated_eval_time=14174.279474, accumulated_logging_time=23.846049, accumulated_submission_time=152541.553813, global_step=346956, preemption_count=0, score=152541.553813, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=166757.762756, train/accuracy=0.888516, train/loss=0.420100, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:26:22.604742 139881799980800 logging_writer.py:48] [347000] global_step=347000, grad_norm=3.0205307006835938, loss=1.7290563583374023
I0304 09:27:05.791718 139881808373504 logging_writer.py:48] [347100] global_step=347100, grad_norm=3.577657699584961, loss=2.424471378326416
I0304 09:27:50.288111 139881799980800 logging_writer.py:48] [347200] global_step=347200, grad_norm=4.122406959533691, loss=3.2556450366973877
I0304 09:28:34.950159 139881808373504 logging_writer.py:48] [347300] global_step=347300, grad_norm=2.8973920345306396, loss=1.681783676147461
I0304 09:29:19.349897 139881799980800 logging_writer.py:48] [347400] global_step=347400, grad_norm=3.808056116104126, loss=3.2201671600341797
I0304 09:30:03.823330 139881808373504 logging_writer.py:48] [347500] global_step=347500, grad_norm=3.672434091567993, loss=1.1925815343856812
I0304 09:30:47.958073 139881799980800 logging_writer.py:48] [347600] global_step=347600, grad_norm=3.0304388999938965, loss=1.8880605697631836
I0304 09:31:32.595833 139881808373504 logging_writer.py:48] [347700] global_step=347700, grad_norm=3.1513118743896484, loss=1.0645173788070679
I0304 09:32:17.339702 139881799980800 logging_writer.py:48] [347800] global_step=347800, grad_norm=2.9314043521881104, loss=1.0469266176223755
I0304 09:33:01.622165 139881808373504 logging_writer.py:48] [347900] global_step=347900, grad_norm=3.5847394466400146, loss=1.1878492832183838
I0304 09:33:04.996781 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:33:15.241189 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:33:48.409434 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:33:49.997907 140077943854912 submission_runner.py:411] Time since start: 167222.80s, 	Step: 347909, 	{'train/accuracy': 0.8882226347923279, 'train/loss': 0.4179379642009735, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 152961.44713258743, 'total_duration': 167222.80291485786, 'accumulated_submission_time': 152961.44713258743, 'accumulated_eval_time': 14219.28055357933, 'accumulated_logging_time': 23.9422287940979}
I0304 09:33:50.086401 139881799980800 logging_writer.py:48] [347909] accumulated_eval_time=14219.280554, accumulated_logging_time=23.942229, accumulated_submission_time=152961.447133, global_step=347909, preemption_count=0, score=152961.447133, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=167222.802915, train/accuracy=0.888223, train/loss=0.417938, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:34:27.418084 139881808373504 logging_writer.py:48] [348000] global_step=348000, grad_norm=3.3905038833618164, loss=2.932004690170288
I0304 09:35:11.830135 139881799980800 logging_writer.py:48] [348100] global_step=348100, grad_norm=3.4585115909576416, loss=2.604879379272461
I0304 09:35:56.255273 139881808373504 logging_writer.py:48] [348200] global_step=348200, grad_norm=3.455132246017456, loss=1.1506836414337158
I0304 09:36:40.788964 139881799980800 logging_writer.py:48] [348300] global_step=348300, grad_norm=3.109166145324707, loss=1.413427710533142
I0304 09:37:25.302497 139881808373504 logging_writer.py:48] [348400] global_step=348400, grad_norm=3.02117919921875, loss=1.2876617908477783
I0304 09:38:09.880453 139881799980800 logging_writer.py:48] [348500] global_step=348500, grad_norm=2.951733350753784, loss=1.3112961053848267
I0304 09:38:54.008327 139881808373504 logging_writer.py:48] [348600] global_step=348600, grad_norm=3.3240184783935547, loss=1.1803431510925293
I0304 09:39:38.466479 139881799980800 logging_writer.py:48] [348700] global_step=348700, grad_norm=3.2364578247070312, loss=1.0773073434829712
I0304 09:40:22.948562 139881808373504 logging_writer.py:48] [348800] global_step=348800, grad_norm=2.9998550415039062, loss=1.380406141281128
I0304 09:40:50.061339 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:41:00.126957 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:41:29.936204 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:41:31.521406 140077943854912 submission_runner.py:411] Time since start: 167684.33s, 	Step: 348863, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.4202927052974701, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 153381.35877251625, 'total_duration': 167684.3264117241, 'accumulated_submission_time': 153381.35877251625, 'accumulated_eval_time': 14260.740604877472, 'accumulated_logging_time': 24.04466724395752}
I0304 09:41:31.608045 139881799980800 logging_writer.py:48] [348863] accumulated_eval_time=14260.740605, accumulated_logging_time=24.044667, accumulated_submission_time=153381.358773, global_step=348863, preemption_count=0, score=153381.358773, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=167684.326412, train/accuracy=0.886465, train/loss=0.420293, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:41:46.433765 139881808373504 logging_writer.py:48] [348900] global_step=348900, grad_norm=3.837202787399292, loss=3.1360208988189697
I0304 09:42:29.185355 139881799980800 logging_writer.py:48] [349000] global_step=349000, grad_norm=2.999213218688965, loss=1.183584213256836
I0304 09:43:13.868809 139881808373504 logging_writer.py:48] [349100] global_step=349100, grad_norm=3.426036834716797, loss=1.1379637718200684
I0304 09:43:58.007916 139881799980800 logging_writer.py:48] [349200] global_step=349200, grad_norm=3.2556400299072266, loss=1.1456921100616455
I0304 09:44:42.263053 139881808373504 logging_writer.py:48] [349300] global_step=349300, grad_norm=3.7032644748687744, loss=3.006895065307617
I0304 09:45:26.598274 139881799980800 logging_writer.py:48] [349400] global_step=349400, grad_norm=2.9322586059570312, loss=1.3721375465393066
I0304 09:46:11.217940 139881808373504 logging_writer.py:48] [349500] global_step=349500, grad_norm=3.0510926246643066, loss=1.1792476177215576
I0304 09:46:55.761547 139881799980800 logging_writer.py:48] [349600] global_step=349600, grad_norm=3.0407705307006836, loss=1.0929094552993774
I0304 09:47:40.523007 139881808373504 logging_writer.py:48] [349700] global_step=349700, grad_norm=3.364804983139038, loss=1.2345045804977417
I0304 09:48:24.658635 139881799980800 logging_writer.py:48] [349800] global_step=349800, grad_norm=3.2119011878967285, loss=1.1463054418563843
I0304 09:48:31.849385 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:48:42.060371 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:49:10.494883 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:49:12.078607 140077943854912 submission_runner.py:411] Time since start: 168144.88s, 	Step: 349818, 	{'train/accuracy': 0.8893945217132568, 'train/loss': 0.4127410650253296, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 153801.53926444054, 'total_duration': 168144.88361668587, 'accumulated_submission_time': 153801.53926444054, 'accumulated_eval_time': 14300.969812393188, 'accumulated_logging_time': 24.14210081100464}
I0304 09:49:12.162978 139881808373504 logging_writer.py:48] [349818] accumulated_eval_time=14300.969812, accumulated_logging_time=24.142101, accumulated_submission_time=153801.539264, global_step=349818, preemption_count=0, score=153801.539264, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=168144.883617, train/accuracy=0.889395, train/loss=0.412741, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:49:44.820119 139881799980800 logging_writer.py:48] [349900] global_step=349900, grad_norm=3.272808313369751, loss=1.050926685333252
I0304 09:50:28.930638 139881808373504 logging_writer.py:48] [350000] global_step=350000, grad_norm=3.2098031044006348, loss=1.6400628089904785
I0304 09:51:13.325972 139881799980800 logging_writer.py:48] [350100] global_step=350100, grad_norm=3.5843393802642822, loss=3.0206503868103027
I0304 09:51:57.751158 139881808373504 logging_writer.py:48] [350200] global_step=350200, grad_norm=3.351555109024048, loss=2.9072744846343994
I0304 09:52:41.794201 139881799980800 logging_writer.py:48] [350300] global_step=350300, grad_norm=3.283949136734009, loss=2.445646286010742
I0304 09:53:26.521516 139881808373504 logging_writer.py:48] [350400] global_step=350400, grad_norm=3.4717907905578613, loss=3.0356955528259277
I0304 09:54:11.036626 139881799980800 logging_writer.py:48] [350500] global_step=350500, grad_norm=3.5932703018188477, loss=1.2552144527435303
I0304 09:54:55.357310 139881808373504 logging_writer.py:48] [350600] global_step=350600, grad_norm=3.1135873794555664, loss=1.15699303150177
I0304 09:55:39.764179 139881799980800 logging_writer.py:48] [350700] global_step=350700, grad_norm=3.0976529121398926, loss=2.3304123878479004
I0304 09:56:12.367684 140077943854912 spec.py:321] Evaluating on the training split.
I0304 09:56:23.037830 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 09:56:50.542982 140077943854912 spec.py:349] Evaluating on the test split.
I0304 09:56:52.127187 140077943854912 submission_runner.py:411] Time since start: 168604.93s, 	Step: 350775, 	{'train/accuracy': 0.8864843845367432, 'train/loss': 0.4197324514389038, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 154221.6833667755, 'total_duration': 168604.9321911335, 'accumulated_submission_time': 154221.6833667755, 'accumulated_eval_time': 14340.72930598259, 'accumulated_logging_time': 24.237903833389282}
I0304 09:56:52.212851 139881808373504 logging_writer.py:48] [350775] accumulated_eval_time=14340.729306, accumulated_logging_time=24.237904, accumulated_submission_time=154221.683367, global_step=350775, preemption_count=0, score=154221.683367, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=168604.932191, train/accuracy=0.886484, train/loss=0.419732, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 09:57:02.637333 139881799980800 logging_writer.py:48] [350800] global_step=350800, grad_norm=3.228635311126709, loss=1.1732406616210938
I0304 09:57:44.601714 139881808373504 logging_writer.py:48] [350900] global_step=350900, grad_norm=3.236757755279541, loss=1.1608917713165283
I0304 09:58:28.943580 139881799980800 logging_writer.py:48] [351000] global_step=351000, grad_norm=2.887017011642456, loss=1.0423225164413452
I0304 09:59:13.469535 139881808373504 logging_writer.py:48] [351100] global_step=351100, grad_norm=3.10927677154541, loss=2.270263910293579
I0304 09:59:57.659457 139881799980800 logging_writer.py:48] [351200] global_step=351200, grad_norm=2.937809467315674, loss=1.521169662475586
I0304 10:00:42.026464 139881808373504 logging_writer.py:48] [351300] global_step=351300, grad_norm=3.340892791748047, loss=1.1354520320892334
I0304 10:01:26.589734 139881799980800 logging_writer.py:48] [351400] global_step=351400, grad_norm=3.1128714084625244, loss=1.1916648149490356
I0304 10:02:11.123349 139881808373504 logging_writer.py:48] [351500] global_step=351500, grad_norm=3.1259284019470215, loss=2.128197431564331
I0304 10:02:55.588259 139881799980800 logging_writer.py:48] [351600] global_step=351600, grad_norm=3.7050600051879883, loss=2.836280345916748
I0304 10:03:39.788682 139881808373504 logging_writer.py:48] [351700] global_step=351700, grad_norm=3.499924898147583, loss=1.1185109615325928
I0304 10:03:52.316575 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:04:02.552211 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:04:40.333316 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:04:41.909669 140077943854912 submission_runner.py:411] Time since start: 169074.71s, 	Step: 351730, 	{'train/accuracy': 0.8885937333106995, 'train/loss': 0.41555702686309814, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 154641.72449684143, 'total_duration': 169074.7146832943, 'accumulated_submission_time': 154641.72449684143, 'accumulated_eval_time': 14390.322369813919, 'accumulated_logging_time': 24.33543372154236}
I0304 10:04:41.979495 139881799980800 logging_writer.py:48] [351730] accumulated_eval_time=14390.322370, accumulated_logging_time=24.335434, accumulated_submission_time=154641.724497, global_step=351730, preemption_count=0, score=154641.724497, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=169074.714683, train/accuracy=0.888594, train/loss=0.415557, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:05:09.691206 139881808373504 logging_writer.py:48] [351800] global_step=351800, grad_norm=3.8455193042755127, loss=1.1662465333938599
I0304 10:05:52.773406 139881799980800 logging_writer.py:48] [351900] global_step=351900, grad_norm=3.699643611907959, loss=3.1049747467041016
I0304 10:06:37.398817 139881808373504 logging_writer.py:48] [352000] global_step=352000, grad_norm=3.2533440589904785, loss=1.1895853281021118
I0304 10:07:22.080575 139881799980800 logging_writer.py:48] [352100] global_step=352100, grad_norm=4.667474269866943, loss=3.2002832889556885
I0304 10:08:06.402552 139881808373504 logging_writer.py:48] [352200] global_step=352200, grad_norm=3.014785051345825, loss=1.073307752609253
I0304 10:08:50.901229 139881799980800 logging_writer.py:48] [352300] global_step=352300, grad_norm=3.105102300643921, loss=2.6789839267730713
I0304 10:09:35.114588 139881808373504 logging_writer.py:48] [352400] global_step=352400, grad_norm=3.1616342067718506, loss=1.3216032981872559
I0304 10:10:19.703717 139881799980800 logging_writer.py:48] [352500] global_step=352500, grad_norm=3.1910274028778076, loss=2.160964012145996
I0304 10:11:04.169406 139881808373504 logging_writer.py:48] [352600] global_step=352600, grad_norm=3.1630260944366455, loss=1.0355538129806519
I0304 10:11:42.216283 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:11:52.379386 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:12:21.610936 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:12:23.215501 140077943854912 submission_runner.py:411] Time since start: 169536.02s, 	Step: 352688, 	{'train/accuracy': 0.8866210579872131, 'train/loss': 0.4199872612953186, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 155061.90138220787, 'total_duration': 169536.02051210403, 'accumulated_submission_time': 155061.90138220787, 'accumulated_eval_time': 14431.321568489075, 'accumulated_logging_time': 24.41545557975769}
I0304 10:12:23.283136 139881799980800 logging_writer.py:48] [352688] accumulated_eval_time=14431.321568, accumulated_logging_time=24.415456, accumulated_submission_time=155061.901382, global_step=352688, preemption_count=0, score=155061.901382, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=169536.020512, train/accuracy=0.886621, train/loss=0.419987, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:12:28.347440 139881808373504 logging_writer.py:48] [352700] global_step=352700, grad_norm=2.807948112487793, loss=1.6818925142288208
I0304 10:13:09.013311 139881799980800 logging_writer.py:48] [352800] global_step=352800, grad_norm=4.194733619689941, loss=2.9095022678375244
I0304 10:13:53.236166 139881808373504 logging_writer.py:48] [352900] global_step=352900, grad_norm=3.078713893890381, loss=2.644007444381714
I0304 10:14:37.608213 139881799980800 logging_writer.py:48] [353000] global_step=353000, grad_norm=2.867467164993286, loss=1.4539484977722168
I0304 10:15:22.387258 139881808373504 logging_writer.py:48] [353100] global_step=353100, grad_norm=2.970458507537842, loss=1.1216201782226562
I0304 10:16:06.757780 139881799980800 logging_writer.py:48] [353200] global_step=353200, grad_norm=3.296935796737671, loss=1.1259183883666992
I0304 10:16:51.185289 139881808373504 logging_writer.py:48] [353300] global_step=353300, grad_norm=3.638532876968384, loss=2.9441637992858887
I0304 10:17:35.495851 139881799980800 logging_writer.py:48] [353400] global_step=353400, grad_norm=3.1414883136749268, loss=1.1141740083694458
I0304 10:18:19.745395 139881808373504 logging_writer.py:48] [353500] global_step=353500, grad_norm=3.0053677558898926, loss=1.121866226196289
I0304 10:19:04.084527 139881799980800 logging_writer.py:48] [353600] global_step=353600, grad_norm=3.1332221031188965, loss=1.5252503156661987
I0304 10:19:23.221711 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:19:33.515790 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:20:06.122251 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:20:07.708966 140077943854912 submission_runner.py:411] Time since start: 170000.51s, 	Step: 353645, 	{'train/accuracy': 0.8891991972923279, 'train/loss': 0.4173726439476013, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 155481.78094792366, 'total_duration': 170000.51396226883, 'accumulated_submission_time': 155481.78094792366, 'accumulated_eval_time': 14475.808803319931, 'accumulated_logging_time': 24.493077278137207}
I0304 10:20:07.808030 139881808373504 logging_writer.py:48] [353645] accumulated_eval_time=14475.808803, accumulated_logging_time=24.493077, accumulated_submission_time=155481.780948, global_step=353645, preemption_count=0, score=155481.780948, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=170000.513962, train/accuracy=0.889199, train/loss=0.417373, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:20:29.655244 139881799980800 logging_writer.py:48] [353700] global_step=353700, grad_norm=2.9590325355529785, loss=1.0889135599136353
I0304 10:21:12.833798 139881808373504 logging_writer.py:48] [353800] global_step=353800, grad_norm=3.4663443565368652, loss=2.9167258739471436
I0304 10:21:57.313325 139881799980800 logging_writer.py:48] [353900] global_step=353900, grad_norm=3.0413546562194824, loss=1.1019248962402344
I0304 10:22:42.015165 139881808373504 logging_writer.py:48] [354000] global_step=354000, grad_norm=3.0560379028320312, loss=1.2783541679382324
I0304 10:23:26.759237 139881799980800 logging_writer.py:48] [354100] global_step=354100, grad_norm=3.828178882598877, loss=3.107632637023926
I0304 10:24:11.233901 139881808373504 logging_writer.py:48] [354200] global_step=354200, grad_norm=3.182814836502075, loss=2.651217460632324
I0304 10:24:55.404640 139881799980800 logging_writer.py:48] [354300] global_step=354300, grad_norm=3.151057243347168, loss=1.1506657600402832
I0304 10:25:39.990412 139881808373504 logging_writer.py:48] [354400] global_step=354400, grad_norm=3.5779309272766113, loss=2.443934202194214
I0304 10:26:24.487703 139881799980800 logging_writer.py:48] [354500] global_step=354500, grad_norm=3.1308555603027344, loss=2.2579245567321777
I0304 10:27:07.763179 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:27:18.075880 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:27:44.131226 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:27:45.717762 140077943854912 submission_runner.py:411] Time since start: 170458.52s, 	Step: 354599, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.41711628437042236, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 155901.67514777184, 'total_duration': 170458.52275180817, 'accumulated_submission_time': 155901.67514777184, 'accumulated_eval_time': 14513.76334285736, 'accumulated_logging_time': 24.60359287261963}
I0304 10:27:45.804228 139881808373504 logging_writer.py:48] [354599] accumulated_eval_time=14513.763343, accumulated_logging_time=24.603593, accumulated_submission_time=155901.675148, global_step=354599, preemption_count=0, score=155901.675148, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=170458.522752, train/accuracy=0.888438, train/loss=0.417116, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:27:46.591345 139881799980800 logging_writer.py:48] [354600] global_step=354600, grad_norm=3.121312379837036, loss=1.4757847785949707
I0304 10:28:27.549097 139881808373504 logging_writer.py:48] [354700] global_step=354700, grad_norm=3.3378286361694336, loss=1.2538182735443115
I0304 10:29:12.022444 139881799980800 logging_writer.py:48] [354800] global_step=354800, grad_norm=3.0430028438568115, loss=2.7003605365753174
I0304 10:29:56.717905 139881808373504 logging_writer.py:48] [354900] global_step=354900, grad_norm=3.012484312057495, loss=1.013008713722229
I0304 10:30:41.470461 139881799980800 logging_writer.py:48] [355000] global_step=355000, grad_norm=3.178575277328491, loss=1.1826815605163574
I0304 10:31:26.071070 139881808373504 logging_writer.py:48] [355100] global_step=355100, grad_norm=3.104353666305542, loss=1.2012805938720703
I0304 10:32:10.571630 139881799980800 logging_writer.py:48] [355200] global_step=355200, grad_norm=3.050591230392456, loss=1.4611786603927612
I0304 10:32:55.058177 139881808373504 logging_writer.py:48] [355300] global_step=355300, grad_norm=3.1369378566741943, loss=2.449720621109009
I0304 10:33:39.956179 139881799980800 logging_writer.py:48] [355400] global_step=355400, grad_norm=3.039350986480713, loss=1.2108495235443115
I0304 10:34:24.505280 139881808373504 logging_writer.py:48] [355500] global_step=355500, grad_norm=3.7515313625335693, loss=3.2407305240631104
I0304 10:34:46.030094 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:34:56.766444 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:35:32.250826 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:35:33.822776 140077943854912 submission_runner.py:411] Time since start: 170926.63s, 	Step: 355550, 	{'train/accuracy': 0.890625, 'train/loss': 0.4058804512023926, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 156321.83713293076, 'total_duration': 170926.6277961731, 'accumulated_submission_time': 156321.83713293076, 'accumulated_eval_time': 14561.556003570557, 'accumulated_logging_time': 24.704198122024536}
I0304 10:35:33.891742 139881799980800 logging_writer.py:48] [355550] accumulated_eval_time=14561.556004, accumulated_logging_time=24.704198, accumulated_submission_time=156321.837133, global_step=355550, preemption_count=0, score=156321.837133, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=170926.627796, train/accuracy=0.890625, train/loss=0.405880, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:35:53.778799 139881808373504 logging_writer.py:48] [355600] global_step=355600, grad_norm=3.625506639480591, loss=2.7293810844421387
I0304 10:36:36.774619 139881799980800 logging_writer.py:48] [355700] global_step=355700, grad_norm=2.9949944019317627, loss=2.1775176525115967
I0304 10:37:21.242704 139881808373504 logging_writer.py:48] [355800] global_step=355800, grad_norm=3.3939127922058105, loss=1.128990888595581
I0304 10:38:05.790952 139881799980800 logging_writer.py:48] [355900] global_step=355900, grad_norm=3.241626262664795, loss=2.156721353530884
I0304 10:38:49.973133 139881808373504 logging_writer.py:48] [356000] global_step=356000, grad_norm=3.165163993835449, loss=1.0279779434204102
I0304 10:39:34.454680 139881799980800 logging_writer.py:48] [356100] global_step=356100, grad_norm=2.999119520187378, loss=1.4520329236984253
I0304 10:40:18.890380 139881808373504 logging_writer.py:48] [356200] global_step=356200, grad_norm=3.537473201751709, loss=2.783259153366089
I0304 10:41:03.110853 139881799980800 logging_writer.py:48] [356300] global_step=356300, grad_norm=2.9869837760925293, loss=1.4020662307739258
I0304 10:41:47.672768 139881808373504 logging_writer.py:48] [356400] global_step=356400, grad_norm=3.8592898845672607, loss=3.270165205001831
I0304 10:42:31.999080 139881799980800 logging_writer.py:48] [356500] global_step=356500, grad_norm=3.3963232040405273, loss=1.5166572332382202
I0304 10:42:34.135642 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:42:44.231460 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:43:09.585238 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:43:11.175130 140077943854912 submission_runner.py:411] Time since start: 171383.98s, 	Step: 356506, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.41649845242500305, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 156742.0211148262, 'total_duration': 171383.98013997078, 'accumulated_submission_time': 156742.0211148262, 'accumulated_eval_time': 14598.595462560654, 'accumulated_logging_time': 24.78358292579651}
I0304 10:43:11.261912 139881808373504 logging_writer.py:48] [356506] accumulated_eval_time=14598.595463, accumulated_logging_time=24.783583, accumulated_submission_time=156742.021115, global_step=356506, preemption_count=0, score=156742.021115, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=171383.980140, train/accuracy=0.888398, train/loss=0.416498, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:43:50.178875 139881799980800 logging_writer.py:48] [356600] global_step=356600, grad_norm=3.860192060470581, loss=3.2026243209838867
I0304 10:44:34.745984 139881808373504 logging_writer.py:48] [356700] global_step=356700, grad_norm=3.2464652061462402, loss=1.2890598773956299
I0304 10:45:19.095401 139881799980800 logging_writer.py:48] [356800] global_step=356800, grad_norm=2.99814772605896, loss=1.1847268342971802
I0304 10:46:03.639341 139881808373504 logging_writer.py:48] [356900] global_step=356900, grad_norm=3.1810357570648193, loss=2.3238000869750977
I0304 10:46:47.887523 139881799980800 logging_writer.py:48] [357000] global_step=357000, grad_norm=2.8057119846343994, loss=2.05220365524292
I0304 10:47:32.454005 139881808373504 logging_writer.py:48] [357100] global_step=357100, grad_norm=3.2562692165374756, loss=1.5553785562515259
I0304 10:48:16.835969 139881799980800 logging_writer.py:48] [357200] global_step=357200, grad_norm=3.1072187423706055, loss=1.2498160600662231
I0304 10:49:01.216299 139881808373504 logging_writer.py:48] [357300] global_step=357300, grad_norm=3.4262311458587646, loss=1.167900562286377
I0304 10:49:45.902459 139881799980800 logging_writer.py:48] [357400] global_step=357400, grad_norm=3.0962753295898438, loss=1.1788725852966309
I0304 10:50:11.314929 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:50:22.248402 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:50:48.847301 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:50:50.432479 140077943854912 submission_runner.py:411] Time since start: 171843.24s, 	Step: 357459, 	{'train/accuracy': 0.88818359375, 'train/loss': 0.4171052873134613, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 157162.01435351372, 'total_duration': 171843.23746800423, 'accumulated_submission_time': 157162.01435351372, 'accumulated_eval_time': 14637.712956905365, 'accumulated_logging_time': 24.881208181381226}
I0304 10:50:50.519953 139881808373504 logging_writer.py:48] [357459] accumulated_eval_time=14637.712957, accumulated_logging_time=24.881208, accumulated_submission_time=157162.014354, global_step=357459, preemption_count=0, score=157162.014354, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=171843.237468, train/accuracy=0.888184, train/loss=0.417105, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:51:06.937194 139881799980800 logging_writer.py:48] [357500] global_step=357500, grad_norm=3.0709688663482666, loss=1.2783339023590088
I0304 10:51:49.937511 139881808373504 logging_writer.py:48] [357600] global_step=357600, grad_norm=3.641209363937378, loss=3.1375808715820312
I0304 10:52:34.229594 139881799980800 logging_writer.py:48] [357700] global_step=357700, grad_norm=3.1249706745147705, loss=1.0877313613891602
I0304 10:53:18.505443 139881808373504 logging_writer.py:48] [357800] global_step=357800, grad_norm=3.128908634185791, loss=1.7946933507919312
I0304 10:54:03.250285 139881799980800 logging_writer.py:48] [357900] global_step=357900, grad_norm=3.3707659244537354, loss=1.1478828191757202
I0304 10:54:47.865783 139881808373504 logging_writer.py:48] [358000] global_step=358000, grad_norm=3.31592059135437, loss=1.2495262622833252
I0304 10:55:32.299385 139881799980800 logging_writer.py:48] [358100] global_step=358100, grad_norm=2.7857377529144287, loss=1.1645028591156006
I0304 10:56:16.888692 139881808373504 logging_writer.py:48] [358200] global_step=358200, grad_norm=2.8311476707458496, loss=1.5125828981399536
I0304 10:57:01.235124 139881799980800 logging_writer.py:48] [358300] global_step=358300, grad_norm=3.4899067878723145, loss=1.326707124710083
I0304 10:57:45.702207 139881808373504 logging_writer.py:48] [358400] global_step=358400, grad_norm=3.266693115234375, loss=1.1663745641708374
I0304 10:57:50.642382 140077943854912 spec.py:321] Evaluating on the training split.
I0304 10:58:00.896144 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 10:58:38.628962 140077943854912 spec.py:349] Evaluating on the test split.
I0304 10:58:40.216241 140077943854912 submission_runner.py:411] Time since start: 172313.02s, 	Step: 358413, 	{'train/accuracy': 0.8861718773841858, 'train/loss': 0.41896742582321167, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 157582.07474136353, 'total_duration': 172313.02126026154, 'accumulated_submission_time': 157582.07474136353, 'accumulated_eval_time': 14687.286793231964, 'accumulated_logging_time': 24.981183767318726}
I0304 10:58:40.291503 139881799980800 logging_writer.py:48] [358413] accumulated_eval_time=14687.286793, accumulated_logging_time=24.981184, accumulated_submission_time=157582.074741, global_step=358413, preemption_count=0, score=157582.074741, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=172313.021260, train/accuracy=0.886172, train/loss=0.418967, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 10:59:14.905652 139881808373504 logging_writer.py:48] [358500] global_step=358500, grad_norm=4.022282600402832, loss=1.2424402236938477
I0304 10:59:59.302799 139881799980800 logging_writer.py:48] [358600] global_step=358600, grad_norm=3.086543321609497, loss=1.7514188289642334
I0304 11:00:44.032347 139881808373504 logging_writer.py:48] [358700] global_step=358700, grad_norm=3.0899851322174072, loss=2.164206027984619
I0304 11:01:28.728037 139881799980800 logging_writer.py:48] [358800] global_step=358800, grad_norm=3.2066702842712402, loss=1.1194920539855957
I0304 11:02:13.485277 139881808373504 logging_writer.py:48] [358900] global_step=358900, grad_norm=3.031564950942993, loss=2.216834306716919
I0304 11:02:57.852495 139881799980800 logging_writer.py:48] [359000] global_step=359000, grad_norm=3.2144827842712402, loss=1.7625147104263306
I0304 11:03:42.583301 139881808373504 logging_writer.py:48] [359100] global_step=359100, grad_norm=3.198010206222534, loss=1.136818766593933
I0304 11:04:26.939141 139881799980800 logging_writer.py:48] [359200] global_step=359200, grad_norm=3.8291070461273193, loss=2.762166976928711
I0304 11:05:11.566880 139881808373504 logging_writer.py:48] [359300] global_step=359300, grad_norm=3.7654709815979004, loss=3.190380096435547
I0304 11:05:40.427363 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:05:50.632198 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 11:06:18.741984 140077943854912 spec.py:349] Evaluating on the test split.
I0304 11:06:20.345238 140077943854912 submission_runner.py:411] Time since start: 172773.15s, 	Step: 359367, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.4130707383155823, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 158002.15069007874, 'total_duration': 172773.15025138855, 'accumulated_submission_time': 158002.15069007874, 'accumulated_eval_time': 14727.204654693604, 'accumulated_logging_time': 25.068183422088623}
I0304 11:06:20.422895 139881799980800 logging_writer.py:48] [359367] accumulated_eval_time=14727.204655, accumulated_logging_time=25.068183, accumulated_submission_time=158002.150690, global_step=359367, preemption_count=0, score=158002.150690, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=172773.150251, train/accuracy=0.888340, train/loss=0.413071, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 11:06:33.680094 139881808373504 logging_writer.py:48] [359400] global_step=359400, grad_norm=3.540694236755371, loss=1.0643006563186646
I0304 11:07:15.176154 139881799980800 logging_writer.py:48] [359500] global_step=359500, grad_norm=3.073901891708374, loss=1.1374062299728394
I0304 11:07:59.434424 139881808373504 logging_writer.py:48] [359600] global_step=359600, grad_norm=4.1790876388549805, loss=2.9460339546203613
I0304 11:08:44.230863 139881799980800 logging_writer.py:48] [359700] global_step=359700, grad_norm=3.460632801055908, loss=2.1451659202575684
I0304 11:09:28.727713 139881808373504 logging_writer.py:48] [359800] global_step=359800, grad_norm=3.4909844398498535, loss=2.9258062839508057
I0304 11:10:12.996314 139881799980800 logging_writer.py:48] [359900] global_step=359900, grad_norm=3.209115505218506, loss=1.171302080154419
I0304 11:10:57.044281 139881808373504 logging_writer.py:48] [360000] global_step=360000, grad_norm=3.276502847671509, loss=2.5572171211242676
I0304 11:11:41.417787 139881799980800 logging_writer.py:48] [360100] global_step=360100, grad_norm=3.0488922595977783, loss=0.9939373731613159
I0304 11:12:25.878644 139881808373504 logging_writer.py:48] [360200] global_step=360200, grad_norm=3.031843900680542, loss=1.1122620105743408
I0304 11:13:10.372707 139881799980800 logging_writer.py:48] [360300] global_step=360300, grad_norm=2.914804458618164, loss=1.9392523765563965
I0304 11:13:20.625082 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:13:30.838971 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 11:13:59.410227 140077943854912 spec.py:349] Evaluating on the test split.
I0304 11:14:00.998108 140077943854912 submission_runner.py:411] Time since start: 173233.80s, 	Step: 360324, 	{'train/accuracy': 0.88929682970047, 'train/loss': 0.4147252142429352, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 158422.29297685623, 'total_duration': 173233.80309987068, 'accumulated_submission_time': 158422.29297685623, 'accumulated_eval_time': 14767.577633619308, 'accumulated_logging_time': 25.156745195388794}
I0304 11:14:01.084582 139881808373504 logging_writer.py:48] [360324] accumulated_eval_time=14767.577634, accumulated_logging_time=25.156745, accumulated_submission_time=158422.292977, global_step=360324, preemption_count=0, score=158422.292977, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=173233.803100, train/accuracy=0.889297, train/loss=0.414725, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 11:14:32.407806 139881799980800 logging_writer.py:48] [360400] global_step=360400, grad_norm=3.2490012645721436, loss=1.1826456785202026
I0304 11:15:17.197849 139881808373504 logging_writer.py:48] [360500] global_step=360500, grad_norm=3.597668170928955, loss=1.1082996129989624
I0304 11:16:02.073843 139881799980800 logging_writer.py:48] [360600] global_step=360600, grad_norm=3.1436920166015625, loss=1.3790737390518188
I0304 11:16:47.027330 139881808373504 logging_writer.py:48] [360700] global_step=360700, grad_norm=3.3647072315216064, loss=1.1579660177230835
I0304 11:17:31.916302 139881799980800 logging_writer.py:48] [360800] global_step=360800, grad_norm=3.2048819065093994, loss=1.9844129085540771
I0304 11:18:16.796506 139881808373504 logging_writer.py:48] [360900] global_step=360900, grad_norm=3.225975275039673, loss=1.3654135465621948
I0304 11:19:01.518537 139881799980800 logging_writer.py:48] [361000] global_step=361000, grad_norm=3.3760199546813965, loss=2.3985347747802734
I0304 11:19:46.364368 139881808373504 logging_writer.py:48] [361100] global_step=361100, grad_norm=3.62137508392334, loss=3.185697078704834
I0304 11:20:31.333931 139881799980800 logging_writer.py:48] [361200] global_step=361200, grad_norm=3.134695053100586, loss=1.1395955085754395
I0304 11:21:01.041460 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:21:11.292841 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 11:21:39.637719 140077943854912 spec.py:349] Evaluating on the test split.
I0304 11:21:41.223089 140077943854912 submission_runner.py:411] Time since start: 173694.03s, 	Step: 361268, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.4192902147769928, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 158842.19017791748, 'total_duration': 173694.02808856964, 'accumulated_submission_time': 158842.19017791748, 'accumulated_eval_time': 14807.759229898453, 'accumulated_logging_time': 25.254371643066406}
I0304 11:21:41.311333 139881808373504 logging_writer.py:48] [361268] accumulated_eval_time=14807.759230, accumulated_logging_time=25.254372, accumulated_submission_time=158842.190178, global_step=361268, preemption_count=0, score=158842.190178, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=173694.028089, train/accuracy=0.888320, train/loss=0.419290, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 11:21:54.220087 139881799980800 logging_writer.py:48] [361300] global_step=361300, grad_norm=3.0198776721954346, loss=1.0948110818862915
I0304 11:22:37.309477 139881808373504 logging_writer.py:48] [361400] global_step=361400, grad_norm=3.3003904819488525, loss=2.9219706058502197
I0304 11:23:21.889499 139881799980800 logging_writer.py:48] [361500] global_step=361500, grad_norm=3.4181361198425293, loss=1.2870523929595947
I0304 11:24:07.150336 139881808373504 logging_writer.py:48] [361600] global_step=361600, grad_norm=3.280689001083374, loss=1.1609808206558228
I0304 11:24:52.018491 139881799980800 logging_writer.py:48] [361700] global_step=361700, grad_norm=2.905724048614502, loss=1.7850830554962158
I0304 11:25:36.743870 139881808373504 logging_writer.py:48] [361800] global_step=361800, grad_norm=3.1100916862487793, loss=2.4447715282440186
I0304 11:26:21.575487 139881799980800 logging_writer.py:48] [361900] global_step=361900, grad_norm=3.159207344055176, loss=1.0903024673461914
I0304 11:27:06.288186 139881808373504 logging_writer.py:48] [362000] global_step=362000, grad_norm=3.083682060241699, loss=1.411346197128296
I0304 11:27:50.971877 139881799980800 logging_writer.py:48] [362100] global_step=362100, grad_norm=3.936245918273926, loss=3.1823959350585938
I0304 11:28:35.790766 139881808373504 logging_writer.py:48] [362200] global_step=362200, grad_norm=3.198930263519287, loss=2.290783405303955
I0304 11:28:41.281064 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:28:51.392242 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 11:29:25.086979 140077943854912 spec.py:349] Evaluating on the test split.
I0304 11:29:26.672561 140077943854912 submission_runner.py:411] Time since start: 174159.48s, 	Step: 362214, 	{'train/accuracy': 0.8856054544448853, 'train/loss': 0.42054837942123413, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 159262.09999990463, 'total_duration': 174159.47754120827, 'accumulated_submission_time': 159262.09999990463, 'accumulated_eval_time': 14853.150671720505, 'accumulated_logging_time': 25.353637218475342}
I0304 11:29:26.755720 139881799980800 logging_writer.py:48] [362214] accumulated_eval_time=14853.150672, accumulated_logging_time=25.353637, accumulated_submission_time=159262.100000, global_step=362214, preemption_count=0, score=159262.100000, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=174159.477541, train/accuracy=0.885605, train/loss=0.420548, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 11:30:00.736980 139881808373504 logging_writer.py:48] [362300] global_step=362300, grad_norm=3.2432944774627686, loss=1.0820225477218628
I0304 11:30:45.080336 139881799980800 logging_writer.py:48] [362400] global_step=362400, grad_norm=3.032738447189331, loss=1.2923696041107178
I0304 11:31:29.818408 139881808373504 logging_writer.py:48] [362500] global_step=362500, grad_norm=3.0968496799468994, loss=1.1604046821594238
I0304 11:32:14.448168 139881799980800 logging_writer.py:48] [362600] global_step=362600, grad_norm=2.8195459842681885, loss=2.184739589691162
I0304 11:32:58.706905 139881808373504 logging_writer.py:48] [362700] global_step=362700, grad_norm=2.9964516162872314, loss=1.3116376399993896
I0304 11:33:43.266352 139881799980800 logging_writer.py:48] [362800] global_step=362800, grad_norm=3.123166084289551, loss=1.2006052732467651
I0304 11:34:27.753675 139881808373504 logging_writer.py:48] [362900] global_step=362900, grad_norm=3.1903085708618164, loss=1.5668833255767822
I0304 11:35:12.381778 139881799980800 logging_writer.py:48] [363000] global_step=363000, grad_norm=3.1760363578796387, loss=1.7199746370315552
I0304 11:35:56.851037 139881808373504 logging_writer.py:48] [363100] global_step=363100, grad_norm=2.9458425045013428, loss=1.7203350067138672
I0304 11:36:26.890305 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:36:37.006283 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 11:37:04.519106 140077943854912 spec.py:349] Evaluating on the test split.
I0304 11:37:06.108429 140077943854912 submission_runner.py:411] Time since start: 174618.91s, 	Step: 363169, 	{'train/accuracy': 0.8899999856948853, 'train/loss': 0.4131052792072296, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 159682.17498278618, 'total_duration': 174618.91343593597, 'accumulated_submission_time': 159682.17498278618, 'accumulated_eval_time': 14892.368756771088, 'accumulated_logging_time': 25.447653770446777}
I0304 11:37:06.197584 139881799980800 logging_writer.py:48] [363169] accumulated_eval_time=14892.368757, accumulated_logging_time=25.447654, accumulated_submission_time=159682.174983, global_step=363169, preemption_count=0, score=159682.174983, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=174618.913436, train/accuracy=0.890000, train/loss=0.413105, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 11:37:18.681477 139881808373504 logging_writer.py:48] [363200] global_step=363200, grad_norm=3.0612828731536865, loss=2.153970718383789
I0304 11:38:01.111591 139881799980800 logging_writer.py:48] [363300] global_step=363300, grad_norm=3.368619441986084, loss=2.9152259826660156
I0304 11:38:45.787127 139881808373504 logging_writer.py:48] [363400] global_step=363400, grad_norm=3.1288554668426514, loss=1.1394323110580444
I0304 11:39:30.322741 139881799980800 logging_writer.py:48] [363500] global_step=363500, grad_norm=3.1122844219207764, loss=1.215460181236267
I0304 11:40:14.763082 139881808373504 logging_writer.py:48] [363600] global_step=363600, grad_norm=4.675477504730225, loss=3.3148558139801025
I0304 11:40:59.173464 139881799980800 logging_writer.py:48] [363700] global_step=363700, grad_norm=2.8866567611694336, loss=1.1019706726074219
I0304 11:41:43.909624 139881808373504 logging_writer.py:48] [363800] global_step=363800, grad_norm=3.2703025341033936, loss=1.1299934387207031
I0304 11:42:28.497415 139881799980800 logging_writer.py:48] [363900] global_step=363900, grad_norm=2.7493841648101807, loss=1.5916239023208618
I0304 11:43:13.053324 139881808373504 logging_writer.py:48] [364000] global_step=364000, grad_norm=3.7980904579162598, loss=3.1455836296081543
I0304 11:43:57.784594 139881799980800 logging_writer.py:48] [364100] global_step=364100, grad_norm=2.861367702484131, loss=1.7621300220489502
I0304 11:44:06.349125 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:44:16.863456 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 11:44:47.252001 140077943854912 spec.py:349] Evaluating on the test split.
I0304 11:44:48.844719 140077943854912 submission_runner.py:411] Time since start: 175081.65s, 	Step: 364121, 	{'train/accuracy': 0.8870507478713989, 'train/loss': 0.4179600775241852, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 160102.2657313347, 'total_duration': 175081.6497273445, 'accumulated_submission_time': 160102.2657313347, 'accumulated_eval_time': 14934.86432981491, 'accumulated_logging_time': 25.548548221588135}
I0304 11:44:48.936839 139881808373504 logging_writer.py:48] [364121] accumulated_eval_time=14934.864330, accumulated_logging_time=25.548548, accumulated_submission_time=160102.265731, global_step=364121, preemption_count=0, score=160102.265731, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=175081.649727, train/accuracy=0.887051, train/loss=0.417960, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 11:45:20.905297 139881799980800 logging_writer.py:48] [364200] global_step=364200, grad_norm=3.0525169372558594, loss=1.2109525203704834
I0304 11:46:05.367547 139881808373504 logging_writer.py:48] [364300] global_step=364300, grad_norm=3.2162184715270996, loss=2.060167074203491
I0304 11:46:50.143650 139881799980800 logging_writer.py:48] [364400] global_step=364400, grad_norm=3.270838499069214, loss=1.0920193195343018
I0304 11:47:34.629573 139881808373504 logging_writer.py:48] [364500] global_step=364500, grad_norm=3.3361573219299316, loss=1.0546716451644897
I0304 11:48:19.282851 139881799980800 logging_writer.py:48] [364600] global_step=364600, grad_norm=3.277226209640503, loss=1.1750937700271606
I0304 11:49:03.908222 139881808373504 logging_writer.py:48] [364700] global_step=364700, grad_norm=3.6243157386779785, loss=3.054141044616699
I0304 11:49:48.329922 139881799980800 logging_writer.py:48] [364800] global_step=364800, grad_norm=3.1591806411743164, loss=2.1763439178466797
I0304 11:50:32.935410 139881808373504 logging_writer.py:48] [364900] global_step=364900, grad_norm=3.12660813331604, loss=1.7088006734848022
I0304 11:51:17.264963 139881799980800 logging_writer.py:48] [365000] global_step=365000, grad_norm=3.9505362510681152, loss=3.01193904876709
I0304 11:51:49.022416 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:51:59.285943 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 11:52:28.446043 140077943854912 spec.py:349] Evaluating on the test split.
I0304 11:52:30.032866 140077943854912 submission_runner.py:411] Time since start: 175542.84s, 	Step: 365073, 	{'train/accuracy': 0.8878124952316284, 'train/loss': 0.41499578952789307, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 160522.2911117077, 'total_duration': 175542.83787035942, 'accumulated_submission_time': 160522.2911117077, 'accumulated_eval_time': 14975.874757051468, 'accumulated_logging_time': 25.65269923210144}
I0304 11:52:30.119467 139881808373504 logging_writer.py:48] [365073] accumulated_eval_time=14975.874757, accumulated_logging_time=25.652699, accumulated_submission_time=160522.291112, global_step=365073, preemption_count=0, score=160522.291112, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=175542.837870, train/accuracy=0.887812, train/loss=0.414996, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 11:52:41.047067 139881799980800 logging_writer.py:48] [365100] global_step=365100, grad_norm=3.198709726333618, loss=3.0314605236053467
I0304 11:53:23.441938 139881808373504 logging_writer.py:48] [365200] global_step=365200, grad_norm=3.320363759994507, loss=2.583071231842041
I0304 11:54:07.837019 139881799980800 logging_writer.py:48] [365300] global_step=365300, grad_norm=2.9458234310150146, loss=1.1715588569641113
I0304 11:54:52.356189 139881808373504 logging_writer.py:48] [365400] global_step=365400, grad_norm=3.3638758659362793, loss=1.1973598003387451
I0304 11:55:37.035296 139881799980800 logging_writer.py:48] [365500] global_step=365500, grad_norm=2.850978374481201, loss=1.364152431488037
I0304 11:56:21.594464 139881808373504 logging_writer.py:48] [365600] global_step=365600, grad_norm=3.39912486076355, loss=2.6456971168518066
I0304 11:57:06.225527 139881799980800 logging_writer.py:48] [365700] global_step=365700, grad_norm=3.1283421516418457, loss=2.645794630050659
I0304 11:57:50.719259 139881808373504 logging_writer.py:48] [365800] global_step=365800, grad_norm=2.9840095043182373, loss=2.2533318996429443
I0304 11:58:35.369830 139881799980800 logging_writer.py:48] [365900] global_step=365900, grad_norm=3.105267286300659, loss=1.1436638832092285
I0304 11:59:19.909646 139881808373504 logging_writer.py:48] [366000] global_step=366000, grad_norm=3.2977333068847656, loss=1.3839715719223022
I0304 11:59:30.194917 140077943854912 spec.py:321] Evaluating on the training split.
I0304 11:59:40.207580 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:00:12.214120 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:00:13.806785 140077943854912 submission_runner.py:411] Time since start: 176006.61s, 	Step: 366025, 	{'train/accuracy': 0.8901953101158142, 'train/loss': 0.4158586859703064, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 160942.30407452583, 'total_duration': 176006.61175465584, 'accumulated_submission_time': 160942.30407452583, 'accumulated_eval_time': 15019.486609220505, 'accumulated_logging_time': 25.752633094787598}
I0304 12:00:13.948375 139881799980800 logging_writer.py:48] [366025] accumulated_eval_time=15019.486609, accumulated_logging_time=25.752633, accumulated_submission_time=160942.304075, global_step=366025, preemption_count=0, score=160942.304075, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=176006.611755, train/accuracy=0.890195, train/loss=0.415859, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:00:43.814640 139881808373504 logging_writer.py:48] [366100] global_step=366100, grad_norm=3.1990444660186768, loss=2.8830370903015137
I0304 12:01:28.188203 139881799980800 logging_writer.py:48] [366200] global_step=366200, grad_norm=3.112074851989746, loss=1.1784626245498657
I0304 12:02:12.799387 139881808373504 logging_writer.py:48] [366300] global_step=366300, grad_norm=3.0494754314422607, loss=2.407968044281006
I0304 12:02:57.001436 139881799980800 logging_writer.py:48] [366400] global_step=366400, grad_norm=3.4917891025543213, loss=2.4746243953704834
I0304 12:03:41.319667 139881808373504 logging_writer.py:48] [366500] global_step=366500, grad_norm=2.992093563079834, loss=1.8182569742202759
I0304 12:04:26.102320 139881799980800 logging_writer.py:48] [366600] global_step=366600, grad_norm=3.194746255874634, loss=1.0453407764434814
I0304 12:05:10.495926 139881808373504 logging_writer.py:48] [366700] global_step=366700, grad_norm=3.8637826442718506, loss=3.2021238803863525
I0304 12:05:54.944742 139881799980800 logging_writer.py:48] [366800] global_step=366800, grad_norm=3.1731667518615723, loss=1.4468293190002441
I0304 12:06:39.896203 139881808373504 logging_writer.py:48] [366900] global_step=366900, grad_norm=3.1088645458221436, loss=1.7379308938980103
I0304 12:07:13.898897 140077943854912 spec.py:321] Evaluating on the training split.
I0304 12:07:24.047641 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:07:50.781180 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:07:52.365058 140077943854912 submission_runner.py:411] Time since start: 176465.17s, 	Step: 366978, 	{'train/accuracy': 0.8854882717132568, 'train/loss': 0.4268224537372589, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 161362.19010972977, 'total_duration': 176465.17006731033, 'accumulated_submission_time': 161362.19010972977, 'accumulated_eval_time': 15057.952741146088, 'accumulated_logging_time': 25.909390687942505}
I0304 12:07:52.453280 139881799980800 logging_writer.py:48] [366978] accumulated_eval_time=15057.952741, accumulated_logging_time=25.909391, accumulated_submission_time=161362.190110, global_step=366978, preemption_count=0, score=161362.190110, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=176465.170067, train/accuracy=0.885488, train/loss=0.426822, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:08:01.752368 139881808373504 logging_writer.py:48] [367000] global_step=367000, grad_norm=4.2209367752075195, loss=3.14693284034729
I0304 12:08:43.623322 139881799980800 logging_writer.py:48] [367100] global_step=367100, grad_norm=3.1286003589630127, loss=1.0745019912719727
I0304 12:09:27.910003 139881808373504 logging_writer.py:48] [367200] global_step=367200, grad_norm=3.0384814739227295, loss=1.111372947692871
I0304 12:10:12.375883 139881799980800 logging_writer.py:48] [367300] global_step=367300, grad_norm=3.227914571762085, loss=1.1888076066970825
I0304 12:10:56.625018 139881808373504 logging_writer.py:48] [367400] global_step=367400, grad_norm=3.722885847091675, loss=2.9493865966796875
I0304 12:11:40.986727 139881799980800 logging_writer.py:48] [367500] global_step=367500, grad_norm=3.16023850440979, loss=1.0578029155731201
I0304 12:12:25.402817 139881808373504 logging_writer.py:48] [367600] global_step=367600, grad_norm=3.0690975189208984, loss=1.0965969562530518
I0304 12:13:10.055922 139881799980800 logging_writer.py:48] [367700] global_step=367700, grad_norm=3.292431592941284, loss=1.5437798500061035
I0304 12:13:54.417021 139881808373504 logging_writer.py:48] [367800] global_step=367800, grad_norm=2.7856600284576416, loss=2.0239992141723633
I0304 12:14:38.900633 139881799980800 logging_writer.py:48] [367900] global_step=367900, grad_norm=3.3969333171844482, loss=1.1325647830963135
I0304 12:14:52.761072 140077943854912 spec.py:321] Evaluating on the training split.
I0304 12:15:03.270005 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:15:35.789738 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:15:37.379871 140077943854912 submission_runner.py:411] Time since start: 176930.18s, 	Step: 367933, 	{'train/accuracy': 0.8866796493530273, 'train/loss': 0.42011314630508423, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 161782.4360189438, 'total_duration': 176930.18487286568, 'accumulated_submission_time': 161782.4360189438, 'accumulated_eval_time': 15102.571516036987, 'accumulated_logging_time': 26.011119604110718}
I0304 12:15:37.471040 139881808373504 logging_writer.py:48] [367933] accumulated_eval_time=15102.571516, accumulated_logging_time=26.011120, accumulated_submission_time=161782.436019, global_step=367933, preemption_count=0, score=161782.436019, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=176930.184873, train/accuracy=0.886680, train/loss=0.420113, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:16:04.115118 139881799980800 logging_writer.py:48] [368000] global_step=368000, grad_norm=2.953886032104492, loss=1.265471339225769
I0304 12:16:48.496037 139881808373504 logging_writer.py:48] [368100] global_step=368100, grad_norm=3.195904016494751, loss=1.986689805984497
I0304 12:17:32.886411 139881799980800 logging_writer.py:48] [368200] global_step=368200, grad_norm=3.2850863933563232, loss=2.834533929824829
I0304 12:18:17.493264 139881808373504 logging_writer.py:48] [368300] global_step=368300, grad_norm=3.025326728820801, loss=2.4722909927368164
I0304 12:19:01.670147 139881799980800 logging_writer.py:48] [368400] global_step=368400, grad_norm=3.085803747177124, loss=1.082932472229004
I0304 12:19:46.049883 139881808373504 logging_writer.py:48] [368500] global_step=368500, grad_norm=3.107149124145508, loss=2.7134337425231934
I0304 12:20:30.617975 139881799980800 logging_writer.py:48] [368600] global_step=368600, grad_norm=3.135646104812622, loss=1.0994967222213745
I0304 12:21:15.099756 139881808373504 logging_writer.py:48] [368700] global_step=368700, grad_norm=3.3255627155303955, loss=2.6008615493774414
I0304 12:21:59.644983 139881799980800 logging_writer.py:48] [368800] global_step=368800, grad_norm=3.0784056186676025, loss=1.4006223678588867
I0304 12:22:37.642620 140077943854912 spec.py:321] Evaluating on the training split.
I0304 12:22:47.774844 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:23:18.689142 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:23:20.296215 140077943854912 submission_runner.py:411] Time since start: 177393.10s, 	Step: 368887, 	{'train/accuracy': 0.8903710842132568, 'train/loss': 0.40767908096313477, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 162202.54720520973, 'total_duration': 177393.1012325287, 'accumulated_submission_time': 162202.54720520973, 'accumulated_eval_time': 15145.225117206573, 'accumulated_logging_time': 26.113094091415405}
I0304 12:23:20.368860 139881808373504 logging_writer.py:48] [368887] accumulated_eval_time=15145.225117, accumulated_logging_time=26.113094, accumulated_submission_time=162202.547205, global_step=368887, preemption_count=0, score=162202.547205, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=177393.101233, train/accuracy=0.890371, train/loss=0.407679, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:23:25.832189 139881799980800 logging_writer.py:48] [368900] global_step=368900, grad_norm=3.1946051120758057, loss=1.3662515878677368
I0304 12:24:06.402369 139881808373504 logging_writer.py:48] [369000] global_step=369000, grad_norm=3.058950185775757, loss=1.100123643875122
I0304 12:24:50.692223 139881799980800 logging_writer.py:48] [369100] global_step=369100, grad_norm=3.1654605865478516, loss=1.114194631576538
I0304 12:25:35.589329 139881808373504 logging_writer.py:48] [369200] global_step=369200, grad_norm=3.1401290893554688, loss=2.376234769821167
I0304 12:26:20.219749 139881799980800 logging_writer.py:48] [369300] global_step=369300, grad_norm=3.212878704071045, loss=2.0582830905914307
I0304 12:27:04.525811 139881808373504 logging_writer.py:48] [369400] global_step=369400, grad_norm=3.4812734127044678, loss=2.72864031791687
I0304 12:27:48.798633 139881799980800 logging_writer.py:48] [369500] global_step=369500, grad_norm=3.08123517036438, loss=1.264765977859497
I0304 12:28:33.157402 139881808373504 logging_writer.py:48] [369600] global_step=369600, grad_norm=3.544365406036377, loss=3.2463696002960205
I0304 12:29:17.661113 139881799980800 logging_writer.py:48] [369700] global_step=369700, grad_norm=4.602711200714111, loss=1.194955587387085
I0304 12:30:01.939483 139881808373504 logging_writer.py:48] [369800] global_step=369800, grad_norm=3.540510416030884, loss=2.7260282039642334
I0304 12:30:20.529552 140077943854912 spec.py:321] Evaluating on the training split.
I0304 12:30:30.660762 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:30:56.888742 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:30:58.479439 140077943854912 submission_runner.py:411] Time since start: 177851.28s, 	Step: 369844, 	{'train/accuracy': 0.887011706829071, 'train/loss': 0.4195477068424225, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 162622.64628648758, 'total_duration': 177851.28444957733, 'accumulated_submission_time': 162622.64628648758, 'accumulated_eval_time': 15183.17496752739, 'accumulated_logging_time': 26.19810652732849}
I0304 12:30:58.567411 139881799980800 logging_writer.py:48] [369844] accumulated_eval_time=15183.174968, accumulated_logging_time=26.198107, accumulated_submission_time=162622.646286, global_step=369844, preemption_count=0, score=162622.646286, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=177851.284450, train/accuracy=0.887012, train/loss=0.419548, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:31:20.858376 139881808373504 logging_writer.py:48] [369900] global_step=369900, grad_norm=3.2188878059387207, loss=1.6727423667907715
I0304 12:32:04.493167 139881799980800 logging_writer.py:48] [370000] global_step=370000, grad_norm=3.119636058807373, loss=1.0454334020614624
I0304 12:32:48.907217 139881808373504 logging_writer.py:48] [370100] global_step=370100, grad_norm=2.977417469024658, loss=1.6332796812057495
I0304 12:33:33.536270 139881799980800 logging_writer.py:48] [370200] global_step=370200, grad_norm=3.044743776321411, loss=1.2928099632263184
I0304 12:34:17.807524 139881808373504 logging_writer.py:48] [370300] global_step=370300, grad_norm=3.0067620277404785, loss=1.1176906824111938
I0304 12:35:02.434262 139881799980800 logging_writer.py:48] [370400] global_step=370400, grad_norm=3.1010913848876953, loss=1.1019364595413208
I0304 12:35:46.466284 139881808373504 logging_writer.py:48] [370500] global_step=370500, grad_norm=3.238189458847046, loss=2.661424398422241
I0304 12:36:31.164348 139881799980800 logging_writer.py:48] [370600] global_step=370600, grad_norm=3.180955410003662, loss=1.1662747859954834
I0304 12:37:15.708306 139881808373504 logging_writer.py:48] [370700] global_step=370700, grad_norm=3.9843735694885254, loss=3.238039255142212
I0304 12:37:58.823928 140077943854912 spec.py:321] Evaluating on the training split.
I0304 12:38:09.197104 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:38:39.245774 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:38:40.836659 140077943854912 submission_runner.py:411] Time since start: 178313.64s, 	Step: 370799, 	{'train/accuracy': 0.8887695074081421, 'train/loss': 0.4166419804096222, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 163042.84110546112, 'total_duration': 178313.641654253, 'accumulated_submission_time': 163042.84110546112, 'accumulated_eval_time': 15225.187652349472, 'accumulated_logging_time': 26.298811674118042}
I0304 12:38:40.924708 139881799980800 logging_writer.py:48] [370799] accumulated_eval_time=15225.187652, accumulated_logging_time=26.298812, accumulated_submission_time=163042.841105, global_step=370799, preemption_count=0, score=163042.841105, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=178313.641654, train/accuracy=0.888770, train/loss=0.416642, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:38:41.717854 139881808373504 logging_writer.py:48] [370800] global_step=370800, grad_norm=3.022026300430298, loss=2.341186285018921
I0304 12:39:22.682460 139881799980800 logging_writer.py:48] [370900] global_step=370900, grad_norm=2.902250051498413, loss=1.0782254934310913
I0304 12:40:07.149390 139881808373504 logging_writer.py:48] [371000] global_step=371000, grad_norm=3.15926456451416, loss=1.184260606765747
I0304 12:40:51.478451 139881799980800 logging_writer.py:48] [371100] global_step=371100, grad_norm=3.3618061542510986, loss=1.0993136167526245
I0304 12:41:35.811776 139881808373504 logging_writer.py:48] [371200] global_step=371200, grad_norm=3.249433755874634, loss=1.163601279258728
I0304 12:42:20.482837 139881799980800 logging_writer.py:48] [371300] global_step=371300, grad_norm=3.1304683685302734, loss=2.8608765602111816
I0304 12:43:05.113808 139881808373504 logging_writer.py:48] [371400] global_step=371400, grad_norm=3.4061927795410156, loss=2.345001697540283
I0304 12:43:49.339019 139881799980800 logging_writer.py:48] [371500] global_step=371500, grad_norm=3.862644672393799, loss=3.273515224456787
I0304 12:44:34.037657 139881808373504 logging_writer.py:48] [371600] global_step=371600, grad_norm=2.9639947414398193, loss=1.2050914764404297
I0304 12:45:18.492709 139881799980800 logging_writer.py:48] [371700] global_step=371700, grad_norm=3.1235744953155518, loss=1.179444670677185
I0304 12:45:41.165781 140077943854912 spec.py:321] Evaluating on the training split.
I0304 12:45:51.753414 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:46:22.700916 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:46:24.319468 140077943854912 submission_runner.py:411] Time since start: 178777.12s, 	Step: 371753, 	{'train/accuracy': 0.8869921565055847, 'train/loss': 0.4218083918094635, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 163463.0209646225, 'total_duration': 178777.1244843006, 'accumulated_submission_time': 163463.0209646225, 'accumulated_eval_time': 15268.341364622116, 'accumulated_logging_time': 26.399053812026978}
I0304 12:46:24.392211 139881808373504 logging_writer.py:48] [371753] accumulated_eval_time=15268.341365, accumulated_logging_time=26.399054, accumulated_submission_time=163463.020965, global_step=371753, preemption_count=0, score=163463.020965, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=178777.124484, train/accuracy=0.886992, train/loss=0.421808, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:46:43.129231 139881799980800 logging_writer.py:48] [371800] global_step=371800, grad_norm=3.605102777481079, loss=2.422722816467285
I0304 12:47:25.089833 139881808373504 logging_writer.py:48] [371900] global_step=371900, grad_norm=4.252450942993164, loss=3.1658506393432617
I0304 12:48:09.543634 139881799980800 logging_writer.py:48] [372000] global_step=372000, grad_norm=3.031153917312622, loss=1.0453927516937256
I0304 12:48:53.952881 139881808373504 logging_writer.py:48] [372100] global_step=372100, grad_norm=3.4205338954925537, loss=1.1909511089324951
I0304 12:49:38.523272 139881799980800 logging_writer.py:48] [372200] global_step=372200, grad_norm=3.1549363136291504, loss=2.4758055210113525
I0304 12:50:23.008669 139881808373504 logging_writer.py:48] [372300] global_step=372300, grad_norm=3.0495998859405518, loss=2.676682472229004
I0304 12:51:07.608216 139881799980800 logging_writer.py:48] [372400] global_step=372400, grad_norm=3.0233163833618164, loss=1.0958772897720337
I0304 12:51:51.886406 139881808373504 logging_writer.py:48] [372500] global_step=372500, grad_norm=3.225379705429077, loss=2.8485655784606934
I0304 12:52:36.404729 139881799980800 logging_writer.py:48] [372600] global_step=372600, grad_norm=2.9075284004211426, loss=1.473717451095581
I0304 12:53:20.813176 139881808373504 logging_writer.py:48] [372700] global_step=372700, grad_norm=3.100064992904663, loss=1.158528447151184
I0304 12:53:24.477489 140077943854912 spec.py:321] Evaluating on the training split.
I0304 12:53:34.629783 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 12:54:00.440005 140077943854912 spec.py:349] Evaluating on the test split.
I0304 12:54:02.028293 140077943854912 submission_runner.py:411] Time since start: 179234.83s, 	Step: 372710, 	{'train/accuracy': 0.8858007788658142, 'train/loss': 0.4265918731689453, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 163883.04605412483, 'total_duration': 179234.83329749107, 'accumulated_submission_time': 163883.04605412483, 'accumulated_eval_time': 15305.892180919647, 'accumulated_logging_time': 26.482391119003296}
I0304 12:54:02.142492 139881799980800 logging_writer.py:48] [372710] accumulated_eval_time=15305.892181, accumulated_logging_time=26.482391, accumulated_submission_time=163883.046054, global_step=372710, preemption_count=0, score=163883.046054, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=179234.833297, train/accuracy=0.885801, train/loss=0.426592, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 12:54:38.952448 139881808373504 logging_writer.py:48] [372800] global_step=372800, grad_norm=3.0601065158843994, loss=1.0145255327224731
I0304 12:55:23.260234 139881799980800 logging_writer.py:48] [372900] global_step=372900, grad_norm=3.0085487365722656, loss=1.0294688940048218
I0304 12:56:07.740719 139881808373504 logging_writer.py:48] [373000] global_step=373000, grad_norm=3.208113431930542, loss=1.1719231605529785
I0304 12:56:52.433546 139881799980800 logging_writer.py:48] [373100] global_step=373100, grad_norm=3.698540449142456, loss=3.237260580062866
I0304 12:57:36.647610 139881808373504 logging_writer.py:48] [373200] global_step=373200, grad_norm=3.2523722648620605, loss=1.1824233531951904
I0304 12:58:21.286530 139881799980800 logging_writer.py:48] [373300] global_step=373300, grad_norm=3.0228092670440674, loss=1.0280773639678955
I0304 12:59:05.619945 139881808373504 logging_writer.py:48] [373400] global_step=373400, grad_norm=3.126556396484375, loss=2.27238130569458
I0304 12:59:49.908139 139881799980800 logging_writer.py:48] [373500] global_step=373500, grad_norm=3.1960294246673584, loss=1.4816919565200806
I0304 13:00:34.502194 139881808373504 logging_writer.py:48] [373600] global_step=373600, grad_norm=3.5581696033477783, loss=1.2583789825439453
I0304 13:01:02.067797 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:01:12.413131 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:01:49.246457 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:01:50.830446 140077943854912 submission_runner.py:411] Time since start: 179703.64s, 	Step: 373664, 	{'train/accuracy': 0.8891406059265137, 'train/loss': 0.4111347496509552, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 164302.91035580635, 'total_duration': 179703.6354522705, 'accumulated_submission_time': 164302.91035580635, 'accumulated_eval_time': 15354.65480685234, 'accumulated_logging_time': 26.608601808547974}
I0304 13:01:50.918014 139881799980800 logging_writer.py:48] [373664] accumulated_eval_time=15354.654807, accumulated_logging_time=26.608602, accumulated_submission_time=164302.910356, global_step=373664, preemption_count=0, score=164302.910356, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=179703.635452, train/accuracy=0.889141, train/loss=0.411135, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:02:05.354161 139881808373504 logging_writer.py:48] [373700] global_step=373700, grad_norm=3.2231016159057617, loss=1.2053169012069702
I0304 13:02:46.983842 139881799980800 logging_writer.py:48] [373800] global_step=373800, grad_norm=3.1367955207824707, loss=1.1642494201660156
I0304 13:03:31.495394 139881808373504 logging_writer.py:48] [373900] global_step=373900, grad_norm=3.0651450157165527, loss=1.9968857765197754
I0304 13:04:16.021083 139881799980800 logging_writer.py:48] [374000] global_step=374000, grad_norm=3.167616844177246, loss=1.16377592086792
I0304 13:05:00.815150 139881808373504 logging_writer.py:48] [374100] global_step=374100, grad_norm=3.196343421936035, loss=1.1973106861114502
I0304 13:05:45.095114 139881799980800 logging_writer.py:48] [374200] global_step=374200, grad_norm=3.1107587814331055, loss=1.2643696069717407
I0304 13:06:29.632280 139881808373504 logging_writer.py:48] [374300] global_step=374300, grad_norm=3.134268283843994, loss=1.466027021408081
I0304 13:07:14.090474 139881799980800 logging_writer.py:48] [374400] global_step=374400, grad_norm=3.1677463054656982, loss=1.0503976345062256
I0304 13:07:58.543810 139881808373504 logging_writer.py:48] [374500] global_step=374500, grad_norm=4.0870747566223145, loss=3.353175163269043
I0304 13:08:42.910510 139881799980800 logging_writer.py:48] [374600] global_step=374600, grad_norm=3.5386135578155518, loss=2.265921115875244
I0304 13:08:50.975590 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:09:01.222836 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:09:34.867987 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:09:36.457583 140077943854912 submission_runner.py:411] Time since start: 180169.26s, 	Step: 374620, 	{'train/accuracy': 0.8878710865974426, 'train/loss': 0.41271552443504333, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 164722.90692043304, 'total_duration': 180169.262591362, 'accumulated_submission_time': 164722.90692043304, 'accumulated_eval_time': 15400.136773586273, 'accumulated_logging_time': 26.708449602127075}
I0304 13:09:36.533556 139881808373504 logging_writer.py:48] [374620] accumulated_eval_time=15400.136774, accumulated_logging_time=26.708450, accumulated_submission_time=164722.906920, global_step=374620, preemption_count=0, score=164722.906920, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=180169.262591, train/accuracy=0.887871, train/loss=0.412716, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:10:08.179801 139881799980800 logging_writer.py:48] [374700] global_step=374700, grad_norm=3.262810468673706, loss=2.810401678085327
I0304 13:10:52.180427 139881808373504 logging_writer.py:48] [374800] global_step=374800, grad_norm=3.021634817123413, loss=1.1532093286514282
I0304 13:11:36.592530 139881799980800 logging_writer.py:48] [374900] global_step=374900, grad_norm=2.8852627277374268, loss=1.4347350597381592
I0304 13:12:21.094096 139881808373504 logging_writer.py:48] [375000] global_step=375000, grad_norm=2.7370593547821045, loss=1.2615503072738647
I0304 13:13:05.380175 139881799980800 logging_writer.py:48] [375100] global_step=375100, grad_norm=2.924288511276245, loss=1.9356271028518677
I0304 13:13:49.865386 139881808373504 logging_writer.py:48] [375200] global_step=375200, grad_norm=4.001499176025391, loss=3.2890491485595703
I0304 13:14:34.107548 139881799980800 logging_writer.py:48] [375300] global_step=375300, grad_norm=3.4324421882629395, loss=2.1846179962158203
I0304 13:15:19.004647 139881808373504 logging_writer.py:48] [375400] global_step=375400, grad_norm=2.986423969268799, loss=1.6905213594436646
I0304 13:16:03.464884 139881799980800 logging_writer.py:48] [375500] global_step=375500, grad_norm=3.534156560897827, loss=1.2328572273254395
I0304 13:16:36.728988 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:16:47.310847 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:17:20.264077 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:17:21.845094 140077943854912 submission_runner.py:411] Time since start: 180634.65s, 	Step: 375576, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.42199134826660156, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 165143.0420908928, 'total_duration': 180634.65010356903, 'accumulated_submission_time': 165143.0420908928, 'accumulated_eval_time': 15445.25285935402, 'accumulated_logging_time': 26.795263290405273}
I0304 13:17:21.917765 139881808373504 logging_writer.py:48] [375576] accumulated_eval_time=15445.252859, accumulated_logging_time=26.795263, accumulated_submission_time=165143.042091, global_step=375576, preemption_count=0, score=165143.042091, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=180634.650104, train/accuracy=0.887461, train/loss=0.421991, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:17:31.656616 139881799980800 logging_writer.py:48] [375600] global_step=375600, grad_norm=3.3087830543518066, loss=2.7380495071411133
I0304 13:18:15.305799 139881808373504 logging_writer.py:48] [375700] global_step=375700, grad_norm=3.500626802444458, loss=1.1391589641571045
I0304 13:18:59.553074 139881799980800 logging_writer.py:48] [375800] global_step=375800, grad_norm=3.5804312229156494, loss=1.1705641746520996
I0304 13:19:44.201055 139881808373504 logging_writer.py:48] [375900] global_step=375900, grad_norm=3.6800544261932373, loss=3.2116963863372803
I0304 13:20:28.579952 139881799980800 logging_writer.py:48] [376000] global_step=376000, grad_norm=3.174407720565796, loss=1.1231878995895386
I0304 13:21:13.265294 139881808373504 logging_writer.py:48] [376100] global_step=376100, grad_norm=3.428873062133789, loss=2.486119508743286
I0304 13:21:57.642001 139881799980800 logging_writer.py:48] [376200] global_step=376200, grad_norm=3.0502662658691406, loss=1.0602890253067017
I0304 13:22:42.154183 139881808373504 logging_writer.py:48] [376300] global_step=376300, grad_norm=2.9687180519104004, loss=1.4165147542953491
I0304 13:23:26.692654 139881799980800 logging_writer.py:48] [376400] global_step=376400, grad_norm=3.097057342529297, loss=1.6822314262390137
I0304 13:24:11.027023 139881808373504 logging_writer.py:48] [376500] global_step=376500, grad_norm=2.992170572280884, loss=1.7940285205841064
I0304 13:24:21.957544 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:24:32.416230 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:25:05.214826 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:25:06.792741 140077943854912 submission_runner.py:411] Time since start: 181099.60s, 	Step: 376526, 	{'train/accuracy': 0.887011706829071, 'train/loss': 0.4182519316673279, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 165563.02144479752, 'total_duration': 181099.59773135185, 'accumulated_submission_time': 165563.02144479752, 'accumulated_eval_time': 15490.088018417358, 'accumulated_logging_time': 26.87953495979309}
I0304 13:25:06.865376 139881799980800 logging_writer.py:48] [376526] accumulated_eval_time=15490.088018, accumulated_logging_time=26.879535, accumulated_submission_time=165563.021445, global_step=376526, preemption_count=0, score=165563.021445, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=181099.597731, train/accuracy=0.887012, train/loss=0.418252, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:25:36.165197 139881808373504 logging_writer.py:48] [376600] global_step=376600, grad_norm=3.4370803833007812, loss=2.4892079830169678
I0304 13:26:20.068557 139881799980800 logging_writer.py:48] [376700] global_step=376700, grad_norm=3.1963000297546387, loss=1.322189450263977
I0304 13:27:04.590031 139881808373504 logging_writer.py:48] [376800] global_step=376800, grad_norm=3.087575674057007, loss=1.4524028301239014
I0304 13:27:49.019311 139881799980800 logging_writer.py:48] [376900] global_step=376900, grad_norm=2.930013418197632, loss=2.0892739295959473
I0304 13:28:33.254648 139881808373504 logging_writer.py:48] [377000] global_step=377000, grad_norm=3.2375752925872803, loss=1.1251978874206543
I0304 13:29:17.682098 139881799980800 logging_writer.py:48] [377100] global_step=377100, grad_norm=3.24603533744812, loss=2.869460105895996
I0304 13:30:02.068616 139881808373504 logging_writer.py:48] [377200] global_step=377200, grad_norm=2.9648499488830566, loss=1.0964925289154053
I0304 13:30:46.503929 139881799980800 logging_writer.py:48] [377300] global_step=377300, grad_norm=2.9958584308624268, loss=1.0801960229873657
I0304 13:31:30.991255 139881808373504 logging_writer.py:48] [377400] global_step=377400, grad_norm=3.4802095890045166, loss=1.1609628200531006
I0304 13:32:07.179141 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:32:17.627479 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:32:43.768403 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:32:45.365097 140077943854912 submission_runner.py:411] Time since start: 181558.17s, 	Step: 377483, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.4191173315048218, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 165983.27627158165, 'total_duration': 181558.17009282112, 'accumulated_submission_time': 165983.27627158165, 'accumulated_eval_time': 15528.273938655853, 'accumulated_logging_time': 26.961669921875}
I0304 13:32:45.451363 139881799980800 logging_writer.py:48] [377483] accumulated_eval_time=15528.273939, accumulated_logging_time=26.961670, accumulated_submission_time=165983.276272, global_step=377483, preemption_count=0, score=165983.276272, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=181558.170093, train/accuracy=0.888340, train/loss=0.419117, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:32:52.488128 139881808373504 logging_writer.py:48] [377500] global_step=377500, grad_norm=3.007450819015503, loss=1.3200421333312988
I0304 13:33:34.329841 139881799980800 logging_writer.py:48] [377600] global_step=377600, grad_norm=3.1235029697418213, loss=2.9452157020568848
I0304 13:34:18.743021 139881808373504 logging_writer.py:48] [377700] global_step=377700, grad_norm=3.7357113361358643, loss=3.259172201156616
I0304 13:35:03.585072 139881799980800 logging_writer.py:48] [377800] global_step=377800, grad_norm=3.236232042312622, loss=2.58329176902771
I0304 13:35:48.013658 139881808373504 logging_writer.py:48] [377900] global_step=377900, grad_norm=3.839200019836426, loss=3.277186870574951
I0304 13:36:32.892865 139881799980800 logging_writer.py:48] [378000] global_step=378000, grad_norm=3.16573166847229, loss=1.328802227973938
I0304 13:37:17.536608 139881808373504 logging_writer.py:48] [378100] global_step=378100, grad_norm=3.257565975189209, loss=1.2815227508544922
I0304 13:38:02.071151 139881799980800 logging_writer.py:48] [378200] global_step=378200, grad_norm=3.5450332164764404, loss=2.953460931777954
I0304 13:38:46.526406 139881808373504 logging_writer.py:48] [378300] global_step=378300, grad_norm=3.4654669761657715, loss=2.6210014820098877
I0304 13:39:31.024124 139881799980800 logging_writer.py:48] [378400] global_step=378400, grad_norm=3.378816843032837, loss=1.109116554260254
I0304 13:39:45.457999 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:39:55.803348 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:40:32.101808 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:40:33.688630 140077943854912 submission_runner.py:411] Time since start: 182026.49s, 	Step: 378434, 	{'train/accuracy': 0.8884570002555847, 'train/loss': 0.41421037912368774, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 166403.22260427475, 'total_duration': 182026.49364376068, 'accumulated_submission_time': 166403.22260427475, 'accumulated_eval_time': 15576.504554748535, 'accumulated_logging_time': 27.059396266937256}
I0304 13:40:33.760725 139881808373504 logging_writer.py:48] [378434] accumulated_eval_time=15576.504555, accumulated_logging_time=27.059396, accumulated_submission_time=166403.222604, global_step=378434, preemption_count=0, score=166403.222604, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=182026.493644, train/accuracy=0.888457, train/loss=0.414210, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:40:59.913312 139881799980800 logging_writer.py:48] [378500] global_step=378500, grad_norm=3.347724199295044, loss=3.0035128593444824
I0304 13:41:43.284091 139881808373504 logging_writer.py:48] [378600] global_step=378600, grad_norm=3.6793582439422607, loss=3.356926202774048
I0304 13:42:27.633545 139881799980800 logging_writer.py:48] [378700] global_step=378700, grad_norm=3.1351938247680664, loss=1.177375078201294
I0304 13:43:12.399815 139881808373504 logging_writer.py:48] [378800] global_step=378800, grad_norm=3.2479138374328613, loss=1.1188825368881226
I0304 13:43:56.730403 139881799980800 logging_writer.py:48] [378900] global_step=378900, grad_norm=2.8838038444519043, loss=1.2051384449005127
I0304 13:44:41.229620 139881808373504 logging_writer.py:48] [379000] global_step=379000, grad_norm=3.0394814014434814, loss=1.0715584754943848
I0304 13:45:25.897887 139881799980800 logging_writer.py:48] [379100] global_step=379100, grad_norm=3.252835988998413, loss=1.1797876358032227
I0304 13:46:10.365042 139881808373504 logging_writer.py:48] [379200] global_step=379200, grad_norm=3.1237425804138184, loss=1.0268288850784302
I0304 13:46:54.733522 139881799980800 logging_writer.py:48] [379300] global_step=379300, grad_norm=3.0227603912353516, loss=1.0815750360488892
I0304 13:47:33.903252 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:47:44.120728 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:48:10.514538 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:48:12.103290 140077943854912 submission_runner.py:411] Time since start: 182484.91s, 	Step: 379390, 	{'train/accuracy': 0.8917577862739563, 'train/loss': 0.4062821865081787, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 166823.30525374413, 'total_duration': 182484.9082839489, 'accumulated_submission_time': 166823.30525374413, 'accumulated_eval_time': 15614.70454120636, 'accumulated_logging_time': 27.141717195510864}
I0304 13:48:12.195911 139881808373504 logging_writer.py:48] [379390] accumulated_eval_time=15614.704541, accumulated_logging_time=27.141717, accumulated_submission_time=166823.305254, global_step=379390, preemption_count=0, score=166823.305254, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=182484.908284, train/accuracy=0.891758, train/loss=0.406282, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:48:16.503899 139881799980800 logging_writer.py:48] [379400] global_step=379400, grad_norm=3.3994553089141846, loss=1.127585530281067
I0304 13:48:57.723156 139881808373504 logging_writer.py:48] [379500] global_step=379500, grad_norm=2.9009206295013428, loss=1.0901931524276733
I0304 13:49:42.283875 139881799980800 logging_writer.py:48] [379600] global_step=379600, grad_norm=3.0837340354919434, loss=1.13645601272583
I0304 13:50:26.676729 139881808373504 logging_writer.py:48] [379700] global_step=379700, grad_norm=3.499743938446045, loss=1.349791407585144
I0304 13:51:11.268931 139881799980800 logging_writer.py:48] [379800] global_step=379800, grad_norm=3.2316391468048096, loss=1.908326506614685
I0304 13:51:55.355917 139881808373504 logging_writer.py:48] [379900] global_step=379900, grad_norm=3.070486068725586, loss=1.2657471895217896
I0304 13:52:39.881367 139881799980800 logging_writer.py:48] [380000] global_step=380000, grad_norm=3.2721493244171143, loss=1.1509573459625244
I0304 13:53:24.735049 139881808373504 logging_writer.py:48] [380100] global_step=380100, grad_norm=3.4210450649261475, loss=2.8844573497772217
I0304 13:54:09.110369 139881799980800 logging_writer.py:48] [380200] global_step=380200, grad_norm=2.971024751663208, loss=1.2110812664031982
I0304 13:54:53.187735 139881808373504 logging_writer.py:48] [380300] global_step=380300, grad_norm=3.3325395584106445, loss=1.0549290180206299
I0304 13:55:12.188234 140077943854912 spec.py:321] Evaluating on the training split.
I0304 13:55:22.573571 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 13:55:47.822655 140077943854912 spec.py:349] Evaluating on the test split.
I0304 13:55:49.410485 140077943854912 submission_runner.py:411] Time since start: 182942.22s, 	Step: 380344, 	{'train/accuracy': 0.8888476490974426, 'train/loss': 0.4164382219314575, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 167243.23605418205, 'total_duration': 182942.21549224854, 'accumulated_submission_time': 167243.23605418205, 'accumulated_eval_time': 15651.926760196686, 'accumulated_logging_time': 27.245988607406616}
I0304 13:55:49.501158 139881799980800 logging_writer.py:48] [380344] accumulated_eval_time=15651.926760, accumulated_logging_time=27.245989, accumulated_submission_time=167243.236054, global_step=380344, preemption_count=0, score=167243.236054, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=182942.215492, train/accuracy=0.888848, train/loss=0.416438, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 13:56:11.748429 139881808373504 logging_writer.py:48] [380400] global_step=380400, grad_norm=3.091461658477783, loss=2.4048497676849365
I0304 13:56:55.950863 139881799980800 logging_writer.py:48] [380500] global_step=380500, grad_norm=3.2790300846099854, loss=3.0383920669555664
I0304 13:57:40.411355 139881808373504 logging_writer.py:48] [380600] global_step=380600, grad_norm=3.0073299407958984, loss=2.44372296333313
I0304 13:58:25.094853 139881799980800 logging_writer.py:48] [380700] global_step=380700, grad_norm=3.2172110080718994, loss=1.0626330375671387
I0304 13:59:09.546545 139881808373504 logging_writer.py:48] [380800] global_step=380800, grad_norm=3.104609251022339, loss=1.025477647781372
I0304 13:59:53.951448 139881799980800 logging_writer.py:48] [380900] global_step=380900, grad_norm=3.1538612842559814, loss=1.896488904953003
I0304 14:00:38.653855 139881808373504 logging_writer.py:48] [381000] global_step=381000, grad_norm=2.9271788597106934, loss=1.141823649406433
I0304 14:01:23.077373 139881799980800 logging_writer.py:48] [381100] global_step=381100, grad_norm=3.1435348987579346, loss=1.0185120105743408
I0304 14:02:07.589579 139881808373504 logging_writer.py:48] [381200] global_step=381200, grad_norm=2.935188055038452, loss=1.533908486366272
I0304 14:02:49.762531 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:03:00.402219 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:03:30.198172 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:03:31.786190 140077943854912 submission_runner.py:411] Time since start: 183404.59s, 	Step: 381297, 	{'train/accuracy': 0.8883007764816284, 'train/loss': 0.41521593928337097, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 167663.43669724464, 'total_duration': 183404.59119343758, 'accumulated_submission_time': 167663.43669724464, 'accumulated_eval_time': 15693.950403213501, 'accumulated_logging_time': 27.34863257408142}
I0304 14:03:31.876436 139881799980800 logging_writer.py:48] [381297] accumulated_eval_time=15693.950403, accumulated_logging_time=27.348633, accumulated_submission_time=167663.436697, global_step=381297, preemption_count=0, score=167663.436697, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=183404.591193, train/accuracy=0.888301, train/loss=0.415216, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:03:33.459596 139881808373504 logging_writer.py:48] [381300] global_step=381300, grad_norm=3.026167631149292, loss=1.137566089630127
I0304 14:04:14.228412 139881799980800 logging_writer.py:48] [381400] global_step=381400, grad_norm=4.068361759185791, loss=3.1589107513427734
I0304 14:04:58.613472 139881808373504 logging_writer.py:48] [381500] global_step=381500, grad_norm=4.086917400360107, loss=3.254021644592285
I0304 14:05:43.549341 139881799980800 logging_writer.py:48] [381600] global_step=381600, grad_norm=3.3199007511138916, loss=2.9042601585388184
I0304 14:06:28.068556 139881808373504 logging_writer.py:48] [381700] global_step=381700, grad_norm=3.327613115310669, loss=1.0686571598052979
I0304 14:07:12.640691 139881799980800 logging_writer.py:48] [381800] global_step=381800, grad_norm=3.0565857887268066, loss=1.1981217861175537
I0304 14:07:56.926963 139881808373504 logging_writer.py:48] [381900] global_step=381900, grad_norm=3.7222630977630615, loss=3.3407657146453857
I0304 14:08:41.381952 139881799980800 logging_writer.py:48] [382000] global_step=382000, grad_norm=3.2218215465545654, loss=1.2736932039260864
I0304 14:09:25.920716 139881808373504 logging_writer.py:48] [382100] global_step=382100, grad_norm=3.3016982078552246, loss=1.3993735313415527
I0304 14:10:10.152187 139881799980800 logging_writer.py:48] [382200] global_step=382200, grad_norm=2.820176362991333, loss=1.435502529144287
I0304 14:10:31.839003 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:10:42.339641 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:11:09.152833 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:11:10.741611 140077943854912 submission_runner.py:411] Time since start: 183863.55s, 	Step: 382250, 	{'train/accuracy': 0.8875195384025574, 'train/loss': 0.416832834482193, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 168083.33858251572, 'total_duration': 183863.54661631584, 'accumulated_submission_time': 168083.33858251572, 'accumulated_eval_time': 15732.852969169617, 'accumulated_logging_time': 27.450412034988403}
I0304 14:11:10.834041 139881808373504 logging_writer.py:48] [382250] accumulated_eval_time=15732.852969, accumulated_logging_time=27.450412, accumulated_submission_time=168083.338583, global_step=382250, preemption_count=0, score=168083.338583, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=183863.546616, train/accuracy=0.887520, train/loss=0.416833, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:11:30.778367 139881799980800 logging_writer.py:48] [382300] global_step=382300, grad_norm=3.5553550720214844, loss=3.0478739738464355
I0304 14:12:13.999114 139881808373504 logging_writer.py:48] [382400] global_step=382400, grad_norm=3.1441164016723633, loss=1.4125733375549316
I0304 14:12:58.074508 139881799980800 logging_writer.py:48] [382500] global_step=382500, grad_norm=3.0010480880737305, loss=1.3659311532974243
I0304 14:13:42.500716 139881808373504 logging_writer.py:48] [382600] global_step=382600, grad_norm=3.2975757122039795, loss=1.0817428827285767
I0304 14:14:26.876206 139881799980800 logging_writer.py:48] [382700] global_step=382700, grad_norm=2.8957011699676514, loss=1.0404026508331299
I0304 14:15:11.306625 139881808373504 logging_writer.py:48] [382800] global_step=382800, grad_norm=3.639897584915161, loss=3.0853395462036133
I0304 14:15:55.743083 139881799980800 logging_writer.py:48] [382900] global_step=382900, grad_norm=3.167022228240967, loss=1.0846047401428223
I0304 14:16:40.443940 139881808373504 logging_writer.py:48] [383000] global_step=383000, grad_norm=2.973905086517334, loss=1.1665199995040894
I0304 14:17:24.982266 139881799980800 logging_writer.py:48] [383100] global_step=383100, grad_norm=3.0620410442352295, loss=1.3146475553512573
I0304 14:18:09.576138 139881808373504 logging_writer.py:48] [383200] global_step=383200, grad_norm=3.225537061691284, loss=1.1672190427780151
I0304 14:18:10.942343 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:18:20.969449 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:18:52.847906 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:18:54.439454 140077943854912 submission_runner.py:411] Time since start: 184327.24s, 	Step: 383205, 	{'train/accuracy': 0.8854296803474426, 'train/loss': 0.4210447669029236, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 168503.38748073578, 'total_duration': 184327.24445915222, 'accumulated_submission_time': 168503.38748073578, 'accumulated_eval_time': 15776.350043535233, 'accumulated_logging_time': 27.553287982940674}
I0304 14:18:54.530091 139881799980800 logging_writer.py:48] [383205] accumulated_eval_time=15776.350044, accumulated_logging_time=27.553288, accumulated_submission_time=168503.387481, global_step=383205, preemption_count=0, score=168503.387481, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=184327.244459, train/accuracy=0.885430, train/loss=0.421045, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:19:33.270968 139881808373504 logging_writer.py:48] [383300] global_step=383300, grad_norm=3.0167434215545654, loss=1.3664131164550781
I0304 14:20:17.359942 139881799980800 logging_writer.py:48] [383400] global_step=383400, grad_norm=2.981424331665039, loss=1.6432392597198486
I0304 14:21:01.909241 139881808373504 logging_writer.py:48] [383500] global_step=383500, grad_norm=3.0618319511413574, loss=1.8804709911346436
I0304 14:21:46.308366 139881799980800 logging_writer.py:48] [383600] global_step=383600, grad_norm=3.401026964187622, loss=2.9917635917663574
I0304 14:22:30.767926 139881808373504 logging_writer.py:48] [383700] global_step=383700, grad_norm=3.04675030708313, loss=2.7843923568725586
I0304 14:23:15.155112 139881799980800 logging_writer.py:48] [383800] global_step=383800, grad_norm=3.4654183387756348, loss=2.9314088821411133
I0304 14:23:59.819517 139881808373504 logging_writer.py:48] [383900] global_step=383900, grad_norm=3.2568602561950684, loss=1.3856704235076904
I0304 14:24:44.317231 139881799980800 logging_writer.py:48] [384000] global_step=384000, grad_norm=3.3195817470550537, loss=2.902573347091675
I0304 14:25:29.293354 139881808373504 logging_writer.py:48] [384100] global_step=384100, grad_norm=3.182166814804077, loss=1.0652151107788086
I0304 14:25:54.790244 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:26:05.059857 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:26:34.219184 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:26:35.808848 140077943854912 submission_runner.py:411] Time since start: 184788.61s, 	Step: 384159, 	{'train/accuracy': 0.889941394329071, 'train/loss': 0.409912645816803, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 168923.58438396454, 'total_duration': 184788.61385440826, 'accumulated_submission_time': 168923.58438396454, 'accumulated_eval_time': 15817.368630886078, 'accumulated_logging_time': 27.65798783302307}
I0304 14:26:35.915033 139881799980800 logging_writer.py:48] [384159] accumulated_eval_time=15817.368631, accumulated_logging_time=27.657988, accumulated_submission_time=168923.584384, global_step=384159, preemption_count=0, score=168923.584384, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=184788.613854, train/accuracy=0.889941, train/loss=0.409913, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:26:52.315528 139881808373504 logging_writer.py:48] [384200] global_step=384200, grad_norm=3.6294281482696533, loss=3.2504348754882812
I0304 14:27:34.676263 139881799980800 logging_writer.py:48] [384300] global_step=384300, grad_norm=2.8535637855529785, loss=1.9701675176620483
I0304 14:28:19.255075 139881808373504 logging_writer.py:48] [384400] global_step=384400, grad_norm=3.886199951171875, loss=1.1768252849578857
I0304 14:29:03.896412 139881799980800 logging_writer.py:48] [384500] global_step=384500, grad_norm=4.159297466278076, loss=3.261786937713623
I0304 14:29:48.110534 139881808373504 logging_writer.py:48] [384600] global_step=384600, grad_norm=3.0007052421569824, loss=1.0573720932006836
I0304 14:30:32.193553 139881799980800 logging_writer.py:48] [384700] global_step=384700, grad_norm=3.6928024291992188, loss=3.259305477142334
I0304 14:31:16.550192 139881808373504 logging_writer.py:48] [384800] global_step=384800, grad_norm=3.4162681102752686, loss=1.1668107509613037
I0304 14:32:00.737822 139881799980800 logging_writer.py:48] [384900] global_step=384900, grad_norm=3.311892032623291, loss=1.4053598642349243
I0304 14:32:45.045266 139881808373504 logging_writer.py:48] [385000] global_step=385000, grad_norm=3.927739143371582, loss=3.2049598693847656
I0304 14:33:29.519967 139881799980800 logging_writer.py:48] [385100] global_step=385100, grad_norm=3.1792685985565186, loss=2.5249714851379395
I0304 14:33:36.208644 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:33:46.367110 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:34:16.368381 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:34:17.976658 140077943854912 submission_runner.py:411] Time since start: 185250.78s, 	Step: 385117, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.4181992709636688, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 169343.8165242672, 'total_duration': 185250.7816569805, 'accumulated_submission_time': 169343.8165242672, 'accumulated_eval_time': 15859.136594057083, 'accumulated_logging_time': 27.77664041519165}
I0304 14:34:18.072674 139881808373504 logging_writer.py:48] [385117] accumulated_eval_time=15859.136594, accumulated_logging_time=27.776640, accumulated_submission_time=169343.816524, global_step=385117, preemption_count=0, score=169343.816524, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=185250.781657, train/accuracy=0.887910, train/loss=0.418199, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:34:50.858657 139881799980800 logging_writer.py:48] [385200] global_step=385200, grad_norm=3.0106897354125977, loss=1.2884867191314697
I0304 14:35:34.770325 139881808373504 logging_writer.py:48] [385300] global_step=385300, grad_norm=3.4461724758148193, loss=1.324074625968933
I0304 14:36:19.480446 139881799980800 logging_writer.py:48] [385400] global_step=385400, grad_norm=3.5558154582977295, loss=3.2396016120910645
I0304 14:37:04.144798 139881808373504 logging_writer.py:48] [385500] global_step=385500, grad_norm=2.946943521499634, loss=1.1953251361846924
I0304 14:37:48.503673 139881799980800 logging_writer.py:48] [385600] global_step=385600, grad_norm=3.1517136096954346, loss=1.1401327848434448
I0304 14:38:32.948012 139881808373504 logging_writer.py:48] [385700] global_step=385700, grad_norm=4.362367630004883, loss=1.1362508535385132
I0304 14:39:17.434344 139881799980800 logging_writer.py:48] [385800] global_step=385800, grad_norm=4.3003764152526855, loss=2.830503463745117
I0304 14:40:01.698209 139881808373504 logging_writer.py:48] [385900] global_step=385900, grad_norm=3.536034345626831, loss=1.121692180633545
I0304 14:40:45.985088 139881808373504 logging_writer.py:48] [386000] global_step=386000, grad_norm=3.4483141899108887, loss=2.2900917530059814
I0304 14:41:18.281317 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:41:28.508626 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:41:55.038639 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:41:56.623824 140077943854912 submission_runner.py:411] Time since start: 185709.43s, 	Step: 386074, 	{'train/accuracy': 0.8887499570846558, 'train/loss': 0.41673368215560913, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 169763.95485639572, 'total_duration': 185709.42883133888, 'accumulated_submission_time': 169763.95485639572, 'accumulated_eval_time': 15897.479062080383, 'accumulated_logging_time': 27.886797189712524}
I0304 14:41:56.718554 139881799980800 logging_writer.py:48] [386074] accumulated_eval_time=15897.479062, accumulated_logging_time=27.886797, accumulated_submission_time=169763.954856, global_step=386074, preemption_count=0, score=169763.954856, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=185709.428831, train/accuracy=0.888750, train/loss=0.416734, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:42:07.252296 139881808373504 logging_writer.py:48] [386100] global_step=386100, grad_norm=2.8013827800750732, loss=1.0495986938476562
I0304 14:42:49.460493 139881799980800 logging_writer.py:48] [386200] global_step=386200, grad_norm=3.598027467727661, loss=3.143052577972412
I0304 14:43:33.812983 139881808373504 logging_writer.py:48] [386300] global_step=386300, grad_norm=3.3755943775177, loss=1.2349679470062256
I0304 14:44:18.354691 139881799980800 logging_writer.py:48] [386400] global_step=386400, grad_norm=2.827080488204956, loss=1.130716323852539
I0304 14:45:02.770338 139881808373504 logging_writer.py:48] [386500] global_step=386500, grad_norm=3.0434038639068604, loss=1.4652663469314575
I0304 14:45:47.330519 139881799980800 logging_writer.py:48] [386600] global_step=386600, grad_norm=3.105161666870117, loss=1.4059978723526
I0304 14:46:32.121991 139881808373504 logging_writer.py:48] [386700] global_step=386700, grad_norm=3.0189216136932373, loss=1.821075677871704
I0304 14:47:17.098021 139881799980800 logging_writer.py:48] [386800] global_step=386800, grad_norm=3.0672757625579834, loss=1.1991782188415527
I0304 14:48:01.495654 139881808373504 logging_writer.py:48] [386900] global_step=386900, grad_norm=3.14890456199646, loss=1.2043955326080322
I0304 14:48:45.777100 139881799980800 logging_writer.py:48] [387000] global_step=387000, grad_norm=3.0721912384033203, loss=1.1237248182296753
I0304 14:48:56.976000 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:49:07.554465 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:49:36.848365 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:49:38.432722 140077943854912 submission_runner.py:411] Time since start: 186171.24s, 	Step: 387027, 	{'train/accuracy': 0.8863476514816284, 'train/loss': 0.42052730917930603, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 170184.15087461472, 'total_duration': 186171.23771500587, 'accumulated_submission_time': 170184.15087461472, 'accumulated_eval_time': 15938.935741901398, 'accumulated_logging_time': 27.993557691574097}
I0304 14:49:38.522113 139881808373504 logging_writer.py:48] [387027] accumulated_eval_time=15938.935742, accumulated_logging_time=27.993558, accumulated_submission_time=170184.150875, global_step=387027, preemption_count=0, score=170184.150875, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=186171.237715, train/accuracy=0.886348, train/loss=0.420527, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:50:07.799132 139881799980800 logging_writer.py:48] [387100] global_step=387100, grad_norm=3.9250917434692383, loss=1.9577159881591797
I0304 14:50:51.882663 139881808373504 logging_writer.py:48] [387200] global_step=387200, grad_norm=2.9074959754943848, loss=1.0527515411376953
I0304 14:51:36.522467 139881799980800 logging_writer.py:48] [387300] global_step=387300, grad_norm=2.8732664585113525, loss=1.73807692527771
I0304 14:52:21.105899 139881808373504 logging_writer.py:48] [387400] global_step=387400, grad_norm=2.871035099029541, loss=1.0651060342788696
I0304 14:53:05.537662 139881799980800 logging_writer.py:48] [387500] global_step=387500, grad_norm=3.1477468013763428, loss=2.8524997234344482
I0304 14:53:49.908797 139881808373504 logging_writer.py:48] [387600] global_step=387600, grad_norm=3.1058290004730225, loss=1.140859603881836
I0304 14:54:34.149068 139881799980800 logging_writer.py:48] [387700] global_step=387700, grad_norm=3.1462652683258057, loss=1.9012418985366821
I0304 14:55:18.442550 139881808373504 logging_writer.py:48] [387800] global_step=387800, grad_norm=3.3060200214385986, loss=1.2588160037994385
I0304 14:56:02.847841 139881799980800 logging_writer.py:48] [387900] global_step=387900, grad_norm=3.058173179626465, loss=2.0346286296844482
I0304 14:56:38.538549 140077943854912 spec.py:321] Evaluating on the training split.
I0304 14:56:48.918543 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 14:57:23.642254 140077943854912 spec.py:349] Evaluating on the test split.
I0304 14:57:25.216808 140077943854912 submission_runner.py:411] Time since start: 186638.02s, 	Step: 387982, 	{'train/accuracy': 0.8876562118530273, 'train/loss': 0.4173603355884552, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 170604.10696482658, 'total_duration': 186638.02182745934, 'accumulated_submission_time': 170604.10696482658, 'accumulated_eval_time': 15985.613999605179, 'accumulated_logging_time': 28.094316720962524}
I0304 14:57:25.290539 139881808373504 logging_writer.py:48] [387982] accumulated_eval_time=15985.614000, accumulated_logging_time=28.094317, accumulated_submission_time=170604.106965, global_step=387982, preemption_count=0, score=170604.106965, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=186638.021827, train/accuracy=0.887656, train/loss=0.417360, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 14:57:32.702141 139881799980800 logging_writer.py:48] [388000] global_step=388000, grad_norm=3.399040937423706, loss=3.0582854747772217
I0304 14:58:13.330263 139881808373504 logging_writer.py:48] [388100] global_step=388100, grad_norm=3.2449145317077637, loss=2.7747304439544678
I0304 14:58:57.391493 139881799980800 logging_writer.py:48] [388200] global_step=388200, grad_norm=3.813523292541504, loss=3.2885918617248535
I0304 14:59:42.181128 139881808373504 logging_writer.py:48] [388300] global_step=388300, grad_norm=3.3972673416137695, loss=1.1594617366790771
I0304 15:00:26.694453 139881799980800 logging_writer.py:48] [388400] global_step=388400, grad_norm=3.198254346847534, loss=1.9479542970657349
I0304 15:01:11.281272 139881808373504 logging_writer.py:48] [388500] global_step=388500, grad_norm=3.705920696258545, loss=3.255263566970825
I0304 15:01:55.307507 139881799980800 logging_writer.py:48] [388600] global_step=388600, grad_norm=3.1376047134399414, loss=1.1903847455978394
I0304 15:02:39.612645 139881808373504 logging_writer.py:48] [388700] global_step=388700, grad_norm=2.8942058086395264, loss=1.7983018159866333
I0304 15:03:24.155592 139881799980800 logging_writer.py:48] [388800] global_step=388800, grad_norm=3.5258805751800537, loss=2.543757438659668
I0304 15:04:08.584162 139881808373504 logging_writer.py:48] [388900] global_step=388900, grad_norm=2.8940751552581787, loss=2.0008442401885986
I0304 15:04:25.443789 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:04:36.369209 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:04:58.945129 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:05:00.529825 140077943854912 submission_runner.py:411] Time since start: 187093.33s, 	Step: 388940, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.4181455373764038, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 171024.2012052536, 'total_duration': 187093.33483076096, 'accumulated_submission_time': 171024.2012052536, 'accumulated_eval_time': 16020.70000576973, 'accumulated_logging_time': 28.178041458129883}
I0304 15:05:00.620765 139881799980800 logging_writer.py:48] [388940] accumulated_eval_time=16020.700006, accumulated_logging_time=28.178041, accumulated_submission_time=171024.201205, global_step=388940, preemption_count=0, score=171024.201205, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=187093.334831, train/accuracy=0.887676, train/loss=0.418146, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:05:24.423434 139881808373504 logging_writer.py:48] [389000] global_step=389000, grad_norm=3.431614875793457, loss=2.981658935546875
I0304 15:06:08.508260 139881799980800 logging_writer.py:48] [389100] global_step=389100, grad_norm=2.900642156600952, loss=2.0517873764038086
I0304 15:06:52.907187 139881808373504 logging_writer.py:48] [389200] global_step=389200, grad_norm=4.050631046295166, loss=3.249087333679199
I0304 15:07:37.609069 139881799980800 logging_writer.py:48] [389300] global_step=389300, grad_norm=3.294959783554077, loss=1.2207565307617188
I0304 15:08:22.293778 139881808373504 logging_writer.py:48] [389400] global_step=389400, grad_norm=2.9812183380126953, loss=2.006192445755005
I0304 15:09:06.720639 139881799980800 logging_writer.py:48] [389500] global_step=389500, grad_norm=3.148456335067749, loss=1.1459578275680542
I0304 15:09:51.104865 139881808373504 logging_writer.py:48] [389600] global_step=389600, grad_norm=3.267662763595581, loss=1.1314643621444702
I0304 15:10:35.662209 139881799980800 logging_writer.py:48] [389700] global_step=389700, grad_norm=3.005991220474243, loss=1.109609842300415
I0304 15:11:20.080607 139881808373504 logging_writer.py:48] [389800] global_step=389800, grad_norm=3.389605760574341, loss=1.1434299945831299
I0304 15:12:00.859215 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:12:11.192610 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:12:39.979516 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:12:41.561058 140077943854912 submission_runner.py:411] Time since start: 187554.37s, 	Step: 389894, 	{'train/accuracy': 0.8898437023162842, 'train/loss': 0.41513514518737793, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 171444.37899065018, 'total_duration': 187554.36606407166, 'accumulated_submission_time': 171444.37899065018, 'accumulated_eval_time': 16061.401812076569, 'accumulated_logging_time': 28.2806077003479}
I0304 15:12:41.653398 139881799980800 logging_writer.py:48] [389894] accumulated_eval_time=16061.401812, accumulated_logging_time=28.280608, accumulated_submission_time=171444.378991, global_step=389894, preemption_count=0, score=171444.378991, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=187554.366064, train/accuracy=0.889844, train/loss=0.415135, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:12:44.402337 139881808373504 logging_writer.py:48] [389900] global_step=389900, grad_norm=3.9443583488464355, loss=2.9938619136810303
I0304 15:13:25.790715 139881799980800 logging_writer.py:48] [390000] global_step=390000, grad_norm=3.849729061126709, loss=3.221820831298828
I0304 15:14:10.384032 139881808373504 logging_writer.py:48] [390100] global_step=390100, grad_norm=3.087509870529175, loss=2.0605735778808594
I0304 15:14:54.969987 139881799980800 logging_writer.py:48] [390200] global_step=390200, grad_norm=2.98899245262146, loss=1.4047813415527344
I0304 15:15:39.274706 139881808373504 logging_writer.py:48] [390300] global_step=390300, grad_norm=3.091559886932373, loss=1.2174098491668701
I0304 15:16:24.114601 139881799980800 logging_writer.py:48] [390400] global_step=390400, grad_norm=3.589193105697632, loss=1.113001823425293
I0304 15:17:08.669439 139881808373504 logging_writer.py:48] [390500] global_step=390500, grad_norm=3.281215190887451, loss=2.742997169494629
I0304 15:17:53.126621 139881799980800 logging_writer.py:48] [390600] global_step=390600, grad_norm=3.1849095821380615, loss=1.3267292976379395
I0304 15:18:38.004752 139881808373504 logging_writer.py:48] [390700] global_step=390700, grad_norm=3.150212049484253, loss=1.1580637693405151
I0304 15:19:22.456981 139881799980800 logging_writer.py:48] [390800] global_step=390800, grad_norm=3.192355155944824, loss=2.3458523750305176
I0304 15:19:41.688627 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:19:52.028553 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:20:30.678086 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:20:32.254880 140077943854912 submission_runner.py:411] Time since start: 188025.06s, 	Step: 390845, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.4167289733886719, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 171864.35090208054, 'total_duration': 188025.0598976612, 'accumulated_submission_time': 171864.35090208054, 'accumulated_eval_time': 16111.968054294586, 'accumulated_logging_time': 28.38612174987793}
I0304 15:20:32.329269 139881808373504 logging_writer.py:48] [390845] accumulated_eval_time=16111.968054, accumulated_logging_time=28.386122, accumulated_submission_time=171864.350902, global_step=390845, preemption_count=0, score=171864.350902, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=188025.059898, train/accuracy=0.888730, train/loss=0.416729, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:20:54.195703 139881799980800 logging_writer.py:48] [390900] global_step=390900, grad_norm=3.2236673831939697, loss=1.1447944641113281
I0304 15:21:36.555832 139881808373504 logging_writer.py:48] [391000] global_step=391000, grad_norm=3.0585849285125732, loss=2.0221636295318604
I0304 15:22:21.014118 139881799980800 logging_writer.py:48] [391100] global_step=391100, grad_norm=3.1456873416900635, loss=1.1123815774917603
I0304 15:23:05.650100 139881808373504 logging_writer.py:48] [391200] global_step=391200, grad_norm=3.3304624557495117, loss=1.0562039613723755
I0304 15:23:49.725306 139881799980800 logging_writer.py:48] [391300] global_step=391300, grad_norm=3.05696702003479, loss=1.148614525794983
I0304 15:24:34.071605 139881808373504 logging_writer.py:48] [391400] global_step=391400, grad_norm=2.9232418537139893, loss=1.023086428642273
I0304 15:25:18.535967 139881799980800 logging_writer.py:48] [391500] global_step=391500, grad_norm=3.110171318054199, loss=1.6827635765075684
I0304 15:26:03.248549 139881808373504 logging_writer.py:48] [391600] global_step=391600, grad_norm=3.3005924224853516, loss=2.0593643188476562
I0304 15:26:47.862737 139881799980800 logging_writer.py:48] [391700] global_step=391700, grad_norm=3.390578031539917, loss=1.273230791091919
I0304 15:27:32.268255 139881808373504 logging_writer.py:48] [391800] global_step=391800, grad_norm=3.1834444999694824, loss=1.2376413345336914
I0304 15:27:32.279526 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:27:42.339972 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:28:08.465674 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:28:10.051272 140077943854912 submission_runner.py:411] Time since start: 188482.86s, 	Step: 391801, 	{'train/accuracy': 0.88818359375, 'train/loss': 0.41370058059692383, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 172284.2420580387, 'total_duration': 188482.85627388954, 'accumulated_submission_time': 172284.2420580387, 'accumulated_eval_time': 16149.739753246307, 'accumulated_logging_time': 28.470293283462524}
I0304 15:28:10.147728 139881799980800 logging_writer.py:48] [391801] accumulated_eval_time=16149.739753, accumulated_logging_time=28.470293, accumulated_submission_time=172284.242058, global_step=391801, preemption_count=0, score=172284.242058, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=188482.856274, train/accuracy=0.888184, train/loss=0.413701, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:28:51.097274 139881808373504 logging_writer.py:48] [391900] global_step=391900, grad_norm=3.3862557411193848, loss=1.1151705980300903
I0304 15:29:35.484681 139881799980800 logging_writer.py:48] [392000] global_step=392000, grad_norm=2.904332399368286, loss=1.2989225387573242
I0304 15:30:19.835258 139881808373504 logging_writer.py:48] [392100] global_step=392100, grad_norm=3.1491141319274902, loss=1.3967695236206055
I0304 15:31:04.260085 139881799980800 logging_writer.py:48] [392200] global_step=392200, grad_norm=3.384415626525879, loss=3.037900924682617
I0304 15:31:48.538092 139881808373504 logging_writer.py:48] [392300] global_step=392300, grad_norm=3.4214868545532227, loss=1.1734392642974854
I0304 15:32:33.056689 139881799980800 logging_writer.py:48] [392400] global_step=392400, grad_norm=3.439631462097168, loss=1.2606877088546753
I0304 15:33:17.439044 139881808373504 logging_writer.py:48] [392500] global_step=392500, grad_norm=2.994255542755127, loss=1.158527135848999
I0304 15:34:01.895447 139881799980800 logging_writer.py:48] [392600] global_step=392600, grad_norm=3.1074376106262207, loss=2.565685510635376
I0304 15:34:46.260280 139881808373504 logging_writer.py:48] [392700] global_step=392700, grad_norm=3.207021951675415, loss=1.01500403881073
I0304 15:35:10.391976 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:35:21.220340 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:35:48.368088 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:35:49.958100 140077943854912 submission_runner.py:411] Time since start: 188942.76s, 	Step: 392756, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.41623175144195557, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 172704.4234380722, 'total_duration': 188942.7630982399, 'accumulated_submission_time': 172704.4234380722, 'accumulated_eval_time': 16189.30582332611, 'accumulated_logging_time': 28.580328226089478}
I0304 15:35:50.049270 139881799980800 logging_writer.py:48] [392756] accumulated_eval_time=16189.305823, accumulated_logging_time=28.580328, accumulated_submission_time=172704.423438, global_step=392756, preemption_count=0, score=172704.423438, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=188942.763098, train/accuracy=0.887734, train/loss=0.416232, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:36:07.632097 139881808373504 logging_writer.py:48] [392800] global_step=392800, grad_norm=3.1108384132385254, loss=1.1140843629837036
I0304 15:36:50.935881 139881799980800 logging_writer.py:48] [392900] global_step=392900, grad_norm=3.1805198192596436, loss=1.184107780456543
I0304 15:37:35.398566 139881808373504 logging_writer.py:48] [393000] global_step=393000, grad_norm=3.433420181274414, loss=1.2197518348693848
I0304 15:38:19.617964 139881799980800 logging_writer.py:48] [393100] global_step=393100, grad_norm=3.0551364421844482, loss=2.5521411895751953
I0304 15:39:04.155121 139881808373504 logging_writer.py:48] [393200] global_step=393200, grad_norm=4.105506420135498, loss=3.2020225524902344
I0304 15:39:48.565117 139881799980800 logging_writer.py:48] [393300] global_step=393300, grad_norm=3.0607025623321533, loss=1.2106928825378418
I0304 15:40:33.107420 139881808373504 logging_writer.py:48] [393400] global_step=393400, grad_norm=3.371161699295044, loss=2.587212324142456
I0304 15:41:17.448090 139881799980800 logging_writer.py:48] [393500] global_step=393500, grad_norm=3.492694139480591, loss=2.707730770111084
I0304 15:42:01.907769 139881808373504 logging_writer.py:48] [393600] global_step=393600, grad_norm=3.3636293411254883, loss=1.1223918199539185
I0304 15:42:46.318534 139881799980800 logging_writer.py:48] [393700] global_step=393700, grad_norm=3.141761064529419, loss=1.070575475692749
I0304 15:42:50.043897 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:42:59.994442 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:43:28.118793 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:43:29.712939 140077943854912 submission_runner.py:411] Time since start: 189402.52s, 	Step: 393710, 	{'train/accuracy': 0.8866796493530273, 'train/loss': 0.42468252778053284, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 173124.35608148575, 'total_duration': 189402.51794099808, 'accumulated_submission_time': 173124.35608148575, 'accumulated_eval_time': 16228.974833250046, 'accumulated_logging_time': 28.682926177978516}
I0304 15:43:29.805117 139881808373504 logging_writer.py:48] [393710] accumulated_eval_time=16228.974833, accumulated_logging_time=28.682926, accumulated_submission_time=173124.356081, global_step=393710, preemption_count=0, score=173124.356081, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=189402.517941, train/accuracy=0.886680, train/loss=0.424683, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:44:06.521222 139881799980800 logging_writer.py:48] [393800] global_step=393800, grad_norm=3.159935235977173, loss=1.4538735151290894
I0304 15:44:50.804533 139881808373504 logging_writer.py:48] [393900] global_step=393900, grad_norm=3.1967742443084717, loss=1.93473482131958
I0304 15:45:35.450821 139881799980800 logging_writer.py:48] [394000] global_step=394000, grad_norm=3.6353302001953125, loss=2.9491820335388184
I0304 15:46:20.185727 139881808373504 logging_writer.py:48] [394100] global_step=394100, grad_norm=3.0399794578552246, loss=1.2218971252441406
I0304 15:47:04.599349 139881799980800 logging_writer.py:48] [394200] global_step=394200, grad_norm=3.0124785900115967, loss=1.3256202936172485
I0304 15:47:49.060566 139881808373504 logging_writer.py:48] [394300] global_step=394300, grad_norm=4.131219863891602, loss=3.236264705657959
I0304 15:48:33.287801 139881799980800 logging_writer.py:48] [394400] global_step=394400, grad_norm=3.2253787517547607, loss=1.1052912473678589
I0304 15:49:17.645590 139881808373504 logging_writer.py:48] [394500] global_step=394500, grad_norm=2.9199187755584717, loss=1.0834890604019165
I0304 15:50:02.002174 139881799980800 logging_writer.py:48] [394600] global_step=394600, grad_norm=3.31252384185791, loss=1.1770055294036865
I0304 15:50:30.023726 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:50:40.090991 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:51:08.075437 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:51:09.666412 140077943854912 submission_runner.py:411] Time since start: 189862.47s, 	Step: 394665, 	{'train/accuracy': 0.8871679306030273, 'train/loss': 0.4199066758155823, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 173544.5121805668, 'total_duration': 189862.47140693665, 'accumulated_submission_time': 173544.5121805668, 'accumulated_eval_time': 16268.61748099327, 'accumulated_logging_time': 28.78764533996582}
I0304 15:51:09.761332 139881808373504 logging_writer.py:48] [394665] accumulated_eval_time=16268.617481, accumulated_logging_time=28.787645, accumulated_submission_time=173544.512181, global_step=394665, preemption_count=0, score=173544.512181, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=189862.471407, train/accuracy=0.887168, train/loss=0.419907, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:51:23.832414 139881799980800 logging_writer.py:48] [394700] global_step=394700, grad_norm=3.0984904766082764, loss=1.7177677154541016
I0304 15:52:06.298050 139881808373504 logging_writer.py:48] [394800] global_step=394800, grad_norm=3.4670751094818115, loss=2.7652273178100586
I0304 15:52:50.486786 139881799980800 logging_writer.py:48] [394900] global_step=394900, grad_norm=3.278566360473633, loss=2.808281898498535
I0304 15:53:34.990242 139881808373504 logging_writer.py:48] [395000] global_step=395000, grad_norm=3.4613466262817383, loss=1.095300555229187
I0304 15:54:19.540709 139881799980800 logging_writer.py:48] [395100] global_step=395100, grad_norm=3.84393310546875, loss=3.0079588890075684
I0304 15:55:04.055999 139881808373504 logging_writer.py:48] [395200] global_step=395200, grad_norm=3.248422145843506, loss=1.4077434539794922
I0304 15:55:48.182190 139881799980800 logging_writer.py:48] [395300] global_step=395300, grad_norm=3.191397190093994, loss=1.4878242015838623
I0304 15:56:32.858230 139881808373504 logging_writer.py:48] [395400] global_step=395400, grad_norm=3.0973691940307617, loss=1.0391533374786377
I0304 15:57:17.589808 139881799980800 logging_writer.py:48] [395500] global_step=395500, grad_norm=3.0652499198913574, loss=1.2756141424179077
I0304 15:58:02.054701 139881808373504 logging_writer.py:48] [395600] global_step=395600, grad_norm=4.0974321365356445, loss=3.259767532348633
I0304 15:58:09.770163 140077943854912 spec.py:321] Evaluating on the training split.
I0304 15:58:19.874307 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 15:58:55.258929 140077943854912 spec.py:349] Evaluating on the test split.
I0304 15:58:56.835200 140077943854912 submission_runner.py:411] Time since start: 190329.64s, 	Step: 395619, 	{'train/accuracy': 0.8871093392372131, 'train/loss': 0.42067912220954895, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 173964.45985746384, 'total_duration': 190329.6402170658, 'accumulated_submission_time': 173964.45985746384, 'accumulated_eval_time': 16315.682483196259, 'accumulated_logging_time': 28.893566131591797}
I0304 15:58:56.913329 139881799980800 logging_writer.py:48] [395619] accumulated_eval_time=16315.682483, accumulated_logging_time=28.893566, accumulated_submission_time=173964.459857, global_step=395619, preemption_count=0, score=173964.459857, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=190329.640217, train/accuracy=0.887109, train/loss=0.420679, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 15:59:28.927755 139881808373504 logging_writer.py:48] [395700] global_step=395700, grad_norm=3.0938050746917725, loss=2.469616413116455
I0304 16:00:12.685818 139881799980800 logging_writer.py:48] [395800] global_step=395800, grad_norm=3.1066911220550537, loss=2.1784534454345703
I0304 16:00:56.911016 139881808373504 logging_writer.py:48] [395900] global_step=395900, grad_norm=3.2182016372680664, loss=1.1628460884094238
I0304 16:01:41.103046 139881799980800 logging_writer.py:48] [396000] global_step=396000, grad_norm=3.8127243518829346, loss=3.200345516204834
I0304 16:02:25.220249 139881808373504 logging_writer.py:48] [396100] global_step=396100, grad_norm=3.3096578121185303, loss=1.1594139337539673
I0304 16:03:09.384362 139881799980800 logging_writer.py:48] [396200] global_step=396200, grad_norm=3.3217854499816895, loss=2.4170775413513184
I0304 16:03:53.676882 139881808373504 logging_writer.py:48] [396300] global_step=396300, grad_norm=3.3118762969970703, loss=1.070924997329712
I0304 16:04:38.288496 139881799980800 logging_writer.py:48] [396400] global_step=396400, grad_norm=3.3095483779907227, loss=1.461907148361206
I0304 16:05:22.704244 139881808373504 logging_writer.py:48] [396500] global_step=396500, grad_norm=3.041825532913208, loss=2.0333011150360107
I0304 16:05:56.870801 140077943854912 spec.py:321] Evaluating on the training split.
I0304 16:06:06.874516 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 16:06:32.983785 140077943854912 spec.py:349] Evaluating on the test split.
I0304 16:06:34.575607 140077943854912 submission_runner.py:411] Time since start: 190787.38s, 	Step: 396579, 	{'train/accuracy': 0.8859961032867432, 'train/loss': 0.42335638403892517, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 174384.35671782494, 'total_duration': 190787.38061189651, 'accumulated_submission_time': 174384.35671782494, 'accumulated_eval_time': 16353.387253761292, 'accumulated_logging_time': 28.98282265663147}
I0304 16:06:34.668756 139881799980800 logging_writer.py:48] [396579] accumulated_eval_time=16353.387254, accumulated_logging_time=28.982823, accumulated_submission_time=174384.356718, global_step=396579, preemption_count=0, score=174384.356718, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=190787.380612, train/accuracy=0.885996, train/loss=0.423356, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 16:06:43.252361 139881808373504 logging_writer.py:48] [396600] global_step=396600, grad_norm=3.123624563217163, loss=1.6857305765151978
I0304 16:07:24.882146 139881799980800 logging_writer.py:48] [396700] global_step=396700, grad_norm=3.1851155757904053, loss=1.3511433601379395
I0304 16:08:09.784607 139881808373504 logging_writer.py:48] [396800] global_step=396800, grad_norm=3.158966302871704, loss=1.9212658405303955
I0304 16:08:53.968163 139881799980800 logging_writer.py:48] [396900] global_step=396900, grad_norm=3.0356497764587402, loss=1.3382363319396973
I0304 16:09:38.359811 139881808373504 logging_writer.py:48] [397000] global_step=397000, grad_norm=3.350756883621216, loss=1.1982436180114746
I0304 16:10:22.732553 139881799980800 logging_writer.py:48] [397100] global_step=397100, grad_norm=3.443821668624878, loss=2.4067437648773193
I0304 16:11:07.104738 139881808373504 logging_writer.py:48] [397200] global_step=397200, grad_norm=3.135952949523926, loss=2.7043209075927734
I0304 16:11:51.568037 139881799980800 logging_writer.py:48] [397300] global_step=397300, grad_norm=4.746001243591309, loss=2.0886337757110596
I0304 16:12:36.037552 139881808373504 logging_writer.py:48] [397400] global_step=397400, grad_norm=3.4868764877319336, loss=2.6960079669952393
I0304 16:13:20.310981 139881799980800 logging_writer.py:48] [397500] global_step=397500, grad_norm=3.3507442474365234, loss=1.300807237625122
I0304 16:13:34.717255 140077943854912 spec.py:321] Evaluating on the training split.
I0304 16:13:45.197410 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 16:14:14.294276 140077943854912 spec.py:349] Evaluating on the test split.
I0304 16:14:15.897267 140077943854912 submission_runner.py:411] Time since start: 191248.70s, 	Step: 397534, 	{'train/accuracy': 0.8891991972923279, 'train/loss': 0.41087934374809265, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 174804.3445544243, 'total_duration': 191248.7022612095, 'accumulated_submission_time': 174804.3445544243, 'accumulated_eval_time': 16394.567228794098, 'accumulated_logging_time': 29.087074756622314}
I0304 16:14:16.004280 139881808373504 logging_writer.py:48] [397534] accumulated_eval_time=16394.567229, accumulated_logging_time=29.087075, accumulated_submission_time=174804.344554, global_step=397534, preemption_count=0, score=174804.344554, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=191248.702261, train/accuracy=0.889199, train/loss=0.410879, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 16:14:42.180928 139881799980800 logging_writer.py:48] [397600] global_step=397600, grad_norm=2.880999803543091, loss=2.083796262741089
I0304 16:15:25.883529 139881808373504 logging_writer.py:48] [397700] global_step=397700, grad_norm=3.0202202796936035, loss=1.1890931129455566
I0304 16:16:10.279598 139881799980800 logging_writer.py:48] [397800] global_step=397800, grad_norm=3.70194935798645, loss=2.2431302070617676
I0304 16:16:54.884725 139881808373504 logging_writer.py:48] [397900] global_step=397900, grad_norm=3.1734535694122314, loss=1.175148606300354
I0304 16:17:39.210250 139881799980800 logging_writer.py:48] [398000] global_step=398000, grad_norm=4.033475875854492, loss=3.2258715629577637
I0304 16:18:23.398901 139881808373504 logging_writer.py:48] [398100] global_step=398100, grad_norm=3.1574201583862305, loss=1.9223936796188354
I0304 16:19:07.940108 139881799980800 logging_writer.py:48] [398200] global_step=398200, grad_norm=2.9433135986328125, loss=1.6965153217315674
I0304 16:19:52.026026 139881808373504 logging_writer.py:48] [398300] global_step=398300, grad_norm=3.31087589263916, loss=1.1344889402389526
I0304 16:20:36.382437 139881799980800 logging_writer.py:48] [398400] global_step=398400, grad_norm=3.1417837142944336, loss=2.532285213470459
I0304 16:21:16.090723 140077943854912 spec.py:321] Evaluating on the training split.
I0304 16:21:26.518799 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 16:21:57.602192 140077943854912 spec.py:349] Evaluating on the test split.
I0304 16:21:59.187351 140077943854912 submission_runner.py:411] Time since start: 191711.99s, 	Step: 398491, 	{'train/accuracy': 0.8869531154632568, 'train/loss': 0.41807159781455994, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 175224.36603736877, 'total_duration': 191711.99235510826, 'accumulated_submission_time': 175224.36603736877, 'accumulated_eval_time': 16437.66381263733, 'accumulated_logging_time': 29.20992875099182}
I0304 16:21:59.281838 139881808373504 logging_writer.py:48] [398491] accumulated_eval_time=16437.663813, accumulated_logging_time=29.209929, accumulated_submission_time=175224.366037, global_step=398491, preemption_count=0, score=175224.366037, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=191711.992355, train/accuracy=0.886953, train/loss=0.418072, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 16:22:03.212187 139881799980800 logging_writer.py:48] [398500] global_step=398500, grad_norm=3.1727135181427, loss=1.1939725875854492
I0304 16:22:44.302502 139881808373504 logging_writer.py:48] [398600] global_step=398600, grad_norm=3.3226377964019775, loss=1.1153136491775513
I0304 16:23:28.460167 139881799980800 logging_writer.py:48] [398700] global_step=398700, grad_norm=4.108810901641846, loss=3.014369010925293
I0304 16:24:12.895071 139881808373504 logging_writer.py:48] [398800] global_step=398800, grad_norm=3.0896852016448975, loss=1.4792776107788086
I0304 16:24:57.079560 139881799980800 logging_writer.py:48] [398900] global_step=398900, grad_norm=3.0665955543518066, loss=2.089130401611328
I0304 16:25:41.702542 139881808373504 logging_writer.py:48] [399000] global_step=399000, grad_norm=3.0669305324554443, loss=1.1270607709884644
I0304 16:26:26.390788 139881799980800 logging_writer.py:48] [399100] global_step=399100, grad_norm=3.500048875808716, loss=1.2441989183425903
I0304 16:27:10.677054 139881808373504 logging_writer.py:48] [399200] global_step=399200, grad_norm=3.0668227672576904, loss=1.0902984142303467
I0304 16:27:55.214040 139881799980800 logging_writer.py:48] [399300] global_step=399300, grad_norm=3.287954330444336, loss=1.1043636798858643
I0304 16:28:39.611237 139881808373504 logging_writer.py:48] [399400] global_step=399400, grad_norm=3.851719379425049, loss=3.0203747749328613
I0304 16:28:59.346039 140077943854912 spec.py:321] Evaluating on the training split.
I0304 16:29:09.406105 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 16:29:40.602929 140077943854912 spec.py:349] Evaluating on the test split.
I0304 16:29:42.189751 140077943854912 submission_runner.py:411] Time since start: 192174.99s, 	Step: 399446, 	{'train/accuracy': 0.8896874785423279, 'train/loss': 0.4124925434589386, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 175644.36986541748, 'total_duration': 192174.99474811554, 'accumulated_submission_time': 175644.36986541748, 'accumulated_eval_time': 16480.50748872757, 'accumulated_logging_time': 29.315454959869385}
I0304 16:29:42.284328 139881799980800 logging_writer.py:48] [399446] accumulated_eval_time=16480.507489, accumulated_logging_time=29.315455, accumulated_submission_time=175644.369865, global_step=399446, preemption_count=0, score=175644.369865, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=192174.994748, train/accuracy=0.889687, train/loss=0.412493, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 16:30:03.767299 139881808373504 logging_writer.py:48] [399500] global_step=399500, grad_norm=3.045562744140625, loss=2.4156603813171387
I0304 16:30:47.007709 139881799980800 logging_writer.py:48] [399600] global_step=399600, grad_norm=2.992507219314575, loss=2.4353554248809814
I0304 16:31:31.374111 139881808373504 logging_writer.py:48] [399700] global_step=399700, grad_norm=3.028733491897583, loss=1.0232577323913574
I0304 16:32:15.735887 139881799980800 logging_writer.py:48] [399800] global_step=399800, grad_norm=3.0798847675323486, loss=1.1466439962387085
I0304 16:33:00.011145 139881808373504 logging_writer.py:48] [399900] global_step=399900, grad_norm=3.033118724822998, loss=1.616728663444519
I0304 16:33:44.653246 139881799980800 logging_writer.py:48] [400000] global_step=400000, grad_norm=3.278616428375244, loss=1.1568348407745361
I0304 16:34:28.918834 139881808373504 logging_writer.py:48] [400100] global_step=400100, grad_norm=2.924940586090088, loss=1.0929628610610962
I0304 16:35:13.417639 139881799980800 logging_writer.py:48] [400200] global_step=400200, grad_norm=2.924808979034424, loss=1.5681899785995483
I0304 16:35:57.669230 139881808373504 logging_writer.py:48] [400300] global_step=400300, grad_norm=4.960328578948975, loss=2.9684853553771973
I0304 16:36:42.369668 139881799980800 logging_writer.py:48] [400400] global_step=400400, grad_norm=3.48235821723938, loss=1.131579875946045
I0304 16:36:42.384939 140077943854912 spec.py:321] Evaluating on the training split.
I0304 16:36:52.448475 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 16:37:30.264831 140077943854912 spec.py:349] Evaluating on the test split.
I0304 16:37:31.849914 140077943854912 submission_runner.py:411] Time since start: 192644.65s, 	Step: 400401, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.4160926342010498, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 176064.40971302986, 'total_duration': 192644.6549062729, 'accumulated_submission_time': 176064.40971302986, 'accumulated_eval_time': 16529.972445726395, 'accumulated_logging_time': 29.421252727508545}
I0304 16:37:31.937638 139881808373504 logging_writer.py:48] [400401] accumulated_eval_time=16529.972446, accumulated_logging_time=29.421253, accumulated_submission_time=176064.409713, global_step=400401, preemption_count=0, score=176064.409713, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=192644.654906, train/accuracy=0.887676, train/loss=0.416093, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 16:38:11.855304 139881799980800 logging_writer.py:48] [400500] global_step=400500, grad_norm=2.6967930793762207, loss=1.6060713529586792
I0304 16:38:56.153979 139881808373504 logging_writer.py:48] [400600] global_step=400600, grad_norm=3.029787063598633, loss=1.081174373626709
I0304 16:39:41.155281 139881799980800 logging_writer.py:48] [400700] global_step=400700, grad_norm=3.0806941986083984, loss=1.1813602447509766
I0304 16:40:25.537414 139881808373504 logging_writer.py:48] [400800] global_step=400800, grad_norm=3.1532444953918457, loss=1.1271717548370361
I0304 16:41:10.345471 139881799980800 logging_writer.py:48] [400900] global_step=400900, grad_norm=3.155803918838501, loss=1.1333202123641968
I0304 16:41:54.649759 139881808373504 logging_writer.py:48] [401000] global_step=401000, grad_norm=3.0929107666015625, loss=1.4148952960968018
I0304 16:42:38.997916 139881799980800 logging_writer.py:48] [401100] global_step=401100, grad_norm=2.9556453227996826, loss=1.1434481143951416
I0304 16:43:23.320014 139881808373504 logging_writer.py:48] [401200] global_step=401200, grad_norm=3.3197267055511475, loss=2.961869716644287
I0304 16:44:07.699602 139881799980800 logging_writer.py:48] [401300] global_step=401300, grad_norm=3.111551284790039, loss=1.640465497970581
I0304 16:44:32.225324 140077943854912 spec.py:321] Evaluating on the training split.
I0304 16:44:42.394726 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 16:45:10.474169 140077943854912 spec.py:349] Evaluating on the test split.
I0304 16:45:12.062776 140077943854912 submission_runner.py:411] Time since start: 193104.87s, 	Step: 401357, 	{'train/accuracy': 0.88880854845047, 'train/loss': 0.417743444442749, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 176484.6373269558, 'total_duration': 193104.86778235435, 'accumulated_submission_time': 176484.6373269558, 'accumulated_eval_time': 16569.809871912003, 'accumulated_logging_time': 29.519530534744263}
I0304 16:45:12.160502 139881808373504 logging_writer.py:48] [401357] accumulated_eval_time=16569.809872, accumulated_logging_time=29.519531, accumulated_submission_time=176484.637327, global_step=401357, preemption_count=0, score=176484.637327, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=193104.867782, train/accuracy=0.888809, train/loss=0.417743, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 16:45:29.343682 139881799980800 logging_writer.py:48] [401400] global_step=401400, grad_norm=2.775756359100342, loss=1.8741049766540527
I0304 16:46:13.908748 139881808373504 logging_writer.py:48] [401500] global_step=401500, grad_norm=2.930588960647583, loss=1.03786301612854
I0304 16:46:59.023512 139881799980800 logging_writer.py:48] [401600] global_step=401600, grad_norm=3.561734199523926, loss=1.0569994449615479
I0304 16:47:43.744633 139881808373504 logging_writer.py:48] [401700] global_step=401700, grad_norm=2.9494636058807373, loss=1.0522222518920898
I0304 16:48:28.532129 139881799980800 logging_writer.py:48] [401800] global_step=401800, grad_norm=3.0560216903686523, loss=1.082271695137024
I0304 16:49:13.294587 139881808373504 logging_writer.py:48] [401900] global_step=401900, grad_norm=3.860755443572998, loss=3.3440380096435547
I0304 16:49:58.086714 139881799980800 logging_writer.py:48] [402000] global_step=402000, grad_norm=3.4373815059661865, loss=2.8148956298828125
I0304 16:50:42.810689 139881808373504 logging_writer.py:48] [402100] global_step=402100, grad_norm=3.2528669834136963, loss=2.1689276695251465
I0304 16:51:27.805505 139881799980800 logging_writer.py:48] [402200] global_step=402200, grad_norm=3.650617837905884, loss=1.1889725923538208
I0304 16:52:12.179435 140077943854912 spec.py:321] Evaluating on the training split.
I0304 16:52:23.253414 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 16:52:50.744374 140077943854912 spec.py:349] Evaluating on the test split.
I0304 16:52:52.335634 140077943854912 submission_runner.py:411] Time since start: 193565.14s, 	Step: 402300, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.42436864972114563, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 176904.59464097023, 'total_duration': 193565.14063882828, 'accumulated_submission_time': 176904.59464097023, 'accumulated_eval_time': 16609.966049671173, 'accumulated_logging_time': 29.63040018081665}
I0304 16:52:52.431430 139881808373504 logging_writer.py:48] [402300] accumulated_eval_time=16609.966050, accumulated_logging_time=29.630400, accumulated_submission_time=176904.594641, global_step=402300, preemption_count=0, score=176904.594641, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=193565.140639, train/accuracy=0.888066, train/loss=0.424369, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 16:52:52.850136 139881799980800 logging_writer.py:48] [402300] global_step=402300, grad_norm=3.0228805541992188, loss=2.0522987842559814
I0304 16:53:34.091302 139881808373504 logging_writer.py:48] [402400] global_step=402400, grad_norm=3.1965646743774414, loss=1.087467074394226
I0304 16:54:18.737986 139881799980800 logging_writer.py:48] [402500] global_step=402500, grad_norm=3.0049378871917725, loss=2.1412100791931152
I0304 16:55:03.804996 139881808373504 logging_writer.py:48] [402600] global_step=402600, grad_norm=3.307462692260742, loss=3.031134605407715
I0304 16:55:48.549997 139881799980800 logging_writer.py:48] [402700] global_step=402700, grad_norm=3.619896650314331, loss=1.1122790575027466
I0304 16:56:33.465965 139881808373504 logging_writer.py:48] [402800] global_step=402800, grad_norm=3.9611587524414062, loss=3.0713934898376465
I0304 16:57:18.446326 139881799980800 logging_writer.py:48] [402900] global_step=402900, grad_norm=3.243922233581543, loss=1.214418888092041
I0304 16:58:03.396981 139881808373504 logging_writer.py:48] [403000] global_step=403000, grad_norm=2.8926212787628174, loss=1.807319164276123
I0304 16:58:48.050492 139881799980800 logging_writer.py:48] [403100] global_step=403100, grad_norm=3.204881191253662, loss=2.655693292617798
I0304 16:59:32.576894 139881808373504 logging_writer.py:48] [403200] global_step=403200, grad_norm=3.3194797039031982, loss=1.065381646156311
I0304 16:59:52.646418 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:00:02.953573 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:00:39.088595 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:00:40.679247 140077943854912 submission_runner.py:411] Time since start: 194033.48s, 	Step: 403247, 	{'train/accuracy': 0.8893554210662842, 'train/loss': 0.40641748905181885, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 177324.74939084053, 'total_duration': 194033.4842557907, 'accumulated_submission_time': 177324.74939084053, 'accumulated_eval_time': 16657.998848199844, 'accumulated_logging_time': 29.737738132476807}
I0304 17:00:40.755884 139881799980800 logging_writer.py:48] [403247] accumulated_eval_time=16657.998848, accumulated_logging_time=29.737738, accumulated_submission_time=177324.749391, global_step=403247, preemption_count=0, score=177324.749391, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=194033.484256, train/accuracy=0.889355, train/loss=0.406417, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:01:01.838817 139881808373504 logging_writer.py:48] [403300] global_step=403300, grad_norm=3.6950650215148926, loss=3.2275071144104004
I0304 17:01:44.390903 139881799980800 logging_writer.py:48] [403400] global_step=403400, grad_norm=3.1295664310455322, loss=2.0986745357513428
I0304 17:02:28.992445 139881808373504 logging_writer.py:48] [403500] global_step=403500, grad_norm=2.99033260345459, loss=1.0838289260864258
I0304 17:03:13.560547 139881799980800 logging_writer.py:48] [403600] global_step=403600, grad_norm=2.756049633026123, loss=1.1103166341781616
I0304 17:03:57.673074 139881808373504 logging_writer.py:48] [403700] global_step=403700, grad_norm=3.09779953956604, loss=1.0951390266418457
I0304 17:04:42.216583 139881799980800 logging_writer.py:48] [403800] global_step=403800, grad_norm=2.870755195617676, loss=1.9218823909759521
I0304 17:05:26.653647 139881808373504 logging_writer.py:48] [403900] global_step=403900, grad_norm=3.313361883163452, loss=2.815300464630127
I0304 17:06:11.061130 139881799980800 logging_writer.py:48] [404000] global_step=404000, grad_norm=2.9247264862060547, loss=1.7226290702819824
I0304 17:06:55.769734 139881808373504 logging_writer.py:48] [404100] global_step=404100, grad_norm=3.009192705154419, loss=1.2522600889205933
I0304 17:07:40.415343 139881799980800 logging_writer.py:48] [404200] global_step=404200, grad_norm=3.050032377243042, loss=1.1899372339248657
I0304 17:07:40.974290 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:07:51.018885 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:08:18.979796 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:08:20.591440 140077943854912 submission_runner.py:411] Time since start: 194493.40s, 	Step: 404203, 	{'train/accuracy': 0.8868359327316284, 'train/loss': 0.42025455832481384, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 177744.90615653992, 'total_duration': 194493.39645719528, 'accumulated_submission_time': 177744.90615653992, 'accumulated_eval_time': 16697.615966558456, 'accumulated_logging_time': 29.82686495780945}
I0304 17:08:20.668607 139881808373504 logging_writer.py:48] [404203] accumulated_eval_time=16697.615967, accumulated_logging_time=29.826865, accumulated_submission_time=177744.906157, global_step=404203, preemption_count=0, score=177744.906157, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=194493.396457, train/accuracy=0.886836, train/loss=0.420255, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:08:59.729769 139881799980800 logging_writer.py:48] [404300] global_step=404300, grad_norm=4.097855567932129, loss=3.2255301475524902
I0304 17:09:44.042901 139881808373504 logging_writer.py:48] [404400] global_step=404400, grad_norm=3.027707815170288, loss=1.0771538019180298
I0304 17:10:28.357306 139881799980800 logging_writer.py:48] [404500] global_step=404500, grad_norm=3.304746150970459, loss=1.1291694641113281
I0304 17:11:12.925875 139881808373504 logging_writer.py:48] [404600] global_step=404600, grad_norm=3.0182056427001953, loss=1.2397863864898682
I0304 17:11:57.241918 139881799980800 logging_writer.py:48] [404700] global_step=404700, grad_norm=3.176117181777954, loss=1.3090629577636719
I0304 17:12:41.668196 139881808373504 logging_writer.py:48] [404800] global_step=404800, grad_norm=3.096256732940674, loss=1.6507298946380615
I0304 17:13:25.758853 139881799980800 logging_writer.py:48] [404900] global_step=404900, grad_norm=3.968501567840576, loss=3.173229455947876
I0304 17:14:10.103654 139881808373504 logging_writer.py:48] [405000] global_step=405000, grad_norm=3.0342354774475098, loss=2.3214588165283203
I0304 17:14:54.523523 139881799980800 logging_writer.py:48] [405100] global_step=405100, grad_norm=3.3659181594848633, loss=1.0454936027526855
I0304 17:15:20.839038 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:15:32.052619 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:16:02.873465 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:16:04.462004 140077943854912 submission_runner.py:411] Time since start: 194957.27s, 	Step: 405161, 	{'train/accuracy': 0.8908202648162842, 'train/loss': 0.40891405940055847, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 178165.01534843445, 'total_duration': 194957.26694130898, 'accumulated_submission_time': 178165.01534843445, 'accumulated_eval_time': 16741.23883986473, 'accumulated_logging_time': 29.913761138916016}
I0304 17:16:04.558218 139881808373504 logging_writer.py:48] [405161] accumulated_eval_time=16741.238840, accumulated_logging_time=29.913761, accumulated_submission_time=178165.015348, global_step=405161, preemption_count=0, score=178165.015348, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=194957.266941, train/accuracy=0.890820, train/loss=0.408914, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:16:20.180289 139881799980800 logging_writer.py:48] [405200] global_step=405200, grad_norm=3.0723726749420166, loss=1.860442042350769
I0304 17:17:02.776040 139881808373504 logging_writer.py:48] [405300] global_step=405300, grad_norm=3.2570300102233887, loss=1.060774803161621
I0304 17:17:46.938952 139881799980800 logging_writer.py:48] [405400] global_step=405400, grad_norm=3.2104220390319824, loss=1.9834829568862915
I0304 17:18:31.430968 139881808373504 logging_writer.py:48] [405500] global_step=405500, grad_norm=3.4306509494781494, loss=1.1275783777236938
I0304 17:19:16.027114 139881799980800 logging_writer.py:48] [405600] global_step=405600, grad_norm=3.3283467292785645, loss=1.3187696933746338
I0304 17:20:00.197225 139881808373504 logging_writer.py:48] [405700] global_step=405700, grad_norm=3.07270884513855, loss=1.2549737691879272
I0304 17:20:44.612966 139881799980800 logging_writer.py:48] [405800] global_step=405800, grad_norm=2.9712328910827637, loss=1.131347894668579
I0304 17:21:29.099567 139881808373504 logging_writer.py:48] [405900] global_step=405900, grad_norm=3.085207939147949, loss=2.031431198120117
I0304 17:22:13.478691 139881799980800 logging_writer.py:48] [406000] global_step=406000, grad_norm=2.9455442428588867, loss=1.5753062963485718
I0304 17:22:57.877475 139881808373504 logging_writer.py:48] [406100] global_step=406100, grad_norm=2.943686008453369, loss=1.0621343851089478
I0304 17:23:04.793356 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:23:15.007418 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:23:44.393546 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:23:45.976444 140077943854912 submission_runner.py:411] Time since start: 195418.78s, 	Step: 406117, 	{'train/accuracy': 0.8858398199081421, 'train/loss': 0.42009931802749634, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 178585.18918466568, 'total_duration': 195418.78145456314, 'accumulated_submission_time': 178585.18918466568, 'accumulated_eval_time': 16782.42190861702, 'accumulated_logging_time': 30.021697521209717}
I0304 17:23:46.074476 139881799980800 logging_writer.py:48] [406117] accumulated_eval_time=16782.421909, accumulated_logging_time=30.021698, accumulated_submission_time=178585.189185, global_step=406117, preemption_count=0, score=178585.189185, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=195418.781455, train/accuracy=0.885840, train/loss=0.420099, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:24:20.763835 139881808373504 logging_writer.py:48] [406200] global_step=406200, grad_norm=3.2316040992736816, loss=1.4808660745620728
I0304 17:25:06.230318 139881799980800 logging_writer.py:48] [406300] global_step=406300, grad_norm=3.067547082901001, loss=1.0812443494796753
I0304 17:25:51.232665 139881808373504 logging_writer.py:48] [406400] global_step=406400, grad_norm=3.072183132171631, loss=1.1063841581344604
I0304 17:26:36.622744 139881799980800 logging_writer.py:48] [406500] global_step=406500, grad_norm=3.31797194480896, loss=1.0250681638717651
I0304 17:27:22.019885 139881808373504 logging_writer.py:48] [406600] global_step=406600, grad_norm=3.260053873062134, loss=1.1050734519958496
I0304 17:28:07.437111 139881799980800 logging_writer.py:48] [406700] global_step=406700, grad_norm=2.971710443496704, loss=1.9793452024459839
I0304 17:28:52.611320 139881808373504 logging_writer.py:48] [406800] global_step=406800, grad_norm=3.199321746826172, loss=1.5386488437652588
I0304 17:29:37.906838 139881799980800 logging_writer.py:48] [406900] global_step=406900, grad_norm=2.935819149017334, loss=2.2909436225891113
I0304 17:30:23.035045 139881808373504 logging_writer.py:48] [407000] global_step=407000, grad_norm=3.2389965057373047, loss=2.7896363735198975
I0304 17:30:46.236354 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:30:56.365586 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:31:29.891781 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:31:31.470826 140077943854912 submission_runner.py:411] Time since start: 195884.28s, 	Step: 407053, 	{'train/accuracy': 0.8891991972923279, 'train/loss': 0.41036850214004517, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 179005.29097795486, 'total_duration': 195884.27584457397, 'accumulated_submission_time': 179005.29097795486, 'accumulated_eval_time': 16827.65636920929, 'accumulated_logging_time': 30.131014585494995}
I0304 17:31:31.547555 139881799980800 logging_writer.py:48] [407053] accumulated_eval_time=16827.656369, accumulated_logging_time=30.131015, accumulated_submission_time=179005.290978, global_step=407053, preemption_count=0, score=179005.290978, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=195884.275845, train/accuracy=0.889199, train/loss=0.410369, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:31:50.287718 139881808373504 logging_writer.py:48] [407100] global_step=407100, grad_norm=3.187736988067627, loss=1.07769775390625
I0304 17:32:33.063301 139881799980800 logging_writer.py:48] [407200] global_step=407200, grad_norm=3.2021114826202393, loss=1.199849247932434
I0304 17:33:17.645712 139881808373504 logging_writer.py:48] [407300] global_step=407300, grad_norm=3.2784523963928223, loss=1.0887525081634521
I0304 17:34:02.357447 139881799980800 logging_writer.py:48] [407400] global_step=407400, grad_norm=3.5112249851226807, loss=3.1289525032043457
I0304 17:34:46.606462 139881808373504 logging_writer.py:48] [407500] global_step=407500, grad_norm=3.1489946842193604, loss=2.350353717803955
I0304 17:35:31.062872 139881799980800 logging_writer.py:48] [407600] global_step=407600, grad_norm=3.053765058517456, loss=1.0884349346160889
I0304 17:36:15.761826 139881808373504 logging_writer.py:48] [407700] global_step=407700, grad_norm=3.0265092849731445, loss=1.2111964225769043
I0304 17:37:00.348385 139881799980800 logging_writer.py:48] [407800] global_step=407800, grad_norm=3.1306939125061035, loss=1.0701977014541626
I0304 17:37:45.183768 139881808373504 logging_writer.py:48] [407900] global_step=407900, grad_norm=2.9316024780273438, loss=1.311082124710083
I0304 17:38:29.695371 139881799980800 logging_writer.py:48] [408000] global_step=408000, grad_norm=3.1567113399505615, loss=1.1115970611572266
I0304 17:38:31.659585 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:38:41.662276 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:39:10.173705 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:39:11.763241 140077943854912 submission_runner.py:411] Time since start: 196344.57s, 	Step: 408006, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.4193182587623596, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 179425.34422326088, 'total_duration': 196344.56824064255, 'accumulated_submission_time': 179425.34422326088, 'accumulated_eval_time': 16867.759991645813, 'accumulated_logging_time': 30.217520475387573}
I0304 17:39:11.854872 139881808373504 logging_writer.py:48] [408006] accumulated_eval_time=16867.759992, accumulated_logging_time=30.217520, accumulated_submission_time=179425.344223, global_step=408006, preemption_count=0, score=179425.344223, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=196344.568241, train/accuracy=0.887461, train/loss=0.419318, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:39:50.858422 139881799980800 logging_writer.py:48] [408100] global_step=408100, grad_norm=3.264200448989868, loss=2.834127426147461
I0304 17:40:35.553110 139881808373504 logging_writer.py:48] [408200] global_step=408200, grad_norm=2.964045286178589, loss=1.694986343383789
I0304 17:41:20.226000 139881799980800 logging_writer.py:48] [408300] global_step=408300, grad_norm=2.946492910385132, loss=1.252833604812622
I0304 17:42:05.084332 139881808373504 logging_writer.py:48] [408400] global_step=408400, grad_norm=2.992753267288208, loss=1.9176080226898193
I0304 17:42:49.391452 139881799980800 logging_writer.py:48] [408500] global_step=408500, grad_norm=3.152752161026001, loss=2.7530226707458496
I0304 17:43:34.613428 139881808373504 logging_writer.py:48] [408600] global_step=408600, grad_norm=3.024848461151123, loss=2.137822151184082
I0304 17:44:18.926729 139881799980800 logging_writer.py:48] [408700] global_step=408700, grad_norm=3.113710880279541, loss=1.0427069664001465
I0304 17:45:03.536200 139881808373504 logging_writer.py:48] [408800] global_step=408800, grad_norm=2.978386640548706, loss=2.219144344329834
I0304 17:45:48.289934 139881799980800 logging_writer.py:48] [408900] global_step=408900, grad_norm=2.8765923976898193, loss=1.5927600860595703
I0304 17:46:12.071748 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:46:22.658898 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:46:57.234037 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:46:58.820489 140077943854912 submission_runner.py:411] Time since start: 196811.63s, 	Step: 408955, 	{'train/accuracy': 0.8893163800239563, 'train/loss': 0.4162834584712982, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 179845.50100183487, 'total_duration': 196811.6254954338, 'accumulated_submission_time': 179845.50100183487, 'accumulated_eval_time': 16914.508714675903, 'accumulated_logging_time': 30.320476055145264}
I0304 17:46:58.916558 139881808373504 logging_writer.py:48] [408955] accumulated_eval_time=16914.508715, accumulated_logging_time=30.320476, accumulated_submission_time=179845.501002, global_step=408955, preemption_count=0, score=179845.501002, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=196811.625495, train/accuracy=0.889316, train/loss=0.416283, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:47:16.874730 139881799980800 logging_writer.py:48] [409000] global_step=409000, grad_norm=3.0712735652923584, loss=2.288334369659424
I0304 17:47:59.668339 139881808373504 logging_writer.py:48] [409100] global_step=409100, grad_norm=4.8299880027771, loss=1.1068055629730225
I0304 17:49:02.558429 139881799980800 logging_writer.py:48] [409200] global_step=409200, grad_norm=2.9454903602600098, loss=1.0301727056503296
I0304 17:49:46.173728 139881808373504 logging_writer.py:48] [409300] global_step=409300, grad_norm=3.1216089725494385, loss=1.1253234148025513
I0304 17:50:30.626838 139881799980800 logging_writer.py:48] [409400] global_step=409400, grad_norm=3.072474479675293, loss=1.2174656391143799
I0304 17:51:15.303982 139881808373504 logging_writer.py:48] [409500] global_step=409500, grad_norm=3.303975820541382, loss=1.2612961530685425
I0304 17:51:59.782788 139881799980800 logging_writer.py:48] [409600] global_step=409600, grad_norm=3.45822811126709, loss=1.3918551206588745
I0304 17:52:44.173066 139881808373504 logging_writer.py:48] [409700] global_step=409700, grad_norm=3.016772985458374, loss=1.0292644500732422
I0304 17:53:28.657948 139881799980800 logging_writer.py:48] [409800] global_step=409800, grad_norm=3.763911724090576, loss=3.2044761180877686
I0304 17:53:58.873552 140077943854912 spec.py:321] Evaluating on the training split.
I0304 17:54:09.056196 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 17:54:46.444519 140077943854912 spec.py:349] Evaluating on the test split.
I0304 17:54:48.022027 140077943854912 submission_runner.py:411] Time since start: 197280.83s, 	Step: 409870, 	{'train/accuracy': 0.8877733945846558, 'train/loss': 0.4182986617088318, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 180265.39924263954, 'total_duration': 197280.82704353333, 'accumulated_submission_time': 180265.39924263954, 'accumulated_eval_time': 16963.657194137573, 'accumulated_logging_time': 30.428412675857544}
I0304 17:54:48.099489 139881808373504 logging_writer.py:48] [409870] accumulated_eval_time=16963.657194, accumulated_logging_time=30.428413, accumulated_submission_time=180265.399243, global_step=409870, preemption_count=0, score=180265.399243, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=197280.827044, train/accuracy=0.887773, train/loss=0.418299, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 17:55:00.187028 139881799980800 logging_writer.py:48] [409900] global_step=409900, grad_norm=3.1137478351593018, loss=1.096251130104065
I0304 17:55:41.661934 139881808373504 logging_writer.py:48] [410000] global_step=410000, grad_norm=3.212815761566162, loss=2.0345308780670166
I0304 17:56:26.517539 139881799980800 logging_writer.py:48] [410100] global_step=410100, grad_norm=3.472069263458252, loss=1.8361845016479492
I0304 17:57:11.051543 139881808373504 logging_writer.py:48] [410200] global_step=410200, grad_norm=3.389446973800659, loss=2.0286364555358887
I0304 17:57:55.309195 139881799980800 logging_writer.py:48] [410300] global_step=410300, grad_norm=3.219651937484741, loss=2.7455711364746094
I0304 17:58:40.223877 139881808373504 logging_writer.py:48] [410400] global_step=410400, grad_norm=3.033411979675293, loss=1.1574962139129639
I0304 17:59:24.511646 139881799980800 logging_writer.py:48] [410500] global_step=410500, grad_norm=3.140061140060425, loss=1.1533372402191162
I0304 18:00:08.835581 139881808373504 logging_writer.py:48] [410600] global_step=410600, grad_norm=3.3185861110687256, loss=3.067659616470337
I0304 18:00:53.204696 139881799980800 logging_writer.py:48] [410700] global_step=410700, grad_norm=3.0669617652893066, loss=1.1627073287963867
I0304 18:01:37.857179 139881808373504 logging_writer.py:48] [410800] global_step=410800, grad_norm=3.309995651245117, loss=1.0034888982772827
I0304 18:01:48.246300 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:01:58.512674 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:02:29.741729 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:02:31.315184 140077943854912 submission_runner.py:411] Time since start: 197744.12s, 	Step: 410825, 	{'train/accuracy': 0.8863281011581421, 'train/loss': 0.42161667346954346, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 180685.4873828888, 'total_duration': 197744.12019467354, 'accumulated_submission_time': 180685.4873828888, 'accumulated_eval_time': 17006.726067066193, 'accumulated_logging_time': 30.515804767608643}
I0304 18:02:31.391539 139881799980800 logging_writer.py:48] [410825] accumulated_eval_time=17006.726067, accumulated_logging_time=30.515805, accumulated_submission_time=180685.487383, global_step=410825, preemption_count=0, score=180685.487383, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=197744.120195, train/accuracy=0.886328, train/loss=0.421617, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:03:01.081032 139881808373504 logging_writer.py:48] [410900] global_step=410900, grad_norm=3.8854598999023438, loss=2.73903751373291
I0304 18:03:45.145330 139881799980800 logging_writer.py:48] [411000] global_step=411000, grad_norm=3.118330478668213, loss=1.058150053024292
I0304 18:04:29.818271 139881808373504 logging_writer.py:48] [411100] global_step=411100, grad_norm=3.3497121334075928, loss=2.0848498344421387
I0304 18:05:14.654015 139881799980800 logging_writer.py:48] [411200] global_step=411200, grad_norm=3.8154571056365967, loss=2.733764886856079
I0304 18:05:58.966069 139881808373504 logging_writer.py:48] [411300] global_step=411300, grad_norm=3.5013041496276855, loss=3.228677749633789
I0304 18:06:43.928859 139881799980800 logging_writer.py:48] [411400] global_step=411400, grad_norm=2.9995384216308594, loss=1.038877010345459
I0304 18:07:28.271363 139881808373504 logging_writer.py:48] [411500] global_step=411500, grad_norm=2.9184787273406982, loss=1.8403456211090088
I0304 18:08:12.925336 139881799980800 logging_writer.py:48] [411600] global_step=411600, grad_norm=3.433605670928955, loss=3.3001770973205566
I0304 18:08:57.934383 139881808373504 logging_writer.py:48] [411700] global_step=411700, grad_norm=2.955238103866577, loss=1.3092983961105347
I0304 18:09:31.766937 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:09:42.023922 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:10:07.726804 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:10:09.310764 140077943854912 submission_runner.py:411] Time since start: 198202.12s, 	Step: 411778, 	{'train/accuracy': 0.890625, 'train/loss': 0.41061341762542725, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 181105.803034544, 'total_duration': 198202.1157720089, 'accumulated_submission_time': 181105.803034544, 'accumulated_eval_time': 17044.269870519638, 'accumulated_logging_time': 30.603248834609985}
I0304 18:10:09.407159 139881799980800 logging_writer.py:48] [411778] accumulated_eval_time=17044.269871, accumulated_logging_time=30.603249, accumulated_submission_time=181105.803035, global_step=411778, preemption_count=0, score=181105.803035, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=198202.115772, train/accuracy=0.890625, train/loss=0.410613, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:10:18.380572 139881808373504 logging_writer.py:48] [411800] global_step=411800, grad_norm=3.3459463119506836, loss=2.982146978378296
I0304 18:11:01.801037 139881799980800 logging_writer.py:48] [411900] global_step=411900, grad_norm=3.4570229053497314, loss=3.0108275413513184
I0304 18:11:47.232434 139881808373504 logging_writer.py:48] [412000] global_step=412000, grad_norm=2.944986343383789, loss=1.0084036588668823
I0304 18:12:32.304073 139881799980800 logging_writer.py:48] [412100] global_step=412100, grad_norm=3.0511131286621094, loss=1.6117022037506104
I0304 18:13:17.808500 139881808373504 logging_writer.py:48] [412200] global_step=412200, grad_norm=3.0605783462524414, loss=1.09700345993042
I0304 18:14:03.281978 139881799980800 logging_writer.py:48] [412300] global_step=412300, grad_norm=3.0383059978485107, loss=1.1479482650756836
I0304 18:14:48.437409 139881808373504 logging_writer.py:48] [412400] global_step=412400, grad_norm=3.890817880630493, loss=3.2080869674682617
I0304 18:15:33.674221 139881799980800 logging_writer.py:48] [412500] global_step=412500, grad_norm=3.0132718086242676, loss=1.9020644426345825
I0304 18:16:19.285188 139881808373504 logging_writer.py:48] [412600] global_step=412600, grad_norm=3.9892947673797607, loss=3.330850601196289
I0304 18:17:04.819748 139881799980800 logging_writer.py:48] [412700] global_step=412700, grad_norm=3.1845059394836426, loss=1.2151395082473755
I0304 18:17:09.408415 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:17:19.677372 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:17:46.905456 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:17:48.490434 140077943854912 submission_runner.py:411] Time since start: 198661.30s, 	Step: 412712, 	{'train/accuracy': 0.8864843845367432, 'train/loss': 0.4179598391056061, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 181525.74473643303, 'total_duration': 198661.29543995857, 'accumulated_submission_time': 181525.74473643303, 'accumulated_eval_time': 17083.35184264183, 'accumulated_logging_time': 30.711477279663086}
I0304 18:17:48.586948 139881808373504 logging_writer.py:48] [412712] accumulated_eval_time=17083.351843, accumulated_logging_time=30.711477, accumulated_submission_time=181525.744736, global_step=412712, preemption_count=0, score=181525.744736, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=198661.295440, train/accuracy=0.886484, train/loss=0.417960, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:18:24.725953 139881799980800 logging_writer.py:48] [412800] global_step=412800, grad_norm=3.0160157680511475, loss=1.0606489181518555
I0304 18:19:09.294402 139881808373504 logging_writer.py:48] [412900] global_step=412900, grad_norm=2.9474496841430664, loss=1.1455411911010742
I0304 18:19:53.992358 139881799980800 logging_writer.py:48] [413000] global_step=413000, grad_norm=2.8751959800720215, loss=1.0797698497772217
I0304 18:20:38.862173 139881808373504 logging_writer.py:48] [413100] global_step=413100, grad_norm=2.932558059692383, loss=1.0854445695877075
I0304 18:21:23.565531 139881799980800 logging_writer.py:48] [413200] global_step=413200, grad_norm=3.169334650039673, loss=1.2553483247756958
I0304 18:22:08.184672 139881808373504 logging_writer.py:48] [413300] global_step=413300, grad_norm=2.8310794830322266, loss=1.2401573657989502
I0304 18:22:52.789618 139881799980800 logging_writer.py:48] [413400] global_step=413400, grad_norm=3.4327030181884766, loss=3.0253918170928955
I0304 18:23:37.499509 139881808373504 logging_writer.py:48] [413500] global_step=413500, grad_norm=3.485414743423462, loss=1.7755613327026367
I0304 18:24:22.043269 139881799980800 logging_writer.py:48] [413600] global_step=413600, grad_norm=3.665100574493408, loss=1.7436330318450928
I0304 18:24:48.886106 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:24:59.136743 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:25:38.291599 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:25:39.867529 140077943854912 submission_runner.py:411] Time since start: 199132.67s, 	Step: 413662, 	{'train/accuracy': 0.8892187476158142, 'train/loss': 0.41308170557022095, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 181945.98531413078, 'total_duration': 199132.67255043983, 'accumulated_submission_time': 181945.98531413078, 'accumulated_eval_time': 17134.33325767517, 'accumulated_logging_time': 30.818686723709106}
I0304 18:25:39.944816 139881808373504 logging_writer.py:48] [413662] accumulated_eval_time=17134.333258, accumulated_logging_time=30.818687, accumulated_submission_time=181945.985314, global_step=413662, preemption_count=0, score=181945.985314, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=199132.672550, train/accuracy=0.889219, train/loss=0.413082, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:25:55.161026 139881799980800 logging_writer.py:48] [413700] global_step=413700, grad_norm=3.0632565021514893, loss=1.1888118982315063
I0304 18:26:36.992326 139881808373504 logging_writer.py:48] [413800] global_step=413800, grad_norm=3.0847432613372803, loss=1.1357884407043457
I0304 18:27:21.514827 139881799980800 logging_writer.py:48] [413900] global_step=413900, grad_norm=3.1086394786834717, loss=1.5828886032104492
I0304 18:28:06.162888 139881808373504 logging_writer.py:48] [414000] global_step=414000, grad_norm=3.1250040531158447, loss=2.651991605758667
I0304 18:28:50.387946 139881799980800 logging_writer.py:48] [414100] global_step=414100, grad_norm=3.3103389739990234, loss=1.3231240510940552
I0304 18:29:34.964020 139881808373504 logging_writer.py:48] [414200] global_step=414200, grad_norm=3.7545430660247803, loss=2.9912590980529785
I0304 18:30:19.534306 139881799980800 logging_writer.py:48] [414300] global_step=414300, grad_norm=3.1455562114715576, loss=1.2590277194976807
I0304 18:31:03.787221 139881808373504 logging_writer.py:48] [414400] global_step=414400, grad_norm=2.9798378944396973, loss=1.1766635179519653
I0304 18:31:48.532542 139881799980800 logging_writer.py:48] [414500] global_step=414500, grad_norm=3.179431200027466, loss=2.2100930213928223
I0304 18:32:32.938802 139881808373504 logging_writer.py:48] [414600] global_step=414600, grad_norm=3.2922630310058594, loss=1.2196376323699951
I0304 18:32:40.162963 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:32:50.421806 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:33:16.461717 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:33:18.072309 140077943854912 submission_runner.py:411] Time since start: 199590.88s, 	Step: 414618, 	{'train/accuracy': 0.8873242139816284, 'train/loss': 0.4246455430984497, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 182366.14447641373, 'total_duration': 199590.87727713585, 'accumulated_submission_time': 182366.14447641373, 'accumulated_eval_time': 17172.24253630638, 'accumulated_logging_time': 30.905985593795776}
I0304 18:33:18.213319 139881799980800 logging_writer.py:48] [414618] accumulated_eval_time=17172.242536, accumulated_logging_time=30.905986, accumulated_submission_time=182366.144476, global_step=414618, preemption_count=0, score=182366.144476, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=199590.877277, train/accuracy=0.887324, train/loss=0.424646, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:33:50.607086 139881808373504 logging_writer.py:48] [414700] global_step=414700, grad_norm=2.9759507179260254, loss=1.1447184085845947
I0304 18:34:34.893266 139881799980800 logging_writer.py:48] [414800] global_step=414800, grad_norm=3.0526204109191895, loss=1.4992454051971436
I0304 18:35:19.296676 139881808373504 logging_writer.py:48] [414900] global_step=414900, grad_norm=3.3117408752441406, loss=2.6874313354492188
I0304 18:36:03.371207 139881799980800 logging_writer.py:48] [415000] global_step=415000, grad_norm=3.357457399368286, loss=1.1340150833129883
I0304 18:36:47.694705 139881808373504 logging_writer.py:48] [415100] global_step=415100, grad_norm=2.855268955230713, loss=1.0890181064605713
I0304 18:37:32.203270 139881799980800 logging_writer.py:48] [415200] global_step=415200, grad_norm=3.035522222518921, loss=1.176809549331665
I0304 18:38:16.386822 139881808373504 logging_writer.py:48] [415300] global_step=415300, grad_norm=2.9635887145996094, loss=1.1881197690963745
I0304 18:39:00.916147 139881799980800 logging_writer.py:48] [415400] global_step=415400, grad_norm=3.525075912475586, loss=3.0145485401153564
I0304 18:39:45.233363 139881808373504 logging_writer.py:48] [415500] global_step=415500, grad_norm=3.3414597511291504, loss=1.620430827140808
I0304 18:40:18.375419 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:40:28.572352 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:40:59.524397 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:41:01.110808 140077943854912 submission_runner.py:411] Time since start: 200053.92s, 	Step: 415576, 	{'train/accuracy': 0.8868749737739563, 'train/loss': 0.4205108880996704, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 182786.24632263184, 'total_duration': 200053.91581463814, 'accumulated_submission_time': 182786.24632263184, 'accumulated_eval_time': 17214.97789669037, 'accumulated_logging_time': 31.057560920715332}
I0304 18:41:01.206327 139881799980800 logging_writer.py:48] [415576] accumulated_eval_time=17214.977897, accumulated_logging_time=31.057561, accumulated_submission_time=182786.246323, global_step=415576, preemption_count=0, score=182786.246323, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=200053.915815, train/accuracy=0.886875, train/loss=0.420511, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:41:10.969849 139881808373504 logging_writer.py:48] [415600] global_step=415600, grad_norm=2.8617937564849854, loss=1.7625272274017334
I0304 18:41:53.199725 139881799980800 logging_writer.py:48] [415700] global_step=415700, grad_norm=2.944226026535034, loss=1.1882401704788208
I0304 18:42:37.342522 139881808373504 logging_writer.py:48] [415800] global_step=415800, grad_norm=3.244372606277466, loss=1.0789239406585693
I0304 18:43:22.165389 139881799980800 logging_writer.py:48] [415900] global_step=415900, grad_norm=3.2039294242858887, loss=1.1018208265304565
I0304 18:44:07.027470 139881808373504 logging_writer.py:48] [416000] global_step=416000, grad_norm=3.0276854038238525, loss=1.3268611431121826
I0304 18:44:51.382800 139881799980800 logging_writer.py:48] [416100] global_step=416100, grad_norm=2.883533477783203, loss=1.3108606338500977
I0304 18:45:36.025416 139881808373504 logging_writer.py:48] [416200] global_step=416200, grad_norm=2.988940477371216, loss=1.2929496765136719
I0304 18:46:20.480603 139881799980800 logging_writer.py:48] [416300] global_step=416300, grad_norm=3.194279670715332, loss=2.1291255950927734
I0304 18:47:05.195586 139881808373504 logging_writer.py:48] [416400] global_step=416400, grad_norm=3.7765958309173584, loss=3.353799343109131
I0304 18:47:49.506825 139881799980800 logging_writer.py:48] [416500] global_step=416500, grad_norm=2.9552743434906006, loss=1.8290997743606567
I0304 18:48:01.366495 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:48:12.094475 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:48:43.216004 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:48:44.818962 140077943854912 submission_runner.py:411] Time since start: 200517.62s, 	Step: 416528, 	{'train/accuracy': 0.888964831829071, 'train/loss': 0.4104123115539551, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 183206.33918309212, 'total_duration': 200517.62397146225, 'accumulated_submission_time': 183206.33918309212, 'accumulated_eval_time': 17258.430349826813, 'accumulated_logging_time': 31.167073965072632}
I0304 18:48:44.917983 139881808373504 logging_writer.py:48] [416528] accumulated_eval_time=17258.430350, accumulated_logging_time=31.167074, accumulated_submission_time=183206.339183, global_step=416528, preemption_count=0, score=183206.339183, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=200517.623971, train/accuracy=0.888965, train/loss=0.410412, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:49:13.899175 139881799980800 logging_writer.py:48] [416600] global_step=416600, grad_norm=3.1958417892456055, loss=2.707266330718994
I0304 18:49:58.237268 139881808373504 logging_writer.py:48] [416700] global_step=416700, grad_norm=3.416226863861084, loss=1.3977022171020508
I0304 18:50:42.985422 139881799980800 logging_writer.py:48] [416800] global_step=416800, grad_norm=3.159210205078125, loss=1.1135529279708862
I0304 18:51:27.731559 139881808373504 logging_writer.py:48] [416900] global_step=416900, grad_norm=2.9858334064483643, loss=1.1454441547393799
I0304 18:52:12.353574 139881799980800 logging_writer.py:48] [417000] global_step=417000, grad_norm=3.6332600116729736, loss=3.0097508430480957
I0304 18:52:56.792050 139881808373504 logging_writer.py:48] [417100] global_step=417100, grad_norm=3.184443235397339, loss=1.4801985025405884
I0304 18:53:41.441085 139881799980800 logging_writer.py:48] [417200] global_step=417200, grad_norm=3.164015531539917, loss=1.373233437538147
I0304 18:54:25.988612 139881808373504 logging_writer.py:48] [417300] global_step=417300, grad_norm=2.9048104286193848, loss=1.853649377822876
I0304 18:55:10.480022 139881799980800 logging_writer.py:48] [417400] global_step=417400, grad_norm=3.255702495574951, loss=1.1693153381347656
I0304 18:55:44.954872 140077943854912 spec.py:321] Evaluating on the training split.
I0304 18:55:55.138422 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 18:56:24.836129 140077943854912 spec.py:349] Evaluating on the test split.
I0304 18:56:26.428947 140077943854912 submission_runner.py:411] Time since start: 200979.23s, 	Step: 417479, 	{'train/accuracy': 0.8873632550239563, 'train/loss': 0.41789519786834717, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 183626.31464791298, 'total_duration': 200979.23395895958, 'accumulated_submission_time': 183626.31464791298, 'accumulated_eval_time': 17299.904410362244, 'accumulated_logging_time': 31.27821397781372}
I0304 18:56:26.510756 139881808373504 logging_writer.py:48] [417479] accumulated_eval_time=17299.904410, accumulated_logging_time=31.278214, accumulated_submission_time=183626.314648, global_step=417479, preemption_count=0, score=183626.314648, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=200979.233959, train/accuracy=0.887363, train/loss=0.417895, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 18:56:35.168861 139881799980800 logging_writer.py:48] [417500] global_step=417500, grad_norm=2.965494155883789, loss=1.0680214166641235
I0304 18:57:16.239276 139881808373504 logging_writer.py:48] [417600] global_step=417600, grad_norm=2.8851611614227295, loss=1.689261555671692
I0304 18:58:00.522440 139881799980800 logging_writer.py:48] [417700] global_step=417700, grad_norm=3.2139065265655518, loss=1.3222451210021973
I0304 18:58:45.359465 139881808373504 logging_writer.py:48] [417800] global_step=417800, grad_norm=3.9929919242858887, loss=3.3166964054107666
I0304 18:59:30.160259 139881799980800 logging_writer.py:48] [417900] global_step=417900, grad_norm=3.0881965160369873, loss=2.050854206085205
I0304 19:00:14.750899 139881808373504 logging_writer.py:48] [418000] global_step=418000, grad_norm=3.3176991939544678, loss=1.1612353324890137
I0304 19:00:59.182870 139881799980800 logging_writer.py:48] [418100] global_step=418100, grad_norm=3.142848253250122, loss=1.0726170539855957
I0304 19:01:43.653965 139881808373504 logging_writer.py:48] [418200] global_step=418200, grad_norm=2.9809305667877197, loss=1.2293024063110352
I0304 19:02:27.967996 139881799980800 logging_writer.py:48] [418300] global_step=418300, grad_norm=3.067310094833374, loss=1.563848853111267
I0304 19:03:12.489206 139881808373504 logging_writer.py:48] [418400] global_step=418400, grad_norm=3.550480842590332, loss=3.0963120460510254
I0304 19:03:26.560184 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:03:36.859163 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:04:04.059172 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:04:05.646756 140077943854912 submission_runner.py:411] Time since start: 201438.45s, 	Step: 418433, 	{'train/accuracy': 0.8864062428474426, 'train/loss': 0.42548057436943054, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 184046.30386471748, 'total_duration': 201438.4517595768, 'accumulated_submission_time': 184046.30386471748, 'accumulated_eval_time': 17338.990936517715, 'accumulated_logging_time': 31.370931386947632}
I0304 19:04:05.745579 139881799980800 logging_writer.py:48] [418433] accumulated_eval_time=17338.990937, accumulated_logging_time=31.370931, accumulated_submission_time=184046.303865, global_step=418433, preemption_count=0, score=184046.303865, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=201438.451760, train/accuracy=0.886406, train/loss=0.425481, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:04:32.419487 139881808373504 logging_writer.py:48] [418500] global_step=418500, grad_norm=3.5821282863616943, loss=1.0904502868652344
I0304 19:05:16.920993 139881799980800 logging_writer.py:48] [418600] global_step=418600, grad_norm=3.168519973754883, loss=2.8935132026672363
I0304 19:06:01.358342 139881808373504 logging_writer.py:48] [418700] global_step=418700, grad_norm=3.3596391677856445, loss=1.9398913383483887
I0304 19:06:45.852719 139881799980800 logging_writer.py:48] [418800] global_step=418800, grad_norm=2.9711759090423584, loss=2.675567865371704
I0304 19:07:30.441434 139881808373504 logging_writer.py:48] [418900] global_step=418900, grad_norm=3.024115562438965, loss=1.6184545755386353
I0304 19:08:15.162081 139881799980800 logging_writer.py:48] [419000] global_step=419000, grad_norm=2.955739736557007, loss=1.4928029775619507
I0304 19:08:59.351600 139881808373504 logging_writer.py:48] [419100] global_step=419100, grad_norm=3.0074307918548584, loss=1.1566267013549805
I0304 19:09:44.026397 139881799980800 logging_writer.py:48] [419200] global_step=419200, grad_norm=3.097700595855713, loss=2.7369611263275146
I0304 19:10:28.590434 139881808373504 logging_writer.py:48] [419300] global_step=419300, grad_norm=2.8813297748565674, loss=1.135369062423706
I0304 19:11:05.648304 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:11:15.513787 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:11:53.599971 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:11:55.183856 140077943854912 submission_runner.py:411] Time since start: 201907.99s, 	Step: 419385, 	{'train/accuracy': 0.8881250023841858, 'train/loss': 0.4159334599971771, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 184466.1449456215, 'total_duration': 201907.98886823654, 'accumulated_submission_time': 184466.1449456215, 'accumulated_eval_time': 17388.526458263397, 'accumulated_logging_time': 31.482157945632935}
I0304 19:11:55.265115 139881799980800 logging_writer.py:48] [419385] accumulated_eval_time=17388.526458, accumulated_logging_time=31.482158, accumulated_submission_time=184466.144946, global_step=419385, preemption_count=0, score=184466.144946, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=201907.988868, train/accuracy=0.888125, train/loss=0.415933, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:12:01.741941 139881808373504 logging_writer.py:48] [419400] global_step=419400, grad_norm=3.5511538982391357, loss=2.9383387565612793
I0304 19:12:42.494841 139881799980800 logging_writer.py:48] [419500] global_step=419500, grad_norm=3.0323023796081543, loss=1.6928670406341553
I0304 19:13:26.836912 139881808373504 logging_writer.py:48] [419600] global_step=419600, grad_norm=3.0213782787323, loss=2.4009695053100586
I0304 19:14:11.402313 139881799980800 logging_writer.py:48] [419700] global_step=419700, grad_norm=3.032904624938965, loss=1.0337021350860596
I0304 19:14:55.659852 139881808373504 logging_writer.py:48] [419800] global_step=419800, grad_norm=3.2928354740142822, loss=1.9663838148117065
I0304 19:15:40.152272 139881799980800 logging_writer.py:48] [419900] global_step=419900, grad_norm=3.251141309738159, loss=2.1046431064605713
I0304 19:16:24.603411 139881808373504 logging_writer.py:48] [420000] global_step=420000, grad_norm=3.1693482398986816, loss=1.60024094581604
I0304 19:17:09.022674 139881799980800 logging_writer.py:48] [420100] global_step=420100, grad_norm=3.196216344833374, loss=2.6194751262664795
I0304 19:17:53.752096 139881808373504 logging_writer.py:48] [420200] global_step=420200, grad_norm=3.3002607822418213, loss=1.8585741519927979
I0304 19:18:37.845445 139881799980800 logging_writer.py:48] [420300] global_step=420300, grad_norm=3.1404778957366943, loss=2.483365058898926
I0304 19:18:55.256806 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:19:05.802423 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:19:31.766152 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:19:33.353005 140077943854912 submission_runner.py:411] Time since start: 202366.16s, 	Step: 420341, 	{'train/accuracy': 0.8867773413658142, 'train/loss': 0.423092246055603, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 184885.83039593697, 'total_duration': 202366.15796732903, 'accumulated_submission_time': 184885.83039593697, 'accumulated_eval_time': 17426.62258195877, 'accumulated_logging_time': 31.82004451751709}
I0304 19:19:33.456772 139881808373504 logging_writer.py:48] [420341] accumulated_eval_time=17426.622582, accumulated_logging_time=31.820045, accumulated_submission_time=184885.830396, global_step=420341, preemption_count=0, score=184885.830396, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=202366.157967, train/accuracy=0.886777, train/loss=0.423092, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:19:56.884779 139881799980800 logging_writer.py:48] [420400] global_step=420400, grad_norm=2.9688541889190674, loss=1.0167490243911743
I0304 19:20:40.881324 139881808373504 logging_writer.py:48] [420500] global_step=420500, grad_norm=3.1819546222686768, loss=1.812134861946106
I0304 19:21:25.647291 139881799980800 logging_writer.py:48] [420600] global_step=420600, grad_norm=3.061856269836426, loss=1.9980034828186035
I0304 19:22:10.305103 139881808373504 logging_writer.py:48] [420700] global_step=420700, grad_norm=3.0317673683166504, loss=1.6181989908218384
I0304 19:22:54.685111 139881799980800 logging_writer.py:48] [420800] global_step=420800, grad_norm=3.197280168533325, loss=1.282120704650879
I0304 19:23:39.271101 139881808373504 logging_writer.py:48] [420900] global_step=420900, grad_norm=3.5923452377319336, loss=1.821424126625061
I0304 19:24:23.660244 139881799980800 logging_writer.py:48] [421000] global_step=421000, grad_norm=3.0245001316070557, loss=1.1796460151672363
I0304 19:25:08.100820 139881808373504 logging_writer.py:48] [421100] global_step=421100, grad_norm=3.7033910751342773, loss=1.1201164722442627
I0304 19:25:52.514113 139881799980800 logging_writer.py:48] [421200] global_step=421200, grad_norm=3.658595323562622, loss=1.0827441215515137
I0304 19:26:33.540847 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:26:44.283742 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:27:14.922242 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:27:16.524347 140077943854912 submission_runner.py:411] Time since start: 202829.33s, 	Step: 421294, 	{'train/accuracy': 0.8882421851158142, 'train/loss': 0.4161365032196045, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 185305.8543047905, 'total_duration': 202829.32935857773, 'accumulated_submission_time': 185305.8543047905, 'accumulated_eval_time': 17469.606053113937, 'accumulated_logging_time': 31.93477702140808}
I0304 19:27:16.604557 139881808373504 logging_writer.py:48] [421294] accumulated_eval_time=17469.606053, accumulated_logging_time=31.934777, accumulated_submission_time=185305.854305, global_step=421294, preemption_count=0, score=185305.854305, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=202829.329359, train/accuracy=0.888242, train/loss=0.416137, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:27:19.332593 139881799980800 logging_writer.py:48] [421300] global_step=421300, grad_norm=3.827178478240967, loss=1.1466894149780273
I0304 19:27:59.802550 139881808373504 logging_writer.py:48] [421400] global_step=421400, grad_norm=2.9898600578308105, loss=1.803816556930542
I0304 19:28:44.133794 139881799980800 logging_writer.py:48] [421500] global_step=421500, grad_norm=3.0729434490203857, loss=2.738426685333252
I0304 19:29:28.615907 139881808373504 logging_writer.py:48] [421600] global_step=421600, grad_norm=3.4542505741119385, loss=2.2600314617156982
I0304 19:30:13.241943 139881799980800 logging_writer.py:48] [421700] global_step=421700, grad_norm=3.121365785598755, loss=1.1282074451446533
I0304 19:30:57.602282 139881808373504 logging_writer.py:48] [421800] global_step=421800, grad_norm=2.894979953765869, loss=1.2524067163467407
I0304 19:31:42.086647 139881799980800 logging_writer.py:48] [421900] global_step=421900, grad_norm=2.9826762676239014, loss=2.2982559204101562
I0304 19:32:26.471857 139881808373504 logging_writer.py:48] [422000] global_step=422000, grad_norm=4.108445644378662, loss=3.1894099712371826
I0304 19:33:11.021535 139881799980800 logging_writer.py:48] [422100] global_step=422100, grad_norm=3.0874361991882324, loss=1.121816873550415
I0304 19:33:55.352816 139881808373504 logging_writer.py:48] [422200] global_step=422200, grad_norm=3.4573240280151367, loss=2.4810664653778076
I0304 19:34:16.805085 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:34:26.918487 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:34:53.618607 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:34:55.205037 140077943854912 submission_runner.py:411] Time since start: 203288.01s, 	Step: 422250, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.41208335757255554, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 185725.99530100822, 'total_duration': 203288.01004314423, 'accumulated_submission_time': 185725.99530100822, 'accumulated_eval_time': 17508.005979537964, 'accumulated_logging_time': 32.02518367767334}
I0304 19:34:55.302530 139881799980800 logging_writer.py:48] [422250] accumulated_eval_time=17508.005980, accumulated_logging_time=32.025184, accumulated_submission_time=185725.995301, global_step=422250, preemption_count=0, score=185725.995301, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=203288.010043, train/accuracy=0.888477, train/loss=0.412083, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:35:15.209389 139881808373504 logging_writer.py:48] [422300] global_step=422300, grad_norm=3.112194538116455, loss=1.1453911066055298
I0304 19:35:58.437175 139881799980800 logging_writer.py:48] [422400] global_step=422400, grad_norm=3.274268627166748, loss=1.0745223760604858
I0304 19:36:43.356861 139881808373504 logging_writer.py:48] [422500] global_step=422500, grad_norm=4.299243927001953, loss=3.1729702949523926
I0304 19:37:27.811917 139881799980800 logging_writer.py:48] [422600] global_step=422600, grad_norm=3.886308431625366, loss=3.159449338912964
I0304 19:38:12.533568 139881808373504 logging_writer.py:48] [422700] global_step=422700, grad_norm=3.0043787956237793, loss=2.61240553855896
I0304 19:38:56.724573 139881799980800 logging_writer.py:48] [422800] global_step=422800, grad_norm=3.4311957359313965, loss=1.0773320198059082
I0304 19:39:41.100731 139881808373504 logging_writer.py:48] [422900] global_step=422900, grad_norm=3.3102288246154785, loss=2.5567076206207275
I0304 19:40:25.669176 139881799980800 logging_writer.py:48] [423000] global_step=423000, grad_norm=3.2708041667938232, loss=2.3658223152160645
I0304 19:41:10.255237 139881808373504 logging_writer.py:48] [423100] global_step=423100, grad_norm=3.1367125511169434, loss=1.1363826990127563
I0304 19:41:54.730638 139881799980800 logging_writer.py:48] [423200] global_step=423200, grad_norm=3.188288450241089, loss=1.6342638731002808
I0304 19:41:55.355036 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:42:06.121108 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:42:34.445384 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:42:36.041981 140077943854912 submission_runner.py:411] Time since start: 203748.85s, 	Step: 423203, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.41462627053260803, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 186145.98817968369, 'total_duration': 203748.84698295593, 'accumulated_submission_time': 186145.98817968369, 'accumulated_eval_time': 17548.692868709564, 'accumulated_logging_time': 32.13347125053406}
I0304 19:42:36.139976 139881808373504 logging_writer.py:48] [423203] accumulated_eval_time=17548.692869, accumulated_logging_time=32.133471, accumulated_submission_time=186145.988180, global_step=423203, preemption_count=0, score=186145.988180, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=203748.846983, train/accuracy=0.888340, train/loss=0.414626, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:43:16.060107 139881799980800 logging_writer.py:48] [423300] global_step=423300, grad_norm=3.5262351036071777, loss=2.934724807739258
I0304 19:44:00.457554 139881808373504 logging_writer.py:48] [423400] global_step=423400, grad_norm=3.1081390380859375, loss=1.0759538412094116
I0304 19:44:44.802741 139881799980800 logging_writer.py:48] [423500] global_step=423500, grad_norm=3.1328377723693848, loss=1.175206184387207
I0304 19:45:29.083319 139881808373504 logging_writer.py:48] [423600] global_step=423600, grad_norm=3.2788989543914795, loss=1.4899778366088867
I0304 19:46:13.202717 139881799980800 logging_writer.py:48] [423700] global_step=423700, grad_norm=2.976027727127075, loss=2.0724523067474365
I0304 19:46:57.651913 139881808373504 logging_writer.py:48] [423800] global_step=423800, grad_norm=2.8628358840942383, loss=1.6219946146011353
I0304 19:47:42.322824 139881799980800 logging_writer.py:48] [423900] global_step=423900, grad_norm=3.100630283355713, loss=1.277450442314148
I0304 19:48:26.681671 139881808373504 logging_writer.py:48] [424000] global_step=424000, grad_norm=3.188511610031128, loss=1.7964595556259155
I0304 19:49:10.904188 139881799980800 logging_writer.py:48] [424100] global_step=424100, grad_norm=3.297957420349121, loss=1.129690170288086
I0304 19:49:36.100895 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:49:46.245357 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:50:19.225680 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:50:20.844311 140077943854912 submission_runner.py:411] Time since start: 204213.65s, 	Step: 424158, 	{'train/accuracy': 0.8863085508346558, 'train/loss': 0.42144614458084106, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 186565.88954353333, 'total_duration': 204213.6493074894, 'accumulated_submission_time': 186565.88954353333, 'accumulated_eval_time': 17593.436250925064, 'accumulated_logging_time': 32.24198937416077}
I0304 19:50:20.937515 139881808373504 logging_writer.py:48] [424158] accumulated_eval_time=17593.436251, accumulated_logging_time=32.241989, accumulated_submission_time=186565.889544, global_step=424158, preemption_count=0, score=186565.889544, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=204213.649307, train/accuracy=0.886309, train/loss=0.421446, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:50:37.708741 139881799980800 logging_writer.py:48] [424200] global_step=424200, grad_norm=2.976733922958374, loss=1.3225953578948975
I0304 19:51:19.584104 139881808373504 logging_writer.py:48] [424300] global_step=424300, grad_norm=3.314767837524414, loss=1.086099624633789
I0304 19:52:04.512744 139881799980800 logging_writer.py:48] [424400] global_step=424400, grad_norm=3.344541311264038, loss=1.1998766660690308
I0304 19:52:49.095562 139881808373504 logging_writer.py:48] [424500] global_step=424500, grad_norm=3.1349599361419678, loss=1.1335835456848145
I0304 19:53:33.452261 139881799980800 logging_writer.py:48] [424600] global_step=424600, grad_norm=3.1458983421325684, loss=2.520763397216797
I0304 19:54:18.218797 139881808373504 logging_writer.py:48] [424700] global_step=424700, grad_norm=2.7551722526550293, loss=1.443681240081787
I0304 19:55:02.538860 139881799980800 logging_writer.py:48] [424800] global_step=424800, grad_norm=3.192317247390747, loss=1.0388566255569458
I0304 19:55:47.075106 139881808373504 logging_writer.py:48] [424900] global_step=424900, grad_norm=3.0565600395202637, loss=1.644791841506958
I0304 19:56:31.888740 139881799980800 logging_writer.py:48] [425000] global_step=425000, grad_norm=3.3121304512023926, loss=1.3403726816177368
I0304 19:57:16.493494 139881808373504 logging_writer.py:48] [425100] global_step=425100, grad_norm=3.081376552581787, loss=1.1079788208007812
I0304 19:57:21.109297 140077943854912 spec.py:321] Evaluating on the training split.
I0304 19:57:31.360193 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 19:57:56.800464 140077943854912 spec.py:349] Evaluating on the test split.
I0304 19:57:58.397627 140077943854912 submission_runner.py:411] Time since start: 204671.20s, 	Step: 425112, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.416959673166275, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 186986.0024909973, 'total_duration': 204671.20263504982, 'accumulated_submission_time': 186986.0024909973, 'accumulated_eval_time': 17630.724541187286, 'accumulated_logging_time': 32.34537315368652}
I0304 19:57:58.496393 139881799980800 logging_writer.py:48] [425112] accumulated_eval_time=17630.724541, accumulated_logging_time=32.345373, accumulated_submission_time=186986.002491, global_step=425112, preemption_count=0, score=186986.002491, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=204671.202635, train/accuracy=0.888906, train/loss=0.416960, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 19:58:34.355327 139881808373504 logging_writer.py:48] [425200] global_step=425200, grad_norm=3.4431076049804688, loss=1.1400314569473267
I0304 19:59:18.523689 139881799980800 logging_writer.py:48] [425300] global_step=425300, grad_norm=3.180382490158081, loss=1.163880467414856
I0304 20:00:03.286834 139881808373504 logging_writer.py:48] [425400] global_step=425400, grad_norm=3.099213123321533, loss=1.7479338645935059
I0304 20:00:47.721218 139881799980800 logging_writer.py:48] [425500] global_step=425500, grad_norm=3.6564245223999023, loss=1.1033997535705566
I0304 20:01:32.007236 139881808373504 logging_writer.py:48] [425600] global_step=425600, grad_norm=3.183756113052368, loss=2.194429874420166
I0304 20:02:16.588800 139881799980800 logging_writer.py:48] [425700] global_step=425700, grad_norm=3.008058547973633, loss=1.2064799070358276
I0304 20:03:00.956365 139881808373504 logging_writer.py:48] [425800] global_step=425800, grad_norm=3.1552250385284424, loss=1.1249397993087769
I0304 20:03:45.431938 139881799980800 logging_writer.py:48] [425900] global_step=425900, grad_norm=2.9554641246795654, loss=1.1217679977416992
I0304 20:04:29.774065 139881808373504 logging_writer.py:48] [426000] global_step=426000, grad_norm=3.2774672508239746, loss=1.1818132400512695
I0304 20:04:58.688001 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:05:09.245180 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:05:42.748513 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:05:44.335482 140077943854912 submission_runner.py:411] Time since start: 205137.14s, 	Step: 426067, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.4230095446109772, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 187406.1336224079, 'total_duration': 205137.14049386978, 'accumulated_submission_time': 187406.1336224079, 'accumulated_eval_time': 17676.37200140953, 'accumulated_logging_time': 32.45468544960022}
I0304 20:05:44.433921 139881799980800 logging_writer.py:48] [426067] accumulated_eval_time=17676.372001, accumulated_logging_time=32.454685, accumulated_submission_time=187406.133622, global_step=426067, preemption_count=0, score=187406.133622, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=205137.140494, train/accuracy=0.888477, train/loss=0.423010, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 20:05:57.714787 139881808373504 logging_writer.py:48] [426100] global_step=426100, grad_norm=3.026550054550171, loss=2.0693745613098145
I0304 20:06:39.706448 139881799980800 logging_writer.py:48] [426200] global_step=426200, grad_norm=2.8861401081085205, loss=1.6930304765701294
I0304 20:07:24.000781 139881808373504 logging_writer.py:48] [426300] global_step=426300, grad_norm=3.290010452270508, loss=1.562738060951233
I0304 20:08:08.834642 139881799980800 logging_writer.py:48] [426400] global_step=426400, grad_norm=2.9468460083007812, loss=1.8835904598236084
I0304 20:08:52.944483 139881808373504 logging_writer.py:48] [426500] global_step=426500, grad_norm=3.4006450176239014, loss=2.6532492637634277
I0304 20:09:37.480482 139881799980800 logging_writer.py:48] [426600] global_step=426600, grad_norm=2.9718613624572754, loss=2.0191047191619873
I0304 20:10:22.172056 139881808373504 logging_writer.py:48] [426700] global_step=426700, grad_norm=3.2435200214385986, loss=1.1816694736480713
I0304 20:11:06.606505 139881799980800 logging_writer.py:48] [426800] global_step=426800, grad_norm=3.3310468196868896, loss=2.6945278644561768
I0304 20:11:51.149809 139881808373504 logging_writer.py:48] [426900] global_step=426900, grad_norm=2.9632372856140137, loss=1.5133564472198486
I0304 20:12:35.751516 139881799980800 logging_writer.py:48] [427000] global_step=427000, grad_norm=3.0609302520751953, loss=1.1329983472824097
I0304 20:12:44.729527 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:12:54.929012 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:13:27.206200 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:13:28.814857 140077943854912 submission_runner.py:411] Time since start: 205601.62s, 	Step: 427022, 	{'train/accuracy': 0.8894140720367432, 'train/loss': 0.40900570154190063, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 187826.3649520874, 'total_duration': 205601.61987805367, 'accumulated_submission_time': 187826.3649520874, 'accumulated_eval_time': 17720.457312583923, 'accumulated_logging_time': 32.567978382110596}
I0304 20:13:28.894038 139881808373504 logging_writer.py:48] [427022] accumulated_eval_time=17720.457313, accumulated_logging_time=32.567978, accumulated_submission_time=187826.364952, global_step=427022, preemption_count=0, score=187826.364952, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=205601.619878, train/accuracy=0.889414, train/loss=0.409006, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 20:13:59.701069 139881799980800 logging_writer.py:48] [427100] global_step=427100, grad_norm=3.225440740585327, loss=1.207930564880371
I0304 20:14:43.489659 139881808373504 logging_writer.py:48] [427200] global_step=427200, grad_norm=3.082797050476074, loss=2.4201722145080566
I0304 20:15:28.155753 139881799980800 logging_writer.py:48] [427300] global_step=427300, grad_norm=4.354759693145752, loss=2.98498797416687
I0304 20:16:12.853358 139881808373504 logging_writer.py:48] [427400] global_step=427400, grad_norm=3.1625640392303467, loss=1.1345080137252808
I0304 20:16:57.150531 139881799980800 logging_writer.py:48] [427500] global_step=427500, grad_norm=3.050736427307129, loss=1.2153619527816772
I0304 20:17:41.620251 139881808373504 logging_writer.py:48] [427600] global_step=427600, grad_norm=3.05851149559021, loss=1.2594997882843018
I0304 20:18:26.189661 139881799980800 logging_writer.py:48] [427700] global_step=427700, grad_norm=2.956160068511963, loss=1.110714316368103
I0304 20:19:10.381535 139881808373504 logging_writer.py:48] [427800] global_step=427800, grad_norm=2.9050261974334717, loss=1.6178202629089355
I0304 20:19:54.943203 139881799980800 logging_writer.py:48] [427900] global_step=427900, grad_norm=3.3561007976531982, loss=1.1689019203186035
I0304 20:20:29.233347 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:20:39.408228 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:21:15.012198 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:21:16.585744 140077943854912 submission_runner.py:411] Time since start: 206069.39s, 	Step: 427979, 	{'train/accuracy': 0.8889452815055847, 'train/loss': 0.41165655851364136, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 188246.64551234245, 'total_duration': 206069.3907442093, 'accumulated_submission_time': 188246.64551234245, 'accumulated_eval_time': 17767.809679031372, 'accumulated_logging_time': 32.65678024291992}
I0304 20:21:16.665929 139881808373504 logging_writer.py:48] [427979] accumulated_eval_time=17767.809679, accumulated_logging_time=32.656780, accumulated_submission_time=188246.645512, global_step=427979, preemption_count=0, score=188246.645512, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=206069.390744, train/accuracy=0.888945, train/loss=0.411657, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 20:21:25.236545 139881799980800 logging_writer.py:48] [428000] global_step=428000, grad_norm=3.156559467315674, loss=1.3474749326705933
I0304 20:22:06.771016 139881808373504 logging_writer.py:48] [428100] global_step=428100, grad_norm=3.5360569953918457, loss=2.476820707321167
I0304 20:22:51.190762 139881799980800 logging_writer.py:48] [428200] global_step=428200, grad_norm=4.003283500671387, loss=3.407841205596924
I0304 20:23:35.798227 139881808373504 logging_writer.py:48] [428300] global_step=428300, grad_norm=3.3999476432800293, loss=1.6900187730789185
I0304 20:24:20.234598 139881799980800 logging_writer.py:48] [428400] global_step=428400, grad_norm=3.251983165740967, loss=2.61118483543396
I0304 20:25:04.689593 139881808373504 logging_writer.py:48] [428500] global_step=428500, grad_norm=2.969846725463867, loss=1.1420037746429443
I0304 20:25:48.980583 139881799980800 logging_writer.py:48] [428600] global_step=428600, grad_norm=3.7989561557769775, loss=1.8526843786239624
I0304 20:26:33.862424 139881808373504 logging_writer.py:48] [428700] global_step=428700, grad_norm=3.0458734035491943, loss=1.880242109298706
I0304 20:27:18.025760 139881799980800 logging_writer.py:48] [428800] global_step=428800, grad_norm=3.5952391624450684, loss=1.4296486377716064
I0304 20:28:02.375372 139881808373504 logging_writer.py:48] [428900] global_step=428900, grad_norm=3.069735527038574, loss=1.8251986503601074
I0304 20:28:16.722908 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:28:27.985430 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:28:56.589491 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:28:58.179619 140077943854912 submission_runner.py:411] Time since start: 206530.98s, 	Step: 428934, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.4169478118419647, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 188666.6430413723, 'total_duration': 206530.98461413383, 'accumulated_submission_time': 188666.6430413723, 'accumulated_eval_time': 17809.26633501053, 'accumulated_logging_time': 32.74723792076111}
I0304 20:28:58.276629 139881799980800 logging_writer.py:48] [428934] accumulated_eval_time=17809.266335, accumulated_logging_time=32.747238, accumulated_submission_time=188666.643041, global_step=428934, preemption_count=0, score=188666.643041, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=206530.984614, train/accuracy=0.888066, train/loss=0.416948, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 20:29:24.455975 139881808373504 logging_writer.py:48] [429000] global_step=429000, grad_norm=3.0882747173309326, loss=1.0831669569015503
I0304 20:30:08.305266 139881799980800 logging_writer.py:48] [429100] global_step=429100, grad_norm=3.039804220199585, loss=1.142830729484558
I0304 20:30:52.944712 139881808373504 logging_writer.py:48] [429200] global_step=429200, grad_norm=2.933725357055664, loss=1.526207685470581
I0304 20:31:37.415880 139881799980800 logging_writer.py:48] [429300] global_step=429300, grad_norm=3.056011199951172, loss=1.5349922180175781
I0304 20:32:21.972576 139881808373504 logging_writer.py:48] [429400] global_step=429400, grad_norm=2.8679990768432617, loss=1.411472201347351
I0304 20:33:06.428479 139881799980800 logging_writer.py:48] [429500] global_step=429500, grad_norm=3.0105857849121094, loss=1.2868905067443848
I0304 20:33:51.104545 139881808373504 logging_writer.py:48] [429600] global_step=429600, grad_norm=2.9609572887420654, loss=1.1209111213684082
I0304 20:34:35.617101 139881799980800 logging_writer.py:48] [429700] global_step=429700, grad_norm=3.1995129585266113, loss=1.2557686567306519
I0304 20:35:20.150887 139881808373504 logging_writer.py:48] [429800] global_step=429800, grad_norm=4.653923988342285, loss=3.1432924270629883
I0304 20:35:58.251841 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:36:08.905796 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:36:40.782649 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:36:42.364751 140077943854912 submission_runner.py:411] Time since start: 206995.17s, 	Step: 429888, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.41411325335502625, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 189086.55633735657, 'total_duration': 206995.16974568367, 'accumulated_submission_time': 189086.55633735657, 'accumulated_eval_time': 17853.379207134247, 'accumulated_logging_time': 32.857391119003296}
I0304 20:36:42.465957 139881799980800 logging_writer.py:48] [429888] accumulated_eval_time=17853.379207, accumulated_logging_time=32.857391, accumulated_submission_time=189086.556337, global_step=429888, preemption_count=0, score=189086.556337, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=206995.169746, train/accuracy=0.887910, train/loss=0.414113, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 20:36:47.538343 139881808373504 logging_writer.py:48] [429900] global_step=429900, grad_norm=3.313722610473633, loss=1.141555666923523
I0304 20:37:29.676225 139881799980800 logging_writer.py:48] [430000] global_step=430000, grad_norm=2.9231395721435547, loss=1.6934478282928467
I0304 20:38:14.228653 139881808373504 logging_writer.py:48] [430100] global_step=430100, grad_norm=3.1472880840301514, loss=1.17010498046875
I0304 20:38:58.841459 139881799980800 logging_writer.py:48] [430200] global_step=430200, grad_norm=3.311535596847534, loss=1.1832005977630615
I0304 20:39:43.895408 139881808373504 logging_writer.py:48] [430300] global_step=430300, grad_norm=3.104757308959961, loss=2.656902313232422
I0304 20:40:29.096380 139881799980800 logging_writer.py:48] [430400] global_step=430400, grad_norm=3.107396125793457, loss=1.2987208366394043
I0304 20:41:13.709937 139881808373504 logging_writer.py:48] [430500] global_step=430500, grad_norm=3.0027689933776855, loss=1.0911270380020142
I0304 20:41:58.732360 139881799980800 logging_writer.py:48] [430600] global_step=430600, grad_norm=3.086129903793335, loss=1.179795503616333
I0304 20:42:43.695389 139881808373504 logging_writer.py:48] [430700] global_step=430700, grad_norm=3.394901990890503, loss=2.960874080657959
I0304 20:43:28.543771 139881799980800 logging_writer.py:48] [430800] global_step=430800, grad_norm=3.012678623199463, loss=1.0843372344970703
I0304 20:43:42.448053 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:43:52.398227 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:44:23.547513 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:44:25.142977 140077943854912 submission_runner.py:411] Time since start: 207457.95s, 	Step: 430833, 	{'train/accuracy': 0.8874804377555847, 'train/loss': 0.4158562123775482, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 189506.47734236717, 'total_duration': 207457.9479892254, 'accumulated_submission_time': 189506.47734236717, 'accumulated_eval_time': 17896.074108600616, 'accumulated_logging_time': 32.970332860946655}
I0304 20:44:25.223685 139881808373504 logging_writer.py:48] [430833] accumulated_eval_time=17896.074109, accumulated_logging_time=32.970333, accumulated_submission_time=189506.477342, global_step=430833, preemption_count=0, score=189506.477342, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=207457.947989, train/accuracy=0.887480, train/loss=0.415856, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 20:44:51.743638 139881799980800 logging_writer.py:48] [430900] global_step=430900, grad_norm=2.842348098754883, loss=1.1300950050354004
I0304 20:45:35.391239 139881808373504 logging_writer.py:48] [431000] global_step=431000, grad_norm=4.260553359985352, loss=2.832324504852295
I0304 20:46:20.180066 139881799980800 logging_writer.py:48] [431100] global_step=431100, grad_norm=3.144688129425049, loss=1.12791907787323
I0304 20:47:05.048569 139881808373504 logging_writer.py:48] [431200] global_step=431200, grad_norm=3.229886770248413, loss=1.140588641166687
I0304 20:47:49.265457 139881799980800 logging_writer.py:48] [431300] global_step=431300, grad_norm=3.2081761360168457, loss=1.2104344367980957
I0304 20:48:33.870735 139881808373504 logging_writer.py:48] [431400] global_step=431400, grad_norm=2.9941868782043457, loss=1.1546119451522827
I0304 20:49:18.264728 139881799980800 logging_writer.py:48] [431500] global_step=431500, grad_norm=3.1240909099578857, loss=1.1509476900100708
I0304 20:50:02.927708 139881808373504 logging_writer.py:48] [431600] global_step=431600, grad_norm=3.228883981704712, loss=1.459959864616394
I0304 20:50:47.712777 139881799980800 logging_writer.py:48] [431700] global_step=431700, grad_norm=3.128173589706421, loss=2.0423507690429688
I0304 20:51:25.417738 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:51:35.394918 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:52:03.669708 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:52:05.260510 140077943854912 submission_runner.py:411] Time since start: 207918.07s, 	Step: 431786, 	{'train/accuracy': 0.8893945217132568, 'train/loss': 0.41295158863067627, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 189926.61285805702, 'total_duration': 207918.0655157566, 'accumulated_submission_time': 189926.61285805702, 'accumulated_eval_time': 17935.916864156723, 'accumulated_logging_time': 33.06070804595947}
I0304 20:52:05.362433 139881808373504 logging_writer.py:48] [431786] accumulated_eval_time=17935.916864, accumulated_logging_time=33.060708, accumulated_submission_time=189926.612858, global_step=431786, preemption_count=0, score=189926.612858, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=207918.065516, train/accuracy=0.889395, train/loss=0.412952, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 20:52:11.235908 139881799980800 logging_writer.py:48] [431800] global_step=431800, grad_norm=3.2327611446380615, loss=2.3197484016418457
I0304 20:52:53.486780 139881808373504 logging_writer.py:48] [431900] global_step=431900, grad_norm=3.2608554363250732, loss=1.1500087976455688
I0304 20:53:38.456082 139881799980800 logging_writer.py:48] [432000] global_step=432000, grad_norm=3.143143653869629, loss=1.0477746725082397
I0304 20:54:23.327574 139881808373504 logging_writer.py:48] [432100] global_step=432100, grad_norm=3.2880942821502686, loss=1.6076576709747314
I0304 20:55:08.294026 139881799980800 logging_writer.py:48] [432200] global_step=432200, grad_norm=3.1367383003234863, loss=1.1155486106872559
I0304 20:55:53.072448 139881808373504 logging_writer.py:48] [432300] global_step=432300, grad_norm=3.0317556858062744, loss=1.6378661394119263
I0304 20:56:38.037191 139881799980800 logging_writer.py:48] [432400] global_step=432400, grad_norm=3.109502077102661, loss=1.2672333717346191
I0304 20:57:22.902629 139881808373504 logging_writer.py:48] [432500] global_step=432500, grad_norm=3.253610372543335, loss=1.5846065282821655
I0304 20:58:07.839752 139881799980800 logging_writer.py:48] [432600] global_step=432600, grad_norm=3.283468008041382, loss=1.1175695657730103
I0304 20:58:52.824432 139881808373504 logging_writer.py:48] [432700] global_step=432700, grad_norm=3.785966157913208, loss=3.381085157394409
I0304 20:59:05.513662 140077943854912 spec.py:321] Evaluating on the training split.
I0304 20:59:16.060717 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 20:59:44.246883 140077943854912 spec.py:349] Evaluating on the test split.
I0304 20:59:45.828562 140077943854912 submission_runner.py:411] Time since start: 208378.63s, 	Step: 432730, 	{'train/accuracy': 0.8885937333106995, 'train/loss': 0.41985487937927246, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 190346.70286297798, 'total_duration': 208378.6335697174, 'accumulated_submission_time': 190346.70286297798, 'accumulated_eval_time': 17976.231738567352, 'accumulated_logging_time': 33.17487382888794}
I0304 20:59:45.930416 139881799980800 logging_writer.py:48] [432730] accumulated_eval_time=17976.231739, accumulated_logging_time=33.174874, accumulated_submission_time=190346.702863, global_step=432730, preemption_count=0, score=190346.702863, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=208378.633570, train/accuracy=0.888594, train/loss=0.419855, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:00:14.030743 139881808373504 logging_writer.py:48] [432800] global_step=432800, grad_norm=2.7804009914398193, loss=1.9777979850769043
I0304 21:00:58.375798 139881799980800 logging_writer.py:48] [432900] global_step=432900, grad_norm=3.0666747093200684, loss=1.1423943042755127
I0304 21:01:42.996635 139881808373504 logging_writer.py:48] [433000] global_step=433000, grad_norm=3.1527767181396484, loss=1.1958227157592773
I0304 21:02:27.788503 139881799980800 logging_writer.py:48] [433100] global_step=433100, grad_norm=3.739161729812622, loss=1.1260287761688232
I0304 21:03:12.466012 139881808373504 logging_writer.py:48] [433200] global_step=433200, grad_norm=3.28641414642334, loss=1.1761404275894165
I0304 21:03:56.820208 139881799980800 logging_writer.py:48] [433300] global_step=433300, grad_norm=3.6428918838500977, loss=3.1905086040496826
I0304 21:04:41.498831 139881808373504 logging_writer.py:48] [433400] global_step=433400, grad_norm=3.2883589267730713, loss=1.1791185140609741
I0304 21:05:26.197201 139881799980800 logging_writer.py:48] [433500] global_step=433500, grad_norm=3.165144681930542, loss=1.152226448059082
I0304 21:06:10.666276 139881808373504 logging_writer.py:48] [433600] global_step=433600, grad_norm=3.253927707672119, loss=1.0376126766204834
I0304 21:06:45.873708 140077943854912 spec.py:321] Evaluating on the training split.
I0304 21:06:56.252942 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 21:07:30.221615 140077943854912 spec.py:349] Evaluating on the test split.
I0304 21:07:31.803464 140077943854912 submission_runner.py:411] Time since start: 208844.61s, 	Step: 433681, 	{'train/accuracy': 0.8869335651397705, 'train/loss': 0.418942928314209, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 190766.58616805077, 'total_duration': 208844.6084537506, 'accumulated_submission_time': 190766.58616805077, 'accumulated_eval_time': 18022.161470651627, 'accumulated_logging_time': 33.28832411766052}
I0304 21:07:31.894693 139881799980800 logging_writer.py:48] [433681] accumulated_eval_time=18022.161471, accumulated_logging_time=33.288324, accumulated_submission_time=190766.586168, global_step=433681, preemption_count=0, score=190766.586168, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=208844.608454, train/accuracy=0.886934, train/loss=0.418943, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:07:39.682681 139881808373504 logging_writer.py:48] [433700] global_step=433700, grad_norm=3.572059154510498, loss=3.1377949714660645
I0304 21:08:20.342150 139881799980800 logging_writer.py:48] [433800] global_step=433800, grad_norm=3.131530284881592, loss=2.1496524810791016
I0304 21:09:05.016614 139881808373504 logging_writer.py:48] [433900] global_step=433900, grad_norm=2.9207372665405273, loss=1.7184059619903564
I0304 21:09:49.619242 139881799980800 logging_writer.py:48] [434000] global_step=434000, grad_norm=2.887570381164551, loss=1.8301817178726196
I0304 21:10:34.138391 139881808373504 logging_writer.py:48] [434100] global_step=434100, grad_norm=3.3818910121917725, loss=1.0778967142105103
I0304 21:11:18.776730 139881799980800 logging_writer.py:48] [434200] global_step=434200, grad_norm=3.179655075073242, loss=1.1634070873260498
I0304 21:12:03.460572 139881808373504 logging_writer.py:48] [434300] global_step=434300, grad_norm=3.098444700241089, loss=1.090864896774292
I0304 21:12:47.808173 139881799980800 logging_writer.py:48] [434400] global_step=434400, grad_norm=3.3738014698028564, loss=1.2153160572052002
I0304 21:13:32.476529 139881808373504 logging_writer.py:48] [434500] global_step=434500, grad_norm=3.0373268127441406, loss=1.98582124710083
I0304 21:14:16.756213 139881799980800 logging_writer.py:48] [434600] global_step=434600, grad_norm=3.424565553665161, loss=3.123380184173584
I0304 21:14:31.939928 140077943854912 spec.py:321] Evaluating on the training split.
I0304 21:14:41.891398 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 21:15:09.283200 140077943854912 spec.py:349] Evaluating on the test split.
I0304 21:15:10.869064 140077943854912 submission_runner.py:411] Time since start: 209303.67s, 	Step: 434636, 	{'train/accuracy': 0.8886327743530273, 'train/loss': 0.4150497019290924, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 191186.57088375092, 'total_duration': 209303.67406725883, 'accumulated_submission_time': 191186.57088375092, 'accumulated_eval_time': 18061.090587615967, 'accumulated_logging_time': 33.39108967781067}
I0304 21:15:10.971112 139881808373504 logging_writer.py:48] [434636] accumulated_eval_time=18061.090588, accumulated_logging_time=33.391090, accumulated_submission_time=191186.570884, global_step=434636, preemption_count=0, score=191186.570884, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=209303.674067, train/accuracy=0.888633, train/loss=0.415050, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:15:36.359841 139881799980800 logging_writer.py:48] [434700] global_step=434700, grad_norm=3.629608392715454, loss=3.1304705142974854
I0304 21:16:20.525579 139881808373504 logging_writer.py:48] [434800] global_step=434800, grad_norm=4.194631576538086, loss=3.1986238956451416
I0304 21:17:04.988340 139881799980800 logging_writer.py:48] [434900] global_step=434900, grad_norm=3.578179121017456, loss=3.0135321617126465
I0304 21:17:49.359517 139881808373504 logging_writer.py:48] [435000] global_step=435000, grad_norm=3.0447235107421875, loss=1.4134609699249268
I0304 21:18:33.921105 139881799980800 logging_writer.py:48] [435100] global_step=435100, grad_norm=3.323636531829834, loss=1.0596776008605957
I0304 21:19:18.463736 139881808373504 logging_writer.py:48] [435200] global_step=435200, grad_norm=3.1940908432006836, loss=1.1539134979248047
I0304 21:20:03.058823 139881799980800 logging_writer.py:48] [435300] global_step=435300, grad_norm=2.9643943309783936, loss=1.0860135555267334
I0304 21:20:47.588964 139881808373504 logging_writer.py:48] [435400] global_step=435400, grad_norm=4.10705041885376, loss=3.0359177589416504
I0304 21:21:31.824868 139881799980800 logging_writer.py:48] [435500] global_step=435500, grad_norm=3.318002700805664, loss=2.8536787033081055
I0304 21:22:11.253411 140077943854912 spec.py:321] Evaluating on the training split.
I0304 21:22:21.916510 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 21:22:51.630704 140077943854912 spec.py:349] Evaluating on the test split.
I0304 21:22:53.220737 140077943854912 submission_runner.py:411] Time since start: 209766.03s, 	Step: 435590, 	{'train/accuracy': 0.8875195384025574, 'train/loss': 0.41842925548553467, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 191606.79200792313, 'total_duration': 209766.02551412582, 'accumulated_submission_time': 191606.79200792313, 'accumulated_eval_time': 18103.057653665543, 'accumulated_logging_time': 33.505431175231934}
I0304 21:22:53.318791 139881808373504 logging_writer.py:48] [435590] accumulated_eval_time=18103.057654, accumulated_logging_time=33.505431, accumulated_submission_time=191606.792008, global_step=435590, preemption_count=0, score=191606.792008, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=209766.025514, train/accuracy=0.887520, train/loss=0.418429, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:22:57.640974 139881799980800 logging_writer.py:48] [435600] global_step=435600, grad_norm=2.9970622062683105, loss=1.0404577255249023
I0304 21:23:38.901760 139881808373504 logging_writer.py:48] [435700] global_step=435700, grad_norm=3.4023101329803467, loss=1.1898216009140015
I0304 21:24:23.422136 139881799980800 logging_writer.py:48] [435800] global_step=435800, grad_norm=3.3092548847198486, loss=2.5037922859191895
I0304 21:25:08.104196 139881808373504 logging_writer.py:48] [435900] global_step=435900, grad_norm=3.1036176681518555, loss=1.2939567565917969
I0304 21:25:52.274563 139881799980800 logging_writer.py:48] [436000] global_step=436000, grad_norm=3.045923948287964, loss=1.211430311203003
I0304 21:26:36.751809 139881808373504 logging_writer.py:48] [436100] global_step=436100, grad_norm=3.0730905532836914, loss=1.1086783409118652
I0304 21:27:21.107153 139881799980800 logging_writer.py:48] [436200] global_step=436200, grad_norm=3.412318706512451, loss=2.9436206817626953
I0304 21:28:05.402394 139881808373504 logging_writer.py:48] [436300] global_step=436300, grad_norm=3.7326269149780273, loss=1.209168553352356
I0304 21:28:49.487501 139881799980800 logging_writer.py:48] [436400] global_step=436400, grad_norm=3.972834825515747, loss=3.259470224380493
I0304 21:29:34.036017 139881808373504 logging_writer.py:48] [436500] global_step=436500, grad_norm=3.416531801223755, loss=1.6656394004821777
I0304 21:29:53.545058 140077943854912 spec.py:321] Evaluating on the training split.
I0304 21:30:03.820304 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 21:30:33.460553 140077943854912 spec.py:349] Evaluating on the test split.
I0304 21:30:35.048841 140077943854912 submission_runner.py:411] Time since start: 210227.85s, 	Step: 436546, 	{'train/accuracy': 0.8882812261581421, 'train/loss': 0.4159662425518036, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 192026.9568374157, 'total_duration': 210227.85384631157, 'accumulated_submission_time': 192026.9568374157, 'accumulated_eval_time': 18144.561408996582, 'accumulated_logging_time': 33.61554431915283}
I0304 21:30:35.149262 139881799980800 logging_writer.py:48] [436546] accumulated_eval_time=18144.561409, accumulated_logging_time=33.615544, accumulated_submission_time=192026.956837, global_step=436546, preemption_count=0, score=192026.956837, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=210227.853846, train/accuracy=0.888281, train/loss=0.415966, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:30:56.617957 139881808373504 logging_writer.py:48] [436600] global_step=436600, grad_norm=3.100830316543579, loss=1.1368921995162964
I0304 21:31:40.159931 139881799980800 logging_writer.py:48] [436700] global_step=436700, grad_norm=2.9177651405334473, loss=1.5717259645462036
I0304 21:32:24.635874 139881808373504 logging_writer.py:48] [436800] global_step=436800, grad_norm=3.9853968620300293, loss=3.320723056793213
I0304 21:33:08.910431 139881799980800 logging_writer.py:48] [436900] global_step=436900, grad_norm=3.6785802841186523, loss=2.7940726280212402
I0304 21:33:53.309409 139881808373504 logging_writer.py:48] [437000] global_step=437000, grad_norm=3.2035348415374756, loss=1.1466710567474365
I0304 21:34:37.852580 139881799980800 logging_writer.py:48] [437100] global_step=437100, grad_norm=3.3539514541625977, loss=1.2016361951828003
I0304 21:35:22.569875 139881808373504 logging_writer.py:48] [437200] global_step=437200, grad_norm=3.3122658729553223, loss=1.1125895977020264
I0304 21:36:07.076842 139881799980800 logging_writer.py:48] [437300] global_step=437300, grad_norm=3.353403329849243, loss=1.151705026626587
I0304 21:36:51.435700 139881808373504 logging_writer.py:48] [437400] global_step=437400, grad_norm=3.224348783493042, loss=1.8204915523529053
I0304 21:37:35.530403 140077943854912 spec.py:321] Evaluating on the training split.
I0304 21:37:45.909183 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 21:38:15.915877 140077943854912 spec.py:349] Evaluating on the test split.
I0304 21:38:17.527012 140077943854912 submission_runner.py:411] Time since start: 210690.33s, 	Step: 437500, 	{'train/accuracy': 0.8877148032188416, 'train/loss': 0.42000311613082886, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 192447.2765059471, 'total_duration': 210690.33194756508, 'accumulated_submission_time': 192447.2765059471, 'accumulated_eval_time': 18186.55794620514, 'accumulated_logging_time': 33.72833752632141}
I0304 21:38:17.675854 139881799980800 logging_writer.py:48] [437500] accumulated_eval_time=18186.557946, accumulated_logging_time=33.728338, accumulated_submission_time=192447.276506, global_step=437500, preemption_count=0, score=192447.276506, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=210690.331948, train/accuracy=0.887715, train/loss=0.420003, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:38:18.065666 139881808373504 logging_writer.py:48] [437500] global_step=437500, grad_norm=2.9877500534057617, loss=1.0928473472595215
I0304 21:38:57.931862 139881799980800 logging_writer.py:48] [437600] global_step=437600, grad_norm=2.996090888977051, loss=1.589010238647461
I0304 21:39:42.365992 139881808373504 logging_writer.py:48] [437700] global_step=437700, grad_norm=3.281128406524658, loss=1.6080882549285889
I0304 21:40:27.007204 139881799980800 logging_writer.py:48] [437800] global_step=437800, grad_norm=2.9014081954956055, loss=1.1435933113098145
I0304 21:41:11.781492 139881808373504 logging_writer.py:48] [437900] global_step=437900, grad_norm=2.9477334022521973, loss=1.7772623300552368
I0304 21:41:56.038941 139881799980800 logging_writer.py:48] [438000] global_step=438000, grad_norm=3.2276360988616943, loss=1.0779387950897217
I0304 21:42:40.435830 139881808373504 logging_writer.py:48] [438100] global_step=438100, grad_norm=3.033890724182129, loss=1.638718605041504
I0304 21:43:24.843872 139881799980800 logging_writer.py:48] [438200] global_step=438200, grad_norm=3.4309520721435547, loss=1.1386808156967163
I0304 21:44:09.375815 139881808373504 logging_writer.py:48] [438300] global_step=438300, grad_norm=3.5215861797332764, loss=3.229172945022583
I0304 21:44:53.780520 139881799980800 logging_writer.py:48] [438400] global_step=438400, grad_norm=2.8884003162384033, loss=1.0985008478164673
I0304 21:45:17.592444 140077943854912 spec.py:321] Evaluating on the training split.
I0304 21:45:27.830907 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 21:45:54.716022 140077943854912 spec.py:349] Evaluating on the test split.
I0304 21:45:56.304843 140077943854912 submission_runner.py:411] Time since start: 211149.11s, 	Step: 438455, 	{'train/accuracy': 0.88734370470047, 'train/loss': 0.41957610845565796, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 192867.13353562355, 'total_duration': 211149.10984754562, 'accumulated_submission_time': 192867.13353562355, 'accumulated_eval_time': 18225.270318984985, 'accumulated_logging_time': 33.887531042099}
I0304 21:45:56.406777 139881808373504 logging_writer.py:48] [438455] accumulated_eval_time=18225.270319, accumulated_logging_time=33.887531, accumulated_submission_time=192867.133536, global_step=438455, preemption_count=0, score=192867.133536, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=211149.109848, train/accuracy=0.887344, train/loss=0.419576, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:46:14.347802 139881799980800 logging_writer.py:48] [438500] global_step=438500, grad_norm=3.285522222518921, loss=1.5219452381134033
I0304 21:46:57.828514 139881808373504 logging_writer.py:48] [438600] global_step=438600, grad_norm=3.048999547958374, loss=1.3164232969284058
I0304 21:47:42.195667 139881799980800 logging_writer.py:48] [438700] global_step=438700, grad_norm=3.202709674835205, loss=1.7230048179626465
I0304 21:48:27.095671 139881808373504 logging_writer.py:48] [438800] global_step=438800, grad_norm=3.35347318649292, loss=1.8951464891433716
I0304 21:49:11.575819 139881799980800 logging_writer.py:48] [438900] global_step=438900, grad_norm=3.1426422595977783, loss=1.1898994445800781
I0304 21:49:55.938852 139881808373504 logging_writer.py:48] [439000] global_step=439000, grad_norm=3.4244015216827393, loss=2.8888497352600098
I0304 21:50:40.597863 139881799980800 logging_writer.py:48] [439100] global_step=439100, grad_norm=4.311281681060791, loss=3.0943756103515625
I0304 21:51:25.238600 139881808373504 logging_writer.py:48] [439200] global_step=439200, grad_norm=3.2676496505737305, loss=1.2856894731521606
I0304 21:52:09.531615 139881799980800 logging_writer.py:48] [439300] global_step=439300, grad_norm=3.0376484394073486, loss=1.1432592868804932
I0304 21:52:54.183589 139881808373504 logging_writer.py:48] [439400] global_step=439400, grad_norm=2.986217498779297, loss=1.1501868963241577
I0304 21:52:56.508429 140077943854912 spec.py:321] Evaluating on the training split.
I0304 21:53:07.302840 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 21:53:37.063190 140077943854912 spec.py:349] Evaluating on the test split.
I0304 21:53:38.644321 140077943854912 submission_runner.py:411] Time since start: 211611.45s, 	Step: 439407, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.4196644127368927, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 193287.17481279373, 'total_duration': 211611.44933223724, 'accumulated_submission_time': 193287.17481279373, 'accumulated_eval_time': 18267.40621161461, 'accumulated_logging_time': 34.00122618675232}
I0304 21:53:38.744263 139881799980800 logging_writer.py:48] [439407] accumulated_eval_time=18267.406212, accumulated_logging_time=34.001226, accumulated_submission_time=193287.174813, global_step=439407, preemption_count=0, score=193287.174813, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=211611.449332, train/accuracy=0.888320, train/loss=0.419664, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 21:54:17.055162 139881808373504 logging_writer.py:48] [439500] global_step=439500, grad_norm=3.0814383029937744, loss=1.1222643852233887
I0304 21:55:01.373125 139881799980800 logging_writer.py:48] [439600] global_step=439600, grad_norm=3.3846747875213623, loss=2.462873697280884
I0304 21:55:46.117894 139881808373504 logging_writer.py:48] [439700] global_step=439700, grad_norm=3.347444534301758, loss=2.6048805713653564
I0304 21:56:30.955842 139881799980800 logging_writer.py:48] [439800] global_step=439800, grad_norm=3.1074740886688232, loss=1.6792716979980469
I0304 21:57:15.654985 139881808373504 logging_writer.py:48] [439900] global_step=439900, grad_norm=2.9233882427215576, loss=1.7871681451797485
I0304 21:58:00.104836 139881799980800 logging_writer.py:48] [440000] global_step=440000, grad_norm=3.3621537685394287, loss=2.369220495223999
I0304 21:58:44.452944 139881808373504 logging_writer.py:48] [440100] global_step=440100, grad_norm=3.297419786453247, loss=1.1009210348129272
I0304 21:59:29.003988 139881799980800 logging_writer.py:48] [440200] global_step=440200, grad_norm=2.932835340499878, loss=1.1405545473098755
I0304 22:00:13.469197 139881808373504 logging_writer.py:48] [440300] global_step=440300, grad_norm=3.2568199634552, loss=1.0121976137161255
I0304 22:00:38.820558 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:00:49.087581 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:01:18.146506 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:01:19.749603 140077943854912 submission_runner.py:411] Time since start: 212072.55s, 	Step: 440359, 	{'train/accuracy': 0.88671875, 'train/loss': 0.4149238169193268, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 193707.19133090973, 'total_duration': 212072.5546195507, 'accumulated_submission_time': 193707.19133090973, 'accumulated_eval_time': 18308.33525133133, 'accumulated_logging_time': 34.112268686294556}
I0304 22:01:19.835897 139881799980800 logging_writer.py:48] [440359] accumulated_eval_time=18308.335251, accumulated_logging_time=34.112269, accumulated_submission_time=193707.191331, global_step=440359, preemption_count=0, score=193707.191331, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=212072.554620, train/accuracy=0.886719, train/loss=0.414924, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:01:36.204891 139881808373504 logging_writer.py:48] [440400] global_step=440400, grad_norm=3.2019662857055664, loss=1.1815545558929443
I0304 22:02:17.978346 139881799980800 logging_writer.py:48] [440500] global_step=440500, grad_norm=5.473432540893555, loss=1.1046818494796753
I0304 22:03:02.392100 139881808373504 logging_writer.py:48] [440600] global_step=440600, grad_norm=3.336608648300171, loss=2.3190431594848633
I0304 22:03:46.667210 139881799980800 logging_writer.py:48] [440700] global_step=440700, grad_norm=3.10772967338562, loss=2.732489585876465
I0304 22:04:30.966773 139881808373504 logging_writer.py:48] [440800] global_step=440800, grad_norm=2.9352002143859863, loss=2.143627166748047
I0304 22:05:15.277406 139881799980800 logging_writer.py:48] [440900] global_step=440900, grad_norm=3.0811784267425537, loss=2.1261167526245117
I0304 22:05:59.364404 139881808373504 logging_writer.py:48] [441000] global_step=441000, grad_norm=3.1774585247039795, loss=1.0713530778884888
I0304 22:06:44.071226 139881799980800 logging_writer.py:48] [441100] global_step=441100, grad_norm=3.2178163528442383, loss=1.1470333337783813
I0304 22:07:28.465732 139881808373504 logging_writer.py:48] [441200] global_step=441200, grad_norm=2.8794569969177246, loss=1.0778268575668335
I0304 22:08:12.723734 139881799980800 logging_writer.py:48] [441300] global_step=441300, grad_norm=3.2046751976013184, loss=1.558794379234314
I0304 22:08:19.865422 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:08:30.212189 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:09:04.687209 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:09:06.271634 140077943854912 submission_runner.py:411] Time since start: 212539.08s, 	Step: 441318, 	{'train/accuracy': 0.8875781297683716, 'train/loss': 0.41811370849609375, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 194127.15976166725, 'total_duration': 212539.07664871216, 'accumulated_submission_time': 194127.15976166725, 'accumulated_eval_time': 18354.741428136826, 'accumulated_logging_time': 34.21055889129639}
I0304 22:09:06.354288 139881808373504 logging_writer.py:48] [441318] accumulated_eval_time=18354.741428, accumulated_logging_time=34.210559, accumulated_submission_time=194127.159762, global_step=441318, preemption_count=0, score=194127.159762, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=212539.076649, train/accuracy=0.887578, train/loss=0.418114, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:09:38.743072 139881799980800 logging_writer.py:48] [441400] global_step=441400, grad_norm=2.924609899520874, loss=1.004525899887085
I0304 22:10:22.935464 139881808373504 logging_writer.py:48] [441500] global_step=441500, grad_norm=2.96095871925354, loss=1.2304024696350098
I0304 22:11:07.358046 139881799980800 logging_writer.py:48] [441600] global_step=441600, grad_norm=2.9850218296051025, loss=1.136983036994934
I0304 22:11:52.317439 139881808373504 logging_writer.py:48] [441700] global_step=441700, grad_norm=3.0921192169189453, loss=1.531241536140442
I0304 22:12:36.843782 139881799980800 logging_writer.py:48] [441800] global_step=441800, grad_norm=3.01949405670166, loss=1.183876395225525
I0304 22:13:21.240267 139881808373504 logging_writer.py:48] [441900] global_step=441900, grad_norm=3.218376398086548, loss=1.0770810842514038
I0304 22:14:05.569944 139881799980800 logging_writer.py:48] [442000] global_step=442000, grad_norm=2.9979710578918457, loss=1.1833453178405762
I0304 22:14:50.103009 139881808373504 logging_writer.py:48] [442100] global_step=442100, grad_norm=3.4654579162597656, loss=1.105555534362793
I0304 22:15:34.686799 139881799980800 logging_writer.py:48] [442200] global_step=442200, grad_norm=2.9608757495880127, loss=1.6821657419204712
I0304 22:16:06.406347 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:16:16.703655 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:16:49.852596 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:16:51.436909 140077943854912 submission_runner.py:411] Time since start: 213004.24s, 	Step: 442273, 	{'train/accuracy': 0.8886913657188416, 'train/loss': 0.4170783460140228, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 194547.15191221237, 'total_duration': 213004.2418987751, 'accumulated_submission_time': 194547.15191221237, 'accumulated_eval_time': 18399.771948337555, 'accumulated_logging_time': 34.30404305458069}
I0304 22:16:51.534390 139881808373504 logging_writer.py:48] [442273] accumulated_eval_time=18399.771948, accumulated_logging_time=34.304043, accumulated_submission_time=194547.151912, global_step=442273, preemption_count=0, score=194547.151912, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=213004.241899, train/accuracy=0.888691, train/loss=0.417078, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:17:02.450623 139881799980800 logging_writer.py:48] [442300] global_step=442300, grad_norm=3.212118148803711, loss=0.986751139163971
I0304 22:17:43.925725 139881808373504 logging_writer.py:48] [442400] global_step=442400, grad_norm=3.2973482608795166, loss=1.2482097148895264
I0304 22:18:28.300534 139881799980800 logging_writer.py:48] [442500] global_step=442500, grad_norm=3.249943494796753, loss=1.750103235244751
I0304 22:19:13.192813 139881808373504 logging_writer.py:48] [442600] global_step=442600, grad_norm=3.220770835876465, loss=1.1760624647140503
I0304 22:19:57.603164 139881799980800 logging_writer.py:48] [442700] global_step=442700, grad_norm=3.24381947517395, loss=1.1408770084381104
I0304 22:20:42.057542 139881808373504 logging_writer.py:48] [442800] global_step=442800, grad_norm=3.114208698272705, loss=1.0495078563690186
I0304 22:21:26.983549 139881799980800 logging_writer.py:48] [442900] global_step=442900, grad_norm=4.071872711181641, loss=3.2595553398132324
I0304 22:22:11.376798 139881808373504 logging_writer.py:48] [443000] global_step=443000, grad_norm=3.383288621902466, loss=1.0982178449630737
I0304 22:22:55.923508 139881799980800 logging_writer.py:48] [443100] global_step=443100, grad_norm=3.108651876449585, loss=1.1982786655426025
I0304 22:23:40.680535 139881808373504 logging_writer.py:48] [443200] global_step=443200, grad_norm=3.3528363704681396, loss=1.2217925786972046
I0304 22:23:51.796760 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:24:02.232723 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:24:30.235057 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:24:31.828134 140077943854912 submission_runner.py:411] Time since start: 213464.63s, 	Step: 443227, 	{'train/accuracy': 0.8878515362739563, 'train/loss': 0.4187040328979492, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 194967.35440659523, 'total_duration': 213464.63312387466, 'accumulated_submission_time': 194967.35440659523, 'accumulated_eval_time': 18439.803258419037, 'accumulated_logging_time': 34.411983013153076}
I0304 22:24:31.925264 139881799980800 logging_writer.py:48] [443227] accumulated_eval_time=18439.803258, accumulated_logging_time=34.411983, accumulated_submission_time=194967.354407, global_step=443227, preemption_count=0, score=194967.354407, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=213464.633124, train/accuracy=0.887852, train/loss=0.418704, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:25:01.574304 139881808373504 logging_writer.py:48] [443300] global_step=443300, grad_norm=4.057602405548096, loss=3.193028688430786
I0304 22:25:46.318406 139881799980800 logging_writer.py:48] [443400] global_step=443400, grad_norm=3.033322811126709, loss=1.0768835544586182
I0304 22:26:31.076552 139881808373504 logging_writer.py:48] [443500] global_step=443500, grad_norm=2.6941475868225098, loss=1.8455309867858887
I0304 22:27:16.028156 139881799980800 logging_writer.py:48] [443600] global_step=443600, grad_norm=2.8306772708892822, loss=1.7584328651428223
I0304 22:28:01.075596 139881808373504 logging_writer.py:48] [443700] global_step=443700, grad_norm=3.353541374206543, loss=1.2980711460113525
I0304 22:28:46.059606 139881799980800 logging_writer.py:48] [443800] global_step=443800, grad_norm=3.068875789642334, loss=1.280677318572998
I0304 22:29:31.114920 139881808373504 logging_writer.py:48] [443900] global_step=443900, grad_norm=3.1173770427703857, loss=1.1198172569274902
I0304 22:30:16.026971 139881799980800 logging_writer.py:48] [444000] global_step=444000, grad_norm=3.4691972732543945, loss=2.758213996887207
I0304 22:31:00.968767 139881808373504 logging_writer.py:48] [444100] global_step=444100, grad_norm=2.9987435340881348, loss=1.8163633346557617
I0304 22:31:31.928506 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:31:42.127968 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:32:17.110436 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:32:18.716076 140077943854912 submission_runner.py:411] Time since start: 213931.52s, 	Step: 444170, 	{'train/accuracy': 0.8865429759025574, 'train/loss': 0.42362675070762634, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 195387.2975564003, 'total_duration': 213931.52109360695, 'accumulated_submission_time': 195387.2975564003, 'accumulated_eval_time': 18486.59080529213, 'accumulated_logging_time': 34.52042746543884}
I0304 22:32:18.799550 139881799980800 logging_writer.py:48] [444170] accumulated_eval_time=18486.590805, accumulated_logging_time=34.520427, accumulated_submission_time=195387.297556, global_step=444170, preemption_count=0, score=195387.297556, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=213931.521094, train/accuracy=0.886543, train/loss=0.423627, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:32:30.888111 139881808373504 logging_writer.py:48] [444200] global_step=444200, grad_norm=3.2294201850891113, loss=1.1416523456573486
I0304 22:33:12.638841 139881799980800 logging_writer.py:48] [444300] global_step=444300, grad_norm=3.3870043754577637, loss=1.220508098602295
I0304 22:33:56.952925 139881808373504 logging_writer.py:48] [444400] global_step=444400, grad_norm=3.181643009185791, loss=1.2089776992797852
I0304 22:34:41.676681 139881799980800 logging_writer.py:48] [444500] global_step=444500, grad_norm=3.0943071842193604, loss=1.0385874509811401
I0304 22:35:25.945362 139881808373504 logging_writer.py:48] [444600] global_step=444600, grad_norm=3.0517494678497314, loss=2.0216660499572754
I0304 22:36:10.456203 139881799980800 logging_writer.py:48] [444700] global_step=444700, grad_norm=3.3674263954162598, loss=2.7225112915039062
I0304 22:36:54.939456 139881808373504 logging_writer.py:48] [444800] global_step=444800, grad_norm=2.973557949066162, loss=1.137203335762024
I0304 22:37:39.503434 139881799980800 logging_writer.py:48] [444900] global_step=444900, grad_norm=3.3476548194885254, loss=1.1371076107025146
I0304 22:38:23.721832 139881808373504 logging_writer.py:48] [445000] global_step=445000, grad_norm=2.979409694671631, loss=2.1816186904907227
I0304 22:39:08.232931 139881799980800 logging_writer.py:48] [445100] global_step=445100, grad_norm=3.006272792816162, loss=1.1201061010360718
I0304 22:39:18.967417 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:39:29.161286 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:39:58.184247 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:39:59.769594 140077943854912 submission_runner.py:411] Time since start: 214392.57s, 	Step: 445126, 	{'train/accuracy': 0.8879492282867432, 'train/loss': 0.4153803884983063, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 195807.40478396416, 'total_duration': 214392.57460045815, 'accumulated_submission_time': 195807.40478396416, 'accumulated_eval_time': 18527.39293718338, 'accumulated_logging_time': 34.61554837226868}
I0304 22:39:59.873308 139881808373504 logging_writer.py:48] [445126] accumulated_eval_time=18527.392937, accumulated_logging_time=34.615548, accumulated_submission_time=195807.404784, global_step=445126, preemption_count=0, score=195807.404784, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=214392.574600, train/accuracy=0.887949, train/loss=0.415380, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:40:29.865380 139881799980800 logging_writer.py:48] [445200] global_step=445200, grad_norm=3.1405680179595947, loss=2.758185386657715
I0304 22:41:14.301498 139881808373504 logging_writer.py:48] [445300] global_step=445300, grad_norm=3.6691458225250244, loss=2.9355714321136475
I0304 22:41:59.043895 139881799980800 logging_writer.py:48] [445400] global_step=445400, grad_norm=2.9550318717956543, loss=1.119788646697998
I0304 22:42:43.717805 139881808373504 logging_writer.py:48] [445500] global_step=445500, grad_norm=3.168858051300049, loss=1.038000464439392
I0304 22:43:28.211141 139881799980800 logging_writer.py:48] [445600] global_step=445600, grad_norm=3.0347187519073486, loss=1.5840035676956177
I0304 22:44:13.030913 139881808373504 logging_writer.py:48] [445700] global_step=445700, grad_norm=3.1869888305664062, loss=1.1163464784622192
I0304 22:44:57.538673 139881799980800 logging_writer.py:48] [445800] global_step=445800, grad_norm=2.974499464035034, loss=1.2723872661590576
I0304 22:45:42.670402 139881808373504 logging_writer.py:48] [445900] global_step=445900, grad_norm=3.5572426319122314, loss=1.056145191192627
I0304 22:46:27.408941 139881799980800 logging_writer.py:48] [446000] global_step=446000, grad_norm=3.172727108001709, loss=1.3531938791275024
I0304 22:46:59.770682 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:47:10.170492 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:47:41.176038 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:47:42.763138 140077943854912 submission_runner.py:411] Time since start: 214855.57s, 	Step: 446075, 	{'train/accuracy': 0.8886132836341858, 'train/loss': 0.41350340843200684, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 196227.24235582352, 'total_duration': 214855.56814837456, 'accumulated_submission_time': 196227.24235582352, 'accumulated_eval_time': 18570.385375261307, 'accumulated_logging_time': 34.730725049972534}
I0304 22:47:42.874244 139881808373504 logging_writer.py:48] [446075] accumulated_eval_time=18570.385375, accumulated_logging_time=34.730725, accumulated_submission_time=196227.242356, global_step=446075, preemption_count=0, score=196227.242356, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=214855.568148, train/accuracy=0.888613, train/loss=0.413503, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:47:53.005127 139881799980800 logging_writer.py:48] [446100] global_step=446100, grad_norm=3.228878974914551, loss=1.225471019744873
I0304 22:48:36.331792 139881808373504 logging_writer.py:48] [446200] global_step=446200, grad_norm=3.198833703994751, loss=2.594311475753784
I0304 22:49:21.737437 139881799980800 logging_writer.py:48] [446300] global_step=446300, grad_norm=3.478461503982544, loss=1.2180322408676147
I0304 22:50:07.112593 139881808373504 logging_writer.py:48] [446400] global_step=446400, grad_norm=3.159822702407837, loss=1.5192148685455322
I0304 22:50:52.383727 139881799980800 logging_writer.py:48] [446500] global_step=446500, grad_norm=2.824276924133301, loss=1.4600839614868164
I0304 22:51:37.817637 139881808373504 logging_writer.py:48] [446600] global_step=446600, grad_norm=3.0373239517211914, loss=1.1690701246261597
I0304 22:52:23.721725 139881799980800 logging_writer.py:48] [446700] global_step=446700, grad_norm=2.8346736431121826, loss=1.358016014099121
I0304 22:53:09.178193 139881808373504 logging_writer.py:48] [446800] global_step=446800, grad_norm=2.9975125789642334, loss=1.2310980558395386
I0304 22:53:54.756131 139881799980800 logging_writer.py:48] [446900] global_step=446900, grad_norm=3.4589836597442627, loss=1.1708518266677856
I0304 22:54:40.307678 139881808373504 logging_writer.py:48] [447000] global_step=447000, grad_norm=3.246182918548584, loss=1.198700189590454
I0304 22:54:43.152122 140077943854912 spec.py:321] Evaluating on the training split.
I0304 22:54:53.476484 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 22:55:27.332703 140077943854912 spec.py:349] Evaluating on the test split.
I0304 22:55:28.921409 140077943854912 submission_runner.py:411] Time since start: 215321.73s, 	Step: 447008, 	{'train/accuracy': 0.8878905773162842, 'train/loss': 0.4189607799053192, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 196647.45865631104, 'total_duration': 215321.72642993927, 'accumulated_submission_time': 196647.45865631104, 'accumulated_eval_time': 18616.154643535614, 'accumulated_logging_time': 34.85476279258728}
I0304 22:55:29.004162 139881799980800 logging_writer.py:48] [447008] accumulated_eval_time=18616.154644, accumulated_logging_time=34.854763, accumulated_submission_time=196647.458656, global_step=447008, preemption_count=0, score=196647.458656, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=215321.726430, train/accuracy=0.887891, train/loss=0.418961, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 22:56:06.090295 139881808373504 logging_writer.py:48] [447100] global_step=447100, grad_norm=2.9648077487945557, loss=1.1456668376922607
I0304 22:56:50.221423 139881799980800 logging_writer.py:48] [447200] global_step=447200, grad_norm=3.557976484298706, loss=3.053683042526245
I0304 22:57:34.980739 139881808373504 logging_writer.py:48] [447300] global_step=447300, grad_norm=3.2399721145629883, loss=2.487795352935791
I0304 22:58:19.530460 139881799980800 logging_writer.py:48] [447400] global_step=447400, grad_norm=3.1289985179901123, loss=1.1350518465042114
I0304 22:59:04.114347 139881808373504 logging_writer.py:48] [447500] global_step=447500, grad_norm=3.8612711429595947, loss=3.225935935974121
I0304 22:59:48.544811 139881799980800 logging_writer.py:48] [447600] global_step=447600, grad_norm=2.979917526245117, loss=1.09600031375885
I0304 23:00:33.325753 139881808373504 logging_writer.py:48] [447700] global_step=447700, grad_norm=3.2178738117218018, loss=1.158310890197754
I0304 23:01:17.592694 139881799980800 logging_writer.py:48] [447800] global_step=447800, grad_norm=3.6262454986572266, loss=3.214461088180542
I0304 23:02:02.171013 139881808373504 logging_writer.py:48] [447900] global_step=447900, grad_norm=3.5282986164093018, loss=3.03332257270813
I0304 23:02:28.961200 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:02:39.180941 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:03:07.887986 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:03:09.472960 140077943854912 submission_runner.py:411] Time since start: 215782.28s, 	Step: 447962, 	{'train/accuracy': 0.8869726657867432, 'train/loss': 0.4157951772212982, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 197067.3557920456, 'total_duration': 215782.27796936035, 'accumulated_submission_time': 197067.3557920456, 'accumulated_eval_time': 18656.66638660431, 'accumulated_logging_time': 34.947226762771606}
I0304 23:03:09.575256 139881799980800 logging_writer.py:48] [447962] accumulated_eval_time=18656.666387, accumulated_logging_time=34.947227, accumulated_submission_time=197067.355792, global_step=447962, preemption_count=0, score=197067.355792, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=215782.277969, train/accuracy=0.886973, train/loss=0.415795, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:03:24.795947 139881808373504 logging_writer.py:48] [448000] global_step=448000, grad_norm=3.260962963104248, loss=1.0289554595947266
I0304 23:04:08.314519 139881799980800 logging_writer.py:48] [448100] global_step=448100, grad_norm=3.1916496753692627, loss=1.077636480331421
I0304 23:04:52.764338 139881808373504 logging_writer.py:48] [448200] global_step=448200, grad_norm=3.2798914909362793, loss=1.5195993185043335
I0304 23:05:37.546435 139881799980800 logging_writer.py:48] [448300] global_step=448300, grad_norm=3.4696457386016846, loss=1.1243947744369507
I0304 23:06:22.392131 139881808373504 logging_writer.py:48] [448400] global_step=448400, grad_norm=3.561310052871704, loss=1.1145213842391968
I0304 23:07:06.843401 139881799980800 logging_writer.py:48] [448500] global_step=448500, grad_norm=3.8293914794921875, loss=1.5540372133255005
I0304 23:07:51.582604 139881808373504 logging_writer.py:48] [448600] global_step=448600, grad_norm=2.9590182304382324, loss=1.148698091506958
I0304 23:08:36.167833 139881799980800 logging_writer.py:48] [448700] global_step=448700, grad_norm=3.180260419845581, loss=1.217180848121643
I0304 23:09:20.872365 139881808373504 logging_writer.py:48] [448800] global_step=448800, grad_norm=3.0147552490234375, loss=1.0700650215148926
I0304 23:10:05.773501 139881799980800 logging_writer.py:48] [448900] global_step=448900, grad_norm=2.9197373390197754, loss=1.0786815881729126
I0304 23:10:09.932617 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:10:20.544002 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:10:57.875066 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:10:59.463260 140077943854912 submission_runner.py:411] Time since start: 216252.27s, 	Step: 448911, 	{'train/accuracy': 0.8879492282867432, 'train/loss': 0.4203372597694397, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 197487.6512079239, 'total_duration': 216252.2682375908, 'accumulated_submission_time': 197487.6512079239, 'accumulated_eval_time': 18706.196996450424, 'accumulated_logging_time': 35.063289403915405}
I0304 23:10:59.547959 139881808373504 logging_writer.py:48] [448911] accumulated_eval_time=18706.196996, accumulated_logging_time=35.063289, accumulated_submission_time=197487.651208, global_step=448911, preemption_count=0, score=197487.651208, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=216252.268238, train/accuracy=0.887949, train/loss=0.420337, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:11:35.076799 139881799980800 logging_writer.py:48] [449000] global_step=449000, grad_norm=3.153660774230957, loss=1.3400521278381348
I0304 23:12:19.319725 139881808373504 logging_writer.py:48] [449100] global_step=449100, grad_norm=3.622925043106079, loss=3.158919334411621
I0304 23:13:04.028348 139881799980800 logging_writer.py:48] [449200] global_step=449200, grad_norm=3.1398603916168213, loss=2.234217405319214
I0304 23:13:48.637613 139881808373504 logging_writer.py:48] [449300] global_step=449300, grad_norm=3.5116047859191895, loss=3.0103259086608887
I0304 23:14:33.560783 139881799980800 logging_writer.py:48] [449400] global_step=449400, grad_norm=3.4773058891296387, loss=3.254720449447632
I0304 23:15:18.190688 139881808373504 logging_writer.py:48] [449500] global_step=449500, grad_norm=2.9361677169799805, loss=2.1129276752471924
I0304 23:16:02.819463 139881799980800 logging_writer.py:48] [449600] global_step=449600, grad_norm=3.13207745552063, loss=1.1893969774246216
I0304 23:16:47.237640 139881808373504 logging_writer.py:48] [449700] global_step=449700, grad_norm=3.314319133758545, loss=1.3438775539398193
I0304 23:17:31.571772 139881799980800 logging_writer.py:48] [449800] global_step=449800, grad_norm=3.1320247650146484, loss=1.1645861864089966
I0304 23:17:59.516955 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:18:09.991115 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:18:45.471662 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:18:47.052122 140077943854912 submission_runner.py:411] Time since start: 216719.86s, 	Step: 449865, 	{'train/accuracy': 0.8902929425239563, 'train/loss': 0.41343775391578674, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 197907.5611524582, 'total_duration': 216719.85712742805, 'accumulated_submission_time': 197907.5611524582, 'accumulated_eval_time': 18753.732135295868, 'accumulated_logging_time': 35.15776562690735}
I0304 23:18:47.156862 139881808373504 logging_writer.py:48] [449865] accumulated_eval_time=18753.732135, accumulated_logging_time=35.157766, accumulated_submission_time=197907.561152, global_step=449865, preemption_count=0, score=197907.561152, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=216719.857127, train/accuracy=0.890293, train/loss=0.413438, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:19:01.193717 139881799980800 logging_writer.py:48] [449900] global_step=449900, grad_norm=3.2000584602355957, loss=1.2714910507202148
I0304 23:19:43.421632 139881808373504 logging_writer.py:48] [450000] global_step=450000, grad_norm=2.8824095726013184, loss=1.2607481479644775
I0304 23:20:27.929409 139881799980800 logging_writer.py:48] [450100] global_step=450100, grad_norm=3.1283702850341797, loss=1.1193101406097412
I0304 23:21:12.901816 139881808373504 logging_writer.py:48] [450200] global_step=450200, grad_norm=3.162799119949341, loss=1.0888748168945312
I0304 23:21:57.252331 139881799980800 logging_writer.py:48] [450300] global_step=450300, grad_norm=3.087536573410034, loss=1.5279312133789062
I0304 23:22:41.838098 139881808373504 logging_writer.py:48] [450400] global_step=450400, grad_norm=3.2566354274749756, loss=1.1836696863174438
I0304 23:23:26.238078 139881799980800 logging_writer.py:48] [450500] global_step=450500, grad_norm=3.19514799118042, loss=1.1378843784332275
I0304 23:24:10.810796 139881808373504 logging_writer.py:48] [450600] global_step=450600, grad_norm=3.4509077072143555, loss=2.9793741703033447
I0304 23:24:55.225822 139881799980800 logging_writer.py:48] [450700] global_step=450700, grad_norm=3.645949125289917, loss=3.2629218101501465
I0304 23:25:39.827975 139881808373504 logging_writer.py:48] [450800] global_step=450800, grad_norm=3.1819121837615967, loss=1.2426930665969849
I0304 23:25:47.443471 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:25:57.767487 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:26:35.158653 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:26:36.730149 140077943854912 submission_runner.py:411] Time since start: 217189.54s, 	Step: 450819, 	{'train/accuracy': 0.8892773389816284, 'train/loss': 0.41411325335502625, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 198327.78745818138, 'total_duration': 217189.53516674042, 'accumulated_submission_time': 198327.78745818138, 'accumulated_eval_time': 18803.01878094673, 'accumulated_logging_time': 35.27369546890259}
I0304 23:26:36.813791 139881799980800 logging_writer.py:48] [450819] accumulated_eval_time=18803.018781, accumulated_logging_time=35.273695, accumulated_submission_time=198327.787458, global_step=450819, preemption_count=0, score=198327.787458, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=217189.535167, train/accuracy=0.889277, train/loss=0.414113, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:27:09.401372 139881808373504 logging_writer.py:48] [450900] global_step=450900, grad_norm=3.123626947402954, loss=1.3553922176361084
I0304 23:27:53.866261 139881799980800 logging_writer.py:48] [451000] global_step=451000, grad_norm=2.8267171382904053, loss=1.0973966121673584
I0304 23:28:38.541206 139881808373504 logging_writer.py:48] [451100] global_step=451100, grad_norm=2.9861152172088623, loss=1.2743598222732544
I0304 23:29:23.277203 139881799980800 logging_writer.py:48] [451200] global_step=451200, grad_norm=3.0430145263671875, loss=2.2837438583374023
I0304 23:30:07.873852 139881808373504 logging_writer.py:48] [451300] global_step=451300, grad_norm=3.8192906379699707, loss=3.057035446166992
I0304 23:30:52.253165 139881799980800 logging_writer.py:48] [451400] global_step=451400, grad_norm=3.015846014022827, loss=1.0918896198272705
I0304 23:31:36.918175 139881808373504 logging_writer.py:48] [451500] global_step=451500, grad_norm=3.3881218433380127, loss=1.1008388996124268
I0304 23:32:21.711094 139881799980800 logging_writer.py:48] [451600] global_step=451600, grad_norm=2.971722364425659, loss=1.6662468910217285
I0304 23:33:06.259431 139881808373504 logging_writer.py:48] [451700] global_step=451700, grad_norm=3.129964590072632, loss=1.1678111553192139
I0304 23:33:37.015290 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:33:47.430427 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:34:16.256450 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:34:17.861409 140077943854912 submission_runner.py:411] Time since start: 217650.67s, 	Step: 451771, 	{'train/accuracy': 0.8887499570846558, 'train/loss': 0.4107620418071747, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 198747.93030524254, 'total_duration': 217650.66642785072, 'accumulated_submission_time': 198747.93030524254, 'accumulated_eval_time': 18843.864889621735, 'accumulated_logging_time': 35.36725568771362}
I0304 23:34:17.946003 139881799980800 logging_writer.py:48] [451771] accumulated_eval_time=18843.864890, accumulated_logging_time=35.367256, accumulated_submission_time=198747.930305, global_step=451771, preemption_count=0, score=198747.930305, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=217650.666428, train/accuracy=0.888750, train/loss=0.410762, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:34:29.646635 139881808373504 logging_writer.py:48] [451800] global_step=451800, grad_norm=2.9062440395355225, loss=1.6113672256469727
I0304 23:35:11.598554 139881799980800 logging_writer.py:48] [451900] global_step=451900, grad_norm=3.8775839805603027, loss=3.3315958976745605
I0304 23:35:56.007860 139881808373504 logging_writer.py:48] [452000] global_step=452000, grad_norm=3.099149465560913, loss=2.037432909011841
I0304 23:36:40.761522 139881799980800 logging_writer.py:48] [452100] global_step=452100, grad_norm=3.143681764602661, loss=2.148003578186035
I0304 23:37:25.147423 139881808373504 logging_writer.py:48] [452200] global_step=452200, grad_norm=4.109046936035156, loss=3.1709389686584473
I0304 23:38:09.618143 139881799980800 logging_writer.py:48] [452300] global_step=452300, grad_norm=3.1071393489837646, loss=1.4914411306381226
I0304 23:38:53.672052 139881808373504 logging_writer.py:48] [452400] global_step=452400, grad_norm=2.935056209564209, loss=1.040271282196045
I0304 23:39:38.146825 139881799980800 logging_writer.py:48] [452500] global_step=452500, grad_norm=3.2423675060272217, loss=2.8983678817749023
I0304 23:40:22.881078 139881808373504 logging_writer.py:48] [452600] global_step=452600, grad_norm=3.919968605041504, loss=3.3096909523010254
I0304 23:41:07.180549 139881799980800 logging_writer.py:48] [452700] global_step=452700, grad_norm=4.971704006195068, loss=1.1702512502670288
I0304 23:41:18.134591 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:41:29.232338 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:41:55.631839 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:41:57.215941 140077943854912 submission_runner.py:411] Time since start: 218110.02s, 	Step: 452726, 	{'train/accuracy': 0.8876367211341858, 'train/loss': 0.41827714443206787, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 199168.05628609657, 'total_duration': 218110.0209414959, 'accumulated_submission_time': 199168.05628609657, 'accumulated_eval_time': 18882.94619178772, 'accumulated_logging_time': 35.465445041656494}
I0304 23:41:57.319683 139881808373504 logging_writer.py:48] [452726] accumulated_eval_time=18882.946192, accumulated_logging_time=35.465445, accumulated_submission_time=199168.056286, global_step=452726, preemption_count=0, score=199168.056286, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=218110.020941, train/accuracy=0.887637, train/loss=0.418277, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:42:27.785736 139881799980800 logging_writer.py:48] [452800] global_step=452800, grad_norm=3.073702573776245, loss=1.7301902770996094
I0304 23:43:13.158663 139881808373504 logging_writer.py:48] [452900] global_step=452900, grad_norm=3.8676416873931885, loss=3.2586209774017334
I0304 23:43:57.794770 139881799980800 logging_writer.py:48] [453000] global_step=453000, grad_norm=3.0266735553741455, loss=1.1663283109664917
I0304 23:44:42.691266 139881808373504 logging_writer.py:48] [453100] global_step=453100, grad_norm=3.872258424758911, loss=3.2470543384552
I0304 23:45:27.992547 139881799980800 logging_writer.py:48] [453200] global_step=453200, grad_norm=3.317378282546997, loss=2.686530828475952
I0304 23:46:13.006235 139881808373504 logging_writer.py:48] [453300] global_step=453300, grad_norm=2.9252750873565674, loss=1.0063344240188599
I0304 23:46:57.875865 139881799980800 logging_writer.py:48] [453400] global_step=453400, grad_norm=3.520078182220459, loss=3.04669451713562
I0304 23:47:42.950660 139881808373504 logging_writer.py:48] [453500] global_step=453500, grad_norm=3.4873878955841064, loss=1.163818359375
I0304 23:48:28.018370 139881799980800 logging_writer.py:48] [453600] global_step=453600, grad_norm=3.5954666137695312, loss=1.0557658672332764
I0304 23:48:57.500753 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:49:08.284111 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:49:37.452044 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:49:39.044412 140077943854912 submission_runner.py:411] Time since start: 218571.85s, 	Step: 453667, 	{'train/accuracy': 0.8885546922683716, 'train/loss': 0.41385671496391296, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 199588.17515659332, 'total_duration': 218571.84941196442, 'accumulated_submission_time': 199588.17515659332, 'accumulated_eval_time': 18924.489815711975, 'accumulated_logging_time': 35.583218812942505}
I0304 23:49:39.143586 139881808373504 logging_writer.py:48] [453667] accumulated_eval_time=18924.489816, accumulated_logging_time=35.583219, accumulated_submission_time=199588.175157, global_step=453667, preemption_count=0, score=199588.175157, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=218571.849412, train/accuracy=0.888555, train/loss=0.413857, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:49:52.419670 139881799980800 logging_writer.py:48] [453700] global_step=453700, grad_norm=3.1960086822509766, loss=2.6337990760803223
I0304 23:50:35.821911 139881808373504 logging_writer.py:48] [453800] global_step=453800, grad_norm=3.1145498752593994, loss=1.4814701080322266
I0304 23:51:20.802335 139881799980800 logging_writer.py:48] [453900] global_step=453900, grad_norm=3.0227444171905518, loss=1.0671511888504028
I0304 23:52:06.150427 139881808373504 logging_writer.py:48] [454000] global_step=454000, grad_norm=3.3914031982421875, loss=3.061103343963623
I0304 23:52:51.028393 139881799980800 logging_writer.py:48] [454100] global_step=454100, grad_norm=2.927804946899414, loss=1.1450086832046509
I0304 23:53:36.570026 139881808373504 logging_writer.py:48] [454200] global_step=454200, grad_norm=3.00773024559021, loss=1.1657395362854004
I0304 23:54:21.560730 139881799980800 logging_writer.py:48] [454300] global_step=454300, grad_norm=3.214165210723877, loss=1.378146767616272
I0304 23:55:06.462816 139881808373504 logging_writer.py:48] [454400] global_step=454400, grad_norm=3.4101011753082275, loss=1.1491631269454956
I0304 23:55:51.532338 139881799980800 logging_writer.py:48] [454500] global_step=454500, grad_norm=2.817007064819336, loss=1.157683253288269
I0304 23:56:36.572351 139881808373504 logging_writer.py:48] [454600] global_step=454600, grad_norm=2.7684593200683594, loss=1.056073546409607
I0304 23:56:39.414702 140077943854912 spec.py:321] Evaluating on the training split.
I0304 23:56:49.669739 140077943854912 spec.py:333] Evaluating on the validation split.
I0304 23:57:27.973773 140077943854912 spec.py:349] Evaluating on the test split.
I0304 23:57:29.554903 140077943854912 submission_runner.py:411] Time since start: 219042.36s, 	Step: 454608, 	{'train/accuracy': 0.88636714220047, 'train/loss': 0.41708463430404663, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 200008.38172197342, 'total_duration': 219042.35991621017, 'accumulated_submission_time': 200008.38172197342, 'accumulated_eval_time': 18974.629987239838, 'accumulated_logging_time': 35.69882941246033}
I0304 23:57:29.638285 139881799980800 logging_writer.py:48] [454608] accumulated_eval_time=18974.629987, accumulated_logging_time=35.698829, accumulated_submission_time=200008.381722, global_step=454608, preemption_count=0, score=200008.381722, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=219042.359916, train/accuracy=0.886367, train/loss=0.417085, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0304 23:58:06.391226 139881808373504 logging_writer.py:48] [454700] global_step=454700, grad_norm=3.573244333267212, loss=3.0359740257263184
I0304 23:58:50.558764 139881799980800 logging_writer.py:48] [454800] global_step=454800, grad_norm=3.2916369438171387, loss=2.6442980766296387
I0304 23:59:35.291198 139881808373504 logging_writer.py:48] [454900] global_step=454900, grad_norm=3.0964508056640625, loss=1.2073349952697754
I0305 00:00:19.526516 139881799980800 logging_writer.py:48] [455000] global_step=455000, grad_norm=3.189201831817627, loss=2.3618969917297363
I0305 00:01:04.512940 139881808373504 logging_writer.py:48] [455100] global_step=455100, grad_norm=3.211599588394165, loss=1.0632727146148682
I0305 00:01:49.177679 139881799980800 logging_writer.py:48] [455200] global_step=455200, grad_norm=3.8652572631835938, loss=3.2258291244506836
I0305 00:02:33.587430 139881808373504 logging_writer.py:48] [455300] global_step=455300, grad_norm=3.357747793197632, loss=3.0005390644073486
I0305 00:03:18.439628 139881799980800 logging_writer.py:48] [455400] global_step=455400, grad_norm=3.434112071990967, loss=2.19626522064209
I0305 00:04:02.946063 139881808373504 logging_writer.py:48] [455500] global_step=455500, grad_norm=3.5411500930786133, loss=3.0680465698242188
I0305 00:04:29.610923 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:04:39.792337 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:05:07.556741 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:05:09.143845 140077943854912 submission_runner.py:411] Time since start: 219501.95s, 	Step: 455562, 	{'train/accuracy': 0.88978511095047, 'train/loss': 0.41329196095466614, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 200428.2955994606, 'total_duration': 219501.9488492012, 'accumulated_submission_time': 200428.2955994606, 'accumulated_eval_time': 19014.16286468506, 'accumulated_logging_time': 35.791934967041016}
I0305 00:05:09.247813 139881799980800 logging_writer.py:48] [455562] accumulated_eval_time=19014.162865, accumulated_logging_time=35.791935, accumulated_submission_time=200428.295599, global_step=455562, preemption_count=0, score=200428.295599, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=219501.948849, train/accuracy=0.889785, train/loss=0.413292, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:05:24.659737 139881808373504 logging_writer.py:48] [455600] global_step=455600, grad_norm=3.2912464141845703, loss=1.130096197128296
I0305 00:06:07.650314 139881799980800 logging_writer.py:48] [455700] global_step=455700, grad_norm=3.089205741882324, loss=1.102417230606079
I0305 00:06:52.051215 139881808373504 logging_writer.py:48] [455800] global_step=455800, grad_norm=3.7638511657714844, loss=3.147014617919922
I0305 00:07:36.794518 139881799980800 logging_writer.py:48] [455900] global_step=455900, grad_norm=3.219982385635376, loss=1.362870693206787
I0305 00:08:21.172293 139881808373504 logging_writer.py:48] [456000] global_step=456000, grad_norm=2.9450674057006836, loss=2.3254847526550293
I0305 00:09:05.683056 139881799980800 logging_writer.py:48] [456100] global_step=456100, grad_norm=3.213940143585205, loss=1.2512060403823853
I0305 00:09:49.946951 139881808373504 logging_writer.py:48] [456200] global_step=456200, grad_norm=2.889820098876953, loss=1.0324711799621582
I0305 00:10:34.281723 139881799980800 logging_writer.py:48] [456300] global_step=456300, grad_norm=4.011861801147461, loss=3.0403523445129395
I0305 00:11:18.718607 139881808373504 logging_writer.py:48] [456400] global_step=456400, grad_norm=2.9194557666778564, loss=1.0583839416503906
I0305 00:12:03.350747 139881799980800 logging_writer.py:48] [456500] global_step=456500, grad_norm=3.011249303817749, loss=1.0413892269134521
I0305 00:12:09.237215 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:12:19.712422 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:12:47.487869 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:12:49.076788 140077943854912 submission_runner.py:411] Time since start: 219961.88s, 	Step: 456515, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.41712409257888794, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 200848.2231376171, 'total_duration': 219961.88178777695, 'accumulated_submission_time': 200848.2231376171, 'accumulated_eval_time': 19054.002438783646, 'accumulated_logging_time': 35.90884757041931}
I0305 00:12:49.182331 139881808373504 logging_writer.py:48] [456515] accumulated_eval_time=19054.002439, accumulated_logging_time=35.908848, accumulated_submission_time=200848.223138, global_step=456515, preemption_count=0, score=200848.223138, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=219961.881788, train/accuracy=0.888418, train/loss=0.417124, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:13:24.620143 139881799980800 logging_writer.py:48] [456600] global_step=456600, grad_norm=3.0652570724487305, loss=1.0987664461135864
I0305 00:14:09.933136 139881808373504 logging_writer.py:48] [456700] global_step=456700, grad_norm=4.2128167152404785, loss=3.232083559036255
I0305 00:14:54.818287 139881799980800 logging_writer.py:48] [456800] global_step=456800, grad_norm=3.3924927711486816, loss=1.1130958795547485
I0305 00:15:39.555405 139881808373504 logging_writer.py:48] [456900] global_step=456900, grad_norm=3.081942319869995, loss=1.1023832559585571
I0305 00:16:24.748506 139881799980800 logging_writer.py:48] [457000] global_step=457000, grad_norm=3.3239524364471436, loss=1.1251153945922852
I0305 00:17:09.518346 139881808373504 logging_writer.py:48] [457100] global_step=457100, grad_norm=3.5511624813079834, loss=3.0730600357055664
I0305 00:17:54.326406 139881799980800 logging_writer.py:48] [457200] global_step=457200, grad_norm=2.8534369468688965, loss=1.0154181718826294
I0305 00:18:39.397557 139881808373504 logging_writer.py:48] [457300] global_step=457300, grad_norm=3.868678569793701, loss=3.1338539123535156
I0305 00:19:24.411577 139881799980800 logging_writer.py:48] [457400] global_step=457400, grad_norm=3.340144157409668, loss=2.867783784866333
I0305 00:19:49.238815 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:19:59.936388 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:20:30.598238 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:20:32.185324 140077943854912 submission_runner.py:411] Time since start: 220424.99s, 	Step: 457457, 	{'train/accuracy': 0.8882616758346558, 'train/loss': 0.41612708568573, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 201268.22051143646, 'total_duration': 220424.99032568932, 'accumulated_submission_time': 201268.22051143646, 'accumulated_eval_time': 19096.948910951614, 'accumulated_logging_time': 36.02534198760986}
I0305 00:20:32.290233 139881808373504 logging_writer.py:48] [457457] accumulated_eval_time=19096.948911, accumulated_logging_time=36.025342, accumulated_submission_time=201268.220511, global_step=457457, preemption_count=0, score=201268.220511, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=220424.990326, train/accuracy=0.888262, train/loss=0.416127, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:20:49.475243 139881799980800 logging_writer.py:48] [457500] global_step=457500, grad_norm=3.048645496368408, loss=1.0401562452316284
I0305 00:21:32.768915 139881808373504 logging_writer.py:48] [457600] global_step=457600, grad_norm=3.0834896564483643, loss=1.123016119003296
I0305 00:22:17.483430 139881799980800 logging_writer.py:48] [457700] global_step=457700, grad_norm=3.458371639251709, loss=3.1920371055603027
I0305 00:23:02.162231 139881808373504 logging_writer.py:48] [457800] global_step=457800, grad_norm=3.207833766937256, loss=1.0844875574111938
I0305 00:23:46.586804 139881799980800 logging_writer.py:48] [457900] global_step=457900, grad_norm=2.9807705879211426, loss=1.1563944816589355
I0305 00:24:31.201742 139881808373504 logging_writer.py:48] [458000] global_step=458000, grad_norm=4.091014862060547, loss=1.2426187992095947
I0305 00:25:15.779048 139881799980800 logging_writer.py:48] [458100] global_step=458100, grad_norm=4.001152992248535, loss=3.122135877609253
I0305 00:26:00.332311 139881808373504 logging_writer.py:48] [458200] global_step=458200, grad_norm=3.194256544113159, loss=1.1029131412506104
I0305 00:26:45.013527 139881799980800 logging_writer.py:48] [458300] global_step=458300, grad_norm=2.893477439880371, loss=1.2246874570846558
I0305 00:27:29.617915 139881808373504 logging_writer.py:48] [458400] global_step=458400, grad_norm=2.993476390838623, loss=1.5632399320602417
I0305 00:27:32.446101 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:27:42.523379 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:28:14.035238 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:28:15.641992 140077943854912 submission_runner.py:411] Time since start: 220888.45s, 	Step: 458408, 	{'train/accuracy': 0.8860155940055847, 'train/loss': 0.42375800013542175, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 201688.31512522697, 'total_duration': 220888.44696998596, 'accumulated_submission_time': 201688.31512522697, 'accumulated_eval_time': 19140.144728183746, 'accumulated_logging_time': 36.14205241203308}
I0305 00:28:15.810380 139881799980800 logging_writer.py:48] [458408] accumulated_eval_time=19140.144728, accumulated_logging_time=36.142052, accumulated_submission_time=201688.315125, global_step=458408, preemption_count=0, score=201688.315125, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=220888.446970, train/accuracy=0.886016, train/loss=0.423758, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:28:52.800788 139881808373504 logging_writer.py:48] [458500] global_step=458500, grad_norm=3.2729625701904297, loss=2.0662636756896973
I0305 00:29:37.360684 139881799980800 logging_writer.py:48] [458600] global_step=458600, grad_norm=3.2846198081970215, loss=1.0323541164398193
I0305 00:30:21.983169 139881808373504 logging_writer.py:48] [458700] global_step=458700, grad_norm=3.1230967044830322, loss=1.4428187608718872
I0305 00:31:06.363817 139881799980800 logging_writer.py:48] [458800] global_step=458800, grad_norm=3.021735429763794, loss=1.7507634162902832
I0305 00:31:50.593807 139881808373504 logging_writer.py:48] [458900] global_step=458900, grad_norm=3.0785603523254395, loss=1.1807093620300293
I0305 00:32:35.209610 139881799980800 logging_writer.py:48] [459000] global_step=459000, grad_norm=3.22582745552063, loss=1.2629849910736084
I0305 00:33:19.539083 139881808373504 logging_writer.py:48] [459100] global_step=459100, grad_norm=3.370283603668213, loss=1.2061607837677002
I0305 00:34:04.140202 139881799980800 logging_writer.py:48] [459200] global_step=459200, grad_norm=2.984994649887085, loss=1.4473525285720825
I0305 00:34:48.501023 139881808373504 logging_writer.py:48] [459300] global_step=459300, grad_norm=2.9709360599517822, loss=1.101725697517395
I0305 00:35:15.782098 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:35:25.812679 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:35:54.577817 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:35:56.161592 140077943854912 submission_runner.py:411] Time since start: 221348.97s, 	Step: 459363, 	{'train/accuracy': 0.88734370470047, 'train/loss': 0.41942909359931946, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 202108.22252106667, 'total_duration': 221348.96659827232, 'accumulated_submission_time': 202108.22252106667, 'accumulated_eval_time': 19180.524179935455, 'accumulated_logging_time': 36.32553815841675}
I0305 00:35:56.268238 139881799980800 logging_writer.py:48] [459363] accumulated_eval_time=19180.524180, accumulated_logging_time=36.325538, accumulated_submission_time=202108.222521, global_step=459363, preemption_count=0, score=202108.222521, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=221348.966598, train/accuracy=0.887344, train/loss=0.419429, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:36:11.083966 139881808373504 logging_writer.py:48] [459400] global_step=459400, grad_norm=3.117184638977051, loss=1.19752037525177
I0305 00:36:54.134330 139881799980800 logging_writer.py:48] [459500] global_step=459500, grad_norm=3.171627998352051, loss=2.8193538188934326
I0305 00:37:38.548763 139881808373504 logging_writer.py:48] [459600] global_step=459600, grad_norm=3.0988967418670654, loss=1.2152119874954224
I0305 00:38:23.153755 139881799980800 logging_writer.py:48] [459700] global_step=459700, grad_norm=3.5574867725372314, loss=2.9521119594573975
I0305 00:39:07.794289 139881808373504 logging_writer.py:48] [459800] global_step=459800, grad_norm=3.7725250720977783, loss=3.2421717643737793
I0305 00:39:52.244002 139881799980800 logging_writer.py:48] [459900] global_step=459900, grad_norm=3.1042678356170654, loss=2.5083084106445312
I0305 00:40:36.705627 139881808373504 logging_writer.py:48] [460000] global_step=460000, grad_norm=3.4412448406219482, loss=2.916494369506836
I0305 00:41:20.945263 139881799980800 logging_writer.py:48] [460100] global_step=460100, grad_norm=3.197934627532959, loss=1.1024377346038818
I0305 00:42:06.152809 139881808373504 logging_writer.py:48] [460200] global_step=460200, grad_norm=3.0555381774902344, loss=1.3702226877212524
I0305 00:42:50.210182 139881799980800 logging_writer.py:48] [460300] global_step=460300, grad_norm=3.3397927284240723, loss=1.3498398065567017
I0305 00:42:56.543360 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:43:06.914742 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:43:39.221330 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:43:40.808571 140077943854912 submission_runner.py:411] Time since start: 221813.61s, 	Step: 460316, 	{'train/accuracy': 0.890429675579071, 'train/loss': 0.4093267023563385, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 202528.4370057583, 'total_duration': 221813.6135840416, 'accumulated_submission_time': 202528.4370057583, 'accumulated_eval_time': 19224.78936481476, 'accumulated_logging_time': 36.44341278076172}
I0305 00:43:40.912019 139881808373504 logging_writer.py:48] [460316] accumulated_eval_time=19224.789365, accumulated_logging_time=36.443413, accumulated_submission_time=202528.437006, global_step=460316, preemption_count=0, score=202528.437006, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=221813.613584, train/accuracy=0.890430, train/loss=0.409327, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:44:15.196017 139881799980800 logging_writer.py:48] [460400] global_step=460400, grad_norm=3.4598751068115234, loss=1.2812113761901855
I0305 00:44:59.581707 139881808373504 logging_writer.py:48] [460500] global_step=460500, grad_norm=3.0475716590881348, loss=1.1256674528121948
I0305 00:45:44.287456 139881799980800 logging_writer.py:48] [460600] global_step=460600, grad_norm=4.96900749206543, loss=3.1134800910949707
I0305 00:46:29.219215 139881808373504 logging_writer.py:48] [460700] global_step=460700, grad_norm=3.9188058376312256, loss=1.1345717906951904
I0305 00:47:13.503009 139881799980800 logging_writer.py:48] [460800] global_step=460800, grad_norm=3.349144697189331, loss=1.133086085319519
I0305 00:47:57.701205 139881808373504 logging_writer.py:48] [460900] global_step=460900, grad_norm=3.6062865257263184, loss=2.7604074478149414
I0305 00:48:42.169926 139881799980800 logging_writer.py:48] [461000] global_step=461000, grad_norm=3.1747069358825684, loss=1.4498729705810547
I0305 00:49:26.579769 139881808373504 logging_writer.py:48] [461100] global_step=461100, grad_norm=3.1983866691589355, loss=1.118948221206665
I0305 00:50:11.207520 139881799980800 logging_writer.py:48] [461200] global_step=461200, grad_norm=3.271261692047119, loss=2.6084601879119873
I0305 00:50:40.899158 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:50:51.015213 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:51:28.357904 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:51:29.931644 140077943854912 submission_runner.py:411] Time since start: 222282.74s, 	Step: 461268, 	{'train/accuracy': 0.8883007764816284, 'train/loss': 0.4184071719646454, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 202948.36471748352, 'total_duration': 222282.7366580963, 'accumulated_submission_time': 202948.36471748352, 'accumulated_eval_time': 19273.821818590164, 'accumulated_logging_time': 36.55770182609558}
I0305 00:51:30.018226 139881808373504 logging_writer.py:48] [461268] accumulated_eval_time=19273.821819, accumulated_logging_time=36.557702, accumulated_submission_time=202948.364717, global_step=461268, preemption_count=0, score=202948.364717, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=222282.736658, train/accuracy=0.888301, train/loss=0.418407, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:51:42.880468 139881799980800 logging_writer.py:48] [461300] global_step=461300, grad_norm=3.8186845779418945, loss=2.533031463623047
I0305 00:52:24.275353 139881808373504 logging_writer.py:48] [461400] global_step=461400, grad_norm=3.3503482341766357, loss=1.8114045858383179
I0305 00:53:09.117090 139881799980800 logging_writer.py:48] [461500] global_step=461500, grad_norm=3.077967882156372, loss=1.2707104682922363
I0305 00:53:53.854239 139881808373504 logging_writer.py:48] [461600] global_step=461600, grad_norm=3.110295295715332, loss=1.1477508544921875
I0305 00:54:38.488832 139881799980800 logging_writer.py:48] [461700] global_step=461700, grad_norm=3.3013737201690674, loss=2.370630979537964
I0305 00:55:22.910736 139881808373504 logging_writer.py:48] [461800] global_step=461800, grad_norm=3.453157901763916, loss=2.773285150527954
I0305 00:56:07.621411 139881799980800 logging_writer.py:48] [461900] global_step=461900, grad_norm=3.7507998943328857, loss=3.180894374847412
I0305 00:56:51.932917 139881808373504 logging_writer.py:48] [462000] global_step=462000, grad_norm=3.0473899841308594, loss=1.5772732496261597
I0305 00:57:36.066887 139881799980800 logging_writer.py:48] [462100] global_step=462100, grad_norm=3.285357713699341, loss=1.9775214195251465
I0305 00:58:20.274750 139881808373504 logging_writer.py:48] [462200] global_step=462200, grad_norm=3.124732494354248, loss=1.4273439645767212
I0305 00:58:30.159450 140077943854912 spec.py:321] Evaluating on the training split.
I0305 00:58:40.351994 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 00:59:16.987351 140077943854912 spec.py:349] Evaluating on the test split.
I0305 00:59:18.568337 140077943854912 submission_runner.py:411] Time since start: 222751.37s, 	Step: 462224, 	{'train/accuracy': 0.88623046875, 'train/loss': 0.422183096408844, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 203368.44725489616, 'total_duration': 222751.37335205078, 'accumulated_submission_time': 203368.44725489616, 'accumulated_eval_time': 19322.230692386627, 'accumulated_logging_time': 36.654043197631836}
I0305 00:59:18.654159 139881799980800 logging_writer.py:48] [462224] accumulated_eval_time=19322.230692, accumulated_logging_time=36.654043, accumulated_submission_time=203368.447255, global_step=462224, preemption_count=0, score=203368.447255, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=222751.373352, train/accuracy=0.886230, train/loss=0.422183, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 00:59:48.708463 139881808373504 logging_writer.py:48] [462300] global_step=462300, grad_norm=3.005763530731201, loss=1.1979210376739502
I0305 01:00:32.830945 139881799980800 logging_writer.py:48] [462400] global_step=462400, grad_norm=3.0941433906555176, loss=1.0913472175598145
I0305 01:01:17.122346 139881808373504 logging_writer.py:48] [462500] global_step=462500, grad_norm=3.053051233291626, loss=1.1499130725860596
I0305 01:02:01.512430 139881799980800 logging_writer.py:48] [462600] global_step=462600, grad_norm=3.243028402328491, loss=1.3279556035995483
I0305 01:02:45.919909 139881808373504 logging_writer.py:48] [462700] global_step=462700, grad_norm=3.111845016479492, loss=1.1533128023147583
I0305 01:03:30.401135 139881799980800 logging_writer.py:48] [462800] global_step=462800, grad_norm=3.119091272354126, loss=1.1344313621520996
I0305 01:04:14.795572 139881808373504 logging_writer.py:48] [462900] global_step=462900, grad_norm=2.8403542041778564, loss=1.3189691305160522
I0305 01:04:59.357224 139881799980800 logging_writer.py:48] [463000] global_step=463000, grad_norm=3.5502490997314453, loss=3.243621587753296
I0305 01:05:43.777965 139881808373504 logging_writer.py:48] [463100] global_step=463100, grad_norm=3.281766891479492, loss=1.1215156316757202
I0305 01:06:18.686024 140077943854912 spec.py:321] Evaluating on the training split.
I0305 01:06:29.040898 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 01:06:56.217449 140077943854912 spec.py:349] Evaluating on the test split.
I0305 01:06:57.800300 140077943854912 submission_runner.py:411] Time since start: 223210.61s, 	Step: 463180, 	{'train/accuracy': 0.8882421851158142, 'train/loss': 0.41809535026550293, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 203788.41516184807, 'total_duration': 223210.6052725315, 'accumulated_submission_time': 203788.41516184807, 'accumulated_eval_time': 19361.344890594482, 'accumulated_logging_time': 36.750526428222656}
I0305 01:06:57.909651 139881799980800 logging_writer.py:48] [463180] accumulated_eval_time=19361.344891, accumulated_logging_time=36.750526, accumulated_submission_time=203788.415162, global_step=463180, preemption_count=0, score=203788.415162, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=223210.605273, train/accuracy=0.888242, train/loss=0.418095, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 01:07:06.856283 139881808373504 logging_writer.py:48] [463200] global_step=463200, grad_norm=3.406829357147217, loss=2.709162712097168
I0305 01:07:49.674312 139881799980800 logging_writer.py:48] [463300] global_step=463300, grad_norm=3.045275926589966, loss=1.125982642173767
I0305 01:08:34.652282 139881808373504 logging_writer.py:48] [463400] global_step=463400, grad_norm=3.2983782291412354, loss=1.1544499397277832
I0305 01:09:19.662131 139881799980800 logging_writer.py:48] [463500] global_step=463500, grad_norm=3.2903144359588623, loss=1.1462509632110596
I0305 01:10:04.908551 139881808373504 logging_writer.py:48] [463600] global_step=463600, grad_norm=3.3526246547698975, loss=1.271360158920288
I0305 01:10:49.744193 139881799980800 logging_writer.py:48] [463700] global_step=463700, grad_norm=2.920607089996338, loss=1.240418791770935
I0305 01:11:34.443347 139881808373504 logging_writer.py:48] [463800] global_step=463800, grad_norm=3.7777700424194336, loss=3.0635743141174316
I0305 01:12:19.554023 139881799980800 logging_writer.py:48] [463900] global_step=463900, grad_norm=3.2097880840301514, loss=1.060996651649475
I0305 01:13:04.773650 139881808373504 logging_writer.py:48] [464000] global_step=464000, grad_norm=3.092043876647949, loss=2.122892141342163
I0305 01:13:49.975939 139881799980800 logging_writer.py:48] [464100] global_step=464100, grad_norm=3.210357427597046, loss=1.2041187286376953
I0305 01:13:58.137367 140077943854912 spec.py:321] Evaluating on the training split.
I0305 01:14:08.604860 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 01:14:39.365476 140077943854912 spec.py:349] Evaluating on the test split.
I0305 01:14:40.950934 140077943854912 submission_runner.py:411] Time since start: 223673.76s, 	Step: 464120, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.41326144337654114, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 204207.8207669258, 'total_duration': 223673.75593829155, 'accumulated_submission_time': 204207.8207669258, 'accumulated_eval_time': 19404.15842437744, 'accumulated_logging_time': 37.63438177108765}
I0305 01:14:41.058823 139881808373504 logging_writer.py:48] [464120] accumulated_eval_time=19404.158424, accumulated_logging_time=37.634382, accumulated_submission_time=204207.820767, global_step=464120, preemption_count=0, score=204207.820767, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=223673.755938, train/accuracy=0.887500, train/loss=0.413261, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 01:15:13.674669 139881799980800 logging_writer.py:48] [464200] global_step=464200, grad_norm=2.8002192974090576, loss=1.5709214210510254
I0305 01:15:57.657907 139881808373504 logging_writer.py:48] [464300] global_step=464300, grad_norm=2.9352290630340576, loss=1.1405996084213257
I0305 01:16:42.520225 139881799980800 logging_writer.py:48] [464400] global_step=464400, grad_norm=2.872988700866699, loss=1.707655668258667
I0305 01:17:27.428799 139881808373504 logging_writer.py:48] [464500] global_step=464500, grad_norm=3.250715970993042, loss=1.1396992206573486
I0305 01:18:12.099531 139881799980800 logging_writer.py:48] [464600] global_step=464600, grad_norm=3.191802501678467, loss=2.8007421493530273
I0305 01:18:56.536590 139881808373504 logging_writer.py:48] [464700] global_step=464700, grad_norm=3.690718650817871, loss=1.2540490627288818
I0305 01:19:41.254936 139881799980800 logging_writer.py:48] [464800] global_step=464800, grad_norm=2.8011202812194824, loss=1.0390925407409668
I0305 01:20:25.979446 139881808373504 logging_writer.py:48] [464900] global_step=464900, grad_norm=3.2192020416259766, loss=2.455355405807495
I0305 01:21:10.490887 139881799980800 logging_writer.py:48] [465000] global_step=465000, grad_norm=3.5395703315734863, loss=1.057992696762085
I0305 01:21:40.995212 140077943854912 spec.py:321] Evaluating on the training split.
I0305 01:21:51.349134 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 01:22:29.832320 140077943854912 spec.py:349] Evaluating on the test split.
I0305 01:22:31.423431 140077943854912 submission_runner.py:411] Time since start: 224144.23s, 	Step: 465070, 	{'train/accuracy': 0.8865624666213989, 'train/loss': 0.4224892854690552, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 204627.69776153564, 'total_duration': 224144.2284386158, 'accumulated_submission_time': 204627.69776153564, 'accumulated_eval_time': 19454.58660507202, 'accumulated_logging_time': 37.75303912162781}
I0305 01:22:31.512114 139881808373504 logging_writer.py:48] [465070] accumulated_eval_time=19454.586605, accumulated_logging_time=37.753039, accumulated_submission_time=204627.697762, global_step=465070, preemption_count=0, score=204627.697762, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=224144.228439, train/accuracy=0.886562, train/loss=0.422489, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 01:22:43.589932 139881799980800 logging_writer.py:48] [465100] global_step=465100, grad_norm=3.289236068725586, loss=1.6703472137451172
I0305 01:23:24.867844 139881808373504 logging_writer.py:48] [465200] global_step=465200, grad_norm=3.415083169937134, loss=1.2296000719070435
I0305 01:24:09.419520 139881799980800 logging_writer.py:48] [465300] global_step=465300, grad_norm=3.1290011405944824, loss=2.78005313873291
I0305 01:24:53.814027 139881808373504 logging_writer.py:48] [465400] global_step=465400, grad_norm=3.5219414234161377, loss=1.1859797239303589
I0305 01:25:38.745607 139881799980800 logging_writer.py:48] [465500] global_step=465500, grad_norm=3.3504819869995117, loss=2.4467272758483887
I0305 01:26:23.296071 139881808373504 logging_writer.py:48] [465600] global_step=465600, grad_norm=3.184237480163574, loss=1.109110713005066
I0305 01:27:07.913173 139881799980800 logging_writer.py:48] [465700] global_step=465700, grad_norm=3.2436676025390625, loss=1.1094428300857544
I0305 01:27:52.382715 139881808373504 logging_writer.py:48] [465800] global_step=465800, grad_norm=3.2289862632751465, loss=1.1374363899230957
I0305 01:28:36.834125 139881799980800 logging_writer.py:48] [465900] global_step=465900, grad_norm=3.2013626098632812, loss=1.6275615692138672
I0305 01:29:21.334963 139881808373504 logging_writer.py:48] [466000] global_step=466000, grad_norm=3.2801740169525146, loss=1.4489986896514893
I0305 01:29:31.691778 140077943854912 spec.py:321] Evaluating on the training split.
I0305 01:29:41.939285 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 01:30:10.339220 140077943854912 spec.py:349] Evaluating on the test split.
I0305 01:30:11.931132 140077943854912 submission_runner.py:411] Time since start: 224604.74s, 	Step: 466025, 	{'train/accuracy': 0.8872656226158142, 'train/loss': 0.42040178179740906, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 205047.81872677803, 'total_duration': 224604.73613643646, 'accumulated_submission_time': 205047.81872677803, 'accumulated_eval_time': 19494.825929641724, 'accumulated_logging_time': 37.851630210876465}
I0305 01:30:12.047996 139881799980800 logging_writer.py:48] [466025] accumulated_eval_time=19494.825930, accumulated_logging_time=37.851630, accumulated_submission_time=205047.818727, global_step=466025, preemption_count=0, score=205047.818727, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=224604.736136, train/accuracy=0.887266, train/loss=0.420402, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 01:30:42.347790 139881808373504 logging_writer.py:48] [466100] global_step=466100, grad_norm=3.268453359603882, loss=1.3689074516296387
I0305 01:31:26.907321 139881799980800 logging_writer.py:48] [466200] global_step=466200, grad_norm=3.0550403594970703, loss=1.1621601581573486
I0305 01:32:11.373391 139881808373504 logging_writer.py:48] [466300] global_step=466300, grad_norm=3.4686474800109863, loss=2.988940954208374
I0305 01:32:56.132034 139881799980800 logging_writer.py:48] [466400] global_step=466400, grad_norm=3.2308034896850586, loss=1.1199531555175781
I0305 01:33:40.605684 139881808373504 logging_writer.py:48] [466500] global_step=466500, grad_norm=3.163069486618042, loss=1.1814227104187012
I0305 01:34:25.586540 139881799980800 logging_writer.py:48] [466600] global_step=466600, grad_norm=3.633322238922119, loss=3.156017780303955
I0305 01:35:10.220408 139881808373504 logging_writer.py:48] [466700] global_step=466700, grad_norm=2.894774913787842, loss=1.6483466625213623
I0305 01:35:54.787580 139881799980800 logging_writer.py:48] [466800] global_step=466800, grad_norm=3.2271065711975098, loss=1.1032073497772217
I0305 01:36:39.327388 139881808373504 logging_writer.py:48] [466900] global_step=466900, grad_norm=3.019047498703003, loss=1.0613088607788086
I0305 01:37:12.321374 140077943854912 spec.py:321] Evaluating on the training split.
I0305 01:37:22.570381 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 01:37:53.150522 140077943854912 spec.py:349] Evaluating on the test split.
I0305 01:37:54.737271 140077943854912 submission_runner.py:411] Time since start: 225067.54s, 	Step: 466975, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.4198971390724182, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 205468.0308253765, 'total_duration': 225067.5422782898, 'accumulated_submission_time': 205468.0308253765, 'accumulated_eval_time': 19537.241803646088, 'accumulated_logging_time': 37.98124074935913}
I0305 01:37:54.844136 139881799980800 logging_writer.py:48] [466975] accumulated_eval_time=19537.241804, accumulated_logging_time=37.981241, accumulated_submission_time=205468.030825, global_step=466975, preemption_count=0, score=205468.030825, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=225067.542278, train/accuracy=0.887676, train/loss=0.419897, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 01:38:04.981319 139881808373504 logging_writer.py:48] [467000] global_step=467000, grad_norm=3.075192928314209, loss=2.3938939571380615
I0305 01:38:48.309470 139881799980800 logging_writer.py:48] [467100] global_step=467100, grad_norm=3.0984017848968506, loss=1.2541128396987915
I0305 01:39:33.772413 139881808373504 logging_writer.py:48] [467200] global_step=467200, grad_norm=3.243483543395996, loss=1.112119197845459
I0305 01:40:18.976286 139881799980800 logging_writer.py:48] [467300] global_step=467300, grad_norm=2.989586114883423, loss=1.0733668804168701
I0305 01:41:04.259619 139881808373504 logging_writer.py:48] [467400] global_step=467400, grad_norm=3.0848047733306885, loss=1.201767921447754
I0305 01:41:49.269498 139881799980800 logging_writer.py:48] [467500] global_step=467500, grad_norm=2.9572930335998535, loss=2.057349443435669
I0305 01:42:34.298158 139881808373504 logging_writer.py:48] [467600] global_step=467600, grad_norm=3.2424235343933105, loss=1.1181559562683105
I0305 01:43:19.544788 139881799980800 logging_writer.py:48] [467700] global_step=467700, grad_norm=2.872234582901001, loss=1.5079741477966309
I0305 01:44:04.708391 139881808373504 logging_writer.py:48] [467800] global_step=467800, grad_norm=3.520138740539551, loss=3.1328516006469727
I0305 01:44:49.981099 139881799980800 logging_writer.py:48] [467900] global_step=467900, grad_norm=3.304257869720459, loss=2.5429553985595703
I0305 01:44:54.800723 140077943854912 spec.py:321] Evaluating on the training split.
I0305 01:45:05.119920 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 01:45:39.532233 140077943854912 spec.py:349] Evaluating on the test split.
I0305 01:45:41.113176 140077943854912 submission_runner.py:411] Time since start: 225533.92s, 	Step: 467912, 	{'train/accuracy': 0.887988269329071, 'train/loss': 0.41762828826904297, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 205887.92675709724, 'total_duration': 225533.91818737984, 'accumulated_submission_time': 205887.92675709724, 'accumulated_eval_time': 19583.554235219955, 'accumulated_logging_time': 38.10013508796692}
I0305 01:45:41.218892 139881808373504 logging_writer.py:48] [467912] accumulated_eval_time=19583.554235, accumulated_logging_time=38.100135, accumulated_submission_time=205887.926757, global_step=467912, preemption_count=0, score=205887.926757, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=225533.918187, train/accuracy=0.887988, train/loss=0.417628, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 01:46:17.184677 139881799980800 logging_writer.py:48] [468000] global_step=468000, grad_norm=3.9585134983062744, loss=3.088695764541626
I0305 01:47:01.418304 139881808373504 logging_writer.py:48] [468100] global_step=468100, grad_norm=3.1150529384613037, loss=1.0776244401931763
I0305 01:47:46.263961 139881799980800 logging_writer.py:48] [468200] global_step=468200, grad_norm=3.0605578422546387, loss=1.5273635387420654
I0305 01:48:30.665889 139881808373504 logging_writer.py:48] [468300] global_step=468300, grad_norm=3.00423526763916, loss=1.2835721969604492
I0305 01:49:15.256368 139881799980800 logging_writer.py:48] [468400] global_step=468400, grad_norm=3.1352925300598145, loss=1.0764085054397583
I0305 01:49:59.857797 139881808373504 logging_writer.py:48] [468500] global_step=468500, grad_norm=3.4778831005096436, loss=2.3614795207977295
I0305 01:50:44.473224 139881799980800 logging_writer.py:48] [468600] global_step=468600, grad_norm=3.015878915786743, loss=1.0573797225952148
I0305 01:51:29.177648 139881808373504 logging_writer.py:48] [468700] global_step=468700, grad_norm=3.600538969039917, loss=2.992097854614258
I0305 01:52:13.732666 139881799980800 logging_writer.py:48] [468800] global_step=468800, grad_norm=3.2821567058563232, loss=2.2183966636657715
I0305 01:52:41.151599 140077943854912 spec.py:321] Evaluating on the training split.
I0305 01:52:51.781294 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 01:53:30.844520 140077943854912 spec.py:349] Evaluating on the test split.
I0305 01:53:32.424038 140077943854912 submission_runner.py:411] Time since start: 226005.23s, 	Step: 468863, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.415490984916687, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 206307.7999806404, 'total_duration': 226005.22905516624, 'accumulated_submission_time': 206307.7999806404, 'accumulated_eval_time': 19634.826660633087, 'accumulated_logging_time': 38.21635723114014}
I0305 01:53:32.511833 139881808373504 logging_writer.py:48] [468863] accumulated_eval_time=19634.826661, accumulated_logging_time=38.216357, accumulated_submission_time=206307.799981, global_step=468863, preemption_count=0, score=206307.799981, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=226005.229055, train/accuracy=0.888066, train/loss=0.415491, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 01:53:47.341643 139881799980800 logging_writer.py:48] [468900] global_step=468900, grad_norm=3.4313125610351562, loss=3.0542988777160645
I0305 01:54:29.335728 139881808373504 logging_writer.py:48] [469000] global_step=469000, grad_norm=6.968657970428467, loss=3.2514095306396484
I0305 01:55:13.807493 139881799980800 logging_writer.py:48] [469100] global_step=469100, grad_norm=3.1559178829193115, loss=1.9795602560043335
I0305 01:55:58.710740 139881808373504 logging_writer.py:48] [469200] global_step=469200, grad_norm=3.059269428253174, loss=1.0888423919677734
I0305 01:56:43.357734 139881799980800 logging_writer.py:48] [469300] global_step=469300, grad_norm=3.348745346069336, loss=2.7810349464416504
I0305 01:57:27.657821 139881808373504 logging_writer.py:48] [469400] global_step=469400, grad_norm=3.0862462520599365, loss=1.0521507263183594
I0305 01:58:12.344712 139881799980800 logging_writer.py:48] [469500] global_step=469500, grad_norm=4.204187870025635, loss=1.0483465194702148
I0305 01:58:56.600678 139881808373504 logging_writer.py:48] [469600] global_step=469600, grad_norm=3.133127450942993, loss=1.5140560865402222
I0305 01:59:41.075426 139881799980800 logging_writer.py:48] [469700] global_step=469700, grad_norm=3.014888286590576, loss=1.5287193059921265
I0305 02:00:25.905335 139881808373504 logging_writer.py:48] [469800] global_step=469800, grad_norm=3.182116985321045, loss=1.1853382587432861
I0305 02:00:32.645441 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:00:42.707647 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:01:11.547508 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:01:13.130603 140077943854912 submission_runner.py:411] Time since start: 226465.94s, 	Step: 469817, 	{'train/accuracy': 0.8888671398162842, 'train/loss': 0.4122638702392578, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 206727.87339282036, 'total_duration': 226465.93561315536, 'accumulated_submission_time': 206727.87339282036, 'accumulated_eval_time': 19675.311785697937, 'accumulated_logging_time': 38.31474304199219}
I0305 02:01:13.239111 139881799980800 logging_writer.py:48] [469817] accumulated_eval_time=19675.311786, accumulated_logging_time=38.314743, accumulated_submission_time=206727.873393, global_step=469817, preemption_count=0, score=206727.873393, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=226465.935613, train/accuracy=0.888867, train/loss=0.412264, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:01:47.550370 139881808373504 logging_writer.py:48] [469900] global_step=469900, grad_norm=3.063734769821167, loss=1.071040391921997
I0305 02:02:32.551656 139881799980800 logging_writer.py:48] [470000] global_step=470000, grad_norm=3.086555242538452, loss=1.2166659832000732
I0305 02:03:17.626931 139881808373504 logging_writer.py:48] [470100] global_step=470100, grad_norm=3.3951520919799805, loss=1.2197120189666748
I0305 02:04:02.605295 139881799980800 logging_writer.py:48] [470200] global_step=470200, grad_norm=8.374682426452637, loss=2.153266668319702
I0305 02:04:47.798724 139881808373504 logging_writer.py:48] [470300] global_step=470300, grad_norm=3.344067096710205, loss=1.1004300117492676
I0305 02:05:32.768156 139881799980800 logging_writer.py:48] [470400] global_step=470400, grad_norm=3.9436912536621094, loss=1.3410120010375977
I0305 02:06:18.085334 139881808373504 logging_writer.py:48] [470500] global_step=470500, grad_norm=3.097092866897583, loss=2.2089643478393555
I0305 02:07:02.922126 139881799980800 logging_writer.py:48] [470600] global_step=470600, grad_norm=3.2009434700012207, loss=2.894397735595703
I0305 02:07:47.752383 139881808373504 logging_writer.py:48] [470700] global_step=470700, grad_norm=3.1081957817077637, loss=1.0974533557891846
I0305 02:08:13.584205 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:08:23.980334 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:08:57.218659 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:08:58.806460 140077943854912 submission_runner.py:411] Time since start: 226931.61s, 	Step: 470759, 	{'train/accuracy': 0.8885351419448853, 'train/loss': 0.41537272930145264, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 207148.1556749344, 'total_duration': 226931.6114668846, 'accumulated_submission_time': 207148.1556749344, 'accumulated_eval_time': 19720.53402042389, 'accumulated_logging_time': 38.43796992301941}
I0305 02:08:58.915452 139881799980800 logging_writer.py:48] [470759] accumulated_eval_time=19720.534020, accumulated_logging_time=38.437970, accumulated_submission_time=207148.155675, global_step=470759, preemption_count=0, score=207148.155675, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=226931.611467, train/accuracy=0.888535, train/loss=0.415373, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:09:15.351810 139881808373504 logging_writer.py:48] [470800] global_step=470800, grad_norm=3.014604091644287, loss=1.2248115539550781
I0305 02:09:58.849083 139881799980800 logging_writer.py:48] [470900] global_step=470900, grad_norm=3.1252284049987793, loss=1.026055097579956
I0305 02:10:43.941544 139881808373504 logging_writer.py:48] [471000] global_step=471000, grad_norm=3.1881983280181885, loss=1.1256203651428223
I0305 02:11:28.818202 139881799980800 logging_writer.py:48] [471100] global_step=471100, grad_norm=3.3816041946411133, loss=3.0125808715820312
I0305 02:12:13.569477 139881808373504 logging_writer.py:48] [471200] global_step=471200, grad_norm=3.3009145259857178, loss=1.1887786388397217
I0305 02:12:58.278221 139881799980800 logging_writer.py:48] [471300] global_step=471300, grad_norm=3.184021472930908, loss=2.4574453830718994
I0305 02:13:43.239636 139881808373504 logging_writer.py:48] [471400] global_step=471400, grad_norm=4.4642653465271, loss=3.256998062133789
I0305 02:14:28.302826 139881799980800 logging_writer.py:48] [471500] global_step=471500, grad_norm=3.023402214050293, loss=1.3213081359863281
I0305 02:15:13.127431 139881808373504 logging_writer.py:48] [471600] global_step=471600, grad_norm=2.8429243564605713, loss=1.028308629989624
I0305 02:15:58.131487 139881799980800 logging_writer.py:48] [471700] global_step=471700, grad_norm=3.040630340576172, loss=2.6868975162506104
I0305 02:15:59.203931 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:16:09.377047 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:16:39.913037 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:16:41.492860 140077943854912 submission_runner.py:411] Time since start: 227394.30s, 	Step: 471704, 	{'train/accuracy': 0.8871874809265137, 'train/loss': 0.41936278343200684, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 207568.38267040253, 'total_duration': 227394.29787039757, 'accumulated_submission_time': 207568.38267040253, 'accumulated_eval_time': 19762.82291984558, 'accumulated_logging_time': 38.55806303024292}
I0305 02:16:41.601978 139881808373504 logging_writer.py:48] [471704] accumulated_eval_time=19762.822920, accumulated_logging_time=38.558063, accumulated_submission_time=207568.382670, global_step=471704, preemption_count=0, score=207568.382670, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=227394.297870, train/accuracy=0.887187, train/loss=0.419363, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:17:21.379426 139881799980800 logging_writer.py:48] [471800] global_step=471800, grad_norm=3.0449059009552, loss=1.4363621473312378
I0305 02:18:06.124292 139881808373504 logging_writer.py:48] [471900] global_step=471900, grad_norm=3.635906934738159, loss=3.188197135925293
I0305 02:18:50.847495 139881799980800 logging_writer.py:48] [472000] global_step=472000, grad_norm=3.1905126571655273, loss=1.075691819190979
I0305 02:19:35.826321 139881808373504 logging_writer.py:48] [472100] global_step=472100, grad_norm=3.352191925048828, loss=1.19192636013031
I0305 02:20:20.635984 139881799980800 logging_writer.py:48] [472200] global_step=472200, grad_norm=3.33573579788208, loss=1.0824368000030518
I0305 02:21:05.269372 139881808373504 logging_writer.py:48] [472300] global_step=472300, grad_norm=2.899137020111084, loss=1.0593194961547852
I0305 02:21:49.787561 139881799980800 logging_writer.py:48] [472400] global_step=472400, grad_norm=3.2560582160949707, loss=1.2008155584335327
I0305 02:22:34.360280 139881808373504 logging_writer.py:48] [472500] global_step=472500, grad_norm=2.9341888427734375, loss=1.559411883354187
I0305 02:23:19.013637 139881799980800 logging_writer.py:48] [472600] global_step=472600, grad_norm=4.130402565002441, loss=3.213090419769287
I0305 02:23:41.552584 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:23:51.991135 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:24:21.614923 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:24:23.223992 140077943854912 submission_runner.py:411] Time since start: 227856.03s, 	Step: 472652, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.4182244837284088, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 207988.270154953, 'total_duration': 227856.02899241447, 'accumulated_submission_time': 207988.270154953, 'accumulated_eval_time': 19804.494306087494, 'accumulated_logging_time': 38.68139624595642}
I0305 02:24:23.315649 139881808373504 logging_writer.py:48] [472652] accumulated_eval_time=19804.494306, accumulated_logging_time=38.681396, accumulated_submission_time=207988.270155, global_step=472652, preemption_count=0, score=207988.270155, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=227856.028992, train/accuracy=0.888418, train/loss=0.418224, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:24:42.446827 139881799980800 logging_writer.py:48] [472700] global_step=472700, grad_norm=3.1241157054901123, loss=1.0035991668701172
I0305 02:25:25.129937 139881808373504 logging_writer.py:48] [472800] global_step=472800, grad_norm=3.4262969493865967, loss=3.0975985527038574
I0305 02:26:09.908770 139881799980800 logging_writer.py:48] [472900] global_step=472900, grad_norm=2.881356716156006, loss=1.6976715326309204
I0305 02:26:54.925955 139881808373504 logging_writer.py:48] [473000] global_step=473000, grad_norm=3.657731533050537, loss=1.160266399383545
I0305 02:27:39.382395 139881799980800 logging_writer.py:48] [473100] global_step=473100, grad_norm=3.129265069961548, loss=1.4744054079055786
I0305 02:28:23.851553 139881808373504 logging_writer.py:48] [473200] global_step=473200, grad_norm=3.4820685386657715, loss=1.1922063827514648
I0305 02:29:08.398122 139881799980800 logging_writer.py:48] [473300] global_step=473300, grad_norm=3.225992202758789, loss=1.104178547859192
I0305 02:29:52.723094 139881808373504 logging_writer.py:48] [473400] global_step=473400, grad_norm=3.263688564300537, loss=1.1623494625091553
I0305 02:30:37.150491 139881799980800 logging_writer.py:48] [473500] global_step=473500, grad_norm=3.272583246231079, loss=1.224773645401001
I0305 02:31:21.740037 139881808373504 logging_writer.py:48] [473600] global_step=473600, grad_norm=3.885867118835449, loss=1.17122220993042
I0305 02:31:23.610574 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:31:34.051611 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:32:01.492844 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:32:03.089465 140077943854912 submission_runner.py:411] Time since start: 228315.89s, 	Step: 473606, 	{'train/accuracy': 0.8891015648841858, 'train/loss': 0.41549360752105713, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 208408.5045876503, 'total_duration': 228315.894469738, 'accumulated_submission_time': 208408.5045876503, 'accumulated_eval_time': 19843.973166942596, 'accumulated_logging_time': 38.7846896648407}
I0305 02:32:03.195633 139881799980800 logging_writer.py:48] [473606] accumulated_eval_time=19843.973167, accumulated_logging_time=38.784690, accumulated_submission_time=208408.504588, global_step=473606, preemption_count=0, score=208408.504588, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=228315.894470, train/accuracy=0.889102, train/loss=0.415494, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:32:41.718460 139881808373504 logging_writer.py:48] [473700] global_step=473700, grad_norm=2.8267691135406494, loss=1.0068461894989014
I0305 02:33:26.009482 139881799980800 logging_writer.py:48] [473800] global_step=473800, grad_norm=3.06636643409729, loss=2.0534191131591797
I0305 02:34:10.415248 139881808373504 logging_writer.py:48] [473900] global_step=473900, grad_norm=3.2904465198516846, loss=2.6764450073242188
I0305 02:34:54.664208 139881799980800 logging_writer.py:48] [474000] global_step=474000, grad_norm=2.8748226165771484, loss=1.0504320859909058
I0305 02:35:39.190019 139881808373504 logging_writer.py:48] [474100] global_step=474100, grad_norm=3.2118968963623047, loss=1.0954411029815674
I0305 02:36:24.108239 139881799980800 logging_writer.py:48] [474200] global_step=474200, grad_norm=3.333203077316284, loss=1.3296093940734863
I0305 02:37:08.939736 139881808373504 logging_writer.py:48] [474300] global_step=474300, grad_norm=3.1625771522521973, loss=2.7775533199310303
I0305 02:37:53.284209 139881799980800 logging_writer.py:48] [474400] global_step=474400, grad_norm=3.0415005683898926, loss=2.2089405059814453
I0305 02:38:37.715688 139881808373504 logging_writer.py:48] [474500] global_step=474500, grad_norm=2.8698906898498535, loss=1.3361343145370483
I0305 02:39:03.519138 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:39:13.989934 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:39:42.308590 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:39:43.893825 140077943854912 submission_runner.py:411] Time since start: 228776.70s, 	Step: 474560, 	{'train/accuracy': 0.8894921541213989, 'train/loss': 0.4117230474948883, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 208828.76788640022, 'total_duration': 228776.69883298874, 'accumulated_submission_time': 208828.76788640022, 'accumulated_eval_time': 19884.347821950912, 'accumulated_logging_time': 38.901485204696655}
I0305 02:39:44.003581 139881799980800 logging_writer.py:48] [474560] accumulated_eval_time=19884.347822, accumulated_logging_time=38.901485, accumulated_submission_time=208828.767886, global_step=474560, preemption_count=0, score=208828.767886, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=228776.698833, train/accuracy=0.889492, train/loss=0.411723, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:40:00.003042 139881808373504 logging_writer.py:48] [474600] global_step=474600, grad_norm=3.3242526054382324, loss=2.2655179500579834
I0305 02:40:43.175689 139881799980800 logging_writer.py:48] [474700] global_step=474700, grad_norm=3.321553945541382, loss=2.309805393218994
I0305 02:41:28.060787 139881808373504 logging_writer.py:48] [474800] global_step=474800, grad_norm=4.1366868019104, loss=3.312623977661133
I0305 02:42:12.741564 139881799980800 logging_writer.py:48] [474900] global_step=474900, grad_norm=3.1618740558624268, loss=2.979656457901001
I0305 02:42:57.210248 139881808373504 logging_writer.py:48] [475000] global_step=475000, grad_norm=3.0588223934173584, loss=2.0050556659698486
I0305 02:43:42.420034 139881799980800 logging_writer.py:48] [475100] global_step=475100, grad_norm=3.0482637882232666, loss=1.8738735914230347
I0305 02:44:27.453035 139881808373504 logging_writer.py:48] [475200] global_step=475200, grad_norm=4.196305274963379, loss=3.2298150062561035
I0305 02:45:12.231950 139881799980800 logging_writer.py:48] [475300] global_step=475300, grad_norm=3.554368257522583, loss=2.5071940422058105
I0305 02:45:56.758649 139881808373504 logging_writer.py:48] [475400] global_step=475400, grad_norm=3.056976079940796, loss=1.1892623901367188
I0305 02:46:41.710991 139881799980800 logging_writer.py:48] [475500] global_step=475500, grad_norm=3.1869330406188965, loss=1.1556435823440552
I0305 02:46:44.085212 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:46:54.589902 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:47:32.160153 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:47:33.740867 140077943854912 submission_runner.py:411] Time since start: 229246.55s, 	Step: 475507, 	{'train/accuracy': 0.8870507478713989, 'train/loss': 0.4228179156780243, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 209248.7898492813, 'total_duration': 229246.54588580132, 'accumulated_submission_time': 209248.7898492813, 'accumulated_eval_time': 19934.003457069397, 'accumulated_logging_time': 39.022950172424316}
I0305 02:47:33.826000 139881808373504 logging_writer.py:48] [475507] accumulated_eval_time=19934.003457, accumulated_logging_time=39.022950, accumulated_submission_time=209248.789849, global_step=475507, preemption_count=0, score=209248.789849, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=229246.545886, train/accuracy=0.887051, train/loss=0.422818, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:48:10.966044 139881799980800 logging_writer.py:48] [475600] global_step=475600, grad_norm=3.137845993041992, loss=2.6709790229797363
I0305 02:48:55.300355 139881808373504 logging_writer.py:48] [475700] global_step=475700, grad_norm=3.3122994899749756, loss=2.929312229156494
I0305 02:49:40.230962 139881799980800 logging_writer.py:48] [475800] global_step=475800, grad_norm=3.7068400382995605, loss=2.5472941398620605
I0305 02:50:24.663769 139881808373504 logging_writer.py:48] [475900] global_step=475900, grad_norm=3.1297237873077393, loss=2.625293016433716
I0305 02:51:09.237242 139881799980800 logging_writer.py:48] [476000] global_step=476000, grad_norm=3.0680017471313477, loss=2.006807804107666
I0305 02:51:53.386094 139881808373504 logging_writer.py:48] [476100] global_step=476100, grad_norm=2.9818859100341797, loss=2.100968360900879
I0305 02:52:37.575122 139881799980800 logging_writer.py:48] [476200] global_step=476200, grad_norm=3.799755334854126, loss=3.1691431999206543
I0305 02:53:22.003800 139881808373504 logging_writer.py:48] [476300] global_step=476300, grad_norm=2.841301202774048, loss=2.0803961753845215
I0305 02:54:06.243214 139881799980800 logging_writer.py:48] [476400] global_step=476400, grad_norm=2.9612531661987305, loss=1.367599606513977
I0305 02:54:33.835057 140077943854912 spec.py:321] Evaluating on the training split.
I0305 02:54:44.938932 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 02:55:11.491543 140077943854912 spec.py:349] Evaluating on the test split.
I0305 02:55:13.078555 140077943854912 submission_runner.py:411] Time since start: 229705.88s, 	Step: 476464, 	{'train/accuracy': 0.8886327743530273, 'train/loss': 0.41569197177886963, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 209668.7404808998, 'total_duration': 229705.8835630417, 'accumulated_submission_time': 209668.7404808998, 'accumulated_eval_time': 19973.2469329834, 'accumulated_logging_time': 39.11786460876465}
I0305 02:55:13.188732 139881808373504 logging_writer.py:48] [476464] accumulated_eval_time=19973.246933, accumulated_logging_time=39.117865, accumulated_submission_time=209668.740481, global_step=476464, preemption_count=0, score=209668.740481, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=229705.883563, train/accuracy=0.888633, train/loss=0.415692, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 02:55:27.628492 139881799980800 logging_writer.py:48] [476500] global_step=476500, grad_norm=5.368590354919434, loss=3.291515827178955
I0305 02:56:10.649219 139881808373504 logging_writer.py:48] [476600] global_step=476600, grad_norm=2.917020797729492, loss=1.7502264976501465
I0305 02:56:55.410743 139881799980800 logging_writer.py:48] [476700] global_step=476700, grad_norm=3.097076177597046, loss=0.9942082762718201
I0305 02:57:40.248064 139881808373504 logging_writer.py:48] [476800] global_step=476800, grad_norm=3.7904129028320312, loss=2.8014538288116455
I0305 02:58:25.217332 139881799980800 logging_writer.py:48] [476900] global_step=476900, grad_norm=3.151130437850952, loss=1.1802680492401123
I0305 02:59:09.953026 139881808373504 logging_writer.py:48] [477000] global_step=477000, grad_norm=3.3352560997009277, loss=1.1583001613616943
I0305 02:59:54.528415 139881799980800 logging_writer.py:48] [477100] global_step=477100, grad_norm=3.5236504077911377, loss=1.4825924634933472
I0305 03:00:39.403898 139881808373504 logging_writer.py:48] [477200] global_step=477200, grad_norm=3.567155361175537, loss=3.053682565689087
I0305 03:01:24.017118 139881799980800 logging_writer.py:48] [477300] global_step=477300, grad_norm=3.4893577098846436, loss=2.2584941387176514
I0305 03:02:09.049153 139881808373504 logging_writer.py:48] [477400] global_step=477400, grad_norm=3.720508575439453, loss=2.859712839126587
I0305 03:02:13.120319 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:02:23.642720 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:02:57.967833 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:02:59.555478 140077943854912 submission_runner.py:411] Time since start: 230172.36s, 	Step: 477411, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.41074997186660767, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 210088.61083316803, 'total_duration': 230172.36048603058, 'accumulated_submission_time': 210088.61083316803, 'accumulated_eval_time': 20019.682067871094, 'accumulated_logging_time': 39.240925788879395}
I0305 03:02:59.664306 139881799980800 logging_writer.py:48] [477411] accumulated_eval_time=20019.682068, accumulated_logging_time=39.240926, accumulated_submission_time=210088.610833, global_step=477411, preemption_count=0, score=210088.610833, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=230172.360486, train/accuracy=0.887734, train/loss=0.410750, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:03:36.015700 139881808373504 logging_writer.py:48] [477500] global_step=477500, grad_norm=3.0903024673461914, loss=2.4051568508148193
I0305 03:04:20.322138 139881799980800 logging_writer.py:48] [477600] global_step=477600, grad_norm=2.9045073986053467, loss=1.1098400354385376
I0305 03:05:04.806646 139881808373504 logging_writer.py:48] [477700] global_step=477700, grad_norm=3.1384971141815186, loss=2.1209304332733154
I0305 03:05:49.300957 139881799980800 logging_writer.py:48] [477800] global_step=477800, grad_norm=4.01384973526001, loss=3.1636409759521484
I0305 03:06:33.918683 139881808373504 logging_writer.py:48] [477900] global_step=477900, grad_norm=3.0997488498687744, loss=2.5518736839294434
I0305 03:07:18.863262 139881799980800 logging_writer.py:48] [478000] global_step=478000, grad_norm=2.97407865524292, loss=1.0544137954711914
I0305 03:08:03.380800 139881808373504 logging_writer.py:48] [478100] global_step=478100, grad_norm=2.994513511657715, loss=1.0872175693511963
I0305 03:08:47.750749 139881799980800 logging_writer.py:48] [478200] global_step=478200, grad_norm=3.615199089050293, loss=2.261516809463501
I0305 03:09:32.546409 139881808373504 logging_writer.py:48] [478300] global_step=478300, grad_norm=2.9968132972717285, loss=1.0972830057144165
I0305 03:09:59.757072 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:10:09.961007 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:10:38.921664 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:10:40.505158 140077943854912 submission_runner.py:411] Time since start: 230633.31s, 	Step: 478363, 	{'train/accuracy': 0.8869726657867432, 'train/loss': 0.4187818169593811, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 210508.6423151493, 'total_duration': 230633.310161829, 'accumulated_submission_time': 210508.6423151493, 'accumulated_eval_time': 20060.430149316788, 'accumulated_logging_time': 39.36173105239868}
I0305 03:10:40.616160 139881799980800 logging_writer.py:48] [478363] accumulated_eval_time=20060.430149, accumulated_logging_time=39.361731, accumulated_submission_time=210508.642315, global_step=478363, preemption_count=0, score=210508.642315, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=230633.310162, train/accuracy=0.886973, train/loss=0.418782, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:10:55.434528 139881808373504 logging_writer.py:48] [478400] global_step=478400, grad_norm=3.138669013977051, loss=1.0622323751449585
I0305 03:11:39.309058 139881799980800 logging_writer.py:48] [478500] global_step=478500, grad_norm=3.123826503753662, loss=1.144145131111145
I0305 03:12:24.115729 139881808373504 logging_writer.py:48] [478600] global_step=478600, grad_norm=3.266916513442993, loss=1.1093194484710693
I0305 03:13:09.079395 139881799980800 logging_writer.py:48] [478700] global_step=478700, grad_norm=3.7361037731170654, loss=2.939086437225342
I0305 03:13:53.999863 139881808373504 logging_writer.py:48] [478800] global_step=478800, grad_norm=3.1588025093078613, loss=1.072462797164917
I0305 03:14:38.877161 139881799980800 logging_writer.py:48] [478900] global_step=478900, grad_norm=3.4586806297302246, loss=2.050006866455078
I0305 03:15:24.038245 139881808373504 logging_writer.py:48] [479000] global_step=479000, grad_norm=2.731560230255127, loss=1.354191541671753
I0305 03:16:09.105771 139881799980800 logging_writer.py:48] [479100] global_step=479100, grad_norm=3.7291274070739746, loss=2.907623767852783
I0305 03:16:54.201056 139881808373504 logging_writer.py:48] [479200] global_step=479200, grad_norm=2.9944398403167725, loss=1.574154257774353
I0305 03:17:39.188766 139881799980800 logging_writer.py:48] [479300] global_step=479300, grad_norm=3.2386631965637207, loss=2.780425786972046
I0305 03:17:40.637935 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:17:50.848531 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:18:24.245519 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:18:25.840728 140077943854912 submission_runner.py:411] Time since start: 231098.65s, 	Step: 479305, 	{'train/accuracy': 0.8893749713897705, 'train/loss': 0.4133050739765167, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 210928.60261964798, 'total_duration': 231098.6457479, 'accumulated_submission_time': 210928.60261964798, 'accumulated_eval_time': 20105.6329100132, 'accumulated_logging_time': 39.485485315322876}
I0305 03:18:25.929239 139881808373504 logging_writer.py:48] [479305] accumulated_eval_time=20105.632910, accumulated_logging_time=39.485485, accumulated_submission_time=210928.602620, global_step=479305, preemption_count=0, score=210928.602620, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=231098.645748, train/accuracy=0.889375, train/loss=0.413305, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:19:04.222300 139881799980800 logging_writer.py:48] [479400] global_step=479400, grad_norm=2.9310696125030518, loss=1.118016242980957
I0305 03:19:48.317280 139881808373504 logging_writer.py:48] [479500] global_step=479500, grad_norm=3.8115861415863037, loss=1.3226902484893799
I0305 03:20:33.058902 139881799980800 logging_writer.py:48] [479600] global_step=479600, grad_norm=3.1191139221191406, loss=2.6890809535980225
I0305 03:21:17.546118 139881808373504 logging_writer.py:48] [479700] global_step=479700, grad_norm=3.3813185691833496, loss=1.130396842956543
I0305 03:22:02.146571 139881799980800 logging_writer.py:48] [479800] global_step=479800, grad_norm=3.5470216274261475, loss=1.2131242752075195
I0305 03:22:46.674412 139881808373504 logging_writer.py:48] [479900] global_step=479900, grad_norm=3.0368595123291016, loss=1.1392680406570435
I0305 03:23:31.126121 139881799980800 logging_writer.py:48] [480000] global_step=480000, grad_norm=3.0987753868103027, loss=1.2118858098983765
I0305 03:24:15.588642 139881808373504 logging_writer.py:48] [480100] global_step=480100, grad_norm=3.9389781951904297, loss=3.1392016410827637
I0305 03:24:59.974329 139881799980800 logging_writer.py:48] [480200] global_step=480200, grad_norm=3.035977602005005, loss=1.001630187034607
I0305 03:25:26.145154 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:25:36.343161 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:26:04.147898 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:26:05.731704 140077943854912 submission_runner.py:411] Time since start: 231558.54s, 	Step: 480260, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.4162740111351013, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 211348.75797367096, 'total_duration': 231558.53671503067, 'accumulated_submission_time': 211348.75797367096, 'accumulated_eval_time': 20145.219435930252, 'accumulated_logging_time': 39.585007667541504}
I0305 03:26:05.841474 139881808373504 logging_writer.py:48] [480260] accumulated_eval_time=20145.219436, accumulated_logging_time=39.585008, accumulated_submission_time=211348.757974, global_step=480260, preemption_count=0, score=211348.757974, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=231558.536715, train/accuracy=0.888379, train/loss=0.416274, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:26:21.854610 139881799980800 logging_writer.py:48] [480300] global_step=480300, grad_norm=3.6273505687713623, loss=1.1601495742797852
I0305 03:27:05.176466 139881808373504 logging_writer.py:48] [480400] global_step=480400, grad_norm=3.0150673389434814, loss=1.4940661191940308
I0305 03:27:49.937093 139881799980800 logging_writer.py:48] [480500] global_step=480500, grad_norm=3.124701976776123, loss=1.177050232887268
I0305 03:28:34.626306 139881808373504 logging_writer.py:48] [480600] global_step=480600, grad_norm=2.9508113861083984, loss=1.1806573867797852
I0305 03:29:19.531217 139881799980800 logging_writer.py:48] [480700] global_step=480700, grad_norm=3.13802170753479, loss=2.1960113048553467
I0305 03:30:04.083570 139881808373504 logging_writer.py:48] [480800] global_step=480800, grad_norm=2.994349241256714, loss=1.540459156036377
I0305 03:30:48.376349 139881799980800 logging_writer.py:48] [480900] global_step=480900, grad_norm=3.4628684520721436, loss=1.199998140335083
I0305 03:31:33.092844 139881808373504 logging_writer.py:48] [481000] global_step=481000, grad_norm=3.781467914581299, loss=2.9615426063537598
I0305 03:32:17.681730 139881799980800 logging_writer.py:48] [481100] global_step=481100, grad_norm=3.1009068489074707, loss=2.109260320663452
I0305 03:33:01.961708 139881808373504 logging_writer.py:48] [481200] global_step=481200, grad_norm=3.136699914932251, loss=1.5314693450927734
I0305 03:33:05.744164 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:33:16.324838 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:33:47.184559 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:33:48.777580 140077943854912 submission_runner.py:411] Time since start: 232021.58s, 	Step: 481210, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.418246865272522, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 211768.6008861065, 'total_duration': 232021.58257460594, 'accumulated_submission_time': 211768.6008861065, 'accumulated_eval_time': 20188.25280070305, 'accumulated_logging_time': 39.7059965133667}
I0305 03:33:48.884725 139881799980800 logging_writer.py:48] [481210] accumulated_eval_time=20188.252801, accumulated_logging_time=39.705997, accumulated_submission_time=211768.600886, global_step=481210, preemption_count=0, score=211768.600886, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=232021.582575, train/accuracy=0.887676, train/loss=0.418247, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:34:25.915812 139881808373504 logging_writer.py:48] [481300] global_step=481300, grad_norm=3.1154682636260986, loss=1.1151227951049805
I0305 03:35:10.218343 139881799980800 logging_writer.py:48] [481400] global_step=481400, grad_norm=3.518911123275757, loss=1.124860167503357
I0305 03:35:54.463315 139881808373504 logging_writer.py:48] [481500] global_step=481500, grad_norm=3.716733694076538, loss=3.1670970916748047
I0305 03:36:39.150062 139881799980800 logging_writer.py:48] [481600] global_step=481600, grad_norm=3.311009645462036, loss=1.169283151626587
I0305 03:37:23.722334 139881808373504 logging_writer.py:48] [481700] global_step=481700, grad_norm=2.8357110023498535, loss=2.1871912479400635
I0305 03:38:08.215594 139881799980800 logging_writer.py:48] [481800] global_step=481800, grad_norm=3.275380849838257, loss=1.1102955341339111
I0305 03:38:52.587253 139881808373504 logging_writer.py:48] [481900] global_step=481900, grad_norm=3.228572130203247, loss=1.2340378761291504
I0305 03:39:36.899837 139881799980800 logging_writer.py:48] [482000] global_step=482000, grad_norm=3.0593554973602295, loss=1.0753071308135986
I0305 03:40:21.477828 139881808373504 logging_writer.py:48] [482100] global_step=482100, grad_norm=3.208249568939209, loss=1.9797526597976685
I0305 03:40:48.791424 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:40:59.033084 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:41:36.544488 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:41:38.127709 140077943854912 submission_runner.py:411] Time since start: 232490.93s, 	Step: 482163, 	{'train/accuracy': 0.8851562142372131, 'train/loss': 0.4248987138271332, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 212188.4453895092, 'total_duration': 232490.9327290058, 'accumulated_submission_time': 212188.4453895092, 'accumulated_eval_time': 20237.58907341957, 'accumulated_logging_time': 39.825878858566284}
I0305 03:41:38.220069 139881799980800 logging_writer.py:48] [482163] accumulated_eval_time=20237.589073, accumulated_logging_time=39.825879, accumulated_submission_time=212188.445390, global_step=482163, preemption_count=0, score=212188.445390, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=232490.932729, train/accuracy=0.885156, train/loss=0.424899, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:41:53.017472 139881808373504 logging_writer.py:48] [482200] global_step=482200, grad_norm=2.798779010772705, loss=1.1161906719207764
I0305 03:42:34.698112 139881799980800 logging_writer.py:48] [482300] global_step=482300, grad_norm=3.0747969150543213, loss=1.1213278770446777
I0305 03:43:19.202595 139881808373504 logging_writer.py:48] [482400] global_step=482400, grad_norm=3.288684844970703, loss=3.0582356452941895
I0305 03:44:03.854634 139881799980800 logging_writer.py:48] [482500] global_step=482500, grad_norm=3.3765811920166016, loss=1.0185602903366089
I0305 03:44:47.934591 139881808373504 logging_writer.py:48] [482600] global_step=482600, grad_norm=3.3695669174194336, loss=1.4418495893478394
I0305 03:45:32.601723 139881799980800 logging_writer.py:48] [482700] global_step=482700, grad_norm=3.1050469875335693, loss=2.738933801651001
I0305 03:46:16.877173 139881808373504 logging_writer.py:48] [482800] global_step=482800, grad_norm=4.264974594116211, loss=3.2761600017547607
I0305 03:47:01.126848 139881799980800 logging_writer.py:48] [482900] global_step=482900, grad_norm=3.266813039779663, loss=2.8469743728637695
I0305 03:47:45.655658 139881808373504 logging_writer.py:48] [483000] global_step=483000, grad_norm=2.9069736003875732, loss=1.8595423698425293
I0305 03:48:29.978036 139881799980800 logging_writer.py:48] [483100] global_step=483100, grad_norm=3.3722927570343018, loss=2.9089455604553223
I0305 03:48:38.484876 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:48:49.096757 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:49:17.254048 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:49:18.866052 140077943854912 submission_runner.py:411] Time since start: 232951.67s, 	Step: 483121, 	{'train/accuracy': 0.8895312547683716, 'train/loss': 0.41510409116744995, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 212608.65079832077, 'total_duration': 232951.67104578018, 'accumulated_submission_time': 212608.65079832077, 'accumulated_eval_time': 20277.970195531845, 'accumulated_logging_time': 39.92865061759949}
I0305 03:49:18.972623 139881808373504 logging_writer.py:48] [483121] accumulated_eval_time=20277.970196, accumulated_logging_time=39.928651, accumulated_submission_time=212608.650798, global_step=483121, preemption_count=0, score=212608.650798, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=232951.671046, train/accuracy=0.889531, train/loss=0.415104, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:49:50.270665 139881799980800 logging_writer.py:48] [483200] global_step=483200, grad_norm=5.179128170013428, loss=2.778958797454834
I0305 03:50:34.578543 139881808373504 logging_writer.py:48] [483300] global_step=483300, grad_norm=3.1221652030944824, loss=2.3360064029693604
I0305 03:51:19.126854 139881799980800 logging_writer.py:48] [483400] global_step=483400, grad_norm=3.0822246074676514, loss=1.1270337104797363
I0305 03:52:03.756099 139881808373504 logging_writer.py:48] [483500] global_step=483500, grad_norm=3.066627264022827, loss=2.210165500640869
I0305 03:52:48.028245 139881799980800 logging_writer.py:48] [483600] global_step=483600, grad_norm=3.3132712841033936, loss=1.1873798370361328
I0305 03:53:32.412469 139881808373504 logging_writer.py:48] [483700] global_step=483700, grad_norm=3.4074385166168213, loss=1.1896175146102905
I0305 03:54:16.766588 139881799980800 logging_writer.py:48] [483800] global_step=483800, grad_norm=4.090967178344727, loss=2.706533670425415
I0305 03:55:01.174130 139881808373504 logging_writer.py:48] [483900] global_step=483900, grad_norm=3.1570792198181152, loss=1.2028127908706665
I0305 03:55:45.815541 139881799980800 logging_writer.py:48] [484000] global_step=484000, grad_norm=3.09078311920166, loss=1.7521003484725952
I0305 03:56:18.987466 140077943854912 spec.py:321] Evaluating on the training split.
I0305 03:56:29.765018 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 03:56:57.113493 140077943854912 spec.py:349] Evaluating on the test split.
I0305 03:56:58.698394 140077943854912 submission_runner.py:411] Time since start: 233411.50s, 	Step: 484076, 	{'train/accuracy': 0.888964831829071, 'train/loss': 0.40960097312927246, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 213028.60218286514, 'total_duration': 233411.50339460373, 'accumulated_submission_time': 213028.60218286514, 'accumulated_eval_time': 20317.68110179901, 'accumulated_logging_time': 40.049169063568115}
I0305 03:56:58.808866 139881808373504 logging_writer.py:48] [484076] accumulated_eval_time=20317.681102, accumulated_logging_time=40.049169, accumulated_submission_time=213028.602183, global_step=484076, preemption_count=0, score=213028.602183, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=233411.503395, train/accuracy=0.888965, train/loss=0.409601, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 03:57:08.568230 139881799980800 logging_writer.py:48] [484100] global_step=484100, grad_norm=3.307847023010254, loss=1.4133563041687012
I0305 03:57:52.409910 139881808373504 logging_writer.py:48] [484200] global_step=484200, grad_norm=3.4432692527770996, loss=2.9795589447021484
I0305 03:58:37.995911 139881808373504 logging_writer.py:48] [484300] global_step=484300, grad_norm=3.1342430114746094, loss=2.341205596923828
I0305 03:59:23.305382 139881799980800 logging_writer.py:48] [484400] global_step=484400, grad_norm=2.895888090133667, loss=1.6018455028533936
I0305 04:00:08.663084 139881808373504 logging_writer.py:48] [484500] global_step=484500, grad_norm=3.4687767028808594, loss=1.1580121517181396
I0305 04:00:53.709937 139881799980800 logging_writer.py:48] [484600] global_step=484600, grad_norm=3.252335786819458, loss=1.1270476579666138
I0305 04:01:39.280110 139881808373504 logging_writer.py:48] [484700] global_step=484700, grad_norm=3.720642328262329, loss=3.237865924835205
I0305 04:02:24.386310 139881799980800 logging_writer.py:48] [484800] global_step=484800, grad_norm=3.012299060821533, loss=2.1802446842193604
I0305 04:03:09.731974 139881808373504 logging_writer.py:48] [484900] global_step=484900, grad_norm=3.025874137878418, loss=1.804568886756897
I0305 04:03:54.776416 139881799980800 logging_writer.py:48] [485000] global_step=485000, grad_norm=2.8121864795684814, loss=1.717491626739502
I0305 04:03:59.106396 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:04:09.577646 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:04:38.487664 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:04:40.072875 140077943854912 submission_runner.py:411] Time since start: 233872.88s, 	Step: 485011, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.4179162383079529, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 213448.84131765366, 'total_duration': 233872.87785935402, 'accumulated_submission_time': 213448.84131765366, 'accumulated_eval_time': 20358.64752459526, 'accumulated_logging_time': 40.17074942588806}
I0305 04:04:40.194042 139881808373504 logging_writer.py:48] [485011] accumulated_eval_time=20358.647525, accumulated_logging_time=40.170749, accumulated_submission_time=213448.841318, global_step=485011, preemption_count=0, score=213448.841318, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=233872.877859, train/accuracy=0.888320, train/loss=0.417916, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:05:17.470380 139881799980800 logging_writer.py:48] [485100] global_step=485100, grad_norm=3.2168567180633545, loss=1.100180983543396
I0305 04:06:02.512825 139881808373504 logging_writer.py:48] [485200] global_step=485200, grad_norm=2.814126491546631, loss=1.5206717252731323
I0305 04:06:48.005051 139881799980800 logging_writer.py:48] [485300] global_step=485300, grad_norm=3.09938645362854, loss=1.083728551864624
I0305 04:07:33.451731 139881808373504 logging_writer.py:48] [485400] global_step=485400, grad_norm=2.897305488586426, loss=1.0571235418319702
I0305 04:08:19.132207 139881799980800 logging_writer.py:48] [485500] global_step=485500, grad_norm=3.3240530490875244, loss=2.555605888366699
I0305 04:09:04.722030 139881808373504 logging_writer.py:48] [485600] global_step=485600, grad_norm=2.9640121459960938, loss=1.141225814819336
I0305 04:09:50.233364 139881799980800 logging_writer.py:48] [485700] global_step=485700, grad_norm=3.17685866355896, loss=2.5581984519958496
I0305 04:10:36.152752 139881808373504 logging_writer.py:48] [485800] global_step=485800, grad_norm=3.1571083068847656, loss=2.535125494003296
I0305 04:11:21.597849 139881799980800 logging_writer.py:48] [485900] global_step=485900, grad_norm=3.0747578144073486, loss=1.9688448905944824
I0305 04:11:40.361108 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:11:50.581537 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:12:27.654986 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:12:29.230544 140077943854912 submission_runner.py:411] Time since start: 234342.04s, 	Step: 485943, 	{'train/accuracy': 0.8872656226158142, 'train/loss': 0.42406395077705383, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 213868.94949388504, 'total_duration': 234342.0355579853, 'accumulated_submission_time': 213868.94949388504, 'accumulated_eval_time': 20407.51692557335, 'accumulated_logging_time': 40.30259609222412}
I0305 04:12:29.318902 139881808373504 logging_writer.py:48] [485943] accumulated_eval_time=20407.516926, accumulated_logging_time=40.302596, accumulated_submission_time=213868.949494, global_step=485943, preemption_count=0, score=213868.949494, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=234342.035558, train/accuracy=0.887266, train/loss=0.424064, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:12:51.942234 139881799980800 logging_writer.py:48] [486000] global_step=486000, grad_norm=3.1957826614379883, loss=1.2273838520050049
I0305 04:13:34.885119 139881808373504 logging_writer.py:48] [486100] global_step=486100, grad_norm=3.3119332790374756, loss=2.0880470275878906
I0305 04:14:19.471951 139881799980800 logging_writer.py:48] [486200] global_step=486200, grad_norm=3.4729177951812744, loss=1.6089667081832886
I0305 04:15:04.128933 139881808373504 logging_writer.py:48] [486300] global_step=486300, grad_norm=3.798229455947876, loss=3.26870059967041
I0305 04:15:48.334261 139881799980800 logging_writer.py:48] [486400] global_step=486400, grad_norm=3.289395332336426, loss=1.1677594184875488
I0305 04:16:33.194777 139881808373504 logging_writer.py:48] [486500] global_step=486500, grad_norm=3.7196383476257324, loss=3.320033550262451
I0305 04:17:17.603039 139881799980800 logging_writer.py:48] [486600] global_step=486600, grad_norm=3.316924571990967, loss=1.156253695487976
I0305 04:18:02.134256 139881808373504 logging_writer.py:48] [486700] global_step=486700, grad_norm=3.0596120357513428, loss=2.4940080642700195
I0305 04:18:46.591459 139881799980800 logging_writer.py:48] [486800] global_step=486800, grad_norm=3.001786947250366, loss=1.3048807382583618
I0305 04:19:29.628736 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:19:39.733098 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:20:13.989361 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:20:15.593769 140077943854912 submission_runner.py:411] Time since start: 234808.40s, 	Step: 486899, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.416032999753952, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 214289.19634270668, 'total_duration': 234808.39871358871, 'accumulated_submission_time': 214289.19634270668, 'accumulated_eval_time': 20453.481875658035, 'accumulated_logging_time': 40.40373396873474}
I0305 04:20:15.770386 139881808373504 logging_writer.py:48] [486899] accumulated_eval_time=20453.481876, accumulated_logging_time=40.403734, accumulated_submission_time=214289.196343, global_step=486899, preemption_count=0, score=214289.196343, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=234808.398714, train/accuracy=0.888320, train/loss=0.416033, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:20:16.564101 139881799980800 logging_writer.py:48] [486900] global_step=486900, grad_norm=3.2534053325653076, loss=2.640225887298584
I0305 04:20:57.191307 139881808373504 logging_writer.py:48] [487000] global_step=487000, grad_norm=3.214644193649292, loss=1.154299259185791
I0305 04:21:41.516468 139881799980800 logging_writer.py:48] [487100] global_step=487100, grad_norm=3.637857675552368, loss=2.9929592609405518
I0305 04:22:26.487060 139881808373504 logging_writer.py:48] [487200] global_step=487200, grad_norm=3.0066986083984375, loss=1.9666115045547485
I0305 04:23:10.844489 139881799980800 logging_writer.py:48] [487300] global_step=487300, grad_norm=3.092552900314331, loss=1.0849820375442505
I0305 04:23:55.265089 139881808373504 logging_writer.py:48] [487400] global_step=487400, grad_norm=3.0134057998657227, loss=1.1041853427886963
I0305 04:24:39.884916 139881799980800 logging_writer.py:48] [487500] global_step=487500, grad_norm=2.9447813034057617, loss=1.7756863832473755
I0305 04:25:24.018202 139881808373504 logging_writer.py:48] [487600] global_step=487600, grad_norm=3.3918368816375732, loss=1.0784353017807007
I0305 04:26:09.014035 139881799980800 logging_writer.py:48] [487700] global_step=487700, grad_norm=3.164822816848755, loss=2.839988946914673
I0305 04:26:54.409586 139881808373504 logging_writer.py:48] [487800] global_step=487800, grad_norm=3.1645684242248535, loss=1.0843569040298462
I0305 04:27:15.970141 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:27:26.528709 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:27:55.407726 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:27:56.991839 140077943854912 submission_runner.py:411] Time since start: 235269.80s, 	Step: 487850, 	{'train/accuracy': 0.8885351419448853, 'train/loss': 0.4118785858154297, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 214709.33081889153, 'total_duration': 235269.7968466282, 'accumulated_submission_time': 214709.33081889153, 'accumulated_eval_time': 20494.503543138504, 'accumulated_logging_time': 40.596789598464966}
I0305 04:27:57.101875 139881799980800 logging_writer.py:48] [487850] accumulated_eval_time=20494.503543, accumulated_logging_time=40.596790, accumulated_submission_time=214709.330819, global_step=487850, preemption_count=0, score=214709.330819, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=235269.796847, train/accuracy=0.888535, train/loss=0.411879, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:28:16.990367 139881808373504 logging_writer.py:48] [487900] global_step=487900, grad_norm=2.9604008197784424, loss=1.4873900413513184
I0305 04:29:01.810198 139881799980800 logging_writer.py:48] [488000] global_step=488000, grad_norm=3.4801299571990967, loss=2.850363254547119
I0305 04:29:47.224438 139881808373504 logging_writer.py:48] [488100] global_step=488100, grad_norm=3.242985725402832, loss=1.0629348754882812
I0305 04:30:32.522762 139881799980800 logging_writer.py:48] [488200] global_step=488200, grad_norm=3.231407403945923, loss=1.2085434198379517
I0305 04:31:17.643373 139881808373504 logging_writer.py:48] [488300] global_step=488300, grad_norm=2.933210849761963, loss=1.1854329109191895
I0305 04:32:03.400457 139881799980800 logging_writer.py:48] [488400] global_step=488400, grad_norm=3.725404977798462, loss=3.259063243865967
I0305 04:32:48.408461 139881808373504 logging_writer.py:48] [488500] global_step=488500, grad_norm=3.229804754257202, loss=1.090000867843628
I0305 04:33:33.683756 139881799980800 logging_writer.py:48] [488600] global_step=488600, grad_norm=3.795497179031372, loss=3.3206944465637207
I0305 04:34:18.917413 139881808373504 logging_writer.py:48] [488700] global_step=488700, grad_norm=3.1255180835723877, loss=2.2946243286132812
I0305 04:34:57.481099 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:35:08.049328 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:35:37.872723 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:35:39.464835 140077943854912 submission_runner.py:411] Time since start: 235732.27s, 	Step: 488786, 	{'train/accuracy': 0.8866210579872131, 'train/loss': 0.42158743739128113, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 215129.6508102417, 'total_duration': 235732.26984477043, 'accumulated_submission_time': 215129.6508102417, 'accumulated_eval_time': 20536.487267017365, 'accumulated_logging_time': 40.718414545059204}
I0305 04:35:39.577183 139881799980800 logging_writer.py:48] [488786] accumulated_eval_time=20536.487267, accumulated_logging_time=40.718415, accumulated_submission_time=215129.650810, global_step=488786, preemption_count=0, score=215129.650810, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=235732.269845, train/accuracy=0.886621, train/loss=0.421587, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:35:45.423354 139881808373504 logging_writer.py:48] [488800] global_step=488800, grad_norm=4.338479042053223, loss=2.8545515537261963
I0305 04:36:27.159720 139881799980800 logging_writer.py:48] [488900] global_step=488900, grad_norm=3.22078800201416, loss=1.1143320798873901
I0305 04:37:11.889070 139881808373504 logging_writer.py:48] [489000] global_step=489000, grad_norm=3.4078218936920166, loss=1.0716437101364136
I0305 04:37:56.481574 139881799980800 logging_writer.py:48] [489100] global_step=489100, grad_norm=3.614638090133667, loss=3.1603384017944336
I0305 04:38:41.340603 139881808373504 logging_writer.py:48] [489200] global_step=489200, grad_norm=3.252290725708008, loss=1.1244375705718994
I0305 04:39:26.066645 139881799980800 logging_writer.py:48] [489300] global_step=489300, grad_norm=3.114091396331787, loss=1.1703251600265503
I0305 04:40:10.493039 139881808373504 logging_writer.py:48] [489400] global_step=489400, grad_norm=2.7588372230529785, loss=1.3928611278533936
I0305 04:40:55.516564 139881799980800 logging_writer.py:48] [489500] global_step=489500, grad_norm=3.3357491493225098, loss=1.280562162399292
I0305 04:41:40.077528 139881808373504 logging_writer.py:48] [489600] global_step=489600, grad_norm=3.101883888244629, loss=1.1911784410476685
I0305 04:42:24.824056 139881799980800 logging_writer.py:48] [489700] global_step=489700, grad_norm=3.2921931743621826, loss=1.2347898483276367
I0305 04:42:39.824227 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:42:50.331137 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:43:23.083329 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:43:24.682915 140077943854912 submission_runner.py:411] Time since start: 236197.49s, 	Step: 489735, 	{'train/accuracy': 0.8875585794448853, 'train/loss': 0.41839706897735596, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 215549.8371298313, 'total_duration': 236197.48790836334, 'accumulated_submission_time': 215549.8371298313, 'accumulated_eval_time': 20581.345925331116, 'accumulated_logging_time': 40.841949224472046}
I0305 04:43:24.782464 139881808373504 logging_writer.py:48] [489735] accumulated_eval_time=20581.345925, accumulated_logging_time=40.841949, accumulated_submission_time=215549.837130, global_step=489735, preemption_count=0, score=215549.837130, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=236197.487908, train/accuracy=0.887559, train/loss=0.418397, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:43:50.545347 139881799980800 logging_writer.py:48] [489800] global_step=489800, grad_norm=2.989370584487915, loss=1.1114706993103027
I0305 04:44:34.244251 139881808373504 logging_writer.py:48] [489900] global_step=489900, grad_norm=3.296123743057251, loss=1.1425526142120361
I0305 04:45:18.634997 139881799980800 logging_writer.py:48] [490000] global_step=490000, grad_norm=3.1464338302612305, loss=1.611173152923584
I0305 04:46:03.224078 139881808373504 logging_writer.py:48] [490100] global_step=490100, grad_norm=3.1611533164978027, loss=1.512405514717102
I0305 04:46:47.782877 139881799980800 logging_writer.py:48] [490200] global_step=490200, grad_norm=3.078728437423706, loss=1.1627476215362549
I0305 04:47:32.432570 139881808373504 logging_writer.py:48] [490300] global_step=490300, grad_norm=3.16120982170105, loss=1.5143572092056274
I0305 04:48:16.509506 139881799980800 logging_writer.py:48] [490400] global_step=490400, grad_norm=3.8769118785858154, loss=1.8071677684783936
I0305 04:49:01.242669 139881808373504 logging_writer.py:48] [490500] global_step=490500, grad_norm=3.129061460494995, loss=1.116027593612671
I0305 04:49:46.101387 139881799980800 logging_writer.py:48] [490600] global_step=490600, grad_norm=2.929072856903076, loss=1.2314941883087158
I0305 04:50:25.105664 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:50:35.399654 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:51:04.362485 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:51:05.948232 140077943854912 submission_runner.py:411] Time since start: 236658.75s, 	Step: 490689, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.4221860468387604, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 215970.10089540482, 'total_duration': 236658.7532222271, 'accumulated_submission_time': 215970.10089540482, 'accumulated_eval_time': 20622.188474416733, 'accumulated_logging_time': 40.951939821243286}
I0305 04:51:06.054379 139881808373504 logging_writer.py:48] [490689] accumulated_eval_time=20622.188474, accumulated_logging_time=40.951940, accumulated_submission_time=215970.100895, global_step=490689, preemption_count=0, score=215970.100895, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=236658.753222, train/accuracy=0.887598, train/loss=0.422186, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:51:10.770592 139881799980800 logging_writer.py:48] [490700] global_step=490700, grad_norm=3.09624981880188, loss=2.101830005645752
I0305 04:51:52.408287 139881808373504 logging_writer.py:48] [490800] global_step=490800, grad_norm=3.2228336334228516, loss=2.6933677196502686
I0305 04:52:36.839319 139881799980800 logging_writer.py:48] [490900] global_step=490900, grad_norm=3.2016899585723877, loss=2.3140604496002197
I0305 04:53:21.713601 139881808373504 logging_writer.py:48] [491000] global_step=491000, grad_norm=3.416152238845825, loss=1.1197566986083984
I0305 04:54:06.432155 139881799980800 logging_writer.py:48] [491100] global_step=491100, grad_norm=2.972039222717285, loss=1.113715648651123
I0305 04:54:51.150245 139881808373504 logging_writer.py:48] [491200] global_step=491200, grad_norm=3.057722568511963, loss=2.100515127182007
I0305 04:55:35.924474 139881799980800 logging_writer.py:48] [491300] global_step=491300, grad_norm=3.5109286308288574, loss=1.1666662693023682
I0305 04:56:20.745007 139881808373504 logging_writer.py:48] [491400] global_step=491400, grad_norm=3.276684045791626, loss=1.9176615476608276
I0305 04:57:05.424718 139881799980800 logging_writer.py:48] [491500] global_step=491500, grad_norm=2.8410348892211914, loss=1.639891266822815
I0305 04:57:49.769555 139881808373504 logging_writer.py:48] [491600] global_step=491600, grad_norm=2.962956666946411, loss=2.116079092025757
I0305 04:58:06.017617 140077943854912 spec.py:321] Evaluating on the training split.
I0305 04:58:16.361522 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 04:58:44.600081 140077943854912 spec.py:349] Evaluating on the test split.
I0305 04:58:46.188147 140077943854912 submission_runner.py:411] Time since start: 237118.99s, 	Step: 491638, 	{'train/accuracy': 0.88623046875, 'train/loss': 0.4179167151451111, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 216390.0034880638, 'total_duration': 237118.99315714836, 'accumulated_submission_time': 216390.0034880638, 'accumulated_eval_time': 20662.358990192413, 'accumulated_logging_time': 41.06981325149536}
I0305 04:58:46.298435 139881799980800 logging_writer.py:48] [491638] accumulated_eval_time=20662.358990, accumulated_logging_time=41.069813, accumulated_submission_time=216390.003488, global_step=491638, preemption_count=0, score=216390.003488, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=237118.993157, train/accuracy=0.886230, train/loss=0.417917, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 04:59:10.886028 139881808373504 logging_writer.py:48] [491700] global_step=491700, grad_norm=3.141465187072754, loss=1.2767053842544556
I0305 04:59:54.904091 139881799980800 logging_writer.py:48] [491800] global_step=491800, grad_norm=3.501272201538086, loss=3.0432286262512207
I0305 05:00:39.368227 139881808373504 logging_writer.py:48] [491900] global_step=491900, grad_norm=2.9516406059265137, loss=1.15521240234375
I0305 05:01:23.921285 139881799980800 logging_writer.py:48] [492000] global_step=492000, grad_norm=3.0125794410705566, loss=1.1640710830688477
I0305 05:02:08.334309 139881808373504 logging_writer.py:48] [492100] global_step=492100, grad_norm=3.210031270980835, loss=1.2795665264129639
I0305 05:02:52.790358 139881799980800 logging_writer.py:48] [492200] global_step=492200, grad_norm=3.052361011505127, loss=1.848188042640686
I0305 05:03:37.240451 139881808373504 logging_writer.py:48] [492300] global_step=492300, grad_norm=3.204843282699585, loss=2.6555070877075195
I0305 05:04:21.651503 139881799980800 logging_writer.py:48] [492400] global_step=492400, grad_norm=2.996696710586548, loss=1.1311464309692383
I0305 05:05:06.513709 139881808373504 logging_writer.py:48] [492500] global_step=492500, grad_norm=3.201101064682007, loss=1.9674792289733887
I0305 05:05:46.588772 140077943854912 spec.py:321] Evaluating on the training split.
I0305 05:05:56.876377 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 05:06:35.933109 140077943854912 spec.py:349] Evaluating on the test split.
I0305 05:06:37.527448 140077943854912 submission_runner.py:411] Time since start: 237590.33s, 	Step: 492593, 	{'train/accuracy': 0.888964831829071, 'train/loss': 0.41569605469703674, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 216810.23352575302, 'total_duration': 237590.33246302605, 'accumulated_submission_time': 216810.23352575302, 'accumulated_eval_time': 20713.29764199257, 'accumulated_logging_time': 41.19071340560913}
I0305 05:06:37.617104 139881799980800 logging_writer.py:48] [492593] accumulated_eval_time=20713.297642, accumulated_logging_time=41.190713, accumulated_submission_time=216810.233526, global_step=492593, preemption_count=0, score=216810.233526, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=237590.332463, train/accuracy=0.888965, train/loss=0.415696, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 05:06:40.729250 139881808373504 logging_writer.py:48] [492600] global_step=492600, grad_norm=3.3723039627075195, loss=1.274277925491333
I0305 05:07:20.855894 139881799980800 logging_writer.py:48] [492700] global_step=492700, grad_norm=3.345858335494995, loss=1.022997260093689
I0305 05:08:05.198485 139881808373504 logging_writer.py:48] [492800] global_step=492800, grad_norm=3.087212324142456, loss=1.0941126346588135
I0305 05:08:49.474203 139881799980800 logging_writer.py:48] [492900] global_step=492900, grad_norm=3.2083723545074463, loss=1.1968488693237305
I0305 05:09:34.029165 139881808373504 logging_writer.py:48] [493000] global_step=493000, grad_norm=3.02925705909729, loss=1.1653263568878174
I0305 05:10:18.525357 139881799980800 logging_writer.py:48] [493100] global_step=493100, grad_norm=3.078192949295044, loss=1.1073062419891357
I0305 05:11:02.732428 139881808373504 logging_writer.py:48] [493200] global_step=493200, grad_norm=3.2900476455688477, loss=1.346436619758606
I0305 05:11:46.936476 139881799980800 logging_writer.py:48] [493300] global_step=493300, grad_norm=2.989708662033081, loss=1.1385446786880493
I0305 05:12:31.258430 139881808373504 logging_writer.py:48] [493400] global_step=493400, grad_norm=2.931062698364258, loss=1.7409917116165161
I0305 05:13:15.436040 139881799980800 logging_writer.py:48] [493500] global_step=493500, grad_norm=3.8105850219726562, loss=3.0832254886627197
I0305 05:13:37.668618 140077943854912 spec.py:321] Evaluating on the training split.
I0305 05:13:47.804363 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 05:14:24.760972 140077943854912 spec.py:349] Evaluating on the test split.
I0305 05:14:26.338251 140077943854912 submission_runner.py:411] Time since start: 238059.14s, 	Step: 493552, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.4139544665813446, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 217230.22564339638, 'total_duration': 238059.1432621479, 'accumulated_submission_time': 217230.22564339638, 'accumulated_eval_time': 20761.96725344658, 'accumulated_logging_time': 41.290077686309814}
I0305 05:14:26.429903 139881808373504 logging_writer.py:48] [493552] accumulated_eval_time=20761.967253, accumulated_logging_time=41.290078, accumulated_submission_time=217230.225643, global_step=493552, preemption_count=0, score=217230.225643, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=238059.143262, train/accuracy=0.887910, train/loss=0.413954, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 05:14:45.530638 139881799980800 logging_writer.py:48] [493600] global_step=493600, grad_norm=3.2834134101867676, loss=3.0599257946014404
I0305 05:15:27.948135 139881808373504 logging_writer.py:48] [493700] global_step=493700, grad_norm=3.048123359680176, loss=1.2000982761383057
I0305 05:16:12.088903 139881799980800 logging_writer.py:48] [493800] global_step=493800, grad_norm=3.2210423946380615, loss=1.2524772882461548
I0305 05:16:56.822825 139881808373504 logging_writer.py:48] [493900] global_step=493900, grad_norm=2.982372999191284, loss=1.0397207736968994
I0305 05:17:41.313912 139881799980800 logging_writer.py:48] [494000] global_step=494000, grad_norm=3.356983184814453, loss=1.1029431819915771
I0305 05:18:25.780152 139881808373504 logging_writer.py:48] [494100] global_step=494100, grad_norm=3.2868635654449463, loss=1.3872801065444946
I0305 05:19:10.682468 139881799980800 logging_writer.py:48] [494200] global_step=494200, grad_norm=3.199392795562744, loss=2.5146236419677734
I0305 05:19:54.761643 139881808373504 logging_writer.py:48] [494300] global_step=494300, grad_norm=2.914954662322998, loss=1.6106772422790527
I0305 05:20:39.586442 139881799980800 logging_writer.py:48] [494400] global_step=494400, grad_norm=3.0653905868530273, loss=1.9307090044021606
I0305 05:21:24.392493 139881808373504 logging_writer.py:48] [494500] global_step=494500, grad_norm=3.0836150646209717, loss=2.1478359699249268
I0305 05:21:26.609954 140077943854912 spec.py:321] Evaluating on the training split.
I0305 05:21:37.124175 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 05:22:05.019291 140077943854912 spec.py:349] Evaluating on the test split.
I0305 05:22:06.604173 140077943854912 submission_runner.py:411] Time since start: 238519.41s, 	Step: 494507, 	{'train/accuracy': 0.887988269329071, 'train/loss': 0.41721731424331665, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 217650.34621620178, 'total_duration': 238519.40918159485, 'accumulated_submission_time': 217650.34621620178, 'accumulated_eval_time': 20801.961450099945, 'accumulated_logging_time': 41.39179611206055}
I0305 05:22:06.715123 139881799980800 logging_writer.py:48] [494507] accumulated_eval_time=20801.961450, accumulated_logging_time=41.391796, accumulated_submission_time=217650.346216, global_step=494507, preemption_count=0, score=217650.346216, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=238519.409182, train/accuracy=0.887988, train/loss=0.417217, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 05:22:45.517372 139881808373504 logging_writer.py:48] [494600] global_step=494600, grad_norm=2.8712263107299805, loss=1.8150608539581299
I0305 05:23:30.465664 139881799980800 logging_writer.py:48] [494700] global_step=494700, grad_norm=3.112792491912842, loss=1.2293137311935425
I0305 05:24:15.408287 139881808373504 logging_writer.py:48] [494800] global_step=494800, grad_norm=3.2117154598236084, loss=2.921393394470215
I0305 05:25:00.258232 139881799980800 logging_writer.py:48] [494900] global_step=494900, grad_norm=3.2576370239257812, loss=1.171111822128296
I0305 05:25:45.223028 139881808373504 logging_writer.py:48] [495000] global_step=495000, grad_norm=3.104783535003662, loss=1.2237554788589478
I0305 05:26:30.152783 139881799980800 logging_writer.py:48] [495100] global_step=495100, grad_norm=3.297781467437744, loss=1.1262773275375366
I0305 05:27:15.031739 139881808373504 logging_writer.py:48] [495200] global_step=495200, grad_norm=3.2750649452209473, loss=1.1902364492416382
I0305 05:28:00.182915 139881799980800 logging_writer.py:48] [495300] global_step=495300, grad_norm=4.871346950531006, loss=3.2150633335113525
I0305 05:28:45.396215 139881808373504 logging_writer.py:48] [495400] global_step=495400, grad_norm=2.880333423614502, loss=1.0814288854599
I0305 05:29:06.907169 140077943854912 spec.py:321] Evaluating on the training split.
I0305 05:29:17.351118 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 05:29:45.568152 140077943854912 spec.py:349] Evaluating on the test split.
I0305 05:29:47.165161 140077943854912 submission_runner.py:411] Time since start: 238979.97s, 	Step: 495449, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.41678082942962646, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 218070.4790790081, 'total_duration': 238979.97016358376, 'accumulated_submission_time': 218070.4790790081, 'accumulated_eval_time': 20842.219407081604, 'accumulated_logging_time': 41.5134813785553}
I0305 05:29:47.277396 139881799980800 logging_writer.py:48] [495449] accumulated_eval_time=20842.219407, accumulated_logging_time=41.513481, accumulated_submission_time=218070.479079, global_step=495449, preemption_count=0, score=218070.479079, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=238979.970164, train/accuracy=0.888066, train/loss=0.416781, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 05:30:07.588831 139881808373504 logging_writer.py:48] [495500] global_step=495500, grad_norm=3.5597915649414062, loss=1.6943588256835938
I0305 05:30:52.506293 139881799980800 logging_writer.py:48] [495600] global_step=495600, grad_norm=3.018446922302246, loss=1.1203811168670654
I0305 05:31:37.595202 139881808373504 logging_writer.py:48] [495700] global_step=495700, grad_norm=3.1356587409973145, loss=1.0830204486846924
I0305 05:32:22.641042 139881799980800 logging_writer.py:48] [495800] global_step=495800, grad_norm=3.2717702388763428, loss=2.722087860107422
I0305 05:33:08.036099 139881808373504 logging_writer.py:48] [495900] global_step=495900, grad_norm=4.0863542556762695, loss=2.5011792182922363
I0305 05:33:53.451672 139881799980800 logging_writer.py:48] [496000] global_step=496000, grad_norm=3.1859493255615234, loss=1.2538267374038696
I0305 05:34:38.823734 139881808373504 logging_writer.py:48] [496100] global_step=496100, grad_norm=3.634843587875366, loss=3.1831068992614746
I0305 05:35:24.178664 139881799980800 logging_writer.py:48] [496200] global_step=496200, grad_norm=3.0574963092803955, loss=1.388486623764038
I0305 05:36:09.488336 139881808373504 logging_writer.py:48] [496300] global_step=496300, grad_norm=3.0870583057403564, loss=1.0866186618804932
I0305 05:36:47.344637 140077943854912 spec.py:321] Evaluating on the training split.
I0305 05:36:57.482681 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 05:37:37.189262 140077943854912 spec.py:349] Evaluating on the test split.
I0305 05:37:38.773633 140077943854912 submission_runner.py:411] Time since start: 239451.58s, 	Step: 496385, 	{'train/accuracy': 0.8890038728713989, 'train/loss': 0.4185583293437958, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 218490.48626589775, 'total_duration': 239451.57863640785, 'accumulated_submission_time': 218490.48626589775, 'accumulated_eval_time': 20893.64836382866, 'accumulated_logging_time': 41.63759517669678}
I0305 05:37:38.865355 139881799980800 logging_writer.py:48] [496385] accumulated_eval_time=20893.648364, accumulated_logging_time=41.637595, accumulated_submission_time=218490.486266, global_step=496385, preemption_count=0, score=218490.486266, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=239451.578636, train/accuracy=0.889004, train/loss=0.418558, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 05:37:45.096460 139881808373504 logging_writer.py:48] [496400] global_step=496400, grad_norm=3.1453053951263428, loss=1.065295934677124
I0305 05:38:26.085192 139881799980800 logging_writer.py:48] [496500] global_step=496500, grad_norm=3.3608007431030273, loss=1.762277603149414
I0305 05:39:10.459895 139881808373504 logging_writer.py:48] [496600] global_step=496600, grad_norm=3.7470500469207764, loss=3.2465405464172363
I0305 05:39:55.238856 139881799980800 logging_writer.py:48] [496700] global_step=496700, grad_norm=3.1605405807495117, loss=1.1587421894073486
I0305 05:40:39.773873 139881808373504 logging_writer.py:48] [496800] global_step=496800, grad_norm=3.401503801345825, loss=2.3292927742004395
I0305 05:41:24.161661 139881799980800 logging_writer.py:48] [496900] global_step=496900, grad_norm=2.859762668609619, loss=1.1184474229812622
I0305 05:42:08.729216 139881808373504 logging_writer.py:48] [497000] global_step=497000, grad_norm=3.100795030593872, loss=1.4694433212280273
I0305 05:42:53.206179 139881799980800 logging_writer.py:48] [497100] global_step=497100, grad_norm=3.9118492603302, loss=3.342273712158203
I0305 05:43:37.869576 139881808373504 logging_writer.py:48] [497200] global_step=497200, grad_norm=2.988271474838257, loss=1.9007924795150757
I0305 05:44:22.319380 139881799980800 logging_writer.py:48] [497300] global_step=497300, grad_norm=3.2658512592315674, loss=2.8686363697052
I0305 05:44:39.098062 140077943854912 spec.py:321] Evaluating on the training split.
I0305 05:44:49.494340 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 05:45:26.026841 140077943854912 spec.py:349] Evaluating on the test split.
I0305 05:45:27.600519 140077943854912 submission_runner.py:411] Time since start: 239920.41s, 	Step: 497340, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.4235077500343323, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 218910.6556572914, 'total_duration': 239920.40553569794, 'accumulated_submission_time': 218910.6556572914, 'accumulated_eval_time': 20942.15079689026, 'accumulated_logging_time': 41.740726947784424}
I0305 05:45:27.691732 139881808373504 logging_writer.py:48] [497340] accumulated_eval_time=20942.150797, accumulated_logging_time=41.740727, accumulated_submission_time=218910.655657, global_step=497340, preemption_count=0, score=218910.655657, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=239920.405536, train/accuracy=0.887383, train/loss=0.423508, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 05:45:51.502024 139881799980800 logging_writer.py:48] [497400] global_step=497400, grad_norm=3.114439010620117, loss=1.5290064811706543
I0305 05:46:34.605230 139881808373504 logging_writer.py:48] [497500] global_step=497500, grad_norm=2.863950252532959, loss=1.8678420782089233
I0305 05:47:19.081422 139881799980800 logging_writer.py:48] [497600] global_step=497600, grad_norm=3.1472272872924805, loss=2.4440019130706787
I0305 05:48:03.891017 139881808373504 logging_writer.py:48] [497700] global_step=497700, grad_norm=3.2116892337799072, loss=1.1969048976898193
I0305 05:48:47.835367 139881799980800 logging_writer.py:48] [497800] global_step=497800, grad_norm=4.20184850692749, loss=1.1389844417572021
I0305 05:49:32.253793 139881808373504 logging_writer.py:48] [497900] global_step=497900, grad_norm=3.339914321899414, loss=1.2121413946151733
I0305 05:50:17.124608 139881799980800 logging_writer.py:48] [498000] global_step=498000, grad_norm=3.172118902206421, loss=2.5131020545959473
I0305 05:51:01.378191 139881808373504 logging_writer.py:48] [498100] global_step=498100, grad_norm=2.970893383026123, loss=1.9919776916503906
I0305 05:51:45.983727 139881799980800 logging_writer.py:48] [498200] global_step=498200, grad_norm=2.893688678741455, loss=1.1913236379623413
I0305 05:52:28.057844 140077943854912 spec.py:321] Evaluating on the training split.
I0305 05:52:39.347689 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 05:53:11.044849 140077943854912 spec.py:349] Evaluating on the test split.
I0305 05:53:12.632798 140077943854912 submission_runner.py:411] Time since start: 240385.44s, 	Step: 498296, 	{'train/accuracy': 0.8897070288658142, 'train/loss': 0.4100601077079773, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 219330.96313977242, 'total_duration': 240385.43779563904, 'accumulated_submission_time': 219330.96313977242, 'accumulated_eval_time': 20986.72572159767, 'accumulated_logging_time': 41.841379165649414}
I0305 05:53:12.755234 139881808373504 logging_writer.py:48] [498296] accumulated_eval_time=20986.725722, accumulated_logging_time=41.841379, accumulated_submission_time=219330.963140, global_step=498296, preemption_count=0, score=219330.963140, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=240385.437796, train/accuracy=0.889707, train/loss=0.410060, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 05:53:14.706156 139881799980800 logging_writer.py:48] [498300] global_step=498300, grad_norm=4.213931083679199, loss=3.264345645904541
I0305 05:53:55.361234 139881808373504 logging_writer.py:48] [498400] global_step=498400, grad_norm=3.4304211139678955, loss=3.0666356086730957
I0305 05:54:39.613990 139881799980800 logging_writer.py:48] [498500] global_step=498500, grad_norm=3.7014782428741455, loss=3.1309032440185547
I0305 05:55:24.415776 139881808373504 logging_writer.py:48] [498600] global_step=498600, grad_norm=3.0813326835632324, loss=1.1346122026443481
I0305 05:56:09.193897 139881799980800 logging_writer.py:48] [498700] global_step=498700, grad_norm=3.302426338195801, loss=1.1216193437576294
I0305 05:56:53.583756 139881808373504 logging_writer.py:48] [498800] global_step=498800, grad_norm=3.157747745513916, loss=1.454050064086914
I0305 05:57:37.971003 139881799980800 logging_writer.py:48] [498900] global_step=498900, grad_norm=3.3479807376861572, loss=1.1612956523895264
I0305 05:58:22.709995 139881808373504 logging_writer.py:48] [499000] global_step=499000, grad_norm=3.0765810012817383, loss=1.1518603563308716
I0305 05:59:07.292726 139881799980800 logging_writer.py:48] [499100] global_step=499100, grad_norm=3.3382599353790283, loss=2.2363977432250977
I0305 05:59:52.244882 139881808373504 logging_writer.py:48] [499200] global_step=499200, grad_norm=3.0576493740081787, loss=1.4396623373031616
I0305 06:00:13.036866 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:00:23.862649 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:00:56.905031 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:00:58.489794 140077943854912 submission_runner.py:411] Time since start: 240851.29s, 	Step: 499248, 	{'train/accuracy': 0.8898437023162842, 'train/loss': 0.41334936022758484, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 219751.18331694603, 'total_duration': 240851.29478430748, 'accumulated_submission_time': 219751.18331694603, 'accumulated_eval_time': 21032.178614139557, 'accumulated_logging_time': 41.97613787651062}
I0305 06:00:58.608582 139881799980800 logging_writer.py:48] [499248] accumulated_eval_time=21032.178614, accumulated_logging_time=41.976138, accumulated_submission_time=219751.183317, global_step=499248, preemption_count=0, score=219751.183317, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=240851.294784, train/accuracy=0.889844, train/loss=0.413349, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:01:19.320660 139881808373504 logging_writer.py:48] [499300] global_step=499300, grad_norm=3.482914686203003, loss=2.841371774673462
I0305 06:02:03.193342 139881799980800 logging_writer.py:48] [499400] global_step=499400, grad_norm=3.066128730773926, loss=1.0129070281982422
I0305 06:02:47.532438 139881808373504 logging_writer.py:48] [499500] global_step=499500, grad_norm=3.473275661468506, loss=2.275620937347412
I0305 06:03:32.120806 139881799980800 logging_writer.py:48] [499600] global_step=499600, grad_norm=3.048971652984619, loss=1.426551342010498
I0305 06:04:16.926079 139881808373504 logging_writer.py:48] [499700] global_step=499700, grad_norm=3.039836883544922, loss=1.2399566173553467
I0305 06:05:01.596234 139881799980800 logging_writer.py:48] [499800] global_step=499800, grad_norm=3.3452043533325195, loss=1.1885242462158203
I0305 06:05:46.214178 139881808373504 logging_writer.py:48] [499900] global_step=499900, grad_norm=4.188578128814697, loss=3.2070159912109375
I0305 06:06:30.837792 139881799980800 logging_writer.py:48] [500000] global_step=500000, grad_norm=3.3697962760925293, loss=2.4634087085723877
I0305 06:07:15.470133 139881808373504 logging_writer.py:48] [500100] global_step=500100, grad_norm=3.0445973873138428, loss=1.8473212718963623
I0305 06:07:58.711992 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:08:09.819344 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:08:39.409625 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:08:40.998254 140077943854912 submission_runner.py:411] Time since start: 241313.80s, 	Step: 500199, 	{'train/accuracy': 0.8876171708106995, 'train/loss': 0.41181108355522156, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 220171.2231209278, 'total_duration': 241313.80325770378, 'accumulated_submission_time': 220171.2231209278, 'accumulated_eval_time': 21074.464852809906, 'accumulated_logging_time': 42.10923957824707}
I0305 06:08:41.114444 139881799980800 logging_writer.py:48] [500199] accumulated_eval_time=21074.464853, accumulated_logging_time=42.109240, accumulated_submission_time=220171.223121, global_step=500199, preemption_count=0, score=220171.223121, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=241313.803258, train/accuracy=0.887617, train/loss=0.411811, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:08:41.920495 139881808373504 logging_writer.py:48] [500200] global_step=500200, grad_norm=3.000974655151367, loss=1.4397310018539429
I0305 06:09:23.257252 139881799980800 logging_writer.py:48] [500300] global_step=500300, grad_norm=2.9479641914367676, loss=1.2604763507843018
I0305 06:10:08.054226 139881808373504 logging_writer.py:48] [500400] global_step=500400, grad_norm=2.9194328784942627, loss=1.171267032623291
I0305 06:10:52.822649 139881799980800 logging_writer.py:48] [500500] global_step=500500, grad_norm=3.1723949909210205, loss=1.1149699687957764
I0305 06:11:37.887070 139881808373504 logging_writer.py:48] [500600] global_step=500600, grad_norm=3.0708022117614746, loss=1.4068423509597778
I0305 06:12:22.821801 139881799980800 logging_writer.py:48] [500700] global_step=500700, grad_norm=3.0794622898101807, loss=1.0948296785354614
I0305 06:13:07.504898 139881808373504 logging_writer.py:48] [500800] global_step=500800, grad_norm=2.882162570953369, loss=1.9222770929336548
I0305 06:13:52.354680 139881799980800 logging_writer.py:48] [500900] global_step=500900, grad_norm=3.8110949993133545, loss=3.2496531009674072
I0305 06:14:37.009962 139881808373504 logging_writer.py:48] [501000] global_step=501000, grad_norm=3.1277413368225098, loss=2.481667995452881
I0305 06:15:21.670684 139881799980800 logging_writer.py:48] [501100] global_step=501100, grad_norm=4.465434551239014, loss=2.5220742225646973
I0305 06:15:41.340195 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:15:51.813405 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:16:26.222164 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:16:27.819160 140077943854912 submission_runner.py:411] Time since start: 241780.62s, 	Step: 501146, 	{'train/accuracy': 0.8863085508346558, 'train/loss': 0.42149341106414795, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 220591.38791012764, 'total_duration': 241780.624147892, 'accumulated_submission_time': 220591.38791012764, 'accumulated_eval_time': 21120.943769693375, 'accumulated_logging_time': 42.23678421974182}
I0305 06:16:27.932311 139881808373504 logging_writer.py:48] [501146] accumulated_eval_time=21120.943770, accumulated_logging_time=42.236784, accumulated_submission_time=220591.387910, global_step=501146, preemption_count=0, score=220591.387910, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=241780.624148, train/accuracy=0.886309, train/loss=0.421493, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:16:49.382606 139881799980800 logging_writer.py:48] [501200] global_step=501200, grad_norm=3.1395342350006104, loss=1.647832989692688
I0305 06:17:32.495248 139881808373504 logging_writer.py:48] [501300] global_step=501300, grad_norm=3.11842679977417, loss=1.9185091257095337
I0305 06:18:17.034008 139881799980800 logging_writer.py:48] [501400] global_step=501400, grad_norm=2.920410633087158, loss=2.1787517070770264
I0305 06:19:01.595568 139881808373504 logging_writer.py:48] [501500] global_step=501500, grad_norm=3.555746555328369, loss=3.1439833641052246
I0305 06:19:45.989755 139881799980800 logging_writer.py:48] [501600] global_step=501600, grad_norm=3.6060736179351807, loss=3.0517101287841797
I0305 06:20:30.761816 139881808373504 logging_writer.py:48] [501700] global_step=501700, grad_norm=2.958820343017578, loss=1.9579458236694336
I0305 06:21:15.345742 139881799980800 logging_writer.py:48] [501800] global_step=501800, grad_norm=3.0045065879821777, loss=1.168721079826355
I0305 06:21:59.839218 139881808373504 logging_writer.py:48] [501900] global_step=501900, grad_norm=3.856180429458618, loss=3.257390022277832
I0305 06:22:44.381387 139881799980800 logging_writer.py:48] [502000] global_step=502000, grad_norm=3.9157540798187256, loss=3.27321195602417
I0305 06:23:28.216245 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:23:38.741408 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:24:06.799659 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:24:08.382574 140077943854912 submission_runner.py:411] Time since start: 242241.19s, 	Step: 502100, 	{'train/accuracy': 0.8866991996765137, 'train/loss': 0.4188326299190521, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 221011.6120646, 'total_duration': 242241.1875770092, 'accumulated_submission_time': 221011.6120646, 'accumulated_eval_time': 21161.110082149506, 'accumulated_logging_time': 42.36047720909119}
I0305 06:24:08.496638 139881808373504 logging_writer.py:48] [502100] accumulated_eval_time=21161.110082, accumulated_logging_time=42.360477, accumulated_submission_time=221011.612065, global_step=502100, preemption_count=0, score=221011.612065, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=242241.187577, train/accuracy=0.886699, train/loss=0.418833, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:24:08.910147 139881799980800 logging_writer.py:48] [502100] global_step=502100, grad_norm=3.0101497173309326, loss=1.2943975925445557
I0305 06:24:50.983145 139881808373504 logging_writer.py:48] [502200] global_step=502200, grad_norm=2.976304531097412, loss=1.0976262092590332
I0305 06:25:36.604867 139881799980800 logging_writer.py:48] [502300] global_step=502300, grad_norm=2.979052782058716, loss=2.497288703918457
I0305 06:26:21.805517 139881808373504 logging_writer.py:48] [502400] global_step=502400, grad_norm=3.4494357109069824, loss=1.1237058639526367
I0305 06:27:06.897479 139881799980800 logging_writer.py:48] [502500] global_step=502500, grad_norm=2.9440722465515137, loss=1.4650812149047852
I0305 06:27:51.884385 139881808373504 logging_writer.py:48] [502600] global_step=502600, grad_norm=3.0341970920562744, loss=1.172102451324463
I0305 06:28:36.989792 139881799980800 logging_writer.py:48] [502700] global_step=502700, grad_norm=3.990405797958374, loss=3.293112277984619
I0305 06:29:22.431056 139881808373504 logging_writer.py:48] [502800] global_step=502800, grad_norm=3.0580177307128906, loss=1.0599784851074219
I0305 06:30:07.926361 139881799980800 logging_writer.py:48] [502900] global_step=502900, grad_norm=3.5015389919281006, loss=2.960865020751953
I0305 06:30:53.031603 139881808373504 logging_writer.py:48] [503000] global_step=503000, grad_norm=3.0879690647125244, loss=1.1465954780578613
I0305 06:31:08.586625 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:31:19.165682 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:31:54.446419 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:31:56.033303 140077943854912 submission_runner.py:411] Time since start: 242708.84s, 	Step: 503036, 	{'train/accuracy': 0.8915234208106995, 'train/loss': 0.4066730737686157, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 221431.6432979107, 'total_duration': 242708.8383128643, 'accumulated_submission_time': 221431.6432979107, 'accumulated_eval_time': 21208.55673956871, 'accumulated_logging_time': 42.48579788208008}
I0305 06:31:56.147230 139881799980800 logging_writer.py:48] [503036] accumulated_eval_time=21208.556740, accumulated_logging_time=42.485798, accumulated_submission_time=221431.643298, global_step=503036, preemption_count=0, score=221431.643298, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=242708.838313, train/accuracy=0.891523, train/loss=0.406673, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:32:21.541010 139881808373504 logging_writer.py:48] [503100] global_step=503100, grad_norm=2.8344318866729736, loss=1.8563412427902222
I0305 06:33:05.710386 139881799980800 logging_writer.py:48] [503200] global_step=503200, grad_norm=3.284775972366333, loss=1.843443751335144
I0305 06:33:50.359797 139881808373504 logging_writer.py:48] [503300] global_step=503300, grad_norm=3.0557613372802734, loss=2.45251202583313
I0305 06:34:35.035412 139881799980800 logging_writer.py:48] [503400] global_step=503400, grad_norm=2.9831745624542236, loss=2.37778377532959
I0305 06:35:19.954097 139881808373504 logging_writer.py:48] [503500] global_step=503500, grad_norm=4.474251747131348, loss=3.0959181785583496
I0305 06:36:04.596426 139881799980800 logging_writer.py:48] [503600] global_step=503600, grad_norm=3.060357093811035, loss=2.0715792179107666
I0305 06:36:49.074556 139881808373504 logging_writer.py:48] [503700] global_step=503700, grad_norm=2.8933002948760986, loss=1.1435620784759521
I0305 06:37:33.555560 139881799980800 logging_writer.py:48] [503800] global_step=503800, grad_norm=3.204403877258301, loss=2.53519344329834
I0305 06:38:18.182625 139881808373504 logging_writer.py:48] [503900] global_step=503900, grad_norm=3.1877970695495605, loss=1.176583170890808
I0305 06:38:56.362839 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:39:06.935642 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:39:39.318170 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:39:40.902833 140077943854912 submission_runner.py:411] Time since start: 243173.71s, 	Step: 503987, 	{'train/accuracy': 0.8878710865974426, 'train/loss': 0.4177476763725281, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 221851.79825234413, 'total_duration': 243173.70783042908, 'accumulated_submission_time': 221851.79825234413, 'accumulated_eval_time': 21253.096702337265, 'accumulated_logging_time': 42.610806465148926}
I0305 06:39:41.018707 139881799980800 logging_writer.py:48] [503987] accumulated_eval_time=21253.096702, accumulated_logging_time=42.610806, accumulated_submission_time=221851.798252, global_step=503987, preemption_count=0, score=221851.798252, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=243173.707830, train/accuracy=0.887871, train/loss=0.417748, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:39:46.473618 139881808373504 logging_writer.py:48] [504000] global_step=504000, grad_norm=3.546325445175171, loss=3.00104022026062
I0305 06:40:27.658071 139881799980800 logging_writer.py:48] [504100] global_step=504100, grad_norm=3.217301607131958, loss=1.1432429552078247
I0305 06:41:12.124034 139881808373504 logging_writer.py:48] [504200] global_step=504200, grad_norm=3.276637554168701, loss=1.4689576625823975
I0305 06:41:56.535285 139881799980800 logging_writer.py:48] [504300] global_step=504300, grad_norm=3.275730609893799, loss=1.1212754249572754
I0305 06:42:41.188383 139881808373504 logging_writer.py:48] [504400] global_step=504400, grad_norm=2.756439208984375, loss=1.3864928483963013
I0305 06:43:25.777281 139881799980800 logging_writer.py:48] [504500] global_step=504500, grad_norm=3.0256571769714355, loss=1.796675443649292
I0305 06:44:10.539189 139881808373504 logging_writer.py:48] [504600] global_step=504600, grad_norm=3.1005327701568604, loss=1.0516422986984253
I0305 06:44:55.007874 139881799980800 logging_writer.py:48] [504700] global_step=504700, grad_norm=4.362099647521973, loss=3.2065889835357666
I0305 06:45:39.716526 139881808373504 logging_writer.py:48] [504800] global_step=504800, grad_norm=3.639007329940796, loss=2.6813910007476807
I0305 06:46:24.313547 139881799980800 logging_writer.py:48] [504900] global_step=504900, grad_norm=3.352276563644409, loss=1.1670911312103271
I0305 06:46:40.978455 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:46:51.545897 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:47:22.435935 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:47:24.031226 140077943854912 submission_runner.py:411] Time since start: 243636.84s, 	Step: 504939, 	{'train/accuracy': 0.8858398199081421, 'train/loss': 0.4197298288345337, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 222271.69676876068, 'total_duration': 243636.83622574806, 'accumulated_submission_time': 222271.69676876068, 'accumulated_eval_time': 21296.149447202682, 'accumulated_logging_time': 42.73886179924011}
I0305 06:47:24.128967 139881808373504 logging_writer.py:48] [504939] accumulated_eval_time=21296.149447, accumulated_logging_time=42.738862, accumulated_submission_time=222271.696769, global_step=504939, preemption_count=0, score=222271.696769, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=243636.836226, train/accuracy=0.885840, train/loss=0.419730, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:47:48.321658 139881799980800 logging_writer.py:48] [505000] global_step=505000, grad_norm=2.9214279651641846, loss=1.2234041690826416
I0305 06:48:31.608143 139881808373504 logging_writer.py:48] [505100] global_step=505100, grad_norm=3.0699925422668457, loss=2.581613063812256
I0305 06:49:16.258308 139881799980800 logging_writer.py:48] [505200] global_step=505200, grad_norm=3.3519675731658936, loss=1.085317850112915
I0305 06:50:00.710742 139881808373504 logging_writer.py:48] [505300] global_step=505300, grad_norm=3.2869980335235596, loss=1.5344116687774658
I0305 06:50:44.785017 139881799980800 logging_writer.py:48] [505400] global_step=505400, grad_norm=3.245076894760132, loss=3.0086944103240967
I0305 06:51:29.396256 139881808373504 logging_writer.py:48] [505500] global_step=505500, grad_norm=3.0822689533233643, loss=1.1385047435760498
I0305 06:52:13.878523 139881799980800 logging_writer.py:48] [505600] global_step=505600, grad_norm=3.0904552936553955, loss=1.6758867502212524
I0305 06:52:58.304149 139881808373504 logging_writer.py:48] [505700] global_step=505700, grad_norm=3.3413331508636475, loss=1.1791164875030518
I0305 06:53:42.750777 139881799980800 logging_writer.py:48] [505800] global_step=505800, grad_norm=3.36246395111084, loss=2.8463363647460938
I0305 06:54:24.129500 140077943854912 spec.py:321] Evaluating on the training split.
I0305 06:54:34.312458 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 06:55:06.897496 140077943854912 spec.py:349] Evaluating on the test split.
I0305 06:55:08.483371 140077943854912 submission_runner.py:411] Time since start: 244101.29s, 	Step: 505895, 	{'train/accuracy': 0.8896679282188416, 'train/loss': 0.4172879457473755, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 222691.63843798637, 'total_duration': 244101.28838062286, 'accumulated_submission_time': 222691.63843798637, 'accumulated_eval_time': 21340.503289461136, 'accumulated_logging_time': 42.846314430236816}
I0305 06:55:08.596065 139881808373504 logging_writer.py:48] [505895] accumulated_eval_time=21340.503289, accumulated_logging_time=42.846314, accumulated_submission_time=222691.638438, global_step=505895, preemption_count=0, score=222691.638438, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=244101.288381, train/accuracy=0.889668, train/loss=0.417288, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 06:55:10.950767 139881799980800 logging_writer.py:48] [505900] global_step=505900, grad_norm=3.028168201446533, loss=2.1408519744873047
I0305 06:55:51.570691 139881808373504 logging_writer.py:48] [506000] global_step=506000, grad_norm=3.6120452880859375, loss=1.1393123865127563
I0305 06:56:36.248576 139881799980800 logging_writer.py:48] [506100] global_step=506100, grad_norm=3.078059196472168, loss=1.6114532947540283
I0305 06:57:20.592931 139881808373504 logging_writer.py:48] [506200] global_step=506200, grad_norm=3.2614340782165527, loss=1.1464976072311401
I0305 06:58:05.127439 139881799980800 logging_writer.py:48] [506300] global_step=506300, grad_norm=3.482048273086548, loss=2.788219690322876
I0305 06:58:49.346119 139881808373504 logging_writer.py:48] [506400] global_step=506400, grad_norm=3.2193846702575684, loss=2.9073407649993896
I0305 06:59:33.990848 139881799980800 logging_writer.py:48] [506500] global_step=506500, grad_norm=3.2022056579589844, loss=1.4018447399139404
I0305 07:00:18.442653 139881808373504 logging_writer.py:48] [506600] global_step=506600, grad_norm=3.332698345184326, loss=1.1106610298156738
I0305 07:01:02.831425 139881799980800 logging_writer.py:48] [506700] global_step=506700, grad_norm=3.2294065952301025, loss=1.1525944471359253
I0305 07:01:47.033082 139881808373504 logging_writer.py:48] [506800] global_step=506800, grad_norm=3.187415838241577, loss=1.0666972398757935
I0305 07:02:08.844954 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:02:19.524066 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:02:48.324959 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:02:49.918357 140077943854912 submission_runner.py:411] Time since start: 244562.72s, 	Step: 506850, 	{'train/accuracy': 0.88720703125, 'train/loss': 0.417205810546875, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 223111.82583379745, 'total_duration': 244562.72336554527, 'accumulated_submission_time': 223111.82583379745, 'accumulated_eval_time': 21381.57668352127, 'accumulated_logging_time': 42.97149038314819}
I0305 07:02:50.033617 139881799980800 logging_writer.py:48] [506850] accumulated_eval_time=21381.576684, accumulated_logging_time=42.971490, accumulated_submission_time=223111.825834, global_step=506850, preemption_count=0, score=223111.825834, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=244562.723366, train/accuracy=0.887207, train/loss=0.417206, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:03:10.724210 139881808373504 logging_writer.py:48] [506900] global_step=506900, grad_norm=2.873631238937378, loss=1.291609764099121
I0305 07:03:54.710614 139881799980800 logging_writer.py:48] [507000] global_step=507000, grad_norm=4.468629837036133, loss=3.288942575454712
I0305 07:04:39.575094 139881808373504 logging_writer.py:48] [507100] global_step=507100, grad_norm=3.1405811309814453, loss=1.10984206199646
I0305 07:05:24.380635 139881799980800 logging_writer.py:48] [507200] global_step=507200, grad_norm=3.878680467605591, loss=3.033559560775757
I0305 07:06:08.795622 139881808373504 logging_writer.py:48] [507300] global_step=507300, grad_norm=3.332669734954834, loss=1.1135703325271606
I0305 07:06:53.339684 139881799980800 logging_writer.py:48] [507400] global_step=507400, grad_norm=4.145327091217041, loss=3.240250587463379
I0305 07:07:37.936187 139881808373504 logging_writer.py:48] [507500] global_step=507500, grad_norm=3.4971542358398438, loss=2.8122572898864746
I0305 07:08:22.506703 139881799980800 logging_writer.py:48] [507600] global_step=507600, grad_norm=3.24299955368042, loss=1.191030740737915
I0305 07:09:07.270282 139881808373504 logging_writer.py:48] [507700] global_step=507700, grad_norm=3.186565637588501, loss=2.6510508060455322
I0305 07:09:50.026721 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:10:00.342535 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:10:29.640535 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:10:31.230892 140077943854912 submission_runner.py:411] Time since start: 245024.04s, 	Step: 507797, 	{'train/accuracy': 0.8874022960662842, 'train/loss': 0.4177261292934418, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 223530.96260380745, 'total_duration': 245024.03587937355, 'accumulated_submission_time': 223530.96260380745, 'accumulated_eval_time': 21422.78080868721, 'accumulated_logging_time': 43.894623041152954}
I0305 07:10:31.342060 139881799980800 logging_writer.py:48] [507797] accumulated_eval_time=21422.780809, accumulated_logging_time=43.894623, accumulated_submission_time=223530.962604, global_step=507797, preemption_count=0, score=223530.962604, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=245024.035879, train/accuracy=0.887402, train/loss=0.417726, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:10:32.912772 139881808373504 logging_writer.py:48] [507800] global_step=507800, grad_norm=3.160118818283081, loss=1.1810791492462158
I0305 07:11:14.862115 139881799980800 logging_writer.py:48] [507900] global_step=507900, grad_norm=3.302478551864624, loss=1.1543446779251099
I0305 07:12:00.137999 139881808373504 logging_writer.py:48] [508000] global_step=508000, grad_norm=3.016308307647705, loss=1.2945218086242676
I0305 07:12:45.273855 139881799980800 logging_writer.py:48] [508100] global_step=508100, grad_norm=3.1615872383117676, loss=1.2268012762069702
I0305 07:13:30.556989 139881808373504 logging_writer.py:48] [508200] global_step=508200, grad_norm=3.1426944732666016, loss=1.0872764587402344
I0305 07:14:15.749584 139881799980800 logging_writer.py:48] [508300] global_step=508300, grad_norm=3.0420093536376953, loss=1.1659153699874878
I0305 07:15:00.691232 139881808373504 logging_writer.py:48] [508400] global_step=508400, grad_norm=3.2420945167541504, loss=1.2439836263656616
I0305 07:15:46.050210 139881799980800 logging_writer.py:48] [508500] global_step=508500, grad_norm=4.447509765625, loss=3.260448694229126
I0305 07:16:31.506415 139881808373504 logging_writer.py:48] [508600] global_step=508600, grad_norm=3.1099343299865723, loss=1.1263729333877563
I0305 07:17:16.869027 139881799980800 logging_writer.py:48] [508700] global_step=508700, grad_norm=3.418795585632324, loss=2.788093328475952
I0305 07:17:31.439823 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:17:41.812853 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:18:11.502787 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:18:13.100968 140077943854912 submission_runner.py:411] Time since start: 245485.91s, 	Step: 508734, 	{'train/accuracy': 0.8900390267372131, 'train/loss': 0.41310474276542664, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 223951.0003323555, 'total_duration': 245485.90597319603, 'accumulated_submission_time': 223951.0003323555, 'accumulated_eval_time': 21464.441920757294, 'accumulated_logging_time': 44.01762056350708}
I0305 07:18:13.214849 139881808373504 logging_writer.py:48] [508734] accumulated_eval_time=21464.441921, accumulated_logging_time=44.017621, accumulated_submission_time=223951.000332, global_step=508734, preemption_count=0, score=223951.000332, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=245485.905973, train/accuracy=0.890039, train/loss=0.413105, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:18:39.839209 139881799980800 logging_writer.py:48] [508800] global_step=508800, grad_norm=3.1599700450897217, loss=1.1882033348083496
I0305 07:19:24.205908 139881808373504 logging_writer.py:48] [508900] global_step=508900, grad_norm=3.1284706592559814, loss=1.2274255752563477
I0305 07:20:09.092409 139881799980800 logging_writer.py:48] [509000] global_step=509000, grad_norm=3.3990557193756104, loss=2.7188949584960938
I0305 07:20:53.898369 139881808373504 logging_writer.py:48] [509100] global_step=509100, grad_norm=3.2033207416534424, loss=1.1478643417358398
I0305 07:21:38.963349 139881799980800 logging_writer.py:48] [509200] global_step=509200, grad_norm=3.4315552711486816, loss=1.3952136039733887
I0305 07:22:23.703948 139881808373504 logging_writer.py:48] [509300] global_step=509300, grad_norm=3.006481647491455, loss=1.11326003074646
I0305 07:23:08.489665 139881799980800 logging_writer.py:48] [509400] global_step=509400, grad_norm=3.1151201725006104, loss=1.8612771034240723
I0305 07:23:53.215786 139881808373504 logging_writer.py:48] [509500] global_step=509500, grad_norm=3.0670831203460693, loss=1.1707665920257568
I0305 07:24:38.125956 139881799980800 logging_writer.py:48] [509600] global_step=509600, grad_norm=4.074404239654541, loss=3.3669650554656982
I0305 07:25:13.229978 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:25:23.562025 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:25:55.940426 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:25:57.529715 140077943854912 submission_runner.py:411] Time since start: 245950.33s, 	Step: 509680, 	{'train/accuracy': 0.8871093392372131, 'train/loss': 0.4248417615890503, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 224370.9559493065, 'total_duration': 245950.3347005844, 'accumulated_submission_time': 224370.9559493065, 'accumulated_eval_time': 21508.74162054062, 'accumulated_logging_time': 44.142621994018555}
I0305 07:25:57.643572 139881808373504 logging_writer.py:48] [509680] accumulated_eval_time=21508.741621, accumulated_logging_time=44.142622, accumulated_submission_time=224370.955949, global_step=509680, preemption_count=0, score=224370.955949, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=245950.334701, train/accuracy=0.887109, train/loss=0.424842, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:26:05.849662 139881799980800 logging_writer.py:48] [509700] global_step=509700, grad_norm=3.294049024581909, loss=2.386878728866577
I0305 07:26:47.670670 139881808373504 logging_writer.py:48] [509800] global_step=509800, grad_norm=2.9152486324310303, loss=1.8535293340682983
I0305 07:27:32.156713 139881799980800 logging_writer.py:48] [509900] global_step=509900, grad_norm=3.4686954021453857, loss=1.2336337566375732
I0305 07:28:16.720195 139881808373504 logging_writer.py:48] [510000] global_step=510000, grad_norm=3.2730417251586914, loss=1.8162466287612915
I0305 07:29:01.044005 139881799980800 logging_writer.py:48] [510100] global_step=510100, grad_norm=3.0676357746124268, loss=1.5881710052490234
I0305 07:29:45.558608 139881808373504 logging_writer.py:48] [510200] global_step=510200, grad_norm=4.352845191955566, loss=2.887052536010742
I0305 07:30:30.120824 139881799980800 logging_writer.py:48] [510300] global_step=510300, grad_norm=3.1966357231140137, loss=1.2317395210266113
I0305 07:31:14.588906 139881808373504 logging_writer.py:48] [510400] global_step=510400, grad_norm=3.300333261489868, loss=1.0630425214767456
I0305 07:31:59.333387 139881799980800 logging_writer.py:48] [510500] global_step=510500, grad_norm=3.3160934448242188, loss=1.125720739364624
I0305 07:32:43.751623 139881808373504 logging_writer.py:48] [510600] global_step=510600, grad_norm=3.2182464599609375, loss=2.4637022018432617
I0305 07:32:57.532428 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:33:07.652755 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:33:41.545110 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:33:43.128551 140077943854912 submission_runner.py:411] Time since start: 246415.93s, 	Step: 510633, 	{'train/accuracy': 0.8889452815055847, 'train/loss': 0.41446807980537415, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 224790.78458213806, 'total_duration': 246415.93355417252, 'accumulated_submission_time': 224790.78458213806, 'accumulated_eval_time': 21554.337733268738, 'accumulated_logging_time': 44.26745653152466}
I0305 07:33:43.256411 139881799980800 logging_writer.py:48] [510633] accumulated_eval_time=21554.337733, accumulated_logging_time=44.267457, accumulated_submission_time=224790.784582, global_step=510633, preemption_count=0, score=224790.784582, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=246415.933554, train/accuracy=0.888945, train/loss=0.414468, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:34:09.807921 139881808373504 logging_writer.py:48] [510700] global_step=510700, grad_norm=2.979416608810425, loss=2.4328835010528564
I0305 07:34:53.703377 139881799980800 logging_writer.py:48] [510800] global_step=510800, grad_norm=3.4169814586639404, loss=1.8604497909545898
I0305 07:35:38.240383 139881808373504 logging_writer.py:48] [510900] global_step=510900, grad_norm=3.178694486618042, loss=1.0825846195220947
I0305 07:36:22.981526 139881799980800 logging_writer.py:48] [511000] global_step=511000, grad_norm=4.13780403137207, loss=3.3108327388763428
I0305 07:37:07.182498 139881808373504 logging_writer.py:48] [511100] global_step=511100, grad_norm=5.257519245147705, loss=3.2312114238739014
I0305 07:37:51.238139 139881799980800 logging_writer.py:48] [511200] global_step=511200, grad_norm=3.7488107681274414, loss=1.8038450479507446
I0305 07:38:36.010226 139881808373504 logging_writer.py:48] [511300] global_step=511300, grad_norm=3.130073070526123, loss=1.44503653049469
I0305 07:39:20.320277 139881799980800 logging_writer.py:48] [511400] global_step=511400, grad_norm=3.611757516860962, loss=3.054490089416504
I0305 07:40:04.685272 139881808373504 logging_writer.py:48] [511500] global_step=511500, grad_norm=3.222895383834839, loss=0.9911603927612305
I0305 07:40:43.553074 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:40:54.014895 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:41:27.147099 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:41:28.729987 140077943854912 submission_runner.py:411] Time since start: 246881.53s, 	Step: 511589, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.4167560040950775, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 225211.0207374096, 'total_duration': 246881.53498005867, 'accumulated_submission_time': 225211.0207374096, 'accumulated_eval_time': 21599.514624118805, 'accumulated_logging_time': 44.40690755844116}
I0305 07:41:28.829702 139881799980800 logging_writer.py:48] [511589] accumulated_eval_time=21599.514624, accumulated_logging_time=44.406908, accumulated_submission_time=225211.020737, global_step=511589, preemption_count=0, score=225211.020737, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=246881.534980, train/accuracy=0.886465, train/loss=0.416756, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:41:33.505872 139881808373504 logging_writer.py:48] [511600] global_step=511600, grad_norm=3.895665168762207, loss=3.1455650329589844
I0305 07:42:14.277847 139881799980800 logging_writer.py:48] [511700] global_step=511700, grad_norm=3.045724630355835, loss=1.2041724920272827
I0305 07:42:58.569918 139881808373504 logging_writer.py:48] [511800] global_step=511800, grad_norm=2.874494791030884, loss=1.0439753532409668
I0305 07:43:43.506542 139881799980800 logging_writer.py:48] [511900] global_step=511900, grad_norm=3.374955892562866, loss=1.4075067043304443
I0305 07:44:28.469009 139881808373504 logging_writer.py:48] [512000] global_step=512000, grad_norm=3.1762657165527344, loss=1.1110104322433472
I0305 07:45:13.345841 139881799980800 logging_writer.py:48] [512100] global_step=512100, grad_norm=3.0355610847473145, loss=2.4989471435546875
I0305 07:45:58.215451 139881808373504 logging_writer.py:48] [512200] global_step=512200, grad_norm=2.9465317726135254, loss=1.9403533935546875
I0305 07:46:42.862602 139881799980800 logging_writer.py:48] [512300] global_step=512300, grad_norm=2.9481453895568848, loss=2.05708384513855
I0305 07:47:27.517413 139881808373504 logging_writer.py:48] [512400] global_step=512400, grad_norm=3.157576560974121, loss=1.0516223907470703
I0305 07:48:11.878771 139881799980800 logging_writer.py:48] [512500] global_step=512500, grad_norm=3.1640870571136475, loss=1.1576544046401978
I0305 07:48:28.772039 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:48:38.899568 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:49:05.592097 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:49:07.180616 140077943854912 submission_runner.py:411] Time since start: 247339.99s, 	Step: 512540, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.4207066595554352, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 225630.90210723877, 'total_duration': 247339.98562526703, 'accumulated_submission_time': 225630.90210723877, 'accumulated_eval_time': 21637.923177719116, 'accumulated_logging_time': 44.51779532432556}
I0305 07:49:07.303673 139881808373504 logging_writer.py:48] [512540] accumulated_eval_time=21637.923178, accumulated_logging_time=44.517795, accumulated_submission_time=225630.902107, global_step=512540, preemption_count=0, score=225630.902107, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=247339.985625, train/accuracy=0.886465, train/loss=0.420707, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:49:31.620331 139881799980800 logging_writer.py:48] [512600] global_step=512600, grad_norm=3.4176862239837646, loss=1.609403133392334
I0305 07:50:17.391473 139881808373504 logging_writer.py:48] [512700] global_step=512700, grad_norm=3.3605074882507324, loss=2.695047378540039
I0305 07:51:03.054881 139881799980800 logging_writer.py:48] [512800] global_step=512800, grad_norm=3.382474422454834, loss=1.2359154224395752
I0305 07:51:49.259496 139881808373504 logging_writer.py:48] [512900] global_step=512900, grad_norm=2.912550449371338, loss=1.0564231872558594
I0305 07:52:35.344719 139881799980800 logging_writer.py:48] [513000] global_step=513000, grad_norm=3.0530049800872803, loss=1.9415949583053589
I0305 07:53:21.352917 139881808373504 logging_writer.py:48] [513100] global_step=513100, grad_norm=2.947601556777954, loss=1.587409257888794
I0305 07:54:07.454912 139881799980800 logging_writer.py:48] [513200] global_step=513200, grad_norm=3.126091480255127, loss=1.3270140886306763
I0305 07:54:53.184586 139881808373504 logging_writer.py:48] [513300] global_step=513300, grad_norm=3.116372585296631, loss=1.337599754333496
I0305 07:55:39.048597 139881799980800 logging_writer.py:48] [513400] global_step=513400, grad_norm=3.193342924118042, loss=1.034265160560608
I0305 07:56:07.321528 140077943854912 spec.py:321] Evaluating on the training split.
I0305 07:56:17.695593 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 07:56:50.697701 140077943854912 spec.py:349] Evaluating on the test split.
I0305 07:56:52.282329 140077943854912 submission_runner.py:411] Time since start: 247805.09s, 	Step: 513462, 	{'train/accuracy': 0.8897070288658142, 'train/loss': 0.414121150970459, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 226050.86057639122, 'total_duration': 247805.08733654022, 'accumulated_submission_time': 226050.86057639122, 'accumulated_eval_time': 21682.883960962296, 'accumulated_logging_time': 44.65179920196533}
I0305 07:56:52.396210 139881808373504 logging_writer.py:48] [513462] accumulated_eval_time=21682.883961, accumulated_logging_time=44.651799, accumulated_submission_time=226050.860576, global_step=513462, preemption_count=0, score=226050.860576, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=247805.087337, train/accuracy=0.889707, train/loss=0.414121, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 07:57:07.603662 139881799980800 logging_writer.py:48] [513500] global_step=513500, grad_norm=3.6434988975524902, loss=3.159541130065918
I0305 07:57:50.015738 139881808373504 logging_writer.py:48] [513600] global_step=513600, grad_norm=3.0074377059936523, loss=1.1284050941467285
I0305 07:58:34.857130 139881799980800 logging_writer.py:48] [513700] global_step=513700, grad_norm=3.69447922706604, loss=2.8564252853393555
I0305 07:59:19.697405 139881808373504 logging_writer.py:48] [513800] global_step=513800, grad_norm=3.2595407962799072, loss=2.9322080612182617
I0305 08:00:03.972175 139881799980800 logging_writer.py:48] [513900] global_step=513900, grad_norm=3.900069236755371, loss=3.123159170150757
I0305 08:00:48.756826 139881808373504 logging_writer.py:48] [514000] global_step=514000, grad_norm=3.1345713138580322, loss=1.391036868095398
I0305 08:01:33.392200 139881799980800 logging_writer.py:48] [514100] global_step=514100, grad_norm=3.167823076248169, loss=1.1061651706695557
I0305 08:02:17.835253 139881808373504 logging_writer.py:48] [514200] global_step=514200, grad_norm=2.819054365158081, loss=1.0878292322158813
I0305 08:03:02.536647 139881799980800 logging_writer.py:48] [514300] global_step=514300, grad_norm=3.104057550430298, loss=2.05287766456604
I0305 08:03:47.302616 139881808373504 logging_writer.py:48] [514400] global_step=514400, grad_norm=3.0050158500671387, loss=1.0154987573623657
I0305 08:03:52.395302 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:04:02.617270 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:04:33.763286 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:04:35.347322 140077943854912 submission_runner.py:411] Time since start: 248268.15s, 	Step: 514413, 	{'train/accuracy': 0.8862890601158142, 'train/loss': 0.4216505289077759, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 226470.79879546165, 'total_duration': 248268.15232920647, 'accumulated_submission_time': 226470.79879546165, 'accumulated_eval_time': 21725.835948228836, 'accumulated_logging_time': 44.77778220176697}
I0305 08:04:35.461562 139881799980800 logging_writer.py:48] [514413] accumulated_eval_time=21725.835948, accumulated_logging_time=44.777782, accumulated_submission_time=226470.798795, global_step=514413, preemption_count=0, score=226470.798795, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=248268.152329, train/accuracy=0.886289, train/loss=0.421651, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:05:11.458694 139881808373504 logging_writer.py:48] [514500] global_step=514500, grad_norm=3.168687582015991, loss=2.646239757537842
I0305 08:05:55.458751 139881799980800 logging_writer.py:48] [514600] global_step=514600, grad_norm=3.0158262252807617, loss=2.12131404876709
I0305 08:06:40.713412 139881808373504 logging_writer.py:48] [514700] global_step=514700, grad_norm=3.089449882507324, loss=1.8273745775222778
I0305 08:07:25.389139 139881799980800 logging_writer.py:48] [514800] global_step=514800, grad_norm=2.949672222137451, loss=1.0614171028137207
I0305 08:08:10.131307 139881808373504 logging_writer.py:48] [514900] global_step=514900, grad_norm=3.146820545196533, loss=1.353022575378418
I0305 08:08:54.390985 139881799980800 logging_writer.py:48] [515000] global_step=515000, grad_norm=2.8572356700897217, loss=0.9800069332122803
I0305 08:09:38.896342 139881808373504 logging_writer.py:48] [515100] global_step=515100, grad_norm=3.2256014347076416, loss=1.142533540725708
I0305 08:10:23.507484 139881799980800 logging_writer.py:48] [515200] global_step=515200, grad_norm=3.1181607246398926, loss=1.1993660926818848
I0305 08:11:08.169378 139881808373504 logging_writer.py:48] [515300] global_step=515300, grad_norm=2.9361045360565186, loss=1.5708024501800537
I0305 08:11:35.595889 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:11:46.244953 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:12:15.937601 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:12:17.543975 140077943854912 submission_runner.py:411] Time since start: 248730.35s, 	Step: 515363, 	{'train/accuracy': 0.8855664134025574, 'train/loss': 0.4250814616680145, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 226890.87377142906, 'total_duration': 248730.3489470482, 'accumulated_submission_time': 226890.87377142906, 'accumulated_eval_time': 21767.783969163895, 'accumulated_logging_time': 44.90311050415039}
I0305 08:12:17.726837 139881799980800 logging_writer.py:48] [515363] accumulated_eval_time=21767.783969, accumulated_logging_time=44.903111, accumulated_submission_time=226890.873771, global_step=515363, preemption_count=0, score=226890.873771, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=248730.348947, train/accuracy=0.885566, train/loss=0.425081, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:12:32.554369 139881808373504 logging_writer.py:48] [515400] global_step=515400, grad_norm=2.8528435230255127, loss=1.8912156820297241
I0305 08:13:15.055737 139881799980800 logging_writer.py:48] [515500] global_step=515500, grad_norm=3.1484248638153076, loss=2.2453157901763916
I0305 08:13:59.295157 139881808373504 logging_writer.py:48] [515600] global_step=515600, grad_norm=3.084261417388916, loss=1.7481083869934082
I0305 08:14:43.716077 139881799980800 logging_writer.py:48] [515700] global_step=515700, grad_norm=2.8055641651153564, loss=1.065462350845337
I0305 08:15:28.100596 139881808373504 logging_writer.py:48] [515800] global_step=515800, grad_norm=2.8527095317840576, loss=1.3110742568969727
I0305 08:16:12.368097 139881799980800 logging_writer.py:48] [515900] global_step=515900, grad_norm=3.040353536605835, loss=2.68591570854187
I0305 08:16:56.637372 139881808373504 logging_writer.py:48] [516000] global_step=516000, grad_norm=3.1172726154327393, loss=1.126076579093933
I0305 08:17:40.947799 139881799980800 logging_writer.py:48] [516100] global_step=516100, grad_norm=2.9986534118652344, loss=1.113718032836914
I0305 08:18:25.546658 139881808373504 logging_writer.py:48] [516200] global_step=516200, grad_norm=3.198554754257202, loss=1.1118974685668945
I0305 08:19:10.088069 139881799980800 logging_writer.py:48] [516300] global_step=516300, grad_norm=2.9746391773223877, loss=1.691659688949585
I0305 08:19:17.836847 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:19:28.092685 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:20:03.700530 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:20:05.276738 140077943854912 submission_runner.py:411] Time since start: 249198.08s, 	Step: 516319, 	{'train/accuracy': 0.8897656202316284, 'train/loss': 0.4119044840335846, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 227310.91848754883, 'total_duration': 249198.0817565918, 'accumulated_submission_time': 227310.91848754883, 'accumulated_eval_time': 21815.223826885223, 'accumulated_logging_time': 45.10130214691162}
I0305 08:20:05.370173 139881808373504 logging_writer.py:48] [516319] accumulated_eval_time=21815.223827, accumulated_logging_time=45.101302, accumulated_submission_time=227310.918488, global_step=516319, preemption_count=0, score=227310.918488, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=249198.081757, train/accuracy=0.889766, train/loss=0.411904, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:20:37.533937 139881799980800 logging_writer.py:48] [516400] global_step=516400, grad_norm=4.15712833404541, loss=3.1363353729248047
I0305 08:21:21.798976 139881808373504 logging_writer.py:48] [516500] global_step=516500, grad_norm=3.122593879699707, loss=1.1902101039886475
I0305 08:22:06.322515 139881799980800 logging_writer.py:48] [516600] global_step=516600, grad_norm=3.207874298095703, loss=1.8206230401992798
I0305 08:22:50.725730 139881808373504 logging_writer.py:48] [516700] global_step=516700, grad_norm=2.917307138442993, loss=1.4892698526382446
I0305 08:23:35.466211 139881799980800 logging_writer.py:48] [516800] global_step=516800, grad_norm=3.116999387741089, loss=2.4843602180480957
I0305 08:24:19.650419 139881808373504 logging_writer.py:48] [516900] global_step=516900, grad_norm=3.147568464279175, loss=2.757176399230957
I0305 08:25:04.217824 139881799980800 logging_writer.py:48] [517000] global_step=517000, grad_norm=3.0968520641326904, loss=1.1070915460586548
I0305 08:25:48.721913 139881808373504 logging_writer.py:48] [517100] global_step=517100, grad_norm=2.9456095695495605, loss=1.1351451873779297
I0305 08:26:33.598959 139881799980800 logging_writer.py:48] [517200] global_step=517200, grad_norm=3.5953948497772217, loss=3.1092936992645264
I0305 08:27:05.535960 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:27:15.856241 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:27:43.321515 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:27:44.908806 140077943854912 submission_runner.py:411] Time since start: 249657.71s, 	Step: 517273, 	{'train/accuracy': 0.888671875, 'train/loss': 0.41235747933387756, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 227731.02437353134, 'total_duration': 249657.7138082981, 'accumulated_submission_time': 227731.02437353134, 'accumulated_eval_time': 21854.596625089645, 'accumulated_logging_time': 45.2050838470459}
I0305 08:27:45.026445 139881808373504 logging_writer.py:48] [517273] accumulated_eval_time=21854.596625, accumulated_logging_time=45.205084, accumulated_submission_time=227731.024374, global_step=517273, preemption_count=0, score=227731.024374, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=249657.713808, train/accuracy=0.888672, train/loss=0.412357, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:27:55.953731 139881799980800 logging_writer.py:48] [517300] global_step=517300, grad_norm=2.998589515686035, loss=1.054187297821045
I0305 08:28:39.115661 139881808373504 logging_writer.py:48] [517400] global_step=517400, grad_norm=3.034747362136841, loss=1.0627312660217285
I0305 08:29:23.828437 139881799980800 logging_writer.py:48] [517500] global_step=517500, grad_norm=3.0869109630584717, loss=1.1488642692565918
I0305 08:30:08.837409 139881808373504 logging_writer.py:48] [517600] global_step=517600, grad_norm=3.079429864883423, loss=1.1355568170547485
I0305 08:30:53.665928 139881799980800 logging_writer.py:48] [517700] global_step=517700, grad_norm=3.274463176727295, loss=2.225442886352539
I0305 08:31:38.554755 139881808373504 logging_writer.py:48] [517800] global_step=517800, grad_norm=3.552450180053711, loss=3.0479304790496826
I0305 08:32:23.516171 139881799980800 logging_writer.py:48] [517900] global_step=517900, grad_norm=3.112767219543457, loss=1.159990906715393
I0305 08:33:08.434864 139881808373504 logging_writer.py:48] [518000] global_step=518000, grad_norm=3.0846035480499268, loss=1.098575234413147
I0305 08:33:53.106649 139881799980800 logging_writer.py:48] [518100] global_step=518100, grad_norm=3.1627938747406006, loss=1.234195590019226
I0305 08:34:38.210353 139881808373504 logging_writer.py:48] [518200] global_step=518200, grad_norm=2.9877734184265137, loss=1.643404245376587
I0305 08:34:45.124924 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:34:55.708348 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:35:28.362117 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:35:29.947901 140077943854912 submission_runner.py:411] Time since start: 250122.75s, 	Step: 518217, 	{'train/accuracy': 0.8880273103713989, 'train/loss': 0.4175519347190857, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 228151.06265687943, 'total_duration': 250122.75287532806, 'accumulated_submission_time': 228151.06265687943, 'accumulated_eval_time': 21899.41953110695, 'accumulated_logging_time': 45.33416724205017}
I0305 08:35:30.041147 139881799980800 logging_writer.py:48] [518217] accumulated_eval_time=21899.419531, accumulated_logging_time=45.334167, accumulated_submission_time=228151.062657, global_step=518217, preemption_count=0, score=228151.062657, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=250122.752875, train/accuracy=0.888027, train/loss=0.417552, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:36:02.978989 139881808373504 logging_writer.py:48] [518300] global_step=518300, grad_norm=2.927593231201172, loss=2.60469913482666
I0305 08:36:47.264489 139881799980800 logging_writer.py:48] [518400] global_step=518400, grad_norm=3.344419479370117, loss=2.523899555206299
I0305 08:37:32.223063 139881808373504 logging_writer.py:48] [518500] global_step=518500, grad_norm=3.687112331390381, loss=2.9939236640930176
I0305 08:38:16.759844 139881799980800 logging_writer.py:48] [518600] global_step=518600, grad_norm=3.454066276550293, loss=2.7814207077026367
I0305 08:39:01.375255 139881808373504 logging_writer.py:48] [518700] global_step=518700, grad_norm=3.2922158241271973, loss=1.3146337270736694
I0305 08:39:46.346579 139881799980800 logging_writer.py:48] [518800] global_step=518800, grad_norm=3.6292078495025635, loss=3.108736038208008
I0305 08:40:30.807918 139881808373504 logging_writer.py:48] [518900] global_step=518900, grad_norm=2.998474359512329, loss=1.0573575496673584
I0305 08:41:15.585762 139881799980800 logging_writer.py:48] [519000] global_step=519000, grad_norm=2.898137092590332, loss=1.3434793949127197
I0305 08:42:00.012554 139881808373504 logging_writer.py:48] [519100] global_step=519100, grad_norm=3.20469069480896, loss=1.505442500114441
I0305 08:42:29.997999 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:42:40.266227 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:43:05.380405 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:43:06.966501 140077943854912 submission_runner.py:411] Time since start: 250579.77s, 	Step: 519169, 	{'train/accuracy': 0.8868945240974426, 'train/loss': 0.41967707872390747, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 228570.9589471817, 'total_duration': 250579.7715086937, 'accumulated_submission_time': 228570.9589471817, 'accumulated_eval_time': 21936.388018369675, 'accumulated_logging_time': 45.43733549118042}
I0305 08:43:07.084939 139881799980800 logging_writer.py:48] [519169] accumulated_eval_time=21936.388018, accumulated_logging_time=45.437335, accumulated_submission_time=228570.958947, global_step=519169, preemption_count=0, score=228570.958947, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=250579.771509, train/accuracy=0.886895, train/loss=0.419677, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:43:19.561666 139881808373504 logging_writer.py:48] [519200] global_step=519200, grad_norm=3.155872106552124, loss=1.3410561084747314
I0305 08:44:02.009061 139881799980800 logging_writer.py:48] [519300] global_step=519300, grad_norm=3.419999599456787, loss=2.89619517326355
I0305 08:44:46.352283 139881808373504 logging_writer.py:48] [519400] global_step=519400, grad_norm=2.9309041500091553, loss=1.895982265472412
I0305 08:45:30.798637 139881799980800 logging_writer.py:48] [519500] global_step=519500, grad_norm=4.4650397300720215, loss=3.1944005489349365
I0305 08:46:15.435404 139881808373504 logging_writer.py:48] [519600] global_step=519600, grad_norm=3.2363808155059814, loss=1.5355517864227295
I0305 08:47:00.215202 139881799980800 logging_writer.py:48] [519700] global_step=519700, grad_norm=3.0354220867156982, loss=1.0897870063781738
I0305 08:47:44.866320 139881808373504 logging_writer.py:48] [519800] global_step=519800, grad_norm=3.2581257820129395, loss=1.460418701171875
I0305 08:48:29.376219 139881799980800 logging_writer.py:48] [519900] global_step=519900, grad_norm=3.28202748298645, loss=1.016811490058899
I0305 08:49:13.831173 139881808373504 logging_writer.py:48] [520000] global_step=520000, grad_norm=3.1617136001586914, loss=1.1033443212509155
I0305 08:49:58.173274 139881799980800 logging_writer.py:48] [520100] global_step=520100, grad_norm=3.318711280822754, loss=1.3937031030654907
I0305 08:50:06.998790 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:50:17.568900 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:50:48.630515 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:50:50.213713 140077943854912 submission_runner.py:411] Time since start: 251043.02s, 	Step: 520121, 	{'train/accuracy': 0.8871679306030273, 'train/loss': 0.42267757654190063, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 228990.81290125847, 'total_duration': 251043.0187008381, 'accumulated_submission_time': 228990.81290125847, 'accumulated_eval_time': 21979.60288333893, 'accumulated_logging_time': 45.56658720970154}
I0305 08:50:50.326193 139881808373504 logging_writer.py:48] [520121] accumulated_eval_time=21979.602883, accumulated_logging_time=45.566587, accumulated_submission_time=228990.812901, global_step=520121, preemption_count=0, score=228990.812901, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=251043.018701, train/accuracy=0.887168, train/loss=0.422678, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:51:22.570188 139881799980800 logging_writer.py:48] [520200] global_step=520200, grad_norm=3.1901512145996094, loss=1.1139882802963257
I0305 08:52:07.602200 139881808373504 logging_writer.py:48] [520300] global_step=520300, grad_norm=3.458040714263916, loss=2.934243679046631
I0305 08:52:52.359586 139881799980800 logging_writer.py:48] [520400] global_step=520400, grad_norm=3.1350884437561035, loss=1.4299649000167847
I0305 08:53:37.270223 139881808373504 logging_writer.py:48] [520500] global_step=520500, grad_norm=3.682603597640991, loss=2.9409453868865967
I0305 08:54:22.119661 139881799980800 logging_writer.py:48] [520600] global_step=520600, grad_norm=3.1715824604034424, loss=1.2526803016662598
I0305 08:55:07.065964 139881808373504 logging_writer.py:48] [520700] global_step=520700, grad_norm=2.907869338989258, loss=1.111899495124817
I0305 08:55:51.793684 139881799980800 logging_writer.py:48] [520800] global_step=520800, grad_norm=3.2669215202331543, loss=2.684580087661743
I0305 08:56:36.780249 139881808373504 logging_writer.py:48] [520900] global_step=520900, grad_norm=3.2012760639190674, loss=1.1609290838241577
I0305 08:57:21.665814 139881799980800 logging_writer.py:48] [521000] global_step=521000, grad_norm=3.1443777084350586, loss=1.934765100479126
I0305 08:57:50.270241 140077943854912 spec.py:321] Evaluating on the training split.
I0305 08:58:00.627199 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 08:58:33.457813 140077943854912 spec.py:349] Evaluating on the test split.
I0305 08:58:35.042987 140077943854912 submission_runner.py:411] Time since start: 251507.85s, 	Step: 521066, 	{'train/accuracy': 0.8896874785423279, 'train/loss': 0.41497373580932617, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 229410.69715499878, 'total_duration': 251507.84799432755, 'accumulated_submission_time': 229410.69715499878, 'accumulated_eval_time': 22024.37559247017, 'accumulated_logging_time': 45.68960404396057}
I0305 08:58:35.164050 139881808373504 logging_writer.py:48] [521066] accumulated_eval_time=22024.375592, accumulated_logging_time=45.689604, accumulated_submission_time=229410.697155, global_step=521066, preemption_count=0, score=229410.697155, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=251507.847994, train/accuracy=0.889687, train/loss=0.414974, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 08:58:48.840086 139881799980800 logging_writer.py:48] [521100] global_step=521100, grad_norm=3.2697930335998535, loss=2.7154622077941895
I0305 08:59:31.545188 139881808373504 logging_writer.py:48] [521200] global_step=521200, grad_norm=4.052857398986816, loss=3.1636922359466553
I0305 09:00:16.190917 139881799980800 logging_writer.py:48] [521300] global_step=521300, grad_norm=3.0628368854522705, loss=1.571993350982666
I0305 09:01:00.750486 139881808373504 logging_writer.py:48] [521400] global_step=521400, grad_norm=3.375593662261963, loss=1.3404585123062134
I0305 09:01:45.157041 139881799980800 logging_writer.py:48] [521500] global_step=521500, grad_norm=3.5842366218566895, loss=1.1762518882751465
I0305 09:02:29.674647 139881808373504 logging_writer.py:48] [521600] global_step=521600, grad_norm=3.279236078262329, loss=1.5808852910995483
I0305 09:03:14.225755 139881799980800 logging_writer.py:48] [521700] global_step=521700, grad_norm=3.0247020721435547, loss=1.1021814346313477
I0305 09:03:58.761847 139881808373504 logging_writer.py:48] [521800] global_step=521800, grad_norm=3.1251380443573, loss=2.381091356277466
I0305 09:04:43.335220 139881799980800 logging_writer.py:48] [521900] global_step=521900, grad_norm=3.395026445388794, loss=2.9219508171081543
I0305 09:05:27.971574 139881808373504 logging_writer.py:48] [522000] global_step=522000, grad_norm=2.9346818923950195, loss=1.2453688383102417
I0305 09:05:35.122584 140077943854912 spec.py:321] Evaluating on the training split.
I0305 09:05:45.318104 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 09:06:18.694192 140077943854912 spec.py:349] Evaluating on the test split.
I0305 09:06:20.304380 140077943854912 submission_runner.py:411] Time since start: 251973.11s, 	Step: 522018, 	{'train/accuracy': 0.8896093368530273, 'train/loss': 0.4115025997161865, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 229830.59431529045, 'total_duration': 251973.10938835144, 'accumulated_submission_time': 229830.59431529045, 'accumulated_eval_time': 22069.55735874176, 'accumulated_logging_time': 45.82239007949829}
I0305 09:06:20.402288 139881799980800 logging_writer.py:48] [522018] accumulated_eval_time=22069.557359, accumulated_logging_time=45.822390, accumulated_submission_time=229830.594315, global_step=522018, preemption_count=0, score=229830.594315, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=251973.109388, train/accuracy=0.889609, train/loss=0.411503, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 09:06:52.808269 139881808373504 logging_writer.py:48] [522100] global_step=522100, grad_norm=3.4971630573272705, loss=1.125885248184204
I0305 09:07:37.152332 139881799980800 logging_writer.py:48] [522200] global_step=522200, grad_norm=3.4429025650024414, loss=2.8893439769744873
I0305 09:08:21.768531 139881808373504 logging_writer.py:48] [522300] global_step=522300, grad_norm=3.3490800857543945, loss=1.488464117050171
I0305 09:09:06.333236 139881799980800 logging_writer.py:48] [522400] global_step=522400, grad_norm=3.1384313106536865, loss=1.7034814357757568
I0305 09:09:50.486075 139881808373504 logging_writer.py:48] [522500] global_step=522500, grad_norm=3.00592303276062, loss=1.1627531051635742
I0305 09:10:34.707387 139881799980800 logging_writer.py:48] [522600] global_step=522600, grad_norm=3.5070979595184326, loss=2.4941020011901855
I0305 09:11:19.179703 139881808373504 logging_writer.py:48] [522700] global_step=522700, grad_norm=3.508110761642456, loss=1.1580685377120972
I0305 09:12:03.480962 139881799980800 logging_writer.py:48] [522800] global_step=522800, grad_norm=3.158306360244751, loss=1.3358174562454224
I0305 09:12:47.817763 139881808373504 logging_writer.py:48] [522900] global_step=522900, grad_norm=2.9014532566070557, loss=1.1088097095489502
I0305 09:13:20.379889 140077943854912 spec.py:321] Evaluating on the training split.
I0305 09:13:30.743923 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 09:13:58.388248 140077943854912 spec.py:349] Evaluating on the test split.
I0305 09:13:59.975424 140077943854912 submission_runner.py:411] Time since start: 252432.78s, 	Step: 522975, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.41918468475341797, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 230250.51088905334, 'total_duration': 252432.78043317795, 'accumulated_submission_time': 230250.51088905334, 'accumulated_eval_time': 22109.152854681015, 'accumulated_logging_time': 45.93182587623596}
I0305 09:14:00.094496 139881799980800 logging_writer.py:48] [522975] accumulated_eval_time=22109.152855, accumulated_logging_time=45.931826, accumulated_submission_time=230250.510889, global_step=522975, preemption_count=0, score=230250.510889, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=252432.780433, train/accuracy=0.887383, train/loss=0.419185, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 09:14:10.238435 139881808373504 logging_writer.py:48] [523000] global_step=523000, grad_norm=3.1417040824890137, loss=1.5603129863739014
I0305 09:14:53.110587 139881799980800 logging_writer.py:48] [523100] global_step=523100, grad_norm=3.9079535007476807, loss=3.16256046295166
I0305 09:15:37.685345 139881808373504 logging_writer.py:48] [523200] global_step=523200, grad_norm=3.5393240451812744, loss=2.8314781188964844
I0305 09:16:22.454763 139881799980800 logging_writer.py:48] [523300] global_step=523300, grad_norm=3.148648500442505, loss=1.0884910821914673
I0305 09:17:07.541337 139881808373504 logging_writer.py:48] [523400] global_step=523400, grad_norm=3.7225096225738525, loss=1.6126480102539062
I0305 09:17:52.299788 139881799980800 logging_writer.py:48] [523500] global_step=523500, grad_norm=3.314391851425171, loss=1.2560067176818848
I0305 09:18:37.395789 139881808373504 logging_writer.py:48] [523600] global_step=523600, grad_norm=3.0378968715667725, loss=1.4650205373764038
I0305 09:19:22.353028 139881799980800 logging_writer.py:48] [523700] global_step=523700, grad_norm=3.3658759593963623, loss=1.1242520809173584
I0305 09:20:06.953143 139881808373504 logging_writer.py:48] [523800] global_step=523800, grad_norm=3.260256767272949, loss=1.1704617738723755
I0305 09:20:51.463016 139881799980800 logging_writer.py:48] [523900] global_step=523900, grad_norm=3.511812925338745, loss=1.3117367029190063
I0305 09:21:00.118998 140077943854912 spec.py:321] Evaluating on the training split.
I0305 09:21:12.248828 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 09:21:49.833945 140077943854912 spec.py:349] Evaluating on the test split.
I0305 09:21:51.420095 140077943854912 submission_runner.py:411] Time since start: 252904.23s, 	Step: 523921, 	{'train/accuracy': 0.8888671398162842, 'train/loss': 0.41101327538490295, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 230670.47365617752, 'total_duration': 252904.2251083851, 'accumulated_submission_time': 230670.47365617752, 'accumulated_eval_time': 22160.453914642334, 'accumulated_logging_time': 46.063761472702026}
I0305 09:21:51.514618 139881808373504 logging_writer.py:48] [523921] accumulated_eval_time=22160.453915, accumulated_logging_time=46.063761, accumulated_submission_time=230670.473656, global_step=523921, preemption_count=0, score=230670.473656, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=252904.225108, train/accuracy=0.888867, train/loss=0.411013, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 09:22:22.868482 139881799980800 logging_writer.py:48] [524000] global_step=524000, grad_norm=3.651650905609131, loss=3.2404749393463135
I0305 09:23:07.031491 139881808373504 logging_writer.py:48] [524100] global_step=524100, grad_norm=3.3616087436676025, loss=1.1590354442596436
I0305 09:23:51.457206 139881799980800 logging_writer.py:48] [524200] global_step=524200, grad_norm=3.131838083267212, loss=1.074842095375061
I0305 09:24:36.373929 139881808373504 logging_writer.py:48] [524300] global_step=524300, grad_norm=2.9929680824279785, loss=1.0608415603637695
I0305 09:25:20.692147 139881799980800 logging_writer.py:48] [524400] global_step=524400, grad_norm=3.013540744781494, loss=1.0750914812088013
I0305 09:26:05.010629 139881808373504 logging_writer.py:48] [524500] global_step=524500, grad_norm=3.8320200443267822, loss=3.1909449100494385
I0305 09:26:49.383872 139881799980800 logging_writer.py:48] [524600] global_step=524600, grad_norm=3.89703631401062, loss=3.1052489280700684
I0305 09:27:33.612077 139881808373504 logging_writer.py:48] [524700] global_step=524700, grad_norm=4.021049499511719, loss=3.2101433277130127
I0305 09:28:17.905600 139881799980800 logging_writer.py:48] [524800] global_step=524800, grad_norm=3.075441598892212, loss=1.075995683670044
I0305 09:28:51.754171 140077943854912 spec.py:321] Evaluating on the training split.
I0305 09:29:01.891412 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 09:29:32.044253 140077943854912 spec.py:349] Evaluating on the test split.
I0305 09:29:33.639248 140077943854912 submission_runner.py:411] Time since start: 253366.44s, 	Step: 524878, 	{'train/accuracy': 0.8877148032188416, 'train/loss': 0.4167254567146301, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 231090.6543712616, 'total_duration': 253366.4442384243, 'accumulated_submission_time': 231090.6543712616, 'accumulated_eval_time': 22202.33893918991, 'accumulated_logging_time': 46.168038845062256}
I0305 09:29:33.752451 139881808373504 logging_writer.py:48] [524878] accumulated_eval_time=22202.338939, accumulated_logging_time=46.168039, accumulated_submission_time=231090.654371, global_step=524878, preemption_count=0, score=231090.654371, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=253366.444238, train/accuracy=0.887715, train/loss=0.416725, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 09:29:42.726488 139881799980800 logging_writer.py:48] [524900] global_step=524900, grad_norm=3.1241509914398193, loss=1.9173598289489746
I0305 09:30:25.063379 139881808373504 logging_writer.py:48] [525000] global_step=525000, grad_norm=4.195497035980225, loss=3.3433661460876465
I0305 09:31:09.711626 139881799980800 logging_writer.py:48] [525100] global_step=525100, grad_norm=3.061969518661499, loss=1.0728797912597656
I0305 09:31:54.391753 139881808373504 logging_writer.py:48] [525200] global_step=525200, grad_norm=3.115086078643799, loss=1.1023672819137573
I0305 09:32:39.356525 139881799980800 logging_writer.py:48] [525300] global_step=525300, grad_norm=2.97261118888855, loss=1.4519922733306885
I0305 09:33:24.042896 139881808373504 logging_writer.py:48] [525400] global_step=525400, grad_norm=3.7126502990722656, loss=1.1296343803405762
I0305 09:34:09.132471 139881799980800 logging_writer.py:48] [525500] global_step=525500, grad_norm=3.079059600830078, loss=1.1820652484893799
I0305 09:34:53.710516 139881808373504 logging_writer.py:48] [525600] global_step=525600, grad_norm=3.1489827632904053, loss=1.062645673751831
I0305 09:35:38.261950 139881799980800 logging_writer.py:48] [525700] global_step=525700, grad_norm=4.622758865356445, loss=3.2383875846862793
I0305 09:36:23.177152 139881808373504 logging_writer.py:48] [525800] global_step=525800, grad_norm=4.0318403244018555, loss=2.860713481903076
I0305 09:36:33.944857 140077943854912 spec.py:321] Evaluating on the training split.
I0305 09:36:44.601612 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 09:37:15.905368 140077943854912 spec.py:349] Evaluating on the test split.
I0305 09:37:17.516673 140077943854912 submission_runner.py:411] Time since start: 253830.32s, 	Step: 525826, 	{'train/accuracy': 0.8874022960662842, 'train/loss': 0.41480696201324463, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 231510.78193974495, 'total_duration': 253830.32165122032, 'accumulated_submission_time': 231510.78193974495, 'accumulated_eval_time': 22245.91069793701, 'accumulated_logging_time': 46.29690170288086}
I0305 09:37:17.699892 139881799980800 logging_writer.py:48] [525826] accumulated_eval_time=22245.910698, accumulated_logging_time=46.296902, accumulated_submission_time=231510.781940, global_step=525826, preemption_count=0, score=231510.781940, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=253830.321651, train/accuracy=0.887402, train/loss=0.414807, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 09:37:47.332107 139881808373504 logging_writer.py:48] [525900] global_step=525900, grad_norm=3.234262704849243, loss=1.3876571655273438
I0305 09:38:31.879851 139881799980800 logging_writer.py:48] [526000] global_step=526000, grad_norm=3.1345021724700928, loss=1.0416347980499268
I0305 09:39:16.444863 139881808373504 logging_writer.py:48] [526100] global_step=526100, grad_norm=3.0406923294067383, loss=1.2411788702011108
I0305 09:40:01.106971 139881799980800 logging_writer.py:48] [526200] global_step=526200, grad_norm=3.5531184673309326, loss=1.1354725360870361
I0305 09:40:45.301064 139881808373504 logging_writer.py:48] [526300] global_step=526300, grad_norm=3.3796751499176025, loss=3.0981359481811523
I0305 09:41:30.041624 139881799980800 logging_writer.py:48] [526400] global_step=526400, grad_norm=3.146425724029541, loss=1.569719910621643
I0305 09:42:14.703761 139881808373504 logging_writer.py:48] [526500] global_step=526500, grad_norm=3.039334774017334, loss=1.0965847969055176
I0305 09:42:58.965090 139881799980800 logging_writer.py:48] [526600] global_step=526600, grad_norm=3.068005323410034, loss=1.901154637336731
I0305 09:43:43.573091 139881808373504 logging_writer.py:48] [526700] global_step=526700, grad_norm=3.0335471630096436, loss=1.0874629020690918
I0305 09:44:17.729841 140077943854912 spec.py:321] Evaluating on the training split.
I0305 09:44:28.578961 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 09:45:04.493234 140077943854912 spec.py:349] Evaluating on the test split.
I0305 09:45:06.067854 140077943854912 submission_runner.py:411] Time since start: 254298.87s, 	Step: 526778, 	{'train/accuracy': 0.8897070288658142, 'train/loss': 0.4127437472343445, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 231930.74751019478, 'total_duration': 254298.8728711605, 'accumulated_submission_time': 231930.74751019478, 'accumulated_eval_time': 22294.248700141907, 'accumulated_logging_time': 46.49507021903992}
I0305 09:45:06.163847 139881799980800 logging_writer.py:48] [526778] accumulated_eval_time=22294.248700, accumulated_logging_time=46.495070, accumulated_submission_time=231930.747510, global_step=526778, preemption_count=0, score=231930.747510, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=254298.872871, train/accuracy=0.889707, train/loss=0.412744, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 09:45:15.132013 139881808373504 logging_writer.py:48] [526800] global_step=526800, grad_norm=2.9187710285186768, loss=2.008427858352661
I0305 09:45:56.033640 139881799980800 logging_writer.py:48] [526900] global_step=526900, grad_norm=2.890514612197876, loss=1.4318442344665527
I0305 09:46:40.705386 139881808373504 logging_writer.py:48] [527000] global_step=527000, grad_norm=3.0458269119262695, loss=1.144028663635254
I0305 09:47:25.622857 139881799980800 logging_writer.py:48] [527100] global_step=527100, grad_norm=3.122284173965454, loss=1.2485166788101196
I0305 09:48:09.973752 139881808373504 logging_writer.py:48] [527200] global_step=527200, grad_norm=3.6290693283081055, loss=3.035801410675049
I0305 09:48:54.376224 139881799980800 logging_writer.py:48] [527300] global_step=527300, grad_norm=3.1883039474487305, loss=1.164541244506836
I0305 09:49:39.126685 139881808373504 logging_writer.py:48] [527400] global_step=527400, grad_norm=3.1178441047668457, loss=1.0368765592575073
I0305 09:50:23.497279 139881799980800 logging_writer.py:48] [527500] global_step=527500, grad_norm=3.059295415878296, loss=1.219783902168274
I0305 09:51:07.879409 139881808373504 logging_writer.py:48] [527600] global_step=527600, grad_norm=3.413407325744629, loss=1.2571637630462646
I0305 09:51:52.094660 139881799980800 logging_writer.py:48] [527700] global_step=527700, grad_norm=3.0780434608459473, loss=1.1857150793075562
I0305 09:52:06.108029 140077943854912 spec.py:321] Evaluating on the training split.
I0305 09:52:16.266877 140077943854912 spec.py:333] Evaluating on the validation split.
I0305 09:52:44.358597 140077943854912 spec.py:349] Evaluating on the test split.
I0305 09:52:45.944254 140077943854912 submission_runner.py:411] Time since start: 254758.75s, 	Step: 527733, 	{'train/accuracy': 0.8895898461341858, 'train/loss': 0.4154190421104431, 'validation/accuracy': 0.7829399704933167, 'validation/loss': 0.8525302410125732, 'validation/num_examples': 50000, 'test/accuracy': 0.6614000201225281, 'test/loss': 1.453892707824707, 'test/num_examples': 10000, 'score': 232350.62709617615, 'total_duration': 254758.7492594719, 'accumulated_submission_time': 232350.62709617615, 'accumulated_eval_time': 22334.084921598434, 'accumulated_logging_time': 46.60599493980408}
I0305 09:52:46.063575 139881808373504 logging_writer.py:48] [527733] accumulated_eval_time=22334.084922, accumulated_logging_time=46.605995, accumulated_submission_time=232350.627096, global_step=527733, preemption_count=0, score=232350.627096, test/accuracy=0.661400, test/loss=1.453893, test/num_examples=10000, total_duration=254758.749259, train/accuracy=0.889590, train/loss=0.415419, validation/accuracy=0.782940, validation/loss=0.852530, validation/num_examples=50000
I0305 09:53:13.747030 139881799980800 logging_writer.py:48] [527800] global_step=527800, grad_norm=3.44492244720459, loss=1.2115521430969238
I0305 09:53:59.521992 139881808373504 logging_writer.py:48] [527900] global_step=527900, grad_norm=3.005742311477661, loss=1.4517172574996948
I0305 09:54:45.130790 139881799980800 logging_writer.py:48] [528000] global_step=528000, grad_norm=3.539865493774414, loss=1.2156609296798706
I0305 09:55:30.565415 139881808373504 logging_writer.py:48] [528100] global_step=528100, grad_norm=4.278432846069336, loss=3.183350086212158
I0305 09:56:16.032781 139881799980800 logging_writer.py:48] [528200] global_step=528200, grad_norm=2.9886035919189453, loss=2.5748679637908936
I0305 09:56:16.157628 139881808373504 logging_writer.py:48] [528201] global_step=528201, preemption_count=0, score=232560.570173
I0305 09:56:16.532880 140077943854912 checkpoints.py:490] Saving checkpoint at step: 528201
I0305 09:56:17.896604 140077943854912 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification_self_tuning/study_2/imagenet_vit_jax/trial_1/checkpoint_528201
I0305 09:56:17.924877 140077943854912 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification_self_tuning/study_2/imagenet_vit_jax/trial_1/checkpoint_528201.
I0305 09:56:19.081188 140077943854912 submission_runner.py:676] Final imagenet_vit score: 232560.57017302513
