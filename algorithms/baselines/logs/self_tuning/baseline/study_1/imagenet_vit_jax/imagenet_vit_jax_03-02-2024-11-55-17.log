python3 submission_runner.py --framework=jax --workload=imagenet_vit --submission_path=prize_qualification_baselines/self_tuning/jax_nadamw_full_budget.py --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=prize_qualification_self_tuning/study_1 --overwrite=true --save_checkpoints=false --rng_seed=1867293012 --max_global_steps=559998 --imagenet_v2_data_dir=/data/imagenet/jax --tuning_ruleset=self 2>&1 | tee -a /logs/imagenet_vit_jax_03-02-2024-11-55-17.log
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0302 11:55:38.408297 139953291118400 logger_utils.py:76] Creating experiment directory at /experiment_runs/prize_qualification_self_tuning/study_1/imagenet_vit_jax.
I0302 11:55:39.378245 139953291118400 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0302 11:55:39.378969 139953291118400 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0302 11:55:39.379103 139953291118400 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0302 11:55:40.309489 139953291118400 submission_runner.py:605] Creating directory at /experiment_runs/prize_qualification_self_tuning/study_1/imagenet_vit_jax/trial_1.
I0302 11:55:40.509853 139953291118400 submission_runner.py:206] Initializing dataset.
I0302 11:55:40.525670 139953291118400 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:55:40.537111 139953291118400 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:55:40.919934 139953291118400 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:55:49.167341 139953291118400 submission_runner.py:213] Initializing model.
I0302 11:55:58.205132 139953291118400 submission_runner.py:255] Initializing optimizer.
I0302 11:55:59.188640 139953291118400 submission_runner.py:262] Initializing metrics bundle.
I0302 11:55:59.188833 139953291118400 submission_runner.py:280] Initializing checkpoint and logger.
I0302 11:55:59.189671 139953291118400 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification_self_tuning/study_1/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0302 11:55:59.189821 139953291118400 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification_self_tuning/study_1/imagenet_vit_jax/trial_1/meta_data_0.json.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0302 11:55:59.517214 139953291118400 logger_utils.py:220] Unable to record git information. Continuing without it.
I0302 11:55:59.813500 139953291118400 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification_self_tuning/study_1/imagenet_vit_jax/trial_1/flags_0.json.
I0302 11:55:59.823724 139953291118400 submission_runner.py:314] Starting training loop.
I0302 11:56:42.261072 139789623453440 logging_writer.py:48] [0] global_step=0, grad_norm=0.3462356626987457, loss=6.9077558517456055
I0302 11:56:42.279073 139953291118400 spec.py:321] Evaluating on the training split.
I0302 11:56:42.478787 139953291118400 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:56:42.487882 139953291118400 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:56:42.571497 139953291118400 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:56:59.374815 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 11:56:59.386976 139953291118400 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:56:59.406971 139953291118400 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:56:59.485817 139953291118400 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:57:16.684983 139953291118400 spec.py:349] Evaluating on the test split.
I0302 11:57:16.691684 139953291118400 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0302 11:57:16.697453 139953291118400 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0302 11:57:16.746855 139953291118400 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0302 11:57:22.027821 139953291118400 submission_runner.py:411] Time since start: 82.20s, 	Step: 1, 	{'train/accuracy': 0.0009374999790452421, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 42.4552264213562, 'total_duration': 82.20404887199402, 'accumulated_submission_time': 42.4552264213562, 'accumulated_eval_time': 39.74869656562805, 'accumulated_logging_time': 0}
I0302 11:57:22.045155 139758000912128 logging_writer.py:48] [1] accumulated_eval_time=39.748697, accumulated_logging_time=0, accumulated_submission_time=42.455226, global_step=1, preemption_count=0, score=42.455226, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=82.204049, train/accuracy=0.000937, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0302 11:58:24.256727 139790808770304 logging_writer.py:48] [100] global_step=100, grad_norm=0.5264913439750671, loss=6.8752217292785645
I0302 11:59:06.658933 139790817163008 logging_writer.py:48] [200] global_step=200, grad_norm=0.6455488801002502, loss=6.762694835662842
I0302 11:59:50.753104 139790808770304 logging_writer.py:48] [300] global_step=300, grad_norm=0.9554784297943115, loss=6.664155960083008
I0302 12:00:34.904559 139790817163008 logging_writer.py:48] [400] global_step=400, grad_norm=1.2258661985397339, loss=6.558453559875488
I0302 12:01:19.136752 139790808770304 logging_writer.py:48] [500] global_step=500, grad_norm=1.0467201471328735, loss=6.6065778732299805
I0302 12:02:03.329617 139790817163008 logging_writer.py:48] [600] global_step=600, grad_norm=1.3212372064590454, loss=6.325512409210205
I0302 12:02:47.578030 139790808770304 logging_writer.py:48] [700] global_step=700, grad_norm=1.025040864944458, loss=6.617724418640137
I0302 12:03:31.873618 139790817163008 logging_writer.py:48] [800] global_step=800, grad_norm=1.459726333618164, loss=6.1847243309021
I0302 12:04:15.963723 139790808770304 logging_writer.py:48] [900] global_step=900, grad_norm=1.3834128379821777, loss=6.20257568359375
I0302 12:04:22.254849 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:04:33.904822 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:04:42.032127 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:04:43.717492 139953291118400 submission_runner.py:411] Time since start: 523.89s, 	Step: 916, 	{'train/accuracy': 0.033281248062849045, 'train/loss': 5.910701751708984, 'validation/accuracy': 0.03221999853849411, 'validation/loss': 5.930098056793213, 'validation/num_examples': 50000, 'test/accuracy': 0.026500001549720764, 'test/loss': 6.053519248962402, 'test/num_examples': 10000, 'score': 462.6057026386261, 'total_duration': 523.893707036972, 'accumulated_submission_time': 462.6057026386261, 'accumulated_eval_time': 61.21135711669922, 'accumulated_logging_time': 0.026748180389404297}
I0302 12:04:43.734970 139758009304832 logging_writer.py:48] [916] accumulated_eval_time=61.211357, accumulated_logging_time=0.026748, accumulated_submission_time=462.605703, global_step=916, preemption_count=0, score=462.605703, test/accuracy=0.026500, test/loss=6.053519, test/num_examples=10000, total_duration=523.893707, train/accuracy=0.033281, train/loss=5.910702, validation/accuracy=0.032220, validation/loss=5.930098, validation/num_examples=50000
I0302 12:05:17.301155 139758017697536 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.2575092315673828, loss=6.215506553649902
I0302 12:06:00.177460 139758009304832 logging_writer.py:48] [1100] global_step=1100, grad_norm=1.771665096282959, loss=6.3159918785095215
I0302 12:06:44.520523 139758017697536 logging_writer.py:48] [1200] global_step=1200, grad_norm=1.239606499671936, loss=6.387167930603027
I0302 12:07:28.648131 139758009304832 logging_writer.py:48] [1300] global_step=1300, grad_norm=1.1396883726119995, loss=6.582673072814941
I0302 12:08:12.866020 139758017697536 logging_writer.py:48] [1400] global_step=1400, grad_norm=2.2026162147521973, loss=6.053869724273682
I0302 12:08:56.914130 139758009304832 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.285349726676941, loss=5.866876125335693
I0302 12:09:41.153634 139758017697536 logging_writer.py:48] [1600] global_step=1600, grad_norm=1.1889506578445435, loss=6.466545104980469
I0302 12:10:25.339694 139758009304832 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.2360676527023315, loss=6.562926292419434
I0302 12:11:09.372544 139758017697536 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.9384642243385315, loss=5.6188859939575195
I0302 12:11:43.841995 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:11:55.731029 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:12:03.956877 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:12:05.607448 139953291118400 submission_runner.py:411] Time since start: 965.78s, 	Step: 1880, 	{'train/accuracy': 0.0802929699420929, 'train/loss': 5.186488628387451, 'validation/accuracy': 0.07635999470949173, 'validation/loss': 5.225624084472656, 'validation/num_examples': 50000, 'test/accuracy': 0.05780000239610672, 'test/loss': 5.46556282043457, 'test/num_examples': 10000, 'score': 882.6500160694122, 'total_duration': 965.783664226532, 'accumulated_submission_time': 882.6500160694122, 'accumulated_eval_time': 82.97681331634521, 'accumulated_logging_time': 0.055197954177856445}
I0302 12:12:05.624719 139758009304832 logging_writer.py:48] [1880] accumulated_eval_time=82.976813, accumulated_logging_time=0.055198, accumulated_submission_time=882.650016, global_step=1880, preemption_count=0, score=882.650016, test/accuracy=0.057800, test/loss=5.465563, test/num_examples=10000, total_duration=965.783664, train/accuracy=0.080293, train/loss=5.186489, validation/accuracy=0.076360, validation/loss=5.225624, validation/num_examples=50000
I0302 12:12:13.991404 139758017697536 logging_writer.py:48] [1900] global_step=1900, grad_norm=1.1694982051849365, loss=5.656164169311523
I0302 12:12:53.572813 139758009304832 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.4329912662506104, loss=5.602624893188477
I0302 12:13:37.881857 139758017697536 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.9682188034057617, loss=5.480915069580078
I0302 12:14:21.942606 139758009304832 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.9241686463356018, loss=5.687203407287598
I0302 12:15:06.025149 139758017697536 logging_writer.py:48] [2300] global_step=2300, grad_norm=1.245744228363037, loss=5.514707565307617
I0302 12:15:49.998932 139758009304832 logging_writer.py:48] [2400] global_step=2400, grad_norm=1.0248544216156006, loss=5.3624677658081055
I0302 12:16:34.238986 139758017697536 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.0472493171691895, loss=5.692718505859375
I0302 12:17:18.370369 139758009304832 logging_writer.py:48] [2600] global_step=2600, grad_norm=1.104699730873108, loss=5.264293193817139
I0302 12:18:02.665454 139758017697536 logging_writer.py:48] [2700] global_step=2700, grad_norm=1.180761694908142, loss=5.222769260406494
I0302 12:18:46.500809 139758009304832 logging_writer.py:48] [2800] global_step=2800, grad_norm=1.1329920291900635, loss=5.452509880065918
I0302 12:19:05.669865 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:19:17.627069 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:19:25.677232 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:19:27.319728 139953291118400 submission_runner.py:411] Time since start: 1407.50s, 	Step: 2845, 	{'train/accuracy': 0.15416015684604645, 'train/loss': 4.475606441497803, 'validation/accuracy': 0.1417199969291687, 'validation/loss': 4.5772247314453125, 'validation/num_examples': 50000, 'test/accuracy': 0.10980000346899033, 'test/loss': 4.911513328552246, 'test/num_examples': 10000, 'score': 1302.63339304924, 'total_duration': 1407.4959456920624, 'accumulated_submission_time': 1302.63339304924, 'accumulated_eval_time': 104.62666702270508, 'accumulated_logging_time': 0.08291339874267578}
I0302 12:19:27.336852 139758017697536 logging_writer.py:48] [2845] accumulated_eval_time=104.626667, accumulated_logging_time=0.082913, accumulated_submission_time=1302.633393, global_step=2845, preemption_count=0, score=1302.633393, test/accuracy=0.109800, test/loss=4.911513, test/num_examples=10000, total_duration=1407.495946, train/accuracy=0.154160, train/loss=4.475606, validation/accuracy=0.141720, validation/loss=4.577225, validation/num_examples=50000
I0302 12:19:49.484745 139758009304832 logging_writer.py:48] [2900] global_step=2900, grad_norm=1.0142568349838257, loss=5.353214263916016
I0302 12:20:30.939150 139758017697536 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.8810042142868042, loss=6.449263095855713
I0302 12:21:15.184701 139758009304832 logging_writer.py:48] [3100] global_step=3100, grad_norm=1.3235816955566406, loss=5.613535404205322
I0302 12:21:59.296602 139758017697536 logging_writer.py:48] [3200] global_step=3200, grad_norm=1.0097533464431763, loss=5.069243907928467
I0302 12:22:43.460731 139758009304832 logging_writer.py:48] [3300] global_step=3300, grad_norm=1.0212031602859497, loss=5.456384181976318
I0302 12:23:27.718217 139758017697536 logging_writer.py:48] [3400] global_step=3400, grad_norm=1.1802397966384888, loss=4.972363471984863
I0302 12:24:12.007540 139758009304832 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.7265903949737549, loss=6.284540176391602
I0302 12:24:55.952873 139758017697536 logging_writer.py:48] [3600] global_step=3600, grad_norm=1.2875198125839233, loss=4.973567962646484
I0302 12:25:39.974684 139758009304832 logging_writer.py:48] [3700] global_step=3700, grad_norm=1.0270469188690186, loss=5.389688491821289
I0302 12:26:24.287240 139758017697536 logging_writer.py:48] [3800] global_step=3800, grad_norm=1.0257564783096313, loss=4.825289726257324
I0302 12:26:27.415395 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:26:39.510299 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:26:47.504699 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:26:49.156228 139953291118400 submission_runner.py:411] Time since start: 1849.33s, 	Step: 3809, 	{'train/accuracy': 0.21201170980930328, 'train/loss': 3.999783754348755, 'validation/accuracy': 0.19949999451637268, 'validation/loss': 4.077298641204834, 'validation/num_examples': 50000, 'test/accuracy': 0.14800000190734863, 'test/loss': 4.524412155151367, 'test/num_examples': 10000, 'score': 1722.6479833126068, 'total_duration': 1849.3324444293976, 'accumulated_submission_time': 1722.6479833126068, 'accumulated_eval_time': 126.36748099327087, 'accumulated_logging_time': 0.11241769790649414}
I0302 12:26:49.174279 139758009304832 logging_writer.py:48] [3809] accumulated_eval_time=126.367481, accumulated_logging_time=0.112418, accumulated_submission_time=1722.647983, global_step=3809, preemption_count=0, score=1722.647983, test/accuracy=0.148000, test/loss=4.524412, test/num_examples=10000, total_duration=1849.332444, train/accuracy=0.212012, train/loss=3.999784, validation/accuracy=0.199500, validation/loss=4.077299, validation/num_examples=50000
I0302 12:27:25.593092 139758017697536 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.899084210395813, loss=4.682523727416992
I0302 12:28:09.406971 139758009304832 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.23137629032135, loss=5.1142168045043945
I0302 12:28:53.585591 139758017697536 logging_writer.py:48] [4100] global_step=4100, grad_norm=1.2196701765060425, loss=4.798886775970459
I0302 12:29:37.751957 139758009304832 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.6466265320777893, loss=6.046899318695068
I0302 12:30:21.999684 139758017697536 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.8464418649673462, loss=5.2727155685424805
I0302 12:31:06.110055 139758009304832 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.8930078744888306, loss=5.1552581787109375
I0302 12:31:50.211795 139758017697536 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.7182380557060242, loss=5.613675117492676
I0302 12:32:34.321149 139758009304832 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.907069981098175, loss=6.084774017333984
I0302 12:33:18.582421 139758017697536 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.7185640931129456, loss=6.114286422729492
I0302 12:33:49.234802 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:34:01.293365 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:34:09.709422 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:34:11.358682 139953291118400 submission_runner.py:411] Time since start: 2291.53s, 	Step: 4771, 	{'train/accuracy': 0.27146482467651367, 'train/loss': 3.5543103218078613, 'validation/accuracy': 0.2515200078487396, 'validation/loss': 3.6828715801239014, 'validation/num_examples': 50000, 'test/accuracy': 0.18870000541210175, 'test/loss': 4.161242961883545, 'test/num_examples': 10000, 'score': 2142.643502473831, 'total_duration': 2291.534899711609, 'accumulated_submission_time': 2142.643502473831, 'accumulated_eval_time': 148.49134397506714, 'accumulated_logging_time': 0.1440119743347168}
I0302 12:34:11.378201 139758009304832 logging_writer.py:48] [4771] accumulated_eval_time=148.491344, accumulated_logging_time=0.144012, accumulated_submission_time=2142.643502, global_step=4771, preemption_count=0, score=2142.643502, test/accuracy=0.188700, test/loss=4.161243, test/num_examples=10000, total_duration=2291.534900, train/accuracy=0.271465, train/loss=3.554310, validation/accuracy=0.251520, validation/loss=3.682872, validation/num_examples=50000
I0302 12:34:23.260451 139758017697536 logging_writer.py:48] [4800] global_step=4800, grad_norm=1.033894658088684, loss=4.581789970397949
I0302 12:35:03.308032 139758009304832 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.8282867074012756, loss=4.658007621765137
I0302 12:35:47.602174 139758017697536 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.8874189853668213, loss=4.389495372772217
I0302 12:36:32.335190 139758009304832 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.7617363333702087, loss=5.780642032623291
I0302 12:37:16.957561 139758017697536 logging_writer.py:48] [5200] global_step=5200, grad_norm=1.2754091024398804, loss=4.342465400695801
I0302 12:38:01.150264 139758009304832 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.7518595457077026, loss=4.287382125854492
I0302 12:38:45.361904 139758017697536 logging_writer.py:48] [5400] global_step=5400, grad_norm=1.0805875062942505, loss=4.197921276092529
I0302 12:39:29.604474 139758009304832 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.8496419191360474, loss=6.058797359466553
I0302 12:40:13.892351 139758017697536 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.951395571231842, loss=4.181175231933594
I0302 12:40:57.789713 139758009304832 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.8503248691558838, loss=4.1040215492248535
I0302 12:41:11.480308 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:41:23.494726 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:41:31.497031 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:41:33.142825 139953291118400 submission_runner.py:411] Time since start: 2733.32s, 	Step: 5732, 	{'train/accuracy': 0.32369139790534973, 'train/loss': 3.2366814613342285, 'validation/accuracy': 0.2985199987888336, 'validation/loss': 3.391303062438965, 'validation/num_examples': 50000, 'test/accuracy': 0.22520001232624054, 'test/loss': 3.9291419982910156, 'test/num_examples': 10000, 'score': 2562.6839604377747, 'total_duration': 2733.3190398216248, 'accumulated_submission_time': 2562.6839604377747, 'accumulated_eval_time': 170.15383672714233, 'accumulated_logging_time': 0.1743319034576416}
I0302 12:41:33.162462 139758017697536 logging_writer.py:48] [5732] accumulated_eval_time=170.153837, accumulated_logging_time=0.174332, accumulated_submission_time=2562.683960, global_step=5732, preemption_count=0, score=2562.683960, test/accuracy=0.225200, test/loss=3.929142, test/num_examples=10000, total_duration=2733.319040, train/accuracy=0.323691, train/loss=3.236681, validation/accuracy=0.298520, validation/loss=3.391303, validation/num_examples=50000
I0302 12:42:00.470393 139758009304832 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.818485677242279, loss=4.078963279724121
I0302 12:42:42.296971 139758017697536 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.7829355597496033, loss=4.317657470703125
I0302 12:43:26.750062 139758009304832 logging_writer.py:48] [6000] global_step=6000, grad_norm=1.1006500720977783, loss=4.245577335357666
I0302 12:44:11.101648 139758017697536 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.6850242614746094, loss=5.425948143005371
I0302 12:44:55.280384 139758009304832 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.9976946115493774, loss=4.054099082946777
I0302 12:45:40.189827 139758017697536 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.6918126344680786, loss=5.999732971191406
I0302 12:46:25.014264 139758009304832 logging_writer.py:48] [6400] global_step=6400, grad_norm=1.0557740926742554, loss=3.935648202896118
I0302 12:47:09.908594 139758017697536 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.7275208234786987, loss=5.272732734680176
I0302 12:47:54.011176 139758009304832 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.8946456909179688, loss=4.2104973793029785
I0302 12:48:33.409218 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:48:45.639341 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:48:53.697680 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:48:55.328970 139953291118400 submission_runner.py:411] Time since start: 3175.51s, 	Step: 6691, 	{'train/accuracy': 0.38283202052116394, 'train/loss': 2.853161573410034, 'validation/accuracy': 0.3342599868774414, 'validation/loss': 3.1353304386138916, 'validation/num_examples': 50000, 'test/accuracy': 0.2591000199317932, 'test/loss': 3.685933828353882, 'test/num_examples': 10000, 'score': 2982.868365049362, 'total_duration': 3175.5051844120026, 'accumulated_submission_time': 2982.868365049362, 'accumulated_eval_time': 192.07357716560364, 'accumulated_logging_time': 0.2041935920715332}
I0302 12:48:55.347705 139758017697536 logging_writer.py:48] [6691] accumulated_eval_time=192.073577, accumulated_logging_time=0.204194, accumulated_submission_time=2982.868365, global_step=6691, preemption_count=0, score=2982.868365, test/accuracy=0.259100, test/loss=3.685934, test/num_examples=10000, total_duration=3175.505184, train/accuracy=0.382832, train/loss=2.853162, validation/accuracy=0.334260, validation/loss=3.135330, validation/num_examples=50000
I0302 12:48:59.340992 139758009304832 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.9061523079872131, loss=3.843660831451416
I0302 12:49:39.172399 139758017697536 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.9655725359916687, loss=3.84629487991333
I0302 12:50:23.358798 139758009304832 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.8589656949043274, loss=5.7591938972473145
I0302 12:51:07.547723 139758017697536 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.0222623348236084, loss=3.840416431427002
I0302 12:51:51.959248 139758009304832 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.8557090163230896, loss=5.822472095489502
I0302 12:52:36.206217 139758017697536 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.7125732898712158, loss=5.5753960609436035
I0302 12:53:20.546006 139758009304832 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.9012677073478699, loss=3.8094441890716553
I0302 12:54:05.123862 139758017697536 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.9028963446617126, loss=3.845287799835205
I0302 12:54:49.683687 139758009304832 logging_writer.py:48] [7500] global_step=7500, grad_norm=1.090847373008728, loss=3.7969627380371094
I0302 12:55:34.434266 139758017697536 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.7096635699272156, loss=4.51650857925415
I0302 12:55:55.596607 139953291118400 spec.py:321] Evaluating on the training split.
I0302 12:56:07.849232 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 12:56:19.543495 139953291118400 spec.py:349] Evaluating on the test split.
I0302 12:56:21.194900 139953291118400 submission_runner.py:411] Time since start: 3621.37s, 	Step: 7649, 	{'train/accuracy': 0.3971289098262787, 'train/loss': 2.773566722869873, 'validation/accuracy': 0.3694399893283844, 'validation/loss': 2.9177207946777344, 'validation/num_examples': 50000, 'test/accuracy': 0.2818000018596649, 'test/loss': 3.512402057647705, 'test/num_examples': 10000, 'score': 3403.056977033615, 'total_duration': 3621.3701384067535, 'accumulated_submission_time': 3403.056977033615, 'accumulated_eval_time': 217.67090773582458, 'accumulated_logging_time': 0.2334585189819336}
I0302 12:56:21.214630 139758009304832 logging_writer.py:48] [7649] accumulated_eval_time=217.670908, accumulated_logging_time=0.233459, accumulated_submission_time=3403.056977, global_step=7649, preemption_count=0, score=3403.056977, test/accuracy=0.281800, test/loss=3.512402, test/num_examples=10000, total_duration=3621.370138, train/accuracy=0.397129, train/loss=2.773567, validation/accuracy=0.369440, validation/loss=2.917721, validation/num_examples=50000
I0302 12:56:41.820864 139758017697536 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.9148348569869995, loss=3.7532994747161865
I0302 12:57:24.100545 139758009304832 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.958297610282898, loss=3.6600844860076904
I0302 12:58:08.270001 139758017697536 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.751151978969574, loss=5.250362396240234
I0302 12:58:52.490713 139758009304832 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.8968243598937988, loss=3.7495856285095215
I0302 12:59:36.794407 139758017697536 logging_writer.py:48] [8100] global_step=8100, grad_norm=1.0207701921463013, loss=3.678779125213623
I0302 13:00:20.928871 139758009304832 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.8660468459129333, loss=4.5110859870910645
I0302 13:01:05.275234 139758017697536 logging_writer.py:48] [8300] global_step=8300, grad_norm=1.001204490661621, loss=3.6051366329193115
I0302 13:01:49.348643 139758009304832 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.824323832988739, loss=3.7186830043792725
I0302 13:02:33.689656 139758017697536 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.7590427994728088, loss=5.860085964202881
I0302 13:03:18.430206 139758009304832 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.8840622305870056, loss=4.791513919830322
I0302 13:03:21.630343 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:03:33.926897 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:03:52.307916 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:03:53.946692 139953291118400 submission_runner.py:411] Time since start: 4074.12s, 	Step: 8609, 	{'train/accuracy': 0.42283201217651367, 'train/loss': 2.6493871212005615, 'validation/accuracy': 0.3889999985694885, 'validation/loss': 2.8133010864257812, 'validation/num_examples': 50000, 'test/accuracy': 0.30010002851486206, 'test/loss': 3.4087908267974854, 'test/num_examples': 10000, 'score': 3823.41290307045, 'total_duration': 4074.1229090690613, 'accumulated_submission_time': 3823.41290307045, 'accumulated_eval_time': 249.9872395992279, 'accumulated_logging_time': 0.2634403705596924}
I0302 13:03:53.968826 139758017697536 logging_writer.py:48] [8609] accumulated_eval_time=249.987240, accumulated_logging_time=0.263440, accumulated_submission_time=3823.412903, global_step=8609, preemption_count=0, score=3823.412903, test/accuracy=0.300100, test/loss=3.408791, test/num_examples=10000, total_duration=4074.122909, train/accuracy=0.422832, train/loss=2.649387, validation/accuracy=0.389000, validation/loss=2.813301, validation/num_examples=50000
I0302 13:04:30.338099 139758009304832 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.8343627452850342, loss=4.400117874145508
I0302 13:05:14.492146 139758017697536 logging_writer.py:48] [8800] global_step=8800, grad_norm=1.1320853233337402, loss=3.5076992511749268
I0302 13:05:58.663327 139758009304832 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.8966866135597229, loss=3.816124439239502
I0302 13:06:42.939279 139758017697536 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.967807948589325, loss=4.188731670379639
I0302 13:07:27.204054 139758009304832 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.9801889061927795, loss=3.4069881439208984
I0302 13:08:11.414555 139758017697536 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.8198400139808655, loss=5.920956611633301
I0302 13:08:55.469424 139758009304832 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.8799039125442505, loss=4.057348251342773
I0302 13:09:39.525923 139758017697536 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.8461459875106812, loss=5.926609516143799
I0302 13:10:23.939858 139758009304832 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.9828367233276367, loss=3.362241506576538
I0302 13:10:54.202784 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:11:06.836817 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:11:18.346068 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:11:19.989236 139953291118400 submission_runner.py:411] Time since start: 4520.17s, 	Step: 9570, 	{'train/accuracy': 0.4484570324420929, 'train/loss': 2.4750478267669678, 'validation/accuracy': 0.4088599979877472, 'validation/loss': 2.6899614334106445, 'validation/num_examples': 50000, 'test/accuracy': 0.31280001997947693, 'test/loss': 3.3069517612457275, 'test/num_examples': 10000, 'score': 4243.586100816727, 'total_duration': 4520.165455341339, 'accumulated_submission_time': 4243.586100816727, 'accumulated_eval_time': 275.773681640625, 'accumulated_logging_time': 0.296008825302124}
I0302 13:11:20.009244 139758017697536 logging_writer.py:48] [9570] accumulated_eval_time=275.773682, accumulated_logging_time=0.296009, accumulated_submission_time=4243.586101, global_step=9570, preemption_count=0, score=4243.586101, test/accuracy=0.312800, test/loss=3.306952, test/num_examples=10000, total_duration=4520.165455, train/accuracy=0.448457, train/loss=2.475048, validation/accuracy=0.408860, validation/loss=2.689961, validation/num_examples=50000
I0302 13:11:32.287739 139758009304832 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.8539727330207825, loss=4.79020881652832
I0302 13:12:13.797576 139758017697536 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.6965375542640686, loss=5.461703777313232
I0302 13:12:58.287617 139758009304832 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.8768924474716187, loss=3.812743902206421
I0302 13:13:42.843790 139758017697536 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.9292780160903931, loss=5.375217437744141
I0302 13:14:27.617243 139758009304832 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.8536433577537537, loss=4.65800142288208
I0302 13:15:12.062965 139758017697536 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.8357889652252197, loss=5.5830254554748535
I0302 13:15:56.102828 139758009304832 logging_writer.py:48] [10200] global_step=10200, grad_norm=1.0251002311706543, loss=3.603055238723755
I0302 13:16:40.639921 139758017697536 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.9379895329475403, loss=3.8187735080718994
I0302 13:17:24.903684 139758009304832 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.6768273711204529, loss=5.251473426818848
I0302 13:18:08.977972 139758017697536 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.9558067321777344, loss=3.482358694076538
I0302 13:18:20.101482 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:18:32.386731 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:18:44.026914 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:18:45.681043 139953291118400 submission_runner.py:411] Time since start: 4965.86s, 	Step: 10527, 	{'train/accuracy': 0.4597460925579071, 'train/loss': 2.403148651123047, 'validation/accuracy': 0.4257799983024597, 'validation/loss': 2.5876495838165283, 'validation/num_examples': 50000, 'test/accuracy': 0.32360002398490906, 'test/loss': 3.2185275554656982, 'test/num_examples': 10000, 'score': 4663.614185810089, 'total_duration': 4965.85725569725, 'accumulated_submission_time': 4663.614185810089, 'accumulated_eval_time': 301.3532176017761, 'accumulated_logging_time': 0.32981419563293457}
I0302 13:18:45.703058 139758009304832 logging_writer.py:48] [10527] accumulated_eval_time=301.353218, accumulated_logging_time=0.329814, accumulated_submission_time=4663.614186, global_step=10527, preemption_count=0, score=4663.614186, test/accuracy=0.323600, test/loss=3.218528, test/num_examples=10000, total_duration=4965.857256, train/accuracy=0.459746, train/loss=2.403149, validation/accuracy=0.425780, validation/loss=2.587650, validation/num_examples=50000
I0302 13:19:14.954021 139758017697536 logging_writer.py:48] [10600] global_step=10600, grad_norm=1.0673669576644897, loss=3.383985996246338
I0302 13:19:57.577138 139758009304832 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.9524732232093811, loss=4.019099235534668
I0302 13:20:42.071229 139758017697536 logging_writer.py:48] [10800] global_step=10800, grad_norm=1.013548731803894, loss=3.3227546215057373
I0302 13:21:26.431828 139758009304832 logging_writer.py:48] [10900] global_step=10900, grad_norm=1.02898371219635, loss=3.2549538612365723
I0302 13:22:10.936308 139758017697536 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.7491529583930969, loss=4.4924845695495605
I0302 13:22:55.207438 139758009304832 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.9673788547515869, loss=3.386742115020752
I0302 13:23:39.753952 139758017697536 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.8521608114242554, loss=4.059780597686768
I0302 13:24:24.332150 139758009304832 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.8900598287582397, loss=3.262397289276123
I0302 13:25:08.738898 139758017697536 logging_writer.py:48] [11400] global_step=11400, grad_norm=1.1388012170791626, loss=3.329134941101074
I0302 13:25:45.752382 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:25:58.613787 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:26:11.948219 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:26:13.587530 139953291118400 submission_runner.py:411] Time since start: 5413.76s, 	Step: 11485, 	{'train/accuracy': 0.4774218499660492, 'train/loss': 2.352294921875, 'validation/accuracy': 0.4411799907684326, 'validation/loss': 2.527583599090576, 'validation/num_examples': 50000, 'test/accuracy': 0.34610000252723694, 'test/loss': 3.1271629333496094, 'test/num_examples': 10000, 'score': 5083.6017208099365, 'total_duration': 5413.7637457847595, 'accumulated_submission_time': 5083.6017208099365, 'accumulated_eval_time': 329.1883616447449, 'accumulated_logging_time': 0.3632173538208008}
I0302 13:26:13.607223 139758009304832 logging_writer.py:48] [11485] accumulated_eval_time=329.188362, accumulated_logging_time=0.363217, accumulated_submission_time=5083.601721, global_step=11485, preemption_count=0, score=5083.601721, test/accuracy=0.346100, test/loss=3.127163, test/num_examples=10000, total_duration=5413.763746, train/accuracy=0.477422, train/loss=2.352295, validation/accuracy=0.441180, validation/loss=2.527584, validation/num_examples=50000
I0302 13:26:19.938518 139758017697536 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.9928252100944519, loss=3.314314842224121
I0302 13:27:00.304299 139758009304832 logging_writer.py:48] [11600] global_step=11600, grad_norm=1.1077953577041626, loss=3.427372932434082
I0302 13:27:44.416364 139758017697536 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.8266717195510864, loss=4.217048168182373
I0302 13:28:28.663467 139758009304832 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.9846404194831848, loss=4.072101593017578
I0302 13:29:12.975670 139758017697536 logging_writer.py:48] [11900] global_step=11900, grad_norm=1.2468655109405518, loss=3.426347494125366
I0302 13:29:57.100118 139758009304832 logging_writer.py:48] [12000] global_step=12000, grad_norm=1.0527914762496948, loss=3.2734968662261963
I0302 13:30:41.553382 139758017697536 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.9570241570472717, loss=3.286137819290161
I0302 13:31:25.950724 139758009304832 logging_writer.py:48] [12200] global_step=12200, grad_norm=1.0500425100326538, loss=3.2791812419891357
I0302 13:32:10.307200 139758017697536 logging_writer.py:48] [12300] global_step=12300, grad_norm=1.0759799480438232, loss=3.4754672050476074
I0302 13:32:55.202584 139758009304832 logging_writer.py:48] [12400] global_step=12400, grad_norm=1.0469461679458618, loss=3.1798367500305176
I0302 13:33:13.741797 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:33:27.024902 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:33:39.991317 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:33:41.631318 139953291118400 submission_runner.py:411] Time since start: 5861.81s, 	Step: 12442, 	{'train/accuracy': 0.5004491806030273, 'train/loss': 2.173110246658325, 'validation/accuracy': 0.45895999670028687, 'validation/loss': 2.39906644821167, 'validation/num_examples': 50000, 'test/accuracy': 0.3476000130176544, 'test/loss': 3.0680062770843506, 'test/num_examples': 10000, 'score': 5503.675626039505, 'total_duration': 5861.807518482208, 'accumulated_submission_time': 5503.675626039505, 'accumulated_eval_time': 357.07783699035645, 'accumulated_logging_time': 0.39327120780944824}
I0302 13:33:41.651146 139758017697536 logging_writer.py:48] [12442] accumulated_eval_time=357.077837, accumulated_logging_time=0.393271, accumulated_submission_time=5503.675626, global_step=12442, preemption_count=0, score=5503.675626, test/accuracy=0.347600, test/loss=3.068006, test/num_examples=10000, total_duration=5861.807518, train/accuracy=0.500449, train/loss=2.173110, validation/accuracy=0.458960, validation/loss=2.399066, validation/num_examples=50000
I0302 13:34:04.990508 139758009304832 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.8067665696144104, loss=3.840855598449707
I0302 13:34:48.332039 139758017697536 logging_writer.py:48] [12600] global_step=12600, grad_norm=1.182821273803711, loss=3.3934881687164307
I0302 13:35:32.865629 139758009304832 logging_writer.py:48] [12700] global_step=12700, grad_norm=1.1160352230072021, loss=3.258152484893799
I0302 13:36:17.725934 139758017697536 logging_writer.py:48] [12800] global_step=12800, grad_norm=1.1236505508422852, loss=3.2053561210632324
I0302 13:37:02.396803 139758009304832 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.8809230327606201, loss=3.567650556564331
I0302 13:37:46.984421 139758017697536 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.151920199394226, loss=3.164844512939453
I0302 13:38:31.819474 139758009304832 logging_writer.py:48] [13100] global_step=13100, grad_norm=1.3215302228927612, loss=3.221047878265381
I0302 13:39:16.331761 139758017697536 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.9869573712348938, loss=3.6578736305236816
I0302 13:40:00.342579 139758009304832 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.9972898960113525, loss=3.59775447845459
I0302 13:40:41.763558 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:40:54.837391 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:41:08.921729 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:41:10.559340 139953291118400 submission_runner.py:411] Time since start: 6310.74s, 	Step: 13395, 	{'train/accuracy': 0.5154492259025574, 'train/loss': 2.150564432144165, 'validation/accuracy': 0.4667999744415283, 'validation/loss': 2.3906404972076416, 'validation/num_examples': 50000, 'test/accuracy': 0.36550000309944153, 'test/loss': 3.0263166427612305, 'test/num_examples': 10000, 'score': 5923.727476358414, 'total_duration': 6310.735496520996, 'accumulated_submission_time': 5923.727476358414, 'accumulated_eval_time': 385.8735525608063, 'accumulated_logging_time': 0.42369985580444336}
I0302 13:41:10.579573 139758017697536 logging_writer.py:48] [13395] accumulated_eval_time=385.873553, accumulated_logging_time=0.423700, accumulated_submission_time=5923.727476, global_step=13395, preemption_count=0, score=5923.727476, test/accuracy=0.365500, test/loss=3.026317, test/num_examples=10000, total_duration=6310.735497, train/accuracy=0.515449, train/loss=2.150564, validation/accuracy=0.466800, validation/loss=2.390640, validation/num_examples=50000
I0302 13:41:12.976837 139758009304832 logging_writer.py:48] [13400] global_step=13400, grad_norm=1.0526947975158691, loss=3.0301828384399414
I0302 13:41:53.168426 139758017697536 logging_writer.py:48] [13500] global_step=13500, grad_norm=1.0339257717132568, loss=3.2207205295562744
I0302 13:42:37.829426 139758009304832 logging_writer.py:48] [13600] global_step=13600, grad_norm=1.181764006614685, loss=4.670036792755127
I0302 13:43:22.851744 139758017697536 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.9556021690368652, loss=4.077657222747803
I0302 13:44:08.076832 139758009304832 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.7313352227210999, loss=5.617435455322266
I0302 13:44:52.791612 139758017697536 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.9643980264663696, loss=3.110436201095581
I0302 13:45:37.192790 139758009304832 logging_writer.py:48] [14000] global_step=14000, grad_norm=1.0061242580413818, loss=3.128538131713867
I0302 13:46:21.584834 139758017697536 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.8816753029823303, loss=3.8150899410247803
I0302 13:47:06.102397 139758009304832 logging_writer.py:48] [14200] global_step=14200, grad_norm=1.077486515045166, loss=3.1728696823120117
I0302 13:47:50.808909 139758017697536 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.9610593914985657, loss=4.751064777374268
I0302 13:48:10.755032 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:48:24.854461 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:48:39.918116 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:48:41.568675 139953291118400 submission_runner.py:411] Time since start: 6761.74s, 	Step: 14346, 	{'train/accuracy': 0.519238293170929, 'train/loss': 2.1266376972198486, 'validation/accuracy': 0.48023998737335205, 'validation/loss': 2.3121743202209473, 'validation/num_examples': 50000, 'test/accuracy': 0.37470000982284546, 'test/loss': 2.943275213241577, 'test/num_examples': 10000, 'score': 6343.8371758461, 'total_duration': 6761.744855165482, 'accumulated_submission_time': 6343.8371758461, 'accumulated_eval_time': 416.6871347427368, 'accumulated_logging_time': 0.4599125385284424}
I0302 13:48:41.591420 139758009304832 logging_writer.py:48] [14346] accumulated_eval_time=416.687135, accumulated_logging_time=0.459913, accumulated_submission_time=6343.837176, global_step=14346, preemption_count=0, score=6343.837176, test/accuracy=0.374700, test/loss=2.943275, test/num_examples=10000, total_duration=6761.744855, train/accuracy=0.519238, train/loss=2.126638, validation/accuracy=0.480240, validation/loss=2.312174, validation/num_examples=50000
I0302 13:49:03.336361 139758017697536 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.9813652634620667, loss=3.114405632019043
I0302 13:49:46.045739 139758009304832 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.1019996404647827, loss=3.1711158752441406
I0302 13:50:30.805708 139758017697536 logging_writer.py:48] [14600] global_step=14600, grad_norm=1.0690983533859253, loss=3.157930850982666
I0302 13:51:15.603279 139758009304832 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.993121862411499, loss=3.1291110515594482
I0302 13:52:00.546213 139758017697536 logging_writer.py:48] [14800] global_step=14800, grad_norm=1.0031726360321045, loss=3.7286481857299805
I0302 13:52:45.747206 139758009304832 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.8347730040550232, loss=4.454329490661621
I0302 13:53:30.908966 139758017697536 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.1527950763702393, loss=3.0031051635742188
I0302 13:54:15.572962 139758009304832 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.9822812080383301, loss=3.7972865104675293
I0302 13:55:00.118083 139758017697536 logging_writer.py:48] [15200] global_step=15200, grad_norm=1.1619378328323364, loss=2.981083393096924
I0302 13:55:41.904599 139953291118400 spec.py:321] Evaluating on the training split.
I0302 13:55:56.324060 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 13:56:10.474677 139953291118400 spec.py:349] Evaluating on the test split.
I0302 13:56:12.118633 139953291118400 submission_runner.py:411] Time since start: 7212.29s, 	Step: 15295, 	{'train/accuracy': 0.5322265625, 'train/loss': 2.005976915359497, 'validation/accuracy': 0.4880199730396271, 'validation/loss': 2.22807240486145, 'validation/num_examples': 50000, 'test/accuracy': 0.38380002975463867, 'test/loss': 2.8951008319854736, 'test/num_examples': 10000, 'score': 6764.088172674179, 'total_duration': 7212.294851779938, 'accumulated_submission_time': 6764.088172674179, 'accumulated_eval_time': 446.9011867046356, 'accumulated_logging_time': 0.4952383041381836}
I0302 13:56:12.139184 139758009304832 logging_writer.py:48] [15295] accumulated_eval_time=446.901187, accumulated_logging_time=0.495238, accumulated_submission_time=6764.088173, global_step=15295, preemption_count=0, score=6764.088173, test/accuracy=0.383800, test/loss=2.895101, test/num_examples=10000, total_duration=7212.294852, train/accuracy=0.532227, train/loss=2.005977, validation/accuracy=0.488020, validation/loss=2.228072, validation/num_examples=50000
I0302 13:56:14.526916 139758017697536 logging_writer.py:48] [15300] global_step=15300, grad_norm=1.042952060699463, loss=3.727057456970215
I0302 13:56:55.389262 139758009304832 logging_writer.py:48] [15400] global_step=15400, grad_norm=1.158886194229126, loss=3.5533154010772705
I0302 13:57:40.274682 139758017697536 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.4425644874572754, loss=3.0022940635681152
I0302 13:58:25.015514 139758009304832 logging_writer.py:48] [15600] global_step=15600, grad_norm=1.0071324110031128, loss=4.589593410491943
I0302 13:59:09.864010 139758017697536 logging_writer.py:48] [15700] global_step=15700, grad_norm=1.1896076202392578, loss=3.139246940612793
I0302 13:59:54.447258 139758009304832 logging_writer.py:48] [15800] global_step=15800, grad_norm=1.0984057188034058, loss=3.0179531574249268
I0302 14:00:39.187002 139758017697536 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.8131813406944275, loss=4.220037460327148
I0302 14:01:23.858730 139758009304832 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.8331851959228516, loss=5.250403881072998
I0302 14:02:08.562424 139758017697536 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.866968035697937, loss=5.579103946685791
I0302 14:02:53.407425 139758009304832 logging_writer.py:48] [16200] global_step=16200, grad_norm=1.008987307548523, loss=5.633645057678223
I0302 14:03:12.460580 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:03:26.377775 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:03:40.567405 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:03:42.199592 139953291118400 submission_runner.py:411] Time since start: 7662.38s, 	Step: 16244, 	{'train/accuracy': 0.5482421517372131, 'train/loss': 1.9572895765304565, 'validation/accuracy': 0.501259982585907, 'validation/loss': 2.1907479763031006, 'validation/num_examples': 50000, 'test/accuracy': 0.39260002970695496, 'test/loss': 2.8501899242401123, 'test/num_examples': 10000, 'score': 7184.348518371582, 'total_duration': 7662.375813245773, 'accumulated_submission_time': 7184.348518371582, 'accumulated_eval_time': 476.6402099132538, 'accumulated_logging_time': 0.5272412300109863}
I0302 14:03:42.222035 139758017697536 logging_writer.py:48] [16244] accumulated_eval_time=476.640210, accumulated_logging_time=0.527241, accumulated_submission_time=7184.348518, global_step=16244, preemption_count=0, score=7184.348518, test/accuracy=0.392600, test/loss=2.850190, test/num_examples=10000, total_duration=7662.375813, train/accuracy=0.548242, train/loss=1.957290, validation/accuracy=0.501260, validation/loss=2.190748, validation/num_examples=50000
I0302 14:04:04.768608 139758009304832 logging_writer.py:48] [16300] global_step=16300, grad_norm=1.1941213607788086, loss=2.965808391571045
I0302 14:04:48.142259 139758017697536 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.7785388827323914, loss=5.463795185089111
I0302 14:05:32.788823 139758009304832 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.9182187914848328, loss=4.292205333709717
I0302 14:06:17.612072 139758017697536 logging_writer.py:48] [16600] global_step=16600, grad_norm=1.2322895526885986, loss=3.2313785552978516
I0302 14:07:02.280701 139758009304832 logging_writer.py:48] [16700] global_step=16700, grad_norm=1.0111521482467651, loss=4.608789920806885
I0302 14:07:46.901984 139758017697536 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.9897801280021667, loss=3.9400877952575684
I0302 14:08:31.700018 139758009304832 logging_writer.py:48] [16900] global_step=16900, grad_norm=1.0534727573394775, loss=3.2909975051879883
I0302 14:09:16.487186 139758017697536 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.8201897144317627, loss=4.780871391296387
I0302 14:10:01.014616 139758009304832 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.984798014163971, loss=3.192927598953247
I0302 14:10:42.234640 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:10:56.761415 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:11:11.689192 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:11:13.333040 139953291118400 submission_runner.py:411] Time since start: 8113.51s, 	Step: 17194, 	{'train/accuracy': 0.5625194907188416, 'train/loss': 1.8765634298324585, 'validation/accuracy': 0.5061399936676025, 'validation/loss': 2.151052713394165, 'validation/num_examples': 50000, 'test/accuracy': 0.38960000872612, 'test/loss': 2.8292672634124756, 'test/num_examples': 10000, 'score': 7604.298126220703, 'total_duration': 8113.509242534637, 'accumulated_submission_time': 7604.298126220703, 'accumulated_eval_time': 507.73856592178345, 'accumulated_logging_time': 0.5607478618621826}
I0302 14:11:13.366115 139758017697536 logging_writer.py:48] [17194] accumulated_eval_time=507.738566, accumulated_logging_time=0.560748, accumulated_submission_time=7604.298126, global_step=17194, preemption_count=0, score=7604.298126, test/accuracy=0.389600, test/loss=2.829267, test/num_examples=10000, total_duration=8113.509243, train/accuracy=0.562519, train/loss=1.876563, validation/accuracy=0.506140, validation/loss=2.151053, validation/num_examples=50000
I0302 14:11:16.153042 139758009304832 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.944847583770752, loss=3.4452109336853027
I0302 14:11:56.469309 139758017697536 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.8952572345733643, loss=5.5769429206848145
I0302 14:12:41.098845 139758009304832 logging_writer.py:48] [17400] global_step=17400, grad_norm=1.2081376314163208, loss=3.5261332988739014
I0302 14:13:26.047688 139758017697536 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.0425301790237427, loss=2.9203710556030273
I0302 14:14:10.942368 139758009304832 logging_writer.py:48] [17600] global_step=17600, grad_norm=1.1109193563461304, loss=3.011370897293091
I0302 14:14:55.701707 139758017697536 logging_writer.py:48] [17700] global_step=17700, grad_norm=1.222079873085022, loss=2.911062479019165
I0302 14:15:40.932845 139758009304832 logging_writer.py:48] [17800] global_step=17800, grad_norm=1.1700886487960815, loss=2.959791898727417
I0302 14:16:26.025373 139758017697536 logging_writer.py:48] [17900] global_step=17900, grad_norm=1.6422386169433594, loss=3.061460018157959
I0302 14:17:11.001649 139758009304832 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.9561320543289185, loss=3.976672410964966
I0302 14:17:55.818380 139758017697536 logging_writer.py:48] [18100] global_step=18100, grad_norm=1.1394892930984497, loss=2.874204397201538
I0302 14:18:13.504895 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:18:28.170293 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:18:43.710165 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:18:45.346625 139953291118400 submission_runner.py:411] Time since start: 8565.52s, 	Step: 18141, 	{'train/accuracy': 0.5486718416213989, 'train/loss': 1.9616918563842773, 'validation/accuracy': 0.5062800049781799, 'validation/loss': 2.1555776596069336, 'validation/num_examples': 50000, 'test/accuracy': 0.3961000144481659, 'test/loss': 2.798175811767578, 'test/num_examples': 10000, 'score': 8024.374304771423, 'total_duration': 8565.522846698761, 'accumulated_submission_time': 8024.374304771423, 'accumulated_eval_time': 539.5802881717682, 'accumulated_logging_time': 0.6070611476898193}
I0302 14:18:45.368072 139758009304832 logging_writer.py:48] [18141] accumulated_eval_time=539.580288, accumulated_logging_time=0.607061, accumulated_submission_time=8024.374305, global_step=18141, preemption_count=0, score=8024.374305, test/accuracy=0.396100, test/loss=2.798176, test/num_examples=10000, total_duration=8565.522847, train/accuracy=0.548672, train/loss=1.961692, validation/accuracy=0.506280, validation/loss=2.155578, validation/num_examples=50000
I0302 14:19:09.248154 139758017697536 logging_writer.py:48] [18200] global_step=18200, grad_norm=1.0991711616516113, loss=2.8963916301727295
I0302 14:19:52.254299 139758009304832 logging_writer.py:48] [18300] global_step=18300, grad_norm=1.0893056392669678, loss=3.5102157592773438
I0302 14:20:37.252459 139758017697536 logging_writer.py:48] [18400] global_step=18400, grad_norm=1.0407798290252686, loss=3.1780834197998047
I0302 14:21:21.818082 139758009304832 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.2468452453613281, loss=3.158804178237915
I0302 14:22:06.730432 139758017697536 logging_writer.py:48] [18600] global_step=18600, grad_norm=1.342025637626648, loss=3.461380958557129
I0302 14:22:52.092240 139758009304832 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.8917214274406433, loss=3.751126289367676
I0302 14:23:37.107480 139758017697536 logging_writer.py:48] [18800] global_step=18800, grad_norm=1.0114829540252686, loss=3.0951292514801025
I0302 14:24:21.976696 139758009304832 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.9572939276695251, loss=5.416184425354004
I0302 14:25:06.773226 139758017697536 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.8973352909088135, loss=4.335707187652588
I0302 14:25:45.787278 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:26:00.265811 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:26:15.800037 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:26:17.441032 139953291118400 submission_runner.py:411] Time since start: 9017.62s, 	Step: 19089, 	{'train/accuracy': 0.5634179711341858, 'train/loss': 1.8526079654693604, 'validation/accuracy': 0.5212599635124207, 'validation/loss': 2.0621883869171143, 'validation/num_examples': 50000, 'test/accuracy': 0.4065000116825104, 'test/loss': 2.7337896823883057, 'test/num_examples': 10000, 'score': 8444.733457803726, 'total_duration': 9017.617252111435, 'accumulated_submission_time': 8444.733457803726, 'accumulated_eval_time': 571.2340226173401, 'accumulated_logging_time': 0.6397192478179932}
I0302 14:26:17.463668 139758009304832 logging_writer.py:48] [19089] accumulated_eval_time=571.234023, accumulated_logging_time=0.639719, accumulated_submission_time=8444.733458, global_step=19089, preemption_count=0, score=8444.733458, test/accuracy=0.406500, test/loss=2.733790, test/num_examples=10000, total_duration=9017.617252, train/accuracy=0.563418, train/loss=1.852608, validation/accuracy=0.521260, validation/loss=2.062188, validation/num_examples=50000
I0302 14:26:22.209057 139758017697536 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.9011408090591431, loss=4.01527214050293
I0302 14:27:03.634814 139758009304832 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.9047099947929382, loss=5.0958051681518555
I0302 14:27:48.281479 139758017697536 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.9697213768959045, loss=4.072723865509033
I0302 14:28:33.043345 139758009304832 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.9772347211837769, loss=4.637601375579834
I0302 14:29:17.705287 139758017697536 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.0718060731887817, loss=3.356220006942749
I0302 14:30:02.622286 139758009304832 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.9483914971351624, loss=4.463667869567871
I0302 14:30:46.978728 139758017697536 logging_writer.py:48] [19700] global_step=19700, grad_norm=1.0238022804260254, loss=3.457418918609619
I0302 14:31:31.749792 139758009304832 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.944473385810852, loss=4.468791961669922
I0302 14:32:16.288934 139758017697536 logging_writer.py:48] [19900] global_step=19900, grad_norm=1.0627930164337158, loss=2.802095413208008
I0302 14:33:01.016853 139758009304832 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.1683670282363892, loss=3.1594274044036865
I0302 14:33:17.732575 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:33:31.729350 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:33:47.278105 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:33:48.916754 139953291118400 submission_runner.py:411] Time since start: 9469.09s, 	Step: 20038, 	{'train/accuracy': 0.5821679830551147, 'train/loss': 1.7724109888076782, 'validation/accuracy': 0.5266799926757812, 'validation/loss': 2.037682056427002, 'validation/num_examples': 50000, 'test/accuracy': 0.414900004863739, 'test/loss': 2.704115629196167, 'test/num_examples': 10000, 'score': 8864.943633794785, 'total_duration': 9469.092945098877, 'accumulated_submission_time': 8864.943633794785, 'accumulated_eval_time': 602.41819190979, 'accumulated_logging_time': 0.6724779605865479}
I0302 14:33:48.940412 139758017697536 logging_writer.py:48] [20038] accumulated_eval_time=602.418192, accumulated_logging_time=0.672478, accumulated_submission_time=8864.943634, global_step=20038, preemption_count=0, score=8864.943634, test/accuracy=0.414900, test/loss=2.704116, test/num_examples=10000, total_duration=9469.092945, train/accuracy=0.582168, train/loss=1.772411, validation/accuracy=0.526680, validation/loss=2.037682, validation/num_examples=50000
I0302 14:34:13.831980 139758009304832 logging_writer.py:48] [20100] global_step=20100, grad_norm=1.065932035446167, loss=2.947472095489502
I0302 14:34:57.616610 139758017697536 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.9514305591583252, loss=3.36458158493042
I0302 14:35:42.318503 139758009304832 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.8971476554870605, loss=4.545201301574707
I0302 14:36:27.006864 139758017697536 logging_writer.py:48] [20400] global_step=20400, grad_norm=1.0009384155273438, loss=2.8524346351623535
I0302 14:37:11.682281 139758009304832 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.2700153589248657, loss=2.8654491901397705
I0302 14:37:56.350701 139758017697536 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.9161431193351746, loss=4.430026054382324
I0302 14:38:41.311972 139758009304832 logging_writer.py:48] [20700] global_step=20700, grad_norm=1.1067780256271362, loss=2.8849265575408936
I0302 14:39:26.171401 139758017697536 logging_writer.py:48] [20800] global_step=20800, grad_norm=1.107488989830017, loss=3.880316972732544
I0302 14:40:10.951535 139758009304832 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.9210258722305298, loss=4.6228556632995605
I0302 14:40:49.125290 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:41:03.473016 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:41:19.015667 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:41:20.660524 139953291118400 submission_runner.py:411] Time since start: 9920.84s, 	Step: 20987, 	{'train/accuracy': 0.5732030868530273, 'train/loss': 1.8356250524520874, 'validation/accuracy': 0.5278199911117554, 'validation/loss': 2.0457489490509033, 'validation/num_examples': 50000, 'test/accuracy': 0.4214000105857849, 'test/loss': 2.6908113956451416, 'test/num_examples': 10000, 'score': 9285.068341493607, 'total_duration': 9920.836732149124, 'accumulated_submission_time': 9285.068341493607, 'accumulated_eval_time': 633.9534032344818, 'accumulated_logging_time': 0.7069294452667236}
I0302 14:41:20.682090 139758017697536 logging_writer.py:48] [20987] accumulated_eval_time=633.953403, accumulated_logging_time=0.706929, accumulated_submission_time=9285.068341, global_step=20987, preemption_count=0, score=9285.068341, test/accuracy=0.421400, test/loss=2.690811, test/num_examples=10000, total_duration=9920.836732, train/accuracy=0.573203, train/loss=1.835625, validation/accuracy=0.527820, validation/loss=2.045749, validation/num_examples=50000
I0302 14:41:26.214369 139758009304832 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.1053522825241089, loss=3.446446418762207
I0302 14:42:07.934631 139758017697536 logging_writer.py:48] [21100] global_step=21100, grad_norm=1.0249959230422974, loss=3.3955225944519043
I0302 14:42:52.154504 139758009304832 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.9934036731719971, loss=4.710130214691162
I0302 14:43:37.133998 139758017697536 logging_writer.py:48] [21300] global_step=21300, grad_norm=1.0443302392959595, loss=2.740233898162842
I0302 14:44:22.162676 139758009304832 logging_writer.py:48] [21400] global_step=21400, grad_norm=1.5400034189224243, loss=2.8739168643951416
I0302 14:45:06.885278 139758017697536 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.9597472548484802, loss=3.8539180755615234
I0302 14:45:51.674942 139758009304832 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.9651928544044495, loss=2.937095880508423
I0302 14:46:36.561030 139758017697536 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.8413723707199097, loss=5.108003616333008
I0302 14:47:21.477549 139758009304832 logging_writer.py:48] [21800] global_step=21800, grad_norm=1.0799111127853394, loss=2.8650870323181152
I0302 14:48:06.439437 139758017697536 logging_writer.py:48] [21900] global_step=21900, grad_norm=1.115686297416687, loss=2.7930965423583984
I0302 14:48:20.796843 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:48:34.994415 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:48:50.694609 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:48:52.339462 139953291118400 submission_runner.py:411] Time since start: 10372.52s, 	Step: 21934, 	{'train/accuracy': 0.5780468583106995, 'train/loss': 1.77647066116333, 'validation/accuracy': 0.5388399958610535, 'validation/loss': 1.979406476020813, 'validation/num_examples': 50000, 'test/accuracy': 0.4229000210762024, 'test/loss': 2.6369969844818115, 'test/num_examples': 10000, 'score': 9705.122949361801, 'total_duration': 10372.515660524368, 'accumulated_submission_time': 9705.122949361801, 'accumulated_eval_time': 665.4959726333618, 'accumulated_logging_time': 0.7394287586212158}
I0302 14:48:52.362976 139758009304832 logging_writer.py:48] [21934] accumulated_eval_time=665.495973, accumulated_logging_time=0.739429, accumulated_submission_time=9705.122949, global_step=21934, preemption_count=0, score=9705.122949, test/accuracy=0.422900, test/loss=2.636997, test/num_examples=10000, total_duration=10372.515661, train/accuracy=0.578047, train/loss=1.776471, validation/accuracy=0.538840, validation/loss=1.979406, validation/num_examples=50000
I0302 14:49:18.838107 139758017697536 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.1809773445129395, loss=2.795167922973633
I0302 14:50:02.737743 139758009304832 logging_writer.py:48] [22100] global_step=22100, grad_norm=1.2153258323669434, loss=2.8018205165863037
I0302 14:50:47.114090 139758017697536 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.9985454082489014, loss=2.790870189666748
I0302 14:51:32.403061 139758009304832 logging_writer.py:48] [22300] global_step=22300, grad_norm=1.0151008367538452, loss=3.1642403602600098
I0302 14:52:18.292829 139758017697536 logging_writer.py:48] [22400] global_step=22400, grad_norm=1.120349645614624, loss=2.837880849838257
I0302 14:53:03.648755 139758009304832 logging_writer.py:48] [22500] global_step=22500, grad_norm=1.1906702518463135, loss=3.5130043029785156
I0302 14:53:48.595366 139758017697536 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.9359795451164246, loss=4.894245147705078
I0302 14:54:33.668192 139758009304832 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.9131479263305664, loss=3.55649471282959
I0302 14:55:19.106476 139758017697536 logging_writer.py:48] [22800] global_step=22800, grad_norm=1.1330573558807373, loss=2.8244242668151855
I0302 14:55:52.427136 139953291118400 spec.py:321] Evaluating on the training split.
I0302 14:56:03.528129 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 14:56:23.669477 139953291118400 spec.py:349] Evaluating on the test split.
I0302 14:56:25.293851 139953291118400 submission_runner.py:411] Time since start: 10825.47s, 	Step: 22875, 	{'train/accuracy': 0.5887890458106995, 'train/loss': 1.7585443258285522, 'validation/accuracy': 0.5386399626731873, 'validation/loss': 2.00494122505188, 'validation/num_examples': 50000, 'test/accuracy': 0.4220000207424164, 'test/loss': 2.6710598468780518, 'test/num_examples': 10000, 'score': 10125.126637935638, 'total_duration': 10825.470078229904, 'accumulated_submission_time': 10125.126637935638, 'accumulated_eval_time': 698.3626811504364, 'accumulated_logging_time': 0.7748537063598633}
I0302 14:56:25.311784 139758009304832 logging_writer.py:48] [22875] accumulated_eval_time=698.362681, accumulated_logging_time=0.774854, accumulated_submission_time=10125.126638, global_step=22875, preemption_count=0, score=10125.126638, test/accuracy=0.422000, test/loss=2.671060, test/num_examples=10000, total_duration=10825.470078, train/accuracy=0.588789, train/loss=1.758544, validation/accuracy=0.538640, validation/loss=2.004941, validation/num_examples=50000
I0302 14:56:35.581419 139758017697536 logging_writer.py:48] [22900] global_step=22900, grad_norm=1.0222069025039673, loss=3.7660672664642334
I0302 14:57:15.129865 139758009304832 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.995341420173645, loss=3.8818955421447754
I0302 14:57:59.945544 139758017697536 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.9276355504989624, loss=3.5427088737487793
I0302 14:58:45.385942 139758009304832 logging_writer.py:48] [23200] global_step=23200, grad_norm=1.2812532186508179, loss=2.934149980545044
I0302 14:59:29.932008 139758017697536 logging_writer.py:48] [23300] global_step=23300, grad_norm=1.229720950126648, loss=2.852295160293579
I0302 15:00:14.587631 139758009304832 logging_writer.py:48] [23400] global_step=23400, grad_norm=1.1445716619491577, loss=3.0791382789611816
I0302 15:00:59.900761 139758017697536 logging_writer.py:48] [23500] global_step=23500, grad_norm=1.152834177017212, loss=2.8865609169006348
I0302 15:01:44.692566 139758009304832 logging_writer.py:48] [23600] global_step=23600, grad_norm=1.2552317380905151, loss=2.8416905403137207
I0302 15:02:29.293300 139758017697536 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.9641077518463135, loss=4.6562724113464355
I0302 15:03:14.747931 139758009304832 logging_writer.py:48] [23800] global_step=23800, grad_norm=1.1174577474594116, loss=2.791956663131714
I0302 15:03:25.759119 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:03:36.195394 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:03:57.189393 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:03:58.822031 139953291118400 submission_runner.py:411] Time since start: 11279.00s, 	Step: 23826, 	{'train/accuracy': 0.623339831829071, 'train/loss': 1.555069088935852, 'validation/accuracy': 0.5521999597549438, 'validation/loss': 1.9062819480895996, 'validation/num_examples': 50000, 'test/accuracy': 0.4359000325202942, 'test/loss': 2.585143566131592, 'test/num_examples': 10000, 'score': 10545.515405893326, 'total_duration': 11278.99824810028, 'accumulated_submission_time': 10545.515405893326, 'accumulated_eval_time': 731.4255640506744, 'accumulated_logging_time': 0.802415132522583}
I0302 15:03:58.845261 139758017697536 logging_writer.py:48] [23826] accumulated_eval_time=731.425564, accumulated_logging_time=0.802415, accumulated_submission_time=10545.515406, global_step=23826, preemption_count=0, score=10545.515406, test/accuracy=0.435900, test/loss=2.585144, test/num_examples=10000, total_duration=11278.998248, train/accuracy=0.623340, train/loss=1.555069, validation/accuracy=0.552200, validation/loss=1.906282, validation/num_examples=50000
I0302 15:04:28.502022 139758009304832 logging_writer.py:48] [23900] global_step=23900, grad_norm=1.0852693319320679, loss=3.170640230178833
I0302 15:05:11.966680 139758017697536 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.2828142642974854, loss=3.0136489868164062
I0302 15:05:56.680438 139758009304832 logging_writer.py:48] [24100] global_step=24100, grad_norm=1.248383641242981, loss=2.6339268684387207
I0302 15:06:42.012999 139758017697536 logging_writer.py:48] [24200] global_step=24200, grad_norm=1.1524262428283691, loss=2.7455079555511475
I0302 15:07:26.643902 139758009304832 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.9838929772377014, loss=3.011723041534424
I0302 15:08:11.533595 139758017697536 logging_writer.py:48] [24400] global_step=24400, grad_norm=1.2415145635604858, loss=2.727442502975464
I0302 15:08:56.528222 139758009304832 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.214137077331543, loss=2.8994789123535156
I0302 15:09:41.308223 139758017697536 logging_writer.py:48] [24600] global_step=24600, grad_norm=1.1916347742080688, loss=2.7993106842041016
I0302 15:10:26.048205 139758009304832 logging_writer.py:48] [24700] global_step=24700, grad_norm=1.1876991987228394, loss=2.9687530994415283
I0302 15:10:58.828575 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:11:09.914086 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:11:29.001585 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:11:30.644541 139953291118400 submission_runner.py:411] Time since start: 11730.82s, 	Step: 24775, 	{'train/accuracy': 0.5954492092132568, 'train/loss': 1.7052239179611206, 'validation/accuracy': 0.5511800050735474, 'validation/loss': 1.9209455251693726, 'validation/num_examples': 50000, 'test/accuracy': 0.43870002031326294, 'test/loss': 2.591357707977295, 'test/num_examples': 10000, 'score': 10965.437469005585, 'total_duration': 11730.820744037628, 'accumulated_submission_time': 10965.437469005585, 'accumulated_eval_time': 763.2415297031403, 'accumulated_logging_time': 0.8369770050048828}
I0302 15:11:30.666741 139758017697536 logging_writer.py:48] [24775] accumulated_eval_time=763.241530, accumulated_logging_time=0.836977, accumulated_submission_time=10965.437469, global_step=24775, preemption_count=0, score=10965.437469, test/accuracy=0.438700, test/loss=2.591358, test/num_examples=10000, total_duration=11730.820744, train/accuracy=0.595449, train/loss=1.705224, validation/accuracy=0.551180, validation/loss=1.920946, validation/num_examples=50000
I0302 15:11:40.970317 139758009304832 logging_writer.py:48] [24800] global_step=24800, grad_norm=1.1066826581954956, loss=2.740805149078369
I0302 15:12:22.971099 139758017697536 logging_writer.py:48] [24900] global_step=24900, grad_norm=1.0966453552246094, loss=2.551102876663208
I0302 15:13:07.989018 139758009304832 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.0903143882751465, loss=2.850731372833252
I0302 15:13:53.209158 139758017697536 logging_writer.py:48] [25100] global_step=25100, grad_norm=1.209302306175232, loss=2.745476722717285
I0302 15:14:38.137398 139758009304832 logging_writer.py:48] [25200] global_step=25200, grad_norm=1.19925057888031, loss=2.6775336265563965
I0302 15:15:22.865893 139758017697536 logging_writer.py:48] [25300] global_step=25300, grad_norm=1.1238497495651245, loss=2.9021995067596436
I0302 15:16:07.748468 139758009304832 logging_writer.py:48] [25400] global_step=25400, grad_norm=1.1926097869873047, loss=2.7466235160827637
I0302 15:16:52.975327 139758017697536 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.0944408178329468, loss=2.976767063140869
I0302 15:17:37.993170 139758009304832 logging_writer.py:48] [25600] global_step=25600, grad_norm=1.1189625263214111, loss=2.7423696517944336
I0302 15:18:22.958832 139758017697536 logging_writer.py:48] [25700] global_step=25700, grad_norm=1.243980050086975, loss=2.719970226287842
I0302 15:18:31.165338 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:18:41.710790 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:19:01.033426 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:19:02.676869 139953291118400 submission_runner.py:411] Time since start: 12182.85s, 	Step: 25720, 	{'train/accuracy': 0.6026171445846558, 'train/loss': 1.6572762727737427, 'validation/accuracy': 0.5577200055122375, 'validation/loss': 1.8794413805007935, 'validation/num_examples': 50000, 'test/accuracy': 0.4342000186443329, 'test/loss': 2.559943437576294, 'test/num_examples': 10000, 'score': 11385.874091625214, 'total_duration': 12182.853080272675, 'accumulated_submission_time': 11385.874091625214, 'accumulated_eval_time': 794.7530353069305, 'accumulated_logging_time': 0.8722774982452393}
I0302 15:19:02.698929 139758009304832 logging_writer.py:48] [25720] accumulated_eval_time=794.753035, accumulated_logging_time=0.872277, accumulated_submission_time=11385.874092, global_step=25720, preemption_count=0, score=11385.874092, test/accuracy=0.434200, test/loss=2.559943, test/num_examples=10000, total_duration=12182.853080, train/accuracy=0.602617, train/loss=1.657276, validation/accuracy=0.557720, validation/loss=1.879441, validation/num_examples=50000
I0302 15:19:36.013571 139758017697536 logging_writer.py:48] [25800] global_step=25800, grad_norm=1.1146587133407593, loss=3.295219898223877
I0302 15:20:21.040031 139758009304832 logging_writer.py:48] [25900] global_step=25900, grad_norm=1.0210552215576172, loss=2.9078586101531982
I0302 15:21:06.631322 139758017697536 logging_writer.py:48] [26000] global_step=26000, grad_norm=1.129500389099121, loss=2.7184362411499023
I0302 15:21:52.061556 139758009304832 logging_writer.py:48] [26100] global_step=26100, grad_norm=1.1440119743347168, loss=2.762873411178589
I0302 15:22:37.012057 139758017697536 logging_writer.py:48] [26200] global_step=26200, grad_norm=1.121985673904419, loss=2.9953272342681885
I0302 15:23:22.316238 139758009304832 logging_writer.py:48] [26300] global_step=26300, grad_norm=1.0884839296340942, loss=3.00626277923584
I0302 15:24:07.643463 139758017697536 logging_writer.py:48] [26400] global_step=26400, grad_norm=1.00503671169281, loss=3.2762656211853027
I0302 15:24:52.519211 139758009304832 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.1783826351165771, loss=2.650542736053467
I0302 15:25:37.834743 139758017697536 logging_writer.py:48] [26600] global_step=26600, grad_norm=1.0960122346878052, loss=4.359192371368408
I0302 15:26:02.893631 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:26:13.875942 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:26:32.665844 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:26:34.300485 139953291118400 submission_runner.py:411] Time since start: 12634.48s, 	Step: 26657, 	{'train/accuracy': 0.6150780916213989, 'train/loss': 1.6037347316741943, 'validation/accuracy': 0.5588799715042114, 'validation/loss': 1.8744468688964844, 'validation/num_examples': 50000, 'test/accuracy': 0.44510000944137573, 'test/loss': 2.543614387512207, 'test/num_examples': 10000, 'score': 11804.853033542633, 'total_duration': 12634.476700305939, 'accumulated_submission_time': 11804.853033542633, 'accumulated_eval_time': 826.1598796844482, 'accumulated_logging_time': 2.062011241912842}
I0302 15:26:34.327024 139758009304832 logging_writer.py:48] [26657] accumulated_eval_time=826.159880, accumulated_logging_time=2.062011, accumulated_submission_time=11804.853034, global_step=26657, preemption_count=0, score=11804.853034, test/accuracy=0.445100, test/loss=2.543614, test/num_examples=10000, total_duration=12634.476700, train/accuracy=0.615078, train/loss=1.603735, validation/accuracy=0.558880, validation/loss=1.874447, validation/num_examples=50000
I0302 15:26:51.736031 139758017697536 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.9985721707344055, loss=2.7401487827301025
I0302 15:27:34.519534 139758009304832 logging_writer.py:48] [26800] global_step=26800, grad_norm=1.1036354303359985, loss=2.821542263031006
I0302 15:28:19.281647 139758017697536 logging_writer.py:48] [26900] global_step=26900, grad_norm=1.1607598066329956, loss=2.674647331237793
I0302 15:29:04.350550 139758009304832 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.0114519596099854, loss=5.071192741394043
I0302 15:29:49.005536 139758017697536 logging_writer.py:48] [27100] global_step=27100, grad_norm=1.0655224323272705, loss=5.4108428955078125
I0302 15:30:33.863358 139758009304832 logging_writer.py:48] [27200] global_step=27200, grad_norm=1.192008137702942, loss=2.7064831256866455
I0302 15:31:18.992412 139758017697536 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.975045919418335, loss=3.6510965824127197
I0302 15:32:03.854670 139758009304832 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.9638661742210388, loss=4.257717132568359
I0302 15:32:48.479735 139758017697536 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.1260641813278198, loss=3.2920920848846436
I0302 15:33:34.164198 139758009304832 logging_writer.py:48] [27600] global_step=27600, grad_norm=1.2294974327087402, loss=2.6608667373657227
I0302 15:33:34.319606 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:33:45.216799 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:34:05.226937 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:34:06.867216 139953291118400 submission_runner.py:411] Time since start: 13087.04s, 	Step: 27602, 	{'train/accuracy': 0.6069140434265137, 'train/loss': 1.6219347715377808, 'validation/accuracy': 0.5689600110054016, 'validation/loss': 1.8156018257141113, 'validation/num_examples': 50000, 'test/accuracy': 0.45320001244544983, 'test/loss': 2.5086917877197266, 'test/num_examples': 10000, 'score': 12224.784992218018, 'total_duration': 13087.04343366623, 'accumulated_submission_time': 12224.784992218018, 'accumulated_eval_time': 858.7074551582336, 'accumulated_logging_time': 2.100292921066284}
I0302 15:34:06.890967 139758017697536 logging_writer.py:48] [27602] accumulated_eval_time=858.707455, accumulated_logging_time=2.100293, accumulated_submission_time=12224.784992, global_step=27602, preemption_count=0, score=12224.784992, test/accuracy=0.453200, test/loss=2.508692, test/num_examples=10000, total_duration=13087.043434, train/accuracy=0.606914, train/loss=1.621935, validation/accuracy=0.568960, validation/loss=1.815602, validation/num_examples=50000
I0302 15:34:46.152817 139758009304832 logging_writer.py:48] [27700] global_step=27700, grad_norm=1.1877654790878296, loss=2.7390127182006836
I0302 15:35:30.849125 139758017697536 logging_writer.py:48] [27800] global_step=27800, grad_norm=1.3602094650268555, loss=5.403068542480469
I0302 15:36:16.118322 139758009304832 logging_writer.py:48] [27900] global_step=27900, grad_norm=1.1916180849075317, loss=4.469485759735107
I0302 15:37:01.370248 139758017697536 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.1608822345733643, loss=2.7871477603912354
I0302 15:37:46.158221 139758009304832 logging_writer.py:48] [28100] global_step=28100, grad_norm=1.2105045318603516, loss=2.5677990913391113
I0302 15:38:30.922160 139758017697536 logging_writer.py:48] [28200] global_step=28200, grad_norm=1.177778720855713, loss=2.627717971801758
I0302 15:39:15.820774 139758009304832 logging_writer.py:48] [28300] global_step=28300, grad_norm=1.1408518552780151, loss=5.33088493347168
I0302 15:40:00.786963 139758017697536 logging_writer.py:48] [28400] global_step=28400, grad_norm=1.0768444538116455, loss=2.6367006301879883
I0302 15:40:45.706897 139758009304832 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.1287853717803955, loss=2.8140926361083984
I0302 15:41:07.284873 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:41:18.015738 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:41:38.594886 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:41:40.215414 139953291118400 submission_runner.py:411] Time since start: 13540.39s, 	Step: 28549, 	{'train/accuracy': 0.6090429425239563, 'train/loss': 1.6417275667190552, 'validation/accuracy': 0.5631799697875977, 'validation/loss': 1.8570791482925415, 'validation/num_examples': 50000, 'test/accuracy': 0.44950002431869507, 'test/loss': 2.522683620452881, 'test/num_examples': 10000, 'score': 12645.118678808212, 'total_duration': 13540.391645908356, 'accumulated_submission_time': 12645.118678808212, 'accumulated_eval_time': 891.6379976272583, 'accumulated_logging_time': 2.135059118270874}
I0302 15:41:40.234508 139758017697536 logging_writer.py:48] [28549] accumulated_eval_time=891.637998, accumulated_logging_time=2.135059, accumulated_submission_time=12645.118679, global_step=28549, preemption_count=0, score=12645.118679, test/accuracy=0.449500, test/loss=2.522684, test/num_examples=10000, total_duration=13540.391646, train/accuracy=0.609043, train/loss=1.641728, validation/accuracy=0.563180, validation/loss=1.857079, validation/num_examples=50000
I0302 15:42:00.780105 139758009304832 logging_writer.py:48] [28600] global_step=28600, grad_norm=1.0104961395263672, loss=4.400182247161865
I0302 15:42:43.197450 139758017697536 logging_writer.py:48] [28700] global_step=28700, grad_norm=1.0257972478866577, loss=3.5156235694885254
I0302 15:43:28.234345 139758009304832 logging_writer.py:48] [28800] global_step=28800, grad_norm=1.1243723630905151, loss=2.6719141006469727
I0302 15:44:13.284203 139758017697536 logging_writer.py:48] [28900] global_step=28900, grad_norm=1.252059817314148, loss=2.7029428482055664
I0302 15:44:58.313817 139758009304832 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.2723665237426758, loss=2.6364171504974365
I0302 15:45:42.974918 139758017697536 logging_writer.py:48] [29100] global_step=29100, grad_norm=1.1366664171218872, loss=2.619884490966797
I0302 15:46:28.119914 139758009304832 logging_writer.py:48] [29200] global_step=29200, grad_norm=1.130281925201416, loss=2.7484519481658936
I0302 15:47:13.192341 139758017697536 logging_writer.py:48] [29300] global_step=29300, grad_norm=1.002285122871399, loss=3.8460874557495117
I0302 15:47:57.733567 139758009304832 logging_writer.py:48] [29400] global_step=29400, grad_norm=1.231198787689209, loss=2.6572351455688477
I0302 15:48:40.557948 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:48:51.503025 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:49:08.453053 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:49:10.087667 139953291118400 submission_runner.py:411] Time since start: 13990.26s, 	Step: 29497, 	{'train/accuracy': 0.6200780868530273, 'train/loss': 1.5937964916229248, 'validation/accuracy': 0.5712400078773499, 'validation/loss': 1.8428938388824463, 'validation/num_examples': 50000, 'test/accuracy': 0.44930002093315125, 'test/loss': 2.5253915786743164, 'test/num_examples': 10000, 'score': 13065.383793115616, 'total_duration': 13990.263841152191, 'accumulated_submission_time': 13065.383793115616, 'accumulated_eval_time': 921.1676602363586, 'accumulated_logging_time': 2.1631698608398438}
I0302 15:49:10.111231 139758017697536 logging_writer.py:48] [29497] accumulated_eval_time=921.167660, accumulated_logging_time=2.163170, accumulated_submission_time=13065.383793, global_step=29497, preemption_count=0, score=13065.383793, test/accuracy=0.449300, test/loss=2.525392, test/num_examples=10000, total_duration=13990.263841, train/accuracy=0.620078, train/loss=1.593796, validation/accuracy=0.571240, validation/loss=1.842894, validation/num_examples=50000
I0302 15:49:11.729225 139758009304832 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.0713809728622437, loss=2.616974115371704
I0302 15:49:52.816747 139758017697536 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.9117317795753479, loss=4.174670219421387
I0302 15:50:37.993842 139758009304832 logging_writer.py:48] [29700] global_step=29700, grad_norm=1.091605544090271, loss=3.0233492851257324
I0302 15:51:23.014791 139758017697536 logging_writer.py:48] [29800] global_step=29800, grad_norm=1.0808336734771729, loss=2.5893425941467285
I0302 15:52:07.941032 139758009304832 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.9927816987037659, loss=4.760599613189697
I0302 15:52:52.733744 139758017697536 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.212686538696289, loss=2.649404764175415
I0302 15:53:37.915055 139758009304832 logging_writer.py:48] [30100] global_step=30100, grad_norm=1.1654962301254272, loss=2.674501419067383
I0302 15:54:22.683001 139758017697536 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.9761638045310974, loss=4.186468601226807
I0302 15:55:07.660829 139758009304832 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.9424291253089905, loss=4.280094146728516
I0302 15:55:52.501321 139758017697536 logging_writer.py:48] [30400] global_step=30400, grad_norm=1.0128518342971802, loss=3.093186616897583
I0302 15:56:10.172739 139953291118400 spec.py:321] Evaluating on the training split.
I0302 15:56:21.495819 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 15:56:42.169245 139953291118400 spec.py:349] Evaluating on the test split.
I0302 15:56:43.797985 139953291118400 submission_runner.py:411] Time since start: 14443.97s, 	Step: 30441, 	{'train/accuracy': 0.646484375, 'train/loss': 1.4701223373413086, 'validation/accuracy': 0.5729599595069885, 'validation/loss': 1.8155981302261353, 'validation/num_examples': 50000, 'test/accuracy': 0.4524000287055969, 'test/loss': 2.4883368015289307, 'test/num_examples': 10000, 'score': 13485.384624481201, 'total_duration': 14443.974184513092, 'accumulated_submission_time': 13485.384624481201, 'accumulated_eval_time': 954.7928731441498, 'accumulated_logging_time': 2.198180913925171}
I0302 15:56:43.820197 139758009304832 logging_writer.py:48] [30441] accumulated_eval_time=954.792873, accumulated_logging_time=2.198181, accumulated_submission_time=13485.384624, global_step=30441, preemption_count=0, score=13485.384624, test/accuracy=0.452400, test/loss=2.488337, test/num_examples=10000, total_duration=14443.974185, train/accuracy=0.646484, train/loss=1.470122, validation/accuracy=0.572960, validation/loss=1.815598, validation/num_examples=50000
I0302 15:57:07.526998 139758017697536 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.2367383241653442, loss=2.589811086654663
I0302 15:57:50.643634 139758009304832 logging_writer.py:48] [30600] global_step=30600, grad_norm=1.0493463277816772, loss=4.628275394439697
I0302 15:58:35.637299 139758017697536 logging_writer.py:48] [30700] global_step=30700, grad_norm=1.1934691667556763, loss=2.717773914337158
I0302 15:59:20.627121 139758009304832 logging_writer.py:48] [30800] global_step=30800, grad_norm=1.201088547706604, loss=2.772859573364258
I0302 16:00:05.586621 139758017697536 logging_writer.py:48] [30900] global_step=30900, grad_norm=1.1789300441741943, loss=2.596858263015747
I0302 16:00:50.347666 139758009304832 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.0760506391525269, loss=2.5561909675598145
I0302 16:01:35.357503 139758017697536 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.998711109161377, loss=3.786881446838379
I0302 16:02:20.115256 139758009304832 logging_writer.py:48] [31200] global_step=31200, grad_norm=1.2042675018310547, loss=2.5897035598754883
I0302 16:03:05.303406 139758017697536 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.9028510451316833, loss=5.23169469833374
I0302 16:03:44.054915 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:03:54.995233 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:04:14.192172 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:04:15.839014 139953291118400 submission_runner.py:411] Time since start: 14896.02s, 	Step: 31388, 	{'train/accuracy': 0.6192382574081421, 'train/loss': 1.5904227495193481, 'validation/accuracy': 0.5780199766159058, 'validation/loss': 1.7954529523849487, 'validation/num_examples': 50000, 'test/accuracy': 0.4555000364780426, 'test/loss': 2.473357677459717, 'test/num_examples': 10000, 'score': 13905.559622764587, 'total_duration': 14896.015183925629, 'accumulated_submission_time': 13905.559622764587, 'accumulated_eval_time': 986.5768990516663, 'accumulated_logging_time': 2.2313287258148193}
I0302 16:04:15.866055 139758009304832 logging_writer.py:48] [31388] accumulated_eval_time=986.576899, accumulated_logging_time=2.231329, accumulated_submission_time=13905.559623, global_step=31388, preemption_count=0, score=13905.559623, test/accuracy=0.455500, test/loss=2.473358, test/num_examples=10000, total_duration=14896.015184, train/accuracy=0.619238, train/loss=1.590423, validation/accuracy=0.578020, validation/loss=1.795453, validation/num_examples=50000
I0302 16:04:21.033420 139758017697536 logging_writer.py:48] [31400] global_step=31400, grad_norm=1.0084697008132935, loss=4.394830703735352
I0302 16:05:01.419782 139758009304832 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.121926188468933, loss=2.5926952362060547
I0302 16:05:46.441709 139758017697536 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.9889905452728271, loss=4.71550178527832
I0302 16:06:31.833861 139758009304832 logging_writer.py:48] [31700] global_step=31700, grad_norm=1.068071961402893, loss=2.8544652462005615
I0302 16:07:17.183840 139758017697536 logging_writer.py:48] [31800] global_step=31800, grad_norm=1.0299333333969116, loss=4.171940803527832
I0302 16:08:01.633546 139758009304832 logging_writer.py:48] [31900] global_step=31900, grad_norm=1.2068783044815063, loss=2.627068281173706
I0302 16:08:46.710950 139758017697536 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.0301291942596436, loss=3.234531879425049
I0302 16:09:31.617057 139758009304832 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.9611082077026367, loss=5.313477516174316
I0302 16:10:16.443902 139758017697536 logging_writer.py:48] [32200] global_step=32200, grad_norm=1.2401319742202759, loss=2.7470178604125977
I0302 16:11:01.240146 139758009304832 logging_writer.py:48] [32300] global_step=32300, grad_norm=1.1327513456344604, loss=3.778747081756592
I0302 16:11:15.851208 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:11:26.773659 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:11:48.825845 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:11:50.446556 139953291118400 submission_runner.py:411] Time since start: 15350.62s, 	Step: 32334, 	{'train/accuracy': 0.6196874976158142, 'train/loss': 1.594934344291687, 'validation/accuracy': 0.5723400115966797, 'validation/loss': 1.8144795894622803, 'validation/num_examples': 50000, 'test/accuracy': 0.45740002393722534, 'test/loss': 2.485887289047241, 'test/num_examples': 10000, 'score': 14325.485937595367, 'total_duration': 15350.62278676033, 'accumulated_submission_time': 14325.485937595367, 'accumulated_eval_time': 1021.1722357273102, 'accumulated_logging_time': 2.2684500217437744}
I0302 16:11:50.466709 139758017697536 logging_writer.py:48] [32334] accumulated_eval_time=1021.172236, accumulated_logging_time=2.268450, accumulated_submission_time=14325.485938, global_step=32334, preemption_count=0, score=14325.485938, test/accuracy=0.457400, test/loss=2.485887, test/num_examples=10000, total_duration=15350.622787, train/accuracy=0.619687, train/loss=1.594934, validation/accuracy=0.572340, validation/loss=1.814480, validation/num_examples=50000
I0302 16:12:16.948043 139758009304832 logging_writer.py:48] [32400] global_step=32400, grad_norm=1.0212517976760864, loss=3.946565628051758
I0302 16:12:59.839823 139758017697536 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.008968472480774, loss=5.214800834655762
I0302 16:13:45.111078 139758009304832 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.9836788177490234, loss=3.871349811553955
I0302 16:14:30.236218 139758017697536 logging_writer.py:48] [32700] global_step=32700, grad_norm=1.136741280555725, loss=2.6867258548736572
I0302 16:15:15.407289 139758009304832 logging_writer.py:48] [32800] global_step=32800, grad_norm=1.1922773122787476, loss=2.7287395000457764
I0302 16:16:00.010698 139758017697536 logging_writer.py:48] [32900] global_step=32900, grad_norm=1.2473009824752808, loss=2.6714584827423096
I0302 16:16:45.145952 139758009304832 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.2353435754776, loss=2.6991167068481445
I0302 16:17:30.154196 139758017697536 logging_writer.py:48] [33100] global_step=33100, grad_norm=1.3660162687301636, loss=2.594649314880371
I0302 16:18:15.126749 139758009304832 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.9264654517173767, loss=4.763338565826416
I0302 16:18:50.873461 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:19:01.942494 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:19:20.233803 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:19:21.874302 139953291118400 submission_runner.py:411] Time since start: 15802.05s, 	Step: 33281, 	{'train/accuracy': 0.6363476514816284, 'train/loss': 1.4893057346343994, 'validation/accuracy': 0.5823799967765808, 'validation/loss': 1.7727079391479492, 'validation/num_examples': 50000, 'test/accuracy': 0.4593000113964081, 'test/loss': 2.459869623184204, 'test/num_examples': 10000, 'score': 14745.835205078125, 'total_duration': 15802.050520658493, 'accumulated_submission_time': 14745.835205078125, 'accumulated_eval_time': 1052.1730644702911, 'accumulated_logging_time': 2.2977893352508545}
I0302 16:19:21.905730 139758017697536 logging_writer.py:48] [33281] accumulated_eval_time=1052.173064, accumulated_logging_time=2.297789, accumulated_submission_time=14745.835205, global_step=33281, preemption_count=0, score=14745.835205, test/accuracy=0.459300, test/loss=2.459870, test/num_examples=10000, total_duration=15802.050521, train/accuracy=0.636348, train/loss=1.489306, validation/accuracy=0.582380, validation/loss=1.772708, validation/num_examples=50000
I0302 16:19:29.823287 139758009304832 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.929650068283081, loss=3.4588258266448975
I0302 16:20:12.197090 139758017697536 logging_writer.py:48] [33400] global_step=33400, grad_norm=1.0553187131881714, loss=4.383065700531006
I0302 16:20:56.979370 139758009304832 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.2365819215774536, loss=2.6228458881378174
I0302 16:21:42.169440 139758017697536 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.9734435677528381, loss=5.1795806884765625
I0302 16:22:27.350587 139758009304832 logging_writer.py:48] [33700] global_step=33700, grad_norm=1.233188509941101, loss=2.5398545265197754
I0302 16:23:12.214905 139758017697536 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.9782523512840271, loss=4.12264347076416
I0302 16:23:57.043424 139758009304832 logging_writer.py:48] [33900] global_step=33900, grad_norm=1.2694282531738281, loss=2.623284101486206
I0302 16:24:41.899479 139758017697536 logging_writer.py:48] [34000] global_step=34000, grad_norm=1.2005152702331543, loss=2.662386417388916
I0302 16:25:26.739773 139758009304832 logging_writer.py:48] [34100] global_step=34100, grad_norm=1.3481484651565552, loss=2.5374398231506348
I0302 16:26:11.645213 139758017697536 logging_writer.py:48] [34200] global_step=34200, grad_norm=1.0191903114318848, loss=5.239566802978516
I0302 16:26:21.923842 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:26:33.044963 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:26:51.850533 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:26:53.489810 139953291118400 submission_runner.py:411] Time since start: 16253.67s, 	Step: 34224, 	{'train/accuracy': 0.6278319954872131, 'train/loss': 1.517386555671692, 'validation/accuracy': 0.5886200070381165, 'validation/loss': 1.7128303050994873, 'validation/num_examples': 50000, 'test/accuracy': 0.46700000762939453, 'test/loss': 2.4110279083251953, 'test/num_examples': 10000, 'score': 15165.793439865112, 'total_duration': 16253.66602897644, 'accumulated_submission_time': 15165.793439865112, 'accumulated_eval_time': 1083.7390191555023, 'accumulated_logging_time': 2.3401732444763184}
I0302 16:26:53.513934 139758009304832 logging_writer.py:48] [34224] accumulated_eval_time=1083.739019, accumulated_logging_time=2.340173, accumulated_submission_time=15165.793440, global_step=34224, preemption_count=0, score=15165.793440, test/accuracy=0.467000, test/loss=2.411028, test/num_examples=10000, total_duration=16253.666029, train/accuracy=0.627832, train/loss=1.517387, validation/accuracy=0.588620, validation/loss=1.712830, validation/num_examples=50000
I0302 16:27:24.061779 139758017697536 logging_writer.py:48] [34300] global_step=34300, grad_norm=1.2316817045211792, loss=2.4745707511901855
I0302 16:28:08.954973 139758009304832 logging_writer.py:48] [34400] global_step=34400, grad_norm=1.1140995025634766, loss=2.8656868934631348
I0302 16:28:53.992381 139758017697536 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.0774776935577393, loss=3.1101975440979004
I0302 16:29:39.074692 139758009304832 logging_writer.py:48] [34600] global_step=34600, grad_norm=1.143864393234253, loss=2.435368537902832
I0302 16:30:23.836848 139758017697536 logging_writer.py:48] [34700] global_step=34700, grad_norm=1.2985765933990479, loss=2.586829900741577
I0302 16:31:08.696978 139758009304832 logging_writer.py:48] [34800] global_step=34800, grad_norm=1.0926191806793213, loss=4.851065158843994
I0302 16:31:53.775329 139758017697536 logging_writer.py:48] [34900] global_step=34900, grad_norm=1.135807752609253, loss=2.710202217102051
I0302 16:32:38.466561 139758009304832 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.9584421515464783, loss=3.719083309173584
I0302 16:33:23.554029 139758017697536 logging_writer.py:48] [35100] global_step=35100, grad_norm=1.0396769046783447, loss=5.113409042358398
I0302 16:33:53.580413 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:34:04.607481 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:34:23.527803 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:34:25.197793 139953291118400 submission_runner.py:411] Time since start: 16705.37s, 	Step: 35169, 	{'train/accuracy': 0.6328905820846558, 'train/loss': 1.534470796585083, 'validation/accuracy': 0.5838599801063538, 'validation/loss': 1.7675602436065674, 'validation/num_examples': 50000, 'test/accuracy': 0.4645000100135803, 'test/loss': 2.427992582321167, 'test/num_examples': 10000, 'score': 15585.799923658371, 'total_duration': 16705.374019622803, 'accumulated_submission_time': 15585.799923658371, 'accumulated_eval_time': 1115.3563861846924, 'accumulated_logging_time': 2.374427318572998}
I0302 16:34:25.223001 139758009304832 logging_writer.py:48] [35169] accumulated_eval_time=1115.356386, accumulated_logging_time=2.374427, accumulated_submission_time=15585.799924, global_step=35169, preemption_count=0, score=15585.799924, test/accuracy=0.464500, test/loss=2.427993, test/num_examples=10000, total_duration=16705.374020, train/accuracy=0.632891, train/loss=1.534471, validation/accuracy=0.583860, validation/loss=1.767560, validation/num_examples=50000
I0302 16:34:37.869400 139758017697536 logging_writer.py:48] [35200] global_step=35200, grad_norm=1.1067208051681519, loss=2.550784111022949
I0302 16:35:19.300006 139758009304832 logging_writer.py:48] [35300] global_step=35300, grad_norm=1.0979108810424805, loss=5.090905666351318
I0302 16:36:04.592363 139758017697536 logging_writer.py:48] [35400] global_step=35400, grad_norm=1.0786014795303345, loss=5.193995475769043
I0302 16:36:49.818915 139758009304832 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.0794458389282227, loss=3.209294319152832
I0302 16:37:34.805549 139758017697536 logging_writer.py:48] [35600] global_step=35600, grad_norm=1.1256208419799805, loss=3.363389492034912
I0302 16:38:19.576638 139758009304832 logging_writer.py:48] [35700] global_step=35700, grad_norm=1.1902743577957153, loss=2.5745553970336914
I0302 16:39:04.623398 139758017697536 logging_writer.py:48] [35800] global_step=35800, grad_norm=1.2215744256973267, loss=2.5303170680999756
I0302 16:39:49.539962 139758009304832 logging_writer.py:48] [35900] global_step=35900, grad_norm=1.1385040283203125, loss=2.8633880615234375
I0302 16:40:34.308939 139758017697536 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.026641845703125, loss=3.1233718395233154
I0302 16:41:19.700633 139758009304832 logging_writer.py:48] [36100] global_step=36100, grad_norm=1.2284586429595947, loss=2.5168464183807373
I0302 16:41:25.217706 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:41:36.254243 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:41:56.009331 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:41:57.653491 139953291118400 submission_runner.py:411] Time since start: 17157.83s, 	Step: 36114, 	{'train/accuracy': 0.6386132836341858, 'train/loss': 1.4852243661880493, 'validation/accuracy': 0.585099995136261, 'validation/loss': 1.736467719078064, 'validation/num_examples': 50000, 'test/accuracy': 0.46570003032684326, 'test/loss': 2.405973196029663, 'test/num_examples': 10000, 'score': 16005.73632979393, 'total_duration': 17157.829701662064, 'accumulated_submission_time': 16005.73632979393, 'accumulated_eval_time': 1147.792130947113, 'accumulated_logging_time': 2.408688545227051}
I0302 16:41:57.681699 139758017697536 logging_writer.py:48] [36114] accumulated_eval_time=1147.792131, accumulated_logging_time=2.408689, accumulated_submission_time=16005.736330, global_step=36114, preemption_count=0, score=16005.736330, test/accuracy=0.465700, test/loss=2.405973, test/num_examples=10000, total_duration=17157.829702, train/accuracy=0.638613, train/loss=1.485224, validation/accuracy=0.585100, validation/loss=1.736468, validation/num_examples=50000
I0302 16:42:32.271475 139758009304832 logging_writer.py:48] [36200] global_step=36200, grad_norm=1.1269599199295044, loss=3.217024326324463
I0302 16:43:17.234194 139758017697536 logging_writer.py:48] [36300] global_step=36300, grad_norm=1.1554309129714966, loss=2.7085323333740234
I0302 16:44:02.411576 139758009304832 logging_writer.py:48] [36400] global_step=36400, grad_norm=1.11762273311615, loss=2.49735689163208
I0302 16:44:47.626729 139758017697536 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.1218302249908447, loss=2.727900505065918
I0302 16:45:32.412072 139758009304832 logging_writer.py:48] [36600] global_step=36600, grad_norm=1.1239181756973267, loss=3.158186435699463
I0302 16:46:17.247575 139758017697536 logging_writer.py:48] [36700] global_step=36700, grad_norm=1.037592887878418, loss=3.498748540878296
I0302 16:47:02.209609 139758009304832 logging_writer.py:48] [36800] global_step=36800, grad_norm=1.1827582120895386, loss=2.435215711593628
I0302 16:47:46.941270 139758017697536 logging_writer.py:48] [36900] global_step=36900, grad_norm=1.0121272802352905, loss=4.420496940612793
I0302 16:48:31.616766 139758009304832 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.9944020509719849, loss=4.042675495147705
I0302 16:48:57.706677 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:49:08.742131 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:49:28.579918 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:49:30.211009 139953291118400 submission_runner.py:411] Time since start: 17610.39s, 	Step: 37060, 	{'train/accuracy': 0.6688476204872131, 'train/loss': 1.3819684982299805, 'validation/accuracy': 0.5868600010871887, 'validation/loss': 1.7398897409439087, 'validation/num_examples': 50000, 'test/accuracy': 0.47370001673698425, 'test/loss': 2.4095163345336914, 'test/num_examples': 10000, 'score': 16425.699372053146, 'total_duration': 17610.38723230362, 'accumulated_submission_time': 16425.699372053146, 'accumulated_eval_time': 1180.2964413166046, 'accumulated_logging_time': 2.449498414993286}
I0302 16:49:30.231782 139758017697536 logging_writer.py:48] [37060] accumulated_eval_time=1180.296441, accumulated_logging_time=2.449498, accumulated_submission_time=16425.699372, global_step=37060, preemption_count=0, score=16425.699372, test/accuracy=0.473700, test/loss=2.409516, test/num_examples=10000, total_duration=17610.387232, train/accuracy=0.668848, train/loss=1.381968, validation/accuracy=0.586860, validation/loss=1.739890, validation/num_examples=50000
I0302 16:49:46.436700 139758009304832 logging_writer.py:48] [37100] global_step=37100, grad_norm=0.9859482645988464, loss=4.876685619354248
I0302 16:50:28.403265 139758017697536 logging_writer.py:48] [37200] global_step=37200, grad_norm=1.134718656539917, loss=2.3909008502960205
I0302 16:51:13.787801 139758009304832 logging_writer.py:48] [37300] global_step=37300, grad_norm=1.2361880540847778, loss=2.5494227409362793
I0302 16:51:58.981744 139758017697536 logging_writer.py:48] [37400] global_step=37400, grad_norm=0.9812389016151428, loss=4.451465606689453
I0302 16:52:44.234785 139758009304832 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.9418547749519348, loss=3.806114435195923
I0302 16:53:29.170655 139758017697536 logging_writer.py:48] [37600] global_step=37600, grad_norm=1.5702544450759888, loss=2.638584852218628
I0302 16:54:13.992139 139758009304832 logging_writer.py:48] [37700] global_step=37700, grad_norm=1.2575517892837524, loss=2.5544912815093994
I0302 16:54:59.251893 139758017697536 logging_writer.py:48] [37800] global_step=37800, grad_norm=1.366417646408081, loss=2.4927148818969727
I0302 16:55:44.036103 139758009304832 logging_writer.py:48] [37900] global_step=37900, grad_norm=1.0555258989334106, loss=3.365827798843384
I0302 16:56:28.910069 139758017697536 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.0563485622406006, loss=3.862429618835449
I0302 16:56:30.379808 139953291118400 spec.py:321] Evaluating on the training split.
I0302 16:56:41.226275 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 16:56:59.152693 139953291118400 spec.py:349] Evaluating on the test split.
I0302 16:57:00.789687 139953291118400 submission_runner.py:411] Time since start: 18060.97s, 	Step: 38005, 	{'train/accuracy': 0.639355480670929, 'train/loss': 1.477370262145996, 'validation/accuracy': 0.592960000038147, 'validation/loss': 1.6992011070251465, 'validation/num_examples': 50000, 'test/accuracy': 0.47950002551078796, 'test/loss': 2.3602285385131836, 'test/num_examples': 10000, 'score': 16845.78829050064, 'total_duration': 18060.96590399742, 'accumulated_submission_time': 16845.78829050064, 'accumulated_eval_time': 1210.7062888145447, 'accumulated_logging_time': 2.4802818298339844}
I0302 16:57:00.817072 139758009304832 logging_writer.py:48] [38005] accumulated_eval_time=1210.706289, accumulated_logging_time=2.480282, accumulated_submission_time=16845.788291, global_step=38005, preemption_count=0, score=16845.788291, test/accuracy=0.479500, test/loss=2.360229, test/num_examples=10000, total_duration=18060.965904, train/accuracy=0.639355, train/loss=1.477370, validation/accuracy=0.592960, validation/loss=1.699201, validation/num_examples=50000
I0302 16:57:39.844422 139758017697536 logging_writer.py:48] [38100] global_step=38100, grad_norm=1.3032885789871216, loss=2.5326015949249268
I0302 16:58:24.919982 139758009304832 logging_writer.py:48] [38200] global_step=38200, grad_norm=1.35614013671875, loss=4.905306339263916
I0302 16:59:09.867566 139758017697536 logging_writer.py:48] [38300] global_step=38300, grad_norm=1.060715913772583, loss=3.1732337474823
I0302 16:59:54.850554 139758009304832 logging_writer.py:48] [38400] global_step=38400, grad_norm=1.0028390884399414, loss=4.596732139587402
I0302 17:00:39.770363 139758017697536 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.1846150159835815, loss=2.4883012771606445
I0302 17:01:24.523585 139758009304832 logging_writer.py:48] [38600] global_step=38600, grad_norm=1.4508624076843262, loss=2.5258913040161133
I0302 17:02:09.427625 139758017697536 logging_writer.py:48] [38700] global_step=38700, grad_norm=1.1562652587890625, loss=3.120656967163086
I0302 17:02:54.718373 139758009304832 logging_writer.py:48] [38800] global_step=38800, grad_norm=1.0681122541427612, loss=3.142921209335327
I0302 17:03:39.683395 139758017697536 logging_writer.py:48] [38900] global_step=38900, grad_norm=1.2373485565185547, loss=2.5084822177886963
I0302 17:04:00.798017 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:04:12.123768 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:04:29.897192 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:04:31.533860 139953291118400 submission_runner.py:411] Time since start: 18511.71s, 	Step: 38949, 	{'train/accuracy': 0.6482812166213989, 'train/loss': 1.4299132823944092, 'validation/accuracy': 0.601099967956543, 'validation/loss': 1.6725398302078247, 'validation/num_examples': 50000, 'test/accuracy': 0.4771000146865845, 'test/loss': 2.336911916732788, 'test/num_examples': 10000, 'score': 17265.709993124008, 'total_duration': 18511.710064649582, 'accumulated_submission_time': 17265.709993124008, 'accumulated_eval_time': 1241.442130804062, 'accumulated_logging_time': 2.518287420272827}
I0302 17:04:31.559443 139758009304832 logging_writer.py:48] [38949] accumulated_eval_time=1241.442131, accumulated_logging_time=2.518287, accumulated_submission_time=17265.709993, global_step=38949, preemption_count=0, score=17265.709993, test/accuracy=0.477100, test/loss=2.336912, test/num_examples=10000, total_duration=18511.710065, train/accuracy=0.648281, train/loss=1.429913, validation/accuracy=0.601100, validation/loss=1.672540, validation/num_examples=50000
I0302 17:04:52.112704 139758017697536 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.160995364189148, loss=2.576530933380127
I0302 17:05:36.243230 139758009304832 logging_writer.py:48] [39100] global_step=39100, grad_norm=1.0056709051132202, loss=2.956104278564453
I0302 17:06:21.474542 139758017697536 logging_writer.py:48] [39200] global_step=39200, grad_norm=1.2936105728149414, loss=2.574096441268921
I0302 17:07:06.399049 139758009304832 logging_writer.py:48] [39300] global_step=39300, grad_norm=1.2369451522827148, loss=2.433570623397827
I0302 17:07:51.082251 139758017697536 logging_writer.py:48] [39400] global_step=39400, grad_norm=0.9975705742835999, loss=3.3865959644317627
I0302 17:08:36.084367 139758009304832 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.9520649313926697, loss=4.543212413787842
I0302 17:09:20.971346 139758017697536 logging_writer.py:48] [39600] global_step=39600, grad_norm=1.1011768579483032, loss=3.7517006397247314
I0302 17:10:05.796336 139758009304832 logging_writer.py:48] [39700] global_step=39700, grad_norm=0.9470005035400391, loss=4.5449137687683105
I0302 17:10:50.558211 139758017697536 logging_writer.py:48] [39800] global_step=39800, grad_norm=1.2787338495254517, loss=2.6436734199523926
I0302 17:11:31.588769 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:11:42.437653 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:12:00.760763 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:12:02.410409 139953291118400 submission_runner.py:411] Time since start: 18962.59s, 	Step: 39893, 	{'train/accuracy': 0.6584374904632568, 'train/loss': 1.4017064571380615, 'validation/accuracy': 0.6007599830627441, 'validation/loss': 1.6774709224700928, 'validation/num_examples': 50000, 'test/accuracy': 0.48250001668930054, 'test/loss': 2.327033042907715, 'test/num_examples': 10000, 'score': 17685.679537296295, 'total_duration': 18962.586629629135, 'accumulated_submission_time': 17685.679537296295, 'accumulated_eval_time': 1272.2637612819672, 'accumulated_logging_time': 2.5543577671051025}
I0302 17:12:02.439403 139758009304832 logging_writer.py:48] [39893] accumulated_eval_time=1272.263761, accumulated_logging_time=2.554358, accumulated_submission_time=17685.679537, global_step=39893, preemption_count=0, score=17685.679537, test/accuracy=0.482500, test/loss=2.327033, test/num_examples=10000, total_duration=18962.586630, train/accuracy=0.658437, train/loss=1.401706, validation/accuracy=0.600760, validation/loss=1.677471, validation/num_examples=50000
I0302 17:12:05.624380 139758017697536 logging_writer.py:48] [39900] global_step=39900, grad_norm=1.2393786907196045, loss=2.5976500511169434
I0302 17:12:46.270280 139758009304832 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.9568791389465332, loss=4.284295558929443
I0302 17:13:31.285247 139758017697536 logging_writer.py:48] [40100] global_step=40100, grad_norm=1.1900702714920044, loss=2.4670708179473877
I0302 17:14:16.234589 139758009304832 logging_writer.py:48] [40200] global_step=40200, grad_norm=1.2662492990493774, loss=2.676133632659912
I0302 17:15:01.537937 139758017697536 logging_writer.py:48] [40300] global_step=40300, grad_norm=1.1023900508880615, loss=2.6078379154205322
I0302 17:15:46.295417 139758009304832 logging_writer.py:48] [40400] global_step=40400, grad_norm=1.2844743728637695, loss=2.5415632724761963
I0302 17:16:31.372427 139758017697536 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.06095290184021, loss=3.5759246349334717
I0302 17:17:16.662663 139758009304832 logging_writer.py:48] [40600] global_step=40600, grad_norm=1.240110158920288, loss=4.545703411102295
I0302 17:18:01.609018 139758017697536 logging_writer.py:48] [40700] global_step=40700, grad_norm=1.0590366125106812, loss=3.6305112838745117
I0302 17:18:46.528984 139758009304832 logging_writer.py:48] [40800] global_step=40800, grad_norm=1.163491129875183, loss=2.8024673461914062
I0302 17:19:02.480815 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:19:13.183967 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:19:32.444992 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:19:34.086074 139953291118400 submission_runner.py:411] Time since start: 19414.26s, 	Step: 40837, 	{'train/accuracy': 0.6469140648841858, 'train/loss': 1.4363796710968018, 'validation/accuracy': 0.6001799702644348, 'validation/loss': 1.6573528051376343, 'validation/num_examples': 50000, 'test/accuracy': 0.4824000298976898, 'test/loss': 2.323774814605713, 'test/num_examples': 10000, 'score': 18105.65966153145, 'total_duration': 19414.262279510498, 'accumulated_submission_time': 18105.65966153145, 'accumulated_eval_time': 1303.8689863681793, 'accumulated_logging_time': 2.595737934112549}
I0302 17:19:34.115296 139758017697536 logging_writer.py:48] [40837] accumulated_eval_time=1303.868986, accumulated_logging_time=2.595738, accumulated_submission_time=18105.659662, global_step=40837, preemption_count=0, score=18105.659662, test/accuracy=0.482400, test/loss=2.323775, test/num_examples=10000, total_duration=19414.262280, train/accuracy=0.646914, train/loss=1.436380, validation/accuracy=0.600180, validation/loss=1.657353, validation/num_examples=50000
I0302 17:19:59.437377 139758009304832 logging_writer.py:48] [40900] global_step=40900, grad_norm=1.062990665435791, loss=4.065464019775391
I0302 17:20:43.075335 139758017697536 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.0171828269958496, loss=3.7271440029144287
I0302 17:21:28.173200 139758009304832 logging_writer.py:48] [41100] global_step=41100, grad_norm=1.21052086353302, loss=2.594001531600952
I0302 17:22:13.084780 139758017697536 logging_writer.py:48] [41200] global_step=41200, grad_norm=1.2563910484313965, loss=2.630075216293335
I0302 17:22:58.232871 139758009304832 logging_writer.py:48] [41300] global_step=41300, grad_norm=1.1762363910675049, loss=2.5829546451568604
I0302 17:23:43.160697 139758017697536 logging_writer.py:48] [41400] global_step=41400, grad_norm=1.169901967048645, loss=2.666779041290283
I0302 17:24:28.021578 139758009304832 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.2773194313049316, loss=2.5646917819976807
I0302 17:25:12.834588 139758017697536 logging_writer.py:48] [41600] global_step=41600, grad_norm=1.0356096029281616, loss=4.0538716316223145
I0302 17:25:57.433084 139758009304832 logging_writer.py:48] [41700] global_step=41700, grad_norm=1.1501144170761108, loss=2.439610481262207
I0302 17:26:34.291811 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:26:45.042485 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:27:03.265158 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:27:04.910572 139953291118400 submission_runner.py:411] Time since start: 19865.09s, 	Step: 41783, 	{'train/accuracy': 0.6481835842132568, 'train/loss': 1.4439572095870972, 'validation/accuracy': 0.5995799899101257, 'validation/loss': 1.6738475561141968, 'validation/num_examples': 50000, 'test/accuracy': 0.48590001463890076, 'test/loss': 2.331721544265747, 'test/num_examples': 10000, 'score': 18525.777707338333, 'total_duration': 19865.08677005768, 'accumulated_submission_time': 18525.777707338333, 'accumulated_eval_time': 1334.4877030849457, 'accumulated_logging_time': 2.63551926612854}
I0302 17:27:04.938004 139758017697536 logging_writer.py:48] [41783] accumulated_eval_time=1334.487703, accumulated_logging_time=2.635519, accumulated_submission_time=18525.777707, global_step=41783, preemption_count=0, score=18525.777707, test/accuracy=0.485900, test/loss=2.331722, test/num_examples=10000, total_duration=19865.086770, train/accuracy=0.648184, train/loss=1.443957, validation/accuracy=0.599580, validation/loss=1.673848, validation/num_examples=50000
I0302 17:27:12.071510 139758009304832 logging_writer.py:48] [41800] global_step=41800, grad_norm=1.218184232711792, loss=2.4962258338928223
I0302 17:27:53.370806 139758017697536 logging_writer.py:48] [41900] global_step=41900, grad_norm=1.1585379838943481, loss=2.5115342140197754
I0302 17:28:38.355609 139758009304832 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.3111581802368164, loss=2.3613946437835693
I0302 17:29:23.428083 139758017697536 logging_writer.py:48] [42100] global_step=42100, grad_norm=1.2099840641021729, loss=2.511976718902588
I0302 17:30:08.414625 139758009304832 logging_writer.py:48] [42200] global_step=42200, grad_norm=1.1311092376708984, loss=2.7356650829315186
I0302 17:30:53.108238 139758017697536 logging_writer.py:48] [42300] global_step=42300, grad_norm=1.130139946937561, loss=2.453547716140747
I0302 17:31:38.289550 139758009304832 logging_writer.py:48] [42400] global_step=42400, grad_norm=1.0359981060028076, loss=4.338196754455566
I0302 17:32:23.571789 139758017697536 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.0499160289764404, loss=3.8001184463500977
I0302 17:33:08.839688 139758009304832 logging_writer.py:48] [42600] global_step=42600, grad_norm=1.229364037513733, loss=2.580918312072754
I0302 17:33:53.573042 139758017697536 logging_writer.py:48] [42700] global_step=42700, grad_norm=1.2244532108306885, loss=2.5828332901000977
I0302 17:34:05.009407 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:34:15.988343 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:34:33.975563 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:34:35.610833 139953291118400 submission_runner.py:411] Time since start: 20315.79s, 	Step: 42727, 	{'train/accuracy': 0.6622461080551147, 'train/loss': 1.4292950630187988, 'validation/accuracy': 0.6039800047874451, 'validation/loss': 1.6770350933074951, 'validation/num_examples': 50000, 'test/accuracy': 0.48740002512931824, 'test/loss': 2.3381412029266357, 'test/num_examples': 10000, 'score': 18945.784809350967, 'total_duration': 20315.787051200867, 'accumulated_submission_time': 18945.784809350967, 'accumulated_eval_time': 1365.0891120433807, 'accumulated_logging_time': 2.6732630729675293}
I0302 17:34:35.635887 139758009304832 logging_writer.py:48] [42727] accumulated_eval_time=1365.089112, accumulated_logging_time=2.673263, accumulated_submission_time=18945.784809, global_step=42727, preemption_count=0, score=18945.784809, test/accuracy=0.487400, test/loss=2.338141, test/num_examples=10000, total_duration=20315.787051, train/accuracy=0.662246, train/loss=1.429295, validation/accuracy=0.603980, validation/loss=1.677035, validation/num_examples=50000
I0302 17:35:04.893813 139758017697536 logging_writer.py:48] [42800] global_step=42800, grad_norm=1.157979965209961, loss=2.9270763397216797
I0302 17:35:49.301212 139758009304832 logging_writer.py:48] [42900] global_step=42900, grad_norm=1.0503571033477783, loss=3.685683012008667
I0302 17:36:34.419746 139758017697536 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.0243061780929565, loss=4.9420695304870605
I0302 17:37:19.431187 139758009304832 logging_writer.py:48] [43100] global_step=43100, grad_norm=1.0334995985031128, loss=5.028565406799316
I0302 17:38:03.895636 139758017697536 logging_writer.py:48] [43200] global_step=43200, grad_norm=1.2264662981033325, loss=3.1481921672821045
I0302 17:38:48.442833 139758009304832 logging_writer.py:48] [43300] global_step=43300, grad_norm=1.1979302167892456, loss=2.474708318710327
I0302 17:39:33.413794 139758017697536 logging_writer.py:48] [43400] global_step=43400, grad_norm=1.3822685480117798, loss=2.5349183082580566
I0302 17:40:17.993144 139758009304832 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.332330584526062, loss=2.359933614730835
I0302 17:41:02.754382 139758017697536 logging_writer.py:48] [43600] global_step=43600, grad_norm=1.034014105796814, loss=4.94881534576416
I0302 17:41:35.710327 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:41:46.399956 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:42:04.605048 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:42:06.244995 139953291118400 submission_runner.py:411] Time since start: 20766.42s, 	Step: 43675, 	{'train/accuracy': 0.6868749856948853, 'train/loss': 1.3137249946594238, 'validation/accuracy': 0.6068400144577026, 'validation/loss': 1.681557297706604, 'validation/num_examples': 50000, 'test/accuracy': 0.4832000136375427, 'test/loss': 2.350550413131714, 'test/num_examples': 10000, 'score': 19365.801652669907, 'total_duration': 20766.421213150024, 'accumulated_submission_time': 19365.801652669907, 'accumulated_eval_time': 1395.6237680912018, 'accumulated_logging_time': 2.7082393169403076}
I0302 17:42:06.273911 139758009304832 logging_writer.py:48] [43675] accumulated_eval_time=1395.623768, accumulated_logging_time=2.708239, accumulated_submission_time=19365.801653, global_step=43675, preemption_count=0, score=19365.801653, test/accuracy=0.483200, test/loss=2.350550, test/num_examples=10000, total_duration=20766.421213, train/accuracy=0.686875, train/loss=1.313725, validation/accuracy=0.606840, validation/loss=1.681557, validation/num_examples=50000
I0302 17:42:16.587720 139758017697536 logging_writer.py:48] [43700] global_step=43700, grad_norm=1.1344352960586548, loss=2.8012068271636963
I0302 17:42:58.371661 139758009304832 logging_writer.py:48] [43800] global_step=43800, grad_norm=1.2709070444107056, loss=2.511133909225464
I0302 17:43:43.210534 139758017697536 logging_writer.py:48] [43900] global_step=43900, grad_norm=1.2832872867584229, loss=2.4644665718078613
I0302 17:44:28.267523 139758009304832 logging_writer.py:48] [44000] global_step=44000, grad_norm=1.1977834701538086, loss=3.1785500049591064
I0302 17:45:13.246710 139758017697536 logging_writer.py:48] [44100] global_step=44100, grad_norm=1.0837656259536743, loss=4.84160852432251
I0302 17:45:58.247570 139758009304832 logging_writer.py:48] [44200] global_step=44200, grad_norm=1.064814805984497, loss=3.009044885635376
I0302 17:46:43.173344 139758017697536 logging_writer.py:48] [44300] global_step=44300, grad_norm=1.1943519115447998, loss=2.5684893131256104
I0302 17:47:28.151194 139758009304832 logging_writer.py:48] [44400] global_step=44400, grad_norm=1.208248496055603, loss=2.47849702835083
I0302 17:48:13.314251 139758017697536 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.080896258354187, loss=2.838972330093384
I0302 17:48:57.798834 139758009304832 logging_writer.py:48] [44600] global_step=44600, grad_norm=0.9976090788841248, loss=4.654994487762451
I0302 17:49:06.531545 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:49:17.249793 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:49:35.839055 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:49:37.474488 139953291118400 submission_runner.py:411] Time since start: 21217.65s, 	Step: 44621, 	{'train/accuracy': 0.6566405892372131, 'train/loss': 1.4093447923660278, 'validation/accuracy': 0.6092199683189392, 'validation/loss': 1.6448744535446167, 'validation/num_examples': 50000, 'test/accuracy': 0.4914000332355499, 'test/loss': 2.3031435012817383, 'test/num_examples': 10000, 'score': 19785.997804403305, 'total_duration': 21217.650696992874, 'accumulated_submission_time': 19785.997804403305, 'accumulated_eval_time': 1426.566675901413, 'accumulated_logging_time': 2.7504830360412598}
I0302 17:49:37.501224 139758017697536 logging_writer.py:48] [44621] accumulated_eval_time=1426.566676, accumulated_logging_time=2.750483, accumulated_submission_time=19785.997804, global_step=44621, preemption_count=0, score=19785.997804, test/accuracy=0.491400, test/loss=2.303144, test/num_examples=10000, total_duration=21217.650697, train/accuracy=0.656641, train/loss=1.409345, validation/accuracy=0.609220, validation/loss=1.644874, validation/num_examples=50000
I0302 17:50:09.124443 139758009304832 logging_writer.py:48] [44700] global_step=44700, grad_norm=1.339911699295044, loss=2.658170223236084
I0302 17:50:53.510571 139758017697536 logging_writer.py:48] [44800] global_step=44800, grad_norm=1.034267783164978, loss=4.724847316741943
I0302 17:51:38.339866 139758009304832 logging_writer.py:48] [44900] global_step=44900, grad_norm=1.1818504333496094, loss=2.6569435596466064
I0302 17:52:23.262135 139758017697536 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.1709833145141602, loss=2.5024802684783936
I0302 17:53:08.267234 139758009304832 logging_writer.py:48] [45100] global_step=45100, grad_norm=1.2651687860488892, loss=2.5067269802093506
I0302 17:53:53.002079 139758017697536 logging_writer.py:48] [45200] global_step=45200, grad_norm=1.2661936283111572, loss=2.4511466026306152
I0302 17:54:37.848175 139758009304832 logging_writer.py:48] [45300] global_step=45300, grad_norm=1.1793031692504883, loss=3.671877861022949
I0302 17:55:22.674464 139758017697536 logging_writer.py:48] [45400] global_step=45400, grad_norm=1.2118452787399292, loss=2.3921360969543457
I0302 17:56:07.659801 139758009304832 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.188415288925171, loss=2.531336784362793
I0302 17:56:37.783372 139953291118400 spec.py:321] Evaluating on the training split.
I0302 17:56:48.537978 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 17:57:07.439615 139953291118400 spec.py:349] Evaluating on the test split.
I0302 17:57:09.079959 139953291118400 submission_runner.py:411] Time since start: 21669.26s, 	Step: 45569, 	{'train/accuracy': 0.6633593440055847, 'train/loss': 1.3881406784057617, 'validation/accuracy': 0.6101799607276917, 'validation/loss': 1.6343706846237183, 'validation/num_examples': 50000, 'test/accuracy': 0.4869000315666199, 'test/loss': 2.2931628227233887, 'test/num_examples': 10000, 'score': 20206.22102165222, 'total_duration': 21669.25616335869, 'accumulated_submission_time': 20206.22102165222, 'accumulated_eval_time': 1457.8632283210754, 'accumulated_logging_time': 2.7871975898742676}
I0302 17:57:09.109858 139758017697536 logging_writer.py:48] [45569] accumulated_eval_time=1457.863228, accumulated_logging_time=2.787198, accumulated_submission_time=20206.221022, global_step=45569, preemption_count=0, score=20206.221022, test/accuracy=0.486900, test/loss=2.293163, test/num_examples=10000, total_duration=21669.256163, train/accuracy=0.663359, train/loss=1.388141, validation/accuracy=0.610180, validation/loss=1.634371, validation/num_examples=50000
I0302 17:57:21.773924 139758009304832 logging_writer.py:48] [45600] global_step=45600, grad_norm=1.3138823509216309, loss=2.482945203781128
I0302 17:58:03.492914 139758017697536 logging_writer.py:48] [45700] global_step=45700, grad_norm=1.164747953414917, loss=2.4297075271606445
I0302 17:58:48.417709 139758009304832 logging_writer.py:48] [45800] global_step=45800, grad_norm=1.136519432067871, loss=2.7701892852783203
I0302 17:59:33.222004 139758017697536 logging_writer.py:48] [45900] global_step=45900, grad_norm=1.0398507118225098, loss=4.307836532592773
I0302 18:00:17.911824 139758009304832 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.1282981634140015, loss=4.022141456604004
I0302 18:01:02.727535 139758017697536 logging_writer.py:48] [46100] global_step=46100, grad_norm=1.0631035566329956, loss=3.164374589920044
I0302 18:01:47.202864 139758009304832 logging_writer.py:48] [46200] global_step=46200, grad_norm=1.0990896224975586, loss=2.6803667545318604
I0302 18:02:32.488825 139758017697536 logging_writer.py:48] [46300] global_step=46300, grad_norm=1.1299432516098022, loss=2.7035741806030273
I0302 18:03:17.640493 139758009304832 logging_writer.py:48] [46400] global_step=46400, grad_norm=1.1336195468902588, loss=2.827584981918335
I0302 18:04:02.627391 139758017697536 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.2972760200500488, loss=2.547523260116577
I0302 18:04:09.466220 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:04:20.352081 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:04:42.005538 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:04:43.631388 139953291118400 submission_runner.py:411] Time since start: 22123.81s, 	Step: 46517, 	{'train/accuracy': 0.6712695360183716, 'train/loss': 1.3291295766830444, 'validation/accuracy': 0.6121799945831299, 'validation/loss': 1.6179096698760986, 'validation/num_examples': 50000, 'test/accuracy': 0.48670002818107605, 'test/loss': 2.2925844192504883, 'test/num_examples': 10000, 'score': 20626.519107580185, 'total_duration': 22123.807602643967, 'accumulated_submission_time': 20626.519107580185, 'accumulated_eval_time': 1492.0283637046814, 'accumulated_logging_time': 2.8271169662475586}
I0302 18:04:43.655380 139758009304832 logging_writer.py:48] [46517] accumulated_eval_time=1492.028364, accumulated_logging_time=2.827117, accumulated_submission_time=20626.519108, global_step=46517, preemption_count=0, score=20626.519108, test/accuracy=0.486700, test/loss=2.292584, test/num_examples=10000, total_duration=22123.807603, train/accuracy=0.671270, train/loss=1.329130, validation/accuracy=0.612180, validation/loss=1.617910, validation/num_examples=50000
I0302 18:05:16.844168 139758017697536 logging_writer.py:48] [46600] global_step=46600, grad_norm=1.241313099861145, loss=2.4541285037994385
I0302 18:06:00.420346 139758009304832 logging_writer.py:48] [46700] global_step=46700, grad_norm=1.2610687017440796, loss=2.5011634826660156
I0302 18:06:45.765443 139758017697536 logging_writer.py:48] [46800] global_step=46800, grad_norm=1.0707385540008545, loss=3.5955755710601807
I0302 18:07:31.146667 139758009304832 logging_writer.py:48] [46900] global_step=46900, grad_norm=1.2403188943862915, loss=2.4403884410858154
I0302 18:08:15.919349 139758017697536 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.335357427597046, loss=2.4369492530822754
I0302 18:09:00.686567 139758009304832 logging_writer.py:48] [47100] global_step=47100, grad_norm=1.3357055187225342, loss=2.617154359817505
I0302 18:09:45.633451 139758017697536 logging_writer.py:48] [47200] global_step=47200, grad_norm=1.09670090675354, loss=3.7843103408813477
I0302 18:10:30.318290 139758009304832 logging_writer.py:48] [47300] global_step=47300, grad_norm=1.2752741575241089, loss=2.283297538757324
I0302 18:11:15.127360 139758017697536 logging_writer.py:48] [47400] global_step=47400, grad_norm=1.253481388092041, loss=2.360765218734741
I0302 18:11:44.072354 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:11:54.946228 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:12:13.927766 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:12:15.565915 139953291118400 submission_runner.py:411] Time since start: 22575.74s, 	Step: 47466, 	{'train/accuracy': 0.6614062190055847, 'train/loss': 1.4059300422668457, 'validation/accuracy': 0.6163600087165833, 'validation/loss': 1.6147215366363525, 'validation/num_examples': 50000, 'test/accuracy': 0.491100013256073, 'test/loss': 2.2687935829162598, 'test/num_examples': 10000, 'score': 21046.87879395485, 'total_duration': 22575.742127418518, 'accumulated_submission_time': 21046.87879395485, 'accumulated_eval_time': 1523.5219233036041, 'accumulated_logging_time': 2.8597183227539062}
I0302 18:12:15.592462 139758009304832 logging_writer.py:48] [47466] accumulated_eval_time=1523.521923, accumulated_logging_time=2.859718, accumulated_submission_time=21046.878794, global_step=47466, preemption_count=0, score=21046.878794, test/accuracy=0.491100, test/loss=2.268794, test/num_examples=10000, total_duration=22575.742127, train/accuracy=0.661406, train/loss=1.405930, validation/accuracy=0.616360, validation/loss=1.614722, validation/num_examples=50000
I0302 18:12:29.427417 139758017697536 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.3532994985580444, loss=2.395059585571289
I0302 18:13:11.534745 139758009304832 logging_writer.py:48] [47600] global_step=47600, grad_norm=1.0574672222137451, loss=4.510379791259766
I0302 18:13:56.215102 139758017697536 logging_writer.py:48] [47700] global_step=47700, grad_norm=1.2342807054519653, loss=2.497572183609009
I0302 18:14:41.149620 139758009304832 logging_writer.py:48] [47800] global_step=47800, grad_norm=1.1288869380950928, loss=2.70542049407959
I0302 18:15:26.080685 139758017697536 logging_writer.py:48] [47900] global_step=47900, grad_norm=1.0776493549346924, loss=2.907308578491211
I0302 18:16:10.741955 139758009304832 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.079480528831482, loss=3.9402048587799072
I0302 18:16:55.522926 139758017697536 logging_writer.py:48] [48100] global_step=48100, grad_norm=1.2621500492095947, loss=2.4895293712615967
I0302 18:17:40.365467 139758009304832 logging_writer.py:48] [48200] global_step=48200, grad_norm=1.2735072374343872, loss=2.4027137756347656
I0302 18:18:25.118556 139758017697536 logging_writer.py:48] [48300] global_step=48300, grad_norm=1.0758187770843506, loss=3.3634252548217773
I0302 18:19:09.799481 139758009304832 logging_writer.py:48] [48400] global_step=48400, grad_norm=1.1554503440856934, loss=2.341712474822998
I0302 18:19:15.747205 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:19:26.889956 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:19:43.472443 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:19:45.121684 139953291118400 submission_runner.py:411] Time since start: 23025.30s, 	Step: 48415, 	{'train/accuracy': 0.6602538824081421, 'train/loss': 1.423980951309204, 'validation/accuracy': 0.6101399660110474, 'validation/loss': 1.6533193588256836, 'validation/num_examples': 50000, 'test/accuracy': 0.4886000156402588, 'test/loss': 2.3144147396087646, 'test/num_examples': 10000, 'score': 21466.973664999008, 'total_duration': 23025.29788851738, 'accumulated_submission_time': 21466.973664999008, 'accumulated_eval_time': 1552.8963572978973, 'accumulated_logging_time': 2.897174119949341}
I0302 18:19:45.149772 139758017697536 logging_writer.py:48] [48415] accumulated_eval_time=1552.896357, accumulated_logging_time=2.897174, accumulated_submission_time=21466.973665, global_step=48415, preemption_count=0, score=21466.973665, test/accuracy=0.488600, test/loss=2.314415, test/num_examples=10000, total_duration=23025.297889, train/accuracy=0.660254, train/loss=1.423981, validation/accuracy=0.610140, validation/loss=1.653319, validation/num_examples=50000
I0302 18:20:20.009014 139758009304832 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.203935146331787, loss=2.184373378753662
I0302 18:21:04.862917 139758017697536 logging_writer.py:48] [48600] global_step=48600, grad_norm=1.0598746538162231, loss=4.6241326332092285
I0302 18:21:49.472197 139758009304832 logging_writer.py:48] [48700] global_step=48700, grad_norm=1.1407873630523682, loss=2.5804059505462646
I0302 18:22:34.734481 139758017697536 logging_writer.py:48] [48800] global_step=48800, grad_norm=1.5151865482330322, loss=2.408413887023926
I0302 18:23:19.616803 139758009304832 logging_writer.py:48] [48900] global_step=48900, grad_norm=1.1287509202957153, loss=2.7352206707000732
I0302 18:24:04.590565 139758017697536 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.6502419710159302, loss=2.4745919704437256
I0302 18:24:49.252770 139758009304832 logging_writer.py:48] [49100] global_step=49100, grad_norm=1.1445138454437256, loss=2.8474512100219727
I0302 18:25:34.279162 139758017697536 logging_writer.py:48] [49200] global_step=49200, grad_norm=1.2564170360565186, loss=2.2806894779205322
I0302 18:26:19.384921 139758009304832 logging_writer.py:48] [49300] global_step=49300, grad_norm=1.0196659564971924, loss=3.9578707218170166
I0302 18:26:45.256304 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:26:56.214359 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:27:15.709476 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:27:17.342426 139953291118400 submission_runner.py:411] Time since start: 23477.52s, 	Step: 49359, 	{'train/accuracy': 0.6670702695846558, 'train/loss': 1.3476743698120117, 'validation/accuracy': 0.6132599711418152, 'validation/loss': 1.6010985374450684, 'validation/num_examples': 50000, 'test/accuracy': 0.49170002341270447, 'test/loss': 2.266906261444092, 'test/num_examples': 10000, 'score': 21887.021904945374, 'total_duration': 23477.518564224243, 'accumulated_submission_time': 21887.021904945374, 'accumulated_eval_time': 1584.9823913574219, 'accumulated_logging_time': 2.9352879524230957}
I0302 18:27:17.373732 139758017697536 logging_writer.py:48] [49359] accumulated_eval_time=1584.982391, accumulated_logging_time=2.935288, accumulated_submission_time=21887.021905, global_step=49359, preemption_count=0, score=21887.021905, test/accuracy=0.491700, test/loss=2.266906, test/num_examples=10000, total_duration=23477.518564, train/accuracy=0.667070, train/loss=1.347674, validation/accuracy=0.613260, validation/loss=1.601099, validation/num_examples=50000
I0302 18:27:33.994004 139758009304832 logging_writer.py:48] [49400] global_step=49400, grad_norm=1.0589569807052612, loss=4.865057468414307
I0302 18:28:16.554521 139758017697536 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.1972572803497314, loss=2.397465705871582
I0302 18:29:01.515800 139758009304832 logging_writer.py:48] [49600] global_step=49600, grad_norm=1.2023106813430786, loss=3.0355520248413086
I0302 18:29:46.329224 139758017697536 logging_writer.py:48] [49700] global_step=49700, grad_norm=1.1050916910171509, loss=4.5945329666137695
I0302 18:30:31.106180 139758009304832 logging_writer.py:48] [49800] global_step=49800, grad_norm=1.1903759241104126, loss=3.158708333969116
I0302 18:31:15.911942 139758017697536 logging_writer.py:48] [49900] global_step=49900, grad_norm=1.2639671564102173, loss=2.4080162048339844
I0302 18:32:00.611226 139758009304832 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.22897207736969, loss=2.2868833541870117
I0302 18:32:45.903466 139758017697536 logging_writer.py:48] [50100] global_step=50100, grad_norm=1.131713628768921, loss=2.5011353492736816
I0302 18:33:31.018608 139758009304832 logging_writer.py:48] [50200] global_step=50200, grad_norm=1.1119142770767212, loss=4.941693305969238
I0302 18:34:16.029932 139758017697536 logging_writer.py:48] [50300] global_step=50300, grad_norm=1.1328279972076416, loss=4.994274139404297
I0302 18:34:17.497571 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:34:28.225674 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:34:45.654316 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:34:47.291916 139953291118400 submission_runner.py:411] Time since start: 23927.47s, 	Step: 50305, 	{'train/accuracy': 0.6949023008346558, 'train/loss': 1.217258095741272, 'validation/accuracy': 0.6212999820709229, 'validation/loss': 1.570192813873291, 'validation/num_examples': 50000, 'test/accuracy': 0.49800002574920654, 'test/loss': 2.233330488204956, 'test/num_examples': 10000, 'score': 22307.085068941116, 'total_duration': 23927.468125104904, 'accumulated_submission_time': 22307.085068941116, 'accumulated_eval_time': 1614.7766954898834, 'accumulated_logging_time': 2.9790749549865723}
I0302 18:34:47.318263 139758009304832 logging_writer.py:48] [50305] accumulated_eval_time=1614.776695, accumulated_logging_time=2.979075, accumulated_submission_time=22307.085069, global_step=50305, preemption_count=0, score=22307.085069, test/accuracy=0.498000, test/loss=2.233330, test/num_examples=10000, total_duration=23927.468125, train/accuracy=0.694902, train/loss=1.217258, validation/accuracy=0.621300, validation/loss=1.570193, validation/num_examples=50000
I0302 18:35:26.080863 139758017697536 logging_writer.py:48] [50400] global_step=50400, grad_norm=1.2348867654800415, loss=3.693462610244751
I0302 18:36:11.209406 139758009304832 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.3072365522384644, loss=2.4358971118927
I0302 18:36:56.280795 139758017697536 logging_writer.py:48] [50600] global_step=50600, grad_norm=1.0474244356155396, loss=3.3271028995513916
I0302 18:37:41.405281 139758009304832 logging_writer.py:48] [50700] global_step=50700, grad_norm=1.2796144485473633, loss=2.377180814743042
I0302 18:38:26.050443 139758017697536 logging_writer.py:48] [50800] global_step=50800, grad_norm=1.2038520574569702, loss=2.6765809059143066
I0302 18:39:10.695263 139758009304832 logging_writer.py:48] [50900] global_step=50900, grad_norm=1.2669583559036255, loss=2.447554349899292
I0302 18:39:55.445212 139758017697536 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.178175926208496, loss=2.4747061729431152
I0302 18:40:40.214244 139758009304832 logging_writer.py:48] [51100] global_step=51100, grad_norm=1.3367191553115845, loss=2.4892382621765137
I0302 18:41:25.156003 139758017697536 logging_writer.py:48] [51200] global_step=51200, grad_norm=1.348716139793396, loss=2.517077922821045
I0302 18:41:47.526844 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:41:58.363993 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:42:19.586414 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:42:21.222154 139953291118400 submission_runner.py:411] Time since start: 24381.40s, 	Step: 51252, 	{'train/accuracy': 0.6680468320846558, 'train/loss': 1.355788230895996, 'validation/accuracy': 0.6198599934577942, 'validation/loss': 1.5720373392105103, 'validation/num_examples': 50000, 'test/accuracy': 0.49480003118515015, 'test/loss': 2.2380619049072266, 'test/num_examples': 10000, 'score': 22727.23337483406, 'total_duration': 24381.398369073868, 'accumulated_submission_time': 22727.23337483406, 'accumulated_eval_time': 1648.4719729423523, 'accumulated_logging_time': 3.016878128051758}
I0302 18:42:21.248841 139758009304832 logging_writer.py:48] [51252] accumulated_eval_time=1648.471973, accumulated_logging_time=3.016878, accumulated_submission_time=22727.233375, global_step=51252, preemption_count=0, score=22727.233375, test/accuracy=0.494800, test/loss=2.238062, test/num_examples=10000, total_duration=24381.398369, train/accuracy=0.668047, train/loss=1.355788, validation/accuracy=0.619860, validation/loss=1.572037, validation/num_examples=50000
I0302 18:42:40.631860 139758017697536 logging_writer.py:48] [51300] global_step=51300, grad_norm=1.3128509521484375, loss=2.3365674018859863
I0302 18:43:22.459622 139758009304832 logging_writer.py:48] [51400] global_step=51400, grad_norm=1.344420075416565, loss=2.4354071617126465
I0302 18:44:07.349147 139758017697536 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.1241010427474976, loss=3.235050916671753
I0302 18:44:52.391405 139758009304832 logging_writer.py:48] [51600] global_step=51600, grad_norm=1.3027535676956177, loss=4.902721405029297
I0302 18:45:37.244439 139758017697536 logging_writer.py:48] [51700] global_step=51700, grad_norm=1.2626724243164062, loss=2.5959184169769287
I0302 18:46:22.104426 139758009304832 logging_writer.py:48] [51800] global_step=51800, grad_norm=1.3860034942626953, loss=2.2947916984558105
I0302 18:47:07.089254 139758017697536 logging_writer.py:48] [51900] global_step=51900, grad_norm=1.3510740995407104, loss=5.0884552001953125
I0302 18:47:51.610141 139758009304832 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.3119901418685913, loss=2.447122812271118
I0302 18:48:36.139580 139758017697536 logging_writer.py:48] [52100] global_step=52100, grad_norm=1.1475878953933716, loss=3.312492847442627
I0302 18:49:20.952893 139758009304832 logging_writer.py:48] [52200] global_step=52200, grad_norm=1.4445635080337524, loss=2.382397413253784
I0302 18:49:21.530722 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:49:32.313100 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:49:52.945091 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:49:54.589265 139953291118400 submission_runner.py:411] Time since start: 24834.77s, 	Step: 52203, 	{'train/accuracy': 0.6677343845367432, 'train/loss': 1.3512169122695923, 'validation/accuracy': 0.6184799671173096, 'validation/loss': 1.5838528871536255, 'validation/num_examples': 50000, 'test/accuracy': 0.49560001492500305, 'test/loss': 2.272915840148926, 'test/num_examples': 10000, 'score': 23147.45352268219, 'total_duration': 24834.76548576355, 'accumulated_submission_time': 23147.45352268219, 'accumulated_eval_time': 1681.53049826622, 'accumulated_logging_time': 3.0562021732330322}
I0302 18:49:54.616204 139758017697536 logging_writer.py:48] [52203] accumulated_eval_time=1681.530498, accumulated_logging_time=3.056202, accumulated_submission_time=23147.453523, global_step=52203, preemption_count=0, score=23147.453523, test/accuracy=0.495600, test/loss=2.272916, test/num_examples=10000, total_duration=24834.765486, train/accuracy=0.667734, train/loss=1.351217, validation/accuracy=0.618480, validation/loss=1.583853, validation/num_examples=50000
I0302 18:50:33.392628 139758009304832 logging_writer.py:48] [52300] global_step=52300, grad_norm=1.183247447013855, loss=2.724921464920044
I0302 18:51:17.762043 139758017697536 logging_writer.py:48] [52400] global_step=52400, grad_norm=1.1647217273712158, loss=3.1163086891174316
I0302 18:52:02.601355 139758009304832 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.0911738872528076, loss=4.70481014251709
I0302 18:52:47.651777 139758017697536 logging_writer.py:48] [52600] global_step=52600, grad_norm=1.4044476747512817, loss=2.516977071762085
I0302 18:53:32.158260 139758009304832 logging_writer.py:48] [52700] global_step=52700, grad_norm=1.139486312866211, loss=4.129528045654297
I0302 18:54:17.109171 139758017697536 logging_writer.py:48] [52800] global_step=52800, grad_norm=1.1370964050292969, loss=3.310328483581543
I0302 18:55:02.057502 139758009304832 logging_writer.py:48] [52900] global_step=52900, grad_norm=1.2019799947738647, loss=2.3891069889068604
I0302 18:55:46.547125 139758017697536 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.1888636350631714, loss=2.897639751434326
I0302 18:56:31.327566 139758009304832 logging_writer.py:48] [53100] global_step=53100, grad_norm=1.1681820154190063, loss=3.3571932315826416
I0302 18:56:54.857132 139953291118400 spec.py:321] Evaluating on the training split.
I0302 18:57:06.048391 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 18:57:24.326792 139953291118400 spec.py:349] Evaluating on the test split.
I0302 18:57:25.986957 139953291118400 submission_runner.py:411] Time since start: 25286.16s, 	Step: 53154, 	{'train/accuracy': 0.6862499713897705, 'train/loss': 1.2557148933410645, 'validation/accuracy': 0.6257599592208862, 'validation/loss': 1.5392677783966064, 'validation/num_examples': 50000, 'test/accuracy': 0.5009000301361084, 'test/loss': 2.195390224456787, 'test/num_examples': 10000, 'score': 23567.636283397675, 'total_duration': 25286.163171052933, 'accumulated_submission_time': 23567.636283397675, 'accumulated_eval_time': 1712.6602900028229, 'accumulated_logging_time': 3.0928637981414795}
I0302 18:57:26.016580 139758017697536 logging_writer.py:48] [53154] accumulated_eval_time=1712.660290, accumulated_logging_time=3.092864, accumulated_submission_time=23567.636283, global_step=53154, preemption_count=0, score=23567.636283, test/accuracy=0.500900, test/loss=2.195390, test/num_examples=10000, total_duration=25286.163171, train/accuracy=0.686250, train/loss=1.255715, validation/accuracy=0.625760, validation/loss=1.539268, validation/num_examples=50000
I0302 18:57:44.606519 139758009304832 logging_writer.py:48] [53200] global_step=53200, grad_norm=1.288169503211975, loss=2.3319718837738037
I0302 18:58:27.002446 139758017697536 logging_writer.py:48] [53300] global_step=53300, grad_norm=1.1983239650726318, loss=3.244250774383545
I0302 18:59:11.984050 139758009304832 logging_writer.py:48] [53400] global_step=53400, grad_norm=1.2451149225234985, loss=3.9262747764587402
I0302 18:59:57.148030 139758017697536 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.1401726007461548, loss=2.804511070251465
I0302 19:00:42.147645 139758009304832 logging_writer.py:48] [53600] global_step=53600, grad_norm=1.212381362915039, loss=4.793656349182129
I0302 19:01:27.063673 139758017697536 logging_writer.py:48] [53700] global_step=53700, grad_norm=1.165941834449768, loss=3.5727717876434326
I0302 19:02:12.468711 139758009304832 logging_writer.py:48] [53800] global_step=53800, grad_norm=1.2091902494430542, loss=2.3248233795166016
I0302 19:02:57.001202 139758017697536 logging_writer.py:48] [53900] global_step=53900, grad_norm=1.1432278156280518, loss=4.986610412597656
I0302 19:03:41.822542 139758009304832 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.1133099794387817, loss=4.43756628036499
I0302 19:04:26.394175 139758017697536 logging_writer.py:48] [54100] global_step=54100, grad_norm=1.1186423301696777, loss=3.724513530731201
I0302 19:04:26.406294 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:04:37.519594 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:04:54.377854 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:04:56.012923 139953291118400 submission_runner.py:411] Time since start: 25736.19s, 	Step: 54101, 	{'train/accuracy': 0.6750195026397705, 'train/loss': 1.320992112159729, 'validation/accuracy': 0.62527996301651, 'validation/loss': 1.5474814176559448, 'validation/num_examples': 50000, 'test/accuracy': 0.5051000118255615, 'test/loss': 2.1968486309051514, 'test/num_examples': 10000, 'score': 23987.96748137474, 'total_duration': 25736.189141988754, 'accumulated_submission_time': 23987.96748137474, 'accumulated_eval_time': 1742.2668850421906, 'accumulated_logging_time': 3.1326940059661865}
I0302 19:04:56.043742 139758009304832 logging_writer.py:48] [54101] accumulated_eval_time=1742.266885, accumulated_logging_time=3.132694, accumulated_submission_time=23987.967481, global_step=54101, preemption_count=0, score=23987.967481, test/accuracy=0.505100, test/loss=2.196849, test/num_examples=10000, total_duration=25736.189142, train/accuracy=0.675020, train/loss=1.320992, validation/accuracy=0.625280, validation/loss=1.547481, validation/num_examples=50000
I0302 19:05:37.173199 139758017697536 logging_writer.py:48] [54200] global_step=54200, grad_norm=1.1983585357666016, loss=2.7653894424438477
I0302 19:06:21.973177 139758009304832 logging_writer.py:48] [54300] global_step=54300, grad_norm=1.3698941469192505, loss=2.4521942138671875
I0302 19:07:06.804965 139758017697536 logging_writer.py:48] [54400] global_step=54400, grad_norm=1.3317068815231323, loss=2.677152156829834
I0302 19:07:51.176938 139758009304832 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.2340643405914307, loss=2.5141234397888184
I0302 19:08:35.753295 139758017697536 logging_writer.py:48] [54600] global_step=54600, grad_norm=1.0708450078964233, loss=2.9399750232696533
I0302 19:09:20.507259 139758009304832 logging_writer.py:48] [54700] global_step=54700, grad_norm=1.1841936111450195, loss=2.892385244369507
I0302 19:10:05.437694 139758017697536 logging_writer.py:48] [54800] global_step=54800, grad_norm=1.297484040260315, loss=2.416327953338623
I0302 19:10:50.022281 139758009304832 logging_writer.py:48] [54900] global_step=54900, grad_norm=1.1874806880950928, loss=5.0136189460754395
I0302 19:11:34.830332 139758017697536 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.3080451488494873, loss=2.3616209030151367
I0302 19:11:56.248862 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:12:07.316951 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:12:27.667560 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:12:29.309615 139953291118400 submission_runner.py:411] Time since start: 26189.49s, 	Step: 55049, 	{'train/accuracy': 0.6699999570846558, 'train/loss': 1.3624234199523926, 'validation/accuracy': 0.6233199834823608, 'validation/loss': 1.5818876028060913, 'validation/num_examples': 50000, 'test/accuracy': 0.49790000915527344, 'test/loss': 2.2316365242004395, 'test/num_examples': 10000, 'score': 24408.114142656326, 'total_duration': 26189.48584985733, 'accumulated_submission_time': 24408.114142656326, 'accumulated_eval_time': 1775.3276269435883, 'accumulated_logging_time': 3.173816442489624}
I0302 19:12:29.333453 139758009304832 logging_writer.py:48] [55049] accumulated_eval_time=1775.327627, accumulated_logging_time=3.173816, accumulated_submission_time=24408.114143, global_step=55049, preemption_count=0, score=24408.114143, test/accuracy=0.497900, test/loss=2.231637, test/num_examples=10000, total_duration=26189.485850, train/accuracy=0.670000, train/loss=1.362423, validation/accuracy=0.623320, validation/loss=1.581888, validation/num_examples=50000
I0302 19:12:49.884784 139758017697536 logging_writer.py:48] [55100] global_step=55100, grad_norm=1.3104444742202759, loss=2.6035284996032715
I0302 19:13:32.031076 139758009304832 logging_writer.py:48] [55200] global_step=55200, grad_norm=1.1391268968582153, loss=3.1447644233703613
I0302 19:14:16.948821 139758017697536 logging_writer.py:48] [55300] global_step=55300, grad_norm=1.261980414390564, loss=2.3741140365600586
I0302 19:15:01.902745 139758009304832 logging_writer.py:48] [55400] global_step=55400, grad_norm=1.2814109325408936, loss=2.24018931388855
I0302 19:15:46.779760 139758017697536 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.300831913948059, loss=2.359102487564087
I0302 19:16:31.562606 139758009304832 logging_writer.py:48] [55600] global_step=55600, grad_norm=1.291029453277588, loss=2.2694082260131836
I0302 19:17:16.569096 139758017697536 logging_writer.py:48] [55700] global_step=55700, grad_norm=1.1212979555130005, loss=3.2038421630859375
I0302 19:18:01.289278 139758009304832 logging_writer.py:48] [55800] global_step=55800, grad_norm=1.2509632110595703, loss=2.3808135986328125
I0302 19:18:45.992797 139758017697536 logging_writer.py:48] [55900] global_step=55900, grad_norm=1.3746894598007202, loss=2.4023592472076416
I0302 19:19:29.627218 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:19:40.524615 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:19:59.510997 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:20:01.145183 139953291118400 submission_runner.py:411] Time since start: 26641.32s, 	Step: 55999, 	{'train/accuracy': 0.6770898103713989, 'train/loss': 1.3100413084030151, 'validation/accuracy': 0.6246399879455566, 'validation/loss': 1.567784070968628, 'validation/num_examples': 50000, 'test/accuracy': 0.49980002641677856, 'test/loss': 2.230363368988037, 'test/num_examples': 10000, 'score': 24828.346135139465, 'total_duration': 26641.321397066116, 'accumulated_submission_time': 24828.346135139465, 'accumulated_eval_time': 1806.845562696457, 'accumulated_logging_time': 3.211068630218506}
I0302 19:20:01.177571 139758009304832 logging_writer.py:48] [55999] accumulated_eval_time=1806.845563, accumulated_logging_time=3.211069, accumulated_submission_time=24828.346135, global_step=55999, preemption_count=0, score=24828.346135, test/accuracy=0.499800, test/loss=2.230363, test/num_examples=10000, total_duration=26641.321397, train/accuracy=0.677090, train/loss=1.310041, validation/accuracy=0.624640, validation/loss=1.567784, validation/num_examples=50000
I0302 19:20:02.009011 139758017697536 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.3001210689544678, loss=2.287632942199707
I0302 19:20:43.043058 139758009304832 logging_writer.py:48] [56100] global_step=56100, grad_norm=1.3727086782455444, loss=2.2977981567382812
I0302 19:21:27.884177 139758017697536 logging_writer.py:48] [56200] global_step=56200, grad_norm=1.2299401760101318, loss=2.427764415740967
I0302 19:22:13.076733 139758009304832 logging_writer.py:48] [56300] global_step=56300, grad_norm=1.3655353784561157, loss=2.420428991317749
I0302 19:22:58.211702 139758017697536 logging_writer.py:48] [56400] global_step=56400, grad_norm=1.090113639831543, loss=3.4711556434631348
I0302 19:23:43.240016 139758009304832 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.321677803993225, loss=2.5477840900421143
I0302 19:24:28.088941 139758017697536 logging_writer.py:48] [56600] global_step=56600, grad_norm=1.214712142944336, loss=2.611337423324585
I0302 19:25:12.787474 139758009304832 logging_writer.py:48] [56700] global_step=56700, grad_norm=1.143375039100647, loss=4.8333868980407715
I0302 19:25:57.688889 139758017697536 logging_writer.py:48] [56800] global_step=56800, grad_norm=1.0952798128128052, loss=4.483205318450928
I0302 19:26:42.935300 139758009304832 logging_writer.py:48] [56900] global_step=56900, grad_norm=1.223818302154541, loss=2.4321606159210205
I0302 19:27:01.359349 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:27:12.646559 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:27:30.818667 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:27:32.454904 139953291118400 submission_runner.py:411] Time since start: 27092.63s, 	Step: 56943, 	{'train/accuracy': 0.6991015672683716, 'train/loss': 1.2092502117156982, 'validation/accuracy': 0.6245599985122681, 'validation/loss': 1.5463355779647827, 'validation/num_examples': 50000, 'test/accuracy': 0.5057000517845154, 'test/loss': 2.21742582321167, 'test/num_examples': 10000, 'score': 25248.46753191948, 'total_duration': 27092.631110429764, 'accumulated_submission_time': 25248.46753191948, 'accumulated_eval_time': 1837.941088438034, 'accumulated_logging_time': 3.255908966064453}
I0302 19:27:32.486359 139758017697536 logging_writer.py:48] [56943] accumulated_eval_time=1837.941088, accumulated_logging_time=3.255909, accumulated_submission_time=25248.467532, global_step=56943, preemption_count=0, score=25248.467532, test/accuracy=0.505700, test/loss=2.217426, test/num_examples=10000, total_duration=27092.631110, train/accuracy=0.699102, train/loss=1.209250, validation/accuracy=0.624560, validation/loss=1.546336, validation/num_examples=50000
I0302 19:27:55.521168 139758009304832 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.2857694625854492, loss=2.36333966255188
I0302 19:28:39.086762 139758017697536 logging_writer.py:48] [57100] global_step=57100, grad_norm=1.065506935119629, loss=3.4935526847839355
I0302 19:29:23.800000 139758009304832 logging_writer.py:48] [57200] global_step=57200, grad_norm=1.217073678970337, loss=2.4626352787017822
I0302 19:30:08.946267 139758017697536 logging_writer.py:48] [57300] global_step=57300, grad_norm=1.1980925798416138, loss=4.834564208984375
I0302 19:30:53.763543 139758009304832 logging_writer.py:48] [57400] global_step=57400, grad_norm=1.2120338678359985, loss=2.2662441730499268
I0302 19:31:38.735805 139758017697536 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.0692534446716309, loss=3.8697397708892822
I0302 19:32:23.901709 139758009304832 logging_writer.py:48] [57600] global_step=57600, grad_norm=1.122824788093567, loss=2.9102582931518555
I0302 19:33:08.583408 139758017697536 logging_writer.py:48] [57700] global_step=57700, grad_norm=1.3253161907196045, loss=2.2651402950286865
I0302 19:33:53.269386 139758009304832 logging_writer.py:48] [57800] global_step=57800, grad_norm=1.3245840072631836, loss=2.3672890663146973
I0302 19:34:32.523106 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:34:43.278841 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:35:01.162639 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:35:02.808855 139953291118400 submission_runner.py:411] Time since start: 27542.99s, 	Step: 57889, 	{'train/accuracy': 0.6811327934265137, 'train/loss': 1.2940772771835327, 'validation/accuracy': 0.6329799890518188, 'validation/loss': 1.5235350131988525, 'validation/num_examples': 50000, 'test/accuracy': 0.506600022315979, 'test/loss': 2.182492971420288, 'test/num_examples': 10000, 'score': 25668.446413993835, 'total_duration': 27542.98506808281, 'accumulated_submission_time': 25668.446413993835, 'accumulated_eval_time': 1868.226809501648, 'accumulated_logging_time': 3.297309160232544}
I0302 19:35:02.841370 139758017697536 logging_writer.py:48] [57889] accumulated_eval_time=1868.226810, accumulated_logging_time=3.297309, accumulated_submission_time=25668.446414, global_step=57889, preemption_count=0, score=25668.446414, test/accuracy=0.506600, test/loss=2.182493, test/num_examples=10000, total_duration=27542.985068, train/accuracy=0.681133, train/loss=1.294077, validation/accuracy=0.632980, validation/loss=1.523535, validation/num_examples=50000
I0302 19:35:07.597609 139758009304832 logging_writer.py:48] [57900] global_step=57900, grad_norm=1.2827457189559937, loss=2.265564203262329
I0302 19:35:48.858254 139758017697536 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.2248367071151733, loss=2.8809022903442383
I0302 19:36:34.044001 139758009304832 logging_writer.py:48] [58100] global_step=58100, grad_norm=1.211843490600586, loss=2.3485493659973145
I0302 19:37:18.847594 139758017697536 logging_writer.py:48] [58200] global_step=58200, grad_norm=1.147134780883789, loss=2.8561081886291504
I0302 19:38:03.782728 139758009304832 logging_writer.py:48] [58300] global_step=58300, grad_norm=1.3161262273788452, loss=2.4292454719543457
I0302 19:38:48.288543 139758017697536 logging_writer.py:48] [58400] global_step=58400, grad_norm=1.410470962524414, loss=2.290347099304199
I0302 19:39:33.306890 139758009304832 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.1578582525253296, loss=3.2388405799865723
I0302 19:40:18.317430 139758017697536 logging_writer.py:48] [58600] global_step=58600, grad_norm=1.1890605688095093, loss=2.753840684890747
I0302 19:41:03.077309 139758009304832 logging_writer.py:48] [58700] global_step=58700, grad_norm=1.3251440525054932, loss=2.3706350326538086
I0302 19:41:48.110243 139758017697536 logging_writer.py:48] [58800] global_step=58800, grad_norm=1.1500605344772339, loss=2.49692440032959
I0302 19:42:03.109960 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:42:13.941774 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:42:34.121066 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:42:35.766054 139953291118400 submission_runner.py:411] Time since start: 27995.94s, 	Step: 58835, 	{'train/accuracy': 0.68115234375, 'train/loss': 1.3139863014221191, 'validation/accuracy': 0.6299600005149841, 'validation/loss': 1.553807258605957, 'validation/num_examples': 50000, 'test/accuracy': 0.5116000175476074, 'test/loss': 2.191758632659912, 'test/num_examples': 10000, 'score': 26088.65665245056, 'total_duration': 27995.94226884842, 'accumulated_submission_time': 26088.65665245056, 'accumulated_eval_time': 1900.8828961849213, 'accumulated_logging_time': 3.3394837379455566}
I0302 19:42:35.794512 139758009304832 logging_writer.py:48] [58835] accumulated_eval_time=1900.882896, accumulated_logging_time=3.339484, accumulated_submission_time=26088.656652, global_step=58835, preemption_count=0, score=26088.656652, test/accuracy=0.511600, test/loss=2.191759, test/num_examples=10000, total_duration=27995.942269, train/accuracy=0.681152, train/loss=1.313986, validation/accuracy=0.629960, validation/loss=1.553807, validation/num_examples=50000
I0302 19:43:01.911920 139758017697536 logging_writer.py:48] [58900] global_step=58900, grad_norm=1.3054450750350952, loss=2.396188974380493
I0302 19:43:45.246880 139758009304832 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.1787338256835938, loss=2.2545247077941895
I0302 19:44:30.143046 139758017697536 logging_writer.py:48] [59100] global_step=59100, grad_norm=1.0445517301559448, loss=4.049365043640137
I0302 19:45:15.189183 139758009304832 logging_writer.py:48] [59200] global_step=59200, grad_norm=1.2160638570785522, loss=2.2586188316345215
I0302 19:45:59.907579 139758017697536 logging_writer.py:48] [59300] global_step=59300, grad_norm=1.1562199592590332, loss=3.556952953338623
I0302 19:46:44.849074 139758009304832 logging_writer.py:48] [59400] global_step=59400, grad_norm=1.4113929271697998, loss=2.2903475761413574
I0302 19:47:29.831709 139758017697536 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.30055570602417, loss=2.3253419399261475
I0302 19:48:15.049552 139758009304832 logging_writer.py:48] [59600] global_step=59600, grad_norm=1.2822190523147583, loss=2.257093667984009
I0302 19:48:59.846724 139758017697536 logging_writer.py:48] [59700] global_step=59700, grad_norm=1.1401118040084839, loss=3.5940141677856445
I0302 19:49:35.954977 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:49:46.754896 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:50:04.089455 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:50:05.727412 139953291118400 submission_runner.py:411] Time since start: 28445.90s, 	Step: 59782, 	{'train/accuracy': 0.6947851181030273, 'train/loss': 1.258604884147644, 'validation/accuracy': 0.630899965763092, 'validation/loss': 1.5560885667800903, 'validation/num_examples': 50000, 'test/accuracy': 0.5057000517845154, 'test/loss': 2.211388111114502, 'test/num_examples': 10000, 'score': 26508.756959676743, 'total_duration': 28445.90362930298, 'accumulated_submission_time': 26508.756959676743, 'accumulated_eval_time': 1930.6553165912628, 'accumulated_logging_time': 3.3801913261413574}
I0302 19:50:05.759155 139758009304832 logging_writer.py:48] [59782] accumulated_eval_time=1930.655317, accumulated_logging_time=3.380191, accumulated_submission_time=26508.756960, global_step=59782, preemption_count=0, score=26508.756960, test/accuracy=0.505700, test/loss=2.211388, test/num_examples=10000, total_duration=28445.903629, train/accuracy=0.694785, train/loss=1.258605, validation/accuracy=0.630900, validation/loss=1.556089, validation/num_examples=50000
I0302 19:50:13.298834 139758017697536 logging_writer.py:48] [59800] global_step=59800, grad_norm=1.3334617614746094, loss=2.35211443901062
I0302 19:50:54.944070 139758009304832 logging_writer.py:48] [59900] global_step=59900, grad_norm=1.3122214078903198, loss=4.916308879852295
I0302 19:51:39.862053 139758017697536 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.4080839157104492, loss=2.349701404571533
I0302 19:52:36.930772 139758009304832 logging_writer.py:48] [60100] global_step=60100, grad_norm=1.2644743919372559, loss=2.430610418319702
I0302 19:53:27.535572 139758017697536 logging_writer.py:48] [60200] global_step=60200, grad_norm=1.3511481285095215, loss=2.5179665088653564
I0302 19:54:12.164462 139758009304832 logging_writer.py:48] [60300] global_step=60300, grad_norm=1.2212450504302979, loss=3.0469915866851807
I0302 19:54:56.961135 139758017697536 logging_writer.py:48] [60400] global_step=60400, grad_norm=1.2266391515731812, loss=2.16796875
I0302 19:55:41.830480 139758009304832 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.3452427387237549, loss=2.2823193073272705
I0302 19:56:26.999951 139758017697536 logging_writer.py:48] [60600] global_step=60600, grad_norm=1.1617910861968994, loss=4.381491184234619
I0302 19:57:06.100841 139953291118400 spec.py:321] Evaluating on the training split.
I0302 19:57:16.822674 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 19:57:36.876905 139953291118400 spec.py:349] Evaluating on the test split.
I0302 19:57:38.517407 139953291118400 submission_runner.py:411] Time since start: 28898.69s, 	Step: 60689, 	{'train/accuracy': 0.6812695264816284, 'train/loss': 1.2990782260894775, 'validation/accuracy': 0.6337000131607056, 'validation/loss': 1.513222098350525, 'validation/num_examples': 50000, 'test/accuracy': 0.5031999945640564, 'test/loss': 2.1872010231018066, 'test/num_examples': 10000, 'score': 26929.041621923447, 'total_duration': 28898.69361257553, 'accumulated_submission_time': 26929.041621923447, 'accumulated_eval_time': 1963.0718441009521, 'accumulated_logging_time': 3.4235599040985107}
I0302 19:57:38.546417 139758009304832 logging_writer.py:48] [60689] accumulated_eval_time=1963.071844, accumulated_logging_time=3.423560, accumulated_submission_time=26929.041622, global_step=60689, preemption_count=0, score=26929.041622, test/accuracy=0.503200, test/loss=2.187201, test/num_examples=10000, total_duration=28898.693613, train/accuracy=0.681270, train/loss=1.299078, validation/accuracy=0.633700, validation/loss=1.513222, validation/num_examples=50000
I0302 19:57:43.302864 139758017697536 logging_writer.py:48] [60700] global_step=60700, grad_norm=1.208633542060852, loss=4.17180061340332
I0302 19:58:23.399303 139758009304832 logging_writer.py:48] [60800] global_step=60800, grad_norm=1.1798152923583984, loss=2.57289981842041
I0302 19:59:08.183099 139758017697536 logging_writer.py:48] [60900] global_step=60900, grad_norm=1.2496459484100342, loss=2.2408766746520996
I0302 19:59:53.009843 139758009304832 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.2889763116836548, loss=2.234344959259033
I0302 20:00:38.109709 139758017697536 logging_writer.py:48] [61100] global_step=61100, grad_norm=1.3213660717010498, loss=2.268730401992798
I0302 20:01:22.679973 139758009304832 logging_writer.py:48] [61200] global_step=61200, grad_norm=1.2850263118743896, loss=4.515422821044922
I0302 20:02:07.669977 139758017697536 logging_writer.py:48] [61300] global_step=61300, grad_norm=1.2455514669418335, loss=4.575287342071533
I0302 20:02:52.453846 139758009304832 logging_writer.py:48] [61400] global_step=61400, grad_norm=1.301038146018982, loss=2.2396843433380127
I0302 20:03:37.214296 139758017697536 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.195863127708435, loss=2.735365629196167
I0302 20:04:22.005630 139758009304832 logging_writer.py:48] [61600] global_step=61600, grad_norm=1.0992969274520874, loss=2.9866762161254883
I0302 20:04:38.651424 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:04:49.396396 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:05:09.060117 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:05:10.695466 139953291118400 submission_runner.py:411] Time since start: 29350.87s, 	Step: 61639, 	{'train/accuracy': 0.6890038847923279, 'train/loss': 1.2490397691726685, 'validation/accuracy': 0.6389399766921997, 'validation/loss': 1.4967432022094727, 'validation/num_examples': 50000, 'test/accuracy': 0.5178000330924988, 'test/loss': 2.1470038890838623, 'test/num_examples': 10000, 'score': 27349.087817907333, 'total_duration': 29350.871685266495, 'accumulated_submission_time': 27349.087817907333, 'accumulated_eval_time': 1995.115867614746, 'accumulated_logging_time': 3.4631595611572266}
I0302 20:05:10.726772 139758017697536 logging_writer.py:48] [61639] accumulated_eval_time=1995.115868, accumulated_logging_time=3.463160, accumulated_submission_time=27349.087818, global_step=61639, preemption_count=0, score=27349.087818, test/accuracy=0.517800, test/loss=2.147004, test/num_examples=10000, total_duration=29350.871685, train/accuracy=0.689004, train/loss=1.249040, validation/accuracy=0.638940, validation/loss=1.496743, validation/num_examples=50000
I0302 20:05:35.245690 139758009304832 logging_writer.py:48] [61700] global_step=61700, grad_norm=1.3325883150100708, loss=2.287102699279785
I0302 20:06:18.490338 139758017697536 logging_writer.py:48] [61800] global_step=61800, grad_norm=1.1947519779205322, loss=4.551887512207031
I0302 20:07:03.414315 139758009304832 logging_writer.py:48] [61900] global_step=61900, grad_norm=1.1693518161773682, loss=4.666563510894775
I0302 20:07:48.510251 139758017697536 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.311384677886963, loss=2.502551555633545
I0302 20:08:33.276312 139758009304832 logging_writer.py:48] [62100] global_step=62100, grad_norm=1.227063536643982, loss=4.830178737640381
I0302 20:09:18.364907 139758017697536 logging_writer.py:48] [62200] global_step=62200, grad_norm=1.309415340423584, loss=2.5192198753356934
I0302 20:10:03.221542 139758009304832 logging_writer.py:48] [62300] global_step=62300, grad_norm=1.1809953451156616, loss=3.5857250690460205
I0302 20:10:47.853524 139758017697536 logging_writer.py:48] [62400] global_step=62400, grad_norm=1.4547486305236816, loss=2.4707467555999756
I0302 20:11:32.860635 139758009304832 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.3697357177734375, loss=2.1220619678497314
I0302 20:12:10.921036 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:12:22.224196 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:12:40.568775 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:12:42.209770 139953291118400 submission_runner.py:411] Time since start: 29802.39s, 	Step: 62585, 	{'train/accuracy': 0.6906836032867432, 'train/loss': 1.238747477531433, 'validation/accuracy': 0.6342399716377258, 'validation/loss': 1.5011688470840454, 'validation/num_examples': 50000, 'test/accuracy': 0.5063000321388245, 'test/loss': 2.162984848022461, 'test/num_examples': 10000, 'score': 27769.222217321396, 'total_duration': 29802.385987520218, 'accumulated_submission_time': 27769.222217321396, 'accumulated_eval_time': 2026.4046063423157, 'accumulated_logging_time': 3.505953550338745}
I0302 20:12:42.238779 139758017697536 logging_writer.py:48] [62585] accumulated_eval_time=2026.404606, accumulated_logging_time=3.505954, accumulated_submission_time=27769.222217, global_step=62585, preemption_count=0, score=27769.222217, test/accuracy=0.506300, test/loss=2.162985, test/num_examples=10000, total_duration=29802.385988, train/accuracy=0.690684, train/loss=1.238747, validation/accuracy=0.634240, validation/loss=1.501169, validation/num_examples=50000
I0302 20:12:48.599117 139758009304832 logging_writer.py:48] [62600] global_step=62600, grad_norm=1.2166470289230347, loss=3.8406999111175537
I0302 20:13:30.229193 139758017697536 logging_writer.py:48] [62700] global_step=62700, grad_norm=1.3049440383911133, loss=2.2643346786499023
I0302 20:14:15.093992 139758009304832 logging_writer.py:48] [62800] global_step=62800, grad_norm=1.0838981866836548, loss=4.814873695373535
I0302 20:14:59.764687 139758017697536 logging_writer.py:48] [62900] global_step=62900, grad_norm=1.0529168844223022, loss=4.631993293762207
I0302 20:15:44.806511 139758009304832 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.2780441045761108, loss=4.237096309661865
I0302 20:16:29.568201 139758017697536 logging_writer.py:48] [63100] global_step=63100, grad_norm=1.1858159303665161, loss=3.2206363677978516
I0302 20:17:14.349700 139758009304832 logging_writer.py:48] [63200] global_step=63200, grad_norm=1.1867378950119019, loss=2.3854427337646484
I0302 20:17:59.139775 139758017697536 logging_writer.py:48] [63300] global_step=63300, grad_norm=1.2009196281433105, loss=2.4268910884857178
I0302 20:18:43.885695 139758009304832 logging_writer.py:48] [63400] global_step=63400, grad_norm=1.1840593814849854, loss=2.896289348602295
I0302 20:19:28.636938 139758017697536 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.3220398426055908, loss=2.2719650268554688
I0302 20:19:42.598297 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:19:53.884487 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:20:11.882353 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:20:13.524167 139953291118400 submission_runner.py:411] Time since start: 30253.70s, 	Step: 63533, 	{'train/accuracy': 0.71107417345047, 'train/loss': 1.1600855588912964, 'validation/accuracy': 0.6335799694061279, 'validation/loss': 1.5163129568099976, 'validation/num_examples': 50000, 'test/accuracy': 0.508400022983551, 'test/loss': 2.1880664825439453, 'test/num_examples': 10000, 'score': 28189.522920131683, 'total_duration': 30253.700383901596, 'accumulated_submission_time': 28189.522920131683, 'accumulated_eval_time': 2057.330437898636, 'accumulated_logging_time': 3.5457215309143066}
I0302 20:20:13.556752 139758009304832 logging_writer.py:48] [63533] accumulated_eval_time=2057.330438, accumulated_logging_time=3.545722, accumulated_submission_time=28189.522920, global_step=63533, preemption_count=0, score=28189.522920, test/accuracy=0.508400, test/loss=2.188066, test/num_examples=10000, total_duration=30253.700384, train/accuracy=0.711074, train/loss=1.160086, validation/accuracy=0.633580, validation/loss=1.516313, validation/num_examples=50000
I0302 20:20:40.455825 139758017697536 logging_writer.py:48] [63600] global_step=63600, grad_norm=1.3204790353775024, loss=2.241755247116089
I0302 20:21:24.884718 139758009304832 logging_writer.py:48] [63700] global_step=63700, grad_norm=1.2937003374099731, loss=2.290550708770752
I0302 20:22:10.014409 139758017697536 logging_writer.py:48] [63800] global_step=63800, grad_norm=1.423439860343933, loss=2.2827446460723877
I0302 20:22:54.716824 139758009304832 logging_writer.py:48] [63900] global_step=63900, grad_norm=1.1678258180618286, loss=2.865717887878418
I0302 20:23:39.675161 139758017697536 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.268453598022461, loss=2.200644016265869
I0302 20:24:24.419777 139758009304832 logging_writer.py:48] [64100] global_step=64100, grad_norm=1.4743666648864746, loss=2.2342357635498047
I0302 20:25:09.264129 139758017697536 logging_writer.py:48] [64200] global_step=64200, grad_norm=1.1985090970993042, loss=2.795806407928467
I0302 20:25:53.956805 139758009304832 logging_writer.py:48] [64300] global_step=64300, grad_norm=1.4169572591781616, loss=2.3818602561950684
I0302 20:26:38.942025 139758017697536 logging_writer.py:48] [64400] global_step=64400, grad_norm=1.072482705116272, loss=3.007068395614624
I0302 20:27:13.883898 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:27:24.648752 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:27:42.557399 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:27:44.199041 139953291118400 submission_runner.py:411] Time since start: 30704.38s, 	Step: 64480, 	{'train/accuracy': 0.690625011920929, 'train/loss': 1.2341567277908325, 'validation/accuracy': 0.6427800059318542, 'validation/loss': 1.4698628187179565, 'validation/num_examples': 50000, 'test/accuracy': 0.5195000171661377, 'test/loss': 2.1230661869049072, 'test/num_examples': 10000, 'score': 28609.791985034943, 'total_duration': 30704.375244617462, 'accumulated_submission_time': 28609.791985034943, 'accumulated_eval_time': 2087.645537853241, 'accumulated_logging_time': 3.588677167892456}
I0302 20:27:44.229291 139758009304832 logging_writer.py:48] [64480] accumulated_eval_time=2087.645538, accumulated_logging_time=3.588677, accumulated_submission_time=28609.791985, global_step=64480, preemption_count=0, score=28609.791985, test/accuracy=0.519500, test/loss=2.123066, test/num_examples=10000, total_duration=30704.375245, train/accuracy=0.690625, train/loss=1.234157, validation/accuracy=0.642780, validation/loss=1.469863, validation/num_examples=50000
I0302 20:27:52.548638 139758017697536 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.1397666931152344, loss=3.5764403343200684
I0302 20:28:34.255819 139758009304832 logging_writer.py:48] [64600] global_step=64600, grad_norm=1.3232412338256836, loss=2.214672088623047
I0302 20:29:18.946256 139758017697536 logging_writer.py:48] [64700] global_step=64700, grad_norm=1.2488961219787598, loss=2.437840223312378
I0302 20:30:03.761449 139758009304832 logging_writer.py:48] [64800] global_step=64800, grad_norm=1.2665222883224487, loss=2.3019845485687256
I0302 20:30:48.507833 139758017697536 logging_writer.py:48] [64900] global_step=64900, grad_norm=1.0963917970657349, loss=3.944474458694458
I0302 20:31:33.178371 139758009304832 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.0666006803512573, loss=4.540606498718262
I0302 20:32:18.175384 139758017697536 logging_writer.py:48] [65100] global_step=65100, grad_norm=1.1623822450637817, loss=3.863645553588867
I0302 20:33:02.867951 139758009304832 logging_writer.py:48] [65200] global_step=65200, grad_norm=1.3531442880630493, loss=4.290343284606934
I0302 20:33:47.640920 139758017697536 logging_writer.py:48] [65300] global_step=65300, grad_norm=1.4315770864486694, loss=2.299893856048584
I0302 20:34:32.264803 139758009304832 logging_writer.py:48] [65400] global_step=65400, grad_norm=1.3591961860656738, loss=2.3781139850616455
I0302 20:34:44.503139 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:34:55.359456 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:35:16.967607 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:35:18.602205 139953291118400 submission_runner.py:411] Time since start: 31158.78s, 	Step: 65429, 	{'train/accuracy': 0.6970507502555847, 'train/loss': 1.2187137603759766, 'validation/accuracy': 0.642520010471344, 'validation/loss': 1.4679756164550781, 'validation/num_examples': 50000, 'test/accuracy': 0.5190000534057617, 'test/loss': 2.1363329887390137, 'test/num_examples': 10000, 'score': 29030.007290124893, 'total_duration': 31158.778439998627, 'accumulated_submission_time': 29030.007290124893, 'accumulated_eval_time': 2121.744611263275, 'accumulated_logging_time': 3.628873109817505}
I0302 20:35:18.633753 139758017697536 logging_writer.py:48] [65429] accumulated_eval_time=2121.744611, accumulated_logging_time=3.628873, accumulated_submission_time=29030.007290, global_step=65429, preemption_count=0, score=29030.007290, test/accuracy=0.519000, test/loss=2.136333, test/num_examples=10000, total_duration=31158.778440, train/accuracy=0.697051, train/loss=1.218714, validation/accuracy=0.642520, validation/loss=1.467976, validation/num_examples=50000
I0302 20:35:47.073820 139758009304832 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.2615607976913452, loss=2.2100305557250977
I0302 20:36:29.615271 139758017697536 logging_writer.py:48] [65600] global_step=65600, grad_norm=1.1910183429718018, loss=4.802098751068115
I0302 20:37:14.402677 139758009304832 logging_writer.py:48] [65700] global_step=65700, grad_norm=1.2344331741333008, loss=4.043025016784668
I0302 20:37:59.281712 139758017697536 logging_writer.py:48] [65800] global_step=65800, grad_norm=1.3142582178115845, loss=2.15010929107666
I0302 20:38:44.059762 139758009304832 logging_writer.py:48] [65900] global_step=65900, grad_norm=1.1097031831741333, loss=2.8107810020446777
I0302 20:39:28.488456 139758017697536 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.3376424312591553, loss=2.323352098464966
I0302 20:40:13.383503 139758009304832 logging_writer.py:48] [66100] global_step=66100, grad_norm=1.3591370582580566, loss=2.2124738693237305
I0302 20:40:58.104616 139758017697536 logging_writer.py:48] [66200] global_step=66200, grad_norm=1.3145649433135986, loss=2.283883810043335
I0302 20:41:42.931492 139758009304832 logging_writer.py:48] [66300] global_step=66300, grad_norm=1.3425939083099365, loss=2.3676767349243164
I0302 20:42:18.698445 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:42:29.576337 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:42:50.449773 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:42:52.087129 139953291118400 submission_runner.py:411] Time since start: 31612.26s, 	Step: 66381, 	{'train/accuracy': 0.70703125, 'train/loss': 1.1558291912078857, 'validation/accuracy': 0.6475600004196167, 'validation/loss': 1.4485762119293213, 'validation/num_examples': 50000, 'test/accuracy': 0.5151000022888184, 'test/loss': 2.1223251819610596, 'test/num_examples': 10000, 'score': 29450.012192726135, 'total_duration': 31612.26335000992, 'accumulated_submission_time': 29450.012192726135, 'accumulated_eval_time': 2155.1333100795746, 'accumulated_logging_time': 3.671163320541382}
I0302 20:42:52.118691 139758017697536 logging_writer.py:48] [66381] accumulated_eval_time=2155.133310, accumulated_logging_time=3.671163, accumulated_submission_time=29450.012193, global_step=66381, preemption_count=0, score=29450.012193, test/accuracy=0.515100, test/loss=2.122325, test/num_examples=10000, total_duration=31612.263350, train/accuracy=0.707031, train/loss=1.155829, validation/accuracy=0.647560, validation/loss=1.448576, validation/num_examples=50000
I0302 20:43:00.029278 139758009304832 logging_writer.py:48] [66400] global_step=66400, grad_norm=1.1198152303695679, loss=4.858129024505615
I0302 20:43:40.828943 139758017697536 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.191498875617981, loss=2.3377013206481934
I0302 20:44:25.805190 139758009304832 logging_writer.py:48] [66600] global_step=66600, grad_norm=1.239158034324646, loss=3.0828497409820557
I0302 20:45:11.037785 139758017697536 logging_writer.py:48] [66700] global_step=66700, grad_norm=1.1475800275802612, loss=4.858637809753418
I0302 20:45:56.395170 139758009304832 logging_writer.py:48] [66800] global_step=66800, grad_norm=1.2759157419204712, loss=2.5409274101257324
I0302 20:46:41.285420 139758017697536 logging_writer.py:48] [66900] global_step=66900, grad_norm=1.1950575113296509, loss=3.0503339767456055
I0302 20:47:26.273197 139758009304832 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.3468546867370605, loss=2.2824149131774902
I0302 20:48:11.515481 139758017697536 logging_writer.py:48] [67100] global_step=67100, grad_norm=1.633061170578003, loss=2.2981088161468506
I0302 20:48:56.308753 139758009304832 logging_writer.py:48] [67200] global_step=67200, grad_norm=1.4818401336669922, loss=2.330728769302368
I0302 20:49:40.905874 139758017697536 logging_writer.py:48] [67300] global_step=67300, grad_norm=1.5991973876953125, loss=2.586909294128418
I0302 20:49:52.186094 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:50:03.633765 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:50:21.026056 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:50:22.661998 139953291118400 submission_runner.py:411] Time since start: 32062.84s, 	Step: 67327, 	{'train/accuracy': 0.6959765553474426, 'train/loss': 1.256928563117981, 'validation/accuracy': 0.6457599997520447, 'validation/loss': 1.4908559322357178, 'validation/num_examples': 50000, 'test/accuracy': 0.5243000388145447, 'test/loss': 2.134155511856079, 'test/num_examples': 10000, 'score': 29870.019545555115, 'total_duration': 32062.83818912506, 'accumulated_submission_time': 29870.019545555115, 'accumulated_eval_time': 2185.6091549396515, 'accumulated_logging_time': 3.7146735191345215}
I0302 20:50:22.712317 139758009304832 logging_writer.py:48] [67327] accumulated_eval_time=2185.609155, accumulated_logging_time=3.714674, accumulated_submission_time=29870.019546, global_step=67327, preemption_count=0, score=29870.019546, test/accuracy=0.524300, test/loss=2.134156, test/num_examples=10000, total_duration=32062.838189, train/accuracy=0.695977, train/loss=1.256929, validation/accuracy=0.645760, validation/loss=1.490856, validation/num_examples=50000
I0302 20:50:52.385692 139758017697536 logging_writer.py:48] [67400] global_step=67400, grad_norm=1.3001576662063599, loss=2.426879405975342
I0302 20:51:37.220776 139758009304832 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.2081111669540405, loss=2.3384642601013184
I0302 20:52:22.165636 139758017697536 logging_writer.py:48] [67600] global_step=67600, grad_norm=1.3637691736221313, loss=2.2644286155700684
I0302 20:53:06.986607 139758009304832 logging_writer.py:48] [67700] global_step=67700, grad_norm=1.1753299236297607, loss=3.193791627883911
I0302 20:53:51.547549 139758017697536 logging_writer.py:48] [67800] global_step=67800, grad_norm=1.3244479894638062, loss=2.277723789215088
I0302 20:54:36.224579 139758009304832 logging_writer.py:48] [67900] global_step=67900, grad_norm=1.4577687978744507, loss=2.2621212005615234
I0302 20:55:21.160504 139758017697536 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.3687845468521118, loss=2.161015272140503
I0302 20:56:05.967353 139758009304832 logging_writer.py:48] [68100] global_step=68100, grad_norm=1.1778028011322021, loss=4.697936534881592
I0302 20:56:50.607321 139758017697536 logging_writer.py:48] [68200] global_step=68200, grad_norm=1.217415690422058, loss=2.4270424842834473
I0302 20:57:22.741371 139953291118400 spec.py:321] Evaluating on the training split.
I0302 20:57:33.672379 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 20:57:50.723681 139953291118400 spec.py:349] Evaluating on the test split.
I0302 20:57:52.359874 139953291118400 submission_runner.py:411] Time since start: 32512.54s, 	Step: 68273, 	{'train/accuracy': 0.6995898485183716, 'train/loss': 1.2015330791473389, 'validation/accuracy': 0.6462399959564209, 'validation/loss': 1.4489117860794067, 'validation/num_examples': 50000, 'test/accuracy': 0.5218000411987305, 'test/loss': 2.0921084880828857, 'test/num_examples': 10000, 'score': 30289.983651399612, 'total_duration': 32512.536083459854, 'accumulated_submission_time': 30289.983651399612, 'accumulated_eval_time': 2215.2276520729065, 'accumulated_logging_time': 3.780029296875}
I0302 20:57:52.394591 139758009304832 logging_writer.py:48] [68273] accumulated_eval_time=2215.227652, accumulated_logging_time=3.780029, accumulated_submission_time=30289.983651, global_step=68273, preemption_count=0, score=30289.983651, test/accuracy=0.521800, test/loss=2.092108, test/num_examples=10000, total_duration=32512.536083, train/accuracy=0.699590, train/loss=1.201533, validation/accuracy=0.646240, validation/loss=1.448912, validation/num_examples=50000
I0302 20:58:03.482621 139758017697536 logging_writer.py:48] [68300] global_step=68300, grad_norm=1.3879746198654175, loss=2.287749767303467
I0302 20:58:45.904030 139758009304832 logging_writer.py:48] [68400] global_step=68400, grad_norm=1.1851838827133179, loss=4.012489318847656
I0302 20:59:30.560199 139758017697536 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.2486475706100464, loss=2.9213480949401855
I0302 21:00:15.337910 139758009304832 logging_writer.py:48] [68600] global_step=68600, grad_norm=1.241919755935669, loss=2.306662082672119
I0302 21:01:00.226786 139758017697536 logging_writer.py:48] [68700] global_step=68700, grad_norm=1.1801098585128784, loss=2.9672999382019043
I0302 21:01:45.224923 139758009304832 logging_writer.py:48] [68800] global_step=68800, grad_norm=1.259615182876587, loss=2.444624662399292
I0302 21:02:30.403537 139758017697536 logging_writer.py:48] [68900] global_step=68900, grad_norm=1.5899304151535034, loss=2.243867874145508
I0302 21:03:15.659174 139758009304832 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.330172061920166, loss=2.3093957901000977
I0302 21:04:00.490277 139758017697536 logging_writer.py:48] [69100] global_step=69100, grad_norm=1.3854811191558838, loss=2.1516504287719727
I0302 21:04:45.306272 139758009304832 logging_writer.py:48] [69200] global_step=69200, grad_norm=1.2842252254486084, loss=2.235630512237549
I0302 21:04:52.635858 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:05:03.703450 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:05:23.917164 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:05:25.548383 139953291118400 submission_runner.py:411] Time since start: 32965.72s, 	Step: 69218, 	{'train/accuracy': 0.7053906321525574, 'train/loss': 1.2163230180740356, 'validation/accuracy': 0.6477400064468384, 'validation/loss': 1.4740873575210571, 'validation/num_examples': 50000, 'test/accuracy': 0.5241000056266785, 'test/loss': 2.1208341121673584, 'test/num_examples': 10000, 'score': 30710.1666765213, 'total_duration': 32965.72461724281, 'accumulated_submission_time': 30710.1666765213, 'accumulated_eval_time': 2248.1401748657227, 'accumulated_logging_time': 3.823965072631836}
I0302 21:05:25.573282 139758017697536 logging_writer.py:48] [69218] accumulated_eval_time=2248.140175, accumulated_logging_time=3.823965, accumulated_submission_time=30710.166677, global_step=69218, preemption_count=0, score=30710.166677, test/accuracy=0.524100, test/loss=2.120834, test/num_examples=10000, total_duration=32965.724617, train/accuracy=0.705391, train/loss=1.216323, validation/accuracy=0.647740, validation/loss=1.474087, validation/num_examples=50000
I0302 21:05:58.591941 139758009304832 logging_writer.py:48] [69300] global_step=69300, grad_norm=1.3144402503967285, loss=2.336306095123291
I0302 21:06:42.576709 139758017697536 logging_writer.py:48] [69400] global_step=69400, grad_norm=1.4722790718078613, loss=4.758735656738281
I0302 21:07:27.516688 139758009304832 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.2628679275512695, loss=4.742114543914795
I0302 21:08:12.651499 139758017697536 logging_writer.py:48] [69600] global_step=69600, grad_norm=1.2853924036026, loss=2.2784054279327393
I0302 21:08:57.332232 139758009304832 logging_writer.py:48] [69700] global_step=69700, grad_norm=1.127655267715454, loss=4.591568946838379
I0302 21:09:42.468537 139758017697536 logging_writer.py:48] [69800] global_step=69800, grad_norm=1.2373905181884766, loss=2.6267356872558594
I0302 21:10:27.540606 139758009304832 logging_writer.py:48] [69900] global_step=69900, grad_norm=1.1466319561004639, loss=3.6912529468536377
I0302 21:11:12.364475 139758017697536 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.4123034477233887, loss=2.2343063354492188
I0302 21:11:57.449870 139758009304832 logging_writer.py:48] [70100] global_step=70100, grad_norm=1.3001925945281982, loss=2.069394826889038
I0302 21:12:25.734942 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:12:36.592641 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:12:55.353168 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:12:56.990725 139953291118400 submission_runner.py:411] Time since start: 33417.17s, 	Step: 70164, 	{'train/accuracy': 0.7193554639816284, 'train/loss': 1.1367861032485962, 'validation/accuracy': 0.6459199786186218, 'validation/loss': 1.4766112565994263, 'validation/num_examples': 50000, 'test/accuracy': 0.5228000283241272, 'test/loss': 2.128782272338867, 'test/num_examples': 10000, 'score': 31130.051805496216, 'total_duration': 33417.16694736481, 'accumulated_submission_time': 31130.051805496216, 'accumulated_eval_time': 2279.3959465026855, 'accumulated_logging_time': 4.07750391960144}
I0302 21:12:57.026695 139758017697536 logging_writer.py:48] [70164] accumulated_eval_time=2279.395947, accumulated_logging_time=4.077504, accumulated_submission_time=31130.051805, global_step=70164, preemption_count=0, score=31130.051805, test/accuracy=0.522800, test/loss=2.128782, test/num_examples=10000, total_duration=33417.166947, train/accuracy=0.719355, train/loss=1.136786, validation/accuracy=0.645920, validation/loss=1.476611, validation/num_examples=50000
I0302 21:13:11.692358 139758009304832 logging_writer.py:48] [70200] global_step=70200, grad_norm=1.3411483764648438, loss=2.154087543487549
I0302 21:13:54.195754 139758017697536 logging_writer.py:48] [70300] global_step=70300, grad_norm=1.4224308729171753, loss=2.283531904220581
I0302 21:14:39.180352 139758009304832 logging_writer.py:48] [70400] global_step=70400, grad_norm=1.3377659320831299, loss=2.053044319152832
I0302 21:15:24.518667 139758017697536 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.1802082061767578, loss=3.686940908432007
I0302 21:16:09.770981 139758009304832 logging_writer.py:48] [70600] global_step=70600, grad_norm=1.0936967134475708, loss=3.8555948734283447
I0302 21:16:54.716106 139758017697536 logging_writer.py:48] [70700] global_step=70700, grad_norm=1.2698898315429688, loss=2.497352361679077
I0302 21:17:39.924466 139758009304832 logging_writer.py:48] [70800] global_step=70800, grad_norm=1.1090960502624512, loss=3.474702835083008
I0302 21:18:24.884019 139758017697536 logging_writer.py:48] [70900] global_step=70900, grad_norm=1.219774603843689, loss=2.324049472808838
I0302 21:19:09.706069 139758009304832 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.181670904159546, loss=4.36048698425293
I0302 21:19:54.576570 139758017697536 logging_writer.py:48] [71100] global_step=71100, grad_norm=1.2399579286575317, loss=2.4028053283691406
I0302 21:19:57.382616 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:20:08.658664 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:20:30.013429 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:20:31.638373 139953291118400 submission_runner.py:411] Time since start: 33871.81s, 	Step: 71108, 	{'train/accuracy': 0.6978319883346558, 'train/loss': 1.2037420272827148, 'validation/accuracy': 0.6468799710273743, 'validation/loss': 1.4458647966384888, 'validation/num_examples': 50000, 'test/accuracy': 0.5250000357627869, 'test/loss': 2.09932017326355, 'test/num_examples': 10000, 'score': 31550.347512483597, 'total_duration': 33871.81460762024, 'accumulated_submission_time': 31550.347512483597, 'accumulated_eval_time': 2313.6516971588135, 'accumulated_logging_time': 4.12572455406189}
I0302 21:20:31.664046 139758009304832 logging_writer.py:48] [71108] accumulated_eval_time=2313.651697, accumulated_logging_time=4.125725, accumulated_submission_time=31550.347512, global_step=71108, preemption_count=0, score=31550.347512, test/accuracy=0.525000, test/loss=2.099320, test/num_examples=10000, total_duration=33871.814608, train/accuracy=0.697832, train/loss=1.203742, validation/accuracy=0.646880, validation/loss=1.445865, validation/num_examples=50000
I0302 21:21:08.427006 139758017697536 logging_writer.py:48] [71200] global_step=71200, grad_norm=1.1998499631881714, loss=2.621277332305908
I0302 21:21:52.717538 139758009304832 logging_writer.py:48] [71300] global_step=71300, grad_norm=1.3439234495162964, loss=2.63655686378479
I0302 21:22:37.696900 139758017697536 logging_writer.py:48] [71400] global_step=71400, grad_norm=1.1550049781799316, loss=2.9931042194366455
I0302 21:23:22.863303 139758009304832 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.338038444519043, loss=2.175459861755371
I0302 21:24:07.483777 139758017697536 logging_writer.py:48] [71600] global_step=71600, grad_norm=1.455675482749939, loss=2.149569511413574
I0302 21:24:52.019051 139758009304832 logging_writer.py:48] [71700] global_step=71700, grad_norm=1.2075539827346802, loss=3.318556785583496
I0302 21:25:36.755767 139758017697536 logging_writer.py:48] [71800] global_step=71800, grad_norm=1.3010927438735962, loss=3.244725227355957
I0302 21:26:21.779958 139758009304832 logging_writer.py:48] [71900] global_step=71900, grad_norm=1.3003569841384888, loss=2.0747013092041016
I0302 21:27:06.501446 139758017697536 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.322282314300537, loss=2.875197410583496
I0302 21:27:31.662228 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:27:42.519134 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:28:01.096944 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:28:02.732944 139953291118400 submission_runner.py:411] Time since start: 34322.91s, 	Step: 72058, 	{'train/accuracy': 0.7070507407188416, 'train/loss': 1.1535999774932861, 'validation/accuracy': 0.652899980545044, 'validation/loss': 1.4156707525253296, 'validation/num_examples': 50000, 'test/accuracy': 0.5271000266075134, 'test/loss': 2.0786259174346924, 'test/num_examples': 10000, 'score': 31970.288603544235, 'total_duration': 34322.90913772583, 'accumulated_submission_time': 31970.288603544235, 'accumulated_eval_time': 2344.7223691940308, 'accumulated_logging_time': 4.1603617668151855}
I0302 21:28:02.764598 139758009304832 logging_writer.py:48] [72058] accumulated_eval_time=2344.722369, accumulated_logging_time=4.160362, accumulated_submission_time=31970.288604, global_step=72058, preemption_count=0, score=31970.288604, test/accuracy=0.527100, test/loss=2.078626, test/num_examples=10000, total_duration=34322.909138, train/accuracy=0.707051, train/loss=1.153600, validation/accuracy=0.652900, validation/loss=1.415671, validation/num_examples=50000
I0302 21:28:19.956262 139758017697536 logging_writer.py:48] [72100] global_step=72100, grad_norm=1.2521437406539917, loss=2.6348955631256104
I0302 21:29:02.915570 139758009304832 logging_writer.py:48] [72200] global_step=72200, grad_norm=1.165427327156067, loss=3.2590925693511963
I0302 21:29:47.856126 139758017697536 logging_writer.py:48] [72300] global_step=72300, grad_norm=1.3855911493301392, loss=2.597275733947754
I0302 21:30:33.069413 139758009304832 logging_writer.py:48] [72400] global_step=72400, grad_norm=1.6808773279190063, loss=2.290135145187378
I0302 21:31:17.935341 139758017697536 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.2158066034317017, loss=3.2811439037323
I0302 21:32:02.849312 139758009304832 logging_writer.py:48] [72600] global_step=72600, grad_norm=1.2011666297912598, loss=3.1281425952911377
I0302 21:32:47.634581 139758017697536 logging_writer.py:48] [72700] global_step=72700, grad_norm=1.446860909461975, loss=2.3353946208953857
I0302 21:33:32.659998 139758009304832 logging_writer.py:48] [72800] global_step=72800, grad_norm=1.2139753103256226, loss=2.5891435146331787
I0302 21:34:17.353521 139758017697536 logging_writer.py:48] [72900] global_step=72900, grad_norm=1.1806260347366333, loss=3.453732490539551
I0302 21:35:02.297164 139758009304832 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.3559319972991943, loss=2.042799949645996
I0302 21:35:02.993808 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:35:14.298793 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:35:33.060158 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:35:34.692937 139953291118400 submission_runner.py:411] Time since start: 34774.87s, 	Step: 73003, 	{'train/accuracy': 0.710253894329071, 'train/loss': 1.1438536643981934, 'validation/accuracy': 0.6521599888801575, 'validation/loss': 1.4241604804992676, 'validation/num_examples': 50000, 'test/accuracy': 0.5306000113487244, 'test/loss': 2.0731072425842285, 'test/num_examples': 10000, 'score': 32390.458921909332, 'total_duration': 34774.869156360626, 'accumulated_submission_time': 32390.458921909332, 'accumulated_eval_time': 2376.42147231102, 'accumulated_logging_time': 4.202556133270264}
I0302 21:35:34.728877 139758017697536 logging_writer.py:48] [73003] accumulated_eval_time=2376.421472, accumulated_logging_time=4.202556, accumulated_submission_time=32390.458922, global_step=73003, preemption_count=0, score=32390.458922, test/accuracy=0.530600, test/loss=2.073107, test/num_examples=10000, total_duration=34774.869156, train/accuracy=0.710254, train/loss=1.143854, validation/accuracy=0.652160, validation/loss=1.424160, validation/num_examples=50000
I0302 21:36:15.080034 139758009304832 logging_writer.py:48] [73100] global_step=73100, grad_norm=1.3403221368789673, loss=4.762411594390869
I0302 21:37:00.002967 139758017697536 logging_writer.py:48] [73200] global_step=73200, grad_norm=1.41502845287323, loss=2.204307794570923
I0302 21:37:45.108050 139758009304832 logging_writer.py:48] [73300] global_step=73300, grad_norm=1.4114904403686523, loss=2.2066335678100586
I0302 21:38:30.259267 139758017697536 logging_writer.py:48] [73400] global_step=73400, grad_norm=1.2242730855941772, loss=4.165951728820801
I0302 21:39:15.174766 139758009304832 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.1781468391418457, loss=3.2832674980163574
I0302 21:40:00.237828 139758017697536 logging_writer.py:48] [73600] global_step=73600, grad_norm=1.1736550331115723, loss=2.5819032192230225
I0302 21:40:45.447769 139758009304832 logging_writer.py:48] [73700] global_step=73700, grad_norm=1.213216781616211, loss=4.78865909576416
I0302 21:41:30.681960 139758017697536 logging_writer.py:48] [73800] global_step=73800, grad_norm=1.2700657844543457, loss=2.2934277057647705
I0302 21:42:16.099848 139758009304832 logging_writer.py:48] [73900] global_step=73900, grad_norm=1.4402228593826294, loss=2.3963727951049805
I0302 21:42:34.804186 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:42:45.888614 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:43:08.402441 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:43:10.026843 139953291118400 submission_runner.py:411] Time since start: 35230.20s, 	Step: 73943, 	{'train/accuracy': 0.7079882621765137, 'train/loss': 1.155798077583313, 'validation/accuracy': 0.6553399562835693, 'validation/loss': 1.4021482467651367, 'validation/num_examples': 50000, 'test/accuracy': 0.5343000292778015, 'test/loss': 2.051135301589966, 'test/num_examples': 10000, 'score': 32810.473249197006, 'total_duration': 35230.20307135582, 'accumulated_submission_time': 32810.473249197006, 'accumulated_eval_time': 2411.6441247463226, 'accumulated_logging_time': 4.24935245513916}
I0302 21:43:10.056612 139758017697536 logging_writer.py:48] [73943] accumulated_eval_time=2411.644125, accumulated_logging_time=4.249352, accumulated_submission_time=32810.473249, global_step=73943, preemption_count=0, score=32810.473249, test/accuracy=0.534300, test/loss=2.051135, test/num_examples=10000, total_duration=35230.203071, train/accuracy=0.707988, train/loss=1.155798, validation/accuracy=0.655340, validation/loss=1.402148, validation/num_examples=50000
I0302 21:43:32.973653 139758009304832 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.358411431312561, loss=2.1727209091186523
I0302 21:44:15.159388 139758017697536 logging_writer.py:48] [74100] global_step=74100, grad_norm=1.3691158294677734, loss=2.224999189376831
I0302 21:45:00.007122 139758009304832 logging_writer.py:48] [74200] global_step=74200, grad_norm=1.3449293375015259, loss=3.2763543128967285
I0302 21:45:45.295829 139758017697536 logging_writer.py:48] [74300] global_step=74300, grad_norm=1.4852166175842285, loss=2.2525441646575928
I0302 21:46:30.393907 139758009304832 logging_writer.py:48] [74400] global_step=74400, grad_norm=1.295361876487732, loss=3.5989320278167725
I0302 21:47:15.204076 139758017697536 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.3815382719039917, loss=2.3682351112365723
I0302 21:48:00.063669 139758009304832 logging_writer.py:48] [74600] global_step=74600, grad_norm=1.361708641052246, loss=2.4723362922668457
I0302 21:48:45.120865 139758017697536 logging_writer.py:48] [74700] global_step=74700, grad_norm=1.254435420036316, loss=2.650725841522217
I0302 21:49:29.959770 139758009304832 logging_writer.py:48] [74800] global_step=74800, grad_norm=1.377833604812622, loss=4.225799083709717
I0302 21:50:10.454759 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:50:21.300880 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:50:42.618773 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:50:44.253055 139953291118400 submission_runner.py:411] Time since start: 35684.43s, 	Step: 74891, 	{'train/accuracy': 0.706835925579071, 'train/loss': 1.19562828540802, 'validation/accuracy': 0.6556000113487244, 'validation/loss': 1.433531403541565, 'validation/num_examples': 50000, 'test/accuracy': 0.5301000475883484, 'test/loss': 2.0819716453552246, 'test/num_examples': 10000, 'score': 33230.81537055969, 'total_duration': 35684.42928028107, 'accumulated_submission_time': 33230.81537055969, 'accumulated_eval_time': 2445.4424064159393, 'accumulated_logging_time': 4.287355422973633}
I0302 21:50:44.289651 139758017697536 logging_writer.py:48] [74891] accumulated_eval_time=2445.442406, accumulated_logging_time=4.287355, accumulated_submission_time=33230.815371, global_step=74891, preemption_count=0, score=33230.815371, test/accuracy=0.530100, test/loss=2.081972, test/num_examples=10000, total_duration=35684.429280, train/accuracy=0.706836, train/loss=1.195628, validation/accuracy=0.655600, validation/loss=1.433531, validation/num_examples=50000
I0302 21:50:48.241859 139758009304832 logging_writer.py:48] [74900] global_step=74900, grad_norm=1.4261839389801025, loss=2.2196145057678223
I0302 21:51:28.868071 139758017697536 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.204057216644287, loss=2.0240278244018555
I0302 21:52:14.039507 139758009304832 logging_writer.py:48] [75100] global_step=75100, grad_norm=1.4526212215423584, loss=2.118323564529419
I0302 21:52:58.866467 139758017697536 logging_writer.py:48] [75200] global_step=75200, grad_norm=1.2165926694869995, loss=4.447660446166992
I0302 21:53:44.129997 139758009304832 logging_writer.py:48] [75300] global_step=75300, grad_norm=1.1675338745117188, loss=2.5128262042999268
I0302 21:54:28.568938 139758017697536 logging_writer.py:48] [75400] global_step=75400, grad_norm=1.3516870737075806, loss=2.0792715549468994
I0302 21:55:13.314434 139758009304832 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.1587413549423218, loss=4.558337211608887
I0302 21:55:58.118057 139758017697536 logging_writer.py:48] [75600] global_step=75600, grad_norm=1.3395568132400513, loss=2.2483320236206055
I0302 21:56:43.098184 139758009304832 logging_writer.py:48] [75700] global_step=75700, grad_norm=1.3562248945236206, loss=2.271026611328125
I0302 21:57:27.959582 139758017697536 logging_writer.py:48] [75800] global_step=75800, grad_norm=1.4948290586471558, loss=2.2229549884796143
I0302 21:57:44.657682 139953291118400 spec.py:321] Evaluating on the training split.
I0302 21:57:55.855250 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 21:58:14.110499 139953291118400 spec.py:349] Evaluating on the test split.
I0302 21:58:15.753842 139953291118400 submission_runner.py:411] Time since start: 36135.93s, 	Step: 75839, 	{'train/accuracy': 0.71205073595047, 'train/loss': 1.2105128765106201, 'validation/accuracy': 0.6584199666976929, 'validation/loss': 1.4606388807296753, 'validation/num_examples': 50000, 'test/accuracy': 0.5286000370979309, 'test/loss': 2.1042492389678955, 'test/num_examples': 10000, 'score': 33651.12571454048, 'total_duration': 36135.930050849915, 'accumulated_submission_time': 33651.12571454048, 'accumulated_eval_time': 2476.5385341644287, 'accumulated_logging_time': 4.334265470504761}
I0302 21:58:15.789953 139758009304832 logging_writer.py:48] [75839] accumulated_eval_time=2476.538534, accumulated_logging_time=4.334265, accumulated_submission_time=33651.125715, global_step=75839, preemption_count=0, score=33651.125715, test/accuracy=0.528600, test/loss=2.104249, test/num_examples=10000, total_duration=36135.930051, train/accuracy=0.712051, train/loss=1.210513, validation/accuracy=0.658420, validation/loss=1.460639, validation/num_examples=50000
I0302 21:58:40.298735 139758017697536 logging_writer.py:48] [75900] global_step=75900, grad_norm=1.445076584815979, loss=2.1731598377227783
I0302 21:59:24.449430 139758009304832 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.3636205196380615, loss=2.2421798706054688
I0302 22:00:09.333863 139758017697536 logging_writer.py:48] [76100] global_step=76100, grad_norm=1.2912812232971191, loss=2.533812999725342
I0302 22:00:54.337635 139758009304832 logging_writer.py:48] [76200] global_step=76200, grad_norm=1.4327532052993774, loss=2.24769926071167
I0302 22:01:39.198068 139758017697536 logging_writer.py:48] [76300] global_step=76300, grad_norm=1.2817277908325195, loss=2.2691619396209717
I0302 22:02:24.326274 139758009304832 logging_writer.py:48] [76400] global_step=76400, grad_norm=1.2955806255340576, loss=2.2517826557159424
I0302 22:03:09.145381 139758017697536 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.3015857934951782, loss=2.2268967628479004
I0302 22:03:53.945236 139758009304832 logging_writer.py:48] [76600] global_step=76600, grad_norm=1.375057578086853, loss=2.0952751636505127
I0302 22:04:38.792035 139758017697536 logging_writer.py:48] [76700] global_step=76700, grad_norm=1.3708298206329346, loss=2.213493585586548
I0302 22:05:16.015901 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:05:27.104363 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:05:49.367394 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:05:51.004176 139953291118400 submission_runner.py:411] Time since start: 36591.18s, 	Step: 76784, 	{'train/accuracy': 0.72572261095047, 'train/loss': 1.1005898714065552, 'validation/accuracy': 0.651419997215271, 'validation/loss': 1.4404127597808838, 'validation/num_examples': 50000, 'test/accuracy': 0.534000039100647, 'test/loss': 2.07847261428833, 'test/num_examples': 10000, 'score': 34071.293254852295, 'total_duration': 36591.18041014671, 'accumulated_submission_time': 34071.293254852295, 'accumulated_eval_time': 2511.5268075466156, 'accumulated_logging_time': 4.380546808242798}
I0302 22:05:51.034395 139758009304832 logging_writer.py:48] [76784] accumulated_eval_time=2511.526808, accumulated_logging_time=4.380547, accumulated_submission_time=34071.293255, global_step=76784, preemption_count=0, score=34071.293255, test/accuracy=0.534000, test/loss=2.078473, test/num_examples=10000, total_duration=36591.180410, train/accuracy=0.725723, train/loss=1.100590, validation/accuracy=0.651420, validation/loss=1.440413, validation/num_examples=50000
I0302 22:05:57.758582 139758017697536 logging_writer.py:48] [76800] global_step=76800, grad_norm=1.2338473796844482, loss=4.31196928024292
I0302 22:06:38.129316 139758009304832 logging_writer.py:48] [76900] global_step=76900, grad_norm=1.1832852363586426, loss=3.1457860469818115
I0302 22:07:22.944972 139758017697536 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.1850814819335938, loss=4.29978084564209
I0302 22:08:07.729963 139758009304832 logging_writer.py:48] [77100] global_step=77100, grad_norm=1.3081183433532715, loss=3.0968291759490967
I0302 22:08:52.622118 139758017697536 logging_writer.py:48] [77200] global_step=77200, grad_norm=1.331540584564209, loss=2.316080093383789
I0302 22:09:37.283119 139758009304832 logging_writer.py:48] [77300] global_step=77300, grad_norm=1.3035463094711304, loss=2.123101234436035
I0302 22:10:22.132755 139758017697536 logging_writer.py:48] [77400] global_step=77400, grad_norm=1.427366018295288, loss=2.0459401607513428
I0302 22:11:07.169857 139758009304832 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.418284296989441, loss=2.1527724266052246
I0302 22:11:52.357001 139758017697536 logging_writer.py:48] [77600] global_step=77600, grad_norm=1.3637597560882568, loss=2.2674708366394043
I0302 22:12:37.539537 139758009304832 logging_writer.py:48] [77700] global_step=77700, grad_norm=1.412122368812561, loss=2.196481466293335
I0302 22:12:51.423684 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:13:02.372109 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:13:21.587303 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:13:23.239037 139953291118400 submission_runner.py:411] Time since start: 37043.42s, 	Step: 77733, 	{'train/accuracy': 0.7066601514816284, 'train/loss': 1.1821738481521606, 'validation/accuracy': 0.6551199555397034, 'validation/loss': 1.4311776161193848, 'validation/num_examples': 50000, 'test/accuracy': 0.5369000434875488, 'test/loss': 2.0748746395111084, 'test/num_examples': 10000, 'score': 34491.62502241135, 'total_duration': 37043.41521525383, 'accumulated_submission_time': 34491.62502241135, 'accumulated_eval_time': 2543.3420894145966, 'accumulated_logging_time': 4.420172214508057}
I0302 22:13:23.280261 139758017697536 logging_writer.py:48] [77733] accumulated_eval_time=2543.342089, accumulated_logging_time=4.420172, accumulated_submission_time=34491.625022, global_step=77733, preemption_count=0, score=34491.625022, test/accuracy=0.536900, test/loss=2.074875, test/num_examples=10000, total_duration=37043.415215, train/accuracy=0.706660, train/loss=1.182174, validation/accuracy=0.655120, validation/loss=1.431178, validation/num_examples=50000
I0302 22:13:50.171787 139758009304832 logging_writer.py:48] [77800] global_step=77800, grad_norm=1.3091838359832764, loss=2.505730390548706
I0302 22:14:34.090785 139758017697536 logging_writer.py:48] [77900] global_step=77900, grad_norm=1.4067786931991577, loss=2.2072501182556152
I0302 22:15:19.103223 139758009304832 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.4436655044555664, loss=2.0937576293945312
I0302 22:16:04.387906 139758017697536 logging_writer.py:48] [78100] global_step=78100, grad_norm=1.3198435306549072, loss=2.6244919300079346
I0302 22:16:49.418663 139758009304832 logging_writer.py:48] [78200] global_step=78200, grad_norm=1.1900413036346436, loss=4.500016689300537
I0302 22:17:34.550479 139758017697536 logging_writer.py:48] [78300] global_step=78300, grad_norm=1.3019331693649292, loss=3.485140085220337
I0302 22:18:19.659307 139758009304832 logging_writer.py:48] [78400] global_step=78400, grad_norm=1.381751537322998, loss=4.371708869934082
I0302 22:19:04.491391 139758017697536 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.3725509643554688, loss=2.150343894958496
I0302 22:19:49.246333 139758009304832 logging_writer.py:48] [78600] global_step=78600, grad_norm=1.4733426570892334, loss=2.118014335632324
I0302 22:20:23.288257 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:20:34.714137 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:20:51.607440 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:20:53.247776 139953291118400 submission_runner.py:411] Time since start: 37493.42s, 	Step: 78677, 	{'train/accuracy': 0.7102343440055847, 'train/loss': 1.176645040512085, 'validation/accuracy': 0.6593799591064453, 'validation/loss': 1.4185059070587158, 'validation/num_examples': 50000, 'test/accuracy': 0.532200038433075, 'test/loss': 2.0688157081604004, 'test/num_examples': 10000, 'score': 34911.57203626633, 'total_duration': 37493.42399716377, 'accumulated_submission_time': 34911.57203626633, 'accumulated_eval_time': 2573.301589488983, 'accumulated_logging_time': 4.47462272644043}
I0302 22:20:53.285251 139758017697536 logging_writer.py:48] [78677] accumulated_eval_time=2573.301589, accumulated_logging_time=4.474623, accumulated_submission_time=34911.572036, global_step=78677, preemption_count=0, score=34911.572036, test/accuracy=0.532200, test/loss=2.068816, test/num_examples=10000, total_duration=37493.423997, train/accuracy=0.710234, train/loss=1.176645, validation/accuracy=0.659380, validation/loss=1.418506, validation/num_examples=50000
I0302 22:21:02.801988 139758009304832 logging_writer.py:48] [78700] global_step=78700, grad_norm=1.3319942951202393, loss=2.0732421875
I0302 22:21:45.247173 139758017697536 logging_writer.py:48] [78800] global_step=78800, grad_norm=1.2321289777755737, loss=3.2782340049743652
I0302 22:22:30.906475 139758009304832 logging_writer.py:48] [78900] global_step=78900, grad_norm=1.4058583974838257, loss=2.10367488861084
I0302 22:23:15.781977 139758017697536 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.2688981294631958, loss=3.1249589920043945
I0302 22:24:00.715377 139758009304832 logging_writer.py:48] [79100] global_step=79100, grad_norm=1.3858999013900757, loss=2.225297451019287
I0302 22:24:45.609009 139758017697536 logging_writer.py:48] [79200] global_step=79200, grad_norm=1.1625771522521973, loss=3.8719944953918457
I0302 22:25:30.643216 139758009304832 logging_writer.py:48] [79300] global_step=79300, grad_norm=1.1493924856185913, loss=4.553446292877197
I0302 22:26:15.822091 139758017697536 logging_writer.py:48] [79400] global_step=79400, grad_norm=1.3122172355651855, loss=2.178685426712036
I0302 22:27:00.704053 139758009304832 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.4907890558242798, loss=2.03940749168396
I0302 22:27:45.622060 139758017697536 logging_writer.py:48] [79600] global_step=79600, grad_norm=1.3139737844467163, loss=3.1887729167938232
I0302 22:27:53.311173 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:28:04.210034 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:28:23.324692 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:28:24.984984 139953291118400 submission_runner.py:411] Time since start: 37945.16s, 	Step: 79619, 	{'train/accuracy': 0.7199609279632568, 'train/loss': 1.122406244277954, 'validation/accuracy': 0.657759964466095, 'validation/loss': 1.4062657356262207, 'validation/num_examples': 50000, 'test/accuracy': 0.5317000150680542, 'test/loss': 2.070014476776123, 'test/num_examples': 10000, 'score': 35331.53860926628, 'total_duration': 37945.161172389984, 'accumulated_submission_time': 35331.53860926628, 'accumulated_eval_time': 2604.975376367569, 'accumulated_logging_time': 4.523173093795776}
I0302 22:28:25.036023 139758009304832 logging_writer.py:48] [79619] accumulated_eval_time=2604.975376, accumulated_logging_time=4.523173, accumulated_submission_time=35331.538609, global_step=79619, preemption_count=0, score=35331.538609, test/accuracy=0.531700, test/loss=2.070014, test/num_examples=10000, total_duration=37945.161172, train/accuracy=0.719961, train/loss=1.122406, validation/accuracy=0.657760, validation/loss=1.406266, validation/num_examples=50000
I0302 22:28:57.527711 139758017697536 logging_writer.py:48] [79700] global_step=79700, grad_norm=1.2762188911437988, loss=4.379558563232422
I0302 22:29:41.385239 139758009304832 logging_writer.py:48] [79800] global_step=79800, grad_norm=1.308689832687378, loss=3.943211078643799
I0302 22:30:26.429473 139758017697536 logging_writer.py:48] [79900] global_step=79900, grad_norm=1.346345067024231, loss=3.213737964630127
I0302 22:31:11.723299 139758009304832 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.2376176118850708, loss=2.4838414192199707
I0302 22:31:56.644725 139758017697536 logging_writer.py:48] [80100] global_step=80100, grad_norm=1.4885987043380737, loss=2.187913656234741
I0302 22:32:41.320089 139758009304832 logging_writer.py:48] [80200] global_step=80200, grad_norm=1.1995222568511963, loss=2.345177173614502
I0302 22:33:26.334923 139758017697536 logging_writer.py:48] [80300] global_step=80300, grad_norm=1.4934747219085693, loss=2.152372360229492
I0302 22:34:11.295428 139758009304832 logging_writer.py:48] [80400] global_step=80400, grad_norm=1.3611215353012085, loss=2.709751605987549
I0302 22:34:55.804274 139758017697536 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.225663423538208, loss=4.5514678955078125
I0302 22:35:25.128376 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:35:35.792271 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:35:54.968422 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:35:56.604060 139953291118400 submission_runner.py:411] Time since start: 38396.78s, 	Step: 80567, 	{'train/accuracy': 0.7152929306030273, 'train/loss': 1.1523548364639282, 'validation/accuracy': 0.6591199636459351, 'validation/loss': 1.416941523551941, 'validation/num_examples': 50000, 'test/accuracy': 0.5348000526428223, 'test/loss': 2.05126953125, 'test/num_examples': 10000, 'score': 35751.56966614723, 'total_duration': 38396.780281066895, 'accumulated_submission_time': 35751.56966614723, 'accumulated_eval_time': 2636.4510333538055, 'accumulated_logging_time': 4.587049722671509}
I0302 22:35:56.640867 139758009304832 logging_writer.py:48] [80567] accumulated_eval_time=2636.451033, accumulated_logging_time=4.587050, accumulated_submission_time=35751.569666, global_step=80567, preemption_count=0, score=35751.569666, test/accuracy=0.534800, test/loss=2.051270, test/num_examples=10000, total_duration=38396.780281, train/accuracy=0.715293, train/loss=1.152355, validation/accuracy=0.659120, validation/loss=1.416942, validation/num_examples=50000
I0302 22:36:10.075791 139758017697536 logging_writer.py:48] [80600] global_step=80600, grad_norm=1.176533579826355, loss=3.073079824447632
I0302 22:36:52.365729 139758009304832 logging_writer.py:48] [80700] global_step=80700, grad_norm=1.3679461479187012, loss=4.865703105926514
I0302 22:37:37.239160 139758017697536 logging_writer.py:48] [80800] global_step=80800, grad_norm=1.2697319984436035, loss=2.4749927520751953
I0302 22:38:22.189374 139758009304832 logging_writer.py:48] [80900] global_step=80900, grad_norm=1.3394806385040283, loss=2.1923506259918213
I0302 22:39:07.059986 139758017697536 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.3538060188293457, loss=2.087512254714966
I0302 22:39:52.043735 139758009304832 logging_writer.py:48] [81100] global_step=81100, grad_norm=1.3642774820327759, loss=2.110196113586426
I0302 22:40:36.859321 139758017697536 logging_writer.py:48] [81200] global_step=81200, grad_norm=1.3475925922393799, loss=2.8932132720947266
I0302 22:41:21.822117 139758009304832 logging_writer.py:48] [81300] global_step=81300, grad_norm=1.4924260377883911, loss=2.2101635932922363
I0302 22:42:06.977219 139758017697536 logging_writer.py:48] [81400] global_step=81400, grad_norm=1.2356592416763306, loss=4.491830825805664
I0302 22:42:51.700832 139758009304832 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.5849148035049438, loss=2.0895652770996094
I0302 22:42:56.832277 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:43:08.030152 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:43:28.729121 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:43:30.373825 139953291118400 submission_runner.py:411] Time since start: 38850.55s, 	Step: 81513, 	{'train/accuracy': 0.7157031297683716, 'train/loss': 1.1238621473312378, 'validation/accuracy': 0.6619799733161926, 'validation/loss': 1.38247811794281, 'validation/num_examples': 50000, 'test/accuracy': 0.536300003528595, 'test/loss': 2.0532751083374023, 'test/num_examples': 10000, 'score': 36171.70365715027, 'total_duration': 38850.550045251846, 'accumulated_submission_time': 36171.70365715027, 'accumulated_eval_time': 2669.9925594329834, 'accumulated_logging_time': 4.633692026138306}
I0302 22:43:30.404375 139758017697536 logging_writer.py:48] [81513] accumulated_eval_time=2669.992559, accumulated_logging_time=4.633692, accumulated_submission_time=36171.703657, global_step=81513, preemption_count=0, score=36171.703657, test/accuracy=0.536300, test/loss=2.053275, test/num_examples=10000, total_duration=38850.550045, train/accuracy=0.715703, train/loss=1.123862, validation/accuracy=0.661980, validation/loss=1.382478, validation/num_examples=50000
I0302 22:44:05.172253 139758009304832 logging_writer.py:48] [81600] global_step=81600, grad_norm=1.3464744091033936, loss=2.0095481872558594
I0302 22:44:49.366711 139758017697536 logging_writer.py:48] [81700] global_step=81700, grad_norm=1.3868987560272217, loss=4.822861671447754
I0302 22:45:34.243204 139758009304832 logging_writer.py:48] [81800] global_step=81800, grad_norm=1.4237184524536133, loss=2.1599271297454834
I0302 22:46:19.464518 139758017697536 logging_writer.py:48] [81900] global_step=81900, grad_norm=1.2880613803863525, loss=2.371037006378174
I0302 22:47:04.322077 139758009304832 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.6122279167175293, loss=2.028670072555542
I0302 22:47:48.973273 139758017697536 logging_writer.py:48] [82100] global_step=82100, grad_norm=1.4072983264923096, loss=2.0379345417022705
I0302 22:48:33.583610 139758009304832 logging_writer.py:48] [82200] global_step=82200, grad_norm=1.2489551305770874, loss=2.3563225269317627
I0302 22:49:18.336378 139758017697536 logging_writer.py:48] [82300] global_step=82300, grad_norm=1.3122587203979492, loss=3.1231212615966797
I0302 22:50:03.242325 139758009304832 logging_writer.py:48] [82400] global_step=82400, grad_norm=1.5205559730529785, loss=2.1381986141204834
I0302 22:50:30.623415 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:50:41.492684 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:51:01.756170 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:51:03.396252 139953291118400 submission_runner.py:411] Time since start: 39303.57s, 	Step: 82463, 	{'train/accuracy': 0.7237108945846558, 'train/loss': 1.1237812042236328, 'validation/accuracy': 0.6624999642372131, 'validation/loss': 1.4014748334884644, 'validation/num_examples': 50000, 'test/accuracy': 0.5412999987602234, 'test/loss': 2.030993938446045, 'test/num_examples': 10000, 'score': 36591.86593723297, 'total_duration': 39303.57247233391, 'accumulated_submission_time': 36591.86593723297, 'accumulated_eval_time': 2702.7653827667236, 'accumulated_logging_time': 4.6731603145599365}
I0302 22:51:03.433017 139758017697536 logging_writer.py:48] [82463] accumulated_eval_time=2702.765383, accumulated_logging_time=4.673160, accumulated_submission_time=36591.865937, global_step=82463, preemption_count=0, score=36591.865937, test/accuracy=0.541300, test/loss=2.030994, test/num_examples=10000, total_duration=39303.572472, train/accuracy=0.723711, train/loss=1.123781, validation/accuracy=0.662500, validation/loss=1.401475, validation/num_examples=50000
I0302 22:51:18.467459 139758009304832 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.556723952293396, loss=3.9545555114746094
I0302 22:52:00.585013 139758017697536 logging_writer.py:48] [82600] global_step=82600, grad_norm=1.2770689725875854, loss=2.0486643314361572
I0302 22:52:45.438666 139758009304832 logging_writer.py:48] [82700] global_step=82700, grad_norm=1.2397297620773315, loss=4.640013217926025
I0302 22:53:30.249627 139758017697536 logging_writer.py:48] [82800] global_step=82800, grad_norm=1.3618131875991821, loss=4.074599266052246
I0302 22:54:15.217302 139758009304832 logging_writer.py:48] [82900] global_step=82900, grad_norm=1.4669601917266846, loss=2.123361110687256
I0302 22:54:59.772785 139758017697536 logging_writer.py:48] [83000] global_step=83000, grad_norm=1.2754753828048706, loss=3.9151930809020996
I0302 22:55:44.465935 139758009304832 logging_writer.py:48] [83100] global_step=83100, grad_norm=1.1862924098968506, loss=3.0754764080047607
I0302 22:56:29.841186 139758017697536 logging_writer.py:48] [83200] global_step=83200, grad_norm=1.2654750347137451, loss=2.7335972785949707
I0302 22:57:14.620344 139758009304832 logging_writer.py:48] [83300] global_step=83300, grad_norm=1.549983263015747, loss=2.37493634223938
I0302 22:57:59.127711 139758017697536 logging_writer.py:48] [83400] global_step=83400, grad_norm=1.444256067276001, loss=3.7649641036987305
I0302 22:58:03.768163 139953291118400 spec.py:321] Evaluating on the training split.
I0302 22:58:14.734925 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 22:58:31.775110 139953291118400 spec.py:349] Evaluating on the test split.
I0302 22:58:33.406980 139953291118400 submission_runner.py:411] Time since start: 39753.58s, 	Step: 83412, 	{'train/accuracy': 0.7419531345367432, 'train/loss': 1.0138866901397705, 'validation/accuracy': 0.6646199822425842, 'validation/loss': 1.3580873012542725, 'validation/num_examples': 50000, 'test/accuracy': 0.5382000207901001, 'test/loss': 2.0109994411468506, 'test/num_examples': 10000, 'score': 37012.14245843887, 'total_duration': 39753.58320188522, 'accumulated_submission_time': 37012.14245843887, 'accumulated_eval_time': 2732.4041872024536, 'accumulated_logging_time': 4.720138072967529}
I0302 22:58:33.440351 139758009304832 logging_writer.py:48] [83412] accumulated_eval_time=2732.404187, accumulated_logging_time=4.720138, accumulated_submission_time=37012.142458, global_step=83412, preemption_count=0, score=37012.142458, test/accuracy=0.538200, test/loss=2.010999, test/num_examples=10000, total_duration=39753.583202, train/accuracy=0.741953, train/loss=1.013887, validation/accuracy=0.664620, validation/loss=1.358087, validation/num_examples=50000
I0302 22:59:09.704128 139758017697536 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.4768098592758179, loss=2.1332340240478516
I0302 22:59:54.740809 139758009304832 logging_writer.py:48] [83600] global_step=83600, grad_norm=1.5288481712341309, loss=2.1312577724456787
I0302 23:00:39.514422 139758017697536 logging_writer.py:48] [83700] global_step=83700, grad_norm=1.440070629119873, loss=2.1939916610717773
I0302 23:01:24.567018 139758009304832 logging_writer.py:48] [83800] global_step=83800, grad_norm=1.324422836303711, loss=2.3785533905029297
I0302 23:02:09.652947 139758017697536 logging_writer.py:48] [83900] global_step=83900, grad_norm=1.3053158521652222, loss=2.8669121265411377
I0302 23:02:54.601394 139758009304832 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.625797986984253, loss=2.0389597415924072
I0302 23:03:39.596978 139758017697536 logging_writer.py:48] [84100] global_step=84100, grad_norm=1.460220217704773, loss=2.2366058826446533
I0302 23:04:24.374228 139758009304832 logging_writer.py:48] [84200] global_step=84200, grad_norm=1.2359830141067505, loss=3.723237991333008
I0302 23:05:09.330883 139758017697536 logging_writer.py:48] [84300] global_step=84300, grad_norm=1.2089097499847412, loss=3.132721424102783
I0302 23:05:33.615381 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:05:44.421683 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:06:03.873633 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:06:05.512155 139953291118400 submission_runner.py:411] Time since start: 40205.69s, 	Step: 84356, 	{'train/accuracy': 0.721484363079071, 'train/loss': 1.12127685546875, 'validation/accuracy': 0.6665599942207336, 'validation/loss': 1.3685060739517212, 'validation/num_examples': 50000, 'test/accuracy': 0.5446000099182129, 'test/loss': 2.0185341835021973, 'test/num_examples': 10000, 'score': 37432.25945806503, 'total_duration': 40205.688380241394, 'accumulated_submission_time': 37432.25945806503, 'accumulated_eval_time': 2764.3009791374207, 'accumulated_logging_time': 4.763558626174927}
I0302 23:06:05.560061 139758009304832 logging_writer.py:48] [84356] accumulated_eval_time=2764.300979, accumulated_logging_time=4.763559, accumulated_submission_time=37432.259458, global_step=84356, preemption_count=0, score=37432.259458, test/accuracy=0.544600, test/loss=2.018534, test/num_examples=10000, total_duration=40205.688380, train/accuracy=0.721484, train/loss=1.121277, validation/accuracy=0.666560, validation/loss=1.368506, validation/num_examples=50000
I0302 23:06:23.362112 139758017697536 logging_writer.py:48] [84400] global_step=84400, grad_norm=1.5162770748138428, loss=2.1542885303497314
I0302 23:07:06.213390 139758009304832 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.5271966457366943, loss=4.72847843170166
I0302 23:07:50.993070 139758017697536 logging_writer.py:48] [84600] global_step=84600, grad_norm=1.5003221035003662, loss=2.063784599304199
I0302 23:08:35.885749 139758009304832 logging_writer.py:48] [84700] global_step=84700, grad_norm=1.3763043880462646, loss=1.9247334003448486
I0302 23:09:20.707052 139758017697536 logging_writer.py:48] [84800] global_step=84800, grad_norm=1.1859570741653442, loss=3.1699070930480957
I0302 23:10:05.551564 139758009304832 logging_writer.py:48] [84900] global_step=84900, grad_norm=1.4005472660064697, loss=2.5630879402160645
I0302 23:10:50.298367 139758017697536 logging_writer.py:48] [85000] global_step=85000, grad_norm=1.2516417503356934, loss=2.896483898162842
I0302 23:11:35.391966 139758009304832 logging_writer.py:48] [85100] global_step=85100, grad_norm=1.3198260068893433, loss=2.083618402481079
I0302 23:12:20.216732 139758017697536 logging_writer.py:48] [85200] global_step=85200, grad_norm=1.3511953353881836, loss=2.275639295578003
I0302 23:13:05.044297 139758009304832 logging_writer.py:48] [85300] global_step=85300, grad_norm=1.5855125188827515, loss=2.33431339263916
I0302 23:13:05.628695 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:13:16.406159 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:13:34.589132 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:13:36.219772 139953291118400 submission_runner.py:411] Time since start: 40656.40s, 	Step: 85303, 	{'train/accuracy': 0.7251952886581421, 'train/loss': 1.107918620109558, 'validation/accuracy': 0.6675199866294861, 'validation/loss': 1.3741096258163452, 'validation/num_examples': 50000, 'test/accuracy': 0.5424000024795532, 'test/loss': 2.0130226612091064, 'test/num_examples': 10000, 'score': 37852.270012140274, 'total_duration': 40656.39597964287, 'accumulated_submission_time': 37852.270012140274, 'accumulated_eval_time': 2794.8920493125916, 'accumulated_logging_time': 4.8214569091796875}
I0302 23:13:36.257702 139758017697536 logging_writer.py:48] [85303] accumulated_eval_time=2794.892049, accumulated_logging_time=4.821457, accumulated_submission_time=37852.270012, global_step=85303, preemption_count=0, score=37852.270012, test/accuracy=0.542400, test/loss=2.013023, test/num_examples=10000, total_duration=40656.395980, train/accuracy=0.725195, train/loss=1.107919, validation/accuracy=0.667520, validation/loss=1.374110, validation/num_examples=50000
I0302 23:14:15.941510 139758009304832 logging_writer.py:48] [85400] global_step=85400, grad_norm=1.2573959827423096, loss=2.48040771484375
I0302 23:15:00.622670 139758017697536 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.514400839805603, loss=2.0596537590026855
I0302 23:15:45.426805 139758009304832 logging_writer.py:48] [85600] global_step=85600, grad_norm=1.5478962659835815, loss=2.1003613471984863
I0302 23:16:30.508829 139758017697536 logging_writer.py:48] [85700] global_step=85700, grad_norm=1.6928306818008423, loss=2.128551959991455
I0302 23:17:15.068226 139758009304832 logging_writer.py:48] [85800] global_step=85800, grad_norm=1.1704578399658203, loss=3.3523871898651123
I0302 23:17:59.759326 139758017697536 logging_writer.py:48] [85900] global_step=85900, grad_norm=1.4113667011260986, loss=2.3647994995117188
I0302 23:18:44.528306 139758009304832 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.5086324214935303, loss=2.1133999824523926
I0302 23:19:29.467824 139758017697536 logging_writer.py:48] [86100] global_step=86100, grad_norm=1.4430584907531738, loss=2.205378770828247
I0302 23:20:14.394958 139758009304832 logging_writer.py:48] [86200] global_step=86200, grad_norm=1.6599091291427612, loss=4.615133285522461
I0302 23:20:36.592158 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:20:47.468330 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:21:04.482925 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:21:06.128021 139953291118400 submission_runner.py:411] Time since start: 41106.30s, 	Step: 86251, 	{'train/accuracy': 0.7322655916213989, 'train/loss': 1.052381992340088, 'validation/accuracy': 0.6670399904251099, 'validation/loss': 1.3552080392837524, 'validation/num_examples': 50000, 'test/accuracy': 0.5398000478744507, 'test/loss': 2.01186466217041, 'test/num_examples': 10000, 'score': 38272.54418039322, 'total_duration': 41106.304240465164, 'accumulated_submission_time': 38272.54418039322, 'accumulated_eval_time': 2824.427891969681, 'accumulated_logging_time': 4.871694087982178}
I0302 23:21:06.161873 139758017697536 logging_writer.py:48] [86251] accumulated_eval_time=2824.427892, accumulated_logging_time=4.871694, accumulated_submission_time=38272.544180, global_step=86251, preemption_count=0, score=38272.544180, test/accuracy=0.539800, test/loss=2.011865, test/num_examples=10000, total_duration=41106.304240, train/accuracy=0.732266, train/loss=1.052382, validation/accuracy=0.667040, validation/loss=1.355208, validation/num_examples=50000
I0302 23:21:25.919959 139758009304832 logging_writer.py:48] [86300] global_step=86300, grad_norm=1.4846041202545166, loss=2.0537526607513428
I0302 23:22:09.529479 139758017697536 logging_writer.py:48] [86400] global_step=86400, grad_norm=1.3979750871658325, loss=2.0411250591278076
I0302 23:22:54.515191 139758009304832 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.4721932411193848, loss=2.3037736415863037
I0302 23:23:39.638051 139758017697536 logging_writer.py:48] [86600] global_step=86600, grad_norm=1.3519668579101562, loss=2.359417200088501
I0302 23:24:24.494899 139758009304832 logging_writer.py:48] [86700] global_step=86700, grad_norm=1.5353121757507324, loss=2.0858726501464844
I0302 23:25:09.334729 139758017697536 logging_writer.py:48] [86800] global_step=86800, grad_norm=1.3193943500518799, loss=2.3876242637634277
I0302 23:25:54.327375 139758009304832 logging_writer.py:48] [86900] global_step=86900, grad_norm=1.385501742362976, loss=1.9450424909591675
I0302 23:26:39.369480 139758017697536 logging_writer.py:48] [87000] global_step=87000, grad_norm=1.2694129943847656, loss=3.682997465133667
I0302 23:27:24.320782 139758009304832 logging_writer.py:48] [87100] global_step=87100, grad_norm=1.2545251846313477, loss=3.597193956375122
I0302 23:28:06.411057 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:28:17.278986 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:28:40.595139 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:28:42.220398 139953291118400 submission_runner.py:411] Time since start: 41562.40s, 	Step: 87195, 	{'train/accuracy': 0.7362109422683716, 'train/loss': 1.0454906225204468, 'validation/accuracy': 0.6697999835014343, 'validation/loss': 1.338555097579956, 'validation/num_examples': 50000, 'test/accuracy': 0.5415000319480896, 'test/loss': 2.0009829998016357, 'test/num_examples': 10000, 'score': 38692.73499083519, 'total_duration': 41562.396629571915, 'accumulated_submission_time': 38692.73499083519, 'accumulated_eval_time': 2860.237210035324, 'accumulated_logging_time': 4.915456771850586}
I0302 23:28:42.249354 139758017697536 logging_writer.py:48] [87195] accumulated_eval_time=2860.237210, accumulated_logging_time=4.915457, accumulated_submission_time=38692.734991, global_step=87195, preemption_count=0, score=38692.734991, test/accuracy=0.541500, test/loss=2.000983, test/num_examples=10000, total_duration=41562.396630, train/accuracy=0.736211, train/loss=1.045491, validation/accuracy=0.669800, validation/loss=1.338555, validation/num_examples=50000
I0302 23:28:44.618176 139758009304832 logging_writer.py:48] [87200] global_step=87200, grad_norm=1.5171939134597778, loss=2.0272483825683594
I0302 23:29:24.129266 139758017697536 logging_writer.py:48] [87300] global_step=87300, grad_norm=1.4049797058105469, loss=4.679920196533203
I0302 23:30:08.760731 139758009304832 logging_writer.py:48] [87400] global_step=87400, grad_norm=1.4751331806182861, loss=2.494687557220459
I0302 23:30:53.877647 139758017697536 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.5622791051864624, loss=2.1786835193634033
I0302 23:31:39.669518 139758009304832 logging_writer.py:48] [87600] global_step=87600, grad_norm=1.431029200553894, loss=1.975167155265808
I0302 23:32:24.177900 139758017697536 logging_writer.py:48] [87700] global_step=87700, grad_norm=1.3358889818191528, loss=2.2741963863372803
I0302 23:33:08.974986 139758009304832 logging_writer.py:48] [87800] global_step=87800, grad_norm=1.2962627410888672, loss=2.4251766204833984
I0302 23:33:53.852941 139758017697536 logging_writer.py:48] [87900] global_step=87900, grad_norm=1.5073611736297607, loss=2.101936101913452
I0302 23:34:38.509016 139758009304832 logging_writer.py:48] [88000] global_step=88000, grad_norm=1.3310728073120117, loss=3.480816602706909
I0302 23:35:23.470608 139758017697536 logging_writer.py:48] [88100] global_step=88100, grad_norm=1.3096493482589722, loss=2.5916218757629395
I0302 23:35:42.393058 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:35:53.241669 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:36:16.627275 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:36:18.247066 139953291118400 submission_runner.py:411] Time since start: 42018.42s, 	Step: 88144, 	{'train/accuracy': 0.7266015410423279, 'train/loss': 1.0895438194274902, 'validation/accuracy': 0.6708799600601196, 'validation/loss': 1.3421494960784912, 'validation/num_examples': 50000, 'test/accuracy': 0.5432000160217285, 'test/loss': 1.9927676916122437, 'test/num_examples': 10000, 'score': 39112.821246385574, 'total_duration': 42018.42330169678, 'accumulated_submission_time': 39112.821246385574, 'accumulated_eval_time': 2896.0912144184113, 'accumulated_logging_time': 4.953283309936523}
I0302 23:36:18.274977 139758009304832 logging_writer.py:48] [88144] accumulated_eval_time=2896.091214, accumulated_logging_time=4.953283, accumulated_submission_time=39112.821246, global_step=88144, preemption_count=0, score=39112.821246, test/accuracy=0.543200, test/loss=1.992768, test/num_examples=10000, total_duration=42018.423302, train/accuracy=0.726602, train/loss=1.089544, validation/accuracy=0.670880, validation/loss=1.342149, validation/num_examples=50000
I0302 23:36:40.774269 139758017697536 logging_writer.py:48] [88200] global_step=88200, grad_norm=1.45841383934021, loss=2.0318353176116943
I0302 23:37:22.977338 139758009304832 logging_writer.py:48] [88300] global_step=88300, grad_norm=1.288976788520813, loss=4.582211494445801
I0302 23:38:07.925678 139758017697536 logging_writer.py:48] [88400] global_step=88400, grad_norm=1.4859732389450073, loss=2.0352916717529297
I0302 23:38:53.032619 139758009304832 logging_writer.py:48] [88500] global_step=88500, grad_norm=1.4039314985275269, loss=4.579470157623291
I0302 23:39:37.844740 139758017697536 logging_writer.py:48] [88600] global_step=88600, grad_norm=1.4677917957305908, loss=3.0009381771087646
I0302 23:40:22.522477 139758009304832 logging_writer.py:48] [88700] global_step=88700, grad_norm=1.3981636762619019, loss=3.6306519508361816
I0302 23:41:07.588234 139758017697536 logging_writer.py:48] [88800] global_step=88800, grad_norm=1.3475606441497803, loss=4.253777503967285
I0302 23:41:52.593267 139758009304832 logging_writer.py:48] [88900] global_step=88900, grad_norm=1.3312888145446777, loss=4.43917179107666
I0302 23:42:37.305997 139758017697536 logging_writer.py:48] [89000] global_step=89000, grad_norm=1.63654625415802, loss=2.07059645652771
I0302 23:43:18.417994 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:43:29.640951 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:43:47.624492 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:43:49.256330 139953291118400 submission_runner.py:411] Time since start: 42469.43s, 	Step: 89093, 	{'train/accuracy': 0.7369921803474426, 'train/loss': 1.0429660081863403, 'validation/accuracy': 0.6749799847602844, 'validation/loss': 1.325405240058899, 'validation/num_examples': 50000, 'test/accuracy': 0.5485000014305115, 'test/loss': 1.9791725873947144, 'test/num_examples': 10000, 'score': 39532.90726733208, 'total_duration': 42469.43255209923, 'accumulated_submission_time': 39532.90726733208, 'accumulated_eval_time': 2926.929531097412, 'accumulated_logging_time': 4.990481376647949}
I0302 23:43:49.293494 139758009304832 logging_writer.py:48] [89093] accumulated_eval_time=2926.929531, accumulated_logging_time=4.990481, accumulated_submission_time=39532.907267, global_step=89093, preemption_count=0, score=39532.907267, test/accuracy=0.548500, test/loss=1.979173, test/num_examples=10000, total_duration=42469.432552, train/accuracy=0.736992, train/loss=1.042966, validation/accuracy=0.674980, validation/loss=1.325405, validation/num_examples=50000
I0302 23:43:52.484147 139758017697536 logging_writer.py:48] [89100] global_step=89100, grad_norm=1.4035340547561646, loss=4.604636192321777
I0302 23:44:34.047152 139758009304832 logging_writer.py:48] [89200] global_step=89200, grad_norm=1.3315471410751343, loss=4.170900821685791
I0302 23:45:18.807664 139758017697536 logging_writer.py:48] [89300] global_step=89300, grad_norm=1.2643605470657349, loss=3.0705296993255615
I0302 23:46:03.595038 139758009304832 logging_writer.py:48] [89400] global_step=89400, grad_norm=1.5315604209899902, loss=2.0114872455596924
I0302 23:46:48.724251 139758017697536 logging_writer.py:48] [89500] global_step=89500, grad_norm=1.4303269386291504, loss=1.939463496208191
I0302 23:47:33.395503 139758009304832 logging_writer.py:48] [89600] global_step=89600, grad_norm=1.4123097658157349, loss=1.9814724922180176
I0302 23:48:18.381368 139758017697536 logging_writer.py:48] [89700] global_step=89700, grad_norm=1.2847853899002075, loss=2.887650728225708
I0302 23:49:03.149171 139758009304832 logging_writer.py:48] [89800] global_step=89800, grad_norm=1.2625796794891357, loss=3.2812325954437256
I0302 23:49:47.803346 139758017697536 logging_writer.py:48] [89900] global_step=89900, grad_norm=1.3135530948638916, loss=4.704538822174072
I0302 23:50:32.593002 139758009304832 logging_writer.py:48] [90000] global_step=90000, grad_norm=1.456796407699585, loss=1.9857635498046875
I0302 23:50:49.653008 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:51:00.924274 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:51:19.978612 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:51:21.620838 139953291118400 submission_runner.py:411] Time since start: 42921.80s, 	Step: 90040, 	{'train/accuracy': 0.748828113079071, 'train/loss': 1.0013405084609985, 'validation/accuracy': 0.674340009689331, 'validation/loss': 1.3295317888259888, 'validation/num_examples': 50000, 'test/accuracy': 0.5498000383377075, 'test/loss': 1.9649418592453003, 'test/num_examples': 10000, 'score': 39953.20360445976, 'total_duration': 42921.797057151794, 'accumulated_submission_time': 39953.20360445976, 'accumulated_eval_time': 2958.897340297699, 'accumulated_logging_time': 5.042929649353027}
I0302 23:51:21.654943 139758017697536 logging_writer.py:48] [90040] accumulated_eval_time=2958.897340, accumulated_logging_time=5.042930, accumulated_submission_time=39953.203604, global_step=90040, preemption_count=0, score=39953.203604, test/accuracy=0.549800, test/loss=1.964942, test/num_examples=10000, total_duration=42921.797057, train/accuracy=0.748828, train/loss=1.001341, validation/accuracy=0.674340, validation/loss=1.329532, validation/num_examples=50000
I0302 23:51:45.764251 139758009304832 logging_writer.py:48] [90100] global_step=90100, grad_norm=1.550402045249939, loss=4.589542865753174
I0302 23:52:29.439213 139758017697536 logging_writer.py:48] [90200] global_step=90200, grad_norm=1.280405879020691, loss=3.056657552719116
I0302 23:53:14.401272 139758009304832 logging_writer.py:48] [90300] global_step=90300, grad_norm=1.3279544115066528, loss=3.099597692489624
I0302 23:53:59.467168 139758017697536 logging_writer.py:48] [90400] global_step=90400, grad_norm=1.3090823888778687, loss=2.101107597351074
I0302 23:54:44.573686 139758009304832 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.6081597805023193, loss=2.04154109954834
I0302 23:55:29.417608 139758017697536 logging_writer.py:48] [90600] global_step=90600, grad_norm=1.229169487953186, loss=3.0470170974731445
I0302 23:56:14.630017 139758009304832 logging_writer.py:48] [90700] global_step=90700, grad_norm=1.478344440460205, loss=2.174271583557129
I0302 23:56:59.349361 139758017697536 logging_writer.py:48] [90800] global_step=90800, grad_norm=1.3506325483322144, loss=1.9756884574890137
I0302 23:57:44.220051 139758009304832 logging_writer.py:48] [90900] global_step=90900, grad_norm=1.4916030168533325, loss=1.8993037939071655
I0302 23:58:21.708054 139953291118400 spec.py:321] Evaluating on the training split.
I0302 23:58:32.591524 139953291118400 spec.py:333] Evaluating on the validation split.
I0302 23:58:52.995311 139953291118400 spec.py:349] Evaluating on the test split.
I0302 23:58:54.641941 139953291118400 submission_runner.py:411] Time since start: 43374.82s, 	Step: 90985, 	{'train/accuracy': 0.7356249690055847, 'train/loss': 1.0418883562088013, 'validation/accuracy': 0.6781600117683411, 'validation/loss': 1.3062312602996826, 'validation/num_examples': 50000, 'test/accuracy': 0.5527999997138977, 'test/loss': 1.9561856985092163, 'test/num_examples': 10000, 'score': 40373.19947838783, 'total_duration': 43374.818145513535, 'accumulated_submission_time': 40373.19947838783, 'accumulated_eval_time': 2991.8312034606934, 'accumulated_logging_time': 5.086370944976807}
I0302 23:58:54.676742 139758017697536 logging_writer.py:48] [90985] accumulated_eval_time=2991.831203, accumulated_logging_time=5.086371, accumulated_submission_time=40373.199478, global_step=90985, preemption_count=0, score=40373.199478, test/accuracy=0.552800, test/loss=1.956186, test/num_examples=10000, total_duration=43374.818146, train/accuracy=0.735625, train/loss=1.041888, validation/accuracy=0.678160, validation/loss=1.306231, validation/num_examples=50000
I0302 23:59:01.003357 139758009304832 logging_writer.py:48] [91000] global_step=91000, grad_norm=1.3143837451934814, loss=2.062405586242676
I0302 23:59:42.060817 139758017697536 logging_writer.py:48] [91100] global_step=91100, grad_norm=1.3356456756591797, loss=4.615157127380371
I0303 00:00:27.019167 139758009304832 logging_writer.py:48] [91200] global_step=91200, grad_norm=1.5134538412094116, loss=2.0488479137420654
I0303 00:01:12.105479 139758017697536 logging_writer.py:48] [91300] global_step=91300, grad_norm=1.4744969606399536, loss=2.209174633026123
I0303 00:01:57.317280 139758009304832 logging_writer.py:48] [91400] global_step=91400, grad_norm=1.5342117547988892, loss=2.1257739067077637
I0303 00:02:42.215741 139758017697536 logging_writer.py:48] [91500] global_step=91500, grad_norm=1.3918319940567017, loss=2.0224905014038086
I0303 00:03:26.687170 139758009304832 logging_writer.py:48] [91600] global_step=91600, grad_norm=1.3687399625778198, loss=2.8568389415740967
I0303 00:04:11.604986 139758017697536 logging_writer.py:48] [91700] global_step=91700, grad_norm=1.4329566955566406, loss=1.9198098182678223
I0303 00:04:56.545924 139758009304832 logging_writer.py:48] [91800] global_step=91800, grad_norm=1.4483003616333008, loss=2.2342898845672607
I0303 00:05:41.507234 139758017697536 logging_writer.py:48] [91900] global_step=91900, grad_norm=1.7028403282165527, loss=1.9760029315948486
I0303 00:05:54.900218 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:06:05.838989 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:06:23.691027 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:06:25.353676 139953291118400 submission_runner.py:411] Time since start: 43825.53s, 	Step: 91932, 	{'train/accuracy': 0.7396484017372131, 'train/loss': 1.0154486894607544, 'validation/accuracy': 0.6789000034332275, 'validation/loss': 1.2950810194015503, 'validation/num_examples': 50000, 'test/accuracy': 0.5508000254631042, 'test/loss': 1.9430943727493286, 'test/num_examples': 10000, 'score': 40793.36383152008, 'total_duration': 43825.52984857559, 'accumulated_submission_time': 40793.36383152008, 'accumulated_eval_time': 3022.284590482712, 'accumulated_logging_time': 5.132043361663818}
I0303 00:06:25.414788 139758009304832 logging_writer.py:48] [91932] accumulated_eval_time=3022.284590, accumulated_logging_time=5.132043, accumulated_submission_time=40793.363832, global_step=91932, preemption_count=0, score=40793.363832, test/accuracy=0.550800, test/loss=1.943094, test/num_examples=10000, total_duration=43825.529849, train/accuracy=0.739648, train/loss=1.015449, validation/accuracy=0.678900, validation/loss=1.295081, validation/num_examples=50000
I0303 00:06:52.707087 139758017697536 logging_writer.py:48] [92000] global_step=92000, grad_norm=1.6810250282287598, loss=2.076294183731079
I0303 00:07:36.011341 139758009304832 logging_writer.py:48] [92100] global_step=92100, grad_norm=1.4429471492767334, loss=2.1052489280700684
I0303 00:08:20.948779 139758017697536 logging_writer.py:48] [92200] global_step=92200, grad_norm=1.5964438915252686, loss=1.9469902515411377
I0303 00:09:06.132139 139758009304832 logging_writer.py:48] [92300] global_step=92300, grad_norm=1.3414517641067505, loss=3.4439096450805664
I0303 00:09:51.052944 139758017697536 logging_writer.py:48] [92400] global_step=92400, grad_norm=1.4039645195007324, loss=3.7278332710266113
I0303 00:10:36.226917 139758009304832 logging_writer.py:48] [92500] global_step=92500, grad_norm=1.4670530557632446, loss=2.228120803833008
I0303 00:11:21.473398 139758017697536 logging_writer.py:48] [92600] global_step=92600, grad_norm=1.4862957000732422, loss=2.0029654502868652
I0303 00:12:06.587725 139758009304832 logging_writer.py:48] [92700] global_step=92700, grad_norm=1.4742846488952637, loss=1.9206788539886475
I0303 00:12:51.670475 139758017697536 logging_writer.py:48] [92800] global_step=92800, grad_norm=1.328379511833191, loss=2.4224894046783447
I0303 00:13:25.582422 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:13:36.671468 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:13:57.240801 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:13:58.876482 139953291118400 submission_runner.py:411] Time since start: 44279.05s, 	Step: 92877, 	{'train/accuracy': 0.7428515553474426, 'train/loss': 1.0198140144348145, 'validation/accuracy': 0.6730799674987793, 'validation/loss': 1.332512617111206, 'validation/num_examples': 50000, 'test/accuracy': 0.5501000285148621, 'test/loss': 1.9638128280639648, 'test/num_examples': 10000, 'score': 41213.46935200691, 'total_duration': 44279.05270528793, 'accumulated_submission_time': 41213.46935200691, 'accumulated_eval_time': 3055.57865357399, 'accumulated_logging_time': 5.207129716873169}
I0303 00:13:58.911834 139758009304832 logging_writer.py:48] [92877] accumulated_eval_time=3055.578654, accumulated_logging_time=5.207130, accumulated_submission_time=41213.469352, global_step=92877, preemption_count=0, score=41213.469352, test/accuracy=0.550100, test/loss=1.963813, test/num_examples=10000, total_duration=44279.052705, train/accuracy=0.742852, train/loss=1.019814, validation/accuracy=0.673080, validation/loss=1.332513, validation/num_examples=50000
I0303 00:14:08.398227 139758017697536 logging_writer.py:48] [92900] global_step=92900, grad_norm=1.3717241287231445, loss=4.473407745361328
I0303 00:14:49.834954 139758009304832 logging_writer.py:48] [93000] global_step=93000, grad_norm=1.5255131721496582, loss=2.0501790046691895
I0303 00:15:34.601456 139758017697536 logging_writer.py:48] [93100] global_step=93100, grad_norm=1.3933674097061157, loss=2.1486759185791016
I0303 00:16:19.631925 139758009304832 logging_writer.py:48] [93200] global_step=93200, grad_norm=1.6069175004959106, loss=2.110767364501953
I0303 00:17:04.767314 139758017697536 logging_writer.py:48] [93300] global_step=93300, grad_norm=1.3793681859970093, loss=4.247722625732422
I0303 00:17:49.324149 139758009304832 logging_writer.py:48] [93400] global_step=93400, grad_norm=1.5580047369003296, loss=1.8725824356079102
I0303 00:18:34.159603 139758017697536 logging_writer.py:48] [93500] global_step=93500, grad_norm=1.5539532899856567, loss=1.968338966369629
I0303 00:19:18.922814 139758009304832 logging_writer.py:48] [93600] global_step=93600, grad_norm=1.2644950151443481, loss=2.9867842197418213
I0303 00:20:03.689399 139758017697536 logging_writer.py:48] [93700] global_step=93700, grad_norm=1.4698139429092407, loss=2.5640029907226562
I0303 00:20:48.358833 139758009304832 logging_writer.py:48] [93800] global_step=93800, grad_norm=1.4069709777832031, loss=4.1653032302856445
I0303 00:20:59.208976 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:21:10.447107 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:21:28.083053 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:21:29.721488 139953291118400 submission_runner.py:411] Time since start: 44729.90s, 	Step: 93825, 	{'train/accuracy': 0.7576562166213989, 'train/loss': 0.9598555564880371, 'validation/accuracy': 0.6772800087928772, 'validation/loss': 1.3212695121765137, 'validation/num_examples': 50000, 'test/accuracy': 0.5507000088691711, 'test/loss': 1.9684770107269287, 'test/num_examples': 10000, 'score': 41633.70737886429, 'total_duration': 44729.89771127701, 'accumulated_submission_time': 41633.70737886429, 'accumulated_eval_time': 3086.0911548137665, 'accumulated_logging_time': 5.252807855606079}
I0303 00:21:29.756691 139758017697536 logging_writer.py:48] [93825] accumulated_eval_time=3086.091155, accumulated_logging_time=5.252808, accumulated_submission_time=41633.707379, global_step=93825, preemption_count=0, score=41633.707379, test/accuracy=0.550700, test/loss=1.968477, test/num_examples=10000, total_duration=44729.897711, train/accuracy=0.757656, train/loss=0.959856, validation/accuracy=0.677280, validation/loss=1.321270, validation/num_examples=50000
I0303 00:22:00.066408 139758009304832 logging_writer.py:48] [93900] global_step=93900, grad_norm=1.5120971202850342, loss=1.9956610202789307
I0303 00:22:44.786501 139758017697536 logging_writer.py:48] [94000] global_step=94000, grad_norm=1.5450409650802612, loss=2.1248972415924072
I0303 00:23:29.662955 139758009304832 logging_writer.py:48] [94100] global_step=94100, grad_norm=1.3886886835098267, loss=2.3660740852355957
I0303 00:24:14.721336 139758017697536 logging_writer.py:48] [94200] global_step=94200, grad_norm=1.4765440225601196, loss=2.022089958190918
I0303 00:24:59.460187 139758009304832 logging_writer.py:48] [94300] global_step=94300, grad_norm=1.439816951751709, loss=2.1697511672973633
I0303 00:25:44.176301 139758017697536 logging_writer.py:48] [94400] global_step=94400, grad_norm=1.6000088453292847, loss=2.0028390884399414
I0303 00:26:29.218737 139758009304832 logging_writer.py:48] [94500] global_step=94500, grad_norm=1.447089672088623, loss=2.3106181621551514
I0303 00:27:14.449602 139758017697536 logging_writer.py:48] [94600] global_step=94600, grad_norm=1.5327383279800415, loss=1.9276890754699707
I0303 00:27:59.204673 139758009304832 logging_writer.py:48] [94700] global_step=94700, grad_norm=1.4525789022445679, loss=2.1182515621185303
I0303 00:28:29.987269 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:28:40.868479 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:29:00.361270 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:29:02.010785 139953291118400 submission_runner.py:411] Time since start: 45182.19s, 	Step: 94770, 	{'train/accuracy': 0.7390429377555847, 'train/loss': 1.0380719900131226, 'validation/accuracy': 0.6790399551391602, 'validation/loss': 1.304970145225525, 'validation/num_examples': 50000, 'test/accuracy': 0.554900050163269, 'test/loss': 1.9556161165237427, 'test/num_examples': 10000, 'score': 42053.8782582283, 'total_duration': 45182.18700695038, 'accumulated_submission_time': 42053.8782582283, 'accumulated_eval_time': 3118.114638566971, 'accumulated_logging_time': 5.299704313278198}
I0303 00:29:02.046774 139758017697536 logging_writer.py:48] [94770] accumulated_eval_time=3118.114639, accumulated_logging_time=5.299704, accumulated_submission_time=42053.878258, global_step=94770, preemption_count=0, score=42053.878258, test/accuracy=0.554900, test/loss=1.955616, test/num_examples=10000, total_duration=45182.187007, train/accuracy=0.739043, train/loss=1.038072, validation/accuracy=0.679040, validation/loss=1.304970, validation/num_examples=50000
I0303 00:29:14.324629 139758009304832 logging_writer.py:48] [94800] global_step=94800, grad_norm=1.5815987586975098, loss=2.089409351348877
I0303 00:29:56.516883 139758017697536 logging_writer.py:48] [94900] global_step=94900, grad_norm=1.6624891757965088, loss=2.0244009494781494
I0303 00:30:41.386896 139758009304832 logging_writer.py:48] [95000] global_step=95000, grad_norm=1.4600924253463745, loss=1.8471808433532715
I0303 00:31:27.140777 139758017697536 logging_writer.py:48] [95100] global_step=95100, grad_norm=1.4668997526168823, loss=4.169057846069336
I0303 00:32:12.506172 139758009304832 logging_writer.py:48] [95200] global_step=95200, grad_norm=1.5478841066360474, loss=2.3056774139404297
I0303 00:32:57.097361 139758017697536 logging_writer.py:48] [95300] global_step=95300, grad_norm=1.3002738952636719, loss=2.8576505184173584
I0303 00:33:41.903078 139758009304832 logging_writer.py:48] [95400] global_step=95400, grad_norm=1.5554369688034058, loss=2.1144137382507324
I0303 00:34:26.711064 139758017697536 logging_writer.py:48] [95500] global_step=95500, grad_norm=1.4559099674224854, loss=2.0938258171081543
I0303 00:35:11.696900 139758009304832 logging_writer.py:48] [95600] global_step=95600, grad_norm=1.606357455253601, loss=4.4320068359375
I0303 00:35:56.341476 139758017697536 logging_writer.py:48] [95700] global_step=95700, grad_norm=1.3395627737045288, loss=2.689525842666626
I0303 00:36:02.364152 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:36:13.253857 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:36:31.629753 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:36:33.269402 139953291118400 submission_runner.py:411] Time since start: 45633.45s, 	Step: 95715, 	{'train/accuracy': 0.7507030963897705, 'train/loss': 1.004400610923767, 'validation/accuracy': 0.6848599910736084, 'validation/loss': 1.2917283773422241, 'validation/num_examples': 50000, 'test/accuracy': 0.5614000558853149, 'test/loss': 1.9297590255737305, 'test/num_examples': 10000, 'score': 42474.13750100136, 'total_duration': 45633.44561266899, 'accumulated_submission_time': 42474.13750100136, 'accumulated_eval_time': 3149.01988363266, 'accumulated_logging_time': 5.345886945724487}
I0303 00:36:33.309005 139758009304832 logging_writer.py:48] [95715] accumulated_eval_time=3149.019884, accumulated_logging_time=5.345887, accumulated_submission_time=42474.137501, global_step=95715, preemption_count=0, score=42474.137501, test/accuracy=0.561400, test/loss=1.929759, test/num_examples=10000, total_duration=45633.445613, train/accuracy=0.750703, train/loss=1.004401, validation/accuracy=0.684860, validation/loss=1.291728, validation/num_examples=50000
I0303 00:37:07.550410 139758017697536 logging_writer.py:48] [95800] global_step=95800, grad_norm=1.4749380350112915, loss=1.9237732887268066
I0303 00:37:52.150281 139758009304832 logging_writer.py:48] [95900] global_step=95900, grad_norm=1.4354088306427002, loss=2.068537712097168
I0303 00:38:37.049606 139758017697536 logging_writer.py:48] [96000] global_step=96000, grad_norm=1.4514137506484985, loss=3.4917612075805664
I0303 00:39:22.287961 139758009304832 logging_writer.py:48] [96100] global_step=96100, grad_norm=1.461274266242981, loss=1.9381383657455444
I0303 00:40:06.962525 139758017697536 logging_writer.py:48] [96200] global_step=96200, grad_norm=1.464039921760559, loss=4.494788646697998
I0303 00:40:51.616010 139758009304832 logging_writer.py:48] [96300] global_step=96300, grad_norm=1.244663119316101, loss=3.4383106231689453
I0303 00:41:36.937765 139758017697536 logging_writer.py:48] [96400] global_step=96400, grad_norm=1.5365153551101685, loss=4.4652485847473145
I0303 00:42:21.783554 139758009304832 logging_writer.py:48] [96500] global_step=96500, grad_norm=1.540979027748108, loss=1.8745163679122925
I0303 00:43:06.712777 139758017697536 logging_writer.py:48] [96600] global_step=96600, grad_norm=1.499813199043274, loss=2.306900978088379
I0303 00:43:33.370121 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:43:44.177057 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:44:04.819034 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:44:06.453899 139953291118400 submission_runner.py:411] Time since start: 46086.63s, 	Step: 96661, 	{'train/accuracy': 0.7564648389816284, 'train/loss': 0.9674227833747864, 'validation/accuracy': 0.6837799549102783, 'validation/loss': 1.2896058559417725, 'validation/num_examples': 50000, 'test/accuracy': 0.5568000078201294, 'test/loss': 1.9372282028198242, 'test/num_examples': 10000, 'score': 42894.14020085335, 'total_duration': 46086.63012123108, 'accumulated_submission_time': 42894.14020085335, 'accumulated_eval_time': 3182.1036455631256, 'accumulated_logging_time': 5.395781517028809}
I0303 00:44:06.489463 139758009304832 logging_writer.py:48] [96661] accumulated_eval_time=3182.103646, accumulated_logging_time=5.395782, accumulated_submission_time=42894.140201, global_step=96661, preemption_count=0, score=42894.140201, test/accuracy=0.556800, test/loss=1.937228, test/num_examples=10000, total_duration=46086.630121, train/accuracy=0.756465, train/loss=0.967423, validation/accuracy=0.683780, validation/loss=1.289606, validation/num_examples=50000
I0303 00:44:22.297396 139758017697536 logging_writer.py:48] [96700] global_step=96700, grad_norm=1.458986759185791, loss=4.379493713378906
I0303 00:45:04.113912 139758009304832 logging_writer.py:48] [96800] global_step=96800, grad_norm=1.470064401626587, loss=1.9796350002288818
I0303 00:45:48.831500 139758017697536 logging_writer.py:48] [96900] global_step=96900, grad_norm=1.5260173082351685, loss=2.538370370864868
I0303 00:46:33.652934 139758009304832 logging_writer.py:48] [97000] global_step=97000, grad_norm=1.528741478919983, loss=1.9107797145843506
I0303 00:47:18.587369 139758017697536 logging_writer.py:48] [97100] global_step=97100, grad_norm=1.479425311088562, loss=2.278571844100952
I0303 00:48:03.353271 139758009304832 logging_writer.py:48] [97200] global_step=97200, grad_norm=1.337053656578064, loss=3.737618923187256
I0303 00:48:48.005484 139758017697536 logging_writer.py:48] [97300] global_step=97300, grad_norm=1.4436917304992676, loss=4.415907382965088
I0303 00:49:32.646038 139758009304832 logging_writer.py:48] [97400] global_step=97400, grad_norm=1.5986278057098389, loss=1.9295614957809448
I0303 00:50:17.606532 139758017697536 logging_writer.py:48] [97500] global_step=97500, grad_norm=1.2476155757904053, loss=3.8604862689971924
I0303 00:51:02.659511 139758009304832 logging_writer.py:48] [97600] global_step=97600, grad_norm=1.3699524402618408, loss=3.1507298946380615
I0303 00:51:06.911782 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:51:17.591776 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:51:35.963916 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:51:37.598253 139953291118400 submission_runner.py:411] Time since start: 46537.77s, 	Step: 97611, 	{'train/accuracy': 0.7490038871765137, 'train/loss': 0.9923749566078186, 'validation/accuracy': 0.6890199780464172, 'validation/loss': 1.2585322856903076, 'validation/num_examples': 50000, 'test/accuracy': 0.5580000281333923, 'test/loss': 1.9156156778335571, 'test/num_examples': 10000, 'score': 43314.50114059448, 'total_duration': 46537.77447581291, 'accumulated_submission_time': 43314.50114059448, 'accumulated_eval_time': 3212.790130376816, 'accumulated_logging_time': 5.443286895751953}
I0303 00:51:37.640811 139758017697536 logging_writer.py:48] [97611] accumulated_eval_time=3212.790130, accumulated_logging_time=5.443287, accumulated_submission_time=43314.501141, global_step=97611, preemption_count=0, score=43314.501141, test/accuracy=0.558000, test/loss=1.915616, test/num_examples=10000, total_duration=46537.774476, train/accuracy=0.749004, train/loss=0.992375, validation/accuracy=0.689020, validation/loss=1.258532, validation/num_examples=50000
I0303 00:52:13.865706 139758009304832 logging_writer.py:48] [97700] global_step=97700, grad_norm=1.2957172393798828, loss=3.7546114921569824
I0303 00:52:58.713644 139758017697536 logging_writer.py:48] [97800] global_step=97800, grad_norm=1.615922451019287, loss=3.826226234436035
I0303 00:53:43.328756 139758009304832 logging_writer.py:48] [97900] global_step=97900, grad_norm=1.6627295017242432, loss=2.095686435699463
I0303 00:54:28.361343 139758017697536 logging_writer.py:48] [98000] global_step=98000, grad_norm=1.4242331981658936, loss=3.927769184112549
I0303 00:55:13.046012 139758009304832 logging_writer.py:48] [98100] global_step=98100, grad_norm=1.3624297380447388, loss=2.6123766899108887
I0303 00:55:57.896049 139758017697536 logging_writer.py:48] [98200] global_step=98200, grad_norm=1.3426802158355713, loss=2.2402303218841553
I0303 00:56:42.865584 139758009304832 logging_writer.py:48] [98300] global_step=98300, grad_norm=1.637682318687439, loss=1.9642693996429443
I0303 00:57:27.581203 139758017697536 logging_writer.py:48] [98400] global_step=98400, grad_norm=1.5167121887207031, loss=2.2614176273345947
I0303 00:58:12.380529 139758009304832 logging_writer.py:48] [98500] global_step=98500, grad_norm=1.5420053005218506, loss=2.0461199283599854
I0303 00:58:37.653765 139953291118400 spec.py:321] Evaluating on the training split.
I0303 00:58:48.511609 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 00:59:07.226142 139953291118400 spec.py:349] Evaluating on the test split.
I0303 00:59:08.865868 139953291118400 submission_runner.py:411] Time since start: 46989.04s, 	Step: 98558, 	{'train/accuracy': 0.7421093583106995, 'train/loss': 1.0115565061569214, 'validation/accuracy': 0.6842199563980103, 'validation/loss': 1.2888301610946655, 'validation/num_examples': 50000, 'test/accuracy': 0.5594000220298767, 'test/loss': 1.939386248588562, 'test/num_examples': 10000, 'score': 43734.45563292503, 'total_duration': 46989.042090415955, 'accumulated_submission_time': 43734.45563292503, 'accumulated_eval_time': 3244.002207517624, 'accumulated_logging_time': 5.495993137359619}
I0303 00:59:08.902398 139758017697536 logging_writer.py:48] [98558] accumulated_eval_time=3244.002208, accumulated_logging_time=5.495993, accumulated_submission_time=43734.455633, global_step=98558, preemption_count=0, score=43734.455633, test/accuracy=0.559400, test/loss=1.939386, test/num_examples=10000, total_duration=46989.042090, train/accuracy=0.742109, train/loss=1.011557, validation/accuracy=0.684220, validation/loss=1.288830, validation/num_examples=50000
I0303 00:59:25.896804 139758009304832 logging_writer.py:48] [98600] global_step=98600, grad_norm=1.317502737045288, loss=3.2349085807800293
I0303 01:00:08.749285 139758017697536 logging_writer.py:48] [98700] global_step=98700, grad_norm=1.317830204963684, loss=2.6522772312164307
I0303 01:00:53.612768 139758009304832 logging_writer.py:48] [98800] global_step=98800, grad_norm=1.4506118297576904, loss=2.025953769683838
I0303 01:01:38.979702 139758017697536 logging_writer.py:48] [98900] global_step=98900, grad_norm=1.3705617189407349, loss=2.418457269668579
I0303 01:02:23.878762 139758009304832 logging_writer.py:48] [99000] global_step=99000, grad_norm=1.4710067510604858, loss=4.132501602172852
I0303 01:03:08.590727 139758017697536 logging_writer.py:48] [99100] global_step=99100, grad_norm=1.3746116161346436, loss=3.851977825164795
I0303 01:03:53.373291 139758009304832 logging_writer.py:48] [99200] global_step=99200, grad_norm=1.534021019935608, loss=4.4767866134643555
I0303 01:04:38.430317 139758017697536 logging_writer.py:48] [99300] global_step=99300, grad_norm=1.6478660106658936, loss=2.0010197162628174
I0303 01:05:23.231310 139758009304832 logging_writer.py:48] [99400] global_step=99400, grad_norm=1.4576820135116577, loss=1.8203662633895874
I0303 01:06:08.094436 139758017697536 logging_writer.py:48] [99500] global_step=99500, grad_norm=1.3990449905395508, loss=4.326215744018555
I0303 01:06:09.069149 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:06:20.107121 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:06:40.180249 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:06:41.819344 139953291118400 submission_runner.py:411] Time since start: 47442.00s, 	Step: 99504, 	{'train/accuracy': 0.7502343654632568, 'train/loss': 0.9732296466827393, 'validation/accuracy': 0.6872599720954895, 'validation/loss': 1.2587881088256836, 'validation/num_examples': 50000, 'test/accuracy': 0.5587000250816345, 'test/loss': 1.922590732574463, 'test/num_examples': 10000, 'score': 44154.56234765053, 'total_duration': 47441.99556803703, 'accumulated_submission_time': 44154.56234765053, 'accumulated_eval_time': 3276.752377271652, 'accumulated_logging_time': 5.544393062591553}
I0303 01:06:41.858657 139758009304832 logging_writer.py:48] [99504] accumulated_eval_time=3276.752377, accumulated_logging_time=5.544393, accumulated_submission_time=44154.562348, global_step=99504, preemption_count=0, score=44154.562348, test/accuracy=0.558700, test/loss=1.922591, test/num_examples=10000, total_duration=47441.995568, train/accuracy=0.750234, train/loss=0.973230, validation/accuracy=0.687260, validation/loss=1.258788, validation/num_examples=50000
I0303 01:07:20.325307 139758017697536 logging_writer.py:48] [99600] global_step=99600, grad_norm=1.551249384880066, loss=1.972968339920044
I0303 01:08:05.068834 139758009304832 logging_writer.py:48] [99700] global_step=99700, grad_norm=1.2354366779327393, loss=3.297649383544922
I0303 01:08:49.837336 139758017697536 logging_writer.py:48] [99800] global_step=99800, grad_norm=1.3603237867355347, loss=2.6900148391723633
I0303 01:09:35.073179 139758009304832 logging_writer.py:48] [99900] global_step=99900, grad_norm=1.3881003856658936, loss=2.2547285556793213
I0303 01:10:19.829454 139758017697536 logging_writer.py:48] [100000] global_step=100000, grad_norm=1.3457704782485962, loss=2.5132882595062256
I0303 01:11:04.907685 139758009304832 logging_writer.py:48] [100100] global_step=100100, grad_norm=1.6296402215957642, loss=1.9406789541244507
I0303 01:11:49.608730 139758017697536 logging_writer.py:48] [100200] global_step=100200, grad_norm=1.5486936569213867, loss=4.476404190063477
I0303 01:12:34.069115 139758009304832 logging_writer.py:48] [100300] global_step=100300, grad_norm=1.6820201873779297, loss=1.8583412170410156
I0303 01:13:19.294171 139758017697536 logging_writer.py:48] [100400] global_step=100400, grad_norm=1.3207615613937378, loss=3.0316672325134277
I0303 01:13:41.981374 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:13:52.776387 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:14:11.064904 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:14:12.712045 139953291118400 submission_runner.py:411] Time since start: 47892.89s, 	Step: 100452, 	{'train/accuracy': 0.7751367092132568, 'train/loss': 0.8857801556587219, 'validation/accuracy': 0.6929799914360046, 'validation/loss': 1.2570501565933228, 'validation/num_examples': 50000, 'test/accuracy': 0.5685000419616699, 'test/loss': 1.8823338747024536, 'test/num_examples': 10000, 'score': 44574.62707424164, 'total_duration': 47892.888268470764, 'accumulated_submission_time': 44574.62707424164, 'accumulated_eval_time': 3307.483034849167, 'accumulated_logging_time': 5.593884229660034}
I0303 01:14:12.752174 139758009304832 logging_writer.py:48] [100452] accumulated_eval_time=3307.483035, accumulated_logging_time=5.593884, accumulated_submission_time=44574.627074, global_step=100452, preemption_count=0, score=44574.627074, test/accuracy=0.568500, test/loss=1.882334, test/num_examples=10000, total_duration=47892.888268, train/accuracy=0.775137, train/loss=0.885780, validation/accuracy=0.692980, validation/loss=1.257050, validation/num_examples=50000
I0303 01:14:32.117459 139758017697536 logging_writer.py:48] [100500] global_step=100500, grad_norm=1.5094531774520874, loss=4.111454963684082
I0303 01:15:15.202231 139758009304832 logging_writer.py:48] [100600] global_step=100600, grad_norm=1.4544817209243774, loss=3.441110849380493
I0303 01:16:00.138475 139758017697536 logging_writer.py:48] [100700] global_step=100700, grad_norm=1.4875335693359375, loss=2.6457114219665527
I0303 01:16:45.190444 139758009304832 logging_writer.py:48] [100800] global_step=100800, grad_norm=1.314659833908081, loss=3.087582588195801
I0303 01:17:30.087038 139758017697536 logging_writer.py:48] [100900] global_step=100900, grad_norm=1.4408193826675415, loss=1.9439549446105957
I0303 01:18:14.736099 139758009304832 logging_writer.py:48] [101000] global_step=101000, grad_norm=1.644934892654419, loss=2.006481170654297
I0303 01:18:59.514684 139758017697536 logging_writer.py:48] [101100] global_step=101100, grad_norm=1.3635883331298828, loss=4.391857147216797
I0303 01:19:44.781302 139758009304832 logging_writer.py:48] [101200] global_step=101200, grad_norm=1.503901481628418, loss=2.2220001220703125
I0303 01:20:29.497520 139758017697536 logging_writer.py:48] [101300] global_step=101300, grad_norm=1.4552781581878662, loss=3.506516456604004
I0303 01:21:12.990502 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:21:24.006129 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:21:43.724378 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:21:45.358411 139953291118400 submission_runner.py:411] Time since start: 48345.53s, 	Step: 101397, 	{'train/accuracy': 0.7506640553474426, 'train/loss': 0.9665694832801819, 'validation/accuracy': 0.6922799944877625, 'validation/loss': 1.2452056407928467, 'validation/num_examples': 50000, 'test/accuracy': 0.5728000402450562, 'test/loss': 1.8757268190383911, 'test/num_examples': 10000, 'score': 44994.80569982529, 'total_duration': 48345.53457951546, 'accumulated_submission_time': 44994.80569982529, 'accumulated_eval_time': 3339.8508801460266, 'accumulated_logging_time': 5.645975828170776}
I0303 01:21:45.409707 139758009304832 logging_writer.py:48] [101397] accumulated_eval_time=3339.850880, accumulated_logging_time=5.645976, accumulated_submission_time=44994.805700, global_step=101397, preemption_count=0, score=44994.805700, test/accuracy=0.572800, test/loss=1.875727, test/num_examples=10000, total_duration=48345.534580, train/accuracy=0.750664, train/loss=0.966569, validation/accuracy=0.692280, validation/loss=1.245206, validation/num_examples=50000
I0303 01:21:46.989131 139758017697536 logging_writer.py:48] [101400] global_step=101400, grad_norm=1.5894851684570312, loss=2.0588622093200684
I0303 01:22:27.558246 139758009304832 logging_writer.py:48] [101500] global_step=101500, grad_norm=1.5216612815856934, loss=1.9744699001312256
I0303 01:23:12.347774 139758017697536 logging_writer.py:48] [101600] global_step=101600, grad_norm=1.4824020862579346, loss=2.070263385772705
I0303 01:23:57.219217 139758009304832 logging_writer.py:48] [101700] global_step=101700, grad_norm=1.4864799976348877, loss=2.395604133605957
I0303 01:24:42.514439 139758017697536 logging_writer.py:48] [101800] global_step=101800, grad_norm=1.306315541267395, loss=2.4918179512023926
I0303 01:25:27.416677 139758009304832 logging_writer.py:48] [101900] global_step=101900, grad_norm=1.4584194421768188, loss=1.757293462753296
I0303 01:26:12.442682 139758017697536 logging_writer.py:48] [102000] global_step=102000, grad_norm=1.7505637407302856, loss=4.534112930297852
I0303 01:26:57.526336 139758009304832 logging_writer.py:48] [102100] global_step=102100, grad_norm=1.7870769500732422, loss=2.0206081867218018
I0303 01:27:42.451642 139758017697536 logging_writer.py:48] [102200] global_step=102200, grad_norm=1.6036560535430908, loss=2.034945487976074
I0303 01:28:27.490873 139758009304832 logging_writer.py:48] [102300] global_step=102300, grad_norm=1.4522695541381836, loss=1.9917290210723877
I0303 01:28:45.739076 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:28:56.568448 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:29:20.132343 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:29:21.762927 139953291118400 submission_runner.py:411] Time since start: 48801.94s, 	Step: 102342, 	{'train/accuracy': 0.7575390338897705, 'train/loss': 0.9569990038871765, 'validation/accuracy': 0.6941800117492676, 'validation/loss': 1.2485471963882446, 'validation/num_examples': 50000, 'test/accuracy': 0.5701000094413757, 'test/loss': 1.8743760585784912, 'test/num_examples': 10000, 'score': 45415.07636475563, 'total_duration': 48801.93915319443, 'accumulated_submission_time': 45415.07636475563, 'accumulated_eval_time': 3375.8747539520264, 'accumulated_logging_time': 5.707857370376587}
I0303 01:29:21.793060 139758017697536 logging_writer.py:48] [102342] accumulated_eval_time=3375.874754, accumulated_logging_time=5.707857, accumulated_submission_time=45415.076365, global_step=102342, preemption_count=0, score=45415.076365, test/accuracy=0.570100, test/loss=1.874376, test/num_examples=10000, total_duration=48801.939153, train/accuracy=0.757539, train/loss=0.956999, validation/accuracy=0.694180, validation/loss=1.248547, validation/num_examples=50000
I0303 01:29:45.103162 139758009304832 logging_writer.py:48] [102400] global_step=102400, grad_norm=1.54499351978302, loss=1.8464157581329346
I0303 01:30:27.409992 139758017697536 logging_writer.py:48] [102500] global_step=102500, grad_norm=1.4231315851211548, loss=2.2951560020446777
I0303 01:31:12.272224 139758009304832 logging_writer.py:48] [102600] global_step=102600, grad_norm=1.524321436882019, loss=2.018284320831299
I0303 01:31:57.269005 139758017697536 logging_writer.py:48] [102700] global_step=102700, grad_norm=1.4775161743164062, loss=4.181538105010986
I0303 01:32:42.050145 139758009304832 logging_writer.py:48] [102800] global_step=102800, grad_norm=1.4237622022628784, loss=2.3675477504730225
I0303 01:33:26.725945 139758017697536 logging_writer.py:48] [102900] global_step=102900, grad_norm=1.4563974142074585, loss=2.1612040996551514
I0303 01:34:11.556009 139758009304832 logging_writer.py:48] [103000] global_step=103000, grad_norm=1.4890574216842651, loss=2.1621205806732178
I0303 01:34:56.418597 139758017697536 logging_writer.py:48] [103100] global_step=103100, grad_norm=1.4792011976242065, loss=1.893226981163025
I0303 01:35:41.046804 139758009304832 logging_writer.py:48] [103200] global_step=103200, grad_norm=1.538214087486267, loss=1.8642635345458984
I0303 01:36:21.798889 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:36:32.830436 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:36:51.262623 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:36:52.898143 139953291118400 submission_runner.py:411] Time since start: 49253.07s, 	Step: 103292, 	{'train/accuracy': 0.7648046612739563, 'train/loss': 0.9258500933647156, 'validation/accuracy': 0.6905399560928345, 'validation/loss': 1.2477099895477295, 'validation/num_examples': 50000, 'test/accuracy': 0.5659000277519226, 'test/loss': 1.897047519683838, 'test/num_examples': 10000, 'score': 45835.02481293678, 'total_duration': 49253.074348926544, 'accumulated_submission_time': 45835.02481293678, 'accumulated_eval_time': 3406.9739751815796, 'accumulated_logging_time': 5.746920824050903}
I0303 01:36:52.934026 139758017697536 logging_writer.py:48] [103292] accumulated_eval_time=3406.973975, accumulated_logging_time=5.746921, accumulated_submission_time=45835.024813, global_step=103292, preemption_count=0, score=45835.024813, test/accuracy=0.565900, test/loss=1.897048, test/num_examples=10000, total_duration=49253.074349, train/accuracy=0.764805, train/loss=0.925850, validation/accuracy=0.690540, validation/loss=1.247710, validation/num_examples=50000
I0303 01:36:56.494894 139758009304832 logging_writer.py:48] [103300] global_step=103300, grad_norm=1.7189525365829468, loss=2.012601613998413
I0303 01:37:37.696213 139758017697536 logging_writer.py:48] [103400] global_step=103400, grad_norm=1.4937989711761475, loss=1.8075376749038696
I0303 01:38:22.470329 139758009304832 logging_writer.py:48] [103500] global_step=103500, grad_norm=1.498481273651123, loss=4.453784465789795
I0303 01:39:07.285284 139758017697536 logging_writer.py:48] [103600] global_step=103600, grad_norm=1.4801273345947266, loss=2.8138420581817627
I0303 01:39:52.059059 139758009304832 logging_writer.py:48] [103700] global_step=103700, grad_norm=1.6773971319198608, loss=4.439361095428467
I0303 01:40:37.062430 139758017697536 logging_writer.py:48] [103800] global_step=103800, grad_norm=1.3892583847045898, loss=3.023188591003418
I0303 01:41:22.000826 139758009304832 logging_writer.py:48] [103900] global_step=103900, grad_norm=1.631300687789917, loss=1.9661368131637573
I0303 01:42:06.771257 139758017697536 logging_writer.py:48] [104000] global_step=104000, grad_norm=1.469929814338684, loss=1.881925344467163
I0303 01:42:51.672438 139758009304832 logging_writer.py:48] [104100] global_step=104100, grad_norm=1.6298127174377441, loss=1.8078672885894775
I0303 01:43:36.504014 139758017697536 logging_writer.py:48] [104200] global_step=104200, grad_norm=1.532585620880127, loss=2.005898952484131
I0303 01:43:53.170801 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:44:04.446073 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:44:24.393311 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:44:26.054952 139953291118400 submission_runner.py:411] Time since start: 49706.23s, 	Step: 104239, 	{'train/accuracy': 0.7541210651397705, 'train/loss': 0.9695034027099609, 'validation/accuracy': 0.6918599605560303, 'validation/loss': 1.2417765855789185, 'validation/num_examples': 50000, 'test/accuracy': 0.5667000412940979, 'test/loss': 1.8755282163619995, 'test/num_examples': 10000, 'score': 46255.20332431793, 'total_duration': 49706.23113465309, 'accumulated_submission_time': 46255.20332431793, 'accumulated_eval_time': 3439.858054637909, 'accumulated_logging_time': 5.793359994888306}
I0303 01:44:26.095954 139758009304832 logging_writer.py:48] [104239] accumulated_eval_time=3439.858055, accumulated_logging_time=5.793360, accumulated_submission_time=46255.203324, global_step=104239, preemption_count=0, score=46255.203324, test/accuracy=0.566700, test/loss=1.875528, test/num_examples=10000, total_duration=49706.231135, train/accuracy=0.754121, train/loss=0.969503, validation/accuracy=0.691860, validation/loss=1.241777, validation/num_examples=50000
I0303 01:44:50.630401 139758017697536 logging_writer.py:48] [104300] global_step=104300, grad_norm=1.4431275129318237, loss=2.8017468452453613
I0303 01:45:33.439739 139758009304832 logging_writer.py:48] [104400] global_step=104400, grad_norm=1.5056864023208618, loss=1.8822145462036133
I0303 01:46:18.569935 139758017697536 logging_writer.py:48] [104500] global_step=104500, grad_norm=1.6610097885131836, loss=1.8045644760131836
I0303 01:47:03.697760 139758009304832 logging_writer.py:48] [104600] global_step=104600, grad_norm=1.5867984294891357, loss=2.0138213634490967
I0303 01:47:48.458196 139758017697536 logging_writer.py:48] [104700] global_step=104700, grad_norm=1.4171779155731201, loss=3.146069049835205
I0303 01:48:33.098779 139758009304832 logging_writer.py:48] [104800] global_step=104800, grad_norm=1.4090678691864014, loss=2.3949947357177734
I0303 01:49:18.208379 139758017697536 logging_writer.py:48] [104900] global_step=104900, grad_norm=1.5225911140441895, loss=1.974626898765564
I0303 01:50:03.104899 139758009304832 logging_writer.py:48] [105000] global_step=105000, grad_norm=1.5251363515853882, loss=2.800022602081299
I0303 01:50:47.985016 139758017697536 logging_writer.py:48] [105100] global_step=105100, grad_norm=1.5335235595703125, loss=1.8112003803253174
I0303 01:51:26.553166 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:51:37.610270 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:51:59.040433 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:52:00.674277 139953291118400 submission_runner.py:411] Time since start: 50160.85s, 	Step: 105187, 	{'train/accuracy': 0.7598632574081421, 'train/loss': 0.9402235150337219, 'validation/accuracy': 0.6953999996185303, 'validation/loss': 1.232001543045044, 'validation/num_examples': 50000, 'test/accuracy': 0.5755000114440918, 'test/loss': 1.8609957695007324, 'test/num_examples': 10000, 'score': 46675.597521305084, 'total_duration': 50160.85048317909, 'accumulated_submission_time': 46675.597521305084, 'accumulated_eval_time': 3473.9791502952576, 'accumulated_logging_time': 5.849823951721191}
I0303 01:52:00.710851 139758009304832 logging_writer.py:48] [105187] accumulated_eval_time=3473.979150, accumulated_logging_time=5.849824, accumulated_submission_time=46675.597521, global_step=105187, preemption_count=0, score=46675.597521, test/accuracy=0.575500, test/loss=1.860996, test/num_examples=10000, total_duration=50160.850483, train/accuracy=0.759863, train/loss=0.940224, validation/accuracy=0.695400, validation/loss=1.232002, validation/num_examples=50000
I0303 01:52:06.243744 139758017697536 logging_writer.py:48] [105200] global_step=105200, grad_norm=1.5950801372528076, loss=2.0598435401916504
I0303 01:52:46.352082 139758009304832 logging_writer.py:48] [105300] global_step=105300, grad_norm=1.6637991666793823, loss=1.8882014751434326
I0303 01:53:31.179451 139758017697536 logging_writer.py:48] [105400] global_step=105400, grad_norm=1.6771754026412964, loss=4.504221439361572
I0303 01:54:16.366624 139758009304832 logging_writer.py:48] [105500] global_step=105500, grad_norm=1.4125056266784668, loss=3.6980252265930176
I0303 01:55:01.183945 139758017697536 logging_writer.py:48] [105600] global_step=105600, grad_norm=1.644822359085083, loss=3.6640207767486572
I0303 01:55:45.860329 139758009304832 logging_writer.py:48] [105700] global_step=105700, grad_norm=1.741416335105896, loss=1.8060104846954346
I0303 01:56:30.971653 139758017697536 logging_writer.py:48] [105800] global_step=105800, grad_norm=1.4504040479660034, loss=3.3688149452209473
I0303 01:57:15.611362 139758009304832 logging_writer.py:48] [105900] global_step=105900, grad_norm=1.5823136568069458, loss=4.146392345428467
I0303 01:58:00.227638 139758017697536 logging_writer.py:48] [106000] global_step=106000, grad_norm=1.5223194360733032, loss=1.794201374053955
I0303 01:58:45.213472 139758009304832 logging_writer.py:48] [106100] global_step=106100, grad_norm=1.7315033674240112, loss=1.8694360256195068
I0303 01:59:00.725076 139953291118400 spec.py:321] Evaluating on the training split.
I0303 01:59:11.946743 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 01:59:31.403204 139953291118400 spec.py:349] Evaluating on the test split.
I0303 01:59:33.037590 139953291118400 submission_runner.py:411] Time since start: 50613.21s, 	Step: 106136, 	{'train/accuracy': 0.7672656178474426, 'train/loss': 0.9064086079597473, 'validation/accuracy': 0.6967399716377258, 'validation/loss': 1.219843864440918, 'validation/num_examples': 50000, 'test/accuracy': 0.5692000389099121, 'test/loss': 1.8685412406921387, 'test/num_examples': 10000, 'score': 47095.5532104969, 'total_duration': 50613.21381640434, 'accumulated_submission_time': 47095.5532104969, 'accumulated_eval_time': 3506.291650056839, 'accumulated_logging_time': 5.897094011306763}
I0303 01:59:33.078635 139758017697536 logging_writer.py:48] [106136] accumulated_eval_time=3506.291650, accumulated_logging_time=5.897094, accumulated_submission_time=47095.553210, global_step=106136, preemption_count=0, score=47095.553210, test/accuracy=0.569200, test/loss=1.868541, test/num_examples=10000, total_duration=50613.213816, train/accuracy=0.767266, train/loss=0.906409, validation/accuracy=0.696740, validation/loss=1.219844, validation/num_examples=50000
I0303 01:59:58.767616 139758009304832 logging_writer.py:48] [106200] global_step=106200, grad_norm=1.6310125589370728, loss=1.8478796482086182
I0303 02:00:43.224884 139758017697536 logging_writer.py:48] [106300] global_step=106300, grad_norm=1.6023390293121338, loss=1.836110234260559
I0303 02:01:28.612128 139758009304832 logging_writer.py:48] [106400] global_step=106400, grad_norm=1.5499123334884644, loss=4.296976089477539
I0303 02:02:14.061901 139758017697536 logging_writer.py:48] [106500] global_step=106500, grad_norm=1.8286449909210205, loss=1.8530772924423218
I0303 02:02:58.893518 139758009304832 logging_writer.py:48] [106600] global_step=106600, grad_norm=1.5939768552780151, loss=3.294555425643921
I0303 02:03:43.914180 139758017697536 logging_writer.py:48] [106700] global_step=106700, grad_norm=1.4774255752563477, loss=3.9643428325653076
I0303 02:04:28.788946 139758009304832 logging_writer.py:48] [106800] global_step=106800, grad_norm=1.5852144956588745, loss=1.884018063545227
I0303 02:05:13.808191 139758017697536 logging_writer.py:48] [106900] global_step=106900, grad_norm=1.989953875541687, loss=1.9229882955551147
I0303 02:05:58.600992 139758009304832 logging_writer.py:48] [107000] global_step=107000, grad_norm=1.403298258781433, loss=2.1273529529571533
I0303 02:06:33.085596 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:06:44.339190 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:07:04.270900 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:07:05.912983 139953291118400 submission_runner.py:411] Time since start: 51066.09s, 	Step: 107078, 	{'train/accuracy': 0.7860937118530273, 'train/loss': 0.841831624507904, 'validation/accuracy': 0.6953200101852417, 'validation/loss': 1.229534387588501, 'validation/num_examples': 50000, 'test/accuracy': 0.5711000561714172, 'test/loss': 1.8621702194213867, 'test/num_examples': 10000, 'score': 47515.50264263153, 'total_duration': 51066.089199543, 'accumulated_submission_time': 47515.50264263153, 'accumulated_eval_time': 3539.1190111637115, 'accumulated_logging_time': 5.948194980621338}
I0303 02:07:05.950328 139758017697536 logging_writer.py:48] [107078] accumulated_eval_time=3539.119011, accumulated_logging_time=5.948195, accumulated_submission_time=47515.502643, global_step=107078, preemption_count=0, score=47515.502643, test/accuracy=0.571100, test/loss=1.862170, test/num_examples=10000, total_duration=51066.089200, train/accuracy=0.786094, train/loss=0.841832, validation/accuracy=0.695320, validation/loss=1.229534, validation/num_examples=50000
I0303 02:07:15.072160 139758009304832 logging_writer.py:48] [107100] global_step=107100, grad_norm=1.5057692527770996, loss=1.8257691860198975
I0303 02:07:57.093391 139758017697536 logging_writer.py:48] [107200] global_step=107200, grad_norm=1.4680808782577515, loss=4.271683692932129
I0303 02:08:42.135159 139758009304832 logging_writer.py:48] [107300] global_step=107300, grad_norm=1.8376384973526, loss=1.9798731803894043
I0303 02:09:27.248922 139758017697536 logging_writer.py:48] [107400] global_step=107400, grad_norm=1.5528796911239624, loss=1.966585397720337
I0303 02:10:12.469752 139758009304832 logging_writer.py:48] [107500] global_step=107500, grad_norm=1.5143879652023315, loss=3.5089380741119385
I0303 02:10:57.499958 139758017697536 logging_writer.py:48] [107600] global_step=107600, grad_norm=1.6315679550170898, loss=4.255771160125732
I0303 02:11:42.380717 139758009304832 logging_writer.py:48] [107700] global_step=107700, grad_norm=1.4993531703948975, loss=1.8262202739715576
I0303 02:12:27.558184 139758017697536 logging_writer.py:48] [107800] global_step=107800, grad_norm=1.573593020439148, loss=3.7425150871276855
I0303 02:13:12.546596 139758009304832 logging_writer.py:48] [107900] global_step=107900, grad_norm=1.4002968072891235, loss=2.778888702392578
I0303 02:13:57.422276 139758017697536 logging_writer.py:48] [108000] global_step=108000, grad_norm=1.629989743232727, loss=3.140505313873291
I0303 02:14:06.322934 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:14:17.332233 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:14:36.380940 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:14:38.028311 139953291118400 submission_runner.py:411] Time since start: 51518.20s, 	Step: 108021, 	{'train/accuracy': 0.7554101347923279, 'train/loss': 0.9594653844833374, 'validation/accuracy': 0.6963199973106384, 'validation/loss': 1.2319732904434204, 'validation/num_examples': 50000, 'test/accuracy': 0.5750000476837158, 'test/loss': 1.8669058084487915, 'test/num_examples': 10000, 'score': 47935.81768369675, 'total_duration': 51518.20453286171, 'accumulated_submission_time': 47935.81768369675, 'accumulated_eval_time': 3570.8243839740753, 'accumulated_logging_time': 5.9956605434417725}
I0303 02:14:38.069309 139758009304832 logging_writer.py:48] [108021] accumulated_eval_time=3570.824384, accumulated_logging_time=5.995661, accumulated_submission_time=47935.817684, global_step=108021, preemption_count=0, score=47935.817684, test/accuracy=0.575000, test/loss=1.866906, test/num_examples=10000, total_duration=51518.204533, train/accuracy=0.755410, train/loss=0.959465, validation/accuracy=0.696320, validation/loss=1.231973, validation/num_examples=50000
I0303 02:15:09.687953 139758017697536 logging_writer.py:48] [108100] global_step=108100, grad_norm=1.701207160949707, loss=1.8702001571655273
I0303 02:15:54.087033 139758009304832 logging_writer.py:48] [108200] global_step=108200, grad_norm=1.6204482316970825, loss=1.733930230140686
I0303 02:16:39.023265 139758017697536 logging_writer.py:48] [108300] global_step=108300, grad_norm=1.6224017143249512, loss=2.2843527793884277
I0303 02:17:23.904368 139758009304832 logging_writer.py:48] [108400] global_step=108400, grad_norm=1.5449271202087402, loss=1.8941833972930908
I0303 02:18:08.781131 139758017697536 logging_writer.py:48] [108500] global_step=108500, grad_norm=1.4885691404342651, loss=2.0792953968048096
I0303 02:18:53.645249 139758009304832 logging_writer.py:48] [108600] global_step=108600, grad_norm=1.5745530128479004, loss=1.9148378372192383
I0303 02:19:38.558605 139758017697536 logging_writer.py:48] [108700] global_step=108700, grad_norm=1.4752715826034546, loss=4.204310894012451
I0303 02:20:23.596580 139758009304832 logging_writer.py:48] [108800] global_step=108800, grad_norm=1.537522554397583, loss=1.9109742641448975
I0303 02:21:08.812075 139758017697536 logging_writer.py:48] [108900] global_step=108900, grad_norm=1.6784361600875854, loss=1.8416038751602173
I0303 02:21:38.171211 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:21:48.952776 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:22:10.692159 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:22:12.333105 139953291118400 submission_runner.py:411] Time since start: 51972.51s, 	Step: 108967, 	{'train/accuracy': 0.7698437571525574, 'train/loss': 0.8918425440788269, 'validation/accuracy': 0.7005800008773804, 'validation/loss': 1.197978138923645, 'validation/num_examples': 50000, 'test/accuracy': 0.5755000114440918, 'test/loss': 1.845165491104126, 'test/num_examples': 10000, 'score': 48355.86082482338, 'total_duration': 51972.509333372116, 'accumulated_submission_time': 48355.86082482338, 'accumulated_eval_time': 3604.9862751960754, 'accumulated_logging_time': 6.047371864318848}
I0303 02:22:12.367689 139758009304832 logging_writer.py:48] [108967] accumulated_eval_time=3604.986275, accumulated_logging_time=6.047372, accumulated_submission_time=48355.860825, global_step=108967, preemption_count=0, score=48355.860825, test/accuracy=0.575500, test/loss=1.845165, test/num_examples=10000, total_duration=51972.509333, train/accuracy=0.769844, train/loss=0.891843, validation/accuracy=0.700580, validation/loss=1.197978, validation/num_examples=50000
I0303 02:22:25.786967 139758017697536 logging_writer.py:48] [109000] global_step=109000, grad_norm=1.4544681310653687, loss=2.7702584266662598
I0303 02:23:06.940785 139758009304832 logging_writer.py:48] [109100] global_step=109100, grad_norm=1.523913025856018, loss=1.7730904817581177
I0303 02:23:51.828171 139758017697536 logging_writer.py:48] [109200] global_step=109200, grad_norm=1.6813774108886719, loss=3.7770273685455322
I0303 02:24:37.036202 139758009304832 logging_writer.py:48] [109300] global_step=109300, grad_norm=1.5884045362472534, loss=2.296492576599121
I0303 02:25:22.253736 139758017697536 logging_writer.py:48] [109400] global_step=109400, grad_norm=1.5599793195724487, loss=2.757101535797119
I0303 02:26:06.997529 139758009304832 logging_writer.py:48] [109500] global_step=109500, grad_norm=1.7532358169555664, loss=2.0812828540802
I0303 02:26:52.063460 139758017697536 logging_writer.py:48] [109600] global_step=109600, grad_norm=1.696387529373169, loss=1.8619617223739624
I0303 02:27:36.892014 139758009304832 logging_writer.py:48] [109700] global_step=109700, grad_norm=1.645065188407898, loss=2.2652111053466797
I0303 02:28:21.710737 139758017697536 logging_writer.py:48] [109800] global_step=109800, grad_norm=1.842570185661316, loss=1.8511509895324707
I0303 02:29:06.927398 139758009304832 logging_writer.py:48] [109900] global_step=109900, grad_norm=1.5771087408065796, loss=3.4148690700531006
I0303 02:29:12.508184 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:29:23.270189 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:29:43.262368 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:29:44.894669 139953291118400 submission_runner.py:411] Time since start: 52425.07s, 	Step: 109914, 	{'train/accuracy': 0.7803710699081421, 'train/loss': 0.8482807874679565, 'validation/accuracy': 0.7021200060844421, 'validation/loss': 1.1901153326034546, 'validation/num_examples': 50000, 'test/accuracy': 0.579300045967102, 'test/loss': 1.8351106643676758, 'test/num_examples': 10000, 'score': 48775.94476270676, 'total_duration': 52425.07089591026, 'accumulated_submission_time': 48775.94476270676, 'accumulated_eval_time': 3637.372734069824, 'accumulated_logging_time': 6.091373920440674}
I0303 02:29:44.933583 139758017697536 logging_writer.py:48] [109914] accumulated_eval_time=3637.372734, accumulated_logging_time=6.091374, accumulated_submission_time=48775.944763, global_step=109914, preemption_count=0, score=48775.944763, test/accuracy=0.579300, test/loss=1.835111, test/num_examples=10000, total_duration=52425.070896, train/accuracy=0.780371, train/loss=0.848281, validation/accuracy=0.702120, validation/loss=1.190115, validation/num_examples=50000
I0303 02:30:19.671128 139758009304832 logging_writer.py:48] [110000] global_step=110000, grad_norm=1.7141913175582886, loss=1.7941484451293945
I0303 02:31:04.608865 139758017697536 logging_writer.py:48] [110100] global_step=110100, grad_norm=1.7395634651184082, loss=2.0051674842834473
I0303 02:31:49.455960 139758009304832 logging_writer.py:48] [110200] global_step=110200, grad_norm=1.5773988962173462, loss=3.048227310180664
I0303 02:32:34.766827 139758017697536 logging_writer.py:48] [110300] global_step=110300, grad_norm=1.5610039234161377, loss=4.290112495422363
I0303 02:33:19.578361 139758009304832 logging_writer.py:48] [110400] global_step=110400, grad_norm=1.5622475147247314, loss=4.23231315612793
I0303 02:34:04.623009 139758017697536 logging_writer.py:48] [110500] global_step=110500, grad_norm=1.7327768802642822, loss=3.3209922313690186
I0303 02:34:49.327713 139758009304832 logging_writer.py:48] [110600] global_step=110600, grad_norm=1.4496217966079712, loss=3.676438808441162
I0303 02:35:34.282140 139758017697536 logging_writer.py:48] [110700] global_step=110700, grad_norm=1.4446171522140503, loss=2.4014453887939453
I0303 02:36:19.525595 139758009304832 logging_writer.py:48] [110800] global_step=110800, grad_norm=1.7034368515014648, loss=3.0428268909454346
I0303 02:36:44.977487 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:36:56.051876 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:37:14.208859 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:37:15.839878 139953291118400 submission_runner.py:411] Time since start: 52876.02s, 	Step: 110859, 	{'train/accuracy': 0.7680468559265137, 'train/loss': 0.9069384336471558, 'validation/accuracy': 0.7002800107002258, 'validation/loss': 1.197730302810669, 'validation/num_examples': 50000, 'test/accuracy': 0.5750000476837158, 'test/loss': 1.8314648866653442, 'test/num_examples': 10000, 'score': 49195.93100190163, 'total_duration': 52876.01609253883, 'accumulated_submission_time': 49195.93100190163, 'accumulated_eval_time': 3668.2350981235504, 'accumulated_logging_time': 6.1399030685424805}
I0303 02:37:15.879049 139758017697536 logging_writer.py:48] [110859] accumulated_eval_time=3668.235098, accumulated_logging_time=6.139903, accumulated_submission_time=49195.931002, global_step=110859, preemption_count=0, score=49195.931002, test/accuracy=0.575000, test/loss=1.831465, test/num_examples=10000, total_duration=52876.016093, train/accuracy=0.768047, train/loss=0.906938, validation/accuracy=0.700280, validation/loss=1.197730, validation/num_examples=50000
I0303 02:37:32.480603 139758009304832 logging_writer.py:48] [110900] global_step=110900, grad_norm=1.5934889316558838, loss=3.746962308883667
I0303 02:38:15.677514 139758017697536 logging_writer.py:48] [111000] global_step=111000, grad_norm=1.5111422538757324, loss=2.7562193870544434
I0303 02:39:00.422502 139758009304832 logging_writer.py:48] [111100] global_step=111100, grad_norm=1.4700640439987183, loss=3.6171998977661133
I0303 02:39:45.765318 139758017697536 logging_writer.py:48] [111200] global_step=111200, grad_norm=1.4952625036239624, loss=3.2154488563537598
I0303 02:40:30.582548 139758009304832 logging_writer.py:48] [111300] global_step=111300, grad_norm=1.5881385803222656, loss=2.53041672706604
I0303 02:41:15.787760 139758017697536 logging_writer.py:48] [111400] global_step=111400, grad_norm=1.4984179735183716, loss=3.5086350440979004
I0303 02:42:00.608100 139758009304832 logging_writer.py:48] [111500] global_step=111500, grad_norm=1.8059748411178589, loss=1.8451364040374756
I0303 02:42:45.356957 139758017697536 logging_writer.py:48] [111600] global_step=111600, grad_norm=1.547865390777588, loss=2.8876068592071533
I0303 02:43:30.180068 139758009304832 logging_writer.py:48] [111700] global_step=111700, grad_norm=1.5999171733856201, loss=2.6316447257995605
I0303 02:44:15.071334 139758017697536 logging_writer.py:48] [111800] global_step=111800, grad_norm=1.678009033203125, loss=1.7464995384216309
I0303 02:44:16.153622 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:44:26.917970 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:44:45.794071 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:44:47.432869 139953291118400 submission_runner.py:411] Time since start: 53327.61s, 	Step: 111804, 	{'train/accuracy': 0.7716405987739563, 'train/loss': 0.9013556241989136, 'validation/accuracy': 0.7028999924659729, 'validation/loss': 1.2098357677459717, 'validation/num_examples': 50000, 'test/accuracy': 0.5737000107765198, 'test/loss': 1.8351027965545654, 'test/num_examples': 10000, 'score': 49616.14709401131, 'total_duration': 53327.60908675194, 'accumulated_submission_time': 49616.14709401131, 'accumulated_eval_time': 3699.5143172740936, 'accumulated_logging_time': 6.189666271209717}
I0303 02:44:47.472796 139758009304832 logging_writer.py:48] [111804] accumulated_eval_time=3699.514317, accumulated_logging_time=6.189666, accumulated_submission_time=49616.147094, global_step=111804, preemption_count=0, score=49616.147094, test/accuracy=0.573700, test/loss=1.835103, test/num_examples=10000, total_duration=53327.609087, train/accuracy=0.771641, train/loss=0.901356, validation/accuracy=0.702900, validation/loss=1.209836, validation/num_examples=50000
I0303 02:45:26.384613 139758017697536 logging_writer.py:48] [111900] global_step=111900, grad_norm=1.6431392431259155, loss=1.8445135354995728
I0303 02:46:11.355636 139758009304832 logging_writer.py:48] [112000] global_step=112000, grad_norm=1.5793170928955078, loss=1.838197946548462
I0303 02:46:56.364298 139758017697536 logging_writer.py:48] [112100] global_step=112100, grad_norm=1.583667278289795, loss=4.236927032470703
I0303 02:47:41.470072 139758009304832 logging_writer.py:48] [112200] global_step=112200, grad_norm=1.9121540784835815, loss=2.465142250061035
I0303 02:48:26.186121 139758017697536 logging_writer.py:48] [112300] global_step=112300, grad_norm=1.6762385368347168, loss=2.1422767639160156
I0303 02:49:11.205499 139758009304832 logging_writer.py:48] [112400] global_step=112400, grad_norm=1.5162889957427979, loss=3.316107988357544
I0303 02:49:56.208454 139758017697536 logging_writer.py:48] [112500] global_step=112500, grad_norm=1.981555461883545, loss=4.2661051750183105
I0303 02:50:41.340193 139758009304832 logging_writer.py:48] [112600] global_step=112600, grad_norm=1.6156277656555176, loss=1.740588903427124
I0303 02:51:26.717315 139758017697536 logging_writer.py:48] [112700] global_step=112700, grad_norm=1.955960750579834, loss=4.035251140594482
I0303 02:51:47.778902 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:51:58.701565 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:52:22.057910 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:52:23.697579 139953291118400 submission_runner.py:411] Time since start: 53783.87s, 	Step: 112748, 	{'train/accuracy': 0.7766015529632568, 'train/loss': 0.8739011883735657, 'validation/accuracy': 0.7063800096511841, 'validation/loss': 1.1852818727493286, 'validation/num_examples': 50000, 'test/accuracy': 0.5814000368118286, 'test/loss': 1.8124264478683472, 'test/num_examples': 10000, 'score': 50036.39476442337, 'total_duration': 53783.87377977371, 'accumulated_submission_time': 50036.39476442337, 'accumulated_eval_time': 3735.432944059372, 'accumulated_logging_time': 6.240252494812012}
I0303 02:52:23.738876 139758009304832 logging_writer.py:48] [112748] accumulated_eval_time=3735.432944, accumulated_logging_time=6.240252, accumulated_submission_time=50036.394764, global_step=112748, preemption_count=0, score=50036.394764, test/accuracy=0.581400, test/loss=1.812426, test/num_examples=10000, total_duration=53783.873780, train/accuracy=0.776602, train/loss=0.873901, validation/accuracy=0.706380, validation/loss=1.185282, validation/num_examples=50000
I0303 02:52:44.914695 139758017697536 logging_writer.py:48] [112800] global_step=112800, grad_norm=1.6658556461334229, loss=4.27437162399292
I0303 02:53:26.846943 139758009304832 logging_writer.py:48] [112900] global_step=112900, grad_norm=1.508962631225586, loss=3.6181721687316895
I0303 02:54:12.155645 139758017697536 logging_writer.py:48] [113000] global_step=113000, grad_norm=1.6459437608718872, loss=1.7042075395584106
I0303 02:54:57.610876 139758009304832 logging_writer.py:48] [113100] global_step=113100, grad_norm=1.6140533685684204, loss=1.6818389892578125
I0303 02:55:42.917689 139758017697536 logging_writer.py:48] [113200] global_step=113200, grad_norm=1.6784536838531494, loss=1.787811040878296
I0303 02:56:27.877117 139758009304832 logging_writer.py:48] [113300] global_step=113300, grad_norm=1.5365064144134521, loss=3.277503728866577
I0303 02:57:13.100668 139758017697536 logging_writer.py:48] [113400] global_step=113400, grad_norm=1.729813814163208, loss=1.9813663959503174
I0303 02:57:58.057961 139758009304832 logging_writer.py:48] [113500] global_step=113500, grad_norm=1.5159103870391846, loss=3.3352866172790527
I0303 02:58:43.142372 139758017697536 logging_writer.py:48] [113600] global_step=113600, grad_norm=1.539382815361023, loss=3.433227777481079
I0303 02:59:24.094180 139953291118400 spec.py:321] Evaluating on the training split.
I0303 02:59:35.018409 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 02:59:54.669288 139953291118400 spec.py:349] Evaluating on the test split.
I0303 02:59:56.303529 139953291118400 submission_runner.py:411] Time since start: 54236.48s, 	Step: 113693, 	{'train/accuracy': 0.7954491972923279, 'train/loss': 0.7992606163024902, 'validation/accuracy': 0.7044999599456787, 'validation/loss': 1.186686635017395, 'validation/num_examples': 50000, 'test/accuracy': 0.589900016784668, 'test/loss': 1.7972122430801392, 'test/num_examples': 10000, 'score': 50456.448285102844, 'total_duration': 54236.479748010635, 'accumulated_submission_time': 50456.448285102844, 'accumulated_eval_time': 3767.642267227173, 'accumulated_logging_time': 6.5357255935668945}
I0303 02:59:56.343512 139758009304832 logging_writer.py:48] [113693] accumulated_eval_time=3767.642267, accumulated_logging_time=6.535726, accumulated_submission_time=50456.448285, global_step=113693, preemption_count=0, score=50456.448285, test/accuracy=0.589900, test/loss=1.797212, test/num_examples=10000, total_duration=54236.479748, train/accuracy=0.795449, train/loss=0.799261, validation/accuracy=0.704500, validation/loss=1.186687, validation/num_examples=50000
I0303 02:59:59.519350 139758017697536 logging_writer.py:48] [113700] global_step=113700, grad_norm=1.7019758224487305, loss=3.691486358642578
I0303 03:00:40.483545 139758009304832 logging_writer.py:48] [113800] global_step=113800, grad_norm=1.7324070930480957, loss=1.8032457828521729
I0303 03:01:26.474842 139758017697536 logging_writer.py:48] [113900] global_step=113900, grad_norm=1.5853499174118042, loss=2.6234209537506104
I0303 03:02:12.283693 139758009304832 logging_writer.py:48] [114000] global_step=114000, grad_norm=1.8364378213882446, loss=1.8542613983154297
I0303 03:02:57.612749 139758017697536 logging_writer.py:48] [114100] global_step=114100, grad_norm=1.5918139219284058, loss=1.8414490222930908
I0303 03:03:42.569808 139758009304832 logging_writer.py:48] [114200] global_step=114200, grad_norm=1.6553668975830078, loss=1.838944673538208
I0303 03:04:27.780229 139758017697536 logging_writer.py:48] [114300] global_step=114300, grad_norm=1.8660874366760254, loss=2.677708625793457
I0303 03:05:12.909269 139758009304832 logging_writer.py:48] [114400] global_step=114400, grad_norm=1.6266138553619385, loss=4.109562397003174
I0303 03:05:57.601932 139758017697536 logging_writer.py:48] [114500] global_step=114500, grad_norm=1.5595345497131348, loss=2.230503559112549
I0303 03:06:42.874153 139758009304832 logging_writer.py:48] [114600] global_step=114600, grad_norm=1.873799443244934, loss=4.2643232345581055
I0303 03:06:56.457992 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:07:07.846521 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 03:07:26.908127 139953291118400 spec.py:349] Evaluating on the test split.
I0303 03:07:28.561811 139953291118400 submission_runner.py:411] Time since start: 54688.74s, 	Step: 114632, 	{'train/accuracy': 0.7786718606948853, 'train/loss': 0.8812108635902405, 'validation/accuracy': 0.7083799839019775, 'validation/loss': 1.18280029296875, 'validation/num_examples': 50000, 'test/accuracy': 0.5830000042915344, 'test/loss': 1.8008441925048828, 'test/num_examples': 10000, 'score': 50876.50444483757, 'total_duration': 54688.73802089691, 'accumulated_submission_time': 50876.50444483757, 'accumulated_eval_time': 3799.7460713386536, 'accumulated_logging_time': 6.585723876953125}
I0303 03:07:28.600797 139758017697536 logging_writer.py:48] [114632] accumulated_eval_time=3799.746071, accumulated_logging_time=6.585724, accumulated_submission_time=50876.504445, global_step=114632, preemption_count=0, score=50876.504445, test/accuracy=0.583000, test/loss=1.800844, test/num_examples=10000, total_duration=54688.738021, train/accuracy=0.778672, train/loss=0.881211, validation/accuracy=0.708380, validation/loss=1.182800, validation/num_examples=50000
I0303 03:07:55.852656 139758009304832 logging_writer.py:48] [114700] global_step=114700, grad_norm=1.5925257205963135, loss=1.891650915145874
I0303 03:08:39.401929 139758017697536 logging_writer.py:48] [114800] global_step=114800, grad_norm=1.5104620456695557, loss=3.2555432319641113
I0303 03:09:24.665352 139758009304832 logging_writer.py:48] [114900] global_step=114900, grad_norm=1.9674274921417236, loss=4.338089942932129
I0303 03:10:09.908817 139758017697536 logging_writer.py:48] [115000] global_step=115000, grad_norm=1.6847962141036987, loss=1.8811523914337158
I0303 03:10:54.995869 139758009304832 logging_writer.py:48] [115100] global_step=115100, grad_norm=1.5642828941345215, loss=2.053917407989502
I0303 03:11:40.066118 139758017697536 logging_writer.py:48] [115200] global_step=115200, grad_norm=1.7276192903518677, loss=3.954376697540283
I0303 03:12:25.288531 139758009304832 logging_writer.py:48] [115300] global_step=115300, grad_norm=1.8395599126815796, loss=1.8479936122894287
I0303 03:13:10.271466 139758017697536 logging_writer.py:48] [115400] global_step=115400, grad_norm=1.4226986169815063, loss=2.7068238258361816
I0303 03:13:55.338828 139758009304832 logging_writer.py:48] [115500] global_step=115500, grad_norm=1.6729750633239746, loss=1.8646224737167358
I0303 03:14:28.582416 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:14:39.615643 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 03:14:58.008151 139953291118400 spec.py:349] Evaluating on the test split.
I0303 03:14:59.642317 139953291118400 submission_runner.py:411] Time since start: 55139.82s, 	Step: 115575, 	{'train/accuracy': 0.7844336032867432, 'train/loss': 0.8428012132644653, 'validation/accuracy': 0.7099199891090393, 'validation/loss': 1.1657264232635498, 'validation/num_examples': 50000, 'test/accuracy': 0.5892000198364258, 'test/loss': 1.7851496934890747, 'test/num_examples': 10000, 'score': 51296.428337574005, 'total_duration': 55139.81853270531, 'accumulated_submission_time': 51296.428337574005, 'accumulated_eval_time': 3830.8059952259064, 'accumulated_logging_time': 6.634954214096069}
I0303 03:14:59.682366 139758017697536 logging_writer.py:48] [115575] accumulated_eval_time=3830.805995, accumulated_logging_time=6.634954, accumulated_submission_time=51296.428338, global_step=115575, preemption_count=0, score=51296.428338, test/accuracy=0.589200, test/loss=1.785150, test/num_examples=10000, total_duration=55139.818533, train/accuracy=0.784434, train/loss=0.842801, validation/accuracy=0.709920, validation/loss=1.165726, validation/num_examples=50000
I0303 03:15:09.983502 139758009304832 logging_writer.py:48] [115600] global_step=115600, grad_norm=1.6997640132904053, loss=3.092214345932007
I0303 03:15:52.625912 139758017697536 logging_writer.py:48] [115700] global_step=115700, grad_norm=1.6225861310958862, loss=1.913585901260376
I0303 03:16:37.553666 139758009304832 logging_writer.py:48] [115800] global_step=115800, grad_norm=1.736840844154358, loss=1.7938573360443115
I0303 03:17:22.548857 139758017697536 logging_writer.py:48] [115900] global_step=115900, grad_norm=1.6345211267471313, loss=1.8041685819625854
I0303 03:18:07.509080 139758009304832 logging_writer.py:48] [116000] global_step=116000, grad_norm=1.4901219606399536, loss=3.4505059719085693
I0303 03:18:52.418678 139758017697536 logging_writer.py:48] [116100] global_step=116100, grad_norm=1.813204288482666, loss=4.006491661071777
I0303 03:19:37.247512 139758009304832 logging_writer.py:48] [116200] global_step=116200, grad_norm=1.6581250429153442, loss=3.686018466949463
I0303 03:20:22.084798 139758017697536 logging_writer.py:48] [116300] global_step=116300, grad_norm=1.862964153289795, loss=1.8474009037017822
I0303 03:21:07.158666 139758009304832 logging_writer.py:48] [116400] global_step=116400, grad_norm=1.6832020282745361, loss=3.463296890258789
I0303 03:21:51.845380 139758017697536 logging_writer.py:48] [116500] global_step=116500, grad_norm=1.9265575408935547, loss=1.7494935989379883
I0303 03:21:59.977993 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:22:11.149126 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 03:22:31.081580 139953291118400 spec.py:349] Evaluating on the test split.
I0303 03:22:32.720530 139953291118400 submission_runner.py:411] Time since start: 55592.90s, 	Step: 116520, 	{'train/accuracy': 0.7871679663658142, 'train/loss': 0.8348548412322998, 'validation/accuracy': 0.7083399891853333, 'validation/loss': 1.1812052726745605, 'validation/num_examples': 50000, 'test/accuracy': 0.5809000134468079, 'test/loss': 1.824753761291504, 'test/num_examples': 10000, 'score': 51716.66536331177, 'total_duration': 55592.896742105484, 'accumulated_submission_time': 51716.66536331177, 'accumulated_eval_time': 3863.548504590988, 'accumulated_logging_time': 6.685975074768066}
I0303 03:22:32.760423 139758009304832 logging_writer.py:48] [116520] accumulated_eval_time=3863.548505, accumulated_logging_time=6.685975, accumulated_submission_time=51716.665363, global_step=116520, preemption_count=0, score=51716.665363, test/accuracy=0.580900, test/loss=1.824754, test/num_examples=10000, total_duration=55592.896742, train/accuracy=0.787168, train/loss=0.834855, validation/accuracy=0.708340, validation/loss=1.181205, validation/num_examples=50000
I0303 03:23:05.291064 139758017697536 logging_writer.py:48] [116600] global_step=116600, grad_norm=1.7510522603988647, loss=1.8154515027999878
I0303 03:23:50.154433 139758009304832 logging_writer.py:48] [116700] global_step=116700, grad_norm=1.656708836555481, loss=1.7692861557006836
I0303 03:24:35.029853 139758017697536 logging_writer.py:48] [116800] global_step=116800, grad_norm=1.6586315631866455, loss=1.7763457298278809
I0303 03:25:20.006050 139758009304832 logging_writer.py:48] [116900] global_step=116900, grad_norm=1.8412609100341797, loss=1.9955147504806519
I0303 03:26:05.172564 139758017697536 logging_writer.py:48] [117000] global_step=117000, grad_norm=1.6212812662124634, loss=3.865323543548584
I0303 03:26:50.076196 139758009304832 logging_writer.py:48] [117100] global_step=117100, grad_norm=1.542845368385315, loss=1.8758550882339478
I0303 03:27:34.782111 139758017697536 logging_writer.py:48] [117200] global_step=117200, grad_norm=1.6070393323898315, loss=2.526782989501953
I0303 03:28:19.888091 139758009304832 logging_writer.py:48] [117300] global_step=117300, grad_norm=1.6535371541976929, loss=1.6816256046295166
I0303 03:29:04.812847 139758017697536 logging_writer.py:48] [117400] global_step=117400, grad_norm=1.8048535585403442, loss=3.824911594390869
I0303 03:29:32.860123 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:29:43.700639 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 03:30:01.898889 139953291118400 spec.py:349] Evaluating on the test split.
I0303 03:30:03.548376 139953291118400 submission_runner.py:411] Time since start: 56043.72s, 	Step: 117464, 	{'train/accuracy': 0.7781640291213989, 'train/loss': 0.8482047319412231, 'validation/accuracy': 0.7140199542045593, 'validation/loss': 1.1441729068756104, 'validation/num_examples': 50000, 'test/accuracy': 0.5915000438690186, 'test/loss': 1.7694329023361206, 'test/num_examples': 10000, 'score': 52136.707661151886, 'total_duration': 56043.724599123, 'accumulated_submission_time': 52136.707661151886, 'accumulated_eval_time': 3894.2367289066315, 'accumulated_logging_time': 6.735541582107544}
I0303 03:30:03.587914 139758009304832 logging_writer.py:48] [117464] accumulated_eval_time=3894.236729, accumulated_logging_time=6.735542, accumulated_submission_time=52136.707661, global_step=117464, preemption_count=0, score=52136.707661, test/accuracy=0.591500, test/loss=1.769433, test/num_examples=10000, total_duration=56043.724599, train/accuracy=0.778164, train/loss=0.848205, validation/accuracy=0.714020, validation/loss=1.144173, validation/num_examples=50000
I0303 03:30:18.230896 139758017697536 logging_writer.py:48] [117500] global_step=117500, grad_norm=1.9284473657608032, loss=1.775527000427246
I0303 03:31:00.835978 139758009304832 logging_writer.py:48] [117600] global_step=117600, grad_norm=1.712774634361267, loss=1.9321922063827515
I0303 03:31:46.160643 139758017697536 logging_writer.py:48] [117700] global_step=117700, grad_norm=1.614336609840393, loss=2.50418758392334
I0303 03:32:31.315617 139758009304832 logging_writer.py:48] [117800] global_step=117800, grad_norm=1.6817411184310913, loss=2.8375473022460938
I0303 03:33:16.236544 139758017697536 logging_writer.py:48] [117900] global_step=117900, grad_norm=1.5978187322616577, loss=2.1011240482330322
I0303 03:34:01.114087 139758009304832 logging_writer.py:48] [118000] global_step=118000, grad_norm=1.6506989002227783, loss=1.7526415586471558
I0303 03:34:46.434258 139758017697536 logging_writer.py:48] [118100] global_step=118100, grad_norm=1.686663269996643, loss=1.7086063623428345
I0303 03:35:31.303693 139758009304832 logging_writer.py:48] [118200] global_step=118200, grad_norm=1.747101902961731, loss=4.153797626495361
I0303 03:36:16.501419 139758017697536 logging_writer.py:48] [118300] global_step=118300, grad_norm=2.161698341369629, loss=1.8094427585601807
I0303 03:37:01.717031 139758009304832 logging_writer.py:48] [118400] global_step=118400, grad_norm=1.7269330024719238, loss=1.6561778783798218
I0303 03:37:03.650799 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:37:14.495595 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 03:37:33.240278 139953291118400 spec.py:349] Evaluating on the test split.
I0303 03:37:34.873835 139953291118400 submission_runner.py:411] Time since start: 56495.05s, 	Step: 118406, 	{'train/accuracy': 0.7785351276397705, 'train/loss': 0.8815587162971497, 'validation/accuracy': 0.709119975566864, 'validation/loss': 1.1885517835617065, 'validation/num_examples': 50000, 'test/accuracy': 0.586400032043457, 'test/loss': 1.818394660949707, 'test/num_examples': 10000, 'score': 52556.71144080162, 'total_duration': 56495.050055503845, 'accumulated_submission_time': 52556.71144080162, 'accumulated_eval_time': 3925.459734916687, 'accumulated_logging_time': 6.7867701053619385}
I0303 03:37:34.913496 139758017697536 logging_writer.py:48] [118406] accumulated_eval_time=3925.459735, accumulated_logging_time=6.786770, accumulated_submission_time=52556.711441, global_step=118406, preemption_count=0, score=52556.711441, test/accuracy=0.586400, test/loss=1.818395, test/num_examples=10000, total_duration=56495.050056, train/accuracy=0.778535, train/loss=0.881559, validation/accuracy=0.709120, validation/loss=1.188552, validation/num_examples=50000
I0303 03:38:13.091318 139758009304832 logging_writer.py:48] [118500] global_step=118500, grad_norm=1.6524317264556885, loss=1.7819749116897583
I0303 03:38:58.023037 139758017697536 logging_writer.py:48] [118600] global_step=118600, grad_norm=1.7269470691680908, loss=1.7713395357131958
I0303 03:39:43.009457 139758009304832 logging_writer.py:48] [118700] global_step=118700, grad_norm=1.7232156991958618, loss=3.6720364093780518
I0303 03:40:28.218446 139758017697536 logging_writer.py:48] [118800] global_step=118800, grad_norm=1.8768867254257202, loss=4.081183433532715
I0303 03:41:13.138341 139758009304832 logging_writer.py:48] [118900] global_step=118900, grad_norm=1.7238386869430542, loss=1.803037405014038
I0303 03:41:58.042613 139758017697536 logging_writer.py:48] [119000] global_step=119000, grad_norm=1.7331364154815674, loss=1.7723933458328247
I0303 03:42:42.906576 139758009304832 logging_writer.py:48] [119100] global_step=119100, grad_norm=1.7212580442428589, loss=3.1794087886810303
I0303 03:43:27.803570 139758017697536 logging_writer.py:48] [119200] global_step=119200, grad_norm=1.6129305362701416, loss=3.0497686862945557
I0303 03:44:12.919733 139758009304832 logging_writer.py:48] [119300] global_step=119300, grad_norm=1.7443712949752808, loss=1.77613365650177
I0303 03:44:35.177177 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:44:45.959013 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 03:45:05.139187 139953291118400 spec.py:349] Evaluating on the test split.
I0303 03:45:06.768332 139953291118400 submission_runner.py:411] Time since start: 56946.94s, 	Step: 119351, 	{'train/accuracy': 0.7892773151397705, 'train/loss': 0.8121300935745239, 'validation/accuracy': 0.7165200114250183, 'validation/loss': 1.1363714933395386, 'validation/num_examples': 50000, 'test/accuracy': 0.5924000144004822, 'test/loss': 1.7503550052642822, 'test/num_examples': 10000, 'score': 52976.91713619232, 'total_duration': 56946.944548368454, 'accumulated_submission_time': 52976.91713619232, 'accumulated_eval_time': 3957.0508601665497, 'accumulated_logging_time': 6.83685827255249}
I0303 03:45:06.808559 139758017697536 logging_writer.py:48] [119351] accumulated_eval_time=3957.050860, accumulated_logging_time=6.836858, accumulated_submission_time=52976.917136, global_step=119351, preemption_count=0, score=52976.917136, test/accuracy=0.592400, test/loss=1.750355, test/num_examples=10000, total_duration=56946.944548, train/accuracy=0.789277, train/loss=0.812130, validation/accuracy=0.716520, validation/loss=1.136371, validation/num_examples=50000
I0303 03:45:26.580057 139758009304832 logging_writer.py:48] [119400] global_step=119400, grad_norm=2.0035712718963623, loss=4.298068046569824
I0303 03:46:09.617661 139758017697536 logging_writer.py:48] [119500] global_step=119500, grad_norm=1.7795625925064087, loss=1.7832109928131104
I0303 03:46:54.830590 139758009304832 logging_writer.py:48] [119600] global_step=119600, grad_norm=1.645703911781311, loss=3.6992506980895996
I0303 03:47:39.845396 139758017697536 logging_writer.py:48] [119700] global_step=119700, grad_norm=1.7949738502502441, loss=2.048985481262207
I0303 03:48:24.629219 139758009304832 logging_writer.py:48] [119800] global_step=119800, grad_norm=1.7203139066696167, loss=1.932060956954956
I0303 03:49:09.757092 139758017697536 logging_writer.py:48] [119900] global_step=119900, grad_norm=1.919489860534668, loss=1.685381293296814
I0303 03:49:54.734140 139758009304832 logging_writer.py:48] [120000] global_step=120000, grad_norm=1.7251827716827393, loss=2.022554397583008
I0303 03:50:39.918697 139758017697536 logging_writer.py:48] [120100] global_step=120100, grad_norm=1.9780808687210083, loss=3.8873260021209717
I0303 03:51:24.619100 139758009304832 logging_writer.py:48] [120200] global_step=120200, grad_norm=1.8432241678237915, loss=1.7861124277114868
I0303 03:52:07.058568 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:52:17.710224 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 03:52:38.199545 139953291118400 spec.py:349] Evaluating on the test split.
I0303 03:52:39.835284 139953291118400 submission_runner.py:411] Time since start: 57400.01s, 	Step: 120296, 	{'train/accuracy': 0.8076757788658142, 'train/loss': 0.7323868274688721, 'validation/accuracy': 0.7183399796485901, 'validation/loss': 1.1285380125045776, 'validation/num_examples': 50000, 'test/accuracy': 0.5946000218391418, 'test/loss': 1.7501553297042847, 'test/num_examples': 10000, 'score': 53397.10926628113, 'total_duration': 57400.011506319046, 'accumulated_submission_time': 53397.10926628113, 'accumulated_eval_time': 3989.8275697231293, 'accumulated_logging_time': 6.887446403503418}
I0303 03:52:39.879659 139758017697536 logging_writer.py:48] [120296] accumulated_eval_time=3989.827570, accumulated_logging_time=6.887446, accumulated_submission_time=53397.109266, global_step=120296, preemption_count=0, score=53397.109266, test/accuracy=0.594600, test/loss=1.750155, test/num_examples=10000, total_duration=57400.011506, train/accuracy=0.807676, train/loss=0.732387, validation/accuracy=0.718340, validation/loss=1.128538, validation/num_examples=50000
I0303 03:52:41.854395 139758009304832 logging_writer.py:48] [120300] global_step=120300, grad_norm=1.6943888664245605, loss=1.754784345626831
I0303 03:53:21.716354 139758017697536 logging_writer.py:48] [120400] global_step=120400, grad_norm=1.688438892364502, loss=1.7867218255996704
I0303 03:54:06.480818 139758009304832 logging_writer.py:48] [120500] global_step=120500, grad_norm=1.755037784576416, loss=1.700331687927246
I0303 03:54:51.463956 139758017697536 logging_writer.py:48] [120600] global_step=120600, grad_norm=1.9157263040542603, loss=2.5933611392974854
I0303 03:55:36.709915 139758009304832 logging_writer.py:48] [120700] global_step=120700, grad_norm=1.6681798696517944, loss=2.065670967102051
I0303 03:56:21.652196 139758017697536 logging_writer.py:48] [120800] global_step=120800, grad_norm=1.6923366785049438, loss=3.3004283905029297
I0303 03:57:06.405045 139758009304832 logging_writer.py:48] [120900] global_step=120900, grad_norm=1.6676349639892578, loss=2.9356331825256348
I0303 03:57:51.412850 139758017697536 logging_writer.py:48] [121000] global_step=121000, grad_norm=1.8778637647628784, loss=3.4853878021240234
I0303 03:58:36.481686 139758009304832 logging_writer.py:48] [121100] global_step=121100, grad_norm=1.6710891723632812, loss=2.215317964553833
I0303 03:59:21.251573 139758017697536 logging_writer.py:48] [121200] global_step=121200, grad_norm=1.8906631469726562, loss=1.763240933418274
I0303 03:59:39.858555 139953291118400 spec.py:321] Evaluating on the training split.
I0303 03:59:50.480209 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:00:13.432547 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:00:15.059411 139953291118400 submission_runner.py:411] Time since start: 57855.24s, 	Step: 121243, 	{'train/accuracy': 0.7827538847923279, 'train/loss': 0.8527898192405701, 'validation/accuracy': 0.7153399586677551, 'validation/loss': 1.1425896883010864, 'validation/num_examples': 50000, 'test/accuracy': 0.596500039100647, 'test/loss': 1.758715271949768, 'test/num_examples': 10000, 'score': 53817.029266119, 'total_duration': 57855.23564505577, 'accumulated_submission_time': 53817.029266119, 'accumulated_eval_time': 4025.0284378528595, 'accumulated_logging_time': 6.941509246826172}
I0303 04:00:15.098570 139758009304832 logging_writer.py:48] [121243] accumulated_eval_time=4025.028438, accumulated_logging_time=6.941509, accumulated_submission_time=53817.029266, global_step=121243, preemption_count=0, score=53817.029266, test/accuracy=0.596500, test/loss=1.758715, test/num_examples=10000, total_duration=57855.235645, train/accuracy=0.782754, train/loss=0.852790, validation/accuracy=0.715340, validation/loss=1.142590, validation/num_examples=50000
I0303 04:00:38.004739 139758017697536 logging_writer.py:48] [121300] global_step=121300, grad_norm=1.764374852180481, loss=1.7328606843948364
I0303 04:01:20.440121 139758009304832 logging_writer.py:48] [121400] global_step=121400, grad_norm=1.8369059562683105, loss=1.7117040157318115
I0303 04:02:05.121695 139758017697536 logging_writer.py:48] [121500] global_step=121500, grad_norm=1.6491289138793945, loss=1.666847825050354
I0303 04:02:50.321709 139758009304832 logging_writer.py:48] [121600] global_step=121600, grad_norm=1.664727807044983, loss=2.2018015384674072
I0303 04:03:35.153736 139758017697536 logging_writer.py:48] [121700] global_step=121700, grad_norm=1.7066376209259033, loss=1.8660218715667725
I0303 04:04:20.003173 139758009304832 logging_writer.py:48] [121800] global_step=121800, grad_norm=1.6640713214874268, loss=1.7267035245895386
I0303 04:05:05.055737 139758017697536 logging_writer.py:48] [121900] global_step=121900, grad_norm=1.759652018547058, loss=3.403470516204834
I0303 04:05:49.881020 139758009304832 logging_writer.py:48] [122000] global_step=122000, grad_norm=1.6030182838439941, loss=2.79470157623291
I0303 04:06:34.976939 139758017697536 logging_writer.py:48] [122100] global_step=122100, grad_norm=2.1686699390411377, loss=4.22364616394043
I0303 04:07:15.135987 139953291118400 spec.py:321] Evaluating on the training split.
I0303 04:07:26.135222 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:07:44.949227 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:07:46.580618 139953291118400 submission_runner.py:411] Time since start: 58306.76s, 	Step: 122191, 	{'train/accuracy': 0.7879882454872131, 'train/loss': 0.8077414631843567, 'validation/accuracy': 0.7186999917030334, 'validation/loss': 1.1167722940444946, 'validation/num_examples': 50000, 'test/accuracy': 0.5915000438690186, 'test/loss': 1.7542343139648438, 'test/num_examples': 10000, 'score': 54237.009996175766, 'total_duration': 58306.75683450699, 'accumulated_submission_time': 54237.009996175766, 'accumulated_eval_time': 4056.473051548004, 'accumulated_logging_time': 6.989522695541382}
I0303 04:07:46.621575 139758009304832 logging_writer.py:48] [122191] accumulated_eval_time=4056.473052, accumulated_logging_time=6.989523, accumulated_submission_time=54237.009996, global_step=122191, preemption_count=0, score=54237.009996, test/accuracy=0.591500, test/loss=1.754234, test/num_examples=10000, total_duration=58306.756835, train/accuracy=0.787988, train/loss=0.807741, validation/accuracy=0.718700, validation/loss=1.116772, validation/num_examples=50000
I0303 04:07:50.577888 139758017697536 logging_writer.py:48] [122200] global_step=122200, grad_norm=1.7332395315170288, loss=3.235079288482666
I0303 04:08:31.937695 139758009304832 logging_writer.py:48] [122300] global_step=122300, grad_norm=1.6366761922836304, loss=2.2534947395324707
I0303 04:09:16.519065 139758017697536 logging_writer.py:48] [122400] global_step=122400, grad_norm=1.6385939121246338, loss=2.534341335296631
I0303 04:10:01.431044 139758009304832 logging_writer.py:48] [122500] global_step=122500, grad_norm=1.786996841430664, loss=2.655301094055176
I0303 04:10:46.907572 139758017697536 logging_writer.py:48] [122600] global_step=122600, grad_norm=2.1140286922454834, loss=1.7188295125961304
I0303 04:11:31.617023 139758009304832 logging_writer.py:48] [122700] global_step=122700, grad_norm=1.8821220397949219, loss=1.738301396369934
I0303 04:12:16.362862 139758017697536 logging_writer.py:48] [122800] global_step=122800, grad_norm=1.868377923965454, loss=1.6336696147918701
I0303 04:13:01.323159 139758009304832 logging_writer.py:48] [122900] global_step=122900, grad_norm=1.6162697076797485, loss=1.797359824180603
I0303 04:13:46.278058 139758017697536 logging_writer.py:48] [123000] global_step=123000, grad_norm=1.6647753715515137, loss=3.290506601333618
I0303 04:14:30.977720 139758009304832 logging_writer.py:48] [123100] global_step=123100, grad_norm=1.7050026655197144, loss=1.6648955345153809
I0303 04:14:46.884359 139953291118400 spec.py:321] Evaluating on the training split.
I0303 04:14:58.086406 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:15:16.526704 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:15:18.160462 139953291118400 submission_runner.py:411] Time since start: 58758.34s, 	Step: 123137, 	{'train/accuracy': 0.80322265625, 'train/loss': 0.7724707722663879, 'validation/accuracy': 0.7219600081443787, 'validation/loss': 1.1197479963302612, 'validation/num_examples': 50000, 'test/accuracy': 0.6009000539779663, 'test/loss': 1.7268176078796387, 'test/num_examples': 10000, 'score': 54657.21346616745, 'total_duration': 58758.33668446541, 'accumulated_submission_time': 54657.21346616745, 'accumulated_eval_time': 4087.7491562366486, 'accumulated_logging_time': 7.041682243347168}
I0303 04:15:18.201439 139758017697536 logging_writer.py:48] [123137] accumulated_eval_time=4087.749156, accumulated_logging_time=7.041682, accumulated_submission_time=54657.213466, global_step=123137, preemption_count=0, score=54657.213466, test/accuracy=0.600900, test/loss=1.726818, test/num_examples=10000, total_duration=58758.336684, train/accuracy=0.803223, train/loss=0.772471, validation/accuracy=0.721960, validation/loss=1.119748, validation/num_examples=50000
I0303 04:15:43.463124 139758009304832 logging_writer.py:48] [123200] global_step=123200, grad_norm=1.9999139308929443, loss=3.6118857860565186
I0303 04:16:27.883287 139758017697536 logging_writer.py:48] [123300] global_step=123300, grad_norm=1.6445075273513794, loss=3.0607872009277344
I0303 04:17:12.680980 139758009304832 logging_writer.py:48] [123400] global_step=123400, grad_norm=1.6838973760604858, loss=3.143028736114502
I0303 04:17:57.653419 139758017697536 logging_writer.py:48] [123500] global_step=123500, grad_norm=1.7055690288543701, loss=1.9197735786437988
I0303 04:18:42.677882 139758009304832 logging_writer.py:48] [123600] global_step=123600, grad_norm=1.7218043804168701, loss=1.8161463737487793
I0303 04:19:27.656787 139758017697536 logging_writer.py:48] [123700] global_step=123700, grad_norm=1.875382423400879, loss=1.498073697090149
I0303 04:20:12.695790 139758009304832 logging_writer.py:48] [123800] global_step=123800, grad_norm=1.7344965934753418, loss=1.5438910722732544
I0303 04:20:58.052992 139758017697536 logging_writer.py:48] [123900] global_step=123900, grad_norm=1.9713488817214966, loss=2.876725912094116
I0303 04:21:43.011528 139758009304832 logging_writer.py:48] [124000] global_step=124000, grad_norm=1.8738845586776733, loss=1.6816190481185913
I0303 04:22:18.504426 139953291118400 spec.py:321] Evaluating on the training split.
I0303 04:22:29.177936 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:22:49.658255 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:22:51.297890 139953291118400 submission_runner.py:411] Time since start: 59211.47s, 	Step: 124081, 	{'train/accuracy': 0.7920898199081421, 'train/loss': 0.8035741448402405, 'validation/accuracy': 0.7215999960899353, 'validation/loss': 1.1221164464950562, 'validation/num_examples': 50000, 'test/accuracy': 0.6030000448226929, 'test/loss': 1.7267364263534546, 'test/num_examples': 10000, 'score': 55077.45772242546, 'total_duration': 59211.474113702774, 'accumulated_submission_time': 55077.45772242546, 'accumulated_eval_time': 4120.542637825012, 'accumulated_logging_time': 7.0932228565216064}
I0303 04:22:51.343244 139758017697536 logging_writer.py:48] [124081] accumulated_eval_time=4120.542638, accumulated_logging_time=7.093223, accumulated_submission_time=55077.457722, global_step=124081, preemption_count=0, score=55077.457722, test/accuracy=0.603000, test/loss=1.726736, test/num_examples=10000, total_duration=59211.474114, train/accuracy=0.792090, train/loss=0.803574, validation/accuracy=0.721600, validation/loss=1.122116, validation/num_examples=50000
I0303 04:22:59.250598 139758009304832 logging_writer.py:48] [124100] global_step=124100, grad_norm=1.8998281955718994, loss=3.684196710586548
I0303 04:23:40.264199 139758017697536 logging_writer.py:48] [124200] global_step=124200, grad_norm=1.8564130067825317, loss=1.658225178718567
I0303 04:24:25.179146 139758009304832 logging_writer.py:48] [124300] global_step=124300, grad_norm=1.8529605865478516, loss=3.9631259441375732
I0303 04:25:10.325930 139758017697536 logging_writer.py:48] [124400] global_step=124400, grad_norm=1.8740155696868896, loss=1.7737998962402344
I0303 04:25:55.313206 139758009304832 logging_writer.py:48] [124500] global_step=124500, grad_norm=1.7672559022903442, loss=1.77671217918396
I0303 04:26:40.283616 139758017697536 logging_writer.py:48] [124600] global_step=124600, grad_norm=1.7511839866638184, loss=1.7227962017059326
I0303 04:27:25.162484 139758009304832 logging_writer.py:48] [124700] global_step=124700, grad_norm=1.7978342771530151, loss=2.067532539367676
I0303 04:28:10.056541 139758017697536 logging_writer.py:48] [124800] global_step=124800, grad_norm=1.8283283710479736, loss=1.6303447484970093
I0303 04:28:54.604348 139758009304832 logging_writer.py:48] [124900] global_step=124900, grad_norm=1.764112114906311, loss=1.7387840747833252
I0303 04:29:39.283119 139758017697536 logging_writer.py:48] [125000] global_step=125000, grad_norm=1.82411527633667, loss=3.4774742126464844
I0303 04:29:51.455268 139953291118400 spec.py:321] Evaluating on the training split.
I0303 04:30:02.515729 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:30:19.850114 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:30:21.495112 139953291118400 submission_runner.py:411] Time since start: 59661.67s, 	Step: 125028, 	{'train/accuracy': 0.7930859327316284, 'train/loss': 0.8153924345970154, 'validation/accuracy': 0.7215200066566467, 'validation/loss': 1.1258158683776855, 'validation/num_examples': 50000, 'test/accuracy': 0.5985000133514404, 'test/loss': 1.7480947971343994, 'test/num_examples': 10000, 'score': 55497.51085400581, 'total_duration': 59661.67133617401, 'accumulated_submission_time': 55497.51085400581, 'accumulated_eval_time': 4150.5824637413025, 'accumulated_logging_time': 7.149578332901001}
I0303 04:30:21.535984 139758009304832 logging_writer.py:48] [125028] accumulated_eval_time=4150.582464, accumulated_logging_time=7.149578, accumulated_submission_time=55497.510854, global_step=125028, preemption_count=0, score=55497.510854, test/accuracy=0.598500, test/loss=1.748095, test/num_examples=10000, total_duration=59661.671336, train/accuracy=0.793086, train/loss=0.815392, validation/accuracy=0.721520, validation/loss=1.125816, validation/num_examples=50000
I0303 04:30:50.410806 139758017697536 logging_writer.py:48] [125100] global_step=125100, grad_norm=1.8948043584823608, loss=1.719596028327942
I0303 04:31:35.351958 139758009304832 logging_writer.py:48] [125200] global_step=125200, grad_norm=1.8634734153747559, loss=3.095820903778076
I0303 04:32:20.482535 139758017697536 logging_writer.py:48] [125300] global_step=125300, grad_norm=1.8357458114624023, loss=1.9810314178466797
I0303 04:33:05.753446 139758009304832 logging_writer.py:48] [125400] global_step=125400, grad_norm=2.010993719100952, loss=1.6221610307693481
I0303 04:33:50.365321 139758017697536 logging_writer.py:48] [125500] global_step=125500, grad_norm=1.9554731845855713, loss=1.7226381301879883
I0303 04:34:35.257493 139758009304832 logging_writer.py:48] [125600] global_step=125600, grad_norm=1.7169359922409058, loss=2.654517412185669
I0303 04:35:20.239435 139758017697536 logging_writer.py:48] [125700] global_step=125700, grad_norm=1.9894232749938965, loss=3.2460663318634033
I0303 04:36:05.096360 139758009304832 logging_writer.py:48] [125800] global_step=125800, grad_norm=1.7004785537719727, loss=2.8509976863861084
I0303 04:36:49.976981 139758017697536 logging_writer.py:48] [125900] global_step=125900, grad_norm=1.7608081102371216, loss=1.8655766248703003
I0303 04:37:21.673254 139953291118400 spec.py:321] Evaluating on the training split.
I0303 04:37:32.764041 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:37:53.193016 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:37:54.826073 139953291118400 submission_runner.py:411] Time since start: 60115.00s, 	Step: 125972, 	{'train/accuracy': 0.8003320097923279, 'train/loss': 0.7735731601715088, 'validation/accuracy': 0.7224999666213989, 'validation/loss': 1.1156514883041382, 'validation/num_examples': 50000, 'test/accuracy': 0.5933000445365906, 'test/loss': 1.7462410926818848, 'test/num_examples': 10000, 'score': 55917.58813285828, 'total_duration': 60115.00229549408, 'accumulated_submission_time': 55917.58813285828, 'accumulated_eval_time': 4183.735275506973, 'accumulated_logging_time': 7.201582193374634}
I0303 04:37:54.866729 139758009304832 logging_writer.py:48] [125972] accumulated_eval_time=4183.735276, accumulated_logging_time=7.201582, accumulated_submission_time=55917.588133, global_step=125972, preemption_count=0, score=55917.588133, test/accuracy=0.593300, test/loss=1.746241, test/num_examples=10000, total_duration=60115.002295, train/accuracy=0.800332, train/loss=0.773573, validation/accuracy=0.722500, validation/loss=1.115651, validation/num_examples=50000
I0303 04:38:06.343291 139758017697536 logging_writer.py:48] [126000] global_step=126000, grad_norm=1.6632062196731567, loss=2.0799431800842285
I0303 04:38:48.111152 139758009304832 logging_writer.py:48] [126100] global_step=126100, grad_norm=1.665130615234375, loss=2.962165594100952
I0303 04:39:33.216925 139758017697536 logging_writer.py:48] [126200] global_step=126200, grad_norm=1.776612401008606, loss=2.100585699081421
I0303 04:40:18.073859 139758009304832 logging_writer.py:48] [126300] global_step=126300, grad_norm=1.6321570873260498, loss=2.8056066036224365
I0303 04:41:03.286598 139758017697536 logging_writer.py:48] [126400] global_step=126400, grad_norm=1.9365687370300293, loss=1.821775197982788
I0303 04:41:48.013277 139758009304832 logging_writer.py:48] [126500] global_step=126500, grad_norm=1.874996304512024, loss=1.7149587869644165
I0303 04:42:32.915406 139758017697536 logging_writer.py:48] [126600] global_step=126600, grad_norm=2.1138532161712646, loss=4.097327709197998
I0303 04:43:18.260766 139758009304832 logging_writer.py:48] [126700] global_step=126700, grad_norm=1.8186603784561157, loss=1.613081693649292
I0303 04:44:03.527439 139758017697536 logging_writer.py:48] [126800] global_step=126800, grad_norm=1.7375924587249756, loss=2.3190057277679443
I0303 04:44:48.415738 139758009304832 logging_writer.py:48] [126900] global_step=126900, grad_norm=2.0095462799072266, loss=1.7497224807739258
I0303 04:44:54.915531 139953291118400 spec.py:321] Evaluating on the training split.
I0303 04:45:05.797759 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:45:23.928175 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:45:25.600799 139953291118400 submission_runner.py:411] Time since start: 60565.78s, 	Step: 126916, 	{'train/accuracy': 0.8159765601158142, 'train/loss': 0.7205840945243835, 'validation/accuracy': 0.7251399755477905, 'validation/loss': 1.105201005935669, 'validation/num_examples': 50000, 'test/accuracy': 0.6083000302314758, 'test/loss': 1.7146964073181152, 'test/num_examples': 10000, 'score': 56337.57939887047, 'total_duration': 60565.776963710785, 'accumulated_submission_time': 56337.57939887047, 'accumulated_eval_time': 4214.42046713829, 'accumulated_logging_time': 7.252074480056763}
I0303 04:45:25.666717 139758017697536 logging_writer.py:48] [126916] accumulated_eval_time=4214.420467, accumulated_logging_time=7.252074, accumulated_submission_time=56337.579399, global_step=126916, preemption_count=0, score=56337.579399, test/accuracy=0.608300, test/loss=1.714696, test/num_examples=10000, total_duration=60565.776964, train/accuracy=0.815977, train/loss=0.720584, validation/accuracy=0.725140, validation/loss=1.105201, validation/num_examples=50000
I0303 04:45:59.269899 139758009304832 logging_writer.py:48] [127000] global_step=127000, grad_norm=2.002265691757202, loss=1.765071988105774
I0303 04:46:43.292216 139758017697536 logging_writer.py:48] [127100] global_step=127100, grad_norm=2.127908945083618, loss=1.7453988790512085
I0303 04:47:28.329145 139758009304832 logging_writer.py:48] [127200] global_step=127200, grad_norm=2.160950183868408, loss=4.007537841796875
I0303 04:48:13.730233 139758017697536 logging_writer.py:48] [127300] global_step=127300, grad_norm=1.80125892162323, loss=1.6605830192565918
I0303 04:48:58.610305 139758009304832 logging_writer.py:48] [127400] global_step=127400, grad_norm=1.892199158668518, loss=1.650956153869629
I0303 04:49:43.362283 139758017697536 logging_writer.py:48] [127500] global_step=127500, grad_norm=1.8292078971862793, loss=1.9079618453979492
I0303 04:50:28.394996 139758009304832 logging_writer.py:48] [127600] global_step=127600, grad_norm=1.8431687355041504, loss=1.7257003784179688
I0303 04:51:13.306538 139758017697536 logging_writer.py:48] [127700] global_step=127700, grad_norm=1.9400187730789185, loss=1.662328839302063
I0303 04:51:58.077852 139758009304832 logging_writer.py:48] [127800] global_step=127800, grad_norm=1.738876461982727, loss=2.1262876987457275
I0303 04:52:25.817023 139953291118400 spec.py:321] Evaluating on the training split.
I0303 04:52:36.821938 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 04:52:55.070539 139953291118400 spec.py:349] Evaluating on the test split.
I0303 04:52:56.703065 139953291118400 submission_runner.py:411] Time since start: 61016.88s, 	Step: 127863, 	{'train/accuracy': 0.8004687428474426, 'train/loss': 0.7621183395385742, 'validation/accuracy': 0.7263799905776978, 'validation/loss': 1.087070107460022, 'validation/num_examples': 50000, 'test/accuracy': 0.6078000068664551, 'test/loss': 1.6983314752578735, 'test/num_examples': 10000, 'score': 56757.66656923294, 'total_duration': 61016.87927532196, 'accumulated_submission_time': 56757.66656923294, 'accumulated_eval_time': 4245.306490898132, 'accumulated_logging_time': 7.332320213317871}
I0303 04:52:56.749773 139758017697536 logging_writer.py:48] [127863] accumulated_eval_time=4245.306491, accumulated_logging_time=7.332320, accumulated_submission_time=56757.666569, global_step=127863, preemption_count=0, score=56757.666569, test/accuracy=0.607800, test/loss=1.698331, test/num_examples=10000, total_duration=61016.879275, train/accuracy=0.800469, train/loss=0.762118, validation/accuracy=0.726380, validation/loss=1.087070, validation/num_examples=50000
I0303 04:53:11.772143 139758009304832 logging_writer.py:48] [127900] global_step=127900, grad_norm=1.8018792867660522, loss=2.3965091705322266
I0303 04:53:54.439381 139758017697536 logging_writer.py:48] [128000] global_step=128000, grad_norm=2.0268800258636475, loss=1.7912732362747192
I0303 04:54:39.009691 139758009304832 logging_writer.py:48] [128100] global_step=128100, grad_norm=1.7927424907684326, loss=1.5994200706481934
I0303 04:55:23.799027 139758017697536 logging_writer.py:48] [128200] global_step=128200, grad_norm=2.0331785678863525, loss=1.5980110168457031
I0303 04:56:08.559700 139758009304832 logging_writer.py:48] [128300] global_step=128300, grad_norm=2.1334080696105957, loss=1.7303671836853027
I0303 04:56:53.268267 139758017697536 logging_writer.py:48] [128400] global_step=128400, grad_norm=1.9041653871536255, loss=1.7227864265441895
I0303 04:57:38.186813 139758009304832 logging_writer.py:48] [128500] global_step=128500, grad_norm=1.9825390577316284, loss=2.985853433609009
I0303 04:58:23.244570 139758017697536 logging_writer.py:48] [128600] global_step=128600, grad_norm=1.9487793445587158, loss=1.625178337097168
I0303 04:59:08.233649 139758009304832 logging_writer.py:48] [128700] global_step=128700, grad_norm=1.9790211915969849, loss=3.968212366104126
I0303 04:59:53.050287 139758017697536 logging_writer.py:48] [128800] global_step=128800, grad_norm=1.7419356107711792, loss=2.820093870162964
I0303 04:59:56.823717 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:00:07.756057 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:00:28.412796 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:00:30.057574 139953291118400 submission_runner.py:411] Time since start: 61470.23s, 	Step: 128810, 	{'train/accuracy': 0.804492175579071, 'train/loss': 0.7556107044219971, 'validation/accuracy': 0.7278800010681152, 'validation/loss': 1.0926361083984375, 'validation/num_examples': 50000, 'test/accuracy': 0.6009000539779663, 'test/loss': 1.718663215637207, 'test/num_examples': 10000, 'score': 57177.68268537521, 'total_duration': 61470.233803510666, 'accumulated_submission_time': 57177.68268537521, 'accumulated_eval_time': 4278.540325880051, 'accumulated_logging_time': 7.388689041137695}
I0303 05:00:30.090800 139758009304832 logging_writer.py:48] [128810] accumulated_eval_time=4278.540326, accumulated_logging_time=7.388689, accumulated_submission_time=57177.682685, global_step=128810, preemption_count=0, score=57177.682685, test/accuracy=0.600900, test/loss=1.718663, test/num_examples=10000, total_duration=61470.233804, train/accuracy=0.804492, train/loss=0.755611, validation/accuracy=0.727880, validation/loss=1.092636, validation/num_examples=50000
I0303 05:01:06.050933 139758017697536 logging_writer.py:48] [128900] global_step=128900, grad_norm=1.8488272428512573, loss=2.210214614868164
I0303 05:01:50.138226 139758009304832 logging_writer.py:48] [129000] global_step=129000, grad_norm=1.8777750730514526, loss=2.077118396759033
I0303 05:02:35.107770 139758017697536 logging_writer.py:48] [129100] global_step=129100, grad_norm=1.9934413433074951, loss=1.732717752456665
I0303 05:03:20.315241 139758009304832 logging_writer.py:48] [129200] global_step=129200, grad_norm=1.8949549198150635, loss=1.702115535736084
I0303 05:04:05.184522 139758017697536 logging_writer.py:48] [129300] global_step=129300, grad_norm=2.184171438217163, loss=1.7155801057815552
I0303 05:04:49.959667 139758009304832 logging_writer.py:48] [129400] global_step=129400, grad_norm=1.9593491554260254, loss=1.7338452339172363
I0303 05:05:34.964056 139758017697536 logging_writer.py:48] [129500] global_step=129500, grad_norm=1.7872568368911743, loss=2.236628770828247
I0303 05:06:20.025711 139758009304832 logging_writer.py:48] [129600] global_step=129600, grad_norm=1.7768045663833618, loss=3.35782790184021
I0303 05:07:04.964212 139758017697536 logging_writer.py:48] [129700] global_step=129700, grad_norm=2.2899529933929443, loss=1.6171287298202515
I0303 05:07:30.213606 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:07:40.932683 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:08:00.648530 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:08:02.292689 139953291118400 submission_runner.py:411] Time since start: 61922.47s, 	Step: 129758, 	{'train/accuracy': 0.8183202743530273, 'train/loss': 0.6911411881446838, 'validation/accuracy': 0.730139970779419, 'validation/loss': 1.0635643005371094, 'validation/num_examples': 50000, 'test/accuracy': 0.6118000149726868, 'test/loss': 1.675654411315918, 'test/num_examples': 10000, 'score': 57597.74878168106, 'total_duration': 61922.46889066696, 'accumulated_submission_time': 57597.74878168106, 'accumulated_eval_time': 4310.619389057159, 'accumulated_logging_time': 7.430602788925171}
I0303 05:08:02.334464 139758009304832 logging_writer.py:48] [129758] accumulated_eval_time=4310.619389, accumulated_logging_time=7.430603, accumulated_submission_time=57597.748782, global_step=129758, preemption_count=0, score=57597.748782, test/accuracy=0.611800, test/loss=1.675654, test/num_examples=10000, total_duration=61922.468891, train/accuracy=0.818320, train/loss=0.691141, validation/accuracy=0.730140, validation/loss=1.063564, validation/num_examples=50000
I0303 05:08:19.324175 139758017697536 logging_writer.py:48] [129800] global_step=129800, grad_norm=2.1452159881591797, loss=1.6101659536361694
I0303 05:09:02.204927 139758009304832 logging_writer.py:48] [129900] global_step=129900, grad_norm=1.6871371269226074, loss=1.8746716976165771
I0303 05:09:47.002746 139758017697536 logging_writer.py:48] [130000] global_step=130000, grad_norm=1.8548407554626465, loss=2.180999279022217
I0303 05:10:32.137873 139758009304832 logging_writer.py:48] [130100] global_step=130100, grad_norm=2.181917905807495, loss=4.052333831787109
I0303 05:11:17.194622 139758017697536 logging_writer.py:48] [130200] global_step=130200, grad_norm=1.8668726682662964, loss=1.7569096088409424
I0303 05:12:01.950272 139758009304832 logging_writer.py:48] [130300] global_step=130300, grad_norm=2.045527935028076, loss=1.6318573951721191
I0303 05:12:47.213253 139758017697536 logging_writer.py:48] [130400] global_step=130400, grad_norm=1.8889399766921997, loss=1.6488769054412842
I0303 05:13:32.304952 139758009304832 logging_writer.py:48] [130500] global_step=130500, grad_norm=1.7621455192565918, loss=1.6530475616455078
I0303 05:14:17.275299 139758017697536 logging_writer.py:48] [130600] global_step=130600, grad_norm=2.0310750007629395, loss=1.6386321783065796
I0303 05:15:02.089350 139758009304832 logging_writer.py:48] [130700] global_step=130700, grad_norm=1.9743905067443848, loss=1.6335822343826294
I0303 05:15:02.351263 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:15:13.397788 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:15:37.843916 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:15:39.484463 139953291118400 submission_runner.py:411] Time since start: 62379.66s, 	Step: 130702, 	{'train/accuracy': 0.8029296398162842, 'train/loss': 0.7509654760360718, 'validation/accuracy': 0.731220006942749, 'validation/loss': 1.0709768533706665, 'validation/num_examples': 50000, 'test/accuracy': 0.6089000105857849, 'test/loss': 1.6937024593353271, 'test/num_examples': 10000, 'score': 58017.70781111717, 'total_duration': 62379.660683870316, 'accumulated_submission_time': 58017.70781111717, 'accumulated_eval_time': 4347.752557516098, 'accumulated_logging_time': 7.4818854331970215}
I0303 05:15:39.520129 139758017697536 logging_writer.py:48] [130702] accumulated_eval_time=4347.752558, accumulated_logging_time=7.481885, accumulated_submission_time=58017.707811, global_step=130702, preemption_count=0, score=58017.707811, test/accuracy=0.608900, test/loss=1.693702, test/num_examples=10000, total_duration=62379.660684, train/accuracy=0.802930, train/loss=0.750965, validation/accuracy=0.731220, validation/loss=1.070977, validation/num_examples=50000
I0303 05:16:18.667651 139758009304832 logging_writer.py:48] [130800] global_step=130800, grad_norm=2.1055753231048584, loss=1.54152250289917
I0303 05:17:03.393764 139758017697536 logging_writer.py:48] [130900] global_step=130900, grad_norm=1.9771537780761719, loss=2.454035758972168
I0303 05:17:48.313174 139758009304832 logging_writer.py:48] [131000] global_step=131000, grad_norm=2.0148508548736572, loss=1.6892364025115967
I0303 05:18:33.471073 139758017697536 logging_writer.py:48] [131100] global_step=131100, grad_norm=1.7411613464355469, loss=2.571613311767578
I0303 05:19:18.487232 139758009304832 logging_writer.py:48] [131200] global_step=131200, grad_norm=1.8564672470092773, loss=1.7183059453964233
I0303 05:20:03.481794 139758017697536 logging_writer.py:48] [131300] global_step=131300, grad_norm=1.909387230873108, loss=1.599908471107483
I0303 05:20:48.699150 139758009304832 logging_writer.py:48] [131400] global_step=131400, grad_norm=1.9968101978302002, loss=1.6025490760803223
I0303 05:21:33.884852 139758017697536 logging_writer.py:48] [131500] global_step=131500, grad_norm=1.9519779682159424, loss=1.645636796951294
I0303 05:22:18.753592 139758009304832 logging_writer.py:48] [131600] global_step=131600, grad_norm=1.9649111032485962, loss=3.5998101234436035
I0303 05:22:39.518795 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:22:50.382895 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:23:10.202413 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:23:11.843828 139953291118400 submission_runner.py:411] Time since start: 62832.02s, 	Step: 131648, 	{'train/accuracy': 0.80824214220047, 'train/loss': 0.7324361801147461, 'validation/accuracy': 0.7309799790382385, 'validation/loss': 1.0710631608963013, 'validation/num_examples': 50000, 'test/accuracy': 0.6130000352859497, 'test/loss': 1.677901268005371, 'test/num_examples': 10000, 'score': 58437.64938545227, 'total_duration': 62832.02004933357, 'accumulated_submission_time': 58437.64938545227, 'accumulated_eval_time': 4380.077574729919, 'accumulated_logging_time': 7.52693510055542}
I0303 05:23:11.888134 139758017697536 logging_writer.py:48] [131648] accumulated_eval_time=4380.077575, accumulated_logging_time=7.526935, accumulated_submission_time=58437.649385, global_step=131648, preemption_count=0, score=58437.649385, test/accuracy=0.613000, test/loss=1.677901, test/num_examples=10000, total_duration=62832.020049, train/accuracy=0.808242, train/loss=0.732436, validation/accuracy=0.730980, validation/loss=1.071063, validation/num_examples=50000
I0303 05:23:32.835845 139758009304832 logging_writer.py:48] [131700] global_step=131700, grad_norm=2.160686731338501, loss=1.712463617324829
I0303 05:24:16.319173 139758017697536 logging_writer.py:48] [131800] global_step=131800, grad_norm=1.7804397344589233, loss=2.724876880645752
I0303 05:25:01.019046 139758009304832 logging_writer.py:48] [131900] global_step=131900, grad_norm=2.1406869888305664, loss=1.5953640937805176
I0303 05:25:46.029369 139758017697536 logging_writer.py:48] [132000] global_step=132000, grad_norm=2.0828516483306885, loss=1.505554437637329
I0303 05:26:31.185566 139758009304832 logging_writer.py:48] [132100] global_step=132100, grad_norm=2.0118494033813477, loss=1.569853663444519
I0303 05:27:15.819844 139758017697536 logging_writer.py:48] [132200] global_step=132200, grad_norm=1.9639666080474854, loss=2.0131382942199707
I0303 05:28:00.655497 139758009304832 logging_writer.py:48] [132300] global_step=132300, grad_norm=1.8778091669082642, loss=1.7262991666793823
I0303 05:28:45.623321 139758017697536 logging_writer.py:48] [132400] global_step=132400, grad_norm=1.8353636264801025, loss=1.5518417358398438
I0303 05:29:30.502097 139758009304832 logging_writer.py:48] [132500] global_step=132500, grad_norm=1.875625491142273, loss=1.562889814376831
I0303 05:30:12.172824 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:30:23.191373 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:30:42.191619 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:30:43.831728 139953291118400 submission_runner.py:411] Time since start: 63284.01s, 	Step: 132594, 	{'train/accuracy': 0.8122069835662842, 'train/loss': 0.7282311320304871, 'validation/accuracy': 0.7334399819374084, 'validation/loss': 1.0696772336959839, 'validation/num_examples': 50000, 'test/accuracy': 0.6110000014305115, 'test/loss': 1.6827502250671387, 'test/num_examples': 10000, 'score': 58857.876715660095, 'total_duration': 63284.00793981552, 'accumulated_submission_time': 58857.876715660095, 'accumulated_eval_time': 4411.736454963684, 'accumulated_logging_time': 7.580765724182129}
I0303 05:30:43.878234 139758017697536 logging_writer.py:48] [132594] accumulated_eval_time=4411.736455, accumulated_logging_time=7.580766, accumulated_submission_time=58857.876716, global_step=132594, preemption_count=0, score=58857.876716, test/accuracy=0.611000, test/loss=1.682750, test/num_examples=10000, total_duration=63284.007940, train/accuracy=0.812207, train/loss=0.728231, validation/accuracy=0.733440, validation/loss=1.069677, validation/num_examples=50000
I0303 05:30:46.643534 139758009304832 logging_writer.py:48] [132600] global_step=132600, grad_norm=1.9514350891113281, loss=3.2721619606018066
I0303 05:31:27.748483 139758017697536 logging_writer.py:48] [132700] global_step=132700, grad_norm=1.9449502229690552, loss=1.5253665447235107
I0303 05:32:12.719834 139758009304832 logging_writer.py:48] [132800] global_step=132800, grad_norm=2.06433367729187, loss=3.921659231185913
I0303 05:32:57.731656 139758017697536 logging_writer.py:48] [132900] global_step=132900, grad_norm=1.898277997970581, loss=2.2088677883148193
I0303 05:33:43.036239 139758009304832 logging_writer.py:48] [133000] global_step=133000, grad_norm=1.8583201169967651, loss=1.5030829906463623
I0303 05:34:28.035167 139758017697536 logging_writer.py:48] [133100] global_step=133100, grad_norm=1.9346510171890259, loss=1.4941273927688599
I0303 05:35:13.133892 139758009304832 logging_writer.py:48] [133200] global_step=133200, grad_norm=1.8501079082489014, loss=2.0267536640167236
I0303 05:35:57.942676 139758017697536 logging_writer.py:48] [133300] global_step=133300, grad_norm=1.941531777381897, loss=3.2059695720672607
I0303 05:36:43.223931 139758009304832 logging_writer.py:48] [133400] global_step=133400, grad_norm=1.9194164276123047, loss=2.168489694595337
I0303 05:37:28.252134 139758017697536 logging_writer.py:48] [133500] global_step=133500, grad_norm=2.012647867202759, loss=3.122725486755371
I0303 05:37:44.198126 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:37:55.253663 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:38:16.729376 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:38:18.373809 139953291118400 submission_runner.py:411] Time since start: 63738.55s, 	Step: 133537, 	{'train/accuracy': 0.8247460722923279, 'train/loss': 0.6852326989173889, 'validation/accuracy': 0.7335799932479858, 'validation/loss': 1.0745161771774292, 'validation/num_examples': 50000, 'test/accuracy': 0.6073000431060791, 'test/loss': 1.697361946105957, 'test/num_examples': 10000, 'score': 59278.13584399223, 'total_duration': 63738.54997134209, 'accumulated_submission_time': 59278.13584399223, 'accumulated_eval_time': 4445.912066459656, 'accumulated_logging_time': 7.64042592048645}
I0303 05:38:18.425501 139758009304832 logging_writer.py:48] [133537] accumulated_eval_time=4445.912066, accumulated_logging_time=7.640426, accumulated_submission_time=59278.135844, global_step=133537, preemption_count=0, score=59278.135844, test/accuracy=0.607300, test/loss=1.697362, test/num_examples=10000, total_duration=63738.549971, train/accuracy=0.824746, train/loss=0.685233, validation/accuracy=0.733580, validation/loss=1.074516, validation/num_examples=50000
I0303 05:38:43.675070 139758017697536 logging_writer.py:48] [133600] global_step=133600, grad_norm=2.1407532691955566, loss=1.5587185621261597
I0303 05:39:27.239961 139758009304832 logging_writer.py:48] [133700] global_step=133700, grad_norm=1.9755381345748901, loss=1.4930098056793213
I0303 05:40:12.035105 139758017697536 logging_writer.py:48] [133800] global_step=133800, grad_norm=1.939276099205017, loss=1.7134349346160889
I0303 05:40:57.204797 139758009304832 logging_writer.py:48] [133900] global_step=133900, grad_norm=1.95365309715271, loss=1.521399736404419
I0303 05:41:42.101281 139758017697536 logging_writer.py:48] [134000] global_step=134000, grad_norm=1.8536831140518188, loss=2.542144298553467
I0303 05:42:26.963963 139758009304832 logging_writer.py:48] [134100] global_step=134100, grad_norm=1.9911906719207764, loss=1.6397161483764648
I0303 05:43:12.082897 139758017697536 logging_writer.py:48] [134200] global_step=134200, grad_norm=1.92612886428833, loss=3.1710588932037354
I0303 05:43:56.717917 139758009304832 logging_writer.py:48] [134300] global_step=134300, grad_norm=1.8353251218795776, loss=2.369800329208374
I0303 05:44:41.604361 139758017697536 logging_writer.py:48] [134400] global_step=134400, grad_norm=2.009953498840332, loss=1.5225152969360352
I0303 05:45:18.641859 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:45:29.827798 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:45:52.899078 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:45:54.531068 139953291118400 submission_runner.py:411] Time since start: 64194.71s, 	Step: 134484, 	{'train/accuracy': 0.81361323595047, 'train/loss': 0.7152171730995178, 'validation/accuracy': 0.7375999689102173, 'validation/loss': 1.051063895225525, 'validation/num_examples': 50000, 'test/accuracy': 0.613800048828125, 'test/loss': 1.670855164527893, 'test/num_examples': 10000, 'score': 59698.29487943649, 'total_duration': 64194.70729804039, 'accumulated_submission_time': 59698.29487943649, 'accumulated_eval_time': 4481.801281452179, 'accumulated_logging_time': 7.701645374298096}
I0303 05:45:54.566283 139758009304832 logging_writer.py:48] [134484] accumulated_eval_time=4481.801281, accumulated_logging_time=7.701645, accumulated_submission_time=59698.294879, global_step=134484, preemption_count=0, score=59698.294879, test/accuracy=0.613800, test/loss=1.670855, test/num_examples=10000, total_duration=64194.707298, train/accuracy=0.813613, train/loss=0.715217, validation/accuracy=0.737600, validation/loss=1.051064, validation/num_examples=50000
I0303 05:46:01.285244 139758017697536 logging_writer.py:48] [134500] global_step=134500, grad_norm=1.9908548593521118, loss=1.6993530988693237
I0303 05:46:41.307429 139758009304832 logging_writer.py:48] [134600] global_step=134600, grad_norm=1.9259278774261475, loss=1.5780057907104492
I0303 05:47:26.281398 139758017697536 logging_writer.py:48] [134700] global_step=134700, grad_norm=1.9592809677124023, loss=1.6342469453811646
I0303 05:48:11.243669 139758009304832 logging_writer.py:48] [134800] global_step=134800, grad_norm=2.26263689994812, loss=1.5656025409698486
I0303 05:48:56.370692 139758017697536 logging_writer.py:48] [134900] global_step=134900, grad_norm=1.844000220298767, loss=2.5421345233917236
I0303 05:49:41.243610 139758009304832 logging_writer.py:48] [135000] global_step=135000, grad_norm=2.146272897720337, loss=1.6479475498199463
I0303 05:50:26.043813 139758017697536 logging_writer.py:48] [135100] global_step=135100, grad_norm=1.8321294784545898, loss=2.46795392036438
I0303 05:51:11.639605 139758009304832 logging_writer.py:48] [135200] global_step=135200, grad_norm=1.7360862493515015, loss=2.3313727378845215
I0303 05:51:56.223827 139758017697536 logging_writer.py:48] [135300] global_step=135300, grad_norm=2.1038835048675537, loss=1.6692439317703247
I0303 05:52:41.181156 139758009304832 logging_writer.py:48] [135400] global_step=135400, grad_norm=2.2578558921813965, loss=3.6401889324188232
I0303 05:52:54.789802 139953291118400 spec.py:321] Evaluating on the training split.
I0303 05:53:05.990580 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 05:53:26.423055 139953291118400 spec.py:349] Evaluating on the test split.
I0303 05:53:28.067633 139953291118400 submission_runner.py:411] Time since start: 64648.24s, 	Step: 135432, 	{'train/accuracy': 0.8185351490974426, 'train/loss': 0.6898524165153503, 'validation/accuracy': 0.7380599975585938, 'validation/loss': 1.040588140487671, 'validation/num_examples': 50000, 'test/accuracy': 0.6119000315666199, 'test/loss': 1.6614116430282593, 'test/num_examples': 10000, 'score': 60118.45872378349, 'total_duration': 64648.243869543076, 'accumulated_submission_time': 60118.45872378349, 'accumulated_eval_time': 4515.079110383987, 'accumulated_logging_time': 7.7463274002075195}
I0303 05:53:28.106037 139758017697536 logging_writer.py:48] [135432] accumulated_eval_time=4515.079110, accumulated_logging_time=7.746327, accumulated_submission_time=60118.458724, global_step=135432, preemption_count=0, score=60118.458724, test/accuracy=0.611900, test/loss=1.661412, test/num_examples=10000, total_duration=64648.243870, train/accuracy=0.818535, train/loss=0.689852, validation/accuracy=0.738060, validation/loss=1.040588, validation/num_examples=50000
I0303 05:53:55.354340 139758009304832 logging_writer.py:48] [135500] global_step=135500, grad_norm=1.9614816904067993, loss=2.561448812484741
I0303 05:54:38.991782 139758017697536 logging_writer.py:48] [135600] global_step=135600, grad_norm=2.117894411087036, loss=1.566648244857788
I0303 05:55:23.848162 139758009304832 logging_writer.py:48] [135700] global_step=135700, grad_norm=2.086801767349243, loss=3.8265440464019775
I0303 05:56:08.954521 139758017697536 logging_writer.py:48] [135800] global_step=135800, grad_norm=1.9155325889587402, loss=2.466265916824341
I0303 05:56:54.008890 139758009304832 logging_writer.py:48] [135900] global_step=135900, grad_norm=2.025386095046997, loss=2.440335273742676
I0303 05:57:38.839616 139758017697536 logging_writer.py:48] [136000] global_step=136000, grad_norm=1.8051183223724365, loss=2.7021396160125732
I0303 05:58:24.161893 139758009304832 logging_writer.py:48] [136100] global_step=136100, grad_norm=1.9186084270477295, loss=1.7820264101028442
I0303 05:59:08.968558 139758017697536 logging_writer.py:48] [136200] global_step=136200, grad_norm=1.9227617979049683, loss=3.1400163173675537
I0303 05:59:53.803816 139758009304832 logging_writer.py:48] [136300] global_step=136300, grad_norm=1.9799690246582031, loss=2.5636487007141113
I0303 06:00:28.231714 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:00:39.480193 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:00:59.389091 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:01:01.025732 139953291118400 submission_runner.py:411] Time since start: 65101.20s, 	Step: 136378, 	{'train/accuracy': 0.8243945240974426, 'train/loss': 0.6757507920265198, 'validation/accuracy': 0.7364199757575989, 'validation/loss': 1.0444821119308472, 'validation/num_examples': 50000, 'test/accuracy': 0.6154000163078308, 'test/loss': 1.6687698364257812, 'test/num_examples': 10000, 'score': 60538.52721905708, 'total_duration': 65101.20194649696, 'accumulated_submission_time': 60538.52721905708, 'accumulated_eval_time': 4547.873115539551, 'accumulated_logging_time': 7.793517351150513}
I0303 06:01:01.072374 139758017697536 logging_writer.py:48] [136378] accumulated_eval_time=4547.873116, accumulated_logging_time=7.793517, accumulated_submission_time=60538.527219, global_step=136378, preemption_count=0, score=60538.527219, test/accuracy=0.615400, test/loss=1.668770, test/num_examples=10000, total_duration=65101.201946, train/accuracy=0.824395, train/loss=0.675751, validation/accuracy=0.736420, validation/loss=1.044482, validation/num_examples=50000
I0303 06:01:10.192754 139758009304832 logging_writer.py:48] [136400] global_step=136400, grad_norm=1.9667659997940063, loss=1.5157475471496582
I0303 06:01:52.227527 139758017697536 logging_writer.py:48] [136500] global_step=136500, grad_norm=1.784273386001587, loss=2.5647928714752197
I0303 06:02:37.054661 139758009304832 logging_writer.py:48] [136600] global_step=136600, grad_norm=2.011025905609131, loss=1.597965121269226
I0303 06:03:21.834411 139758017697536 logging_writer.py:48] [136700] global_step=136700, grad_norm=2.257925510406494, loss=1.6199016571044922
I0303 06:04:07.337627 139758009304832 logging_writer.py:48] [136800] global_step=136800, grad_norm=2.0048367977142334, loss=2.0444345474243164
I0303 06:04:52.105823 139758017697536 logging_writer.py:48] [136900] global_step=136900, grad_norm=1.8473092317581177, loss=2.765089988708496
I0303 06:05:36.881192 139758009304832 logging_writer.py:48] [137000] global_step=137000, grad_norm=2.023559331893921, loss=1.5320643186569214
I0303 06:06:22.042330 139758017697536 logging_writer.py:48] [137100] global_step=137100, grad_norm=2.0992910861968994, loss=1.5688753128051758
I0303 06:07:07.134685 139758009304832 logging_writer.py:48] [137200] global_step=137200, grad_norm=2.118335247039795, loss=1.599779725074768
I0303 06:07:51.831412 139758017697536 logging_writer.py:48] [137300] global_step=137300, grad_norm=2.238332509994507, loss=1.6540364027023315
I0303 06:08:01.489375 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:08:12.496714 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:08:34.252369 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:08:35.889626 139953291118400 submission_runner.py:411] Time since start: 65556.07s, 	Step: 137323, 	{'train/accuracy': 0.8189452886581421, 'train/loss': 0.6932224631309509, 'validation/accuracy': 0.740339994430542, 'validation/loss': 1.0378048419952393, 'validation/num_examples': 50000, 'test/accuracy': 0.6136000156402588, 'test/loss': 1.6628977060317993, 'test/num_examples': 10000, 'score': 60958.88538622856, 'total_duration': 65556.06583595276, 'accumulated_submission_time': 60958.88538622856, 'accumulated_eval_time': 4582.273346424103, 'accumulated_logging_time': 7.8503875732421875}
I0303 06:08:35.941344 139758009304832 logging_writer.py:48] [137323] accumulated_eval_time=4582.273346, accumulated_logging_time=7.850388, accumulated_submission_time=60958.885386, global_step=137323, preemption_count=0, score=60958.885386, test/accuracy=0.613600, test/loss=1.662898, test/num_examples=10000, total_duration=65556.065836, train/accuracy=0.818945, train/loss=0.693222, validation/accuracy=0.740340, validation/loss=1.037805, validation/num_examples=50000
I0303 06:09:06.748721 139758017697536 logging_writer.py:48] [137400] global_step=137400, grad_norm=2.212416410446167, loss=1.5762267112731934
I0303 06:09:50.593439 139758009304832 logging_writer.py:48] [137500] global_step=137500, grad_norm=1.991518259048462, loss=3.156507968902588
I0303 06:10:35.393849 139758017697536 logging_writer.py:48] [137600] global_step=137600, grad_norm=2.164447784423828, loss=1.517930269241333
I0303 06:11:20.700709 139758009304832 logging_writer.py:48] [137700] global_step=137700, grad_norm=2.221282482147217, loss=3.1667072772979736
I0303 06:12:05.583441 139758017697536 logging_writer.py:48] [137800] global_step=137800, grad_norm=2.108938455581665, loss=1.4456498622894287
I0303 06:12:50.440223 139758009304832 logging_writer.py:48] [137900] global_step=137900, grad_norm=2.021267890930176, loss=1.9788023233413696
I0303 06:13:35.396078 139758017697536 logging_writer.py:48] [138000] global_step=138000, grad_norm=1.96128511428833, loss=2.6278083324432373
I0303 06:14:20.529758 139758009304832 logging_writer.py:48] [138100] global_step=138100, grad_norm=2.1712591648101807, loss=1.4635909795761108
I0303 06:15:05.240124 139758017697536 logging_writer.py:48] [138200] global_step=138200, grad_norm=2.049057722091675, loss=1.524597406387329
I0303 06:15:36.004930 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:15:46.854412 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:16:06.802533 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:16:08.431458 139953291118400 submission_runner.py:411] Time since start: 66008.61s, 	Step: 138270, 	{'train/accuracy': 0.8212890625, 'train/loss': 0.7007355093955994, 'validation/accuracy': 0.7413199543952942, 'validation/loss': 1.0484044551849365, 'validation/num_examples': 50000, 'test/accuracy': 0.6142000555992126, 'test/loss': 1.658218264579773, 'test/num_examples': 10000, 'score': 61378.89130926132, 'total_duration': 66008.60767126083, 'accumulated_submission_time': 61378.89130926132, 'accumulated_eval_time': 4614.699839115143, 'accumulated_logging_time': 7.911661148071289}
I0303 06:16:08.475637 139758009304832 logging_writer.py:48] [138270] accumulated_eval_time=4614.699839, accumulated_logging_time=7.911661, accumulated_submission_time=61378.891309, global_step=138270, preemption_count=0, score=61378.891309, test/accuracy=0.614200, test/loss=1.658218, test/num_examples=10000, total_duration=66008.607671, train/accuracy=0.821289, train/loss=0.700736, validation/accuracy=0.741320, validation/loss=1.048404, validation/num_examples=50000
I0303 06:16:20.760080 139758017697536 logging_writer.py:48] [138300] global_step=138300, grad_norm=2.1364502906799316, loss=1.63545560836792
I0303 06:17:03.422038 139758009304832 logging_writer.py:48] [138400] global_step=138400, grad_norm=2.4729390144348145, loss=3.5526509284973145
I0303 06:17:48.278325 139758017697536 logging_writer.py:48] [138500] global_step=138500, grad_norm=1.9686589241027832, loss=1.9192090034484863
I0303 06:18:33.194779 139758009304832 logging_writer.py:48] [138600] global_step=138600, grad_norm=2.0290699005126953, loss=1.4900957345962524
I0303 06:19:18.406448 139758017697536 logging_writer.py:48] [138700] global_step=138700, grad_norm=2.291891574859619, loss=3.7938923835754395
I0303 06:20:03.164493 139758009304832 logging_writer.py:48] [138800] global_step=138800, grad_norm=2.007474184036255, loss=1.376114845275879
I0303 06:20:48.225376 139758017697536 logging_writer.py:48] [138900] global_step=138900, grad_norm=2.140807867050171, loss=1.4517158269882202
I0303 06:21:33.307256 139758009304832 logging_writer.py:48] [139000] global_step=139000, grad_norm=2.763319730758667, loss=4.004213333129883
I0303 06:22:18.631263 139758017697536 logging_writer.py:48] [139100] global_step=139100, grad_norm=2.0885396003723145, loss=1.6137298345565796
I0303 06:23:03.763726 139758009304832 logging_writer.py:48] [139200] global_step=139200, grad_norm=2.177201747894287, loss=1.6798334121704102
I0303 06:23:08.456060 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:23:19.473906 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:23:38.894618 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:23:40.534629 139953291118400 submission_runner.py:411] Time since start: 66460.71s, 	Step: 139212, 	{'train/accuracy': 0.8290624618530273, 'train/loss': 0.6643991470336914, 'validation/accuracy': 0.7405399680137634, 'validation/loss': 1.040321946144104, 'validation/num_examples': 50000, 'test/accuracy': 0.6215000152587891, 'test/loss': 1.646551251411438, 'test/num_examples': 10000, 'score': 61798.8139359951, 'total_duration': 66460.71085047722, 'accumulated_submission_time': 61798.8139359951, 'accumulated_eval_time': 4646.778388261795, 'accumulated_logging_time': 7.966315031051636}
I0303 06:23:40.579447 139758017697536 logging_writer.py:48] [139212] accumulated_eval_time=4646.778388, accumulated_logging_time=7.966315, accumulated_submission_time=61798.813936, global_step=139212, preemption_count=0, score=61798.813936, test/accuracy=0.621500, test/loss=1.646551, test/num_examples=10000, total_duration=66460.710850, train/accuracy=0.829062, train/loss=0.664399, validation/accuracy=0.740540, validation/loss=1.040322, validation/num_examples=50000
I0303 06:24:16.293192 139758009304832 logging_writer.py:48] [139300] global_step=139300, grad_norm=1.935346245765686, loss=2.012315273284912
I0303 06:25:00.857560 139758017697536 logging_writer.py:48] [139400] global_step=139400, grad_norm=2.186943769454956, loss=1.6190789937973022
I0303 06:25:45.521687 139758009304832 logging_writer.py:48] [139500] global_step=139500, grad_norm=2.2150490283966064, loss=1.6853911876678467
I0303 06:26:30.779523 139758017697536 logging_writer.py:48] [139600] global_step=139600, grad_norm=1.9517416954040527, loss=2.263762950897217
I0303 06:27:15.915950 139758009304832 logging_writer.py:48] [139700] global_step=139700, grad_norm=1.9423774480819702, loss=1.8661880493164062
I0303 06:28:00.621730 139758017697536 logging_writer.py:48] [139800] global_step=139800, grad_norm=2.016202926635742, loss=1.6302402019500732
I0303 06:28:45.952841 139758009304832 logging_writer.py:48] [139900] global_step=139900, grad_norm=2.3614063262939453, loss=3.8449532985687256
I0303 06:29:31.031115 139758017697536 logging_writer.py:48] [140000] global_step=140000, grad_norm=2.1701571941375732, loss=1.5373245477676392
I0303 06:30:16.202925 139758009304832 logging_writer.py:48] [140100] global_step=140100, grad_norm=2.051345109939575, loss=1.7553894519805908
I0303 06:30:40.779805 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:30:51.775516 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:31:10.602654 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:31:12.232560 139953291118400 submission_runner.py:411] Time since start: 66912.41s, 	Step: 140156, 	{'train/accuracy': 0.8376757502555847, 'train/loss': 0.613097608089447, 'validation/accuracy': 0.7422199845314026, 'validation/loss': 1.0231008529663086, 'validation/num_examples': 50000, 'test/accuracy': 0.6212000250816345, 'test/loss': 1.6370558738708496, 'test/num_examples': 10000, 'score': 62218.95655655861, 'total_duration': 66912.40876984596, 'accumulated_submission_time': 62218.95655655861, 'accumulated_eval_time': 4678.231098890305, 'accumulated_logging_time': 8.020896673202515}
I0303 06:31:12.278956 139758017697536 logging_writer.py:48] [140156] accumulated_eval_time=4678.231099, accumulated_logging_time=8.020897, accumulated_submission_time=62218.956557, global_step=140156, preemption_count=0, score=62218.956557, test/accuracy=0.621200, test/loss=1.637056, test/num_examples=10000, total_duration=66912.408770, train/accuracy=0.837676, train/loss=0.613098, validation/accuracy=0.742220, validation/loss=1.023101, validation/num_examples=50000
I0303 06:31:30.067604 139758009304832 logging_writer.py:48] [140200] global_step=140200, grad_norm=2.34027361869812, loss=3.7135980129241943
I0303 06:32:13.007822 139758017697536 logging_writer.py:48] [140300] global_step=140300, grad_norm=2.1624906063079834, loss=1.8396397829055786
I0303 06:32:57.888981 139758009304832 logging_writer.py:48] [140400] global_step=140400, grad_norm=2.8016645908355713, loss=3.7692694664001465
I0303 06:33:43.006477 139758017697536 logging_writer.py:48] [140500] global_step=140500, grad_norm=2.0963692665100098, loss=1.4716943502426147
I0303 06:34:27.884655 139758009304832 logging_writer.py:48] [140600] global_step=140600, grad_norm=2.155942916870117, loss=1.4877820014953613
I0303 06:35:12.821219 139758017697536 logging_writer.py:48] [140700] global_step=140700, grad_norm=2.3277158737182617, loss=3.6715450286865234
I0303 06:35:57.658644 139758009304832 logging_writer.py:48] [140800] global_step=140800, grad_norm=2.2138402462005615, loss=1.594286561012268
I0303 06:36:42.923651 139758017697536 logging_writer.py:48] [140900] global_step=140900, grad_norm=2.0167908668518066, loss=1.9124128818511963
I0303 06:37:27.675420 139758009304832 logging_writer.py:48] [141000] global_step=141000, grad_norm=2.2711076736450195, loss=3.4594051837921143
I0303 06:38:12.684447 139758017697536 logging_writer.py:48] [141100] global_step=141100, grad_norm=2.202296495437622, loss=1.5778216123580933
I0303 06:38:12.699052 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:38:23.637877 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:38:45.315269 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:38:46.950505 139953291118400 submission_runner.py:411] Time since start: 67367.13s, 	Step: 141101, 	{'train/accuracy': 0.8280078172683716, 'train/loss': 0.6409241557121277, 'validation/accuracy': 0.7453199625015259, 'validation/loss': 1.0019612312316895, 'validation/num_examples': 50000, 'test/accuracy': 0.6190000176429749, 'test/loss': 1.6144688129425049, 'test/num_examples': 10000, 'score': 62639.31224012375, 'total_duration': 67367.12671756744, 'accumulated_submission_time': 62639.31224012375, 'accumulated_eval_time': 4712.48251914978, 'accumulated_logging_time': 8.083777904510498}
I0303 06:38:46.994648 139758009304832 logging_writer.py:48] [141101] accumulated_eval_time=4712.482519, accumulated_logging_time=8.083778, accumulated_submission_time=62639.312240, global_step=141101, preemption_count=0, score=62639.312240, test/accuracy=0.619000, test/loss=1.614469, test/num_examples=10000, total_duration=67367.126718, train/accuracy=0.828008, train/loss=0.640924, validation/accuracy=0.745320, validation/loss=1.001961, validation/num_examples=50000
I0303 06:39:27.061270 139758017697536 logging_writer.py:48] [141200] global_step=141200, grad_norm=2.1969797611236572, loss=1.529776930809021
I0303 06:40:11.671906 139758009304832 logging_writer.py:48] [141300] global_step=141300, grad_norm=2.1393473148345947, loss=1.6471285820007324
I0303 06:40:56.704257 139758017697536 logging_writer.py:48] [141400] global_step=141400, grad_norm=2.19521427154541, loss=3.1628170013427734
I0303 06:41:41.773132 139758009304832 logging_writer.py:48] [141500] global_step=141500, grad_norm=2.0703237056732178, loss=1.501081109046936
I0303 06:42:26.395929 139758017697536 logging_writer.py:48] [141600] global_step=141600, grad_norm=2.3196563720703125, loss=3.2562856674194336
I0303 06:43:11.241960 139758009304832 logging_writer.py:48] [141700] global_step=141700, grad_norm=2.5749661922454834, loss=3.824535369873047
I0303 06:43:56.278526 139758017697536 logging_writer.py:48] [141800] global_step=141800, grad_norm=2.109048843383789, loss=1.5322351455688477
I0303 06:44:41.253498 139758009304832 logging_writer.py:48] [141900] global_step=141900, grad_norm=2.2173404693603516, loss=2.3311047554016113
I0303 06:45:26.078135 139758017697536 logging_writer.py:48] [142000] global_step=142000, grad_norm=2.179509162902832, loss=3.0367789268493652
I0303 06:45:47.392831 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:45:58.305462 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:46:18.602358 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:46:20.236796 139953291118400 submission_runner.py:411] Time since start: 67820.41s, 	Step: 142049, 	{'train/accuracy': 0.8278319835662842, 'train/loss': 0.646851658821106, 'validation/accuracy': 0.7454800009727478, 'validation/loss': 1.0134694576263428, 'validation/num_examples': 50000, 'test/accuracy': 0.6236000061035156, 'test/loss': 1.6220612525939941, 'test/num_examples': 10000, 'score': 63059.65165567398, 'total_duration': 67820.41301584244, 'accumulated_submission_time': 63059.65165567398, 'accumulated_eval_time': 4745.326453208923, 'accumulated_logging_time': 8.137955904006958}
I0303 06:46:20.280844 139758009304832 logging_writer.py:48] [142049] accumulated_eval_time=4745.326453, accumulated_logging_time=8.137956, accumulated_submission_time=63059.651656, global_step=142049, preemption_count=0, score=63059.651656, test/accuracy=0.623600, test/loss=1.622061, test/num_examples=10000, total_duration=67820.413016, train/accuracy=0.827832, train/loss=0.646852, validation/accuracy=0.745480, validation/loss=1.013469, validation/num_examples=50000
I0303 06:46:40.826817 139758017697536 logging_writer.py:48] [142100] global_step=142100, grad_norm=2.3054537773132324, loss=3.847877264022827
I0303 06:47:24.225505 139758009304832 logging_writer.py:48] [142200] global_step=142200, grad_norm=2.139488697052002, loss=1.9260900020599365
I0303 06:48:09.623089 139758017697536 logging_writer.py:48] [142300] global_step=142300, grad_norm=2.02280855178833, loss=2.159740447998047
I0303 06:48:54.809231 139758009304832 logging_writer.py:48] [142400] global_step=142400, grad_norm=2.367671012878418, loss=1.4365689754486084
I0303 06:49:39.834904 139758017697536 logging_writer.py:48] [142500] global_step=142500, grad_norm=2.1867051124572754, loss=2.312378168106079
I0303 06:50:24.686646 139758009304832 logging_writer.py:48] [142600] global_step=142600, grad_norm=2.1858859062194824, loss=1.4702532291412354
I0303 06:51:10.243282 139758017697536 logging_writer.py:48] [142700] global_step=142700, grad_norm=2.5484676361083984, loss=3.8158469200134277
I0303 06:51:55.198310 139758009304832 logging_writer.py:48] [142800] global_step=142800, grad_norm=2.016334056854248, loss=2.1728932857513428
I0303 06:52:40.249676 139758017697536 logging_writer.py:48] [142900] global_step=142900, grad_norm=2.075334310531616, loss=2.9239463806152344
I0303 06:53:20.259125 139953291118400 spec.py:321] Evaluating on the training split.
I0303 06:53:31.369712 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 06:53:49.643972 139953291118400 spec.py:349] Evaluating on the test split.
I0303 06:53:51.285387 139953291118400 submission_runner.py:411] Time since start: 68271.46s, 	Step: 142990, 	{'train/accuracy': 0.8350585699081421, 'train/loss': 0.6243909001350403, 'validation/accuracy': 0.7469799518585205, 'validation/loss': 1.008358120918274, 'validation/num_examples': 50000, 'test/accuracy': 0.6205000281333923, 'test/loss': 1.6167891025543213, 'test/num_examples': 10000, 'score': 63479.56883740425, 'total_duration': 68271.46160244942, 'accumulated_submission_time': 63479.56883740425, 'accumulated_eval_time': 4776.352700948715, 'accumulated_logging_time': 8.195709705352783}
I0303 06:53:51.329920 139758009304832 logging_writer.py:48] [142990] accumulated_eval_time=4776.352701, accumulated_logging_time=8.195710, accumulated_submission_time=63479.568837, global_step=142990, preemption_count=0, score=63479.568837, test/accuracy=0.620500, test/loss=1.616789, test/num_examples=10000, total_duration=68271.461602, train/accuracy=0.835059, train/loss=0.624391, validation/accuracy=0.746980, validation/loss=1.008358, validation/num_examples=50000
I0303 06:53:55.686393 139758017697536 logging_writer.py:48] [143000] global_step=143000, grad_norm=2.161548614501953, loss=1.8270342350006104
I0303 06:54:36.464813 139758009304832 logging_writer.py:48] [143100] global_step=143100, grad_norm=2.1289901733398438, loss=1.4836961030960083
I0303 06:55:21.772087 139758017697536 logging_writer.py:48] [143200] global_step=143200, grad_norm=2.3260903358459473, loss=1.6839206218719482
I0303 06:56:06.958993 139758009304832 logging_writer.py:48] [143300] global_step=143300, grad_norm=1.9833773374557495, loss=2.912529468536377
I0303 06:56:52.100067 139758017697536 logging_writer.py:48] [143400] global_step=143400, grad_norm=2.1051483154296875, loss=1.55876624584198
I0303 06:57:37.208678 139758009304832 logging_writer.py:48] [143500] global_step=143500, grad_norm=2.448385238647461, loss=2.310586929321289
I0303 06:58:22.150620 139758017697536 logging_writer.py:48] [143600] global_step=143600, grad_norm=2.2640655040740967, loss=1.4918277263641357
I0303 06:59:07.395847 139758009304832 logging_writer.py:48] [143700] global_step=143700, grad_norm=2.2935314178466797, loss=1.4127662181854248
I0303 06:59:52.559777 139758017697536 logging_writer.py:48] [143800] global_step=143800, grad_norm=2.104222536087036, loss=1.7916191816329956
I0303 07:00:37.842157 139758009304832 logging_writer.py:48] [143900] global_step=143900, grad_norm=2.1277058124542236, loss=2.3059234619140625
I0303 07:00:51.464325 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:01:02.304450 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:01:26.806435 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:01:28.439347 139953291118400 submission_runner.py:411] Time since start: 68728.62s, 	Step: 143932, 	{'train/accuracy': 0.8307421803474426, 'train/loss': 0.6419038772583008, 'validation/accuracy': 0.7469799518585205, 'validation/loss': 0.9995123744010925, 'validation/num_examples': 50000, 'test/accuracy': 0.6215000152587891, 'test/loss': 1.6196413040161133, 'test/num_examples': 10000, 'score': 63899.643840789795, 'total_duration': 68728.61555743217, 'accumulated_submission_time': 63899.643840789795, 'accumulated_eval_time': 4813.3277044296265, 'accumulated_logging_time': 8.251341104507446}
I0303 07:01:28.486597 139758017697536 logging_writer.py:48] [143932] accumulated_eval_time=4813.327704, accumulated_logging_time=8.251341, accumulated_submission_time=63899.643841, global_step=143932, preemption_count=0, score=63899.643841, test/accuracy=0.621500, test/loss=1.619641, test/num_examples=10000, total_duration=68728.615557, train/accuracy=0.830742, train/loss=0.641904, validation/accuracy=0.746980, validation/loss=0.999512, validation/num_examples=50000
I0303 07:01:55.725457 139758009304832 logging_writer.py:48] [144000] global_step=144000, grad_norm=2.2845137119293213, loss=1.3680367469787598
I0303 07:02:38.537959 139758017697536 logging_writer.py:48] [144100] global_step=144100, grad_norm=1.9988982677459717, loss=1.8711377382278442
I0303 07:03:23.703441 139758009304832 logging_writer.py:48] [144200] global_step=144200, grad_norm=2.186976909637451, loss=1.604933500289917
I0303 07:04:08.891875 139758017697536 logging_writer.py:48] [144300] global_step=144300, grad_norm=2.2170944213867188, loss=1.8294795751571655
I0303 07:04:53.537955 139758009304832 logging_writer.py:48] [144400] global_step=144400, grad_norm=2.591827630996704, loss=3.695225477218628
I0303 07:05:38.314210 139758017697536 logging_writer.py:48] [144500] global_step=144500, grad_norm=2.240554094314575, loss=1.644585132598877
I0303 07:06:23.200719 139758009304832 logging_writer.py:48] [144600] global_step=144600, grad_norm=2.156857490539551, loss=2.073854684829712
I0303 07:07:07.926854 139758017697536 logging_writer.py:48] [144700] global_step=144700, grad_norm=2.2625062465667725, loss=3.314692497253418
I0303 07:07:52.685104 139758009304832 logging_writer.py:48] [144800] global_step=144800, grad_norm=2.1479198932647705, loss=1.3795645236968994
I0303 07:08:28.848678 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:08:39.756143 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:09:02.874938 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:09:04.501041 139953291118400 submission_runner.py:411] Time since start: 69184.68s, 	Step: 144882, 	{'train/accuracy': 0.8347265720367432, 'train/loss': 0.622641384601593, 'validation/accuracy': 0.7500399947166443, 'validation/loss': 0.9826123118400574, 'validation/num_examples': 50000, 'test/accuracy': 0.6274000406265259, 'test/loss': 1.5910381078720093, 'test/num_examples': 10000, 'score': 64319.947767972946, 'total_duration': 69184.67727637291, 'accumulated_submission_time': 64319.947767972946, 'accumulated_eval_time': 4848.98010802269, 'accumulated_logging_time': 8.308446168899536}
I0303 07:09:04.539710 139758017697536 logging_writer.py:48] [144882] accumulated_eval_time=4848.980108, accumulated_logging_time=8.308446, accumulated_submission_time=64319.947768, global_step=144882, preemption_count=0, score=64319.947768, test/accuracy=0.627400, test/loss=1.591038, test/num_examples=10000, total_duration=69184.677276, train/accuracy=0.834727, train/loss=0.622641, validation/accuracy=0.750040, validation/loss=0.982612, validation/num_examples=50000
I0303 07:09:12.044391 139758009304832 logging_writer.py:48] [144900] global_step=144900, grad_norm=1.9744036197662354, loss=2.0177462100982666
I0303 07:09:52.831899 139758017697536 logging_writer.py:48] [145000] global_step=145000, grad_norm=2.220691442489624, loss=1.6636123657226562
I0303 07:10:37.428392 139758009304832 logging_writer.py:48] [145100] global_step=145100, grad_norm=2.2877631187438965, loss=1.4857618808746338
I0303 07:11:22.410361 139758017697536 logging_writer.py:48] [145200] global_step=145200, grad_norm=2.0611307621002197, loss=2.1109025478363037
I0303 07:12:07.429974 139758009304832 logging_writer.py:48] [145300] global_step=145300, grad_norm=2.363769054412842, loss=3.184339761734009
I0303 07:12:52.070068 139758017697536 logging_writer.py:48] [145400] global_step=145400, grad_norm=2.3275206089019775, loss=2.4164071083068848
I0303 07:13:37.485188 139758009304832 logging_writer.py:48] [145500] global_step=145500, grad_norm=2.1843438148498535, loss=3.048757314682007
I0303 07:14:22.689345 139758017697536 logging_writer.py:48] [145600] global_step=145600, grad_norm=2.670302152633667, loss=3.7385878562927246
I0303 07:15:07.524300 139758009304832 logging_writer.py:48] [145700] global_step=145700, grad_norm=2.8686721324920654, loss=3.5374977588653564
I0303 07:15:52.307247 139758017697536 logging_writer.py:48] [145800] global_step=145800, grad_norm=2.2746500968933105, loss=1.521578311920166
I0303 07:16:04.668455 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:16:16.180899 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:16:33.827294 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:16:35.470118 139953291118400 submission_runner.py:411] Time since start: 69635.65s, 	Step: 145829, 	{'train/accuracy': 0.8373242020606995, 'train/loss': 0.6188812255859375, 'validation/accuracy': 0.7525999546051025, 'validation/loss': 0.9853445887565613, 'validation/num_examples': 50000, 'test/accuracy': 0.629300057888031, 'test/loss': 1.5892504453659058, 'test/num_examples': 10000, 'score': 64740.01791214943, 'total_duration': 69635.6463303566, 'accumulated_submission_time': 64740.01791214943, 'accumulated_eval_time': 4879.7817924022675, 'accumulated_logging_time': 8.357537031173706}
I0303 07:16:35.515325 139758009304832 logging_writer.py:48] [145829] accumulated_eval_time=4879.781792, accumulated_logging_time=8.357537, accumulated_submission_time=64740.017912, global_step=145829, preemption_count=0, score=64740.017912, test/accuracy=0.629300, test/loss=1.589250, test/num_examples=10000, total_duration=69635.646330, train/accuracy=0.837324, train/loss=0.618881, validation/accuracy=0.752600, validation/loss=0.985345, validation/num_examples=50000
I0303 07:17:04.374214 139758017697536 logging_writer.py:48] [145900] global_step=145900, grad_norm=2.3537075519561768, loss=1.684352993965149
I0303 07:17:49.037285 139758009304832 logging_writer.py:48] [146000] global_step=146000, grad_norm=2.20236873626709, loss=1.4072608947753906
I0303 07:18:33.825214 139758017697536 logging_writer.py:48] [146100] global_step=146100, grad_norm=2.199674129486084, loss=1.4901680946350098
I0303 07:19:18.971425 139758009304832 logging_writer.py:48] [146200] global_step=146200, grad_norm=2.402700662612915, loss=1.434415578842163
I0303 07:20:03.674439 139758017697536 logging_writer.py:48] [146300] global_step=146300, grad_norm=2.2393975257873535, loss=1.3651665449142456
I0303 07:20:48.642309 139758009304832 logging_writer.py:48] [146400] global_step=146400, grad_norm=2.055821657180786, loss=2.648571729660034
I0303 07:21:33.512037 139758017697536 logging_writer.py:48] [146500] global_step=146500, grad_norm=2.1500511169433594, loss=1.8863388299942017
I0303 07:22:18.400242 139758009304832 logging_writer.py:48] [146600] global_step=146600, grad_norm=2.4932494163513184, loss=3.4252359867095947
I0303 07:23:03.335688 139758017697536 logging_writer.py:48] [146700] global_step=146700, grad_norm=2.282102346420288, loss=3.3715920448303223
I0303 07:23:35.598349 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:23:46.643623 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:24:11.781755 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:24:13.406528 139953291118400 submission_runner.py:411] Time since start: 70093.58s, 	Step: 146774, 	{'train/accuracy': 0.8498046398162842, 'train/loss': 0.5664092302322388, 'validation/accuracy': 0.7521399855613708, 'validation/loss': 0.978649377822876, 'validation/num_examples': 50000, 'test/accuracy': 0.6303000450134277, 'test/loss': 1.581558108329773, 'test/num_examples': 10000, 'score': 65160.04265499115, 'total_duration': 70093.58276224136, 'accumulated_submission_time': 65160.04265499115, 'accumulated_eval_time': 4917.589969396591, 'accumulated_logging_time': 8.413017749786377}
I0303 07:24:13.446058 139758009304832 logging_writer.py:48] [146774] accumulated_eval_time=4917.589969, accumulated_logging_time=8.413018, accumulated_submission_time=65160.042655, global_step=146774, preemption_count=0, score=65160.042655, test/accuracy=0.630300, test/loss=1.581558, test/num_examples=10000, total_duration=70093.582762, train/accuracy=0.849805, train/loss=0.566409, validation/accuracy=0.752140, validation/loss=0.978649, validation/num_examples=50000
I0303 07:24:24.099336 139758017697536 logging_writer.py:48] [146800] global_step=146800, grad_norm=2.225609302520752, loss=1.5277619361877441
I0303 07:25:04.900007 139758009304832 logging_writer.py:48] [146900] global_step=146900, grad_norm=2.702199697494507, loss=1.3720247745513916
I0303 07:25:49.890730 139758017697536 logging_writer.py:48] [147000] global_step=147000, grad_norm=2.4195992946624756, loss=2.7188236713409424
I0303 07:26:34.867242 139758009304832 logging_writer.py:48] [147100] global_step=147100, grad_norm=2.4124019145965576, loss=1.4307795763015747
I0303 07:27:19.870841 139758017697536 logging_writer.py:48] [147200] global_step=147200, grad_norm=2.5736520290374756, loss=1.8829270601272583
I0303 07:28:04.727053 139758009304832 logging_writer.py:48] [147300] global_step=147300, grad_norm=2.8807194232940674, loss=3.804842710494995
I0303 07:28:49.604422 139758017697536 logging_writer.py:48] [147400] global_step=147400, grad_norm=2.092268228530884, loss=1.403780221939087
I0303 07:29:34.496985 139758009304832 logging_writer.py:48] [147500] global_step=147500, grad_norm=2.3933372497558594, loss=1.3652607202529907
I0303 07:30:19.300409 139758017697536 logging_writer.py:48] [147600] global_step=147600, grad_norm=2.299182653427124, loss=1.4512805938720703
I0303 07:31:04.408239 139758009304832 logging_writer.py:48] [147700] global_step=147700, grad_norm=2.3468573093414307, loss=1.6269792318344116
I0303 07:31:13.415998 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:31:24.218789 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:31:44.404525 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:31:46.040668 139953291118400 submission_runner.py:411] Time since start: 70546.22s, 	Step: 147722, 	{'train/accuracy': 0.8400195240974426, 'train/loss': 0.6110930442810059, 'validation/accuracy': 0.7532599568367004, 'validation/loss': 0.9788589477539062, 'validation/num_examples': 50000, 'test/accuracy': 0.6295000314712524, 'test/loss': 1.5846375226974487, 'test/num_examples': 10000, 'score': 65579.95571732521, 'total_duration': 70546.2168867588, 'accumulated_submission_time': 65579.95571732521, 'accumulated_eval_time': 4950.214616537094, 'accumulated_logging_time': 8.461366415023804}
I0303 07:31:46.085374 139758017697536 logging_writer.py:48] [147722] accumulated_eval_time=4950.214617, accumulated_logging_time=8.461366, accumulated_submission_time=65579.955717, global_step=147722, preemption_count=0, score=65579.955717, test/accuracy=0.629500, test/loss=1.584638, test/num_examples=10000, total_duration=70546.216887, train/accuracy=0.840020, train/loss=0.611093, validation/accuracy=0.753260, validation/loss=0.978859, validation/num_examples=50000
I0303 07:32:17.304075 139758009304832 logging_writer.py:48] [147800] global_step=147800, grad_norm=2.38055419921875, loss=1.59462571144104
I0303 07:33:01.988376 139758017697536 logging_writer.py:48] [147900] global_step=147900, grad_norm=2.281618356704712, loss=2.318401336669922
I0303 07:33:46.829159 139758009304832 logging_writer.py:48] [148000] global_step=148000, grad_norm=2.2701590061187744, loss=1.331964373588562
I0303 07:34:31.985631 139758017697536 logging_writer.py:48] [148100] global_step=148100, grad_norm=2.3953282833099365, loss=1.5171599388122559
I0303 07:35:16.693463 139758009304832 logging_writer.py:48] [148200] global_step=148200, grad_norm=2.1919806003570557, loss=1.360957384109497
I0303 07:36:01.649002 139758017697536 logging_writer.py:48] [148300] global_step=148300, grad_norm=2.3571531772613525, loss=1.4468677043914795
I0303 07:36:46.648485 139758009304832 logging_writer.py:48] [148400] global_step=148400, grad_norm=2.1884078979492188, loss=3.2463510036468506
I0303 07:37:31.390762 139758017697536 logging_writer.py:48] [148500] global_step=148500, grad_norm=2.4539783000946045, loss=2.4024693965911865
I0303 07:38:15.931852 139758009304832 logging_writer.py:48] [148600] global_step=148600, grad_norm=2.272944211959839, loss=1.4239425659179688
I0303 07:38:46.086689 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:38:57.243473 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:39:17.866951 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:39:19.495956 139953291118400 submission_runner.py:411] Time since start: 70999.67s, 	Step: 148669, 	{'train/accuracy': 0.840624988079071, 'train/loss': 0.6056962609291077, 'validation/accuracy': 0.7522000074386597, 'validation/loss': 0.9804185628890991, 'validation/num_examples': 50000, 'test/accuracy': 0.6278000473976135, 'test/loss': 1.5932260751724243, 'test/num_examples': 10000, 'score': 65999.89698147774, 'total_duration': 70999.6721727848, 'accumulated_submission_time': 65999.89698147774, 'accumulated_eval_time': 4983.62385559082, 'accumulated_logging_time': 8.5170156955719}
I0303 07:39:19.541937 139758017697536 logging_writer.py:48] [148669] accumulated_eval_time=4983.623856, accumulated_logging_time=8.517016, accumulated_submission_time=65999.896981, global_step=148669, preemption_count=0, score=65999.896981, test/accuracy=0.627800, test/loss=1.593226, test/num_examples=10000, total_duration=70999.672173, train/accuracy=0.840625, train/loss=0.605696, validation/accuracy=0.752200, validation/loss=0.980419, validation/num_examples=50000
I0303 07:39:32.177680 139758009304832 logging_writer.py:48] [148700] global_step=148700, grad_norm=2.8491265773773193, loss=3.5833957195281982
I0303 07:40:14.147032 139758017697536 logging_writer.py:48] [148800] global_step=148800, grad_norm=2.4998247623443604, loss=1.435180902481079
I0303 07:40:59.110640 139758009304832 logging_writer.py:48] [148900] global_step=148900, grad_norm=2.0487112998962402, loss=1.7632790803909302
I0303 07:41:43.807855 139758017697536 logging_writer.py:48] [149000] global_step=149000, grad_norm=2.584660053253174, loss=3.6540980339050293
I0303 07:42:28.822867 139758009304832 logging_writer.py:48] [149100] global_step=149100, grad_norm=2.460082530975342, loss=2.9741811752319336
I0303 07:43:13.657678 139758017697536 logging_writer.py:48] [149200] global_step=149200, grad_norm=2.256462812423706, loss=1.658373475074768
I0303 07:43:58.355803 139758009304832 logging_writer.py:48] [149300] global_step=149300, grad_norm=2.2422704696655273, loss=1.4449868202209473
I0303 07:44:43.284453 139758017697536 logging_writer.py:48] [149400] global_step=149400, grad_norm=2.364152193069458, loss=1.4098858833312988
I0303 07:45:28.214993 139758009304832 logging_writer.py:48] [149500] global_step=149500, grad_norm=4.937684535980225, loss=2.8429808616638184
I0303 07:46:13.180762 139758017697536 logging_writer.py:48] [149600] global_step=149600, grad_norm=2.383706569671631, loss=1.635819673538208
I0303 07:46:19.868016 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:46:30.774761 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:46:55.546318 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:46:57.169618 139953291118400 submission_runner.py:411] Time since start: 71457.35s, 	Step: 149616, 	{'train/accuracy': 0.8484765291213989, 'train/loss': 0.5737552046775818, 'validation/accuracy': 0.7560999989509583, 'validation/loss': 0.9599688649177551, 'validation/num_examples': 50000, 'test/accuracy': 0.6355000138282776, 'test/loss': 1.575750470161438, 'test/num_examples': 10000, 'score': 66420.16347050667, 'total_duration': 71457.34581279755, 'accumulated_submission_time': 66420.16347050667, 'accumulated_eval_time': 5020.925404548645, 'accumulated_logging_time': 8.574753284454346}
I0303 07:46:57.207339 139758009304832 logging_writer.py:48] [149616] accumulated_eval_time=5020.925405, accumulated_logging_time=8.574753, accumulated_submission_time=66420.163471, global_step=149616, preemption_count=0, score=66420.163471, test/accuracy=0.635500, test/loss=1.575750, test/num_examples=10000, total_duration=71457.345813, train/accuracy=0.848477, train/loss=0.573755, validation/accuracy=0.756100, validation/loss=0.959969, validation/num_examples=50000
I0303 07:47:30.758904 139758017697536 logging_writer.py:48] [149700] global_step=149700, grad_norm=2.3136603832244873, loss=1.5405755043029785
I0303 07:48:14.750472 139758009304832 logging_writer.py:48] [149800] global_step=149800, grad_norm=2.405959367752075, loss=1.431322455406189
I0303 07:48:59.758813 139758017697536 logging_writer.py:48] [149900] global_step=149900, grad_norm=2.2053356170654297, loss=2.225022792816162
I0303 07:49:45.255003 139758009304832 logging_writer.py:48] [150000] global_step=150000, grad_norm=2.457078456878662, loss=1.5610027313232422
I0303 07:50:30.208112 139758017697536 logging_writer.py:48] [150100] global_step=150100, grad_norm=2.6193747520446777, loss=1.7369405031204224
I0303 07:51:15.582107 139758009304832 logging_writer.py:48] [150200] global_step=150200, grad_norm=2.4293909072875977, loss=1.4635562896728516
I0303 07:52:00.140272 139758017697536 logging_writer.py:48] [150300] global_step=150300, grad_norm=2.29280161857605, loss=1.3723981380462646
I0303 07:52:45.077828 139758009304832 logging_writer.py:48] [150400] global_step=150400, grad_norm=2.2373290061950684, loss=1.9066075086593628
I0303 07:53:29.970778 139758017697536 logging_writer.py:48] [150500] global_step=150500, grad_norm=2.2825090885162354, loss=2.3286080360412598
I0303 07:53:57.369679 139953291118400 spec.py:321] Evaluating on the training split.
I0303 07:54:08.364001 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 07:54:28.950573 139953291118400 spec.py:349] Evaluating on the test split.
I0303 07:54:30.597598 139953291118400 submission_runner.py:411] Time since start: 71910.77s, 	Step: 150563, 	{'train/accuracy': 0.8442773222923279, 'train/loss': 0.588003396987915, 'validation/accuracy': 0.7562599778175354, 'validation/loss': 0.963024377822876, 'validation/num_examples': 50000, 'test/accuracy': 0.6318000555038452, 'test/loss': 1.5865153074264526, 'test/num_examples': 10000, 'score': 66840.26841020584, 'total_duration': 71910.77382802963, 'accumulated_submission_time': 66840.26841020584, 'accumulated_eval_time': 5054.153319835663, 'accumulated_logging_time': 8.622200965881348}
I0303 07:54:30.637202 139758009304832 logging_writer.py:48] [150563] accumulated_eval_time=5054.153320, accumulated_logging_time=8.622201, accumulated_submission_time=66840.268410, global_step=150563, preemption_count=0, score=66840.268410, test/accuracy=0.631800, test/loss=1.586515, test/num_examples=10000, total_duration=71910.773828, train/accuracy=0.844277, train/loss=0.588003, validation/accuracy=0.756260, validation/loss=0.963024, validation/num_examples=50000
I0303 07:54:45.655002 139758017697536 logging_writer.py:48] [150600] global_step=150600, grad_norm=2.1748340129852295, loss=2.0881407260894775
I0303 07:55:27.461411 139758009304832 logging_writer.py:48] [150700] global_step=150700, grad_norm=2.6492862701416016, loss=1.8811503648757935
I0303 07:56:12.658406 139758017697536 logging_writer.py:48] [150800] global_step=150800, grad_norm=2.4217658042907715, loss=1.6881741285324097
I0303 07:56:58.210031 139758009304832 logging_writer.py:48] [150900] global_step=150900, grad_norm=2.1781835556030273, loss=2.1396942138671875
I0303 07:57:43.278359 139758017697536 logging_writer.py:48] [151000] global_step=151000, grad_norm=2.213228702545166, loss=1.4068366289138794
I0303 07:58:28.084697 139758009304832 logging_writer.py:48] [151100] global_step=151100, grad_norm=2.457557439804077, loss=1.711883544921875
I0303 07:59:13.257790 139758017697536 logging_writer.py:48] [151200] global_step=151200, grad_norm=2.871445894241333, loss=3.088021993637085
I0303 07:59:58.452068 139758009304832 logging_writer.py:48] [151300] global_step=151300, grad_norm=2.446723461151123, loss=1.419034719467163
I0303 08:00:43.980241 139758017697536 logging_writer.py:48] [151400] global_step=151400, grad_norm=2.600931167602539, loss=3.564657688140869
I0303 08:01:28.964386 139758009304832 logging_writer.py:48] [151500] global_step=151500, grad_norm=2.34415864944458, loss=2.351313352584839
I0303 08:01:31.013432 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:01:42.166497 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:02:03.594116 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:02:05.235663 139953291118400 submission_runner.py:411] Time since start: 72365.41s, 	Step: 151506, 	{'train/accuracy': 0.8475585579872131, 'train/loss': 0.5803536772727966, 'validation/accuracy': 0.7574999928474426, 'validation/loss': 0.9603232741355896, 'validation/num_examples': 50000, 'test/accuracy': 0.6328000426292419, 'test/loss': 1.5705757141113281, 'test/num_examples': 10000, 'score': 67260.58755874634, 'total_duration': 72365.41188597679, 'accumulated_submission_time': 67260.58755874634, 'accumulated_eval_time': 5088.375540494919, 'accumulated_logging_time': 8.670436143875122}
I0303 08:02:05.281565 139758017697536 logging_writer.py:48] [151506] accumulated_eval_time=5088.375540, accumulated_logging_time=8.670436, accumulated_submission_time=67260.587559, global_step=151506, preemption_count=0, score=67260.587559, test/accuracy=0.632800, test/loss=1.570576, test/num_examples=10000, total_duration=72365.411886, train/accuracy=0.847559, train/loss=0.580354, validation/accuracy=0.757500, validation/loss=0.960323, validation/num_examples=50000
I0303 08:02:43.193380 139758009304832 logging_writer.py:48] [151600] global_step=151600, grad_norm=2.529540538787842, loss=1.4143991470336914
I0303 08:03:27.911354 139758017697536 logging_writer.py:48] [151700] global_step=151700, grad_norm=2.3118743896484375, loss=1.4228872060775757
I0303 08:04:12.886984 139758009304832 logging_writer.py:48] [151800] global_step=151800, grad_norm=2.188687562942505, loss=1.679018497467041
I0303 08:04:58.069500 139758017697536 logging_writer.py:48] [151900] global_step=151900, grad_norm=2.6066081523895264, loss=1.3920025825500488
I0303 08:05:43.016035 139758009304832 logging_writer.py:48] [152000] global_step=152000, grad_norm=2.275066614151001, loss=1.7786383628845215
I0303 08:06:27.981383 139758017697536 logging_writer.py:48] [152100] global_step=152100, grad_norm=2.3578038215637207, loss=1.6494824886322021
I0303 08:07:12.918310 139758009304832 logging_writer.py:48] [152200] global_step=152200, grad_norm=2.2117977142333984, loss=1.6450774669647217
I0303 08:07:57.606847 139758017697536 logging_writer.py:48] [152300] global_step=152300, grad_norm=2.6330862045288086, loss=1.3680405616760254
I0303 08:08:42.587887 139758009304832 logging_writer.py:48] [152400] global_step=152400, grad_norm=2.3444952964782715, loss=1.6883171796798706
I0303 08:09:05.365107 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:09:16.604204 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:09:34.460235 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:09:36.096060 139953291118400 submission_runner.py:411] Time since start: 72816.27s, 	Step: 152452, 	{'train/accuracy': 0.8537304401397705, 'train/loss': 0.5536989569664001, 'validation/accuracy': 0.7576799988746643, 'validation/loss': 0.9566033482551575, 'validation/num_examples': 50000, 'test/accuracy': 0.636400043964386, 'test/loss': 1.5653671026229858, 'test/num_examples': 10000, 'score': 67680.61174440384, 'total_duration': 72816.272285223, 'accumulated_submission_time': 67680.61174440384, 'accumulated_eval_time': 5119.106483459473, 'accumulated_logging_time': 8.727611780166626}
I0303 08:09:36.143978 139758017697536 logging_writer.py:48] [152452] accumulated_eval_time=5119.106483, accumulated_logging_time=8.727612, accumulated_submission_time=67680.611744, global_step=152452, preemption_count=0, score=67680.611744, test/accuracy=0.636400, test/loss=1.565367, test/num_examples=10000, total_duration=72816.272285, train/accuracy=0.853730, train/loss=0.553699, validation/accuracy=0.757680, validation/loss=0.956603, validation/num_examples=50000
I0303 08:09:55.502270 139758009304832 logging_writer.py:48] [152500] global_step=152500, grad_norm=2.607943296432495, loss=1.396877646446228
I0303 08:10:39.267153 139758017697536 logging_writer.py:48] [152600] global_step=152600, grad_norm=2.54844069480896, loss=2.9232048988342285
I0303 08:11:24.306210 139758009304832 logging_writer.py:48] [152700] global_step=152700, grad_norm=2.495210886001587, loss=3.1519932746887207
I0303 08:12:09.619940 139758017697536 logging_writer.py:48] [152800] global_step=152800, grad_norm=2.547029733657837, loss=1.3750280141830444
I0303 08:12:54.565114 139758009304832 logging_writer.py:48] [152900] global_step=152900, grad_norm=2.3243184089660645, loss=1.3299016952514648
I0303 08:13:39.527099 139758017697536 logging_writer.py:48] [153000] global_step=153000, grad_norm=2.3835384845733643, loss=1.3222064971923828
I0303 08:14:24.597678 139758009304832 logging_writer.py:48] [153100] global_step=153100, grad_norm=2.4576542377471924, loss=1.7470955848693848
I0303 08:15:09.541238 139758017697536 logging_writer.py:48] [153200] global_step=153200, grad_norm=2.461036205291748, loss=1.380447268486023
I0303 08:15:54.559835 139758009304832 logging_writer.py:48] [153300] global_step=153300, grad_norm=2.2930121421813965, loss=2.45198392868042
I0303 08:16:36.199509 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:16:47.340862 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:17:08.316419 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:17:09.960145 139953291118400 submission_runner.py:411] Time since start: 73270.14s, 	Step: 153394, 	{'train/accuracy': 0.8624218702316284, 'train/loss': 0.5283911824226379, 'validation/accuracy': 0.7599799633026123, 'validation/loss': 0.9521071910858154, 'validation/num_examples': 50000, 'test/accuracy': 0.6341000199317932, 'test/loss': 1.5579533576965332, 'test/num_examples': 10000, 'score': 68100.60788464546, 'total_duration': 73270.136343956, 'accumulated_submission_time': 68100.60788464546, 'accumulated_eval_time': 5152.867078065872, 'accumulated_logging_time': 8.786496639251709}
I0303 08:17:10.009834 139758017697536 logging_writer.py:48] [153394] accumulated_eval_time=5152.867078, accumulated_logging_time=8.786497, accumulated_submission_time=68100.607885, global_step=153394, preemption_count=0, score=68100.607885, test/accuracy=0.634100, test/loss=1.557953, test/num_examples=10000, total_duration=73270.136344, train/accuracy=0.862422, train/loss=0.528391, validation/accuracy=0.759980, validation/loss=0.952107, validation/num_examples=50000
I0303 08:17:12.802449 139758009304832 logging_writer.py:48] [153400] global_step=153400, grad_norm=2.3588292598724365, loss=1.3787994384765625
I0303 08:17:53.199198 139758017697536 logging_writer.py:48] [153500] global_step=153500, grad_norm=2.3304479122161865, loss=2.173602819442749
I0303 08:18:38.123312 139758009304832 logging_writer.py:48] [153600] global_step=153600, grad_norm=2.304474353790283, loss=1.6216092109680176
I0303 08:19:23.427577 139758017697536 logging_writer.py:48] [153700] global_step=153700, grad_norm=2.9221155643463135, loss=3.454315662384033
I0303 08:20:08.687906 139758009304832 logging_writer.py:48] [153800] global_step=153800, grad_norm=2.5277457237243652, loss=1.294952630996704
I0303 08:20:53.601748 139758017697536 logging_writer.py:48] [153900] global_step=153900, grad_norm=2.238886833190918, loss=1.9649786949157715
I0303 08:21:38.509876 139758009304832 logging_writer.py:48] [154000] global_step=154000, grad_norm=2.6535935401916504, loss=1.3274013996124268
I0303 08:22:23.548841 139758017697536 logging_writer.py:48] [154100] global_step=154100, grad_norm=2.608736276626587, loss=1.3296922445297241
I0303 08:23:08.478140 139758009304832 logging_writer.py:48] [154200] global_step=154200, grad_norm=2.581267833709717, loss=1.433872938156128
I0303 08:23:53.186565 139758017697536 logging_writer.py:48] [154300] global_step=154300, grad_norm=2.6049304008483887, loss=1.3606818914413452
I0303 08:24:10.140613 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:24:20.966669 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:24:38.785160 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:24:40.417203 139953291118400 submission_runner.py:411] Time since start: 73720.59s, 	Step: 154339, 	{'train/accuracy': 0.8519921898841858, 'train/loss': 0.5664136409759521, 'validation/accuracy': 0.7613399624824524, 'validation/loss': 0.9477301836013794, 'validation/num_examples': 50000, 'test/accuracy': 0.6384000182151794, 'test/loss': 1.555184006690979, 'test/num_examples': 10000, 'score': 68520.679936409, 'total_duration': 73720.59342503548, 'accumulated_submission_time': 68520.679936409, 'accumulated_eval_time': 5183.143657207489, 'accumulated_logging_time': 8.846336364746094}
I0303 08:24:40.472091 139758009304832 logging_writer.py:48] [154339] accumulated_eval_time=5183.143657, accumulated_logging_time=8.846336, accumulated_submission_time=68520.679936, global_step=154339, preemption_count=0, score=68520.679936, test/accuracy=0.638400, test/loss=1.555184, test/num_examples=10000, total_duration=73720.593425, train/accuracy=0.851992, train/loss=0.566414, validation/accuracy=0.761340, validation/loss=0.947730, validation/num_examples=50000
I0303 08:25:04.961270 139758017697536 logging_writer.py:48] [154400] global_step=154400, grad_norm=2.418546438217163, loss=1.3083772659301758
I0303 08:25:48.776092 139758009304832 logging_writer.py:48] [154500] global_step=154500, grad_norm=2.4455533027648926, loss=1.793541431427002
I0303 08:26:34.075112 139758017697536 logging_writer.py:48] [154600] global_step=154600, grad_norm=2.4198920726776123, loss=1.4211500883102417
I0303 08:27:19.180682 139758009304832 logging_writer.py:48] [154700] global_step=154700, grad_norm=2.594102382659912, loss=1.3216497898101807
I0303 08:28:03.777086 139758017697536 logging_writer.py:48] [154800] global_step=154800, grad_norm=2.5374133586883545, loss=1.4121814966201782
I0303 08:28:48.631933 139758009304832 logging_writer.py:48] [154900] global_step=154900, grad_norm=2.3862037658691406, loss=1.6888742446899414
I0303 08:29:33.579020 139758017697536 logging_writer.py:48] [155000] global_step=155000, grad_norm=2.6116561889648438, loss=1.2693204879760742
I0303 08:30:18.493250 139758009304832 logging_writer.py:48] [155100] global_step=155100, grad_norm=2.6462016105651855, loss=2.330502986907959
I0303 08:31:03.991384 139758017697536 logging_writer.py:48] [155200] global_step=155200, grad_norm=2.888167142868042, loss=3.1188745498657227
I0303 08:31:40.631412 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:31:51.711793 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:32:16.573255 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:32:18.210466 139953291118400 submission_runner.py:411] Time since start: 74178.39s, 	Step: 155283, 	{'train/accuracy': 0.85498046875, 'train/loss': 0.5443105697631836, 'validation/accuracy': 0.7622199654579163, 'validation/loss': 0.9341087341308594, 'validation/num_examples': 50000, 'test/accuracy': 0.6430000066757202, 'test/loss': 1.5386472940444946, 'test/num_examples': 10000, 'score': 68940.78204774857, 'total_duration': 74178.38667702675, 'accumulated_submission_time': 68940.78204774857, 'accumulated_eval_time': 5220.722696304321, 'accumulated_logging_time': 8.91114854812622}
I0303 08:32:18.255012 139758009304832 logging_writer.py:48] [155283] accumulated_eval_time=5220.722696, accumulated_logging_time=8.911149, accumulated_submission_time=68940.782048, global_step=155283, preemption_count=0, score=68940.782048, test/accuracy=0.643000, test/loss=1.538647, test/num_examples=10000, total_duration=74178.386677, train/accuracy=0.854980, train/loss=0.544311, validation/accuracy=0.762220, validation/loss=0.934109, validation/num_examples=50000
I0303 08:32:25.370816 139758017697536 logging_writer.py:48] [155300] global_step=155300, grad_norm=2.5105679035186768, loss=1.345033049583435
I0303 08:33:05.897621 139758009304832 logging_writer.py:48] [155400] global_step=155400, grad_norm=2.5775961875915527, loss=1.5129711627960205
I0303 08:33:50.604326 139758017697536 logging_writer.py:48] [155500] global_step=155500, grad_norm=2.625775098800659, loss=1.3488390445709229
I0303 08:34:35.726744 139758009304832 logging_writer.py:48] [155600] global_step=155600, grad_norm=2.4779229164123535, loss=1.4729524850845337
I0303 08:35:20.793492 139758017697536 logging_writer.py:48] [155700] global_step=155700, grad_norm=2.364020347595215, loss=1.53094482421875
I0303 08:36:05.688264 139758009304832 logging_writer.py:48] [155800] global_step=155800, grad_norm=2.4418303966522217, loss=2.8221397399902344
I0303 08:36:51.031696 139758017697536 logging_writer.py:48] [155900] global_step=155900, grad_norm=2.6722588539123535, loss=1.386230707168579
I0303 08:37:36.201252 139758009304832 logging_writer.py:48] [156000] global_step=156000, grad_norm=2.421274423599243, loss=1.383924126625061
I0303 08:38:21.181465 139758017697536 logging_writer.py:48] [156100] global_step=156100, grad_norm=2.318305015563965, loss=2.089005947113037
I0303 08:39:06.246755 139758009304832 logging_writer.py:48] [156200] global_step=156200, grad_norm=2.7063920497894287, loss=1.7047293186187744
I0303 08:39:18.592199 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:39:29.406940 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:39:54.102731 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:39:55.730953 139953291118400 submission_runner.py:411] Time since start: 74635.91s, 	Step: 156229, 	{'train/accuracy': 0.8586718440055847, 'train/loss': 0.5289605855941772, 'validation/accuracy': 0.7625399827957153, 'validation/loss': 0.937669038772583, 'validation/num_examples': 50000, 'test/accuracy': 0.6414000391960144, 'test/loss': 1.5460975170135498, 'test/num_examples': 10000, 'score': 69361.06091952324, 'total_duration': 74635.90718269348, 'accumulated_submission_time': 69361.06091952324, 'accumulated_eval_time': 5257.861455440521, 'accumulated_logging_time': 8.966075658798218}
I0303 08:39:55.769617 139758017697536 logging_writer.py:48] [156229] accumulated_eval_time=5257.861455, accumulated_logging_time=8.966076, accumulated_submission_time=69361.060920, global_step=156229, preemption_count=0, score=69361.060920, test/accuracy=0.641400, test/loss=1.546098, test/num_examples=10000, total_duration=74635.907183, train/accuracy=0.858672, train/loss=0.528961, validation/accuracy=0.762540, validation/loss=0.937669, validation/num_examples=50000
I0303 08:40:24.406406 139758009304832 logging_writer.py:48] [156300] global_step=156300, grad_norm=3.654663324356079, loss=3.3021092414855957
I0303 08:41:08.262947 139758017697536 logging_writer.py:48] [156400] global_step=156400, grad_norm=2.455456018447876, loss=2.08901309967041
I0303 08:41:53.520197 139758009304832 logging_writer.py:48] [156500] global_step=156500, grad_norm=2.706101655960083, loss=3.3438355922698975
I0303 08:42:38.738353 139758017697536 logging_writer.py:48] [156600] global_step=156600, grad_norm=2.860048770904541, loss=3.5235443115234375
I0303 08:43:23.474534 139758009304832 logging_writer.py:48] [156700] global_step=156700, grad_norm=2.965548276901245, loss=3.563722610473633
I0303 08:44:08.633629 139758017697536 logging_writer.py:48] [156800] global_step=156800, grad_norm=2.427668333053589, loss=1.371816635131836
I0303 08:44:53.671627 139758009304832 logging_writer.py:48] [156900] global_step=156900, grad_norm=2.706669330596924, loss=1.3022589683532715
I0303 08:45:38.437415 139758017697536 logging_writer.py:48] [157000] global_step=157000, grad_norm=2.9296576976776123, loss=3.402431011199951
I0303 08:46:23.537498 139758009304832 logging_writer.py:48] [157100] global_step=157100, grad_norm=2.511852502822876, loss=1.7797160148620605
I0303 08:46:56.089138 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:47:07.555934 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:47:25.776420 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:47:27.449304 139953291118400 submission_runner.py:411] Time since start: 75087.63s, 	Step: 157174, 	{'train/accuracy': 0.8605468273162842, 'train/loss': 0.5198253989219666, 'validation/accuracy': 0.7628399729728699, 'validation/loss': 0.9245589375495911, 'validation/num_examples': 50000, 'test/accuracy': 0.643500030040741, 'test/loss': 1.5365839004516602, 'test/num_examples': 10000, 'score': 69781.32340240479, 'total_duration': 75087.62546420097, 'accumulated_submission_time': 69781.32340240479, 'accumulated_eval_time': 5289.2215440273285, 'accumulated_logging_time': 9.013855934143066}
I0303 08:47:27.519542 139758017697536 logging_writer.py:48] [157174] accumulated_eval_time=5289.221544, accumulated_logging_time=9.013856, accumulated_submission_time=69781.323402, global_step=157174, preemption_count=0, score=69781.323402, test/accuracy=0.643500, test/loss=1.536584, test/num_examples=10000, total_duration=75087.625464, train/accuracy=0.860547, train/loss=0.519825, validation/accuracy=0.762840, validation/loss=0.924559, validation/num_examples=50000
I0303 08:47:38.198612 139758009304832 logging_writer.py:48] [157200] global_step=157200, grad_norm=2.4890248775482178, loss=1.2538104057312012
I0303 08:48:20.011425 139758017697536 logging_writer.py:48] [157300] global_step=157300, grad_norm=2.6140694618225098, loss=2.394094228744507
I0303 08:49:04.941167 139758009304832 logging_writer.py:48] [157400] global_step=157400, grad_norm=2.6713857650756836, loss=1.3843584060668945
I0303 08:49:50.013108 139758017697536 logging_writer.py:48] [157500] global_step=157500, grad_norm=2.690934896469116, loss=1.5339760780334473
I0303 08:50:35.116538 139758009304832 logging_writer.py:48] [157600] global_step=157600, grad_norm=2.528968572616577, loss=2.2581515312194824
I0303 08:51:20.658866 139758017697536 logging_writer.py:48] [157700] global_step=157700, grad_norm=2.704401969909668, loss=3.0210564136505127
I0303 08:52:05.974086 139758009304832 logging_writer.py:48] [157800] global_step=157800, grad_norm=2.4129369258880615, loss=1.9853754043579102
I0303 08:52:51.233185 139758017697536 logging_writer.py:48] [157900] global_step=157900, grad_norm=2.312668561935425, loss=1.7880892753601074
I0303 08:53:35.951193 139758009304832 logging_writer.py:48] [158000] global_step=158000, grad_norm=2.4935646057128906, loss=2.9159300327301025
I0303 08:54:21.005846 139758017697536 logging_writer.py:48] [158100] global_step=158100, grad_norm=3.0224063396453857, loss=3.3591980934143066
I0303 08:54:27.507275 139953291118400 spec.py:321] Evaluating on the training split.
I0303 08:54:38.659391 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 08:54:59.023230 139953291118400 spec.py:349] Evaluating on the test split.
I0303 08:55:00.660266 139953291118400 submission_runner.py:411] Time since start: 75540.84s, 	Step: 158116, 	{'train/accuracy': 0.8600195050239563, 'train/loss': 0.5220351219177246, 'validation/accuracy': 0.7657999992370605, 'validation/loss': 0.922173261642456, 'validation/num_examples': 50000, 'test/accuracy': 0.6447000503540039, 'test/loss': 1.5228381156921387, 'test/num_examples': 10000, 'score': 70201.25111293793, 'total_duration': 75540.83647584915, 'accumulated_submission_time': 70201.25111293793, 'accumulated_eval_time': 5322.374501943588, 'accumulated_logging_time': 9.09701156616211}
I0303 08:55:00.707543 139758009304832 logging_writer.py:48] [158116] accumulated_eval_time=5322.374502, accumulated_logging_time=9.097012, accumulated_submission_time=70201.251113, global_step=158116, preemption_count=0, score=70201.251113, test/accuracy=0.644700, test/loss=1.522838, test/num_examples=10000, total_duration=75540.836476, train/accuracy=0.860020, train/loss=0.522035, validation/accuracy=0.765800, validation/loss=0.922173, validation/num_examples=50000
I0303 08:55:34.811011 139758017697536 logging_writer.py:48] [158200] global_step=158200, grad_norm=2.3203420639038086, loss=1.7396641969680786
I0303 08:56:19.785058 139758009304832 logging_writer.py:48] [158300] global_step=158300, grad_norm=2.3581910133361816, loss=2.081357002258301
I0303 08:57:04.735445 139758017697536 logging_writer.py:48] [158400] global_step=158400, grad_norm=2.815948724746704, loss=1.3360708951950073
I0303 08:57:49.818638 139758009304832 logging_writer.py:48] [158500] global_step=158500, grad_norm=2.6035547256469727, loss=1.224038004875183
I0303 08:58:34.609158 139758017697536 logging_writer.py:48] [158600] global_step=158600, grad_norm=2.8942384719848633, loss=1.8503687381744385
I0303 08:59:19.889267 139758009304832 logging_writer.py:48] [158700] global_step=158700, grad_norm=3.138639211654663, loss=3.596515417098999
I0303 09:00:05.139636 139758017697536 logging_writer.py:48] [158800] global_step=158800, grad_norm=2.7597055435180664, loss=2.1552467346191406
I0303 09:00:50.139787 139758009304832 logging_writer.py:48] [158900] global_step=158900, grad_norm=2.8578567504882812, loss=2.979247570037842
I0303 09:01:34.974692 139758017697536 logging_writer.py:48] [159000] global_step=159000, grad_norm=2.560696601867676, loss=1.9373739957809448
I0303 09:02:00.742774 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:02:12.135708 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:02:30.627730 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:02:32.273433 139953291118400 submission_runner.py:411] Time since start: 75992.45s, 	Step: 159059, 	{'train/accuracy': 0.8639453053474426, 'train/loss': 0.5182149410247803, 'validation/accuracy': 0.7652599811553955, 'validation/loss': 0.925984799861908, 'validation/num_examples': 50000, 'test/accuracy': 0.6422000527381897, 'test/loss': 1.5358188152313232, 'test/num_examples': 10000, 'score': 70621.22784686089, 'total_duration': 75992.44965624809, 'accumulated_submission_time': 70621.22784686089, 'accumulated_eval_time': 5353.905155658722, 'accumulated_logging_time': 9.155547142028809}
I0303 09:02:32.326660 139758009304832 logging_writer.py:48] [159059] accumulated_eval_time=5353.905156, accumulated_logging_time=9.155547, accumulated_submission_time=70621.227847, global_step=159059, preemption_count=0, score=70621.227847, test/accuracy=0.642200, test/loss=1.535819, test/num_examples=10000, total_duration=75992.449656, train/accuracy=0.863945, train/loss=0.518215, validation/accuracy=0.765260, validation/loss=0.925985, validation/num_examples=50000
I0303 09:02:48.926354 139758017697536 logging_writer.py:48] [159100] global_step=159100, grad_norm=2.373835802078247, loss=1.2651209831237793
I0303 09:03:32.487760 139758009304832 logging_writer.py:48] [159200] global_step=159200, grad_norm=2.6967105865478516, loss=1.2940717935562134
I0303 09:04:17.482973 139758017697536 logging_writer.py:48] [159300] global_step=159300, grad_norm=2.6305296421051025, loss=2.3987812995910645
I0303 09:05:02.702920 139758009304832 logging_writer.py:48] [159400] global_step=159400, grad_norm=2.5875110626220703, loss=1.452596664428711
I0303 09:05:47.828325 139758017697536 logging_writer.py:48] [159500] global_step=159500, grad_norm=2.7758326530456543, loss=2.9207615852355957
I0303 09:06:32.915246 139758009304832 logging_writer.py:48] [159600] global_step=159600, grad_norm=3.2541587352752686, loss=3.4885876178741455
I0303 09:07:17.780902 139758017697536 logging_writer.py:48] [159700] global_step=159700, grad_norm=2.9559240341186523, loss=3.3915536403656006
I0303 09:08:02.900768 139758009304832 logging_writer.py:48] [159800] global_step=159800, grad_norm=3.115846872329712, loss=3.433514356613159
I0303 09:08:47.879861 139758017697536 logging_writer.py:48] [159900] global_step=159900, grad_norm=2.7910702228546143, loss=1.4614038467407227
I0303 09:09:32.334880 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:09:43.308692 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:10:02.689797 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:10:04.324981 139953291118400 submission_runner.py:411] Time since start: 76444.50s, 	Step: 160000, 	{'train/accuracy': 0.8701952695846558, 'train/loss': 0.4905823767185211, 'validation/accuracy': 0.7658799886703491, 'validation/loss': 0.9287203550338745, 'validation/num_examples': 50000, 'test/accuracy': 0.65010005235672, 'test/loss': 1.5326465368270874, 'test/num_examples': 10000, 'score': 71041.17511677742, 'total_duration': 76444.50120282173, 'accumulated_submission_time': 71041.17511677742, 'accumulated_eval_time': 5385.8952486515045, 'accumulated_logging_time': 9.221797943115234}
I0303 09:10:04.374307 139758009304832 logging_writer.py:48] [160000] accumulated_eval_time=5385.895249, accumulated_logging_time=9.221798, accumulated_submission_time=71041.175117, global_step=160000, preemption_count=0, score=71041.175117, test/accuracy=0.650100, test/loss=1.532647, test/num_examples=10000, total_duration=76444.501203, train/accuracy=0.870195, train/loss=0.490582, validation/accuracy=0.765880, validation/loss=0.928720, validation/num_examples=50000
I0303 09:10:04.806640 139758017697536 logging_writer.py:48] [160000] global_step=160000, grad_norm=2.8216729164123535, loss=1.2449733018875122
I0303 09:10:45.618093 139758009304832 logging_writer.py:48] [160100] global_step=160100, grad_norm=2.870577096939087, loss=1.423628807067871
I0303 09:11:30.839405 139758017697536 logging_writer.py:48] [160200] global_step=160200, grad_norm=3.0167434215545654, loss=3.266165256500244
I0303 09:12:15.778936 139758009304832 logging_writer.py:48] [160300] global_step=160300, grad_norm=2.598068952560425, loss=1.2189860343933105
I0303 09:13:00.672333 139758017697536 logging_writer.py:48] [160400] global_step=160400, grad_norm=3.0506207942962646, loss=1.2775441408157349
I0303 09:13:45.909621 139758009304832 logging_writer.py:48] [160500] global_step=160500, grad_norm=2.573155164718628, loss=1.706659197807312
I0303 09:14:30.834337 139758017697536 logging_writer.py:48] [160600] global_step=160600, grad_norm=2.45556378364563, loss=2.2103536128997803
I0303 09:15:15.650478 139758009304832 logging_writer.py:48] [160700] global_step=160700, grad_norm=3.0591652393341064, loss=3.4831833839416504
I0303 09:16:00.361907 139758017697536 logging_writer.py:48] [160800] global_step=160800, grad_norm=2.9574384689331055, loss=1.6494388580322266
I0303 09:16:45.434612 139758009304832 logging_writer.py:48] [160900] global_step=160900, grad_norm=2.458749532699585, loss=1.4816055297851562
I0303 09:17:04.488151 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:17:16.144914 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:17:36.425313 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:17:38.057251 139953291118400 submission_runner.py:411] Time since start: 76898.23s, 	Step: 160944, 	{'train/accuracy': 0.8650195002555847, 'train/loss': 0.5044265985488892, 'validation/accuracy': 0.7679399847984314, 'validation/loss': 0.9082586765289307, 'validation/num_examples': 50000, 'test/accuracy': 0.6476000547409058, 'test/loss': 1.5069485902786255, 'test/num_examples': 10000, 'score': 71461.22817921638, 'total_duration': 76898.23347449303, 'accumulated_submission_time': 71461.22817921638, 'accumulated_eval_time': 5419.464338064194, 'accumulated_logging_time': 9.283828735351562}
I0303 09:17:38.116417 139758017697536 logging_writer.py:48] [160944] accumulated_eval_time=5419.464338, accumulated_logging_time=9.283829, accumulated_submission_time=71461.228179, global_step=160944, preemption_count=0, score=71461.228179, test/accuracy=0.647600, test/loss=1.506949, test/num_examples=10000, total_duration=76898.233474, train/accuracy=0.865020, train/loss=0.504427, validation/accuracy=0.767940, validation/loss=0.908259, validation/num_examples=50000
I0303 09:18:00.621021 139758009304832 logging_writer.py:48] [161000] global_step=161000, grad_norm=2.5824902057647705, loss=1.6744256019592285
I0303 09:18:44.122323 139758017697536 logging_writer.py:48] [161100] global_step=161100, grad_norm=2.5722272396087646, loss=1.1890604496002197
I0303 09:19:29.401228 139758009304832 logging_writer.py:48] [161200] global_step=161200, grad_norm=2.966412305831909, loss=1.1524158716201782
I0303 09:20:14.750592 139758017697536 logging_writer.py:48] [161300] global_step=161300, grad_norm=2.81819748878479, loss=2.8522515296936035
I0303 09:21:00.095272 139758009304832 logging_writer.py:48] [161400] global_step=161400, grad_norm=2.9031522274017334, loss=1.2942241430282593
I0303 09:21:45.113780 139758017697536 logging_writer.py:48] [161500] global_step=161500, grad_norm=2.4619858264923096, loss=1.7700717449188232
I0303 09:22:30.179035 139758009304832 logging_writer.py:48] [161600] global_step=161600, grad_norm=2.5772645473480225, loss=2.3723464012145996
I0303 09:23:15.395159 139758017697536 logging_writer.py:48] [161700] global_step=161700, grad_norm=2.8342809677124023, loss=1.306900143623352
I0303 09:24:00.258989 139758009304832 logging_writer.py:48] [161800] global_step=161800, grad_norm=2.761204242706299, loss=1.2425755262374878
I0303 09:24:38.144364 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:24:48.953778 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:25:07.225784 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:25:08.861269 139953291118400 submission_runner.py:411] Time since start: 77349.04s, 	Step: 161886, 	{'train/accuracy': 0.8689648509025574, 'train/loss': 0.49307504296302795, 'validation/accuracy': 0.7684199810028076, 'validation/loss': 0.9124515652656555, 'validation/num_examples': 50000, 'test/accuracy': 0.648300051689148, 'test/loss': 1.5145506858825684, 'test/num_examples': 10000, 'score': 71881.19460654259, 'total_duration': 77349.03749322891, 'accumulated_submission_time': 71881.19460654259, 'accumulated_eval_time': 5450.181225776672, 'accumulated_logging_time': 9.357109308242798}
I0303 09:25:08.911177 139758017697536 logging_writer.py:48] [161886] accumulated_eval_time=5450.181226, accumulated_logging_time=9.357109, accumulated_submission_time=71881.194607, global_step=161886, preemption_count=0, score=71881.194607, test/accuracy=0.648300, test/loss=1.514551, test/num_examples=10000, total_duration=77349.037493, train/accuracy=0.868965, train/loss=0.493075, validation/accuracy=0.768420, validation/loss=0.912452, validation/num_examples=50000
I0303 09:25:14.861920 139758009304832 logging_writer.py:48] [161900] global_step=161900, grad_norm=3.0350842475891113, loss=3.610970973968506
I0303 09:25:56.080100 139758017697536 logging_writer.py:48] [162000] global_step=162000, grad_norm=2.8351078033447266, loss=1.1711386442184448
I0303 09:26:41.159394 139758009304832 logging_writer.py:48] [162100] global_step=162100, grad_norm=3.1171071529388428, loss=3.3828396797180176
I0303 09:27:26.145288 139758017697536 logging_writer.py:48] [162200] global_step=162200, grad_norm=3.4008493423461914, loss=3.3121438026428223
I0303 09:28:11.179740 139758009304832 logging_writer.py:48] [162300] global_step=162300, grad_norm=2.671734094619751, loss=1.2800363302230835
I0303 09:28:56.115119 139758017697536 logging_writer.py:48] [162400] global_step=162400, grad_norm=2.493767023086548, loss=1.9538451433181763
I0303 09:29:41.177521 139758009304832 logging_writer.py:48] [162500] global_step=162500, grad_norm=2.8175158500671387, loss=1.4285304546356201
I0303 09:30:26.286947 139758017697536 logging_writer.py:48] [162600] global_step=162600, grad_norm=2.662731647491455, loss=1.1252880096435547
I0303 09:31:11.432924 139758009304832 logging_writer.py:48] [162700] global_step=162700, grad_norm=3.028661012649536, loss=3.1301941871643066
I0303 09:31:56.413089 139758017697536 logging_writer.py:48] [162800] global_step=162800, grad_norm=2.7547318935394287, loss=2.6694388389587402
I0303 09:32:08.950088 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:32:19.916893 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:32:44.891530 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:32:46.516399 139953291118400 submission_runner.py:411] Time since start: 77806.69s, 	Step: 162829, 	{'train/accuracy': 0.87416011095047, 'train/loss': 0.4663747251033783, 'validation/accuracy': 0.7705599665641785, 'validation/loss': 0.8969687223434448, 'validation/num_examples': 50000, 'test/accuracy': 0.6515000462532043, 'test/loss': 1.5086804628372192, 'test/num_examples': 10000, 'score': 72301.17582511902, 'total_duration': 77806.6926317215, 'accumulated_submission_time': 72301.17582511902, 'accumulated_eval_time': 5487.747537851334, 'accumulated_logging_time': 9.417224645614624}
I0303 09:32:46.558343 139758009304832 logging_writer.py:48] [162829] accumulated_eval_time=5487.747538, accumulated_logging_time=9.417225, accumulated_submission_time=72301.175825, global_step=162829, preemption_count=0, score=72301.175825, test/accuracy=0.651500, test/loss=1.508680, test/num_examples=10000, total_duration=77806.692632, train/accuracy=0.874160, train/loss=0.466375, validation/accuracy=0.770560, validation/loss=0.896969, validation/num_examples=50000
I0303 09:33:14.966397 139758017697536 logging_writer.py:48] [162900] global_step=162900, grad_norm=2.588778018951416, loss=1.2461903095245361
I0303 09:33:57.866663 139758009304832 logging_writer.py:48] [163000] global_step=163000, grad_norm=2.7839081287384033, loss=1.3203809261322021
I0303 09:34:42.830809 139758017697536 logging_writer.py:48] [163100] global_step=163100, grad_norm=2.8665013313293457, loss=1.3233046531677246
I0303 09:35:27.960881 139758009304832 logging_writer.py:48] [163200] global_step=163200, grad_norm=2.9308011531829834, loss=1.489527702331543
I0303 09:36:12.780125 139758017697536 logging_writer.py:48] [163300] global_step=163300, grad_norm=2.771022081375122, loss=1.2608208656311035
I0303 09:36:57.604606 139758009304832 logging_writer.py:48] [163400] global_step=163400, grad_norm=2.750779867172241, loss=1.1723320484161377
I0303 09:37:42.513760 139758017697536 logging_writer.py:48] [163500] global_step=163500, grad_norm=2.7191219329833984, loss=1.213040828704834
I0303 09:38:27.233889 139758009304832 logging_writer.py:48] [163600] global_step=163600, grad_norm=2.6706299781799316, loss=1.8766742944717407
I0303 09:39:12.267665 139758017697536 logging_writer.py:48] [163700] global_step=163700, grad_norm=2.7465267181396484, loss=1.2484911680221558
I0303 09:39:46.544448 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:39:57.209897 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:40:15.043084 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:40:16.676455 139953291118400 submission_runner.py:411] Time since start: 78256.85s, 	Step: 163779, 	{'train/accuracy': 0.869921863079071, 'train/loss': 0.48062339425086975, 'validation/accuracy': 0.7714200019836426, 'validation/loss': 0.8954671025276184, 'validation/num_examples': 50000, 'test/accuracy': 0.6487000584602356, 'test/loss': 1.4998230934143066, 'test/num_examples': 10000, 'score': 72721.10506033897, 'total_duration': 78256.85267496109, 'accumulated_submission_time': 72721.10506033897, 'accumulated_eval_time': 5517.879540681839, 'accumulated_logging_time': 9.467840194702148}
I0303 09:40:16.725510 139758009304832 logging_writer.py:48] [163779] accumulated_eval_time=5517.879541, accumulated_logging_time=9.467840, accumulated_submission_time=72721.105060, global_step=163779, preemption_count=0, score=72721.105060, test/accuracy=0.648700, test/loss=1.499823, test/num_examples=10000, total_duration=78256.852675, train/accuracy=0.869922, train/loss=0.480623, validation/accuracy=0.771420, validation/loss=0.895467, validation/num_examples=50000
I0303 09:40:25.449234 139758017697536 logging_writer.py:48] [163800] global_step=163800, grad_norm=2.8830676078796387, loss=2.8815646171569824
I0303 09:41:07.701679 139758009304832 logging_writer.py:48] [163900] global_step=163900, grad_norm=3.0789074897766113, loss=1.3029872179031372
I0303 09:41:52.552191 139758017697536 logging_writer.py:48] [164000] global_step=164000, grad_norm=2.747974395751953, loss=2.415449619293213
I0303 09:42:38.225621 139758009304832 logging_writer.py:48] [164100] global_step=164100, grad_norm=3.0614466667175293, loss=2.9952964782714844
I0303 09:43:22.639436 139758017697536 logging_writer.py:48] [164200] global_step=164200, grad_norm=3.2714743614196777, loss=2.762296438217163
I0303 09:44:07.407912 139758009304832 logging_writer.py:48] [164300] global_step=164300, grad_norm=2.753917932510376, loss=1.5617218017578125
I0303 09:44:52.297158 139758017697536 logging_writer.py:48] [164400] global_step=164400, grad_norm=2.800049066543579, loss=1.3228740692138672
I0303 09:45:37.054456 139758009304832 logging_writer.py:48] [164500] global_step=164500, grad_norm=3.0179033279418945, loss=3.2251312732696533
I0303 09:46:21.954137 139758017697536 logging_writer.py:48] [164600] global_step=164600, grad_norm=3.1396143436431885, loss=3.5092673301696777
I0303 09:47:06.935830 139758009304832 logging_writer.py:48] [164700] global_step=164700, grad_norm=2.9434292316436768, loss=1.3234392404556274
I0303 09:47:16.827695 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:47:27.896340 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:47:47.017789 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:47:48.664117 139953291118400 submission_runner.py:411] Time since start: 78708.84s, 	Step: 164724, 	{'train/accuracy': 0.8695507645606995, 'train/loss': 0.48785653710365295, 'validation/accuracy': 0.771399974822998, 'validation/loss': 0.9021183252334595, 'validation/num_examples': 50000, 'test/accuracy': 0.6450000405311584, 'test/loss': 1.5077391862869263, 'test/num_examples': 10000, 'score': 73141.14754962921, 'total_duration': 78708.84034132957, 'accumulated_submission_time': 73141.14754962921, 'accumulated_eval_time': 5549.715945720673, 'accumulated_logging_time': 9.528099298477173}
I0303 09:47:48.711835 139758017697536 logging_writer.py:48] [164724] accumulated_eval_time=5549.715946, accumulated_logging_time=9.528099, accumulated_submission_time=73141.147550, global_step=164724, preemption_count=0, score=73141.147550, test/accuracy=0.645000, test/loss=1.507739, test/num_examples=10000, total_duration=78708.840341, train/accuracy=0.869551, train/loss=0.487857, validation/accuracy=0.771400, validation/loss=0.902118, validation/num_examples=50000
I0303 09:48:19.186979 139758009304832 logging_writer.py:48] [164800] global_step=164800, grad_norm=3.099705457687378, loss=3.03458309173584
I0303 09:49:03.904140 139758017697536 logging_writer.py:48] [164900] global_step=164900, grad_norm=2.7368252277374268, loss=1.1742308139801025
I0303 09:49:49.077490 139758009304832 logging_writer.py:48] [165000] global_step=165000, grad_norm=2.5665946006774902, loss=2.220547914505005
I0303 09:50:34.208010 139758017697536 logging_writer.py:48] [165100] global_step=165100, grad_norm=2.8644654750823975, loss=1.1617717742919922
I0303 09:51:19.115129 139758009304832 logging_writer.py:48] [165200] global_step=165200, grad_norm=2.6862945556640625, loss=1.3089821338653564
I0303 09:52:04.197026 139758017697536 logging_writer.py:48] [165300] global_step=165300, grad_norm=2.698232889175415, loss=1.930139422416687
I0303 09:52:49.327134 139758009304832 logging_writer.py:48] [165400] global_step=165400, grad_norm=3.0607423782348633, loss=1.2604347467422485
I0303 09:53:34.154817 139758017697536 logging_writer.py:48] [165500] global_step=165500, grad_norm=2.7232444286346436, loss=2.276176929473877
I0303 09:54:19.002016 139758009304832 logging_writer.py:48] [165600] global_step=165600, grad_norm=3.7369580268859863, loss=3.171808958053589
I0303 09:54:48.819512 139953291118400 spec.py:321] Evaluating on the training split.
I0303 09:54:59.718342 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 09:55:21.129152 139953291118400 spec.py:349] Evaluating on the test split.
I0303 09:55:22.761222 139953291118400 submission_runner.py:411] Time since start: 79162.94s, 	Step: 165668, 	{'train/accuracy': 0.8700780868530273, 'train/loss': 0.4788884222507477, 'validation/accuracy': 0.7709999680519104, 'validation/loss': 0.8976555466651917, 'validation/num_examples': 50000, 'test/accuracy': 0.6477000117301941, 'test/loss': 1.5097239017486572, 'test/num_examples': 10000, 'score': 73561.19763278961, 'total_duration': 79162.93744325638, 'accumulated_submission_time': 73561.19763278961, 'accumulated_eval_time': 5583.6576244831085, 'accumulated_logging_time': 9.585728645324707}
I0303 09:55:22.810907 139758017697536 logging_writer.py:48] [165668] accumulated_eval_time=5583.657624, accumulated_logging_time=9.585729, accumulated_submission_time=73561.197633, global_step=165668, preemption_count=0, score=73561.197633, test/accuracy=0.647700, test/loss=1.509724, test/num_examples=10000, total_duration=79162.937443, train/accuracy=0.870078, train/loss=0.478888, validation/accuracy=0.771000, validation/loss=0.897656, validation/num_examples=50000
I0303 09:55:35.854007 139758009304832 logging_writer.py:48] [165700] global_step=165700, grad_norm=2.800424575805664, loss=1.2772079706192017
I0303 09:56:17.333489 139758017697536 logging_writer.py:48] [165800] global_step=165800, grad_norm=3.275242328643799, loss=3.3071963787078857
I0303 09:57:01.977020 139758009304832 logging_writer.py:48] [165900] global_step=165900, grad_norm=2.5694730281829834, loss=1.5937871932983398
I0303 09:57:46.984617 139758017697536 logging_writer.py:48] [166000] global_step=166000, grad_norm=2.8592302799224854, loss=1.9712295532226562
I0303 09:58:32.056057 139758009304832 logging_writer.py:48] [166100] global_step=166100, grad_norm=2.957015037536621, loss=2.9965691566467285
I0303 09:59:17.164970 139758017697536 logging_writer.py:48] [166200] global_step=166200, grad_norm=3.034050941467285, loss=2.701611280441284
I0303 10:00:02.413520 139758009304832 logging_writer.py:48] [166300] global_step=166300, grad_norm=2.8315651416778564, loss=1.1757078170776367
I0303 10:00:47.481358 139758017697536 logging_writer.py:48] [166400] global_step=166400, grad_norm=3.1980509757995605, loss=1.2860808372497559
I0303 10:01:32.229622 139758009304832 logging_writer.py:48] [166500] global_step=166500, grad_norm=2.9562346935272217, loss=1.207853078842163
I0303 10:02:17.100279 139758017697536 logging_writer.py:48] [166600] global_step=166600, grad_norm=2.9836909770965576, loss=1.8795527219772339
I0303 10:02:22.935877 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:02:33.751807 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:02:53.467506 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:02:55.100286 139953291118400 submission_runner.py:411] Time since start: 79615.28s, 	Step: 166615, 	{'train/accuracy': 0.8802929520606995, 'train/loss': 0.45079872012138367, 'validation/accuracy': 0.7734799981117249, 'validation/loss': 0.8893938660621643, 'validation/num_examples': 50000, 'test/accuracy': 0.656000018119812, 'test/loss': 1.489260196685791, 'test/num_examples': 10000, 'score': 73981.26328992844, 'total_duration': 79615.27650952339, 'accumulated_submission_time': 73981.26328992844, 'accumulated_eval_time': 5615.822008609772, 'accumulated_logging_time': 9.64665174484253}
I0303 10:02:55.154301 139758009304832 logging_writer.py:48] [166615] accumulated_eval_time=5615.822009, accumulated_logging_time=9.646652, accumulated_submission_time=73981.263290, global_step=166615, preemption_count=0, score=73981.263290, test/accuracy=0.656000, test/loss=1.489260, test/num_examples=10000, total_duration=79615.276510, train/accuracy=0.880293, train/loss=0.450799, validation/accuracy=0.773480, validation/loss=0.889394, validation/num_examples=50000
I0303 10:03:29.234309 139758017697536 logging_writer.py:48] [166700] global_step=166700, grad_norm=3.376596689224243, loss=1.2783889770507812
I0303 10:04:14.081431 139758009304832 logging_writer.py:48] [166800] global_step=166800, grad_norm=3.1658270359039307, loss=1.181050419807434
I0303 10:04:59.005744 139758017697536 logging_writer.py:48] [166900] global_step=166900, grad_norm=2.7627928256988525, loss=1.396968126296997
I0303 10:05:44.104038 139758009304832 logging_writer.py:48] [167000] global_step=167000, grad_norm=3.426600456237793, loss=3.3763184547424316
I0303 10:06:29.252790 139758017697536 logging_writer.py:48] [167100] global_step=167100, grad_norm=2.6626739501953125, loss=1.8585058450698853
I0303 10:07:13.854651 139758009304832 logging_writer.py:48] [167200] global_step=167200, grad_norm=2.6649835109710693, loss=1.2810823917388916
I0303 10:07:58.980361 139758017697536 logging_writer.py:48] [167300] global_step=167300, grad_norm=2.935654640197754, loss=1.9125441312789917
I0303 10:08:43.819690 139758009304832 logging_writer.py:48] [167400] global_step=167400, grad_norm=3.217325210571289, loss=1.272429347038269
I0303 10:09:28.679884 139758017697536 logging_writer.py:48] [167500] global_step=167500, grad_norm=3.3000173568725586, loss=1.2439755201339722
I0303 10:09:55.223166 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:10:06.294811 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:10:26.418307 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:10:28.067952 139953291118400 submission_runner.py:411] Time since start: 80068.24s, 	Step: 167561, 	{'train/accuracy': 0.8752539157867432, 'train/loss': 0.4655075669288635, 'validation/accuracy': 0.7736200094223022, 'validation/loss': 0.8859438300132751, 'validation/num_examples': 50000, 'test/accuracy': 0.6522000432014465, 'test/loss': 1.4930800199508667, 'test/num_examples': 10000, 'score': 74401.27312350273, 'total_duration': 80068.24415230751, 'accumulated_submission_time': 74401.27312350273, 'accumulated_eval_time': 5648.666755914688, 'accumulated_logging_time': 9.712154865264893}
I0303 10:10:28.123340 139758009304832 logging_writer.py:48] [167561] accumulated_eval_time=5648.666756, accumulated_logging_time=9.712155, accumulated_submission_time=74401.273124, global_step=167561, preemption_count=0, score=74401.273124, test/accuracy=0.652200, test/loss=1.493080, test/num_examples=10000, total_duration=80068.244152, train/accuracy=0.875254, train/loss=0.465508, validation/accuracy=0.773620, validation/loss=0.885944, validation/num_examples=50000
I0303 10:10:43.915012 139758017697536 logging_writer.py:48] [167600] global_step=167600, grad_norm=2.9514379501342773, loss=1.7528516054153442
I0303 10:11:25.743392 139758009304832 logging_writer.py:48] [167700] global_step=167700, grad_norm=2.9277658462524414, loss=1.3910311460494995
I0303 10:12:10.743468 139758017697536 logging_writer.py:48] [167800] global_step=167800, grad_norm=2.8609626293182373, loss=1.3501229286193848
I0303 10:12:55.776302 139758009304832 logging_writer.py:48] [167900] global_step=167900, grad_norm=2.9730968475341797, loss=1.4257380962371826
I0303 10:13:41.047384 139758017697536 logging_writer.py:48] [168000] global_step=168000, grad_norm=3.28532075881958, loss=3.235750913619995
I0303 10:14:25.982185 139758009304832 logging_writer.py:48] [168100] global_step=168100, grad_norm=2.6982457637786865, loss=2.1656696796417236
I0303 10:15:10.812191 139758017697536 logging_writer.py:48] [168200] global_step=168200, grad_norm=2.7043023109436035, loss=1.378823161125183
I0303 10:15:55.640261 139758009304832 logging_writer.py:48] [168300] global_step=168300, grad_norm=2.903778076171875, loss=1.1130027770996094
I0303 10:16:40.650592 139758017697536 logging_writer.py:48] [168400] global_step=168400, grad_norm=3.2198095321655273, loss=3.0074009895324707
I0303 10:17:25.631809 139758009304832 logging_writer.py:48] [168500] global_step=168500, grad_norm=2.9164202213287354, loss=1.1002148389816284
I0303 10:17:28.493735 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:17:39.310408 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:18:01.951412 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:18:03.597468 139953291118400 submission_runner.py:411] Time since start: 80523.77s, 	Step: 168508, 	{'train/accuracy': 0.87708979845047, 'train/loss': 0.45731988549232483, 'validation/accuracy': 0.7735799551010132, 'validation/loss': 0.8782155513763428, 'validation/num_examples': 50000, 'test/accuracy': 0.6541000604629517, 'test/loss': 1.4873871803283691, 'test/num_examples': 10000, 'score': 74821.58446097374, 'total_duration': 80523.77368187904, 'accumulated_submission_time': 74821.58446097374, 'accumulated_eval_time': 5683.770456075668, 'accumulated_logging_time': 9.778326272964478}
I0303 10:18:03.649643 139758017697536 logging_writer.py:48] [168508] accumulated_eval_time=5683.770456, accumulated_logging_time=9.778326, accumulated_submission_time=74821.584461, global_step=168508, preemption_count=0, score=74821.584461, test/accuracy=0.654100, test/loss=1.487387, test/num_examples=10000, total_duration=80523.773682, train/accuracy=0.877090, train/loss=0.457320, validation/accuracy=0.773580, validation/loss=0.878216, validation/num_examples=50000
I0303 10:18:40.359456 139758009304832 logging_writer.py:48] [168600] global_step=168600, grad_norm=2.9831395149230957, loss=1.250301718711853
I0303 10:19:25.167449 139758017697536 logging_writer.py:48] [168700] global_step=168700, grad_norm=2.7340586185455322, loss=1.3448479175567627
I0303 10:20:10.335668 139758009304832 logging_writer.py:48] [168800] global_step=168800, grad_norm=3.0878825187683105, loss=3.0306761264801025
I0303 10:20:55.859260 139758017697536 logging_writer.py:48] [168900] global_step=168900, grad_norm=3.4542644023895264, loss=3.3072640895843506
I0303 10:21:40.608428 139758009304832 logging_writer.py:48] [169000] global_step=169000, grad_norm=2.892960786819458, loss=1.7055127620697021
I0303 10:22:25.440425 139758017697536 logging_writer.py:48] [169100] global_step=169100, grad_norm=3.6444549560546875, loss=3.203507900238037
I0303 10:23:10.690330 139758009304832 logging_writer.py:48] [169200] global_step=169200, grad_norm=3.016279458999634, loss=1.1992331743240356
I0303 10:23:55.470419 139758017697536 logging_writer.py:48] [169300] global_step=169300, grad_norm=2.7767839431762695, loss=1.154970407485962
I0303 10:24:40.291656 139758009304832 logging_writer.py:48] [169400] global_step=169400, grad_norm=5.390230178833008, loss=1.1615370512008667
I0303 10:25:04.054202 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:25:15.366565 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:25:36.558165 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:25:38.203758 139953291118400 submission_runner.py:411] Time since start: 80978.38s, 	Step: 169454, 	{'train/accuracy': 0.8761327862739563, 'train/loss': 0.46349942684173584, 'validation/accuracy': 0.773859977722168, 'validation/loss': 0.8852800726890564, 'validation/num_examples': 50000, 'test/accuracy': 0.6522000432014465, 'test/loss': 1.4902135133743286, 'test/num_examples': 10000, 'score': 75241.93149113655, 'total_duration': 80978.3799700737, 'accumulated_submission_time': 75241.93149113655, 'accumulated_eval_time': 5717.919988632202, 'accumulated_logging_time': 9.840453386306763}
I0303 10:25:38.256740 139758017697536 logging_writer.py:48] [169454] accumulated_eval_time=5717.919989, accumulated_logging_time=9.840453, accumulated_submission_time=75241.931491, global_step=169454, preemption_count=0, score=75241.931491, test/accuracy=0.652200, test/loss=1.490214, test/num_examples=10000, total_duration=80978.379970, train/accuracy=0.876133, train/loss=0.463499, validation/accuracy=0.773860, validation/loss=0.885280, validation/num_examples=50000
I0303 10:25:56.807136 139758009304832 logging_writer.py:48] [169500] global_step=169500, grad_norm=2.8797788619995117, loss=1.1932817697525024
I0303 10:26:39.611821 139758017697536 logging_writer.py:48] [169600] global_step=169600, grad_norm=2.7871551513671875, loss=1.465611457824707
I0303 10:27:24.578992 139758009304832 logging_writer.py:48] [169700] global_step=169700, grad_norm=3.2325639724731445, loss=1.2918267250061035
I0303 10:28:09.612319 139758017697536 logging_writer.py:48] [169800] global_step=169800, grad_norm=2.8978445529937744, loss=1.2247768640518188
I0303 10:28:54.551611 139758009304832 logging_writer.py:48] [169900] global_step=169900, grad_norm=3.0620861053466797, loss=2.4373488426208496
I0303 10:29:39.390901 139758017697536 logging_writer.py:48] [170000] global_step=170000, grad_norm=3.4478490352630615, loss=3.3852109909057617
I0303 10:30:24.241286 139758009304832 logging_writer.py:48] [170100] global_step=170100, grad_norm=2.7739033699035645, loss=1.1643673181533813
I0303 10:31:09.426990 139758017697536 logging_writer.py:48] [170200] global_step=170200, grad_norm=2.9140663146972656, loss=1.2146366834640503
I0303 10:31:54.427280 139758009304832 logging_writer.py:48] [170300] global_step=170300, grad_norm=3.288125991821289, loss=1.2828788757324219
I0303 10:32:38.630716 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:32:49.534087 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:33:07.796162 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:33:09.429269 139953291118400 submission_runner.py:411] Time since start: 81429.61s, 	Step: 170400, 	{'train/accuracy': 0.8781054615974426, 'train/loss': 0.45171058177948, 'validation/accuracy': 0.7761200070381165, 'validation/loss': 0.874293863773346, 'validation/num_examples': 50000, 'test/accuracy': 0.6583000421524048, 'test/loss': 1.4806007146835327, 'test/num_examples': 10000, 'score': 75662.24620199203, 'total_duration': 81429.60545611382, 'accumulated_submission_time': 75662.24620199203, 'accumulated_eval_time': 5748.718489408493, 'accumulated_logging_time': 9.904155015945435}
I0303 10:33:09.478212 139758017697536 logging_writer.py:48] [170400] accumulated_eval_time=5748.718489, accumulated_logging_time=9.904155, accumulated_submission_time=75662.246202, global_step=170400, preemption_count=0, score=75662.246202, test/accuracy=0.658300, test/loss=1.480601, test/num_examples=10000, total_duration=81429.605456, train/accuracy=0.878105, train/loss=0.451711, validation/accuracy=0.776120, validation/loss=0.874294, validation/num_examples=50000
I0303 10:33:09.890473 139758009304832 logging_writer.py:48] [170400] global_step=170400, grad_norm=2.903393268585205, loss=1.1575909852981567
I0303 10:33:50.973320 139758017697536 logging_writer.py:48] [170500] global_step=170500, grad_norm=2.776925802230835, loss=1.1890287399291992
I0303 10:34:35.882447 139758009304832 logging_writer.py:48] [170600] global_step=170600, grad_norm=3.073580026626587, loss=1.180174469947815
I0303 10:35:20.816224 139758017697536 logging_writer.py:48] [170700] global_step=170700, grad_norm=3.102447986602783, loss=1.2517757415771484
I0303 10:36:05.745708 139758009304832 logging_writer.py:48] [170800] global_step=170800, grad_norm=3.0342960357666016, loss=1.2128427028656006
I0303 10:36:50.515652 139758017697536 logging_writer.py:48] [170900] global_step=170900, grad_norm=2.911593437194824, loss=2.1605749130249023
I0303 10:37:35.603831 139758009304832 logging_writer.py:48] [171000] global_step=171000, grad_norm=2.6425938606262207, loss=1.6407607793807983
I0303 10:38:20.662829 139758017697536 logging_writer.py:48] [171100] global_step=171100, grad_norm=2.7849478721618652, loss=1.1011525392532349
I0303 10:39:05.714205 139758009304832 logging_writer.py:48] [171200] global_step=171200, grad_norm=3.0144121646881104, loss=1.2138805389404297
I0303 10:39:50.540829 139758017697536 logging_writer.py:48] [171300] global_step=171300, grad_norm=2.971735954284668, loss=1.2664191722869873
I0303 10:40:09.498592 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:40:20.356300 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:40:41.945086 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:40:43.580607 139953291118400 submission_runner.py:411] Time since start: 81883.76s, 	Step: 171344, 	{'train/accuracy': 0.8800976276397705, 'train/loss': 0.444496214389801, 'validation/accuracy': 0.7761799693107605, 'validation/loss': 0.873876690864563, 'validation/num_examples': 50000, 'test/accuracy': 0.6561000347137451, 'test/loss': 1.4711897373199463, 'test/num_examples': 10000, 'score': 76082.20815610886, 'total_duration': 81883.75682711601, 'accumulated_submission_time': 76082.20815610886, 'accumulated_eval_time': 5782.800493478775, 'accumulated_logging_time': 9.963026523590088}
I0303 10:40:43.631697 139758009304832 logging_writer.py:48] [171344] accumulated_eval_time=5782.800493, accumulated_logging_time=9.963027, accumulated_submission_time=76082.208156, global_step=171344, preemption_count=0, score=76082.208156, test/accuracy=0.656100, test/loss=1.471190, test/num_examples=10000, total_duration=81883.756827, train/accuracy=0.880098, train/loss=0.444496, validation/accuracy=0.776180, validation/loss=0.873877, validation/num_examples=50000
I0303 10:41:06.833222 139758017697536 logging_writer.py:48] [171400] global_step=171400, grad_norm=3.3129594326019287, loss=2.9071459770202637
I0303 10:42:03.121608 139758009304832 logging_writer.py:48] [171500] global_step=171500, grad_norm=2.972846269607544, loss=2.644543170928955
I0303 10:42:47.572576 139758017697536 logging_writer.py:48] [171600] global_step=171600, grad_norm=2.7315564155578613, loss=1.8020811080932617
I0303 10:43:32.681139 139758009304832 logging_writer.py:48] [171700] global_step=171700, grad_norm=3.045759916305542, loss=1.2305994033813477
I0303 10:44:17.412344 139758017697536 logging_writer.py:48] [171800] global_step=171800, grad_norm=2.770120620727539, loss=1.1205567121505737
I0303 10:45:02.171182 139758009304832 logging_writer.py:48] [171900] global_step=171900, grad_norm=2.9071693420410156, loss=1.1900346279144287
I0303 10:45:47.075265 139758017697536 logging_writer.py:48] [172000] global_step=172000, grad_norm=3.1298108100891113, loss=1.3304718732833862
I0303 10:46:32.388587 139758009304832 logging_writer.py:48] [172100] global_step=172100, grad_norm=3.0788631439208984, loss=1.3857046365737915
I0303 10:47:17.217111 139758017697536 logging_writer.py:48] [172200] global_step=172200, grad_norm=3.183166742324829, loss=2.894996166229248
I0303 10:47:43.730498 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:47:54.465454 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:48:23.185638 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:48:24.818258 139953291118400 submission_runner.py:411] Time since start: 82344.99s, 	Step: 172261, 	{'train/accuracy': 0.8818749785423279, 'train/loss': 0.43519195914268494, 'validation/accuracy': 0.7774199843406677, 'validation/loss': 0.8687987923622131, 'validation/num_examples': 50000, 'test/accuracy': 0.6562000513076782, 'test/loss': 1.4677006006240845, 'test/num_examples': 10000, 'score': 76502.247112751, 'total_duration': 82344.99448871613, 'accumulated_submission_time': 76502.247112751, 'accumulated_eval_time': 5823.888249158859, 'accumulated_logging_time': 10.027615547180176}
I0303 10:48:24.861189 139758009304832 logging_writer.py:48] [172261] accumulated_eval_time=5823.888249, accumulated_logging_time=10.027616, accumulated_submission_time=76502.247113, global_step=172261, preemption_count=0, score=76502.247113, test/accuracy=0.656200, test/loss=1.467701, test/num_examples=10000, total_duration=82344.994489, train/accuracy=0.881875, train/loss=0.435192, validation/accuracy=0.777420, validation/loss=0.868799, validation/num_examples=50000
I0303 10:48:40.648259 139758017697536 logging_writer.py:48] [172300] global_step=172300, grad_norm=2.9225785732269287, loss=1.2517139911651611
I0303 10:49:21.657412 139758009304832 logging_writer.py:48] [172400] global_step=172400, grad_norm=2.9273033142089844, loss=1.4331398010253906
I0303 10:50:07.006976 139758017697536 logging_writer.py:48] [172500] global_step=172500, grad_norm=3.0143277645111084, loss=1.114241123199463
I0303 10:50:51.833940 139758009304832 logging_writer.py:48] [172600] global_step=172600, grad_norm=3.600464344024658, loss=3.3869588375091553
I0303 10:51:36.774003 139758017697536 logging_writer.py:48] [172700] global_step=172700, grad_norm=3.0272903442382812, loss=1.269028902053833
I0303 10:52:21.657706 139758009304832 logging_writer.py:48] [172800] global_step=172800, grad_norm=3.2317922115325928, loss=2.4966893196105957
I0303 10:53:07.028627 139758017697536 logging_writer.py:48] [172900] global_step=172900, grad_norm=2.9540812969207764, loss=2.383347988128662
I0303 10:53:51.610680 139758009304832 logging_writer.py:48] [173000] global_step=173000, grad_norm=3.479875326156616, loss=2.9809927940368652
I0303 10:54:36.342443 139758017697536 logging_writer.py:48] [173100] global_step=173100, grad_norm=2.785061836242676, loss=1.6475787162780762
I0303 10:55:21.442199 139758009304832 logging_writer.py:48] [173200] global_step=173200, grad_norm=3.2897253036499023, loss=1.148646593093872
I0303 10:55:25.229910 139953291118400 spec.py:321] Evaluating on the training split.
I0303 10:55:36.146974 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 10:56:00.423313 139953291118400 spec.py:349] Evaluating on the test split.
I0303 10:56:02.054733 139953291118400 submission_runner.py:411] Time since start: 82802.23s, 	Step: 173210, 	{'train/accuracy': 0.8833593726158142, 'train/loss': 0.43679869174957275, 'validation/accuracy': 0.7771399617195129, 'validation/loss': 0.8698133230209351, 'validation/num_examples': 50000, 'test/accuracy': 0.6541000604629517, 'test/loss': 1.4714024066925049, 'test/num_examples': 10000, 'score': 76922.55945754051, 'total_duration': 82802.23096346855, 'accumulated_submission_time': 76922.55945754051, 'accumulated_eval_time': 5860.713069200516, 'accumulated_logging_time': 10.078977823257446}
I0303 10:56:02.098424 139758017697536 logging_writer.py:48] [173210] accumulated_eval_time=5860.713069, accumulated_logging_time=10.078978, accumulated_submission_time=76922.559458, global_step=173210, preemption_count=0, score=76922.559458, test/accuracy=0.654100, test/loss=1.471402, test/num_examples=10000, total_duration=82802.230963, train/accuracy=0.883359, train/loss=0.436799, validation/accuracy=0.777140, validation/loss=0.869813, validation/num_examples=50000
I0303 10:56:38.030311 139758009304832 logging_writer.py:48] [173300] global_step=173300, grad_norm=3.1384599208831787, loss=2.90814208984375
I0303 10:57:22.554699 139758017697536 logging_writer.py:48] [173400] global_step=173400, grad_norm=3.0185465812683105, loss=2.122576951980591
I0303 10:58:07.448570 139758009304832 logging_writer.py:48] [173500] global_step=173500, grad_norm=3.0649189949035645, loss=1.0871508121490479
I0303 10:58:52.425417 139758017697536 logging_writer.py:48] [173600] global_step=173600, grad_norm=2.8547065258026123, loss=1.8440732955932617
I0303 10:59:37.330693 139758009304832 logging_writer.py:48] [173700] global_step=173700, grad_norm=2.9438693523406982, loss=1.203373670578003
I0303 11:00:22.440026 139758017697536 logging_writer.py:48] [173800] global_step=173800, grad_norm=3.2494146823883057, loss=2.6823716163635254
I0303 11:01:07.630075 139758009304832 logging_writer.py:48] [173900] global_step=173900, grad_norm=3.347476005554199, loss=3.0709962844848633
I0303 11:01:52.640198 139758017697536 logging_writer.py:48] [174000] global_step=174000, grad_norm=2.9953744411468506, loss=1.237609624862671
I0303 11:02:37.681899 139758009304832 logging_writer.py:48] [174100] global_step=174100, grad_norm=3.08683705329895, loss=1.114971399307251
I0303 11:03:02.105029 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:03:13.768408 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:03:35.377004 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:03:37.003312 139953291118400 submission_runner.py:411] Time since start: 83257.18s, 	Step: 174156, 	{'train/accuracy': 0.8812890648841858, 'train/loss': 0.4501301944255829, 'validation/accuracy': 0.7763199806213379, 'validation/loss': 0.872589111328125, 'validation/num_examples': 50000, 'test/accuracy': 0.6601000428199768, 'test/loss': 1.4674209356307983, 'test/num_examples': 10000, 'score': 77342.50984573364, 'total_duration': 83257.17953515053, 'accumulated_submission_time': 77342.50984573364, 'accumulated_eval_time': 5895.611342906952, 'accumulated_logging_time': 10.131336688995361}
I0303 11:03:37.057083 139758017697536 logging_writer.py:48] [174156] accumulated_eval_time=5895.611343, accumulated_logging_time=10.131337, accumulated_submission_time=77342.509846, global_step=174156, preemption_count=0, score=77342.509846, test/accuracy=0.660100, test/loss=1.467421, test/num_examples=10000, total_duration=83257.179535, train/accuracy=0.881289, train/loss=0.450130, validation/accuracy=0.776320, validation/loss=0.872589, validation/num_examples=50000
I0303 11:03:54.835475 139758009304832 logging_writer.py:48] [174200] global_step=174200, grad_norm=3.254275321960449, loss=1.7959113121032715
I0303 11:04:37.660964 139758017697536 logging_writer.py:48] [174300] global_step=174300, grad_norm=2.9114067554473877, loss=1.8370553255081177
I0303 11:05:22.402216 139758009304832 logging_writer.py:48] [174400] global_step=174400, grad_norm=2.864391565322876, loss=1.694198727607727
I0303 11:06:07.275563 139758017697536 logging_writer.py:48] [174500] global_step=174500, grad_norm=3.4055144786834717, loss=1.192347764968872
I0303 11:06:52.437549 139758009304832 logging_writer.py:48] [174600] global_step=174600, grad_norm=3.515686511993408, loss=3.133863925933838
I0303 11:07:37.819805 139758017697536 logging_writer.py:48] [174700] global_step=174700, grad_norm=3.137357234954834, loss=1.2116984128952026
I0303 11:08:22.552568 139758009304832 logging_writer.py:48] [174800] global_step=174800, grad_norm=2.9006385803222656, loss=1.1935341358184814
I0303 11:09:07.326471 139758017697536 logging_writer.py:48] [174900] global_step=174900, grad_norm=3.2264559268951416, loss=1.0861077308654785
I0303 11:09:52.125020 139758009304832 logging_writer.py:48] [175000] global_step=175000, grad_norm=2.837540864944458, loss=1.1191023588180542
I0303 11:10:37.085929 139758017697536 logging_writer.py:48] [175100] global_step=175100, grad_norm=3.297144889831543, loss=2.9523766040802
I0303 11:10:37.098661 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:10:48.144891 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:11:14.557630 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:11:16.189536 139953291118400 submission_runner.py:411] Time since start: 83716.37s, 	Step: 175101, 	{'train/accuracy': 0.8842968344688416, 'train/loss': 0.4302087426185608, 'validation/accuracy': 0.7767399549484253, 'validation/loss': 0.869044840335846, 'validation/num_examples': 50000, 'test/accuracy': 0.6586000323295593, 'test/loss': 1.465294361114502, 'test/num_examples': 10000, 'score': 77762.4930267334, 'total_duration': 83716.3657438755, 'accumulated_submission_time': 77762.4930267334, 'accumulated_eval_time': 5934.702550172806, 'accumulated_logging_time': 10.195268630981445}
I0303 11:11:16.243189 139758009304832 logging_writer.py:48] [175101] accumulated_eval_time=5934.702550, accumulated_logging_time=10.195269, accumulated_submission_time=77762.493027, global_step=175101, preemption_count=0, score=77762.493027, test/accuracy=0.658600, test/loss=1.465294, test/num_examples=10000, total_duration=83716.365744, train/accuracy=0.884297, train/loss=0.430209, validation/accuracy=0.776740, validation/loss=0.869045, validation/num_examples=50000
I0303 11:11:55.995471 139758017697536 logging_writer.py:48] [175200] global_step=175200, grad_norm=3.0743751525878906, loss=2.4512767791748047
I0303 11:12:40.850365 139758009304832 logging_writer.py:48] [175300] global_step=175300, grad_norm=3.4870967864990234, loss=3.221980571746826
I0303 11:13:26.242460 139758017697536 logging_writer.py:48] [175400] global_step=175400, grad_norm=3.022522449493408, loss=1.1389786005020142
I0303 11:14:11.462400 139758009304832 logging_writer.py:48] [175500] global_step=175500, grad_norm=2.8495798110961914, loss=1.146528959274292
I0303 11:14:56.161035 139758017697536 logging_writer.py:48] [175600] global_step=175600, grad_norm=3.0634713172912598, loss=2.162720203399658
I0303 11:15:41.136493 139758009304832 logging_writer.py:48] [175700] global_step=175700, grad_norm=2.8913028240203857, loss=1.1225364208221436
I0303 11:16:26.336133 139758017697536 logging_writer.py:48] [175800] global_step=175800, grad_norm=3.397825241088867, loss=2.8233585357666016
I0303 11:17:11.294597 139758009304832 logging_writer.py:48] [175900] global_step=175900, grad_norm=2.980348587036133, loss=1.3083536624908447
I0303 11:17:56.004390 139758017697536 logging_writer.py:48] [176000] global_step=176000, grad_norm=3.0853235721588135, loss=1.1320490837097168
I0303 11:18:16.566973 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:18:27.691659 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:18:46.470880 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:18:48.102658 139953291118400 submission_runner.py:411] Time since start: 84168.28s, 	Step: 176047, 	{'train/accuracy': 0.8846288919448853, 'train/loss': 0.4247990846633911, 'validation/accuracy': 0.7781800031661987, 'validation/loss': 0.8619899749755859, 'validation/num_examples': 50000, 'test/accuracy': 0.6606000065803528, 'test/loss': 1.4649004936218262, 'test/num_examples': 10000, 'score': 78182.75847244263, 'total_duration': 84168.2788734436, 'accumulated_submission_time': 78182.75847244263, 'accumulated_eval_time': 5966.2382390499115, 'accumulated_logging_time': 10.259270668029785}
I0303 11:18:48.154398 139758009304832 logging_writer.py:48] [176047] accumulated_eval_time=5966.238239, accumulated_logging_time=10.259271, accumulated_submission_time=78182.758472, global_step=176047, preemption_count=0, score=78182.758472, test/accuracy=0.660600, test/loss=1.464900, test/num_examples=10000, total_duration=84168.278873, train/accuracy=0.884629, train/loss=0.424799, validation/accuracy=0.778180, validation/loss=0.861990, validation/num_examples=50000
I0303 11:19:09.479735 139758017697536 logging_writer.py:48] [176100] global_step=176100, grad_norm=3.2828617095947266, loss=1.2379212379455566
I0303 11:19:53.324159 139758009304832 logging_writer.py:48] [176200] global_step=176200, grad_norm=3.250761032104492, loss=1.1205793619155884
I0303 11:20:38.381908 139758017697536 logging_writer.py:48] [176300] global_step=176300, grad_norm=3.291200637817383, loss=1.867249846458435
I0303 11:21:23.612694 139758009304832 logging_writer.py:48] [176400] global_step=176400, grad_norm=3.0552330017089844, loss=1.1909878253936768
I0303 11:22:09.034556 139758017697536 logging_writer.py:48] [176500] global_step=176500, grad_norm=2.818725109100342, loss=1.0463725328445435
I0303 11:22:54.041145 139758009304832 logging_writer.py:48] [176600] global_step=176600, grad_norm=2.918684959411621, loss=1.9497212171554565
I0303 11:23:39.148347 139758017697536 logging_writer.py:48] [176700] global_step=176700, grad_norm=3.0477726459503174, loss=1.2581274509429932
I0303 11:24:24.287018 139758009304832 logging_writer.py:48] [176800] global_step=176800, grad_norm=3.3795113563537598, loss=2.771332025527954
I0303 11:25:09.797233 139758017697536 logging_writer.py:48] [176900] global_step=176900, grad_norm=3.3316216468811035, loss=2.8342394828796387
I0303 11:25:48.347043 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:25:59.741827 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:26:20.642416 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:26:22.287438 139953291118400 submission_runner.py:411] Time since start: 84622.46s, 	Step: 176987, 	{'train/accuracy': 0.8851367235183716, 'train/loss': 0.4297102391719818, 'validation/accuracy': 0.7775399684906006, 'validation/loss': 0.867326021194458, 'validation/num_examples': 50000, 'test/accuracy': 0.6599000096321106, 'test/loss': 1.464371919631958, 'test/num_examples': 10000, 'score': 78602.89275169373, 'total_duration': 84622.46363949776, 'accumulated_submission_time': 78602.89275169373, 'accumulated_eval_time': 6000.178608179092, 'accumulated_logging_time': 10.321425676345825}
I0303 11:26:22.337105 139758009304832 logging_writer.py:48] [176987] accumulated_eval_time=6000.178608, accumulated_logging_time=10.321426, accumulated_submission_time=78602.892752, global_step=176987, preemption_count=0, score=78602.892752, test/accuracy=0.659900, test/loss=1.464372, test/num_examples=10000, total_duration=84622.463639, train/accuracy=0.885137, train/loss=0.429710, validation/accuracy=0.777540, validation/loss=0.867326, validation/num_examples=50000
I0303 11:26:27.863467 139758017697536 logging_writer.py:48] [177000] global_step=177000, grad_norm=2.9671878814697266, loss=1.068618893623352
I0303 11:27:09.411569 139758009304832 logging_writer.py:48] [177100] global_step=177100, grad_norm=3.268650770187378, loss=1.1812998056411743
I0303 11:27:54.257261 139758017697536 logging_writer.py:48] [177200] global_step=177200, grad_norm=3.1488797664642334, loss=1.1270647048950195
I0303 11:28:39.243941 139758009304832 logging_writer.py:48] [177300] global_step=177300, grad_norm=3.298933506011963, loss=3.2063052654266357
I0303 11:29:24.410415 139758017697536 logging_writer.py:48] [177400] global_step=177400, grad_norm=3.325850009918213, loss=2.307389736175537
I0303 11:30:09.571065 139758009304832 logging_writer.py:48] [177500] global_step=177500, grad_norm=3.2655887603759766, loss=1.2337067127227783
I0303 11:30:54.472216 139758017697536 logging_writer.py:48] [177600] global_step=177600, grad_norm=3.1498398780822754, loss=1.1729177236557007
I0303 11:31:40.143824 139758009304832 logging_writer.py:48] [177700] global_step=177700, grad_norm=3.1146340370178223, loss=1.1271843910217285
I0303 11:32:25.048028 139758017697536 logging_writer.py:48] [177800] global_step=177800, grad_norm=3.2790138721466064, loss=2.739969253540039
I0303 11:33:10.157401 139758009304832 logging_writer.py:48] [177900] global_step=177900, grad_norm=2.828556776046753, loss=1.6906522512435913
I0303 11:33:22.493523 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:33:33.282686 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:33:57.762303 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:33:59.396214 139953291118400 submission_runner.py:411] Time since start: 85079.57s, 	Step: 177929, 	{'train/accuracy': 0.8857812285423279, 'train/loss': 0.4314631521701813, 'validation/accuracy': 0.7797799706459045, 'validation/loss': 0.8623688220977783, 'validation/num_examples': 50000, 'test/accuracy': 0.6630000472068787, 'test/loss': 1.4578428268432617, 'test/num_examples': 10000, 'score': 79022.98996186256, 'total_duration': 85079.57243037224, 'accumulated_submission_time': 79022.98996186256, 'accumulated_eval_time': 6037.081268548965, 'accumulated_logging_time': 10.381896018981934}
I0303 11:33:59.452286 139758017697536 logging_writer.py:48] [177929] accumulated_eval_time=6037.081269, accumulated_logging_time=10.381896, accumulated_submission_time=79022.989962, global_step=177929, preemption_count=0, score=79022.989962, test/accuracy=0.663000, test/loss=1.457843, test/num_examples=10000, total_duration=85079.572430, train/accuracy=0.885781, train/loss=0.431463, validation/accuracy=0.779780, validation/loss=0.862369, validation/num_examples=50000
I0303 11:34:27.888254 139758009304832 logging_writer.py:48] [178000] global_step=178000, grad_norm=3.17164945602417, loss=1.1208683252334595
I0303 11:35:11.054695 139758017697536 logging_writer.py:48] [178100] global_step=178100, grad_norm=3.0972864627838135, loss=1.123502254486084
I0303 11:35:56.025272 139758009304832 logging_writer.py:48] [178200] global_step=178200, grad_norm=2.8316144943237305, loss=1.1190797090530396
I0303 11:36:41.110569 139758017697536 logging_writer.py:48] [178300] global_step=178300, grad_norm=2.986743450164795, loss=2.2904186248779297
I0303 11:37:25.721472 139758009304832 logging_writer.py:48] [178400] global_step=178400, grad_norm=2.934248685836792, loss=1.419179081916809
I0303 11:38:10.353218 139758017697536 logging_writer.py:48] [178500] global_step=178500, grad_norm=2.921450614929199, loss=1.1402016878128052
I0303 11:38:55.386476 139758009304832 logging_writer.py:48] [178600] global_step=178600, grad_norm=2.895050287246704, loss=1.6211962699890137
I0303 11:39:40.206017 139758017697536 logging_writer.py:48] [178700] global_step=178700, grad_norm=3.086160182952881, loss=1.114849328994751
I0303 11:40:25.248539 139758009304832 logging_writer.py:48] [178800] global_step=178800, grad_norm=2.854588031768799, loss=2.0942609310150146
I0303 11:40:59.794219 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:41:10.899573 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:41:30.701615 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:41:32.343107 139953291118400 submission_runner.py:411] Time since start: 85532.52s, 	Step: 178879, 	{'train/accuracy': 0.8853515386581421, 'train/loss': 0.42699044942855835, 'validation/accuracy': 0.7788599729537964, 'validation/loss': 0.8618048429489136, 'validation/num_examples': 50000, 'test/accuracy': 0.6585000157356262, 'test/loss': 1.4597877264022827, 'test/num_examples': 10000, 'score': 79443.26837658882, 'total_duration': 85532.51931023598, 'accumulated_submission_time': 79443.26837658882, 'accumulated_eval_time': 6069.630121469498, 'accumulated_logging_time': 10.452614307403564}
I0303 11:41:32.397436 139758017697536 logging_writer.py:48] [178879] accumulated_eval_time=6069.630121, accumulated_logging_time=10.452614, accumulated_submission_time=79443.268377, global_step=178879, preemption_count=0, score=79443.268377, test/accuracy=0.658500, test/loss=1.459788, test/num_examples=10000, total_duration=85532.519310, train/accuracy=0.885352, train/loss=0.426990, validation/accuracy=0.778860, validation/loss=0.861805, validation/num_examples=50000
I0303 11:41:41.121375 139758009304832 logging_writer.py:48] [178900] global_step=178900, grad_norm=3.714059352874756, loss=3.146204710006714
I0303 11:42:22.987411 139758017697536 logging_writer.py:48] [179000] global_step=179000, grad_norm=3.1041929721832275, loss=1.7217166423797607
I0303 11:43:08.111378 139758009304832 logging_writer.py:48] [179100] global_step=179100, grad_norm=2.9200351238250732, loss=1.0095610618591309
I0303 11:43:53.027320 139758017697536 logging_writer.py:48] [179200] global_step=179200, grad_norm=2.945836067199707, loss=1.0954461097717285
I0303 11:44:37.961910 139758009304832 logging_writer.py:48] [179300] global_step=179300, grad_norm=3.17246413230896, loss=2.159878969192505
I0303 11:45:23.016848 139758017697536 logging_writer.py:48] [179400] global_step=179400, grad_norm=3.0630364418029785, loss=1.0468897819519043
I0303 11:46:07.883292 139758009304832 logging_writer.py:48] [179500] global_step=179500, grad_norm=3.863138198852539, loss=3.219836473464966
I0303 11:46:52.700524 139758017697536 logging_writer.py:48] [179600] global_step=179600, grad_norm=3.1595804691314697, loss=1.0492758750915527
I0303 11:47:37.607387 139758009304832 logging_writer.py:48] [179700] global_step=179700, grad_norm=3.3079636096954346, loss=2.957791566848755
I0303 11:48:22.803556 139758017697536 logging_writer.py:48] [179800] global_step=179800, grad_norm=3.352858781814575, loss=1.1610946655273438
I0303 11:48:32.729161 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:48:43.825844 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:49:03.517107 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:49:05.151992 139953291118400 submission_runner.py:411] Time since start: 85985.33s, 	Step: 179824, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.42315149307250977, 'validation/accuracy': 0.7784799933433533, 'validation/loss': 0.8612497448921204, 'validation/num_examples': 50000, 'test/accuracy': 0.661300003528595, 'test/loss': 1.4576455354690552, 'test/num_examples': 10000, 'score': 79863.53984189034, 'total_duration': 85985.32821440697, 'accumulated_submission_time': 79863.53984189034, 'accumulated_eval_time': 6102.052920103073, 'accumulated_logging_time': 10.519617795944214}
I0303 11:49:05.206338 139758009304832 logging_writer.py:48] [179824] accumulated_eval_time=6102.052920, accumulated_logging_time=10.519618, accumulated_submission_time=79863.539842, global_step=179824, preemption_count=0, score=79863.539842, test/accuracy=0.661300, test/loss=1.457646, test/num_examples=10000, total_duration=85985.328214, train/accuracy=0.887500, train/loss=0.423151, validation/accuracy=0.778480, validation/loss=0.861250, validation/num_examples=50000
I0303 11:49:35.721642 139758017697536 logging_writer.py:48] [179900] global_step=179900, grad_norm=2.911248207092285, loss=1.8324978351593018
I0303 11:50:20.872054 139758009304832 logging_writer.py:48] [180000] global_step=180000, grad_norm=3.0331976413726807, loss=1.1663305759429932
I0303 11:51:05.875139 139758017697536 logging_writer.py:48] [180100] global_step=180100, grad_norm=3.1133499145507812, loss=1.2457388639450073
I0303 11:51:50.915050 139758009304832 logging_writer.py:48] [180200] global_step=180200, grad_norm=3.089808464050293, loss=1.094262957572937
I0303 11:52:35.628454 139758017697536 logging_writer.py:48] [180300] global_step=180300, grad_norm=3.0635242462158203, loss=1.139374852180481
I0303 11:53:20.779422 139758009304832 logging_writer.py:48] [180400] global_step=180400, grad_norm=3.0922276973724365, loss=1.157526969909668
I0303 11:54:05.824795 139758017697536 logging_writer.py:48] [180500] global_step=180500, grad_norm=3.1908581256866455, loss=1.1760690212249756
I0303 11:54:50.628100 139758009304832 logging_writer.py:48] [180600] global_step=180600, grad_norm=3.1013715267181396, loss=1.206289529800415
I0303 11:55:35.420158 139758017697536 logging_writer.py:48] [180700] global_step=180700, grad_norm=3.1133313179016113, loss=1.1485333442687988
I0303 11:56:05.318814 139953291118400 spec.py:321] Evaluating on the training split.
I0303 11:56:16.372169 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 11:56:40.241214 139953291118400 spec.py:349] Evaluating on the test split.
I0303 11:56:41.869375 139953291118400 submission_runner.py:411] Time since start: 86442.05s, 	Step: 180768, 	{'train/accuracy': 0.8854296803474426, 'train/loss': 0.42564108967781067, 'validation/accuracy': 0.7800599932670593, 'validation/loss': 0.8574149012565613, 'validation/num_examples': 50000, 'test/accuracy': 0.6619000434875488, 'test/loss': 1.4548231363296509, 'test/num_examples': 10000, 'score': 80283.59482526779, 'total_duration': 86442.04560875893, 'accumulated_submission_time': 80283.59482526779, 'accumulated_eval_time': 6138.60348033905, 'accumulated_logging_time': 10.583715915679932}
I0303 11:56:41.911892 139758009304832 logging_writer.py:48] [180768] accumulated_eval_time=6138.603480, accumulated_logging_time=10.583716, accumulated_submission_time=80283.594825, global_step=180768, preemption_count=0, score=80283.594825, test/accuracy=0.661900, test/loss=1.454823, test/num_examples=10000, total_duration=86442.045609, train/accuracy=0.885430, train/loss=0.425641, validation/accuracy=0.780060, validation/loss=0.857415, validation/num_examples=50000
I0303 11:56:54.936943 139758017697536 logging_writer.py:48] [180800] global_step=180800, grad_norm=3.4463067054748535, loss=2.9616708755493164
I0303 11:57:35.742357 139758009304832 logging_writer.py:48] [180900] global_step=180900, grad_norm=2.9368555545806885, loss=1.910102128982544
I0303 11:58:20.725841 139758017697536 logging_writer.py:48] [181000] global_step=181000, grad_norm=3.2514119148254395, loss=1.2010176181793213
I0303 11:59:05.931162 139758009304832 logging_writer.py:48] [181100] global_step=181100, grad_norm=3.1984763145446777, loss=1.0608822107315063
I0303 11:59:50.989379 139758017697536 logging_writer.py:48] [181200] global_step=181200, grad_norm=2.950181484222412, loss=1.0462322235107422
I0303 12:00:35.790839 139758009304832 logging_writer.py:48] [181300] global_step=181300, grad_norm=3.156029224395752, loss=1.3633718490600586
I0303 12:01:20.936423 139758017697536 logging_writer.py:48] [181400] global_step=181400, grad_norm=3.343156576156616, loss=2.7487807273864746
I0303 12:02:06.042830 139758009304832 logging_writer.py:48] [181500] global_step=181500, grad_norm=2.996002435684204, loss=1.0706809759140015
I0303 12:02:50.601687 139758017697536 logging_writer.py:48] [181600] global_step=181600, grad_norm=2.994086980819702, loss=1.3972958326339722
I0303 12:03:35.701970 139758009304832 logging_writer.py:48] [181700] global_step=181700, grad_norm=2.820399761199951, loss=1.0275408029556274
I0303 12:03:42.111833 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:03:52.927097 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:04:11.084669 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:04:12.718882 139953291118400 submission_runner.py:411] Time since start: 86892.90s, 	Step: 181716, 	{'train/accuracy': 0.8868945240974426, 'train/loss': 0.4210363030433655, 'validation/accuracy': 0.7802599668502808, 'validation/loss': 0.8553614616394043, 'validation/num_examples': 50000, 'test/accuracy': 0.6617000102996826, 'test/loss': 1.4499728679656982, 'test/num_examples': 10000, 'score': 80703.73807430267, 'total_duration': 86892.89508104324, 'accumulated_submission_time': 80703.73807430267, 'accumulated_eval_time': 6169.210487604141, 'accumulated_logging_time': 10.634981632232666}
I0303 12:04:12.770134 139758017697536 logging_writer.py:48] [181716] accumulated_eval_time=6169.210488, accumulated_logging_time=10.634982, accumulated_submission_time=80703.738074, global_step=181716, preemption_count=0, score=80703.738074, test/accuracy=0.661700, test/loss=1.449973, test/num_examples=10000, total_duration=86892.895081, train/accuracy=0.886895, train/loss=0.421036, validation/accuracy=0.780260, validation/loss=0.855361, validation/num_examples=50000
I0303 12:04:46.749041 139758009304832 logging_writer.py:48] [181800] global_step=181800, grad_norm=4.60284948348999, loss=3.21940279006958
I0303 12:05:31.582191 139758017697536 logging_writer.py:48] [181900] global_step=181900, grad_norm=2.9975318908691406, loss=1.3044867515563965
I0303 12:06:16.592030 139758009304832 logging_writer.py:48] [182000] global_step=182000, grad_norm=3.0254111289978027, loss=2.043987989425659
I0303 12:07:01.616088 139758017697536 logging_writer.py:48] [182100] global_step=182100, grad_norm=3.4139513969421387, loss=1.787709355354309
I0303 12:07:46.255563 139758009304832 logging_writer.py:48] [182200] global_step=182200, grad_norm=2.957158088684082, loss=1.4177377223968506
I0303 12:08:31.485493 139758017697536 logging_writer.py:48] [182300] global_step=182300, grad_norm=3.5936903953552246, loss=2.8343329429626465
I0303 12:09:16.732886 139758009304832 logging_writer.py:48] [182400] global_step=182400, grad_norm=3.0183634757995605, loss=1.8934519290924072
I0303 12:10:01.545401 139758017697536 logging_writer.py:48] [182500] global_step=182500, grad_norm=3.04030179977417, loss=1.1402761936187744
I0303 12:10:46.626924 139758009304832 logging_writer.py:48] [182600] global_step=182600, grad_norm=3.05523943901062, loss=1.1763253211975098
I0303 12:11:12.746250 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:11:23.947342 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:11:45.507875 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:11:47.138922 139953291118400 submission_runner.py:411] Time since start: 87347.32s, 	Step: 182659, 	{'train/accuracy': 0.8882421851158142, 'train/loss': 0.41791942715644836, 'validation/accuracy': 0.780299961566925, 'validation/loss': 0.8557093739509583, 'validation/num_examples': 50000, 'test/accuracy': 0.6627000570297241, 'test/loss': 1.4520686864852905, 'test/num_examples': 10000, 'score': 81123.65591287613, 'total_duration': 87347.31507396698, 'accumulated_submission_time': 81123.65591287613, 'accumulated_eval_time': 6203.603073835373, 'accumulated_logging_time': 10.696644067764282}
I0303 12:11:47.194315 139758017697536 logging_writer.py:48] [182659] accumulated_eval_time=6203.603074, accumulated_logging_time=10.696644, accumulated_submission_time=81123.655913, global_step=182659, preemption_count=0, score=81123.655913, test/accuracy=0.662700, test/loss=1.452069, test/num_examples=10000, total_duration=87347.315074, train/accuracy=0.888242, train/loss=0.417919, validation/accuracy=0.780300, validation/loss=0.855709, validation/num_examples=50000
I0303 12:12:03.782713 139758009304832 logging_writer.py:48] [182700] global_step=182700, grad_norm=2.9938535690307617, loss=1.4237794876098633
I0303 12:12:46.114767 139758017697536 logging_writer.py:48] [182800] global_step=182800, grad_norm=2.9918148517608643, loss=1.25667142868042
I0303 12:13:31.269871 139758009304832 logging_writer.py:48] [182900] global_step=182900, grad_norm=2.8530993461608887, loss=1.2262985706329346
I0303 12:14:16.712321 139758017697536 logging_writer.py:48] [183000] global_step=183000, grad_norm=3.9222466945648193, loss=3.351522922515869
I0303 12:15:01.681073 139758009304832 logging_writer.py:48] [183100] global_step=183100, grad_norm=3.6120922565460205, loss=2.9042229652404785
I0303 12:15:46.620617 139758017697536 logging_writer.py:48] [183200] global_step=183200, grad_norm=3.2519941329956055, loss=1.2067927122116089
I0303 12:16:31.735963 139758009304832 logging_writer.py:48] [183300] global_step=183300, grad_norm=3.1104016304016113, loss=2.285785675048828
I0303 12:17:16.967965 139758017697536 logging_writer.py:48] [183400] global_step=183400, grad_norm=2.9697213172912598, loss=1.757979393005371
I0303 12:18:01.685135 139758009304832 logging_writer.py:48] [183500] global_step=183500, grad_norm=3.1542534828186035, loss=1.6461237668991089
I0303 12:18:46.768249 139758017697536 logging_writer.py:48] [183600] global_step=183600, grad_norm=3.0866811275482178, loss=1.2472903728485107
I0303 12:18:47.393506 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:18:58.210350 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:19:22.307707 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:19:23.940978 139953291118400 submission_runner.py:411] Time since start: 87804.12s, 	Step: 183603, 	{'train/accuracy': 0.8871288895606995, 'train/loss': 0.42072662711143494, 'validation/accuracy': 0.7800599932670593, 'validation/loss': 0.855748176574707, 'validation/num_examples': 50000, 'test/accuracy': 0.6643000245094299, 'test/loss': 1.4516526460647583, 'test/num_examples': 10000, 'score': 81543.79722166061, 'total_duration': 87804.11721277237, 'accumulated_submission_time': 81543.79722166061, 'accumulated_eval_time': 6240.15052652359, 'accumulated_logging_time': 10.76271915435791}
I0303 12:19:23.985026 139758009304832 logging_writer.py:48] [183603] accumulated_eval_time=6240.150527, accumulated_logging_time=10.762719, accumulated_submission_time=81543.797222, global_step=183603, preemption_count=0, score=81543.797222, test/accuracy=0.664300, test/loss=1.451653, test/num_examples=10000, total_duration=87804.117213, train/accuracy=0.887129, train/loss=0.420727, validation/accuracy=0.780060, validation/loss=0.855748, validation/num_examples=50000
I0303 12:20:02.698688 139758017697536 logging_writer.py:48] [183700] global_step=183700, grad_norm=2.86077618598938, loss=1.7253549098968506
I0303 12:20:47.294082 139758009304832 logging_writer.py:48] [183800] global_step=183800, grad_norm=3.333798885345459, loss=2.6020240783691406
I0303 12:21:32.581561 139758017697536 logging_writer.py:48] [183900] global_step=183900, grad_norm=2.9800634384155273, loss=1.214475393295288
I0303 12:22:18.318268 139758009304832 logging_writer.py:48] [184000] global_step=184000, grad_norm=4.093343734741211, loss=3.2349936962127686
I0303 12:23:03.037388 139758017697536 logging_writer.py:48] [184100] global_step=184100, grad_norm=3.556286573410034, loss=2.8813118934631348
I0303 12:23:47.980315 139758009304832 logging_writer.py:48] [184200] global_step=184200, grad_norm=3.1462595462799072, loss=1.203634262084961
I0303 12:24:32.858749 139758017697536 logging_writer.py:48] [184300] global_step=184300, grad_norm=3.0602781772613525, loss=1.0927395820617676
I0303 12:25:17.896865 139758009304832 logging_writer.py:48] [184400] global_step=184400, grad_norm=2.97025465965271, loss=2.482696294784546
I0303 12:26:02.808173 139758017697536 logging_writer.py:48] [184500] global_step=184500, grad_norm=3.2981739044189453, loss=2.149137258529663
I0303 12:26:24.185140 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:26:35.235095 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:26:55.347774 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:26:56.983567 139953291118400 submission_runner.py:411] Time since start: 88257.16s, 	Step: 184549, 	{'train/accuracy': 0.8898437023162842, 'train/loss': 0.4142662286758423, 'validation/accuracy': 0.7801600098609924, 'validation/loss': 0.8554735779762268, 'validation/num_examples': 50000, 'test/accuracy': 0.663800060749054, 'test/loss': 1.4520243406295776, 'test/num_examples': 10000, 'score': 81963.94086170197, 'total_duration': 88257.15979456902, 'accumulated_submission_time': 81963.94086170197, 'accumulated_eval_time': 6272.948943138123, 'accumulated_logging_time': 10.815591096878052}
I0303 12:26:57.036961 139758009304832 logging_writer.py:48] [184549] accumulated_eval_time=6272.948943, accumulated_logging_time=10.815591, accumulated_submission_time=81963.940862, global_step=184549, preemption_count=0, score=81963.940862, test/accuracy=0.663800, test/loss=1.452024, test/num_examples=10000, total_duration=88257.159795, train/accuracy=0.889844, train/loss=0.414266, validation/accuracy=0.780160, validation/loss=0.855474, validation/num_examples=50000
I0303 12:27:17.586258 139758017697536 logging_writer.py:48] [184600] global_step=184600, grad_norm=3.0629072189331055, loss=1.1872386932373047
I0303 12:28:01.136208 139758009304832 logging_writer.py:48] [184700] global_step=184700, grad_norm=3.00824236869812, loss=1.0960729122161865
I0303 12:28:45.625176 139758017697536 logging_writer.py:48] [184800] global_step=184800, grad_norm=4.00288200378418, loss=1.102716088294983
I0303 12:29:30.723598 139758009304832 logging_writer.py:48] [184900] global_step=184900, grad_norm=3.796661615371704, loss=3.302753448486328
I0303 12:30:15.641836 139758017697536 logging_writer.py:48] [185000] global_step=185000, grad_norm=3.3307015895843506, loss=3.0204620361328125
I0303 12:31:00.445526 139758009304832 logging_writer.py:48] [185100] global_step=185100, grad_norm=3.443206787109375, loss=2.89752197265625
I0303 12:31:45.886893 139758017697536 logging_writer.py:48] [185200] global_step=185200, grad_norm=3.2794671058654785, loss=1.135121464729309
I0303 12:32:31.398868 139758009304832 logging_writer.py:48] [185300] global_step=185300, grad_norm=3.018831729888916, loss=1.160571575164795
I0303 12:33:16.496668 139758017697536 logging_writer.py:48] [185400] global_step=185400, grad_norm=3.0207040309906006, loss=2.4645605087280273
I0303 12:33:57.187060 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:34:08.515474 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:34:28.628825 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:34:30.289669 139953291118400 submission_runner.py:411] Time since start: 88710.47s, 	Step: 185492, 	{'train/accuracy': 0.8886523246765137, 'train/loss': 0.41877874732017517, 'validation/accuracy': 0.7800799608230591, 'validation/loss': 0.8548168540000916, 'validation/num_examples': 50000, 'test/accuracy': 0.664400041103363, 'test/loss': 1.4500694274902344, 'test/num_examples': 10000, 'score': 82384.03376245499, 'total_duration': 88710.46589899063, 'accumulated_submission_time': 82384.03376245499, 'accumulated_eval_time': 6306.051533937454, 'accumulated_logging_time': 10.878965616226196}
I0303 12:34:30.332225 139758009304832 logging_writer.py:48] [185492] accumulated_eval_time=6306.051534, accumulated_logging_time=10.878966, accumulated_submission_time=82384.033762, global_step=185492, preemption_count=0, score=82384.033762, test/accuracy=0.664400, test/loss=1.450069, test/num_examples=10000, total_duration=88710.465899, train/accuracy=0.888652, train/loss=0.418779, validation/accuracy=0.780080, validation/loss=0.854817, validation/num_examples=50000
I0303 12:34:33.885695 139758017697536 logging_writer.py:48] [185500] global_step=185500, grad_norm=5.070175647735596, loss=1.4863700866699219
I0303 12:35:14.372457 139758009304832 logging_writer.py:48] [185600] global_step=185600, grad_norm=2.9987919330596924, loss=1.748116374015808
I0303 12:35:59.325737 139758017697536 logging_writer.py:48] [185700] global_step=185700, grad_norm=3.0698750019073486, loss=1.775941252708435
I0303 12:36:44.492573 139758009304832 logging_writer.py:48] [185800] global_step=185800, grad_norm=3.1191458702087402, loss=2.5165717601776123
I0303 12:37:29.514473 139758017697536 logging_writer.py:48] [185900] global_step=185900, grad_norm=3.08088755607605, loss=1.105006456375122
I0303 12:38:14.296828 139758009304832 logging_writer.py:48] [186000] global_step=186000, grad_norm=3.729738235473633, loss=3.079355239868164
I0303 12:38:59.234137 139758017697536 logging_writer.py:48] [186100] global_step=186100, grad_norm=3.0756356716156006, loss=2.761119842529297
I0303 12:39:44.482787 139758009304832 logging_writer.py:48] [186200] global_step=186200, grad_norm=3.8187191486358643, loss=2.76423716545105
I0303 12:40:29.434843 139758017697536 logging_writer.py:48] [186300] global_step=186300, grad_norm=3.008737325668335, loss=1.3162685632705688
I0303 12:41:14.606382 139758009304832 logging_writer.py:48] [186400] global_step=186400, grad_norm=2.992211103439331, loss=2.0314221382141113
I0303 12:41:30.511652 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:41:41.428015 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:42:04.901995 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:42:06.542293 139953291118400 submission_runner.py:411] Time since start: 89166.72s, 	Step: 186437, 	{'train/accuracy': 0.8884961009025574, 'train/loss': 0.418078750371933, 'validation/accuracy': 0.7803399562835693, 'validation/loss': 0.8548141121864319, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.450608491897583, 'test/num_examples': 10000, 'score': 82804.15239548683, 'total_duration': 89166.71850991249, 'accumulated_submission_time': 82804.15239548683, 'accumulated_eval_time': 6342.082160711288, 'accumulated_logging_time': 10.93463397026062}
I0303 12:42:06.595479 139758017697536 logging_writer.py:48] [186437] accumulated_eval_time=6342.082161, accumulated_logging_time=10.934634, accumulated_submission_time=82804.152395, global_step=186437, preemption_count=0, score=82804.152395, test/accuracy=0.664800, test/loss=1.450608, test/num_examples=10000, total_duration=89166.718510, train/accuracy=0.888496, train/loss=0.418079, validation/accuracy=0.780340, validation/loss=0.854814, validation/num_examples=50000
I0303 12:42:31.869674 139758009304832 logging_writer.py:48] [186500] global_step=186500, grad_norm=3.1188552379608154, loss=1.1564648151397705
I0303 12:43:15.060764 139758017697536 logging_writer.py:48] [186600] global_step=186600, grad_norm=3.9519472122192383, loss=2.3247175216674805
I0303 12:43:59.834120 139758009304832 logging_writer.py:48] [186700] global_step=186700, grad_norm=3.133269786834717, loss=1.12534499168396
I0303 12:44:44.743522 139758017697536 logging_writer.py:48] [186800] global_step=186800, grad_norm=3.178067684173584, loss=1.1665892601013184
I0303 12:45:29.961321 139758009304832 logging_writer.py:48] [186900] global_step=186900, grad_norm=3.5897696018218994, loss=3.193845272064209
I0303 12:46:14.859402 139758017697536 logging_writer.py:48] [187000] global_step=187000, grad_norm=2.8477213382720947, loss=1.9711189270019531
I0303 12:46:59.804233 139758009304832 logging_writer.py:48] [187100] global_step=187100, grad_norm=3.137615442276001, loss=1.142927646636963
I0303 12:47:44.618211 139758017697536 logging_writer.py:48] [187200] global_step=187200, grad_norm=3.0532267093658447, loss=2.4725594520568848
I0303 12:48:29.538754 139758009304832 logging_writer.py:48] [187300] global_step=187300, grad_norm=3.130506753921509, loss=1.2062056064605713
I0303 12:49:06.578234 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:49:17.502265 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:49:42.461311 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:49:44.084694 139953291118400 submission_runner.py:411] Time since start: 89624.26s, 	Step: 187384, 	{'train/accuracy': 0.8875585794448853, 'train/loss': 0.41433584690093994, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 83224.0760512352, 'total_duration': 89624.2609269619, 'accumulated_submission_time': 83224.0760512352, 'accumulated_eval_time': 6379.588619709015, 'accumulated_logging_time': 10.998920679092407}
I0303 12:49:44.130053 139758017697536 logging_writer.py:48] [187384] accumulated_eval_time=6379.588620, accumulated_logging_time=10.998921, accumulated_submission_time=83224.076051, global_step=187384, preemption_count=0, score=83224.076051, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=89624.260927, train/accuracy=0.887559, train/loss=0.414336, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 12:49:50.835924 139758009304832 logging_writer.py:48] [187400] global_step=187400, grad_norm=3.805293083190918, loss=3.3130505084991455
I0303 12:50:31.728650 139758017697536 logging_writer.py:48] [187500] global_step=187500, grad_norm=4.198159217834473, loss=3.257697343826294
I0303 12:51:16.599117 139758009304832 logging_writer.py:48] [187600] global_step=187600, grad_norm=3.2211785316467285, loss=1.1187517642974854
I0303 12:52:01.887656 139758017697536 logging_writer.py:48] [187700] global_step=187700, grad_norm=3.199725866317749, loss=1.8968102931976318
I0303 12:52:47.431096 139758009304832 logging_writer.py:48] [187800] global_step=187800, grad_norm=3.105396270751953, loss=2.8122665882110596
I0303 12:53:32.438414 139758017697536 logging_writer.py:48] [187900] global_step=187900, grad_norm=3.126971483230591, loss=1.0317109823226929
I0303 12:54:17.444311 139758009304832 logging_writer.py:48] [188000] global_step=188000, grad_norm=4.157359600067139, loss=2.984309673309326
I0303 12:55:02.585727 139758017697536 logging_writer.py:48] [188100] global_step=188100, grad_norm=3.320068359375, loss=2.7294511795043945
I0303 12:55:47.507092 139758009304832 logging_writer.py:48] [188200] global_step=188200, grad_norm=3.8158164024353027, loss=3.3938794136047363
I0303 12:56:32.811111 139758017697536 logging_writer.py:48] [188300] global_step=188300, grad_norm=3.055643081665039, loss=1.1456385850906372
I0303 12:56:44.173674 139953291118400 spec.py:321] Evaluating on the training split.
I0303 12:56:55.213939 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 12:57:14.704940 139953291118400 spec.py:349] Evaluating on the test split.
I0303 12:57:16.334008 139953291118400 submission_runner.py:411] Time since start: 90076.51s, 	Step: 188327, 	{'train/accuracy': 0.8861523270606995, 'train/loss': 0.41948404908180237, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 83644.06291556358, 'total_duration': 90076.51022052765, 'accumulated_submission_time': 83644.06291556358, 'accumulated_eval_time': 6411.748934745789, 'accumulated_logging_time': 11.053326845169067}
I0303 12:57:16.390605 139758009304832 logging_writer.py:48] [188327] accumulated_eval_time=6411.748935, accumulated_logging_time=11.053327, accumulated_submission_time=83644.062916, global_step=188327, preemption_count=0, score=83644.062916, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=90076.510221, train/accuracy=0.886152, train/loss=0.419484, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 12:57:45.727983 139758017697536 logging_writer.py:48] [188400] global_step=188400, grad_norm=3.1873974800109863, loss=2.097471237182617
I0303 12:58:30.406665 139758009304832 logging_writer.py:48] [188500] global_step=188500, grad_norm=3.2627980709075928, loss=2.2203409671783447
I0303 12:59:15.442667 139758017697536 logging_writer.py:48] [188600] global_step=188600, grad_norm=2.9332973957061768, loss=1.071332335472107
I0303 13:00:00.467904 139758009304832 logging_writer.py:48] [188700] global_step=188700, grad_norm=3.3714241981506348, loss=2.9733190536499023
I0303 13:00:45.376072 139758017697536 logging_writer.py:48] [188800] global_step=188800, grad_norm=2.8862226009368896, loss=1.970971703529358
I0303 13:01:30.450117 139758009304832 logging_writer.py:48] [188900] global_step=188900, grad_norm=3.53532075881958, loss=1.0427948236465454
I0303 13:02:16.079496 139758017697536 logging_writer.py:48] [189000] global_step=189000, grad_norm=3.0629639625549316, loss=1.9001632928848267
I0303 13:03:01.069020 139758009304832 logging_writer.py:48] [189100] global_step=189100, grad_norm=3.851611375808716, loss=2.8325510025024414
I0303 13:03:45.924987 139758017697536 logging_writer.py:48] [189200] global_step=189200, grad_norm=3.063283920288086, loss=2.824517011642456
I0303 13:04:16.686911 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:04:27.991233 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:04:48.775144 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:04:50.418084 139953291118400 submission_runner.py:411] Time since start: 90530.59s, 	Step: 189270, 	{'train/accuracy': 0.885058581829071, 'train/loss': 0.42135584354400635, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 84064.30104327202, 'total_duration': 90530.59429717064, 'accumulated_submission_time': 84064.30104327202, 'accumulated_eval_time': 6445.480100631714, 'accumulated_logging_time': 11.119504451751709}
I0303 13:04:50.472589 139758009304832 logging_writer.py:48] [189270] accumulated_eval_time=6445.480101, accumulated_logging_time=11.119504, accumulated_submission_time=84064.301043, global_step=189270, preemption_count=0, score=84064.301043, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=90530.594297, train/accuracy=0.885059, train/loss=0.421356, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:05:02.715164 139758017697536 logging_writer.py:48] [189300] global_step=189300, grad_norm=3.5977444648742676, loss=3.0776381492614746
I0303 13:05:44.779994 139758009304832 logging_writer.py:48] [189400] global_step=189400, grad_norm=3.324693202972412, loss=1.498006820678711
I0303 13:06:29.897191 139758017697536 logging_writer.py:48] [189500] global_step=189500, grad_norm=2.9872100353240967, loss=1.0262080430984497
I0303 13:07:14.768462 139758009304832 logging_writer.py:48] [189600] global_step=189600, grad_norm=2.9312710762023926, loss=2.4505867958068848
I0303 13:07:59.611134 139758017697536 logging_writer.py:48] [189700] global_step=189700, grad_norm=3.2878973484039307, loss=1.137277364730835
I0303 13:08:44.453226 139758009304832 logging_writer.py:48] [189800] global_step=189800, grad_norm=3.1096458435058594, loss=2.2486109733581543
I0303 13:09:29.586712 139758017697536 logging_writer.py:48] [189900] global_step=189900, grad_norm=2.9359569549560547, loss=1.3786351680755615
I0303 13:10:14.703150 139758009304832 logging_writer.py:48] [190000] global_step=190000, grad_norm=3.1292884349823, loss=2.3216898441314697
I0303 13:10:59.880289 139758017697536 logging_writer.py:48] [190100] global_step=190100, grad_norm=3.0440638065338135, loss=2.519176959991455
I0303 13:11:45.149342 139758009304832 logging_writer.py:48] [190200] global_step=190200, grad_norm=3.173009157180786, loss=1.248323678970337
I0303 13:11:50.421031 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:12:01.356983 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:12:20.974706 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:12:22.602935 139953291118400 submission_runner.py:411] Time since start: 90982.78s, 	Step: 190213, 	{'train/accuracy': 0.8882812261581421, 'train/loss': 0.4192114472389221, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 84484.19007110596, 'total_duration': 90982.77915644646, 'accumulated_submission_time': 84484.19007110596, 'accumulated_eval_time': 6477.661994457245, 'accumulated_logging_time': 11.18522047996521}
I0303 13:12:22.656143 139758017697536 logging_writer.py:48] [190213] accumulated_eval_time=6477.661994, accumulated_logging_time=11.185220, accumulated_submission_time=84484.190071, global_step=190213, preemption_count=0, score=84484.190071, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=90982.779156, train/accuracy=0.888281, train/loss=0.419211, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:12:57.762487 139758009304832 logging_writer.py:48] [190300] global_step=190300, grad_norm=3.1378629207611084, loss=1.0782867670059204
I0303 13:13:42.337708 139758017697536 logging_writer.py:48] [190400] global_step=190400, grad_norm=3.38419771194458, loss=1.4213621616363525
I0303 13:14:27.172042 139758009304832 logging_writer.py:48] [190500] global_step=190500, grad_norm=3.3674116134643555, loss=1.091491937637329
I0303 13:15:12.519635 139758017697536 logging_writer.py:48] [190600] global_step=190600, grad_norm=3.069995164871216, loss=1.306434988975525
I0303 13:15:57.257512 139758009304832 logging_writer.py:48] [190700] global_step=190700, grad_norm=3.0278899669647217, loss=1.0702859163284302
I0303 13:16:42.437459 139758017697536 logging_writer.py:48] [190800] global_step=190800, grad_norm=3.1067240238189697, loss=1.2854160070419312
I0303 13:17:27.688854 139758009304832 logging_writer.py:48] [190900] global_step=190900, grad_norm=3.145115613937378, loss=2.5139002799987793
I0303 13:18:12.483945 139758017697536 logging_writer.py:48] [191000] global_step=191000, grad_norm=3.3359179496765137, loss=1.4388630390167236
I0303 13:18:57.427391 139758009304832 logging_writer.py:48] [191100] global_step=191100, grad_norm=3.0304908752441406, loss=1.2227743864059448
I0303 13:19:22.747150 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:19:33.894501 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:19:52.984132 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:19:54.619004 139953291118400 submission_runner.py:411] Time since start: 91434.80s, 	Step: 191158, 	{'train/accuracy': 0.8881054520606995, 'train/loss': 0.4155466854572296, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 84904.22356843948, 'total_duration': 91434.7952284813, 'accumulated_submission_time': 84904.22356843948, 'accumulated_eval_time': 6509.533877134323, 'accumulated_logging_time': 11.248058319091797}
I0303 13:19:54.674117 139758017697536 logging_writer.py:48] [191158] accumulated_eval_time=6509.533877, accumulated_logging_time=11.248058, accumulated_submission_time=84904.223568, global_step=191158, preemption_count=0, score=84904.223568, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=91434.795228, train/accuracy=0.888105, train/loss=0.415547, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:20:11.648069 139758009304832 logging_writer.py:48] [191200] global_step=191200, grad_norm=2.9920949935913086, loss=1.0612053871154785
I0303 13:20:54.378869 139758017697536 logging_writer.py:48] [191300] global_step=191300, grad_norm=3.304748773574829, loss=1.0880615711212158
I0303 13:21:39.506103 139758009304832 logging_writer.py:48] [191400] global_step=191400, grad_norm=3.225553512573242, loss=1.5888885259628296
I0303 13:22:24.581501 139758017697536 logging_writer.py:48] [191500] global_step=191500, grad_norm=2.8746299743652344, loss=1.0390022993087769
I0303 13:23:09.385347 139758009304832 logging_writer.py:48] [191600] global_step=191600, grad_norm=3.0646941661834717, loss=1.2669405937194824
I0303 13:23:54.243741 139758017697536 logging_writer.py:48] [191700] global_step=191700, grad_norm=3.213416814804077, loss=2.526320695877075
I0303 13:24:39.210834 139758009304832 logging_writer.py:48] [191800] global_step=191800, grad_norm=3.029247999191284, loss=2.293179988861084
I0303 13:25:24.281926 139758017697536 logging_writer.py:48] [191900] global_step=191900, grad_norm=2.915570020675659, loss=1.2568318843841553
I0303 13:26:09.094829 139758009304832 logging_writer.py:48] [192000] global_step=192000, grad_norm=3.5528509616851807, loss=2.4218249320983887
I0303 13:26:54.217275 139758017697536 logging_writer.py:48] [192100] global_step=192100, grad_norm=3.1569395065307617, loss=1.1922402381896973
I0303 13:26:54.813618 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:27:05.888188 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:27:24.194766 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:27:25.860479 139953291118400 submission_runner.py:411] Time since start: 91886.04s, 	Step: 192103, 	{'train/accuracy': 0.8872460722923279, 'train/loss': 0.4198216497898102, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 85324.30487179756, 'total_duration': 91886.03667712212, 'accumulated_submission_time': 85324.30487179756, 'accumulated_eval_time': 6540.580693721771, 'accumulated_logging_time': 11.31272554397583}
I0303 13:27:25.920772 139758009304832 logging_writer.py:48] [192103] accumulated_eval_time=6540.580694, accumulated_logging_time=11.312726, accumulated_submission_time=85324.304872, global_step=192103, preemption_count=0, score=85324.304872, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=91886.036677, train/accuracy=0.887246, train/loss=0.419822, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:28:04.997084 139758017697536 logging_writer.py:48] [192200] global_step=192200, grad_norm=3.7054035663604736, loss=3.212007761001587
I0303 13:28:49.625386 139758009304832 logging_writer.py:48] [192300] global_step=192300, grad_norm=3.169125556945801, loss=1.9191398620605469
I0303 13:29:34.651417 139758017697536 logging_writer.py:48] [192400] global_step=192400, grad_norm=3.198780059814453, loss=1.0961158275604248
I0303 13:30:19.551227 139758009304832 logging_writer.py:48] [192500] global_step=192500, grad_norm=3.188924551010132, loss=1.1700996160507202
I0303 13:31:04.249207 139758017697536 logging_writer.py:48] [192600] global_step=192600, grad_norm=3.2457687854766846, loss=2.8679821491241455
I0303 13:31:49.543161 139758009304832 logging_writer.py:48] [192700] global_step=192700, grad_norm=2.997390031814575, loss=1.7372242212295532
I0303 13:32:34.380035 139758017697536 logging_writer.py:48] [192800] global_step=192800, grad_norm=3.0887341499328613, loss=2.5353074073791504
I0303 13:33:19.195702 139758009304832 logging_writer.py:48] [192900] global_step=192900, grad_norm=3.6551740169525146, loss=3.247873067855835
I0303 13:34:04.114060 139758017697536 logging_writer.py:48] [193000] global_step=193000, grad_norm=4.127967834472656, loss=2.916330575942993
I0303 13:34:25.991785 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:34:36.735047 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:34:59.617813 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:35:01.250602 139953291118400 submission_runner.py:411] Time since start: 92341.43s, 	Step: 193050, 	{'train/accuracy': 0.8844921588897705, 'train/loss': 0.4295682907104492, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 85744.3128118515, 'total_duration': 92341.42679834366, 'accumulated_submission_time': 85744.3128118515, 'accumulated_eval_time': 6575.839470863342, 'accumulated_logging_time': 11.38812780380249}
I0303 13:35:01.301139 139758009304832 logging_writer.py:48] [193050] accumulated_eval_time=6575.839471, accumulated_logging_time=11.388128, accumulated_submission_time=85744.312812, global_step=193050, preemption_count=0, score=85744.312812, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=92341.426798, train/accuracy=0.884492, train/loss=0.429568, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:35:21.432734 139758017697536 logging_writer.py:48] [193100] global_step=193100, grad_norm=3.8058769702911377, loss=1.0949110984802246
I0303 13:36:03.606433 139758009304832 logging_writer.py:48] [193200] global_step=193200, grad_norm=2.937291383743286, loss=1.0685083866119385
I0303 13:36:49.064661 139758017697536 logging_writer.py:48] [193300] global_step=193300, grad_norm=3.8884098529815674, loss=1.1028203964233398
I0303 13:37:34.227401 139758009304832 logging_writer.py:48] [193400] global_step=193400, grad_norm=3.239223003387451, loss=2.8143656253814697
I0303 13:38:19.111050 139758017697536 logging_writer.py:48] [193500] global_step=193500, grad_norm=2.8361098766326904, loss=1.388844609260559
I0303 13:39:03.941848 139758009304832 logging_writer.py:48] [193600] global_step=193600, grad_norm=3.046558380126953, loss=1.2009278535842896
I0303 13:39:48.875716 139758017697536 logging_writer.py:48] [193700] global_step=193700, grad_norm=3.2729599475860596, loss=2.1308741569519043
I0303 13:40:33.803705 139758009304832 logging_writer.py:48] [193800] global_step=193800, grad_norm=3.4631710052490234, loss=1.1121854782104492
I0303 13:41:18.534271 139758017697536 logging_writer.py:48] [193900] global_step=193900, grad_norm=3.3916008472442627, loss=1.1278311014175415
I0303 13:42:01.260350 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:42:12.392293 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:42:30.236586 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:42:31.882483 139953291118400 submission_runner.py:411] Time since start: 92792.06s, 	Step: 193996, 	{'train/accuracy': 0.8874413967132568, 'train/loss': 0.4196164309978485, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 86164.21161937714, 'total_duration': 92792.05870342255, 'accumulated_submission_time': 86164.21161937714, 'accumulated_eval_time': 6606.46160697937, 'accumulated_logging_time': 11.450967073440552}
I0303 13:42:31.939738 139758009304832 logging_writer.py:48] [193996] accumulated_eval_time=6606.461607, accumulated_logging_time=11.450967, accumulated_submission_time=86164.211619, global_step=193996, preemption_count=0, score=86164.211619, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=92792.058703, train/accuracy=0.887441, train/loss=0.419616, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:42:33.928464 139758017697536 logging_writer.py:48] [194000] global_step=194000, grad_norm=3.125007152557373, loss=1.411761999130249
I0303 13:43:15.347068 139758009304832 logging_writer.py:48] [194100] global_step=194100, grad_norm=2.7642693519592285, loss=1.9856321811676025
I0303 13:44:00.141237 139758017697536 logging_writer.py:48] [194200] global_step=194200, grad_norm=3.0885767936706543, loss=1.2219557762145996
I0303 13:44:45.096992 139758009304832 logging_writer.py:48] [194300] global_step=194300, grad_norm=3.579951047897339, loss=3.00022554397583
I0303 13:45:30.277337 139758017697536 logging_writer.py:48] [194400] global_step=194400, grad_norm=3.593911647796631, loss=2.761404275894165
I0303 13:46:15.121028 139758009304832 logging_writer.py:48] [194500] global_step=194500, grad_norm=3.0289993286132812, loss=1.7947661876678467
I0303 13:46:59.915484 139758017697536 logging_writer.py:48] [194600] global_step=194600, grad_norm=3.453984498977661, loss=1.2367942333221436
I0303 13:47:45.069843 139758009304832 logging_writer.py:48] [194700] global_step=194700, grad_norm=3.1177845001220703, loss=1.0745927095413208
I0303 13:48:30.063515 139758017697536 logging_writer.py:48] [194800] global_step=194800, grad_norm=3.779587507247925, loss=2.0525660514831543
I0303 13:49:15.117923 139758009304832 logging_writer.py:48] [194900] global_step=194900, grad_norm=3.0376720428466797, loss=1.231825828552246
I0303 13:49:32.260293 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:49:43.405934 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:50:06.210242 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:50:07.843602 139953291118400 submission_runner.py:411] Time since start: 93248.02s, 	Step: 194940, 	{'train/accuracy': 0.8882421851158142, 'train/loss': 0.41262489557266235, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 86584.47300457954, 'total_duration': 93248.01982617378, 'accumulated_submission_time': 86584.47300457954, 'accumulated_eval_time': 6642.044916152954, 'accumulated_logging_time': 11.519468545913696}
I0303 13:50:07.897788 139758017697536 logging_writer.py:48] [194940] accumulated_eval_time=6642.044916, accumulated_logging_time=11.519469, accumulated_submission_time=86584.473005, global_step=194940, preemption_count=0, score=86584.473005, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=93248.019826, train/accuracy=0.888242, train/loss=0.412625, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:50:31.989274 139758009304832 logging_writer.py:48] [195000] global_step=195000, grad_norm=3.0146493911743164, loss=1.1350692510604858
I0303 13:51:14.945971 139758017697536 logging_writer.py:48] [195100] global_step=195100, grad_norm=3.177478790283203, loss=1.2177749872207642
I0303 13:52:00.191937 139758009304832 logging_writer.py:48] [195200] global_step=195200, grad_norm=3.0002942085266113, loss=1.1267480850219727
I0303 13:52:45.727508 139758017697536 logging_writer.py:48] [195300] global_step=195300, grad_norm=3.072622060775757, loss=2.2176809310913086
I0303 13:53:30.841955 139758009304832 logging_writer.py:48] [195400] global_step=195400, grad_norm=2.8972134590148926, loss=1.6000163555145264
I0303 13:54:15.622957 139758017697536 logging_writer.py:48] [195500] global_step=195500, grad_norm=3.3165786266326904, loss=1.1003913879394531
I0303 13:55:00.435578 139758009304832 logging_writer.py:48] [195600] global_step=195600, grad_norm=3.6777842044830322, loss=3.1202969551086426
I0303 13:55:45.407989 139758017697536 logging_writer.py:48] [195700] global_step=195700, grad_norm=3.2391998767852783, loss=2.1923112869262695
I0303 13:56:30.589654 139758009304832 logging_writer.py:48] [195800] global_step=195800, grad_norm=3.1222176551818848, loss=1.1133445501327515
I0303 13:57:08.063127 139953291118400 spec.py:321] Evaluating on the training split.
I0303 13:57:18.981169 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 13:57:41.854919 139953291118400 spec.py:349] Evaluating on the test split.
I0303 13:57:43.492007 139953291118400 submission_runner.py:411] Time since start: 93703.67s, 	Step: 195885, 	{'train/accuracy': 0.8870898485183716, 'train/loss': 0.41832828521728516, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 87004.58102655411, 'total_duration': 93703.66821908951, 'accumulated_submission_time': 87004.58102655411, 'accumulated_eval_time': 6677.47377038002, 'accumulated_logging_time': 11.58312463760376}
I0303 13:57:43.545758 139758017697536 logging_writer.py:48] [195885] accumulated_eval_time=6677.473770, accumulated_logging_time=11.583125, accumulated_submission_time=87004.581027, global_step=195885, preemption_count=0, score=87004.581027, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=93703.668219, train/accuracy=0.887090, train/loss=0.418328, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 13:57:49.876109 139758009304832 logging_writer.py:48] [195900] global_step=195900, grad_norm=3.1008238792419434, loss=1.8955398797988892
I0303 13:58:30.130755 139758017697536 logging_writer.py:48] [196000] global_step=196000, grad_norm=3.060368537902832, loss=1.108959674835205
I0303 13:59:15.227632 139758009304832 logging_writer.py:48] [196100] global_step=196100, grad_norm=3.3376266956329346, loss=2.7336630821228027
I0303 14:00:00.020887 139758017697536 logging_writer.py:48] [196200] global_step=196200, grad_norm=3.1861815452575684, loss=2.650789737701416
I0303 14:00:45.491034 139758009304832 logging_writer.py:48] [196300] global_step=196300, grad_norm=3.6891050338745117, loss=3.2023730278015137
I0303 14:01:30.241788 139758017697536 logging_writer.py:48] [196400] global_step=196400, grad_norm=3.3500285148620605, loss=2.367607593536377
I0303 14:02:15.248939 139758009304832 logging_writer.py:48] [196500] global_step=196500, grad_norm=2.954738140106201, loss=2.206078290939331
I0303 14:02:59.973243 139758017697536 logging_writer.py:48] [196600] global_step=196600, grad_norm=3.937849521636963, loss=3.0583608150482178
I0303 14:03:44.724317 139758009304832 logging_writer.py:48] [196700] global_step=196700, grad_norm=2.8853719234466553, loss=1.0674846172332764
I0303 14:04:29.479628 139758017697536 logging_writer.py:48] [196800] global_step=196800, grad_norm=2.9804399013519287, loss=1.3161766529083252
I0303 14:04:43.639699 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:04:54.789256 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:05:15.016773 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:05:16.657473 139953291118400 submission_runner.py:411] Time since start: 94156.83s, 	Step: 196833, 	{'train/accuracy': 0.8863085508346558, 'train/loss': 0.42069876194000244, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 87424.61718916893, 'total_duration': 94156.83369517326, 'accumulated_submission_time': 87424.61718916893, 'accumulated_eval_time': 6710.491514205933, 'accumulated_logging_time': 11.646705865859985}
I0303 14:05:16.714214 139758009304832 logging_writer.py:48] [196833] accumulated_eval_time=6710.491514, accumulated_logging_time=11.646706, accumulated_submission_time=87424.617189, global_step=196833, preemption_count=0, score=87424.617189, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=94156.833695, train/accuracy=0.886309, train/loss=0.420699, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:05:43.584115 139758017697536 logging_writer.py:48] [196900] global_step=196900, grad_norm=3.1226937770843506, loss=1.159356713294983
I0303 14:06:28.178534 139758009304832 logging_writer.py:48] [197000] global_step=197000, grad_norm=2.9446730613708496, loss=1.2885301113128662
I0303 14:07:13.408975 139758017697536 logging_writer.py:48] [197100] global_step=197100, grad_norm=2.872562885284424, loss=2.145857334136963
I0303 14:07:58.504879 139758009304832 logging_writer.py:48] [197200] global_step=197200, grad_norm=2.8779749870300293, loss=2.4179136753082275
I0303 14:08:43.301001 139758017697536 logging_writer.py:48] [197300] global_step=197300, grad_norm=3.454455852508545, loss=2.900679111480713
I0303 14:09:28.355989 139758009304832 logging_writer.py:48] [197400] global_step=197400, grad_norm=3.9488441944122314, loss=3.2431142330169678
I0303 14:10:13.706666 139758017697536 logging_writer.py:48] [197500] global_step=197500, grad_norm=3.4164316654205322, loss=1.1446545124053955
I0303 14:10:58.402198 139758009304832 logging_writer.py:48] [197600] global_step=197600, grad_norm=2.9198758602142334, loss=1.9154691696166992
I0303 14:11:43.681073 139758017697536 logging_writer.py:48] [197700] global_step=197700, grad_norm=3.1675984859466553, loss=1.7085819244384766
I0303 14:12:16.704249 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:12:27.907042 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:12:50.011587 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:12:51.645258 139953291118400 submission_runner.py:411] Time since start: 94611.82s, 	Step: 197775, 	{'train/accuracy': 0.8870312571525574, 'train/loss': 0.4229859709739685, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 87844.54752922058, 'total_duration': 94611.82145762444, 'accumulated_submission_time': 87844.54752922058, 'accumulated_eval_time': 6745.4324831962585, 'accumulated_logging_time': 11.7142493724823}
I0303 14:12:51.702856 139758009304832 logging_writer.py:48] [197775] accumulated_eval_time=6745.432483, accumulated_logging_time=11.714249, accumulated_submission_time=87844.547529, global_step=197775, preemption_count=0, score=87844.547529, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=94611.821458, train/accuracy=0.887031, train/loss=0.422986, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:13:01.981010 139758017697536 logging_writer.py:48] [197800] global_step=197800, grad_norm=3.2289137840270996, loss=1.544771671295166
I0303 14:13:43.413073 139758009304832 logging_writer.py:48] [197900] global_step=197900, grad_norm=3.099640130996704, loss=1.136069655418396
I0303 14:14:28.560215 139758017697536 logging_writer.py:48] [198000] global_step=198000, grad_norm=3.2646608352661133, loss=1.1176912784576416
I0303 14:15:13.819703 139758009304832 logging_writer.py:48] [198100] global_step=198100, grad_norm=5.233737945556641, loss=1.1935511827468872
I0303 14:15:59.006212 139758017697536 logging_writer.py:48] [198200] global_step=198200, grad_norm=3.6232552528381348, loss=2.8614630699157715
I0303 14:16:44.104207 139758009304832 logging_writer.py:48] [198300] global_step=198300, grad_norm=3.0496630668640137, loss=1.1462152004241943
I0303 14:17:29.133882 139758017697536 logging_writer.py:48] [198400] global_step=198400, grad_norm=3.407325029373169, loss=1.1279091835021973
I0303 14:18:14.254860 139758009304832 logging_writer.py:48] [198500] global_step=198500, grad_norm=3.4642794132232666, loss=1.5417454242706299
I0303 14:18:58.936326 139758017697536 logging_writer.py:48] [198600] global_step=198600, grad_norm=3.40018630027771, loss=1.302833080291748
I0303 14:19:44.167787 139758009304832 logging_writer.py:48] [198700] global_step=198700, grad_norm=3.0311036109924316, loss=1.3790957927703857
I0303 14:19:51.982659 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:20:03.085959 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:20:24.521594 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:20:26.193557 139953291118400 submission_runner.py:411] Time since start: 95066.37s, 	Step: 198719, 	{'train/accuracy': 0.8882030844688416, 'train/loss': 0.41904616355895996, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 88264.76767849922, 'total_duration': 95066.36974191666, 'accumulated_submission_time': 88264.76767849922, 'accumulated_eval_time': 6779.6433300971985, 'accumulated_logging_time': 11.784050464630127}
I0303 14:20:26.282475 139758017697536 logging_writer.py:48] [198719] accumulated_eval_time=6779.643330, accumulated_logging_time=11.784050, accumulated_submission_time=88264.767678, global_step=198719, preemption_count=0, score=88264.767678, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=95066.369742, train/accuracy=0.888203, train/loss=0.419046, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:20:58.670864 139758009304832 logging_writer.py:48] [198800] global_step=198800, grad_norm=3.247044801712036, loss=1.0882223844528198
I0303 14:21:42.402597 139758017697536 logging_writer.py:48] [198900] global_step=198900, grad_norm=2.863511562347412, loss=1.0375707149505615
I0303 14:22:27.991684 139758009304832 logging_writer.py:48] [199000] global_step=199000, grad_norm=3.465111017227173, loss=2.2617385387420654
I0303 14:23:13.557673 139758017697536 logging_writer.py:48] [199100] global_step=199100, grad_norm=3.185648202896118, loss=1.181134819984436
I0303 14:23:58.552735 139758009304832 logging_writer.py:48] [199200] global_step=199200, grad_norm=3.211150646209717, loss=1.8742575645446777
I0303 14:24:43.509602 139758017697536 logging_writer.py:48] [199300] global_step=199300, grad_norm=3.354337215423584, loss=1.2597154378890991
I0303 14:25:28.981994 139758009304832 logging_writer.py:48] [199400] global_step=199400, grad_norm=3.138084888458252, loss=1.1078088283538818
I0303 14:26:14.036657 139758017697536 logging_writer.py:48] [199500] global_step=199500, grad_norm=3.1131536960601807, loss=1.3107357025146484
I0303 14:26:58.909649 139758009304832 logging_writer.py:48] [199600] global_step=199600, grad_norm=3.065211534500122, loss=1.1592860221862793
I0303 14:27:26.364222 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:27:37.444609 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:27:55.650297 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:27:57.285654 139953291118400 submission_runner.py:411] Time since start: 95517.46s, 	Step: 199663, 	{'train/accuracy': 0.8855078220367432, 'train/loss': 0.42011791467666626, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 88684.78815793991, 'total_duration': 95517.46187448502, 'accumulated_submission_time': 88684.78815793991, 'accumulated_eval_time': 6810.564759016037, 'accumulated_logging_time': 11.886321544647217}
I0303 14:27:57.344674 139758017697536 logging_writer.py:48] [199663] accumulated_eval_time=6810.564759, accumulated_logging_time=11.886322, accumulated_submission_time=88684.788158, global_step=199663, preemption_count=0, score=88684.788158, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=95517.461874, train/accuracy=0.885508, train/loss=0.420118, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:28:12.375336 139758009304832 logging_writer.py:48] [199700] global_step=199700, grad_norm=3.033482789993286, loss=1.2706003189086914
I0303 14:28:55.501633 139758017697536 logging_writer.py:48] [199800] global_step=199800, grad_norm=3.0259225368499756, loss=1.0759656429290771
I0303 14:29:40.653141 139758009304832 logging_writer.py:48] [199900] global_step=199900, grad_norm=2.8076181411743164, loss=1.502563238143921
I0303 14:30:25.864849 139758017697536 logging_writer.py:48] [200000] global_step=200000, grad_norm=3.1365716457366943, loss=1.2146849632263184
I0303 14:31:11.878466 139758009304832 logging_writer.py:48] [200100] global_step=200100, grad_norm=3.0322341918945312, loss=1.082679033279419
I0303 14:31:56.808268 139758017697536 logging_writer.py:48] [200200] global_step=200200, grad_norm=4.014382362365723, loss=3.3051793575286865
I0303 14:32:41.517087 139758009304832 logging_writer.py:48] [200300] global_step=200300, grad_norm=3.17779278755188, loss=1.3844428062438965
I0303 14:33:26.605629 139758017697536 logging_writer.py:48] [200400] global_step=200400, grad_norm=3.1553287506103516, loss=1.4536412954330444
I0303 14:34:11.749991 139758009304832 logging_writer.py:48] [200500] global_step=200500, grad_norm=3.112485647201538, loss=1.1938470602035522
I0303 14:34:56.652707 139758017697536 logging_writer.py:48] [200600] global_step=200600, grad_norm=3.176206350326538, loss=2.7592854499816895
I0303 14:34:57.717787 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:35:09.160528 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:35:34.585844 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:35:36.222258 139953291118400 submission_runner.py:411] Time since start: 95976.40s, 	Step: 200604, 	{'train/accuracy': 0.8885741829872131, 'train/loss': 0.4168844521045685, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 89105.10370564461, 'total_duration': 95976.39848995209, 'accumulated_submission_time': 89105.10370564461, 'accumulated_eval_time': 6849.069217681885, 'accumulated_logging_time': 11.955017805099487}
I0303 14:35:36.272785 139758009304832 logging_writer.py:48] [200604] accumulated_eval_time=6849.069218, accumulated_logging_time=11.955018, accumulated_submission_time=89105.103706, global_step=200604, preemption_count=0, score=89105.103706, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=95976.398490, train/accuracy=0.888574, train/loss=0.416884, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:36:14.817673 139758017697536 logging_writer.py:48] [200700] global_step=200700, grad_norm=3.020859479904175, loss=1.3117095232009888
I0303 14:36:59.414971 139758009304832 logging_writer.py:48] [200800] global_step=200800, grad_norm=2.907744884490967, loss=2.01718807220459
I0303 14:37:44.391215 139758017697536 logging_writer.py:48] [200900] global_step=200900, grad_norm=3.054798126220703, loss=1.4890658855438232
I0303 14:38:29.669390 139758009304832 logging_writer.py:48] [201000] global_step=201000, grad_norm=2.8406379222869873, loss=1.0674190521240234
I0303 14:39:14.603582 139758017697536 logging_writer.py:48] [201100] global_step=201100, grad_norm=3.0454442501068115, loss=1.76865816116333
I0303 14:39:59.432818 139758009304832 logging_writer.py:48] [201200] global_step=201200, grad_norm=3.5190930366516113, loss=1.9577549695968628
I0303 14:40:44.746506 139758017697536 logging_writer.py:48] [201300] global_step=201300, grad_norm=3.505742311477661, loss=3.1842286586761475
I0303 14:41:29.774213 139758009304832 logging_writer.py:48] [201400] global_step=201400, grad_norm=2.9273295402526855, loss=1.70055091381073
I0303 14:42:14.889633 139758017697536 logging_writer.py:48] [201500] global_step=201500, grad_norm=2.958418846130371, loss=1.1356538534164429
I0303 14:42:36.235202 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:42:47.158084 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:43:06.613648 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:43:08.256522 139953291118400 submission_runner.py:411] Time since start: 96428.43s, 	Step: 201549, 	{'train/accuracy': 0.8887695074081421, 'train/loss': 0.4169636070728302, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 89525.00794053078, 'total_duration': 96428.4326581955, 'accumulated_submission_time': 89525.00794053078, 'accumulated_eval_time': 6881.090431928635, 'accumulated_logging_time': 12.015576601028442}
I0303 14:43:08.316491 139758009304832 logging_writer.py:48] [201549] accumulated_eval_time=6881.090432, accumulated_logging_time=12.015577, accumulated_submission_time=89525.007941, global_step=201549, preemption_count=0, score=89525.007941, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=96428.432658, train/accuracy=0.888770, train/loss=0.416964, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:43:28.856656 139758017697536 logging_writer.py:48] [201600] global_step=201600, grad_norm=2.904252052307129, loss=1.3362809419631958
I0303 14:44:12.501518 139758009304832 logging_writer.py:48] [201700] global_step=201700, grad_norm=3.0294861793518066, loss=1.1550300121307373
I0303 14:44:57.285271 139758017697536 logging_writer.py:48] [201800] global_step=201800, grad_norm=3.0621962547302246, loss=1.1287552118301392
I0303 14:45:42.364123 139758009304832 logging_writer.py:48] [201900] global_step=201900, grad_norm=3.08001971244812, loss=1.1085426807403564
I0303 14:46:27.490323 139758017697536 logging_writer.py:48] [202000] global_step=202000, grad_norm=3.357253074645996, loss=1.1826592683792114
I0303 14:47:12.344979 139758009304832 logging_writer.py:48] [202100] global_step=202100, grad_norm=3.7862963676452637, loss=3.199018716812134
I0303 14:47:57.188359 139758017697536 logging_writer.py:48] [202200] global_step=202200, grad_norm=2.9246673583984375, loss=1.2151076793670654
I0303 14:48:41.827453 139758009304832 logging_writer.py:48] [202300] global_step=202300, grad_norm=2.989157199859619, loss=1.9990683794021606
I0303 14:49:26.703824 139758017697536 logging_writer.py:48] [202400] global_step=202400, grad_norm=3.0658037662506104, loss=1.1940999031066895
I0303 14:50:08.648289 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:50:19.833273 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:50:44.184191 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:50:45.814080 139953291118400 submission_runner.py:411] Time since start: 96885.99s, 	Step: 202495, 	{'train/accuracy': 0.8854491710662842, 'train/loss': 0.4246847927570343, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 89945.28154015541, 'total_duration': 96885.9902985096, 'accumulated_submission_time': 89945.28154015541, 'accumulated_eval_time': 6918.2562119960785, 'accumulated_logging_time': 12.085902690887451}
I0303 14:50:45.870081 139758009304832 logging_writer.py:48] [202495] accumulated_eval_time=6918.256212, accumulated_logging_time=12.085903, accumulated_submission_time=89945.281540, global_step=202495, preemption_count=0, score=89945.281540, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=96885.990299, train/accuracy=0.885449, train/loss=0.424685, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:50:48.243308 139758017697536 logging_writer.py:48] [202500] global_step=202500, grad_norm=3.174206018447876, loss=1.1340014934539795
I0303 14:51:28.257087 139758009304832 logging_writer.py:48] [202600] global_step=202600, grad_norm=3.0733399391174316, loss=1.1837587356567383
I0303 14:52:13.330135 139758017697536 logging_writer.py:48] [202700] global_step=202700, grad_norm=2.8731093406677246, loss=1.2445158958435059
I0303 14:52:58.394851 139758009304832 logging_writer.py:48] [202800] global_step=202800, grad_norm=3.2617621421813965, loss=1.5432785749435425
I0303 14:53:43.793824 139758017697536 logging_writer.py:48] [202900] global_step=202900, grad_norm=3.288045644760132, loss=1.4315807819366455
I0303 14:54:28.704090 139758009304832 logging_writer.py:48] [203000] global_step=203000, grad_norm=5.257852554321289, loss=2.0785939693450928
I0303 14:55:13.462807 139758017697536 logging_writer.py:48] [203100] global_step=203100, grad_norm=3.391674041748047, loss=2.912081003189087
I0303 14:55:58.172472 139758009304832 logging_writer.py:48] [203200] global_step=203200, grad_norm=2.8338944911956787, loss=1.5410712957382202
I0303 14:56:43.180886 139758017697536 logging_writer.py:48] [203300] global_step=203300, grad_norm=3.089804172515869, loss=1.1209557056427002
I0303 14:57:28.852809 139758009304832 logging_writer.py:48] [203400] global_step=203400, grad_norm=3.136347532272339, loss=1.3253161907196045
I0303 14:57:45.978244 139953291118400 spec.py:321] Evaluating on the training split.
I0303 14:57:56.942312 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 14:58:20.619590 139953291118400 spec.py:349] Evaluating on the test split.
I0303 14:58:22.247079 139953291118400 submission_runner.py:411] Time since start: 97342.42s, 	Step: 203440, 	{'train/accuracy': 0.8881250023841858, 'train/loss': 0.42219778895378113, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 90365.33030056953, 'total_duration': 97342.42331409454, 'accumulated_submission_time': 90365.33030056953, 'accumulated_eval_time': 6954.5250408649445, 'accumulated_logging_time': 12.15333890914917}
I0303 14:58:22.295998 139758017697536 logging_writer.py:48] [203440] accumulated_eval_time=6954.525041, accumulated_logging_time=12.153339, accumulated_submission_time=90365.330301, global_step=203440, preemption_count=0, score=90365.330301, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=97342.423314, train/accuracy=0.888125, train/loss=0.422198, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 14:58:46.367798 139758009304832 logging_writer.py:48] [203500] global_step=203500, grad_norm=3.1780731678009033, loss=1.8391928672790527
I0303 14:59:28.997733 139758017697536 logging_writer.py:48] [203600] global_step=203600, grad_norm=3.4622602462768555, loss=2.1940395832061768
I0303 15:00:14.556837 139758009304832 logging_writer.py:48] [203700] global_step=203700, grad_norm=3.835397243499756, loss=2.8797085285186768
I0303 15:01:00.377166 139758017697536 logging_writer.py:48] [203800] global_step=203800, grad_norm=2.921081304550171, loss=1.1749681234359741
I0303 15:01:45.477447 139758009304832 logging_writer.py:48] [203900] global_step=203900, grad_norm=3.721363067626953, loss=1.2465050220489502
I0303 15:02:30.858308 139758017697536 logging_writer.py:48] [204000] global_step=204000, grad_norm=3.235398769378662, loss=1.549143671989441
I0303 15:03:16.023941 139758009304832 logging_writer.py:48] [204100] global_step=204100, grad_norm=3.0837342739105225, loss=1.6721333265304565
I0303 15:04:01.138561 139758017697536 logging_writer.py:48] [204200] global_step=204200, grad_norm=3.1574854850769043, loss=1.2334424257278442
I0303 15:04:46.021623 139758009304832 logging_writer.py:48] [204300] global_step=204300, grad_norm=3.198450803756714, loss=1.1155893802642822
I0303 15:05:22.643605 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:05:33.846481 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:05:54.463365 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:05:56.108433 139953291118400 submission_runner.py:411] Time since start: 97796.28s, 	Step: 204383, 	{'train/accuracy': 0.8873046636581421, 'train/loss': 0.4180344343185425, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 90785.62109804153, 'total_duration': 97796.2846519947, 'accumulated_submission_time': 90785.62109804153, 'accumulated_eval_time': 6987.989857196808, 'accumulated_logging_time': 12.211401224136353}
I0303 15:05:56.167017 139758017697536 logging_writer.py:48] [204383] accumulated_eval_time=6987.989857, accumulated_logging_time=12.211401, accumulated_submission_time=90785.621098, global_step=204383, preemption_count=0, score=90785.621098, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=97796.284652, train/accuracy=0.887305, train/loss=0.418034, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:06:03.282187 139758009304832 logging_writer.py:48] [204400] global_step=204400, grad_norm=2.862946033477783, loss=1.0843219757080078
I0303 15:06:44.921026 139758017697536 logging_writer.py:48] [204500] global_step=204500, grad_norm=2.890056848526001, loss=2.0840141773223877
I0303 15:07:29.812780 139758009304832 logging_writer.py:48] [204600] global_step=204600, grad_norm=3.1294336318969727, loss=1.2357085943222046
I0303 15:08:14.842477 139758017697536 logging_writer.py:48] [204700] global_step=204700, grad_norm=2.9552040100097656, loss=1.9459712505340576
I0303 15:09:00.019069 139758009304832 logging_writer.py:48] [204800] global_step=204800, grad_norm=3.0758867263793945, loss=2.182685613632202
I0303 15:09:44.696233 139758017697536 logging_writer.py:48] [204900] global_step=204900, grad_norm=3.23657488822937, loss=2.1296393871307373
I0303 15:10:29.790441 139758009304832 logging_writer.py:48] [205000] global_step=205000, grad_norm=3.938190221786499, loss=1.1226158142089844
I0303 15:11:14.658812 139758017697536 logging_writer.py:48] [205100] global_step=205100, grad_norm=2.9290966987609863, loss=1.3094873428344727
I0303 15:11:59.704461 139758009304832 logging_writer.py:48] [205200] global_step=205200, grad_norm=3.7361412048339844, loss=2.8524978160858154
I0303 15:12:44.516625 139758017697536 logging_writer.py:48] [205300] global_step=205300, grad_norm=3.0820274353027344, loss=1.0292327404022217
I0303 15:12:56.395287 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:13:07.764531 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:13:35.936222 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:13:37.572272 139953291118400 submission_runner.py:411] Time since start: 98257.75s, 	Step: 205328, 	{'train/accuracy': 0.8882616758346558, 'train/loss': 0.41387656331062317, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 91205.78978681564, 'total_duration': 98257.74850678444, 'accumulated_submission_time': 91205.78978681564, 'accumulated_eval_time': 7029.166851758957, 'accumulated_logging_time': 12.281495094299316}
I0303 15:13:37.621921 139758009304832 logging_writer.py:48] [205328] accumulated_eval_time=7029.166852, accumulated_logging_time=12.281495, accumulated_submission_time=91205.789787, global_step=205328, preemption_count=0, score=91205.789787, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=98257.748507, train/accuracy=0.888262, train/loss=0.413877, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:14:06.440726 139758017697536 logging_writer.py:48] [205400] global_step=205400, grad_norm=2.9149539470672607, loss=1.0968083143234253
I0303 15:14:50.281113 139758009304832 logging_writer.py:48] [205500] global_step=205500, grad_norm=3.242271661758423, loss=2.0130929946899414
I0303 15:15:35.199819 139758017697536 logging_writer.py:48] [205600] global_step=205600, grad_norm=3.071288585662842, loss=1.0932029485702515
I0303 15:16:20.639210 139758009304832 logging_writer.py:48] [205700] global_step=205700, grad_norm=3.5829622745513916, loss=1.2256455421447754
I0303 15:17:05.500850 139758017697536 logging_writer.py:48] [205800] global_step=205800, grad_norm=3.1467702388763428, loss=1.2342522144317627
I0303 15:17:50.218001 139758009304832 logging_writer.py:48] [205900] global_step=205900, grad_norm=3.109161853790283, loss=1.6771059036254883
I0303 15:18:34.977362 139758017697536 logging_writer.py:48] [206000] global_step=206000, grad_norm=3.173611640930176, loss=1.1617470979690552
I0303 15:19:19.841432 139758009304832 logging_writer.py:48] [206100] global_step=206100, grad_norm=3.38724422454834, loss=3.113175392150879
I0303 15:20:04.845057 139758017697536 logging_writer.py:48] [206200] global_step=206200, grad_norm=2.925877809524536, loss=1.2603682279586792
I0303 15:20:37.825671 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:20:48.857220 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:21:09.972505 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:21:11.610741 139953291118400 submission_runner.py:411] Time since start: 98711.79s, 	Step: 206275, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.4200892448425293, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 91625.9358868599, 'total_duration': 98711.78695297241, 'accumulated_submission_time': 91625.9358868599, 'accumulated_eval_time': 7062.951898813248, 'accumulated_logging_time': 12.340657472610474}
I0303 15:21:11.671399 139758009304832 logging_writer.py:48] [206275] accumulated_eval_time=7062.951899, accumulated_logging_time=12.340657, accumulated_submission_time=91625.935887, global_step=206275, preemption_count=0, score=91625.935887, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=98711.786953, train/accuracy=0.887383, train/loss=0.420089, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:21:21.934217 139758017697536 logging_writer.py:48] [206300] global_step=206300, grad_norm=3.3403282165527344, loss=2.858015775680542
I0303 15:22:03.822032 139758009304832 logging_writer.py:48] [206400] global_step=206400, grad_norm=3.2965288162231445, loss=2.8341667652130127
I0303 15:22:48.837198 139758017697536 logging_writer.py:48] [206500] global_step=206500, grad_norm=3.17574143409729, loss=1.0449433326721191
I0303 15:23:33.844222 139758009304832 logging_writer.py:48] [206600] global_step=206600, grad_norm=3.037205934524536, loss=1.0616120100021362
I0303 15:24:18.917275 139758017697536 logging_writer.py:48] [206700] global_step=206700, grad_norm=3.133922815322876, loss=2.6473851203918457
I0303 15:25:03.692972 139758009304832 logging_writer.py:48] [206800] global_step=206800, grad_norm=3.0347368717193604, loss=1.1047608852386475
I0303 15:25:48.737128 139758017697536 logging_writer.py:48] [206900] global_step=206900, grad_norm=3.113985776901245, loss=1.1382577419281006
I0303 15:26:33.859009 139758009304832 logging_writer.py:48] [207000] global_step=207000, grad_norm=3.28311824798584, loss=1.5686177015304565
I0303 15:27:18.677810 139758017697536 logging_writer.py:48] [207100] global_step=207100, grad_norm=3.6205201148986816, loss=3.0330970287323
I0303 15:28:03.637238 139758009304832 logging_writer.py:48] [207200] global_step=207200, grad_norm=3.1800320148468018, loss=1.2709681987762451
I0303 15:28:12.021431 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:28:23.308788 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:28:42.758505 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:28:44.395360 139953291118400 submission_runner.py:411] Time since start: 99164.57s, 	Step: 207220, 	{'train/accuracy': 0.8865429759025574, 'train/loss': 0.4198354482650757, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 92046.22657752037, 'total_duration': 99164.57158637047, 'accumulated_submission_time': 92046.22657752037, 'accumulated_eval_time': 7095.32580947876, 'accumulated_logging_time': 12.412407398223877}
I0303 15:28:44.456146 139758017697536 logging_writer.py:48] [207220] accumulated_eval_time=7095.325809, accumulated_logging_time=12.412407, accumulated_submission_time=92046.226578, global_step=207220, preemption_count=0, score=92046.226578, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=99164.571586, train/accuracy=0.886543, train/loss=0.419835, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:29:16.705559 139758009304832 logging_writer.py:48] [207300] global_step=207300, grad_norm=3.0003020763397217, loss=1.660287618637085
I0303 15:30:01.228986 139758017697536 logging_writer.py:48] [207400] global_step=207400, grad_norm=3.022584915161133, loss=2.494459629058838
I0303 15:30:46.075952 139758009304832 logging_writer.py:48] [207500] global_step=207500, grad_norm=3.365185499191284, loss=0.9158901572227478
I0303 15:31:30.752937 139758017697536 logging_writer.py:48] [207600] global_step=207600, grad_norm=3.2687456607818604, loss=1.108442783355713
I0303 15:32:16.018860 139758009304832 logging_writer.py:48] [207700] global_step=207700, grad_norm=2.99516224861145, loss=2.4341487884521484
I0303 15:33:00.689442 139758017697536 logging_writer.py:48] [207800] global_step=207800, grad_norm=3.177198886871338, loss=1.4255034923553467
I0303 15:33:45.704194 139758009304832 logging_writer.py:48] [207900] global_step=207900, grad_norm=3.93151593208313, loss=3.288621425628662
I0303 15:34:30.938060 139758017697536 logging_writer.py:48] [208000] global_step=208000, grad_norm=3.1958184242248535, loss=1.586074709892273
I0303 15:35:15.742230 139758009304832 logging_writer.py:48] [208100] global_step=208100, grad_norm=2.970656156539917, loss=1.1383322477340698
I0303 15:35:44.812890 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:35:55.949369 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:36:22.895519 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:36:24.513747 139953291118400 submission_runner.py:411] Time since start: 99624.69s, 	Step: 208166, 	{'train/accuracy': 0.8901171684265137, 'train/loss': 0.4154210090637207, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 92466.52595090866, 'total_duration': 99624.68998265266, 'accumulated_submission_time': 92466.52595090866, 'accumulated_eval_time': 7135.026664972305, 'accumulated_logging_time': 12.482912302017212}
I0303 15:36:24.559981 139758017697536 logging_writer.py:48] [208166] accumulated_eval_time=7135.026665, accumulated_logging_time=12.482912, accumulated_submission_time=92466.525951, global_step=208166, preemption_count=0, score=92466.525951, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=99624.689983, train/accuracy=0.890117, train/loss=0.415421, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:36:38.365219 139758009304832 logging_writer.py:48] [208200] global_step=208200, grad_norm=3.142064332962036, loss=2.169860363006592
I0303 15:37:19.511063 139758017697536 logging_writer.py:48] [208300] global_step=208300, grad_norm=4.585258483886719, loss=2.984231472015381
I0303 15:38:04.163096 139758009304832 logging_writer.py:48] [208400] global_step=208400, grad_norm=3.3975179195404053, loss=1.128088355064392
I0303 15:38:49.064442 139758017697536 logging_writer.py:48] [208500] global_step=208500, grad_norm=3.186089277267456, loss=2.2117998600006104
I0303 15:39:34.137660 139758009304832 logging_writer.py:48] [208600] global_step=208600, grad_norm=3.535632371902466, loss=3.162827968597412
I0303 15:40:19.026100 139758017697536 logging_writer.py:48] [208700] global_step=208700, grad_norm=2.984351873397827, loss=1.0959810018539429
I0303 15:41:04.055019 139758009304832 logging_writer.py:48] [208800] global_step=208800, grad_norm=3.3819191455841064, loss=1.1183243989944458
I0303 15:41:49.107591 139758017697536 logging_writer.py:48] [208900] global_step=208900, grad_norm=3.5471813678741455, loss=3.176027536392212
I0303 15:42:34.028452 139758009304832 logging_writer.py:48] [209000] global_step=209000, grad_norm=3.547051191329956, loss=3.0405707359313965
I0303 15:43:19.043706 139758017697536 logging_writer.py:48] [209100] global_step=209100, grad_norm=2.93416166305542, loss=1.5513615608215332
I0303 15:43:24.921070 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:43:35.961367 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:43:57.334915 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:43:58.974330 139953291118400 submission_runner.py:411] Time since start: 100079.15s, 	Step: 209115, 	{'train/accuracy': 0.8893554210662842, 'train/loss': 0.4160081148147583, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 92886.82992863655, 'total_duration': 100079.15053081512, 'accumulated_submission_time': 92886.82992863655, 'accumulated_eval_time': 7169.079889535904, 'accumulated_logging_time': 12.53828740119934}
I0303 15:43:59.038458 139758009304832 logging_writer.py:48] [209115] accumulated_eval_time=7169.079890, accumulated_logging_time=12.538287, accumulated_submission_time=92886.829929, global_step=209115, preemption_count=0, score=92886.829929, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=100079.150531, train/accuracy=0.889355, train/loss=0.416008, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:44:33.509943 139758017697536 logging_writer.py:48] [209200] global_step=209200, grad_norm=3.1447768211364746, loss=1.7891390323638916
I0303 15:45:18.388353 139758009304832 logging_writer.py:48] [209300] global_step=209300, grad_norm=3.3571887016296387, loss=1.1228827238082886
I0303 15:46:03.463842 139758017697536 logging_writer.py:48] [209400] global_step=209400, grad_norm=3.792027235031128, loss=3.2429816722869873
I0303 15:46:48.708721 139758009304832 logging_writer.py:48] [209500] global_step=209500, grad_norm=3.1174561977386475, loss=1.1778645515441895
I0303 15:47:33.470215 139758017697536 logging_writer.py:48] [209600] global_step=209600, grad_norm=3.9835665225982666, loss=3.3191864490509033
I0303 15:48:18.461514 139758009304832 logging_writer.py:48] [209700] global_step=209700, grad_norm=3.0339765548706055, loss=1.1854935884475708
I0303 15:49:03.451912 139758017697536 logging_writer.py:48] [209800] global_step=209800, grad_norm=3.3432095050811768, loss=1.0371603965759277
I0303 15:49:48.181218 139758009304832 logging_writer.py:48] [209900] global_step=209900, grad_norm=3.087777614593506, loss=1.1099421977996826
I0303 15:50:33.401340 139758017697536 logging_writer.py:48] [210000] global_step=210000, grad_norm=3.0877766609191895, loss=2.309256076812744
I0303 15:50:59.068982 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:51:10.397164 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:51:34.061690 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:51:35.707449 139953291118400 submission_runner.py:411] Time since start: 100535.88s, 	Step: 210059, 	{'train/accuracy': 0.8882812261581421, 'train/loss': 0.41373205184936523, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 93306.80130004883, 'total_duration': 100535.8836786747, 'accumulated_submission_time': 93306.80130004883, 'accumulated_eval_time': 7205.7183492183685, 'accumulated_logging_time': 12.614384651184082}
I0303 15:51:35.754521 139758009304832 logging_writer.py:48] [210059] accumulated_eval_time=7205.718349, accumulated_logging_time=12.614385, accumulated_submission_time=93306.801300, global_step=210059, preemption_count=0, score=93306.801300, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=100535.883679, train/accuracy=0.888281, train/loss=0.413732, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:51:52.331067 139758017697536 logging_writer.py:48] [210100] global_step=210100, grad_norm=3.0382814407348633, loss=1.0868456363677979
I0303 15:52:34.548447 139758009304832 logging_writer.py:48] [210200] global_step=210200, grad_norm=2.8443877696990967, loss=1.0826181173324585
I0303 15:53:19.644111 139758017697536 logging_writer.py:48] [210300] global_step=210300, grad_norm=3.1769657135009766, loss=1.037506341934204
I0303 15:54:04.752439 139758009304832 logging_writer.py:48] [210400] global_step=210400, grad_norm=3.1059648990631104, loss=2.316757917404175
I0303 15:54:49.786159 139758017697536 logging_writer.py:48] [210500] global_step=210500, grad_norm=3.8062548637390137, loss=3.187953233718872
I0303 15:55:34.876614 139758009304832 logging_writer.py:48] [210600] global_step=210600, grad_norm=3.00470232963562, loss=1.0842493772506714
I0303 15:56:20.067875 139758017697536 logging_writer.py:48] [210700] global_step=210700, grad_norm=3.145857572555542, loss=1.6551649570465088
I0303 15:57:05.116068 139758009304832 logging_writer.py:48] [210800] global_step=210800, grad_norm=3.13456392288208, loss=1.2786084413528442
I0303 15:57:49.997924 139758017697536 logging_writer.py:48] [210900] global_step=210900, grad_norm=3.2156548500061035, loss=1.1304657459259033
I0303 15:58:35.104282 139758009304832 logging_writer.py:48] [211000] global_step=211000, grad_norm=3.4581458568573, loss=1.0763410329818726
I0303 15:58:35.710389 139953291118400 spec.py:321] Evaluating on the training split.
I0303 15:58:46.678381 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 15:59:13.909000 139953291118400 spec.py:349] Evaluating on the test split.
I0303 15:59:15.529196 139953291118400 submission_runner.py:411] Time since start: 100995.71s, 	Step: 211003, 	{'train/accuracy': 0.8879687190055847, 'train/loss': 0.4160420000553131, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 93726.69717526436, 'total_duration': 100995.70543003082, 'accumulated_submission_time': 93726.69717526436, 'accumulated_eval_time': 7245.537149429321, 'accumulated_logging_time': 12.672444820404053}
I0303 15:59:15.578630 139758017697536 logging_writer.py:48] [211003] accumulated_eval_time=7245.537149, accumulated_logging_time=12.672445, accumulated_submission_time=93726.697175, global_step=211003, preemption_count=0, score=93726.697175, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=100995.705430, train/accuracy=0.887969, train/loss=0.416042, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 15:59:54.409394 139758009304832 logging_writer.py:48] [211100] global_step=211100, grad_norm=2.933046817779541, loss=1.809005618095398
I0303 16:00:39.312188 139758017697536 logging_writer.py:48] [211200] global_step=211200, grad_norm=3.2996952533721924, loss=1.1106244325637817
I0303 16:01:24.623634 139758009304832 logging_writer.py:48] [211300] global_step=211300, grad_norm=3.150449752807617, loss=1.1959986686706543
I0303 16:02:09.984406 139758017697536 logging_writer.py:48] [211400] global_step=211400, grad_norm=2.857025623321533, loss=1.1297705173492432
I0303 16:02:55.050300 139758009304832 logging_writer.py:48] [211500] global_step=211500, grad_norm=3.164696455001831, loss=1.162124752998352
I0303 16:03:40.168681 139758017697536 logging_writer.py:48] [211600] global_step=211600, grad_norm=4.148109436035156, loss=3.214535713195801
I0303 16:04:25.398807 139758009304832 logging_writer.py:48] [211700] global_step=211700, grad_norm=3.1926989555358887, loss=1.3510197401046753
I0303 16:05:10.421020 139758017697536 logging_writer.py:48] [211800] global_step=211800, grad_norm=2.9817144870758057, loss=1.7851181030273438
I0303 16:05:55.225968 139758009304832 logging_writer.py:48] [211900] global_step=211900, grad_norm=3.8239457607269287, loss=3.1512491703033447
I0303 16:06:15.828689 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:06:27.789243 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 16:06:47.598294 139953291118400 spec.py:349] Evaluating on the test split.
I0303 16:06:49.231595 139953291118400 submission_runner.py:411] Time since start: 101449.41s, 	Step: 211947, 	{'train/accuracy': 0.8864062428474426, 'train/loss': 0.41835248470306396, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 94146.89120841026, 'total_duration': 101449.40781760216, 'accumulated_submission_time': 94146.89120841026, 'accumulated_eval_time': 7278.940035820007, 'accumulated_logging_time': 12.730435132980347}
I0303 16:06:49.290084 139758017697536 logging_writer.py:48] [211947] accumulated_eval_time=7278.940036, accumulated_logging_time=12.730435, accumulated_submission_time=94146.891208, global_step=211947, preemption_count=0, score=94146.891208, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=101449.407818, train/accuracy=0.886406, train/loss=0.418352, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 16:07:10.610142 139758009304832 logging_writer.py:48] [212000] global_step=212000, grad_norm=3.15773344039917, loss=1.1606959104537964
I0303 16:07:54.412873 139758017697536 logging_writer.py:48] [212100] global_step=212100, grad_norm=3.7573347091674805, loss=3.2202320098876953
I0303 16:08:39.697309 139758009304832 logging_writer.py:48] [212200] global_step=212200, grad_norm=3.1672537326812744, loss=1.0887908935546875
I0303 16:09:24.814527 139758017697536 logging_writer.py:48] [212300] global_step=212300, grad_norm=3.027211904525757, loss=1.0790081024169922
I0303 16:10:09.906569 139758009304832 logging_writer.py:48] [212400] global_step=212400, grad_norm=3.0334253311157227, loss=1.3577100038528442
I0303 16:10:55.220941 139758017697536 logging_writer.py:48] [212500] global_step=212500, grad_norm=3.350019693374634, loss=1.3396881818771362
I0303 16:11:40.375040 139758009304832 logging_writer.py:48] [212600] global_step=212600, grad_norm=3.25665020942688, loss=1.8280144929885864
I0303 16:12:25.603732 139758017697536 logging_writer.py:48] [212700] global_step=212700, grad_norm=3.309232234954834, loss=1.1850743293762207
I0303 16:13:10.609532 139758009304832 logging_writer.py:48] [212800] global_step=212800, grad_norm=3.1354551315307617, loss=2.731412172317505
I0303 16:13:49.402993 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:14:00.489901 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 16:14:28.918091 139953291118400 spec.py:349] Evaluating on the test split.
I0303 16:14:30.546340 139953291118400 submission_runner.py:411] Time since start: 101910.72s, 	Step: 212888, 	{'train/accuracy': 0.8856250047683716, 'train/loss': 0.41986170411109924, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 94566.94662880898, 'total_duration': 101910.72256612778, 'accumulated_submission_time': 94566.94662880898, 'accumulated_eval_time': 7320.083385229111, 'accumulated_logging_time': 12.798975467681885}
I0303 16:14:30.594937 139758017697536 logging_writer.py:48] [212888] accumulated_eval_time=7320.083385, accumulated_logging_time=12.798975, accumulated_submission_time=94566.946629, global_step=212888, preemption_count=0, score=94566.946629, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=101910.722566, train/accuracy=0.885625, train/loss=0.419862, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 16:14:35.721122 139758009304832 logging_writer.py:48] [212900] global_step=212900, grad_norm=3.2265470027923584, loss=2.830436944961548
I0303 16:15:16.416830 139758017697536 logging_writer.py:48] [213000] global_step=213000, grad_norm=3.0376036167144775, loss=1.0910483598709106
I0303 16:16:01.055423 139758009304832 logging_writer.py:48] [213100] global_step=213100, grad_norm=3.510894536972046, loss=1.055187463760376
I0303 16:16:46.532144 139758017697536 logging_writer.py:48] [213200] global_step=213200, grad_norm=2.924916982650757, loss=1.1113373041152954
I0303 16:17:31.711209 139758009304832 logging_writer.py:48] [213300] global_step=213300, grad_norm=3.000714063644409, loss=1.7553142309188843
I0303 16:18:16.388663 139758017697536 logging_writer.py:48] [213400] global_step=213400, grad_norm=3.6686604022979736, loss=3.2219247817993164
I0303 16:19:00.938037 139758009304832 logging_writer.py:48] [213500] global_step=213500, grad_norm=2.978555917739868, loss=1.9677928686141968
I0303 16:19:45.902305 139758017697536 logging_writer.py:48] [213600] global_step=213600, grad_norm=3.4979965686798096, loss=1.152664065361023
I0303 16:20:30.653119 139758009304832 logging_writer.py:48] [213700] global_step=213700, grad_norm=3.0100631713867188, loss=1.2427730560302734
I0303 16:21:15.581814 139758017697536 logging_writer.py:48] [213800] global_step=213800, grad_norm=3.183016538619995, loss=1.8714587688446045
I0303 16:21:30.630736 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:21:41.427954 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 16:22:01.073412 139953291118400 spec.py:349] Evaluating on the test split.
I0303 16:22:02.721864 139953291118400 submission_runner.py:411] Time since start: 102362.90s, 	Step: 213835, 	{'train/accuracy': 0.8876562118530273, 'train/loss': 0.41909927129745483, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 94986.92520284653, 'total_duration': 102362.89806699753, 'accumulated_submission_time': 94986.92520284653, 'accumulated_eval_time': 7352.1744792461395, 'accumulated_logging_time': 12.85687255859375}
I0303 16:22:02.784005 139758009304832 logging_writer.py:48] [213835] accumulated_eval_time=7352.174479, accumulated_logging_time=12.856873, accumulated_submission_time=94986.925203, global_step=213835, preemption_count=0, score=94986.925203, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=102362.898067, train/accuracy=0.887656, train/loss=0.419099, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 16:22:28.873319 139758017697536 logging_writer.py:48] [213900] global_step=213900, grad_norm=2.9364728927612305, loss=1.0988010168075562
I0303 16:23:13.014565 139758009304832 logging_writer.py:48] [214000] global_step=214000, grad_norm=3.1389689445495605, loss=1.9929219484329224
I0303 16:23:57.863272 139758017697536 logging_writer.py:48] [214100] global_step=214100, grad_norm=3.2088534832000732, loss=1.775221347808838
I0303 16:24:43.040644 139758009304832 logging_writer.py:48] [214200] global_step=214200, grad_norm=2.997316598892212, loss=1.1536506414413452
I0303 16:25:27.894945 139758017697536 logging_writer.py:48] [214300] global_step=214300, grad_norm=3.5665793418884277, loss=1.1916301250457764
I0303 16:26:12.793481 139758009304832 logging_writer.py:48] [214400] global_step=214400, grad_norm=3.7338082790374756, loss=2.7538177967071533
I0303 16:26:57.830176 139758017697536 logging_writer.py:48] [214500] global_step=214500, grad_norm=3.172987461090088, loss=2.3656005859375
I0303 16:27:42.853851 139758009304832 logging_writer.py:48] [214600] global_step=214600, grad_norm=3.26918363571167, loss=1.170938491821289
I0303 16:28:27.901092 139758017697536 logging_writer.py:48] [214700] global_step=214700, grad_norm=3.260814905166626, loss=1.1969391107559204
I0303 16:29:03.112627 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:29:14.331647 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 16:29:39.642598 139953291118400 spec.py:349] Evaluating on the test split.
I0303 16:29:41.280850 139953291118400 submission_runner.py:411] Time since start: 102821.46s, 	Step: 214780, 	{'train/accuracy': 0.8873242139816284, 'train/loss': 0.4169353246688843, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 95407.19551420212, 'total_duration': 102821.45707058907, 'accumulated_submission_time': 95407.19551420212, 'accumulated_eval_time': 7390.342691898346, 'accumulated_logging_time': 12.929483413696289}
I0303 16:29:41.342629 139758009304832 logging_writer.py:48] [214780] accumulated_eval_time=7390.342692, accumulated_logging_time=12.929483, accumulated_submission_time=95407.195514, global_step=214780, preemption_count=0, score=95407.195514, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=102821.457071, train/accuracy=0.887324, train/loss=0.416935, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 16:29:49.650239 139758017697536 logging_writer.py:48] [214800] global_step=214800, grad_norm=3.735847234725952, loss=3.15067982673645
I0303 16:30:30.506980 139758009304832 logging_writer.py:48] [214900] global_step=214900, grad_norm=3.0035364627838135, loss=1.156086802482605
I0303 16:31:15.277607 139758017697536 logging_writer.py:48] [215000] global_step=215000, grad_norm=3.1769180297851562, loss=1.0998923778533936
I0303 16:32:00.018985 139758009304832 logging_writer.py:48] [215100] global_step=215100, grad_norm=3.8368091583251953, loss=3.3910913467407227
I0303 16:32:45.262440 139758017697536 logging_writer.py:48] [215200] global_step=215200, grad_norm=2.9670891761779785, loss=1.220397710800171
I0303 16:33:30.225449 139758009304832 logging_writer.py:48] [215300] global_step=215300, grad_norm=2.9507393836975098, loss=1.0545696020126343
I0303 16:34:15.108698 139758017697536 logging_writer.py:48] [215400] global_step=215400, grad_norm=3.0037899017333984, loss=1.0728390216827393
I0303 16:34:59.784125 139758009304832 logging_writer.py:48] [215500] global_step=215500, grad_norm=3.393118381500244, loss=2.739365339279175
I0303 16:35:44.670743 139758017697536 logging_writer.py:48] [215600] global_step=215600, grad_norm=3.223576545715332, loss=1.1487860679626465
I0303 16:36:29.842888 139758009304832 logging_writer.py:48] [215700] global_step=215700, grad_norm=3.1783077716827393, loss=1.1371431350708008
I0303 16:36:41.638044 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:36:52.611471 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 16:37:18.970602 139953291118400 spec.py:349] Evaluating on the test split.
I0303 16:37:20.593086 139953291118400 submission_runner.py:411] Time since start: 103280.77s, 	Step: 215728, 	{'train/accuracy': 0.8858398199081421, 'train/loss': 0.42532575130462646, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 95827.43306875229, 'total_duration': 103280.76931118965, 'accumulated_submission_time': 95827.43306875229, 'accumulated_eval_time': 7429.297716617584, 'accumulated_logging_time': 13.001351118087769}
I0303 16:37:20.640768 139758017697536 logging_writer.py:48] [215728] accumulated_eval_time=7429.297717, accumulated_logging_time=13.001351, accumulated_submission_time=95827.433069, global_step=215728, preemption_count=0, score=95827.433069, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=103280.769311, train/accuracy=0.885840, train/loss=0.425326, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 16:37:49.474671 139758009304832 logging_writer.py:48] [215800] global_step=215800, grad_norm=3.602557897567749, loss=1.7399893999099731
I0303 16:38:32.836403 139758017697536 logging_writer.py:48] [215900] global_step=215900, grad_norm=3.016164779663086, loss=1.1819859743118286
I0303 16:39:17.999188 139758009304832 logging_writer.py:48] [216000] global_step=216000, grad_norm=3.2293827533721924, loss=1.3923885822296143
I0303 16:40:03.052539 139758017697536 logging_writer.py:48] [216100] global_step=216100, grad_norm=3.1190168857574463, loss=1.1647318601608276
I0303 16:40:47.803137 139758009304832 logging_writer.py:48] [216200] global_step=216200, grad_norm=3.1691291332244873, loss=1.1690038442611694
I0303 16:41:32.511842 139758017697536 logging_writer.py:48] [216300] global_step=216300, grad_norm=2.9342238903045654, loss=1.4634236097335815
I0303 16:42:17.615479 139758009304832 logging_writer.py:48] [216400] global_step=216400, grad_norm=3.0866637229919434, loss=1.158797264099121
I0303 16:43:03.085168 139758017697536 logging_writer.py:48] [216500] global_step=216500, grad_norm=3.2013370990753174, loss=2.543644666671753
I0303 16:43:47.689800 139758009304832 logging_writer.py:48] [216600] global_step=216600, grad_norm=3.316229820251465, loss=1.1657719612121582
I0303 16:44:20.895794 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:44:32.095293 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 16:44:50.512901 139953291118400 spec.py:349] Evaluating on the test split.
I0303 16:44:52.148650 139953291118400 submission_runner.py:411] Time since start: 103732.32s, 	Step: 216675, 	{'train/accuracy': 0.8865820169448853, 'train/loss': 0.4243214726448059, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 96247.62993168831, 'total_duration': 103732.32486963272, 'accumulated_submission_time': 96247.62993168831, 'accumulated_eval_time': 7460.550596475601, 'accumulated_logging_time': 13.059123516082764}
I0303 16:44:52.212673 139758017697536 logging_writer.py:48] [216675] accumulated_eval_time=7460.550596, accumulated_logging_time=13.059124, accumulated_submission_time=96247.629932, global_step=216675, preemption_count=0, score=96247.629932, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=103732.324870, train/accuracy=0.886582, train/loss=0.424321, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 16:45:02.489138 139758009304832 logging_writer.py:48] [216700] global_step=216700, grad_norm=3.5869932174682617, loss=2.8346705436706543
I0303 16:45:45.396105 139758017697536 logging_writer.py:48] [216800] global_step=216800, grad_norm=3.5387933254241943, loss=3.1025705337524414
I0303 16:46:30.536667 139758009304832 logging_writer.py:48] [216900] global_step=216900, grad_norm=2.971209764480591, loss=2.0226473808288574
I0303 16:47:15.870361 139758017697536 logging_writer.py:48] [217000] global_step=217000, grad_norm=3.3884470462799072, loss=1.706299066543579
I0303 16:48:01.024764 139758009304832 logging_writer.py:48] [217100] global_step=217100, grad_norm=3.4001283645629883, loss=1.9234387874603271
I0303 16:48:46.260361 139758017697536 logging_writer.py:48] [217200] global_step=217200, grad_norm=3.725818634033203, loss=3.0159921646118164
I0303 16:49:31.480407 139758009304832 logging_writer.py:48] [217300] global_step=217300, grad_norm=2.912552833557129, loss=1.1579492092132568
I0303 16:50:16.517582 139758017697536 logging_writer.py:48] [217400] global_step=217400, grad_norm=3.1888206005096436, loss=1.5549789667129517
I0303 16:51:01.588646 139758009304832 logging_writer.py:48] [217500] global_step=217500, grad_norm=2.9706287384033203, loss=1.0723230838775635
I0303 16:51:46.755179 139758017697536 logging_writer.py:48] [217600] global_step=217600, grad_norm=3.1972837448120117, loss=1.4550390243530273
I0303 16:51:52.363973 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:52:03.634065 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 16:52:26.282063 139953291118400 spec.py:349] Evaluating on the test split.
I0303 16:52:27.938274 139953291118400 submission_runner.py:411] Time since start: 104188.11s, 	Step: 217614, 	{'train/accuracy': 0.8871874809265137, 'train/loss': 0.4233055114746094, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 96667.72405338287, 'total_duration': 104188.11450624466, 'accumulated_submission_time': 96667.72405338287, 'accumulated_eval_time': 7496.124892711639, 'accumulated_logging_time': 13.133168935775757}
I0303 16:52:27.989796 139758009304832 logging_writer.py:48] [217614] accumulated_eval_time=7496.124893, accumulated_logging_time=13.133169, accumulated_submission_time=96667.724053, global_step=217614, preemption_count=0, score=96667.724053, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=104188.114506, train/accuracy=0.887187, train/loss=0.423306, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 16:53:02.338737 139758017697536 logging_writer.py:48] [217700] global_step=217700, grad_norm=3.3332581520080566, loss=1.195234775543213
I0303 16:53:47.168269 139758009304832 logging_writer.py:48] [217800] global_step=217800, grad_norm=3.624241590499878, loss=3.2005341053009033
I0303 16:54:32.097276 139758017697536 logging_writer.py:48] [217900] global_step=217900, grad_norm=2.9420387744903564, loss=2.414921998977661
I0303 16:55:17.545844 139758009304832 logging_writer.py:48] [218000] global_step=218000, grad_norm=3.1562485694885254, loss=2.520430326461792
I0303 16:56:02.227722 139758017697536 logging_writer.py:48] [218100] global_step=218100, grad_norm=3.2507407665252686, loss=1.257345199584961
I0303 16:56:47.440760 139758009304832 logging_writer.py:48] [218200] global_step=218200, grad_norm=3.4058940410614014, loss=2.6868908405303955
I0303 16:57:32.598870 139758017697536 logging_writer.py:48] [218300] global_step=218300, grad_norm=2.988990068435669, loss=1.1379977464675903
I0303 16:58:17.345549 139758009304832 logging_writer.py:48] [218400] global_step=218400, grad_norm=2.926520824432373, loss=1.061486005783081
I0303 16:59:02.543641 139758017697536 logging_writer.py:48] [218500] global_step=218500, grad_norm=3.040796995162964, loss=2.665271759033203
I0303 16:59:28.074103 139953291118400 spec.py:321] Evaluating on the training split.
I0303 16:59:38.961034 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:00:00.058478 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:00:01.697217 139953291118400 submission_runner.py:411] Time since start: 104641.87s, 	Step: 218559, 	{'train/accuracy': 0.8890820145606995, 'train/loss': 0.41174280643463135, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 97087.75162792206, 'total_duration': 104641.87342977524, 'accumulated_submission_time': 97087.75162792206, 'accumulated_eval_time': 7529.747981071472, 'accumulated_logging_time': 13.193522214889526}
I0303 17:00:01.761682 139758009304832 logging_writer.py:48] [218559] accumulated_eval_time=7529.747981, accumulated_logging_time=13.193522, accumulated_submission_time=97087.751628, global_step=218559, preemption_count=0, score=97087.751628, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=104641.873430, train/accuracy=0.889082, train/loss=0.411743, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:00:18.377489 139758017697536 logging_writer.py:48] [218600] global_step=218600, grad_norm=2.912238359451294, loss=1.8608036041259766
I0303 17:01:00.967760 139758009304832 logging_writer.py:48] [218700] global_step=218700, grad_norm=2.9534270763397217, loss=1.0566271543502808
I0303 17:01:46.116256 139758017697536 logging_writer.py:48] [218800] global_step=218800, grad_norm=3.2784066200256348, loss=1.1973488330841064
I0303 17:02:31.243132 139758009304832 logging_writer.py:48] [218900] global_step=218900, grad_norm=3.8585751056671143, loss=2.4916975498199463
I0303 17:03:16.597547 139758017697536 logging_writer.py:48] [219000] global_step=219000, grad_norm=3.075610637664795, loss=1.123564600944519
I0303 17:04:01.723774 139758009304832 logging_writer.py:48] [219100] global_step=219100, grad_norm=3.2898430824279785, loss=1.1581027507781982
I0303 17:04:46.667720 139758017697536 logging_writer.py:48] [219200] global_step=219200, grad_norm=3.099201202392578, loss=2.014863967895508
I0303 17:05:31.663745 139758009304832 logging_writer.py:48] [219300] global_step=219300, grad_norm=3.1202540397644043, loss=2.3518269062042236
I0303 17:06:16.711390 139758017697536 logging_writer.py:48] [219400] global_step=219400, grad_norm=2.8991830348968506, loss=1.942021369934082
I0303 17:07:01.788821 139758009304832 logging_writer.py:48] [219500] global_step=219500, grad_norm=3.3493311405181885, loss=1.1780632734298706
I0303 17:07:01.803568 139953291118400 spec.py:321] Evaluating on the training split.
I0303 17:07:12.844838 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:07:32.114575 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:07:33.751376 139953291118400 submission_runner.py:411] Time since start: 105093.93s, 	Step: 219501, 	{'train/accuracy': 0.8858202695846558, 'train/loss': 0.421209454536438, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 97507.7348575592, 'total_duration': 105093.92755794525, 'accumulated_submission_time': 97507.7348575592, 'accumulated_eval_time': 7561.695729017258, 'accumulated_logging_time': 13.267573595046997}
I0303 17:07:33.816815 139758017697536 logging_writer.py:48] [219501] accumulated_eval_time=7561.695729, accumulated_logging_time=13.267574, accumulated_submission_time=97507.734858, global_step=219501, preemption_count=0, score=97507.734858, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=105093.927558, train/accuracy=0.885820, train/loss=0.421209, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:08:14.757841 139758009304832 logging_writer.py:48] [219600] global_step=219600, grad_norm=3.0324041843414307, loss=1.950164794921875
I0303 17:08:59.547776 139758017697536 logging_writer.py:48] [219700] global_step=219700, grad_norm=3.266066789627075, loss=1.2854276895523071
I0303 17:09:44.390170 139758009304832 logging_writer.py:48] [219800] global_step=219800, grad_norm=3.6959686279296875, loss=2.97121524810791
I0303 17:10:29.425754 139758017697536 logging_writer.py:48] [219900] global_step=219900, grad_norm=3.0132246017456055, loss=1.034358024597168
I0303 17:11:14.596225 139758009304832 logging_writer.py:48] [220000] global_step=220000, grad_norm=3.1687841415405273, loss=2.544442653656006
I0303 17:11:59.412022 139758017697536 logging_writer.py:48] [220100] global_step=220100, grad_norm=2.9781198501586914, loss=1.1286489963531494
I0303 17:12:44.571053 139758009304832 logging_writer.py:48] [220200] global_step=220200, grad_norm=3.09037709236145, loss=1.1671090126037598
I0303 17:13:29.507367 139758017697536 logging_writer.py:48] [220300] global_step=220300, grad_norm=3.1760246753692627, loss=2.125305652618408
I0303 17:14:14.421200 139758009304832 logging_writer.py:48] [220400] global_step=220400, grad_norm=2.9792263507843018, loss=1.4639313220977783
I0303 17:14:33.833278 139953291118400 spec.py:321] Evaluating on the training split.
I0303 17:14:44.793451 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:15:11.634228 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:15:13.262868 139953291118400 submission_runner.py:411] Time since start: 105553.44s, 	Step: 220445, 	{'train/accuracy': 0.8859570026397705, 'train/loss': 0.42330828309059143, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 97927.69353795052, 'total_duration': 105553.43908929825, 'accumulated_submission_time': 97927.69353795052, 'accumulated_eval_time': 7601.125306606293, 'accumulated_logging_time': 13.342846632003784}
I0303 17:15:13.324879 139758017697536 logging_writer.py:48] [220445] accumulated_eval_time=7601.125307, accumulated_logging_time=13.342847, accumulated_submission_time=97927.693538, global_step=220445, preemption_count=0, score=97927.693538, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=105553.439089, train/accuracy=0.885957, train/loss=0.423308, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:15:35.445399 139758009304832 logging_writer.py:48] [220500] global_step=220500, grad_norm=3.1269187927246094, loss=1.7471230030059814
I0303 17:16:17.864337 139758017697536 logging_writer.py:48] [220600] global_step=220600, grad_norm=3.228506088256836, loss=2.908020496368408
I0303 17:17:03.106916 139758009304832 logging_writer.py:48] [220700] global_step=220700, grad_norm=3.3231420516967773, loss=1.0978517532348633
I0303 17:17:47.918924 139758017697536 logging_writer.py:48] [220800] global_step=220800, grad_norm=3.1101255416870117, loss=1.1365422010421753
I0303 17:18:32.862809 139758009304832 logging_writer.py:48] [220900] global_step=220900, grad_norm=3.1248738765716553, loss=1.7285373210906982
I0303 17:19:17.665390 139758017697536 logging_writer.py:48] [221000] global_step=221000, grad_norm=3.990131139755249, loss=3.0042476654052734
I0303 17:20:02.789925 139758009304832 logging_writer.py:48] [221100] global_step=221100, grad_norm=2.968653440475464, loss=1.1433961391448975
I0303 17:20:47.901438 139758017697536 logging_writer.py:48] [221200] global_step=221200, grad_norm=2.7127203941345215, loss=1.051937460899353
I0303 17:21:33.245631 139758009304832 logging_writer.py:48] [221300] global_step=221300, grad_norm=3.231558084487915, loss=1.115649700164795
I0303 17:22:13.526105 139953291118400 spec.py:321] Evaluating on the training split.
I0303 17:22:24.398508 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:22:59.837086 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:23:01.459222 139953291118400 submission_runner.py:411] Time since start: 106021.64s, 	Step: 221391, 	{'train/accuracy': 0.8848632574081421, 'train/loss': 0.4247506260871887, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 98347.8355793953, 'total_duration': 106021.63544940948, 'accumulated_submission_time': 98347.8355793953, 'accumulated_eval_time': 7649.0584235191345, 'accumulated_logging_time': 13.41545057296753}
I0303 17:23:01.511699 139758017697536 logging_writer.py:48] [221391] accumulated_eval_time=7649.058424, accumulated_logging_time=13.415451, accumulated_submission_time=98347.835579, global_step=221391, preemption_count=0, score=98347.835579, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=106021.635449, train/accuracy=0.884863, train/loss=0.424751, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:23:05.459920 139758009304832 logging_writer.py:48] [221400] global_step=221400, grad_norm=4.367495536804199, loss=3.229063034057617
I0303 17:23:45.674328 139758017697536 logging_writer.py:48] [221500] global_step=221500, grad_norm=3.2128946781158447, loss=1.1548272371292114
I0303 17:24:30.465720 139758009304832 logging_writer.py:48] [221600] global_step=221600, grad_norm=3.223628044128418, loss=2.272557497024536
I0303 17:25:15.442309 139758017697536 logging_writer.py:48] [221700] global_step=221700, grad_norm=3.1538569927215576, loss=1.1809003353118896
I0303 17:26:00.453216 139758009304832 logging_writer.py:48] [221800] global_step=221800, grad_norm=3.127793312072754, loss=1.3077396154403687
I0303 17:26:45.448158 139758017697536 logging_writer.py:48] [221900] global_step=221900, grad_norm=2.8585681915283203, loss=1.9266281127929688
I0303 17:27:30.412433 139758009304832 logging_writer.py:48] [222000] global_step=222000, grad_norm=3.5199759006500244, loss=2.953479766845703
I0303 17:28:15.127256 139758017697536 logging_writer.py:48] [222100] global_step=222100, grad_norm=3.4182374477386475, loss=2.808338165283203
I0303 17:29:00.062138 139758009304832 logging_writer.py:48] [222200] global_step=222200, grad_norm=3.6139719486236572, loss=1.1237375736236572
I0303 17:29:45.236829 139758017697536 logging_writer.py:48] [222300] global_step=222300, grad_norm=3.274088144302368, loss=2.709376096725464
I0303 17:30:01.925791 139953291118400 spec.py:321] Evaluating on the training split.
I0303 17:30:13.177559 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:30:32.895624 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:30:34.540734 139953291118400 submission_runner.py:411] Time since start: 106474.72s, 	Step: 222339, 	{'train/accuracy': 0.8887499570846558, 'train/loss': 0.41264036297798157, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 98768.19242358208, 'total_duration': 106474.71693491936, 'accumulated_submission_time': 98768.19242358208, 'accumulated_eval_time': 7681.673318862915, 'accumulated_logging_time': 13.478192329406738}
I0303 17:30:34.605681 139758009304832 logging_writer.py:48] [222339] accumulated_eval_time=7681.673319, accumulated_logging_time=13.478192, accumulated_submission_time=98768.192424, global_step=222339, preemption_count=0, score=98768.192424, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=106474.716935, train/accuracy=0.888750, train/loss=0.412640, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:30:59.094153 139758017697536 logging_writer.py:48] [222400] global_step=222400, grad_norm=3.408590078353882, loss=1.2624226808547974
I0303 17:31:43.930488 139758009304832 logging_writer.py:48] [222500] global_step=222500, grad_norm=3.033771514892578, loss=1.210925579071045
I0303 17:32:28.746448 139758017697536 logging_writer.py:48] [222600] global_step=222600, grad_norm=3.512399435043335, loss=1.1553397178649902
I0303 17:33:13.997126 139758009304832 logging_writer.py:48] [222700] global_step=222700, grad_norm=3.2770752906799316, loss=1.076358437538147
I0303 17:33:58.601585 139758017697536 logging_writer.py:48] [222800] global_step=222800, grad_norm=3.066073179244995, loss=1.199414849281311
I0303 17:34:43.626475 139758009304832 logging_writer.py:48] [222900] global_step=222900, grad_norm=2.8662896156311035, loss=1.0315173864364624
I0303 17:35:28.806369 139758017697536 logging_writer.py:48] [223000] global_step=223000, grad_norm=3.046097993850708, loss=1.05899977684021
I0303 17:36:13.747197 139758009304832 logging_writer.py:48] [223100] global_step=223100, grad_norm=3.1317219734191895, loss=1.1026219129562378
I0303 17:36:58.636487 139758017697536 logging_writer.py:48] [223200] global_step=223200, grad_norm=3.457702398300171, loss=3.0633978843688965
I0303 17:37:34.949464 139953291118400 spec.py:321] Evaluating on the training split.
I0303 17:37:46.263339 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:38:19.217750 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:38:20.851033 139953291118400 submission_runner.py:411] Time since start: 106941.03s, 	Step: 223282, 	{'train/accuracy': 0.8872851133346558, 'train/loss': 0.41973817348480225, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 99188.47766494751, 'total_duration': 106941.02724575996, 'accumulated_submission_time': 99188.47766494751, 'accumulated_eval_time': 7727.574855804443, 'accumulated_logging_time': 13.553714990615845}
I0303 17:38:20.908358 139758009304832 logging_writer.py:48] [223282] accumulated_eval_time=7727.574856, accumulated_logging_time=13.553715, accumulated_submission_time=99188.477665, global_step=223282, preemption_count=0, score=99188.477665, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=106941.027246, train/accuracy=0.887285, train/loss=0.419738, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:38:28.412034 139758017697536 logging_writer.py:48] [223300] global_step=223300, grad_norm=3.0335161685943604, loss=1.513992428779602
I0303 17:39:09.326250 139758009304832 logging_writer.py:48] [223400] global_step=223400, grad_norm=3.2396609783172607, loss=2.5779080390930176
I0303 17:39:54.247360 139758017697536 logging_writer.py:48] [223500] global_step=223500, grad_norm=3.905907154083252, loss=3.198230504989624
I0303 17:40:39.151902 139758009304832 logging_writer.py:48] [223600] global_step=223600, grad_norm=3.189847707748413, loss=1.1290165185928345
I0303 17:41:24.407136 139758017697536 logging_writer.py:48] [223700] global_step=223700, grad_norm=3.1368370056152344, loss=1.0933046340942383
I0303 17:42:09.371512 139758009304832 logging_writer.py:48] [223800] global_step=223800, grad_norm=2.8808929920196533, loss=1.00813627243042
I0303 17:42:54.368378 139758017697536 logging_writer.py:48] [223900] global_step=223900, grad_norm=3.3737518787384033, loss=1.1049304008483887
I0303 17:43:39.861554 139758009304832 logging_writer.py:48] [224000] global_step=224000, grad_norm=3.175128698348999, loss=2.7267093658447266
I0303 17:44:24.767449 139758017697536 logging_writer.py:48] [224100] global_step=224100, grad_norm=3.0823235511779785, loss=1.1574653387069702
I0303 17:45:09.916584 139758009304832 logging_writer.py:48] [224200] global_step=224200, grad_norm=3.3597803115844727, loss=1.722201943397522
I0303 17:45:21.113152 139953291118400 spec.py:321] Evaluating on the training split.
I0303 17:45:32.083819 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:45:53.583799 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:45:55.216071 139953291118400 submission_runner.py:411] Time since start: 107395.39s, 	Step: 224226, 	{'train/accuracy': 0.8883593678474426, 'train/loss': 0.41791120171546936, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 99608.62461566925, 'total_duration': 107395.39229464531, 'accumulated_submission_time': 99608.62461566925, 'accumulated_eval_time': 7761.677759170532, 'accumulated_logging_time': 13.621427297592163}
I0303 17:45:55.277028 139758017697536 logging_writer.py:48] [224226] accumulated_eval_time=7761.677759, accumulated_logging_time=13.621427, accumulated_submission_time=99608.624616, global_step=224226, preemption_count=0, score=99608.624616, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=107395.392295, train/accuracy=0.888359, train/loss=0.417911, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:46:24.902371 139758009304832 logging_writer.py:48] [224300] global_step=224300, grad_norm=3.1574060916900635, loss=1.147768497467041
I0303 17:47:09.629621 139758017697536 logging_writer.py:48] [224400] global_step=224400, grad_norm=3.2008447647094727, loss=1.184105634689331
I0303 17:47:54.778456 139758009304832 logging_writer.py:48] [224500] global_step=224500, grad_norm=2.9194600582122803, loss=1.7634048461914062
I0303 17:48:40.068293 139758017697536 logging_writer.py:48] [224600] global_step=224600, grad_norm=2.923522472381592, loss=1.1055727005004883
I0303 17:49:25.269754 139758009304832 logging_writer.py:48] [224700] global_step=224700, grad_norm=3.5809593200683594, loss=1.18574857711792
I0303 17:50:10.512644 139758017697536 logging_writer.py:48] [224800] global_step=224800, grad_norm=3.2486836910247803, loss=2.5833356380462646
I0303 17:50:55.492526 139758009304832 logging_writer.py:48] [224900] global_step=224900, grad_norm=2.9462292194366455, loss=1.1820127964019775
I0303 17:51:40.514224 139758017697536 logging_writer.py:48] [225000] global_step=225000, grad_norm=3.1502504348754883, loss=1.9837265014648438
I0303 17:52:25.645254 139758009304832 logging_writer.py:48] [225100] global_step=225100, grad_norm=3.052243947982788, loss=1.0254095792770386
I0303 17:52:55.524291 139953291118400 spec.py:321] Evaluating on the training split.
I0303 17:53:06.818140 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 17:53:28.443450 139953291118400 spec.py:349] Evaluating on the test split.
I0303 17:53:30.109579 139953291118400 submission_runner.py:411] Time since start: 107850.29s, 	Step: 225168, 	{'train/accuracy': 0.8888476490974426, 'train/loss': 0.42029598355293274, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 100028.81389117241, 'total_duration': 107850.28579640388, 'accumulated_submission_time': 100028.81389117241, 'accumulated_eval_time': 7796.263030529022, 'accumulated_logging_time': 13.69261384010315}
I0303 17:53:30.162790 139758017697536 logging_writer.py:48] [225168] accumulated_eval_time=7796.263031, accumulated_logging_time=13.692614, accumulated_submission_time=100028.813891, global_step=225168, preemption_count=0, score=100028.813891, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=107850.285796, train/accuracy=0.888848, train/loss=0.420296, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 17:53:43.198228 139758009304832 logging_writer.py:48] [225200] global_step=225200, grad_norm=2.9490420818328857, loss=1.195762038230896
I0303 17:54:24.958274 139758017697536 logging_writer.py:48] [225300] global_step=225300, grad_norm=2.902193307876587, loss=1.46908438205719
I0303 17:55:09.913613 139758009304832 logging_writer.py:48] [225400] global_step=225400, grad_norm=3.0334722995758057, loss=1.2836804389953613
I0303 17:55:54.959102 139758017697536 logging_writer.py:48] [225500] global_step=225500, grad_norm=3.218435049057007, loss=1.0309122800827026
I0303 17:56:40.157031 139758009304832 logging_writer.py:48] [225600] global_step=225600, grad_norm=2.868018627166748, loss=1.6270860433578491
I0303 17:57:24.847274 139758017697536 logging_writer.py:48] [225700] global_step=225700, grad_norm=2.949986219406128, loss=1.2816773653030396
I0303 17:58:09.947499 139758009304832 logging_writer.py:48] [225800] global_step=225800, grad_norm=3.0790209770202637, loss=1.0922966003417969
I0303 17:58:55.017366 139758017697536 logging_writer.py:48] [225900] global_step=225900, grad_norm=3.630815029144287, loss=2.767012119293213
I0303 17:59:39.930828 139758009304832 logging_writer.py:48] [226000] global_step=226000, grad_norm=3.378253221511841, loss=2.824876070022583
I0303 18:00:25.039321 139758017697536 logging_writer.py:48] [226100] global_step=226100, grad_norm=3.6274566650390625, loss=2.815617561340332
I0303 18:00:30.593297 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:00:41.537987 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:01:04.617891 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:01:06.250888 139953291118400 submission_runner.py:411] Time since start: 108306.43s, 	Step: 226114, 	{'train/accuracy': 0.8854687213897705, 'train/loss': 0.4251309037208557, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 100449.1869559288, 'total_duration': 108306.42710208893, 'accumulated_submission_time': 100449.1869559288, 'accumulated_eval_time': 7831.920604705811, 'accumulated_logging_time': 13.755226135253906}
I0303 18:01:06.313418 139758009304832 logging_writer.py:48] [226114] accumulated_eval_time=7831.920605, accumulated_logging_time=13.755226, accumulated_submission_time=100449.186956, global_step=226114, preemption_count=0, score=100449.186956, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=108306.427102, train/accuracy=0.885469, train/loss=0.425131, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:01:40.980996 139758017697536 logging_writer.py:48] [226200] global_step=226200, grad_norm=2.8553292751312256, loss=1.6397192478179932
I0303 18:02:25.863134 139758009304832 logging_writer.py:48] [226300] global_step=226300, grad_norm=3.278885841369629, loss=1.1598440408706665
I0303 18:03:11.240929 139758017697536 logging_writer.py:48] [226400] global_step=226400, grad_norm=3.0806684494018555, loss=1.0825910568237305
I0303 18:03:56.854004 139758009304832 logging_writer.py:48] [226500] global_step=226500, grad_norm=2.981168270111084, loss=1.12617826461792
I0303 18:04:41.878885 139758017697536 logging_writer.py:48] [226600] global_step=226600, grad_norm=3.8064706325531006, loss=3.205667018890381
I0303 18:05:26.786827 139758009304832 logging_writer.py:48] [226700] global_step=226700, grad_norm=3.9354593753814697, loss=3.162038803100586
I0303 18:06:11.978606 139758017697536 logging_writer.py:48] [226800] global_step=226800, grad_norm=3.2299230098724365, loss=2.87090802192688
I0303 18:06:56.923225 139758009304832 logging_writer.py:48] [226900] global_step=226900, grad_norm=3.0171902179718018, loss=1.2197428941726685
I0303 18:07:42.122032 139758017697536 logging_writer.py:48] [227000] global_step=227000, grad_norm=3.7651777267456055, loss=3.235305070877075
I0303 18:08:06.453747 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:08:17.802978 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:08:44.690053 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:08:46.312457 139953291118400 submission_runner.py:411] Time since start: 108766.49s, 	Step: 227056, 	{'train/accuracy': 0.8884961009025574, 'train/loss': 0.41931357979774475, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 100869.26940894127, 'total_duration': 108766.48868989944, 'accumulated_submission_time': 100869.26940894127, 'accumulated_eval_time': 7871.779316186905, 'accumulated_logging_time': 13.82857346534729}
I0303 18:08:46.361765 139758009304832 logging_writer.py:48] [227056] accumulated_eval_time=7871.779316, accumulated_logging_time=13.828573, accumulated_submission_time=100869.269409, global_step=227056, preemption_count=0, score=100869.269409, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=108766.488690, train/accuracy=0.888496, train/loss=0.419314, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:09:04.145308 139758017697536 logging_writer.py:48] [227100] global_step=227100, grad_norm=2.902850389480591, loss=1.7358784675598145
I0303 18:09:46.044717 139758009304832 logging_writer.py:48] [227200] global_step=227200, grad_norm=3.070019483566284, loss=1.2079970836639404
I0303 18:10:30.905672 139758017697536 logging_writer.py:48] [227300] global_step=227300, grad_norm=3.7320258617401123, loss=1.9683252573013306
I0303 18:11:16.210174 139758009304832 logging_writer.py:48] [227400] global_step=227400, grad_norm=3.1221773624420166, loss=1.1807368993759155
I0303 18:12:01.370768 139758017697536 logging_writer.py:48] [227500] global_step=227500, grad_norm=3.4383490085601807, loss=2.63936710357666
I0303 18:12:46.311951 139758009304832 logging_writer.py:48] [227600] global_step=227600, grad_norm=2.787020206451416, loss=1.0864598751068115
I0303 18:13:31.415534 139758017697536 logging_writer.py:48] [227700] global_step=227700, grad_norm=3.3804101943969727, loss=2.9443023204803467
I0303 18:14:16.507357 139758009304832 logging_writer.py:48] [227800] global_step=227800, grad_norm=2.9163742065429688, loss=1.1891340017318726
I0303 18:15:01.237023 139758017697536 logging_writer.py:48] [227900] global_step=227900, grad_norm=2.9470176696777344, loss=1.1708377599716187
I0303 18:15:46.171338 139758009304832 logging_writer.py:48] [228000] global_step=228000, grad_norm=3.3452601432800293, loss=1.1432280540466309
I0303 18:15:46.316033 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:15:57.561886 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:16:16.849323 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:16:18.490911 139953291118400 submission_runner.py:411] Time since start: 109218.67s, 	Step: 228002, 	{'train/accuracy': 0.8871288895606995, 'train/loss': 0.41788092255592346, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 101289.16657400131, 'total_duration': 109218.66709923744, 'accumulated_submission_time': 101289.16657400131, 'accumulated_eval_time': 7903.954140663147, 'accumulated_logging_time': 13.88698935508728}
I0303 18:16:18.560825 139758017697536 logging_writer.py:48] [228002] accumulated_eval_time=7903.954141, accumulated_logging_time=13.886989, accumulated_submission_time=101289.166574, global_step=228002, preemption_count=0, score=101289.166574, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=109218.667099, train/accuracy=0.887129, train/loss=0.417881, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:16:59.188089 139758009304832 logging_writer.py:48] [228100] global_step=228100, grad_norm=3.376864194869995, loss=1.2677137851715088
I0303 18:17:44.086684 139758017697536 logging_writer.py:48] [228200] global_step=228200, grad_norm=3.327287435531616, loss=1.1934345960617065
I0303 18:18:29.076663 139758009304832 logging_writer.py:48] [228300] global_step=228300, grad_norm=3.1379384994506836, loss=1.4032734632492065
I0303 18:19:14.154397 139758017697536 logging_writer.py:48] [228400] global_step=228400, grad_norm=3.013718605041504, loss=1.1329045295715332
I0303 18:19:58.746392 139758009304832 logging_writer.py:48] [228500] global_step=228500, grad_norm=3.0071914196014404, loss=1.1008517742156982
I0303 18:20:43.657758 139758017697536 logging_writer.py:48] [228600] global_step=228600, grad_norm=3.146385908126831, loss=1.4965379238128662
I0303 18:21:28.687812 139758009304832 logging_writer.py:48] [228700] global_step=228700, grad_norm=3.0477874279022217, loss=1.1027612686157227
I0303 18:22:13.712646 139758017697536 logging_writer.py:48] [228800] global_step=228800, grad_norm=3.0069687366485596, loss=1.0219764709472656
I0303 18:22:58.803348 139758009304832 logging_writer.py:48] [228900] global_step=228900, grad_norm=3.911931037902832, loss=3.166743755340576
I0303 18:23:18.565498 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:23:29.709068 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:23:52.696709 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:23:54.345089 139953291118400 submission_runner.py:411] Time since start: 109674.52s, 	Step: 228945, 	{'train/accuracy': 0.8885351419448853, 'train/loss': 0.41260093450546265, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 101709.11290287971, 'total_duration': 109674.52127766609, 'accumulated_submission_time': 101709.11290287971, 'accumulated_eval_time': 7939.73398065567, 'accumulated_logging_time': 13.966781616210938}
I0303 18:23:54.411718 139758017697536 logging_writer.py:48] [228945] accumulated_eval_time=7939.733981, accumulated_logging_time=13.966782, accumulated_submission_time=101709.112903, global_step=228945, preemption_count=0, score=101709.112903, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=109674.521278, train/accuracy=0.888535, train/loss=0.412601, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:24:16.549991 139758009304832 logging_writer.py:48] [229000] global_step=229000, grad_norm=3.082458972930908, loss=1.1249841451644897
I0303 18:25:00.423490 139758017697536 logging_writer.py:48] [229100] global_step=229100, grad_norm=2.848978042602539, loss=1.1714744567871094
I0303 18:25:45.654565 139758009304832 logging_writer.py:48] [229200] global_step=229200, grad_norm=3.27305269241333, loss=2.771150827407837
I0303 18:26:30.581016 139758017697536 logging_writer.py:48] [229300] global_step=229300, grad_norm=3.0639679431915283, loss=1.3972607851028442
I0303 18:27:15.429985 139758009304832 logging_writer.py:48] [229400] global_step=229400, grad_norm=4.438337802886963, loss=2.632526397705078
I0303 18:28:00.440574 139758017697536 logging_writer.py:48] [229500] global_step=229500, grad_norm=3.0714268684387207, loss=1.3416011333465576
I0303 18:28:45.532336 139758009304832 logging_writer.py:48] [229600] global_step=229600, grad_norm=3.044710636138916, loss=1.0531693696975708
I0303 18:29:30.588001 139758017697536 logging_writer.py:48] [229700] global_step=229700, grad_norm=3.0191125869750977, loss=1.0886751413345337
I0303 18:30:15.367568 139758009304832 logging_writer.py:48] [229800] global_step=229800, grad_norm=3.151496648788452, loss=2.1026721000671387
I0303 18:30:54.384662 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:31:05.289956 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:31:35.818794 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:31:37.460480 139953291118400 submission_runner.py:411] Time since start: 110137.64s, 	Step: 229889, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.4152209758758545, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 102129.02837610245, 'total_duration': 110137.63670706749, 'accumulated_submission_time': 102129.02837610245, 'accumulated_eval_time': 7982.809792280197, 'accumulated_logging_time': 14.043018579483032}
I0303 18:31:37.510096 139758017697536 logging_writer.py:48] [229889] accumulated_eval_time=7982.809792, accumulated_logging_time=14.043019, accumulated_submission_time=102129.028376, global_step=229889, preemption_count=0, score=102129.028376, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=110137.636707, train/accuracy=0.888398, train/loss=0.415221, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:31:42.245913 139758009304832 logging_writer.py:48] [229900] global_step=229900, grad_norm=2.975599527359009, loss=1.1694986820220947
I0303 18:32:22.336545 139758017697536 logging_writer.py:48] [230000] global_step=230000, grad_norm=3.3143136501312256, loss=2.2559733390808105
I0303 18:33:07.036083 139758009304832 logging_writer.py:48] [230100] global_step=230100, grad_norm=3.1326260566711426, loss=1.1608281135559082
I0303 18:33:52.455012 139758017697536 logging_writer.py:48] [230200] global_step=230200, grad_norm=3.093705415725708, loss=1.654051423072815
I0303 18:34:37.583889 139758009304832 logging_writer.py:48] [230300] global_step=230300, grad_norm=3.1781623363494873, loss=2.6200265884399414
I0303 18:35:22.188266 139758017697536 logging_writer.py:48] [230400] global_step=230400, grad_norm=3.3801941871643066, loss=1.3314753770828247
I0303 18:36:06.953635 139758009304832 logging_writer.py:48] [230500] global_step=230500, grad_norm=3.4177777767181396, loss=2.948638916015625
I0303 18:36:52.184405 139758017697536 logging_writer.py:48] [230600] global_step=230600, grad_norm=3.221506357192993, loss=1.2419207096099854
I0303 18:37:37.420789 139758009304832 logging_writer.py:48] [230700] global_step=230700, grad_norm=3.1385602951049805, loss=2.276397705078125
I0303 18:38:22.306617 139758017697536 logging_writer.py:48] [230800] global_step=230800, grad_norm=3.181065320968628, loss=1.1989216804504395
I0303 18:38:37.816354 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:38:49.111713 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:39:07.955189 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:39:09.587223 139953291118400 submission_runner.py:411] Time since start: 110589.76s, 	Step: 230836, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.42096811532974243, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 102549.27608656883, 'total_duration': 110589.76342749596, 'accumulated_submission_time': 102549.27608656883, 'accumulated_eval_time': 8014.580620288849, 'accumulated_logging_time': 14.102319240570068}
I0303 18:39:09.648112 139758009304832 logging_writer.py:48] [230836] accumulated_eval_time=8014.580620, accumulated_logging_time=14.102319, accumulated_submission_time=102549.276087, global_step=230836, preemption_count=0, score=102549.276087, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=110589.763427, train/accuracy=0.886738, train/loss=0.420968, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:39:35.360669 139758017697536 logging_writer.py:48] [230900] global_step=230900, grad_norm=3.0280561447143555, loss=1.3260687589645386
I0303 18:40:20.008130 139758009304832 logging_writer.py:48] [231000] global_step=231000, grad_norm=3.0792484283447266, loss=1.2938733100891113
I0303 18:41:04.971775 139758017697536 logging_writer.py:48] [231100] global_step=231100, grad_norm=3.2103099822998047, loss=1.1017494201660156
I0303 18:41:49.869256 139758009304832 logging_writer.py:48] [231200] global_step=231200, grad_norm=3.795271635055542, loss=3.2112245559692383
I0303 18:42:34.817041 139758017697536 logging_writer.py:48] [231300] global_step=231300, grad_norm=3.0324628353118896, loss=1.924148440361023
I0303 18:43:19.926683 139758009304832 logging_writer.py:48] [231400] global_step=231400, grad_norm=3.2927064895629883, loss=2.5378048419952393
I0303 18:44:05.208968 139758017697536 logging_writer.py:48] [231500] global_step=231500, grad_norm=2.860002040863037, loss=1.2494661808013916
I0303 18:44:50.152716 139758009304832 logging_writer.py:48] [231600] global_step=231600, grad_norm=3.300762891769409, loss=1.1160300970077515
I0303 18:45:35.138858 139758017697536 logging_writer.py:48] [231700] global_step=231700, grad_norm=2.94435977935791, loss=1.0534212589263916
I0303 18:46:09.803331 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:46:21.482186 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:46:46.784595 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:46:48.421636 139953291118400 submission_runner.py:411] Time since start: 111048.60s, 	Step: 231779, 	{'train/accuracy': 0.8880859017372131, 'train/loss': 0.424091637134552, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 102969.37177467346, 'total_duration': 111048.59785699844, 'accumulated_submission_time': 102969.37177467346, 'accumulated_eval_time': 8053.198905706406, 'accumulated_logging_time': 14.175431966781616}
I0303 18:46:48.487596 139758009304832 logging_writer.py:48] [231779] accumulated_eval_time=8053.198906, accumulated_logging_time=14.175432, accumulated_submission_time=102969.371775, global_step=231779, preemption_count=0, score=102969.371775, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=111048.597857, train/accuracy=0.888086, train/loss=0.424092, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:46:57.199666 139758017697536 logging_writer.py:48] [231800] global_step=231800, grad_norm=3.285977363586426, loss=1.2077516317367554
I0303 18:47:38.945283 139758009304832 logging_writer.py:48] [231900] global_step=231900, grad_norm=3.2419729232788086, loss=2.2807414531707764
I0303 18:48:23.785812 139758017697536 logging_writer.py:48] [232000] global_step=232000, grad_norm=2.9054148197174072, loss=1.1663167476654053
I0303 18:49:08.512302 139758009304832 logging_writer.py:48] [232100] global_step=232100, grad_norm=3.119873285293579, loss=2.2581682205200195
I0303 18:49:53.302946 139758017697536 logging_writer.py:48] [232200] global_step=232200, grad_norm=3.3694956302642822, loss=1.08811616897583
I0303 18:50:37.934771 139758009304832 logging_writer.py:48] [232300] global_step=232300, grad_norm=2.9731128215789795, loss=1.4644486904144287
I0303 18:51:22.802557 139758017697536 logging_writer.py:48] [232400] global_step=232400, grad_norm=3.169053554534912, loss=1.1343305110931396
I0303 18:52:07.596367 139758009304832 logging_writer.py:48] [232500] global_step=232500, grad_norm=3.4902219772338867, loss=2.9444520473480225
I0303 18:52:52.349512 139758017697536 logging_writer.py:48] [232600] global_step=232600, grad_norm=3.068077802658081, loss=2.175081253051758
I0303 18:53:37.403491 139758009304832 logging_writer.py:48] [232700] global_step=232700, grad_norm=3.0008022785186768, loss=1.0630648136138916
I0303 18:53:48.450784 139953291118400 spec.py:321] Evaluating on the training split.
I0303 18:53:59.371708 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 18:54:24.319383 139953291118400 spec.py:349] Evaluating on the test split.
I0303 18:54:25.981607 139953291118400 submission_runner.py:411] Time since start: 111506.16s, 	Step: 232726, 	{'train/accuracy': 0.8880859017372131, 'train/loss': 0.4161204695701599, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 103389.27419066429, 'total_duration': 111506.15778017044, 'accumulated_submission_time': 103389.27419066429, 'accumulated_eval_time': 8090.729656934738, 'accumulated_logging_time': 14.253586530685425}
I0303 18:54:26.076560 139758017697536 logging_writer.py:48] [232726] accumulated_eval_time=8090.729657, accumulated_logging_time=14.253587, accumulated_submission_time=103389.274191, global_step=232726, preemption_count=0, score=103389.274191, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=111506.157780, train/accuracy=0.888086, train/loss=0.416120, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 18:54:55.705803 139758009304832 logging_writer.py:48] [232800] global_step=232800, grad_norm=3.1932008266448975, loss=1.537629246711731
I0303 18:55:39.632034 139758017697536 logging_writer.py:48] [232900] global_step=232900, grad_norm=3.216580867767334, loss=1.2499943971633911
I0303 18:56:24.897535 139758009304832 logging_writer.py:48] [233000] global_step=233000, grad_norm=3.3098533153533936, loss=1.734838843345642
I0303 18:57:10.153403 139758017697536 logging_writer.py:48] [233100] global_step=233100, grad_norm=3.8413007259368896, loss=2.932812213897705
I0303 18:57:54.996287 139758009304832 logging_writer.py:48] [233200] global_step=233200, grad_norm=3.3156681060791016, loss=1.0378998517990112
I0303 18:58:39.891273 139758017697536 logging_writer.py:48] [233300] global_step=233300, grad_norm=2.9599502086639404, loss=1.1014735698699951
I0303 18:59:25.190826 139758009304832 logging_writer.py:48] [233400] global_step=233400, grad_norm=2.898374080657959, loss=1.1394562721252441
I0303 19:00:09.973047 139758017697536 logging_writer.py:48] [233500] global_step=233500, grad_norm=3.143341302871704, loss=1.1284799575805664
I0303 19:00:54.843422 139758009304832 logging_writer.py:48] [233600] global_step=233600, grad_norm=3.2214462757110596, loss=1.1744253635406494
I0303 19:01:26.043978 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:01:37.169139 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:02:03.860871 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:02:05.490137 139953291118400 submission_runner.py:411] Time since start: 111965.67s, 	Step: 233671, 	{'train/accuracy': 0.889941394329071, 'train/loss': 0.4111701250076294, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 103809.17875909805, 'total_duration': 111965.66636037827, 'accumulated_submission_time': 103809.17875909805, 'accumulated_eval_time': 8130.175797224045, 'accumulated_logging_time': 14.363630533218384}
I0303 19:02:05.557427 139758017697536 logging_writer.py:48] [233671] accumulated_eval_time=8130.175797, accumulated_logging_time=14.363631, accumulated_submission_time=103809.178759, global_step=233671, preemption_count=0, score=103809.178759, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=111965.666360, train/accuracy=0.889941, train/loss=0.411170, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:02:17.401980 139758009304832 logging_writer.py:48] [233700] global_step=233700, grad_norm=3.329458713531494, loss=1.1852707862854004
I0303 19:02:59.431732 139758017697536 logging_writer.py:48] [233800] global_step=233800, grad_norm=3.8494956493377686, loss=3.2026760578155518
I0303 19:03:44.335667 139758009304832 logging_writer.py:48] [233900] global_step=233900, grad_norm=3.0317723751068115, loss=1.1075620651245117
I0303 19:04:29.640956 139758017697536 logging_writer.py:48] [234000] global_step=234000, grad_norm=2.9652509689331055, loss=1.119512677192688
I0303 19:05:14.450489 139758009304832 logging_writer.py:48] [234100] global_step=234100, grad_norm=3.1755425930023193, loss=1.0934971570968628
I0303 19:05:59.747343 139758017697536 logging_writer.py:48] [234200] global_step=234200, grad_norm=2.844669818878174, loss=1.013838768005371
I0303 19:06:44.859879 139758009304832 logging_writer.py:48] [234300] global_step=234300, grad_norm=3.076160192489624, loss=1.1971726417541504
I0303 19:07:29.682392 139758017697536 logging_writer.py:48] [234400] global_step=234400, grad_norm=3.4967031478881836, loss=1.3061408996582031
I0303 19:08:14.911839 139758009304832 logging_writer.py:48] [234500] global_step=234500, grad_norm=3.1028761863708496, loss=1.138122797012329
I0303 19:08:59.640139 139758017697536 logging_writer.py:48] [234600] global_step=234600, grad_norm=2.9810550212860107, loss=1.3216009140014648
I0303 19:09:05.883486 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:09:17.006242 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:09:38.459658 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:09:40.097469 139953291118400 submission_runner.py:411] Time since start: 112420.27s, 	Step: 234615, 	{'train/accuracy': 0.8862109184265137, 'train/loss': 0.4182306230068207, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 104229.44356608391, 'total_duration': 112420.273696661, 'accumulated_submission_time': 104229.44356608391, 'accumulated_eval_time': 8164.389766454697, 'accumulated_logging_time': 14.44425344467163}
I0303 19:09:40.162249 139758009304832 logging_writer.py:48] [234615] accumulated_eval_time=8164.389766, accumulated_logging_time=14.444253, accumulated_submission_time=104229.443566, global_step=234615, preemption_count=0, score=104229.443566, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=112420.273697, train/accuracy=0.886211, train/loss=0.418231, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:10:14.872064 139758017697536 logging_writer.py:48] [234700] global_step=234700, grad_norm=3.9471373558044434, loss=2.9431941509246826
I0303 19:10:59.429953 139758009304832 logging_writer.py:48] [234800] global_step=234800, grad_norm=3.107274293899536, loss=1.2687437534332275
I0303 19:11:44.153573 139758017697536 logging_writer.py:48] [234900] global_step=234900, grad_norm=3.02846360206604, loss=1.1812388896942139
I0303 19:12:29.203395 139758009304832 logging_writer.py:48] [235000] global_step=235000, grad_norm=3.1759023666381836, loss=1.1879109144210815
I0303 19:13:14.042143 139758017697536 logging_writer.py:48] [235100] global_step=235100, grad_norm=3.215170383453369, loss=1.108866810798645
I0303 19:13:59.165889 139758009304832 logging_writer.py:48] [235200] global_step=235200, grad_norm=3.9002552032470703, loss=3.0902023315429688
I0303 19:14:43.975723 139758017697536 logging_writer.py:48] [235300] global_step=235300, grad_norm=2.7968900203704834, loss=1.410946011543274
I0303 19:15:29.007061 139758009304832 logging_writer.py:48] [235400] global_step=235400, grad_norm=3.1892552375793457, loss=2.1798095703125
I0303 19:16:13.894015 139758017697536 logging_writer.py:48] [235500] global_step=235500, grad_norm=3.1329994201660156, loss=1.2354393005371094
I0303 19:16:40.115916 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:16:52.064983 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:17:21.494860 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:17:23.125744 139953291118400 submission_runner.py:411] Time since start: 112883.30s, 	Step: 235560, 	{'train/accuracy': 0.8863866925239563, 'train/loss': 0.4218202233314514, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 104649.33818554878, 'total_duration': 112883.30195975304, 'accumulated_submission_time': 104649.33818554878, 'accumulated_eval_time': 8207.39955830574, 'accumulated_logging_time': 14.519267797470093}
I0303 19:17:23.189940 139758009304832 logging_writer.py:48] [235560] accumulated_eval_time=8207.399558, accumulated_logging_time=14.519268, accumulated_submission_time=104649.338186, global_step=235560, preemption_count=0, score=104649.338186, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=112883.301960, train/accuracy=0.886387, train/loss=0.421820, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:17:39.408313 139758017697536 logging_writer.py:48] [235600] global_step=235600, grad_norm=3.495166063308716, loss=1.9133917093276978
I0303 19:18:21.357921 139758009304832 logging_writer.py:48] [235700] global_step=235700, grad_norm=2.9279017448425293, loss=0.9280703663825989
I0303 19:19:06.181007 139758017697536 logging_writer.py:48] [235800] global_step=235800, grad_norm=3.083918571472168, loss=1.13756263256073
I0303 19:19:51.128312 139758009304832 logging_writer.py:48] [235900] global_step=235900, grad_norm=3.1465365886688232, loss=1.1956216096878052
I0303 19:20:36.275357 139758017697536 logging_writer.py:48] [236000] global_step=236000, grad_norm=2.980649948120117, loss=1.350750207901001
I0303 19:21:21.113647 139758009304832 logging_writer.py:48] [236100] global_step=236100, grad_norm=3.6545889377593994, loss=2.447378158569336
I0303 19:22:06.087504 139758017697536 logging_writer.py:48] [236200] global_step=236200, grad_norm=3.4717001914978027, loss=2.844083786010742
I0303 19:22:51.031208 139758009304832 logging_writer.py:48] [236300] global_step=236300, grad_norm=2.9608154296875, loss=1.5837516784667969
I0303 19:23:35.914536 139758017697536 logging_writer.py:48] [236400] global_step=236400, grad_norm=3.274651288986206, loss=1.1867098808288574
I0303 19:24:21.068535 139758009304832 logging_writer.py:48] [236500] global_step=236500, grad_norm=3.1455960273742676, loss=1.098124623298645
I0303 19:24:23.487122 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:24:34.454613 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:25:01.111544 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:25:02.734619 139953291118400 submission_runner.py:411] Time since start: 113342.91s, 	Step: 236507, 	{'train/accuracy': 0.8854101300239563, 'train/loss': 0.4208202362060547, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 105069.57685279846, 'total_duration': 113342.91085219383, 'accumulated_submission_time': 105069.57685279846, 'accumulated_eval_time': 8246.647035121918, 'accumulated_logging_time': 14.593485116958618}
I0303 19:25:02.787086 139758017697536 logging_writer.py:48] [236507] accumulated_eval_time=8246.647035, accumulated_logging_time=14.593485, accumulated_submission_time=105069.576853, global_step=236507, preemption_count=0, score=105069.576853, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=113342.910852, train/accuracy=0.885410, train/loss=0.420820, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:25:39.877578 139758009304832 logging_writer.py:48] [236600] global_step=236600, grad_norm=2.9158473014831543, loss=2.4585530757904053
I0303 19:26:24.848151 139758017697536 logging_writer.py:48] [236700] global_step=236700, grad_norm=2.916929006576538, loss=1.4312243461608887
I0303 19:27:09.798712 139758009304832 logging_writer.py:48] [236800] global_step=236800, grad_norm=3.659853935241699, loss=3.012772798538208
I0303 19:27:54.929530 139758017697536 logging_writer.py:48] [236900] global_step=236900, grad_norm=3.2490108013153076, loss=2.3081166744232178
I0303 19:28:39.903796 139758009304832 logging_writer.py:48] [237000] global_step=237000, grad_norm=3.2807788848876953, loss=2.572660446166992
I0303 19:29:24.844321 139758017697536 logging_writer.py:48] [237100] global_step=237100, grad_norm=3.3856587409973145, loss=2.035719394683838
I0303 19:30:09.752954 139758009304832 logging_writer.py:48] [237200] global_step=237200, grad_norm=3.852360248565674, loss=3.349821090698242
I0303 19:30:54.723980 139758017697536 logging_writer.py:48] [237300] global_step=237300, grad_norm=3.39987850189209, loss=1.1703294515609741
I0303 19:31:39.932109 139758009304832 logging_writer.py:48] [237400] global_step=237400, grad_norm=3.8998522758483887, loss=3.2987349033355713
I0303 19:32:03.045024 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:32:14.145062 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:32:34.713604 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:32:36.349049 139953291118400 submission_runner.py:411] Time since start: 113796.53s, 	Step: 237453, 	{'train/accuracy': 0.8888476490974426, 'train/loss': 0.41301271319389343, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 105489.77764558792, 'total_duration': 113796.5252687931, 'accumulated_submission_time': 105489.77764558792, 'accumulated_eval_time': 8279.95104432106, 'accumulated_logging_time': 14.655708074569702}
I0303 19:32:36.415250 139758017697536 logging_writer.py:48] [237453] accumulated_eval_time=8279.951044, accumulated_logging_time=14.655708, accumulated_submission_time=105489.777646, global_step=237453, preemption_count=0, score=105489.777646, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=113796.525269, train/accuracy=0.888848, train/loss=0.413013, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:32:55.384518 139758009304832 logging_writer.py:48] [237500] global_step=237500, grad_norm=2.8852884769439697, loss=1.3763840198516846
I0303 19:33:39.082949 139758017697536 logging_writer.py:48] [237600] global_step=237600, grad_norm=2.8172895908355713, loss=1.0035581588745117
I0303 19:34:24.285486 139758009304832 logging_writer.py:48] [237700] global_step=237700, grad_norm=3.118558168411255, loss=1.1028714179992676
I0303 19:35:09.183482 139758017697536 logging_writer.py:48] [237800] global_step=237800, grad_norm=3.356497049331665, loss=1.4966260194778442
I0303 19:35:54.029283 139758009304832 logging_writer.py:48] [237900] global_step=237900, grad_norm=3.159127712249756, loss=1.8984391689300537
I0303 19:36:39.031059 139758017697536 logging_writer.py:48] [238000] global_step=238000, grad_norm=3.1096320152282715, loss=1.2427409887313843
I0303 19:37:24.002253 139758009304832 logging_writer.py:48] [238100] global_step=238100, grad_norm=3.002903938293457, loss=1.0897178649902344
I0303 19:38:08.745725 139758017697536 logging_writer.py:48] [238200] global_step=238200, grad_norm=2.8648667335510254, loss=1.1070060729980469
I0303 19:38:53.541574 139758009304832 logging_writer.py:48] [238300] global_step=238300, grad_norm=2.9880006313323975, loss=1.334245204925537
I0303 19:39:36.473629 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:39:47.826751 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:40:10.745501 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:40:12.381576 139953291118400 submission_runner.py:411] Time since start: 114252.56s, 	Step: 238397, 	{'train/accuracy': 0.8869140148162842, 'train/loss': 0.4204769432544708, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 105909.77715063095, 'total_duration': 114252.5577852726, 'accumulated_submission_time': 105909.77715063095, 'accumulated_eval_time': 8315.858958244324, 'accumulated_logging_time': 14.733111381530762}
I0303 19:40:12.444238 139758017697536 logging_writer.py:48] [238397] accumulated_eval_time=8315.858958, accumulated_logging_time=14.733111, accumulated_submission_time=105909.777151, global_step=238397, preemption_count=0, score=105909.777151, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=114252.557785, train/accuracy=0.886914, train/loss=0.420477, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:40:14.051924 139758009304832 logging_writer.py:48] [238400] global_step=238400, grad_norm=3.4111602306365967, loss=2.8151004314422607
I0303 19:40:55.128553 139758017697536 logging_writer.py:48] [238500] global_step=238500, grad_norm=3.854051351547241, loss=3.225574493408203
I0303 19:41:39.689010 139758009304832 logging_writer.py:48] [238600] global_step=238600, grad_norm=3.253815174102783, loss=2.360107898712158
I0303 19:42:24.534276 139758017697536 logging_writer.py:48] [238700] global_step=238700, grad_norm=3.1533522605895996, loss=1.3040761947631836
I0303 19:43:09.537479 139758009304832 logging_writer.py:48] [238800] global_step=238800, grad_norm=3.248558521270752, loss=2.378614902496338
I0303 19:43:54.180352 139758017697536 logging_writer.py:48] [238900] global_step=238900, grad_norm=3.365391492843628, loss=1.6099928617477417
I0303 19:44:39.621603 139758009304832 logging_writer.py:48] [239000] global_step=239000, grad_norm=3.5015158653259277, loss=2.878791332244873
I0303 19:45:24.679599 139758017697536 logging_writer.py:48] [239100] global_step=239100, grad_norm=2.9119136333465576, loss=1.5964863300323486
I0303 19:46:09.654765 139758009304832 logging_writer.py:48] [239200] global_step=239200, grad_norm=3.061596393585205, loss=1.1144744157791138
I0303 19:46:54.650150 139758017697536 logging_writer.py:48] [239300] global_step=239300, grad_norm=3.1227283477783203, loss=2.1426663398742676
I0303 19:47:12.422163 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:47:23.309835 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:47:51.408101 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:47:53.045040 139953291118400 submission_runner.py:411] Time since start: 114713.22s, 	Step: 239341, 	{'train/accuracy': 0.8874022960662842, 'train/loss': 0.4200328290462494, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 106329.69542336464, 'total_duration': 114713.22124695778, 'accumulated_submission_time': 106329.69542336464, 'accumulated_eval_time': 8356.481803894043, 'accumulated_logging_time': 14.807372331619263}
I0303 19:47:53.111934 139758009304832 logging_writer.py:48] [239341] accumulated_eval_time=8356.481804, accumulated_logging_time=14.807372, accumulated_submission_time=106329.695423, global_step=239341, preemption_count=0, score=106329.695423, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=114713.221247, train/accuracy=0.887402, train/loss=0.420033, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:48:16.790378 139758017697536 logging_writer.py:48] [239400] global_step=239400, grad_norm=3.2626709938049316, loss=2.0346741676330566
I0303 19:49:00.295627 139758009304832 logging_writer.py:48] [239500] global_step=239500, grad_norm=3.0121099948883057, loss=1.1439921855926514
I0303 19:49:45.129379 139758017697536 logging_writer.py:48] [239600] global_step=239600, grad_norm=3.1291332244873047, loss=2.1362597942352295
I0303 19:50:30.497276 139758009304832 logging_writer.py:48] [239700] global_step=239700, grad_norm=4.143274784088135, loss=3.2880029678344727
I0303 19:51:15.207975 139758017697536 logging_writer.py:48] [239800] global_step=239800, grad_norm=3.211899757385254, loss=1.1775400638580322
I0303 19:52:00.110364 139758009304832 logging_writer.py:48] [239900] global_step=239900, grad_norm=3.9560091495513916, loss=3.233097791671753
I0303 19:52:44.963250 139758017697536 logging_writer.py:48] [240000] global_step=240000, grad_norm=3.0042614936828613, loss=1.5934637784957886
I0303 19:53:29.700285 139758009304832 logging_writer.py:48] [240100] global_step=240100, grad_norm=2.9215657711029053, loss=1.0776116847991943
I0303 19:54:14.671066 139758017697536 logging_writer.py:48] [240200] global_step=240200, grad_norm=3.7953202724456787, loss=3.2540018558502197
I0303 19:54:53.208107 139953291118400 spec.py:321] Evaluating on the training split.
I0303 19:55:04.407530 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 19:55:26.513858 139953291118400 spec.py:349] Evaluating on the test split.
I0303 19:55:28.169294 139953291118400 submission_runner.py:411] Time since start: 115168.35s, 	Step: 240287, 	{'train/accuracy': 0.8852929472923279, 'train/loss': 0.4266456067562103, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 106749.73273301125, 'total_duration': 115168.345505476, 'accumulated_submission_time': 106749.73273301125, 'accumulated_eval_time': 8391.442966938019, 'accumulated_logging_time': 14.885765552520752}
I0303 19:55:28.231709 139758009304832 logging_writer.py:48] [240287] accumulated_eval_time=8391.442967, accumulated_logging_time=14.885766, accumulated_submission_time=106749.732733, global_step=240287, preemption_count=0, score=106749.732733, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=115168.345505, train/accuracy=0.885293, train/loss=0.426646, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 19:55:33.765708 139758017697536 logging_writer.py:48] [240300] global_step=240300, grad_norm=3.6216633319854736, loss=2.9141499996185303
I0303 19:56:14.299402 139758009304832 logging_writer.py:48] [240400] global_step=240400, grad_norm=3.657761812210083, loss=1.252210021018982
I0303 19:56:59.106839 139758017697536 logging_writer.py:48] [240500] global_step=240500, grad_norm=3.136044502258301, loss=2.357362985610962
I0303 19:57:44.219493 139758009304832 logging_writer.py:48] [240600] global_step=240600, grad_norm=3.2399792671203613, loss=1.1101688146591187
I0303 19:58:29.691495 139758017697536 logging_writer.py:48] [240700] global_step=240700, grad_norm=3.6006152629852295, loss=3.1961114406585693
I0303 19:59:14.612668 139758009304832 logging_writer.py:48] [240800] global_step=240800, grad_norm=3.04502534866333, loss=2.2294769287109375
I0303 19:59:59.395710 139758017697536 logging_writer.py:48] [240900] global_step=240900, grad_norm=3.4335453510284424, loss=1.1996173858642578
I0303 20:00:44.356173 139758009304832 logging_writer.py:48] [241000] global_step=241000, grad_norm=3.0569779872894287, loss=1.7539315223693848
I0303 20:01:29.426265 139758017697536 logging_writer.py:48] [241100] global_step=241100, grad_norm=3.8138623237609863, loss=3.1755363941192627
I0303 20:02:14.358731 139758009304832 logging_writer.py:48] [241200] global_step=241200, grad_norm=3.0690665245056152, loss=1.111795425415039
I0303 20:02:28.460711 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:02:39.459648 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:03:00.952036 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:03:02.587598 139953291118400 submission_runner.py:411] Time since start: 115622.76s, 	Step: 241233, 	{'train/accuracy': 0.8872656226158142, 'train/loss': 0.42016327381134033, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 107169.90454864502, 'total_duration': 115622.76381874084, 'accumulated_submission_time': 107169.90454864502, 'accumulated_eval_time': 8425.569839000702, 'accumulated_logging_time': 14.957653284072876}
I0303 20:03:02.655241 139758017697536 logging_writer.py:48] [241233] accumulated_eval_time=8425.569839, accumulated_logging_time=14.957653, accumulated_submission_time=107169.904549, global_step=241233, preemption_count=0, score=107169.904549, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=115622.763819, train/accuracy=0.887266, train/loss=0.420163, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:03:29.491703 139758009304832 logging_writer.py:48] [241300] global_step=241300, grad_norm=3.31172251701355, loss=1.21620512008667
I0303 20:04:13.689560 139758017697536 logging_writer.py:48] [241400] global_step=241400, grad_norm=3.1332316398620605, loss=1.9904277324676514
I0303 20:04:58.851862 139758009304832 logging_writer.py:48] [241500] global_step=241500, grad_norm=3.1378536224365234, loss=1.1625560522079468
I0303 20:05:44.019564 139758017697536 logging_writer.py:48] [241600] global_step=241600, grad_norm=3.220862627029419, loss=1.146162986755371
I0303 20:06:28.954800 139758009304832 logging_writer.py:48] [241700] global_step=241700, grad_norm=3.0948503017425537, loss=1.2612686157226562
I0303 20:07:13.856544 139758017697536 logging_writer.py:48] [241800] global_step=241800, grad_norm=3.1306447982788086, loss=1.3660306930541992
I0303 20:07:58.865128 139758009304832 logging_writer.py:48] [241900] global_step=241900, grad_norm=5.725975036621094, loss=1.137800931930542
I0303 20:08:43.883760 139758017697536 logging_writer.py:48] [242000] global_step=242000, grad_norm=2.9956603050231934, loss=1.178654670715332
I0303 20:09:28.635617 139758009304832 logging_writer.py:48] [242100] global_step=242100, grad_norm=3.4712727069854736, loss=1.1160062551498413
I0303 20:10:02.972535 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:10:14.049720 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:10:40.578813 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:10:42.215329 139953291118400 submission_runner.py:411] Time since start: 116082.39s, 	Step: 242178, 	{'train/accuracy': 0.887988269329071, 'train/loss': 0.4175548553466797, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 107590.16424393654, 'total_duration': 116082.39153313637, 'accumulated_submission_time': 107590.16424393654, 'accumulated_eval_time': 8464.812617301941, 'accumulated_logging_time': 15.034671306610107}
I0303 20:10:42.281246 139758017697536 logging_writer.py:48] [242178] accumulated_eval_time=8464.812617, accumulated_logging_time=15.034671, accumulated_submission_time=107590.164244, global_step=242178, preemption_count=0, score=107590.164244, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=116082.391533, train/accuracy=0.887988, train/loss=0.417555, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:10:51.366111 139758009304832 logging_writer.py:48] [242200] global_step=242200, grad_norm=3.2404656410217285, loss=1.0692204236984253
I0303 20:11:32.955210 139758017697536 logging_writer.py:48] [242300] global_step=242300, grad_norm=3.1548104286193848, loss=1.1699334383010864
I0303 20:12:17.930473 139758009304832 logging_writer.py:48] [242400] global_step=242400, grad_norm=3.157010078430176, loss=1.1083309650421143
I0303 20:13:03.258136 139758017697536 logging_writer.py:48] [242500] global_step=242500, grad_norm=3.819502592086792, loss=1.2822084426879883
I0303 20:13:48.426294 139758009304832 logging_writer.py:48] [242600] global_step=242600, grad_norm=3.2679555416107178, loss=2.4853034019470215
I0303 20:14:33.358602 139758017697536 logging_writer.py:48] [242700] global_step=242700, grad_norm=3.2612431049346924, loss=1.044463872909546
I0303 20:15:18.774378 139758009304832 logging_writer.py:48] [242800] global_step=242800, grad_norm=3.008427381515503, loss=1.8629655838012695
I0303 20:16:04.101455 139758017697536 logging_writer.py:48] [242900] global_step=242900, grad_norm=4.232025623321533, loss=3.291584014892578
I0303 20:16:49.029187 139758009304832 logging_writer.py:48] [243000] global_step=243000, grad_norm=3.529820442199707, loss=2.8759641647338867
I0303 20:17:34.156461 139758017697536 logging_writer.py:48] [243100] global_step=243100, grad_norm=2.821796178817749, loss=1.4642101526260376
I0303 20:17:42.408287 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:17:53.468587 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:18:23.876136 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:18:25.520586 139953291118400 submission_runner.py:411] Time since start: 116545.70s, 	Step: 243120, 	{'train/accuracy': 0.8871093392372131, 'train/loss': 0.4164575934410095, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 108010.23139071465, 'total_duration': 116545.69679760933, 'accumulated_submission_time': 108010.23139071465, 'accumulated_eval_time': 8507.924887418747, 'accumulated_logging_time': 15.112300157546997}
I0303 20:18:25.572981 139758009304832 logging_writer.py:48] [243120] accumulated_eval_time=8507.924887, accumulated_logging_time=15.112300, accumulated_submission_time=108010.231391, global_step=243120, preemption_count=0, score=108010.231391, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=116545.696798, train/accuracy=0.887109, train/loss=0.416458, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:18:57.524761 139758017697536 logging_writer.py:48] [243200] global_step=243200, grad_norm=2.9996232986450195, loss=1.2076151371002197
I0303 20:19:41.305502 139758009304832 logging_writer.py:48] [243300] global_step=243300, grad_norm=3.779038667678833, loss=3.289259910583496
I0303 20:20:26.526169 139758017697536 logging_writer.py:48] [243400] global_step=243400, grad_norm=2.8681206703186035, loss=1.1454896926879883
I0303 20:21:11.882143 139758009304832 logging_writer.py:48] [243500] global_step=243500, grad_norm=3.037592887878418, loss=2.6027421951293945
I0303 20:21:56.636697 139758017697536 logging_writer.py:48] [243600] global_step=243600, grad_norm=2.8502707481384277, loss=2.2267065048217773
I0303 20:22:42.793454 139758009304832 logging_writer.py:48] [243700] global_step=243700, grad_norm=3.1194183826446533, loss=2.2211506366729736
I0303 20:23:28.201792 139758017697536 logging_writer.py:48] [243800] global_step=243800, grad_norm=3.1887543201446533, loss=1.1826140880584717
I0303 20:24:13.527203 139758009304832 logging_writer.py:48] [243900] global_step=243900, grad_norm=3.2338125705718994, loss=1.2723733186721802
I0303 20:24:58.732758 139758017697536 logging_writer.py:48] [244000] global_step=244000, grad_norm=3.1180927753448486, loss=1.9131441116333008
I0303 20:25:25.623236 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:25:37.250844 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:25:57.811413 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:25:59.443354 139953291118400 submission_runner.py:411] Time since start: 116999.62s, 	Step: 244061, 	{'train/accuracy': 0.8856835961341858, 'train/loss': 0.4228624999523163, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 108430.22557520866, 'total_duration': 116999.61957454681, 'accumulated_submission_time': 108430.22557520866, 'accumulated_eval_time': 8541.744990348816, 'accumulated_logging_time': 15.172938346862793}
I0303 20:25:59.513629 139758009304832 logging_writer.py:48] [244061] accumulated_eval_time=8541.744990, accumulated_logging_time=15.172938, accumulated_submission_time=108430.225575, global_step=244061, preemption_count=0, score=108430.225575, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=116999.619575, train/accuracy=0.885684, train/loss=0.422862, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:26:15.308020 139758017697536 logging_writer.py:48] [244100] global_step=244100, grad_norm=3.0727603435516357, loss=1.5129297971725464
I0303 20:26:58.283977 139758009304832 logging_writer.py:48] [244200] global_step=244200, grad_norm=3.6106390953063965, loss=2.6029300689697266
I0303 20:27:43.071510 139758017697536 logging_writer.py:48] [244300] global_step=244300, grad_norm=3.02777361869812, loss=2.144820213317871
I0303 20:28:27.770294 139758009304832 logging_writer.py:48] [244400] global_step=244400, grad_norm=3.420989990234375, loss=3.0204885005950928
I0303 20:29:12.604940 139758017697536 logging_writer.py:48] [244500] global_step=244500, grad_norm=2.883627414703369, loss=2.234820604324341
I0303 20:29:57.286504 139758009304832 logging_writer.py:48] [244600] global_step=244600, grad_norm=3.186551570892334, loss=1.166535496711731
I0303 20:30:42.541643 139758017697536 logging_writer.py:48] [244700] global_step=244700, grad_norm=3.0093472003936768, loss=1.719570279121399
I0303 20:31:27.364396 139758009304832 logging_writer.py:48] [244800] global_step=244800, grad_norm=2.897230386734009, loss=2.186134099960327
I0303 20:32:12.251425 139758017697536 logging_writer.py:48] [244900] global_step=244900, grad_norm=2.9364359378814697, loss=1.1140769720077515
I0303 20:32:57.034104 139758009304832 logging_writer.py:48] [245000] global_step=245000, grad_norm=3.0238828659057617, loss=1.2067468166351318
I0303 20:32:59.829739 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:33:11.363785 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:33:38.543111 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:33:40.160906 139953291118400 submission_runner.py:411] Time since start: 117460.34s, 	Step: 245008, 	{'train/accuracy': 0.8870702981948853, 'train/loss': 0.41824817657470703, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 108850.48312044144, 'total_duration': 117460.33714318275, 'accumulated_submission_time': 108850.48312044144, 'accumulated_eval_time': 8582.07614517212, 'accumulated_logging_time': 15.252984046936035}
I0303 20:33:40.216730 139758017697536 logging_writer.py:48] [245008] accumulated_eval_time=8582.076145, accumulated_logging_time=15.252984, accumulated_submission_time=108850.483120, global_step=245008, preemption_count=0, score=108850.483120, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=117460.337143, train/accuracy=0.887070, train/loss=0.418248, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:34:16.953791 139758009304832 logging_writer.py:48] [245100] global_step=245100, grad_norm=3.732736825942993, loss=2.9691083431243896
I0303 20:35:01.775842 139758017697536 logging_writer.py:48] [245200] global_step=245200, grad_norm=2.8490047454833984, loss=1.764526128768921
I0303 20:35:47.487416 139758009304832 logging_writer.py:48] [245300] global_step=245300, grad_norm=3.0045790672302246, loss=1.4057345390319824
I0303 20:36:33.295045 139758017697536 logging_writer.py:48] [245400] global_step=245400, grad_norm=3.2426648139953613, loss=1.1253081560134888
I0303 20:37:18.273790 139758009304832 logging_writer.py:48] [245500] global_step=245500, grad_norm=3.079374074935913, loss=1.0842236280441284
I0303 20:38:03.264405 139758017697536 logging_writer.py:48] [245600] global_step=245600, grad_norm=3.101228713989258, loss=1.1489778757095337
I0303 20:38:48.459350 139758009304832 logging_writer.py:48] [245700] global_step=245700, grad_norm=3.189589023590088, loss=1.1373965740203857
I0303 20:39:33.180113 139758017697536 logging_writer.py:48] [245800] global_step=245800, grad_norm=3.7292044162750244, loss=3.154550075531006
I0303 20:40:18.151971 139758009304832 logging_writer.py:48] [245900] global_step=245900, grad_norm=2.942415237426758, loss=1.0674362182617188
I0303 20:40:40.250897 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:40:51.152252 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:41:20.049663 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:41:21.677637 139953291118400 submission_runner.py:411] Time since start: 117921.85s, 	Step: 245951, 	{'train/accuracy': 0.8870898485183716, 'train/loss': 0.42040500044822693, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 109270.4581296444, 'total_duration': 117921.85386919975, 'accumulated_submission_time': 109270.4581296444, 'accumulated_eval_time': 8623.50287437439, 'accumulated_logging_time': 15.32018232345581}
I0303 20:41:21.733509 139758017697536 logging_writer.py:48] [245951] accumulated_eval_time=8623.502874, accumulated_logging_time=15.320182, accumulated_submission_time=109270.458130, global_step=245951, preemption_count=0, score=109270.458130, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=117921.853869, train/accuracy=0.887090, train/loss=0.420405, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:41:41.461176 139758009304832 logging_writer.py:48] [246000] global_step=246000, grad_norm=3.2255804538726807, loss=1.554579257965088
I0303 20:42:23.689715 139758017697536 logging_writer.py:48] [246100] global_step=246100, grad_norm=3.2822537422180176, loss=1.0976840257644653
I0303 20:43:08.514610 139758009304832 logging_writer.py:48] [246200] global_step=246200, grad_norm=3.448521375656128, loss=1.4472428560256958
I0303 20:43:53.409403 139758017697536 logging_writer.py:48] [246300] global_step=246300, grad_norm=3.9065208435058594, loss=3.277604579925537
I0303 20:44:38.431405 139758009304832 logging_writer.py:48] [246400] global_step=246400, grad_norm=3.1319520473480225, loss=1.187898874282837
I0303 20:45:24.028322 139758017697536 logging_writer.py:48] [246500] global_step=246500, grad_norm=3.2362091541290283, loss=2.5611441135406494
I0303 20:46:08.995546 139758009304832 logging_writer.py:48] [246600] global_step=246600, grad_norm=3.118997097015381, loss=1.2279629707336426
I0303 20:46:54.004408 139758017697536 logging_writer.py:48] [246700] global_step=246700, grad_norm=3.0709481239318848, loss=1.3825246095657349
I0303 20:47:39.367867 139758009304832 logging_writer.py:48] [246800] global_step=246800, grad_norm=2.927267551422119, loss=1.053794026374817
I0303 20:48:21.980966 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:48:33.331251 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:48:54.025504 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:48:55.657392 139953291118400 submission_runner.py:411] Time since start: 118375.83s, 	Step: 246896, 	{'train/accuracy': 0.8881640434265137, 'train/loss': 0.4150146245956421, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 109690.64672994614, 'total_duration': 118375.8336148262, 'accumulated_submission_time': 109690.64672994614, 'accumulated_eval_time': 8657.179294109344, 'accumulated_logging_time': 15.38704538345337}
I0303 20:48:55.724999 139758017697536 logging_writer.py:48] [246896] accumulated_eval_time=8657.179294, accumulated_logging_time=15.387045, accumulated_submission_time=109690.646730, global_step=246896, preemption_count=0, score=109690.646730, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=118375.833615, train/accuracy=0.888164, train/loss=0.415015, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:48:57.716242 139758009304832 logging_writer.py:48] [246900] global_step=246900, grad_norm=3.271137237548828, loss=1.1227729320526123
I0303 20:49:38.795629 139758009304832 logging_writer.py:48] [247000] global_step=247000, grad_norm=3.003833532333374, loss=1.5505726337432861
I0303 20:50:23.715118 139758017697536 logging_writer.py:48] [247100] global_step=247100, grad_norm=2.8620967864990234, loss=1.1410032510757446
I0303 20:51:08.844224 139758009304832 logging_writer.py:48] [247200] global_step=247200, grad_norm=3.075892925262451, loss=1.184931993484497
I0303 20:51:54.115423 139758017697536 logging_writer.py:48] [247300] global_step=247300, grad_norm=3.0519964694976807, loss=2.303518295288086
I0303 20:52:39.360261 139758009304832 logging_writer.py:48] [247400] global_step=247400, grad_norm=3.1241464614868164, loss=2.3318445682525635
I0303 20:53:24.499891 139758017697536 logging_writer.py:48] [247500] global_step=247500, grad_norm=3.200082778930664, loss=1.207218885421753
I0303 20:54:09.481670 139758009304832 logging_writer.py:48] [247600] global_step=247600, grad_norm=2.96663761138916, loss=1.1039326190948486
I0303 20:54:54.482371 139758017697536 logging_writer.py:48] [247700] global_step=247700, grad_norm=3.276785135269165, loss=1.0792138576507568
I0303 20:55:39.558101 139758009304832 logging_writer.py:48] [247800] global_step=247800, grad_norm=3.0023984909057617, loss=1.4167518615722656
I0303 20:55:55.702082 139953291118400 spec.py:321] Evaluating on the training split.
I0303 20:56:06.968048 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 20:56:41.497760 139953291118400 spec.py:349] Evaluating on the test split.
I0303 20:56:43.123555 139953291118400 submission_runner.py:411] Time since start: 118843.30s, 	Step: 247838, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.42507949471473694, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 110110.56650781631, 'total_duration': 118843.29978728294, 'accumulated_submission_time': 110110.56650781631, 'accumulated_eval_time': 8704.600757598877, 'accumulated_logging_time': 15.464092493057251}
I0303 20:56:43.175183 139758017697536 logging_writer.py:48] [247838] accumulated_eval_time=8704.600758, accumulated_logging_time=15.464092, accumulated_submission_time=110110.566508, global_step=247838, preemption_count=0, score=110110.566508, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=118843.299787, train/accuracy=0.886465, train/loss=0.425079, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 20:57:08.025441 139758009304832 logging_writer.py:48] [247900] global_step=247900, grad_norm=3.0911452770233154, loss=2.260728359222412
I0303 20:57:50.872674 139758017697536 logging_writer.py:48] [248000] global_step=248000, grad_norm=3.4000160694122314, loss=1.1234771013259888
I0303 20:58:35.999466 139758009304832 logging_writer.py:48] [248100] global_step=248100, grad_norm=3.09574818611145, loss=2.257514238357544
I0303 20:59:21.231812 139758017697536 logging_writer.py:48] [248200] global_step=248200, grad_norm=3.2596538066864014, loss=2.411006212234497
I0303 21:00:06.263678 139758009304832 logging_writer.py:48] [248300] global_step=248300, grad_norm=2.9758901596069336, loss=1.111661434173584
I0303 21:00:51.288847 139758017697536 logging_writer.py:48] [248400] global_step=248400, grad_norm=8.306617736816406, loss=1.5820869207382202
I0303 21:01:36.308073 139758009304832 logging_writer.py:48] [248500] global_step=248500, grad_norm=3.1690478324890137, loss=2.448408603668213
I0303 21:02:21.470852 139758017697536 logging_writer.py:48] [248600] global_step=248600, grad_norm=3.1588940620422363, loss=1.1448438167572021
I0303 21:03:06.279242 139758009304832 logging_writer.py:48] [248700] global_step=248700, grad_norm=3.7536962032318115, loss=2.8646178245544434
I0303 21:03:43.448369 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:03:54.504097 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:04:14.769482 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:04:16.405973 139953291118400 submission_runner.py:411] Time since start: 119296.58s, 	Step: 248784, 	{'train/accuracy': 0.8899218440055847, 'train/loss': 0.4135270118713379, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 110530.78303217888, 'total_duration': 119296.5821928978, 'accumulated_submission_time': 110530.78303217888, 'accumulated_eval_time': 8737.558348178864, 'accumulated_logging_time': 15.524272203445435}
I0303 21:04:16.474119 139758017697536 logging_writer.py:48] [248784] accumulated_eval_time=8737.558348, accumulated_logging_time=15.524272, accumulated_submission_time=110530.783032, global_step=248784, preemption_count=0, score=110530.783032, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=119296.582193, train/accuracy=0.889922, train/loss=0.413527, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:04:23.194998 139758009304832 logging_writer.py:48] [248800] global_step=248800, grad_norm=3.184931755065918, loss=1.4283742904663086
I0303 21:05:04.985689 139758017697536 logging_writer.py:48] [248900] global_step=248900, grad_norm=3.0248053073883057, loss=1.1386995315551758
I0303 21:05:50.193516 139758009304832 logging_writer.py:48] [249000] global_step=249000, grad_norm=3.1535611152648926, loss=1.2548794746398926
I0303 21:06:35.299196 139758017697536 logging_writer.py:48] [249100] global_step=249100, grad_norm=3.3241989612579346, loss=1.1291437149047852
I0303 21:07:20.257915 139758009304832 logging_writer.py:48] [249200] global_step=249200, grad_norm=3.3985602855682373, loss=2.648705005645752
I0303 21:08:04.986720 139758017697536 logging_writer.py:48] [249300] global_step=249300, grad_norm=2.9932944774627686, loss=1.1447283029556274
I0303 21:08:49.802867 139758009304832 logging_writer.py:48] [249400] global_step=249400, grad_norm=3.0802083015441895, loss=1.1067285537719727
I0303 21:09:34.901599 139758017697536 logging_writer.py:48] [249500] global_step=249500, grad_norm=3.058649778366089, loss=1.163978934288025
I0303 21:10:19.864196 139758009304832 logging_writer.py:48] [249600] global_step=249600, grad_norm=2.852627992630005, loss=1.0902304649353027
I0303 21:11:04.666150 139758017697536 logging_writer.py:48] [249700] global_step=249700, grad_norm=3.3941869735717773, loss=1.994643211364746
I0303 21:11:16.421372 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:11:27.682261 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:11:53.675625 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:11:55.305161 139953291118400 submission_runner.py:411] Time since start: 119755.48s, 	Step: 249728, 	{'train/accuracy': 0.887011706829071, 'train/loss': 0.42465606331825256, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 110950.67167448997, 'total_duration': 119755.48139166832, 'accumulated_submission_time': 110950.67167448997, 'accumulated_eval_time': 8776.442138671875, 'accumulated_logging_time': 15.602407932281494}
I0303 21:11:55.361383 139758009304832 logging_writer.py:48] [249728] accumulated_eval_time=8776.442139, accumulated_logging_time=15.602408, accumulated_submission_time=110950.671674, global_step=249728, preemption_count=0, score=110950.671674, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=119755.481392, train/accuracy=0.887012, train/loss=0.424656, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:12:24.184817 139758017697536 logging_writer.py:48] [249800] global_step=249800, grad_norm=2.9847803115844727, loss=1.1116245985031128
I0303 21:13:07.940126 139758009304832 logging_writer.py:48] [249900] global_step=249900, grad_norm=3.1066267490386963, loss=1.4206821918487549
I0303 21:13:52.828165 139758017697536 logging_writer.py:48] [250000] global_step=250000, grad_norm=3.1723287105560303, loss=1.3578704595565796
I0303 21:14:38.132950 139758009304832 logging_writer.py:48] [250100] global_step=250100, grad_norm=2.909594774246216, loss=1.1533544063568115
I0303 21:15:23.154515 139758017697536 logging_writer.py:48] [250200] global_step=250200, grad_norm=3.099348545074463, loss=1.2253328561782837
I0303 21:16:08.689196 139758009304832 logging_writer.py:48] [250300] global_step=250300, grad_norm=2.9885106086730957, loss=2.525172233581543
I0303 21:16:53.882755 139758017697536 logging_writer.py:48] [250400] global_step=250400, grad_norm=3.789442539215088, loss=3.1217894554138184
I0303 21:17:39.121874 139758009304832 logging_writer.py:48] [250500] global_step=250500, grad_norm=3.094341993331909, loss=1.1323400735855103
I0303 21:18:24.020443 139758017697536 logging_writer.py:48] [250600] global_step=250600, grad_norm=3.2491579055786133, loss=2.793534517288208
I0303 21:18:55.357380 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:19:06.367683 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:19:25.559609 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:19:27.226341 139953291118400 submission_runner.py:411] Time since start: 120207.40s, 	Step: 250671, 	{'train/accuracy': 0.8860546946525574, 'train/loss': 0.4246920347213745, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 111370.60998010635, 'total_duration': 120207.40252876282, 'accumulated_submission_time': 111370.60998010635, 'accumulated_eval_time': 8808.311047792435, 'accumulated_logging_time': 15.668404340744019}
I0303 21:19:27.333443 139758009304832 logging_writer.py:48] [250671] accumulated_eval_time=8808.311048, accumulated_logging_time=15.668404, accumulated_submission_time=111370.609980, global_step=250671, preemption_count=0, score=111370.609980, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=120207.402529, train/accuracy=0.886055, train/loss=0.424692, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:19:39.184139 139758017697536 logging_writer.py:48] [250700] global_step=250700, grad_norm=2.754037380218506, loss=0.9954473972320557
I0303 21:20:20.834475 139758009304832 logging_writer.py:48] [250800] global_step=250800, grad_norm=3.3060462474823, loss=2.54967999458313
I0303 21:21:05.637735 139758017697536 logging_writer.py:48] [250900] global_step=250900, grad_norm=3.270230770111084, loss=1.1046795845031738
I0303 21:21:50.584655 139758009304832 logging_writer.py:48] [251000] global_step=251000, grad_norm=2.963967800140381, loss=1.2516976594924927
I0303 21:22:35.661396 139758017697536 logging_writer.py:48] [251100] global_step=251100, grad_norm=3.1732656955718994, loss=1.0791491270065308
I0303 21:23:20.520689 139758009304832 logging_writer.py:48] [251200] global_step=251200, grad_norm=2.9421496391296387, loss=1.390907883644104
I0303 21:24:05.567667 139758017697536 logging_writer.py:48] [251300] global_step=251300, grad_norm=3.1189024448394775, loss=1.038028359413147
I0303 21:24:50.556284 139758009304832 logging_writer.py:48] [251400] global_step=251400, grad_norm=3.3081228733062744, loss=2.607158899307251
I0303 21:25:35.740876 139758017697536 logging_writer.py:48] [251500] global_step=251500, grad_norm=3.0292649269104004, loss=1.430593729019165
I0303 21:26:20.882024 139758009304832 logging_writer.py:48] [251600] global_step=251600, grad_norm=3.1860363483428955, loss=2.062814235687256
I0303 21:26:27.368398 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:26:38.545555 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:27:07.032622 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:27:08.669669 139953291118400 submission_runner.py:411] Time since start: 120668.85s, 	Step: 251616, 	{'train/accuracy': 0.887011706829071, 'train/loss': 0.4161558449268341, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 111790.58244228363, 'total_duration': 120668.84587788582, 'accumulated_submission_time': 111790.58244228363, 'accumulated_eval_time': 8849.612287044525, 'accumulated_logging_time': 15.789583206176758}
I0303 21:27:08.738775 139758017697536 logging_writer.py:48] [251616] accumulated_eval_time=8849.612287, accumulated_logging_time=15.789583, accumulated_submission_time=111790.582442, global_step=251616, preemption_count=0, score=111790.582442, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=120668.845878, train/accuracy=0.887012, train/loss=0.416156, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:27:42.295802 139758009304832 logging_writer.py:48] [251700] global_step=251700, grad_norm=3.10994291305542, loss=1.0787404775619507
I0303 21:28:26.620708 139758017697536 logging_writer.py:48] [251800] global_step=251800, grad_norm=3.3654768466949463, loss=1.111397624015808
I0303 21:29:11.678541 139758009304832 logging_writer.py:48] [251900] global_step=251900, grad_norm=3.540085792541504, loss=2.4305930137634277
I0303 21:29:56.776240 139758017697536 logging_writer.py:48] [252000] global_step=252000, grad_norm=3.0716142654418945, loss=1.5474917888641357
I0303 21:30:41.819209 139758009304832 logging_writer.py:48] [252100] global_step=252100, grad_norm=3.142235279083252, loss=1.1511170864105225
I0303 21:31:26.634946 139758017697536 logging_writer.py:48] [252200] global_step=252200, grad_norm=3.31396222114563, loss=1.0702184438705444
I0303 21:32:11.772685 139758009304832 logging_writer.py:48] [252300] global_step=252300, grad_norm=3.109768867492676, loss=1.745255470275879
I0303 21:32:56.509216 139758017697536 logging_writer.py:48] [252400] global_step=252400, grad_norm=3.8102545738220215, loss=3.2217514514923096
I0303 21:33:41.600114 139758009304832 logging_writer.py:48] [252500] global_step=252500, grad_norm=2.9206008911132812, loss=1.33259117603302
I0303 21:34:08.766541 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:34:19.921250 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:34:44.666473 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:34:46.300682 139953291118400 submission_runner.py:411] Time since start: 121126.48s, 	Step: 252562, 	{'train/accuracy': 0.8890429735183716, 'train/loss': 0.4178885519504547, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 112210.55100989342, 'total_duration': 121126.47691631317, 'accumulated_submission_time': 112210.55100989342, 'accumulated_eval_time': 8887.146436452866, 'accumulated_logging_time': 15.8693106174469}
I0303 21:34:46.356876 139758017697536 logging_writer.py:48] [252562] accumulated_eval_time=8887.146436, accumulated_logging_time=15.869311, accumulated_submission_time=112210.551010, global_step=252562, preemption_count=0, score=112210.551010, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=121126.476916, train/accuracy=0.889043, train/loss=0.417889, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:35:01.755154 139758009304832 logging_writer.py:48] [252600] global_step=252600, grad_norm=3.0907440185546875, loss=1.2476717233657837
I0303 21:35:43.413668 139758017697536 logging_writer.py:48] [252700] global_step=252700, grad_norm=2.955697536468506, loss=1.2754034996032715
I0303 21:36:29.099309 139758009304832 logging_writer.py:48] [252800] global_step=252800, grad_norm=3.0329248905181885, loss=1.2002770900726318
I0303 21:37:14.144237 139758017697536 logging_writer.py:48] [252900] global_step=252900, grad_norm=3.2824223041534424, loss=2.328921318054199
I0303 21:37:59.189780 139758009304832 logging_writer.py:48] [253000] global_step=253000, grad_norm=2.889789581298828, loss=1.1261496543884277
I0303 21:38:44.275287 139758017697536 logging_writer.py:48] [253100] global_step=253100, grad_norm=3.1616370677948, loss=1.1619961261749268
I0303 21:39:29.354562 139758009304832 logging_writer.py:48] [253200] global_step=253200, grad_norm=4.071861743927002, loss=2.887760639190674
I0303 21:40:14.470948 139758017697536 logging_writer.py:48] [253300] global_step=253300, grad_norm=3.1903257369995117, loss=1.110124945640564
I0303 21:40:59.539616 139758009304832 logging_writer.py:48] [253400] global_step=253400, grad_norm=3.151991605758667, loss=1.051065444946289
I0303 21:41:44.628861 139758017697536 logging_writer.py:48] [253500] global_step=253500, grad_norm=3.02579927444458, loss=1.0696461200714111
I0303 21:41:46.515888 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:41:57.802766 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:42:21.552657 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:42:23.189452 139953291118400 submission_runner.py:411] Time since start: 121583.37s, 	Step: 253506, 	{'train/accuracy': 0.8874413967132568, 'train/loss': 0.4144672751426697, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 112630.65174293518, 'total_duration': 121583.36565971375, 'accumulated_submission_time': 112630.65174293518, 'accumulated_eval_time': 8923.819966077805, 'accumulated_logging_time': 15.935075044631958}
I0303 21:42:23.253702 139758009304832 logging_writer.py:48] [253506] accumulated_eval_time=8923.819966, accumulated_logging_time=15.935075, accumulated_submission_time=112630.651743, global_step=253506, preemption_count=0, score=112630.651743, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=121583.365660, train/accuracy=0.887441, train/loss=0.414467, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:43:01.679404 139758017697536 logging_writer.py:48] [253600] global_step=253600, grad_norm=4.155555725097656, loss=1.2208977937698364
I0303 21:43:46.600886 139758009304832 logging_writer.py:48] [253700] global_step=253700, grad_norm=3.679828405380249, loss=1.5872104167938232
I0303 21:44:31.766000 139758017697536 logging_writer.py:48] [253800] global_step=253800, grad_norm=2.9547929763793945, loss=1.0254228115081787
I0303 21:45:16.918963 139758009304832 logging_writer.py:48] [253900] global_step=253900, grad_norm=3.176927089691162, loss=1.529168725013733
I0303 21:46:01.976660 139758017697536 logging_writer.py:48] [254000] global_step=254000, grad_norm=3.058929681777954, loss=1.426121711730957
I0303 21:46:47.277100 139758009304832 logging_writer.py:48] [254100] global_step=254100, grad_norm=3.281655788421631, loss=1.143819808959961
I0303 21:47:32.253931 139758017697536 logging_writer.py:48] [254200] global_step=254200, grad_norm=3.668795585632324, loss=3.137688636779785
I0303 21:48:17.462550 139758009304832 logging_writer.py:48] [254300] global_step=254300, grad_norm=2.945897340774536, loss=1.4924612045288086
I0303 21:49:02.064100 139758017697536 logging_writer.py:48] [254400] global_step=254400, grad_norm=3.27569842338562, loss=3.0546398162841797
I0303 21:49:23.395962 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:49:34.690122 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:49:57.110787 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:49:58.748669 139953291118400 submission_runner.py:411] Time since start: 122038.92s, 	Step: 254449, 	{'train/accuracy': 0.88623046875, 'train/loss': 0.418743759393692, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 113050.73615145683, 'total_duration': 122038.92489051819, 'accumulated_submission_time': 113050.73615145683, 'accumulated_eval_time': 8959.172646284103, 'accumulated_logging_time': 16.009252786636353}
I0303 21:49:58.814152 139758009304832 logging_writer.py:48] [254449] accumulated_eval_time=8959.172646, accumulated_logging_time=16.009253, accumulated_submission_time=113050.736151, global_step=254449, preemption_count=0, score=113050.736151, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=122038.924891, train/accuracy=0.886230, train/loss=0.418744, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:50:19.363118 139758017697536 logging_writer.py:48] [254500] global_step=254500, grad_norm=3.060267448425293, loss=2.295177936553955
I0303 21:51:02.879878 139758009304832 logging_writer.py:48] [254600] global_step=254600, grad_norm=3.685805082321167, loss=2.8365306854248047
I0303 21:51:47.728618 139758017697536 logging_writer.py:48] [254700] global_step=254700, grad_norm=2.9239144325256348, loss=1.9559829235076904
I0303 21:52:32.459882 139758009304832 logging_writer.py:48] [254800] global_step=254800, grad_norm=3.4103238582611084, loss=2.8354978561401367
I0303 21:53:17.227096 139758017697536 logging_writer.py:48] [254900] global_step=254900, grad_norm=3.071457624435425, loss=1.0639854669570923
I0303 21:54:02.193677 139758009304832 logging_writer.py:48] [255000] global_step=255000, grad_norm=3.6328420639038086, loss=3.163529396057129
I0303 21:54:47.122694 139758017697536 logging_writer.py:48] [255100] global_step=255100, grad_norm=2.930332899093628, loss=1.8747084140777588
I0303 21:55:32.100099 139758009304832 logging_writer.py:48] [255200] global_step=255200, grad_norm=3.064032793045044, loss=1.2836929559707642
I0303 21:56:17.913835 139758017697536 logging_writer.py:48] [255300] global_step=255300, grad_norm=3.5745253562927246, loss=3.2416844367980957
I0303 21:56:58.778392 139953291118400 spec.py:321] Evaluating on the training split.
I0303 21:57:10.066643 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 21:57:42.867023 139953291118400 spec.py:349] Evaluating on the test split.
I0303 21:57:44.491870 139953291118400 submission_runner.py:411] Time since start: 122504.67s, 	Step: 255392, 	{'train/accuracy': 0.8873242139816284, 'train/loss': 0.4254908561706543, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 113470.6403222084, 'total_duration': 122504.66809415817, 'accumulated_submission_time': 113470.6403222084, 'accumulated_eval_time': 9004.886109113693, 'accumulated_logging_time': 16.087283849716187}
I0303 21:57:44.547518 139758009304832 logging_writer.py:48] [255392] accumulated_eval_time=9004.886109, accumulated_logging_time=16.087284, accumulated_submission_time=113470.640322, global_step=255392, preemption_count=0, score=113470.640322, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=122504.668094, train/accuracy=0.887324, train/loss=0.425491, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 21:57:48.096190 139758017697536 logging_writer.py:48] [255400] global_step=255400, grad_norm=3.9128921031951904, loss=3.3249967098236084
I0303 21:58:28.439278 139758009304832 logging_writer.py:48] [255500] global_step=255500, grad_norm=3.1398661136627197, loss=2.2924256324768066
I0303 21:59:13.321692 139758017697536 logging_writer.py:48] [255600] global_step=255600, grad_norm=2.808746814727783, loss=1.2066380977630615
I0303 21:59:58.628552 139758009304832 logging_writer.py:48] [255700] global_step=255700, grad_norm=3.138352155685425, loss=1.449729561805725
I0303 22:00:43.901671 139758017697536 logging_writer.py:48] [255800] global_step=255800, grad_norm=2.959428548812866, loss=1.2182523012161255
I0303 22:01:28.899780 139758009304832 logging_writer.py:48] [255900] global_step=255900, grad_norm=3.2667462825775146, loss=1.2521946430206299
I0303 22:02:14.109984 139758017697536 logging_writer.py:48] [256000] global_step=256000, grad_norm=3.3168821334838867, loss=1.0960363149642944
I0303 22:02:59.239885 139758009304832 logging_writer.py:48] [256100] global_step=256100, grad_norm=2.8160877227783203, loss=1.9349455833435059
I0303 22:03:44.223101 139758017697536 logging_writer.py:48] [256200] global_step=256200, grad_norm=3.523366928100586, loss=1.4056843519210815
I0303 22:04:29.553326 139758009304832 logging_writer.py:48] [256300] global_step=256300, grad_norm=2.7156989574432373, loss=1.382256269454956
I0303 22:04:44.852787 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:04:55.983288 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:05:27.837877 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:05:29.465082 139953291118400 submission_runner.py:411] Time since start: 122969.64s, 	Step: 256336, 	{'train/accuracy': 0.8916210532188416, 'train/loss': 0.4107459783554077, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 113890.8896214962, 'total_duration': 122969.64131331444, 'accumulated_submission_time': 113890.8896214962, 'accumulated_eval_time': 9049.498392343521, 'accumulated_logging_time': 16.151769876480103}
I0303 22:05:29.519429 139758017697536 logging_writer.py:48] [256336] accumulated_eval_time=9049.498392, accumulated_logging_time=16.151770, accumulated_submission_time=113890.889621, global_step=256336, preemption_count=0, score=113890.889621, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=122969.641313, train/accuracy=0.891621, train/loss=0.410746, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:05:55.142185 139758009304832 logging_writer.py:48] [256400] global_step=256400, grad_norm=3.3273701667785645, loss=2.7695748805999756
I0303 22:06:38.707594 139758017697536 logging_writer.py:48] [256500] global_step=256500, grad_norm=3.4890854358673096, loss=2.799959659576416
I0303 22:07:23.566328 139758009304832 logging_writer.py:48] [256600] global_step=256600, grad_norm=3.812685489654541, loss=3.0142998695373535
I0303 22:08:08.623023 139758017697536 logging_writer.py:48] [256700] global_step=256700, grad_norm=3.0233070850372314, loss=1.0993202924728394
I0303 22:08:53.523964 139758009304832 logging_writer.py:48] [256800] global_step=256800, grad_norm=2.8557891845703125, loss=1.6166765689849854
I0303 22:09:38.490483 139758017697536 logging_writer.py:48] [256900] global_step=256900, grad_norm=3.1086089611053467, loss=1.0618621110916138
I0303 22:10:23.514490 139758009304832 logging_writer.py:48] [257000] global_step=257000, grad_norm=3.0794711112976074, loss=1.4130481481552124
I0303 22:11:08.366948 139758017697536 logging_writer.py:48] [257100] global_step=257100, grad_norm=2.7148618698120117, loss=1.0629117488861084
I0303 22:11:53.573891 139758009304832 logging_writer.py:48] [257200] global_step=257200, grad_norm=3.079664707183838, loss=1.097615361213684
I0303 22:12:29.534779 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:12:40.924408 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:13:08.722943 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:13:10.345852 139953291118400 submission_runner.py:411] Time since start: 123430.52s, 	Step: 257282, 	{'train/accuracy': 0.8884570002555847, 'train/loss': 0.4124673306941986, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 114310.84763216972, 'total_duration': 123430.52208042145, 'accumulated_submission_time': 114310.84763216972, 'accumulated_eval_time': 9090.309470415115, 'accumulated_logging_time': 16.214890003204346}
I0303 22:13:10.402232 139758017697536 logging_writer.py:48] [257282] accumulated_eval_time=9090.309470, accumulated_logging_time=16.214890, accumulated_submission_time=114310.847632, global_step=257282, preemption_count=0, score=114310.847632, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=123430.522080, train/accuracy=0.888457, train/loss=0.412467, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:13:17.895021 139758009304832 logging_writer.py:48] [257300] global_step=257300, grad_norm=3.0549511909484863, loss=2.2064483165740967
I0303 22:13:59.106894 139758017697536 logging_writer.py:48] [257400] global_step=257400, grad_norm=3.246109962463379, loss=1.3482869863510132
I0303 22:14:44.373674 139758009304832 logging_writer.py:48] [257500] global_step=257500, grad_norm=3.030118465423584, loss=1.8813350200653076
I0303 22:15:30.008971 139758017697536 logging_writer.py:48] [257600] global_step=257600, grad_norm=2.9912924766540527, loss=1.507989764213562
I0303 22:16:15.952992 139758009304832 logging_writer.py:48] [257700] global_step=257700, grad_norm=2.924837827682495, loss=1.3955641984939575
I0303 22:17:01.041136 139758017697536 logging_writer.py:48] [257800] global_step=257800, grad_norm=3.1950905323028564, loss=1.108293890953064
I0303 22:17:46.239731 139758009304832 logging_writer.py:48] [257900] global_step=257900, grad_norm=2.9771740436553955, loss=1.052483081817627
I0303 22:18:31.695373 139758017697536 logging_writer.py:48] [258000] global_step=258000, grad_norm=3.3038041591644287, loss=2.0876846313476562
I0303 22:19:17.013395 139758009304832 logging_writer.py:48] [258100] global_step=258100, grad_norm=3.357618570327759, loss=2.325413465499878
I0303 22:20:02.254592 139758017697536 logging_writer.py:48] [258200] global_step=258200, grad_norm=2.6919448375701904, loss=1.063880443572998
I0303 22:20:10.564098 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:20:22.026254 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:20:47.549736 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:20:49.174504 139953291118400 submission_runner.py:411] Time since start: 123889.35s, 	Step: 258220, 	{'train/accuracy': 0.8871874809265137, 'train/loss': 0.41939395666122437, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 114730.95115160942, 'total_duration': 123889.350730896, 'accumulated_submission_time': 114730.95115160942, 'accumulated_eval_time': 9128.919853687286, 'accumulated_logging_time': 16.28192138671875}
I0303 22:20:49.231499 139758009304832 logging_writer.py:48] [258220] accumulated_eval_time=9128.919854, accumulated_logging_time=16.281921, accumulated_submission_time=114730.951152, global_step=258220, preemption_count=0, score=114730.951152, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=123889.350731, train/accuracy=0.887187, train/loss=0.419394, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:21:21.192392 139758017697536 logging_writer.py:48] [258300] global_step=258300, grad_norm=3.273165702819824, loss=2.551666259765625
I0303 22:22:05.787636 139758009304832 logging_writer.py:48] [258400] global_step=258400, grad_norm=3.169835329055786, loss=2.8197875022888184
I0303 22:22:50.900161 139758017697536 logging_writer.py:48] [258500] global_step=258500, grad_norm=3.2827186584472656, loss=1.218317985534668
I0303 22:23:36.250706 139758009304832 logging_writer.py:48] [258600] global_step=258600, grad_norm=2.998107433319092, loss=2.167046308517456
I0303 22:24:21.341054 139758017697536 logging_writer.py:48] [258700] global_step=258700, grad_norm=3.0063588619232178, loss=1.1740293502807617
I0303 22:25:06.588247 139758009304832 logging_writer.py:48] [258800] global_step=258800, grad_norm=2.947096347808838, loss=1.4228752851486206
I0303 22:25:51.755162 139758017697536 logging_writer.py:48] [258900] global_step=258900, grad_norm=3.1503992080688477, loss=1.7284455299377441
I0303 22:26:37.331864 139758009304832 logging_writer.py:48] [259000] global_step=259000, grad_norm=2.9737770557403564, loss=1.1074658632278442
I0303 22:27:22.618288 139758017697536 logging_writer.py:48] [259100] global_step=259100, grad_norm=3.0669116973876953, loss=1.0982062816619873
I0303 22:27:49.215061 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:28:01.410998 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:28:22.253530 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:28:23.880633 139953291118400 submission_runner.py:411] Time since start: 124344.06s, 	Step: 259161, 	{'train/accuracy': 0.8880859017372131, 'train/loss': 0.41526010632514954, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 115150.87838816643, 'total_duration': 124344.05685377121, 'accumulated_submission_time': 115150.87838816643, 'accumulated_eval_time': 9163.585408687592, 'accumulated_logging_time': 16.34766459465027}
I0303 22:28:23.949978 139758009304832 logging_writer.py:48] [259161] accumulated_eval_time=9163.585409, accumulated_logging_time=16.347665, accumulated_submission_time=115150.878388, global_step=259161, preemption_count=0, score=115150.878388, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=124344.056854, train/accuracy=0.888086, train/loss=0.415260, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:28:39.753263 139758017697536 logging_writer.py:48] [259200] global_step=259200, grad_norm=3.0725128650665283, loss=2.2371325492858887
I0303 22:29:22.916944 139758009304832 logging_writer.py:48] [259300] global_step=259300, grad_norm=2.933152675628662, loss=1.1909098625183105
I0303 22:30:08.054786 139758017697536 logging_writer.py:48] [259400] global_step=259400, grad_norm=3.170146942138672, loss=1.1289721727371216
I0303 22:30:53.101611 139758009304832 logging_writer.py:48] [259500] global_step=259500, grad_norm=3.406796455383301, loss=1.1495729684829712
I0303 22:31:38.189246 139758017697536 logging_writer.py:48] [259600] global_step=259600, grad_norm=3.1311748027801514, loss=1.1102900505065918
I0303 22:32:23.107881 139758009304832 logging_writer.py:48] [259700] global_step=259700, grad_norm=3.5846199989318848, loss=2.566204309463501
I0303 22:33:08.194686 139758017697536 logging_writer.py:48] [259800] global_step=259800, grad_norm=2.9020800590515137, loss=1.672202229499817
I0303 22:33:53.075302 139758009304832 logging_writer.py:48] [259900] global_step=259900, grad_norm=3.0607025623321533, loss=1.1975219249725342
I0303 22:34:38.451312 139758017697536 logging_writer.py:48] [260000] global_step=260000, grad_norm=3.0783355236053467, loss=2.4941442012786865
I0303 22:35:23.676919 139758009304832 logging_writer.py:48] [260100] global_step=260100, grad_norm=3.0741050243377686, loss=1.0769784450531006
I0303 22:35:24.250215 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:35:35.555111 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:36:03.489269 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:36:05.121068 139953291118400 submission_runner.py:411] Time since start: 124805.30s, 	Step: 260103, 	{'train/accuracy': 0.8839648365974426, 'train/loss': 0.42421600222587585, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 115571.12068414688, 'total_duration': 124805.29729104042, 'accumulated_submission_time': 115571.12068414688, 'accumulated_eval_time': 9204.456241607666, 'accumulated_logging_time': 16.427672386169434}
I0303 22:36:05.190126 139758017697536 logging_writer.py:48] [260103] accumulated_eval_time=9204.456242, accumulated_logging_time=16.427672, accumulated_submission_time=115571.120684, global_step=260103, preemption_count=0, score=115571.120684, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=124805.297291, train/accuracy=0.883965, train/loss=0.424216, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:36:44.485487 139758009304832 logging_writer.py:48] [260200] global_step=260200, grad_norm=4.606968402862549, loss=3.1229326725006104
I0303 22:37:29.599253 139758017697536 logging_writer.py:48] [260300] global_step=260300, grad_norm=2.879188299179077, loss=1.279380440711975
I0303 22:38:14.589856 139758009304832 logging_writer.py:48] [260400] global_step=260400, grad_norm=3.3436238765716553, loss=3.0212419033050537
I0303 22:38:59.793122 139758017697536 logging_writer.py:48] [260500] global_step=260500, grad_norm=3.2040059566497803, loss=1.1062748432159424
I0303 22:39:45.015629 139758009304832 logging_writer.py:48] [260600] global_step=260600, grad_norm=4.471765518188477, loss=1.088205099105835
I0303 22:40:30.071819 139758017697536 logging_writer.py:48] [260700] global_step=260700, grad_norm=3.014263391494751, loss=1.2165982723236084
I0303 22:41:14.992264 139758009304832 logging_writer.py:48] [260800] global_step=260800, grad_norm=3.0203638076782227, loss=1.1670478582382202
I0303 22:41:59.761745 139758017697536 logging_writer.py:48] [260900] global_step=260900, grad_norm=3.114778757095337, loss=1.7754278182983398
I0303 22:42:44.653600 139758009304832 logging_writer.py:48] [261000] global_step=261000, grad_norm=3.0810389518737793, loss=1.3511888980865479
I0303 22:43:05.523416 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:43:16.612520 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:43:38.283204 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:43:39.921959 139953291118400 submission_runner.py:411] Time since start: 125260.10s, 	Step: 261048, 	{'train/accuracy': 0.8904882669448853, 'train/loss': 0.4089166224002838, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 115991.3933467865, 'total_duration': 125260.09818053246, 'accumulated_submission_time': 115991.3933467865, 'accumulated_eval_time': 9238.854766130447, 'accumulated_logging_time': 16.508938312530518}
I0303 22:43:39.991638 139758017697536 logging_writer.py:48] [261048] accumulated_eval_time=9238.854766, accumulated_logging_time=16.508938, accumulated_submission_time=115991.393347, global_step=261048, preemption_count=0, score=115991.393347, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=125260.098181, train/accuracy=0.890488, train/loss=0.408917, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:44:01.072413 139758009304832 logging_writer.py:48] [261100] global_step=261100, grad_norm=3.0725202560424805, loss=1.3112950325012207
I0303 22:44:44.856696 139758017697536 logging_writer.py:48] [261200] global_step=261200, grad_norm=3.1012163162231445, loss=2.269634962081909
I0303 22:45:30.361180 139758009304832 logging_writer.py:48] [261300] global_step=261300, grad_norm=3.112203598022461, loss=1.7494010925292969
I0303 22:46:15.495856 139758017697536 logging_writer.py:48] [261400] global_step=261400, grad_norm=2.9144790172576904, loss=1.1380404233932495
I0303 22:47:00.669017 139758009304832 logging_writer.py:48] [261500] global_step=261500, grad_norm=3.1607325077056885, loss=1.1460826396942139
I0303 22:47:45.597331 139758017697536 logging_writer.py:48] [261600] global_step=261600, grad_norm=3.0573196411132812, loss=1.105920672416687
I0303 22:48:30.530195 139758009304832 logging_writer.py:48] [261700] global_step=261700, grad_norm=3.011040210723877, loss=1.624999761581421
I0303 22:49:15.576328 139758017697536 logging_writer.py:48] [261800] global_step=261800, grad_norm=3.2375576496124268, loss=1.1982431411743164
I0303 22:50:00.534017 139758009304832 logging_writer.py:48] [261900] global_step=261900, grad_norm=3.689929723739624, loss=1.1160327196121216
I0303 22:50:40.237755 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:50:51.463837 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:51:20.649267 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:51:22.285866 139953291118400 submission_runner.py:411] Time since start: 125722.46s, 	Step: 261990, 	{'train/accuracy': 0.8859374523162842, 'train/loss': 0.4217362105846405, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 116411.57664585114, 'total_duration': 125722.46207761765, 'accumulated_submission_time': 116411.57664585114, 'accumulated_eval_time': 9280.902841329575, 'accumulated_logging_time': 16.59387707710266}
I0303 22:51:22.353945 139758017697536 logging_writer.py:48] [261990] accumulated_eval_time=9280.902841, accumulated_logging_time=16.593877, accumulated_submission_time=116411.576646, global_step=261990, preemption_count=0, score=116411.576646, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=125722.462078, train/accuracy=0.885937, train/loss=0.421736, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:51:26.694297 139758009304832 logging_writer.py:48] [262000] global_step=262000, grad_norm=3.412407398223877, loss=2.939462184906006
I0303 22:52:07.659372 139758017697536 logging_writer.py:48] [262100] global_step=262100, grad_norm=3.081490993499756, loss=1.44081711769104
I0303 22:52:52.652228 139758009304832 logging_writer.py:48] [262200] global_step=262200, grad_norm=3.509500741958618, loss=2.693486213684082
I0303 22:53:38.065566 139758017697536 logging_writer.py:48] [262300] global_step=262300, grad_norm=3.0154948234558105, loss=1.2589622735977173
I0303 22:54:23.473465 139758009304832 logging_writer.py:48] [262400] global_step=262400, grad_norm=3.1204190254211426, loss=1.7994952201843262
I0303 22:55:08.333177 139758017697536 logging_writer.py:48] [262500] global_step=262500, grad_norm=3.1716904640197754, loss=2.6992952823638916
I0303 22:55:53.631294 139758009304832 logging_writer.py:48] [262600] global_step=262600, grad_norm=3.1475090980529785, loss=2.0996286869049072
I0303 22:56:39.177076 139758017697536 logging_writer.py:48] [262700] global_step=262700, grad_norm=3.5406322479248047, loss=2.9718570709228516
I0303 22:57:24.250834 139758009304832 logging_writer.py:48] [262800] global_step=262800, grad_norm=2.8467042446136475, loss=1.6304970979690552
I0303 22:58:09.163883 139758017697536 logging_writer.py:48] [262900] global_step=262900, grad_norm=2.9831349849700928, loss=1.2750108242034912
I0303 22:58:22.795087 139953291118400 spec.py:321] Evaluating on the training split.
I0303 22:58:33.846515 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 22:59:02.427311 139953291118400 spec.py:349] Evaluating on the test split.
I0303 22:59:04.047550 139953291118400 submission_runner.py:411] Time since start: 126184.22s, 	Step: 262932, 	{'train/accuracy': 0.8861132860183716, 'train/loss': 0.42596235871315, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 116831.9596195221, 'total_duration': 126184.22378492355, 'accumulated_submission_time': 116831.9596195221, 'accumulated_eval_time': 9322.155301809311, 'accumulated_logging_time': 16.67237138748169}
I0303 22:59:04.103303 139758009304832 logging_writer.py:48] [262932] accumulated_eval_time=9322.155302, accumulated_logging_time=16.672371, accumulated_submission_time=116831.959620, global_step=262932, preemption_count=0, score=116831.959620, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=126184.223785, train/accuracy=0.886113, train/loss=0.425962, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 22:59:31.339894 139758017697536 logging_writer.py:48] [263000] global_step=263000, grad_norm=3.7216789722442627, loss=3.1939914226531982
I0303 23:00:14.721655 139758009304832 logging_writer.py:48] [263100] global_step=263100, grad_norm=3.267282009124756, loss=2.6655752658843994
I0303 23:00:59.417164 139758017697536 logging_writer.py:48] [263200] global_step=263200, grad_norm=3.2172842025756836, loss=2.475703716278076
I0303 23:01:44.347906 139758009304832 logging_writer.py:48] [263300] global_step=263300, grad_norm=3.307913303375244, loss=2.60967755317688
I0303 23:02:29.092218 139758017697536 logging_writer.py:48] [263400] global_step=263400, grad_norm=3.368419885635376, loss=1.7717740535736084
I0303 23:03:13.964403 139758009304832 logging_writer.py:48] [263500] global_step=263500, grad_norm=3.103555917739868, loss=1.7928955554962158
I0303 23:03:58.949170 139758017697536 logging_writer.py:48] [263600] global_step=263600, grad_norm=3.045771598815918, loss=1.1335574388504028
I0303 23:04:43.699850 139758009304832 logging_writer.py:48] [263700] global_step=263700, grad_norm=3.1226112842559814, loss=1.5721020698547363
I0303 23:05:28.785638 139758017697536 logging_writer.py:48] [263800] global_step=263800, grad_norm=3.090857982635498, loss=2.499454975128174
I0303 23:06:04.330378 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:06:15.830498 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 23:06:35.958711 139953291118400 spec.py:349] Evaluating on the test split.
I0303 23:06:37.593872 139953291118400 submission_runner.py:411] Time since start: 126637.77s, 	Step: 263881, 	{'train/accuracy': 0.8869140148162842, 'train/loss': 0.4212360680103302, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 117252.12936592102, 'total_duration': 126637.7700855732, 'accumulated_submission_time': 117252.12936592102, 'accumulated_eval_time': 9355.41879272461, 'accumulated_logging_time': 16.736831426620483}
I0303 23:06:37.661821 139758009304832 logging_writer.py:48] [263881] accumulated_eval_time=9355.418793, accumulated_logging_time=16.736831, accumulated_submission_time=117252.129366, global_step=263881, preemption_count=0, score=117252.129366, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=126637.770086, train/accuracy=0.886914, train/loss=0.421236, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 23:06:45.581855 139758017697536 logging_writer.py:48] [263900] global_step=263900, grad_norm=3.1399896144866943, loss=1.0966575145721436
I0303 23:07:27.648680 139758009304832 logging_writer.py:48] [264000] global_step=264000, grad_norm=2.925346612930298, loss=1.268049716949463
I0303 23:08:12.744332 139758017697536 logging_writer.py:48] [264100] global_step=264100, grad_norm=3.113515615463257, loss=2.1545886993408203
I0303 23:08:57.698975 139758009304832 logging_writer.py:48] [264200] global_step=264200, grad_norm=3.2803971767425537, loss=1.1665905714035034
I0303 23:09:43.020730 139758017697536 logging_writer.py:48] [264300] global_step=264300, grad_norm=2.9656379222869873, loss=1.8987919092178345
I0303 23:10:28.210392 139758009304832 logging_writer.py:48] [264400] global_step=264400, grad_norm=3.3911030292510986, loss=2.879277229309082
I0303 23:11:13.400829 139758017697536 logging_writer.py:48] [264500] global_step=264500, grad_norm=2.7927536964416504, loss=1.5181689262390137
I0303 23:11:58.498080 139758009304832 logging_writer.py:48] [264600] global_step=264600, grad_norm=4.231607437133789, loss=3.341290235519409
I0303 23:12:43.462796 139758017697536 logging_writer.py:48] [264700] global_step=264700, grad_norm=5.11719274520874, loss=3.2091126441955566
I0303 23:13:28.369577 139758009304832 logging_writer.py:48] [264800] global_step=264800, grad_norm=3.0198299884796143, loss=1.3135052919387817
I0303 23:13:37.964561 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:13:49.213529 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 23:14:20.811752 139953291118400 spec.py:349] Evaluating on the test split.
I0303 23:14:22.435554 139953291118400 submission_runner.py:411] Time since start: 127102.61s, 	Step: 264823, 	{'train/accuracy': 0.8873632550239563, 'train/loss': 0.41834211349487305, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 117672.37464976311, 'total_duration': 127102.61178898811, 'accumulated_submission_time': 117672.37464976311, 'accumulated_eval_time': 9399.889789581299, 'accumulated_logging_time': 16.814719676971436}
I0303 23:14:22.492007 139758017697536 logging_writer.py:48] [264823] accumulated_eval_time=9399.889790, accumulated_logging_time=16.814720, accumulated_submission_time=117672.374650, global_step=264823, preemption_count=0, score=117672.374650, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=127102.611789, train/accuracy=0.887363, train/loss=0.418342, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 23:14:53.289674 139758009304832 logging_writer.py:48] [264900] global_step=264900, grad_norm=3.3087589740753174, loss=1.07218337059021
I0303 23:15:37.325693 139758017697536 logging_writer.py:48] [265000] global_step=265000, grad_norm=2.9914767742156982, loss=1.3264881372451782
I0303 23:16:22.668238 139758009304832 logging_writer.py:48] [265100] global_step=265100, grad_norm=3.434999704360962, loss=1.2361785173416138
I0303 23:17:08.041049 139758017697536 logging_writer.py:48] [265200] global_step=265200, grad_norm=3.082380533218384, loss=1.062492847442627
I0303 23:17:53.100075 139758009304832 logging_writer.py:48] [265300] global_step=265300, grad_norm=3.7451391220092773, loss=1.1797842979431152
I0303 23:18:38.198716 139758017697536 logging_writer.py:48] [265400] global_step=265400, grad_norm=2.971597194671631, loss=1.1283354759216309
I0303 23:19:23.325857 139758009304832 logging_writer.py:48] [265500] global_step=265500, grad_norm=2.9989166259765625, loss=2.403230667114258
I0303 23:20:08.206965 139758017697536 logging_writer.py:48] [265600] global_step=265600, grad_norm=3.064903736114502, loss=1.308329463005066
I0303 23:20:53.142250 139758009304832 logging_writer.py:48] [265700] global_step=265700, grad_norm=3.4393582344055176, loss=3.0966975688934326
I0303 23:21:22.511253 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:21:33.461380 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 23:21:53.602202 139953291118400 spec.py:349] Evaluating on the test split.
I0303 23:21:55.236986 139953291118400 submission_runner.py:411] Time since start: 127555.41s, 	Step: 265767, 	{'train/accuracy': 0.88671875, 'train/loss': 0.420605331659317, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 118092.33594608307, 'total_duration': 127555.41320848465, 'accumulated_submission_time': 118092.33594608307, 'accumulated_eval_time': 9432.615530729294, 'accumulated_logging_time': 16.88166904449463}
I0303 23:21:55.304067 139758017697536 logging_writer.py:48] [265767] accumulated_eval_time=9432.615531, accumulated_logging_time=16.881669, accumulated_submission_time=118092.335946, global_step=265767, preemption_count=0, score=118092.335946, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=127555.413208, train/accuracy=0.886719, train/loss=0.420605, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 23:22:08.743575 139758009304832 logging_writer.py:48] [265800] global_step=265800, grad_norm=3.645456075668335, loss=3.0645337104797363
I0303 23:22:51.370464 139758017697536 logging_writer.py:48] [265900] global_step=265900, grad_norm=3.0658833980560303, loss=1.4784927368164062
I0303 23:23:36.486830 139758009304832 logging_writer.py:48] [266000] global_step=266000, grad_norm=3.03144907951355, loss=1.1861332654953003
I0303 23:24:21.707019 139758017697536 logging_writer.py:48] [266100] global_step=266100, grad_norm=3.1090550422668457, loss=1.189796805381775
I0303 23:25:06.865226 139758009304832 logging_writer.py:48] [266200] global_step=266200, grad_norm=2.9345808029174805, loss=1.1075371503829956
I0303 23:25:51.841490 139758017697536 logging_writer.py:48] [266300] global_step=266300, grad_norm=3.1497364044189453, loss=1.276578426361084
I0303 23:26:37.040619 139758009304832 logging_writer.py:48] [266400] global_step=266400, grad_norm=3.0852644443511963, loss=1.2100939750671387
I0303 23:27:22.388004 139758017697536 logging_writer.py:48] [266500] global_step=266500, grad_norm=3.547438144683838, loss=2.8698270320892334
I0303 23:28:07.233973 139758009304832 logging_writer.py:48] [266600] global_step=266600, grad_norm=3.2218170166015625, loss=1.0956295728683472
I0303 23:28:52.247338 139758017697536 logging_writer.py:48] [266700] global_step=266700, grad_norm=2.8445544242858887, loss=1.078165054321289
I0303 23:28:55.441788 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:29:06.738177 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 23:29:35.993704 139953291118400 spec.py:349] Evaluating on the test split.
I0303 23:29:37.633643 139953291118400 submission_runner.py:411] Time since start: 128017.81s, 	Step: 266709, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.4178589880466461, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 118512.41550278664, 'total_duration': 128017.80984807014, 'accumulated_submission_time': 118512.41550278664, 'accumulated_eval_time': 9474.807350158691, 'accumulated_logging_time': 16.959134101867676}
I0303 23:29:37.700458 139758009304832 logging_writer.py:48] [266709] accumulated_eval_time=9474.807350, accumulated_logging_time=16.959134, accumulated_submission_time=118512.415503, global_step=266709, preemption_count=0, score=118512.415503, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=128017.809848, train/accuracy=0.887383, train/loss=0.417859, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 23:30:14.039626 139758017697536 logging_writer.py:48] [266800] global_step=266800, grad_norm=3.200347661972046, loss=1.1370748281478882
I0303 23:30:58.720943 139758009304832 logging_writer.py:48] [266900] global_step=266900, grad_norm=3.177013397216797, loss=1.2486199140548706
I0303 23:31:43.849326 139758017697536 logging_writer.py:48] [267000] global_step=267000, grad_norm=3.077847480773926, loss=1.302391767501831
I0303 23:32:29.223040 139758009304832 logging_writer.py:48] [267100] global_step=267100, grad_norm=3.078503370285034, loss=1.1417804956436157
I0303 23:33:14.079241 139758017697536 logging_writer.py:48] [267200] global_step=267200, grad_norm=3.4124081134796143, loss=1.4912679195404053
I0303 23:33:59.128732 139758009304832 logging_writer.py:48] [267300] global_step=267300, grad_norm=3.1780736446380615, loss=2.6591005325317383
I0303 23:34:44.019769 139758017697536 logging_writer.py:48] [267400] global_step=267400, grad_norm=3.4967336654663086, loss=2.9398739337921143
I0303 23:35:29.105372 139758009304832 logging_writer.py:48] [267500] global_step=267500, grad_norm=3.2193856239318848, loss=1.0769399404525757
I0303 23:36:14.193861 139758017697536 logging_writer.py:48] [267600] global_step=267600, grad_norm=2.9931609630584717, loss=1.3698426485061646
I0303 23:36:37.926066 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:36:48.956265 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 23:37:09.576884 139953291118400 spec.py:349] Evaluating on the test split.
I0303 23:37:11.213976 139953291118400 submission_runner.py:411] Time since start: 128471.39s, 	Step: 267654, 	{'train/accuracy': 0.8849608898162842, 'train/loss': 0.4240126311779022, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 118932.5847196579, 'total_duration': 128471.3901963234, 'accumulated_submission_time': 118932.5847196579, 'accumulated_eval_time': 9508.095239162445, 'accumulated_logging_time': 17.03475069999695}
I0303 23:37:11.285471 139758009304832 logging_writer.py:48] [267654] accumulated_eval_time=9508.095239, accumulated_logging_time=17.034751, accumulated_submission_time=118932.584720, global_step=267654, preemption_count=0, score=118932.584720, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=128471.390196, train/accuracy=0.884961, train/loss=0.424013, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 23:37:29.844111 139758017697536 logging_writer.py:48] [267700] global_step=267700, grad_norm=2.912727117538452, loss=1.1830071210861206
I0303 23:38:13.389026 139758009304832 logging_writer.py:48] [267800] global_step=267800, grad_norm=2.975644588470459, loss=1.0212520360946655
I0303 23:38:58.252605 139758017697536 logging_writer.py:48] [267900] global_step=267900, grad_norm=3.1243181228637695, loss=1.0628758668899536
I0303 23:39:43.473349 139758009304832 logging_writer.py:48] [268000] global_step=268000, grad_norm=2.9371466636657715, loss=1.2016083002090454
I0303 23:40:28.475729 139758017697536 logging_writer.py:48] [268100] global_step=268100, grad_norm=3.0867292881011963, loss=1.0514507293701172
I0303 23:41:13.685420 139758009304832 logging_writer.py:48] [268200] global_step=268200, grad_norm=3.0094499588012695, loss=1.3530633449554443
I0303 23:41:58.885592 139758017697536 logging_writer.py:48] [268300] global_step=268300, grad_norm=2.9880154132843018, loss=1.3128749132156372
I0303 23:42:43.725364 139758009304832 logging_writer.py:48] [268400] global_step=268400, grad_norm=3.462341070175171, loss=3.096883773803711
I0303 23:43:28.514567 139758017697536 logging_writer.py:48] [268500] global_step=268500, grad_norm=2.9660563468933105, loss=2.408588171005249
I0303 23:44:11.285810 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:44:22.457680 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 23:44:52.372283 139953291118400 spec.py:349] Evaluating on the test split.
I0303 23:44:53.998570 139953291118400 submission_runner.py:411] Time since start: 128934.17s, 	Step: 268597, 	{'train/accuracy': 0.8870702981948853, 'train/loss': 0.42286941409111023, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 119352.5260078907, 'total_duration': 128934.17479658127, 'accumulated_submission_time': 119352.5260078907, 'accumulated_eval_time': 9550.807997703552, 'accumulated_logging_time': 17.11642861366272}
I0303 23:44:54.053333 139758009304832 logging_writer.py:48] [268597] accumulated_eval_time=9550.807998, accumulated_logging_time=17.116429, accumulated_submission_time=119352.526008, global_step=268597, preemption_count=0, score=119352.526008, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=128934.174797, train/accuracy=0.887070, train/loss=0.422869, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 23:44:55.631825 139758017697536 logging_writer.py:48] [268600] global_step=268600, grad_norm=3.826582193374634, loss=3.235902786254883
I0303 23:45:35.694928 139758009304832 logging_writer.py:48] [268700] global_step=268700, grad_norm=3.592623710632324, loss=1.2242480516433716
I0303 23:46:20.464628 139758017697536 logging_writer.py:48] [268800] global_step=268800, grad_norm=3.405754327774048, loss=3.053018093109131
I0303 23:47:05.323130 139758009304832 logging_writer.py:48] [268900] global_step=268900, grad_norm=4.589846611022949, loss=2.7567765712738037
I0303 23:47:50.776055 139758017697536 logging_writer.py:48] [269000] global_step=269000, grad_norm=3.4290075302124023, loss=2.8958401679992676
I0303 23:48:35.711244 139758009304832 logging_writer.py:48] [269100] global_step=269100, grad_norm=2.9872329235076904, loss=1.0788965225219727
I0303 23:49:20.732461 139758017697536 logging_writer.py:48] [269200] global_step=269200, grad_norm=3.2845406532287598, loss=1.0815386772155762
I0303 23:50:05.809734 139758009304832 logging_writer.py:48] [269300] global_step=269300, grad_norm=3.105975866317749, loss=2.7448809146881104
I0303 23:50:50.422361 139758017697536 logging_writer.py:48] [269400] global_step=269400, grad_norm=3.6304705142974854, loss=3.017422914505005
I0303 23:51:35.537453 139758009304832 logging_writer.py:48] [269500] global_step=269500, grad_norm=3.0588765144348145, loss=1.1286091804504395
I0303 23:51:54.068836 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:52:05.156458 139953291118400 spec.py:333] Evaluating on the validation split.
I0303 23:52:26.302492 139953291118400 spec.py:349] Evaluating on the test split.
I0303 23:52:27.967034 139953291118400 submission_runner.py:411] Time since start: 129388.14s, 	Step: 269543, 	{'train/accuracy': 0.8866991996765137, 'train/loss': 0.4204760789871216, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 119772.48274731636, 'total_duration': 129388.14326405525, 'accumulated_submission_time': 119772.48274731636, 'accumulated_eval_time': 9584.70620727539, 'accumulated_logging_time': 17.181878328323364}
I0303 23:52:28.025052 139758017697536 logging_writer.py:48] [269543] accumulated_eval_time=9584.706207, accumulated_logging_time=17.181878, accumulated_submission_time=119772.482747, global_step=269543, preemption_count=0, score=119772.482747, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=129388.143264, train/accuracy=0.886699, train/loss=0.420476, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0303 23:52:50.921836 139758009304832 logging_writer.py:48] [269600] global_step=269600, grad_norm=2.906282901763916, loss=2.2177414894104004
I0303 23:53:33.535633 139758017697536 logging_writer.py:48] [269700] global_step=269700, grad_norm=3.195103645324707, loss=1.1004550457000732
I0303 23:54:18.791192 139758009304832 logging_writer.py:48] [269800] global_step=269800, grad_norm=3.5889859199523926, loss=3.130601167678833
I0303 23:55:04.049596 139758017697536 logging_writer.py:48] [269900] global_step=269900, grad_norm=2.9272170066833496, loss=1.2254109382629395
I0303 23:55:49.081927 139758009304832 logging_writer.py:48] [270000] global_step=270000, grad_norm=3.162275552749634, loss=1.0683468580245972
I0303 23:56:34.237022 139758017697536 logging_writer.py:48] [270100] global_step=270100, grad_norm=2.8425116539001465, loss=1.0958105325698853
I0303 23:57:19.389233 139758009304832 logging_writer.py:48] [270200] global_step=270200, grad_norm=3.090728759765625, loss=1.0691629648208618
I0303 23:58:04.872152 139758017697536 logging_writer.py:48] [270300] global_step=270300, grad_norm=3.133369207382202, loss=1.17853844165802
I0303 23:58:49.770941 139758009304832 logging_writer.py:48] [270400] global_step=270400, grad_norm=2.954756259918213, loss=1.4194108247756958
I0303 23:59:28.377528 139953291118400 spec.py:321] Evaluating on the training split.
I0303 23:59:39.694174 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:00:04.045499 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:00:05.683853 139953291118400 submission_runner.py:411] Time since start: 129845.86s, 	Step: 270487, 	{'train/accuracy': 0.88734370470047, 'train/loss': 0.41676583886146545, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 120192.77802968025, 'total_duration': 129845.8600654602, 'accumulated_submission_time': 120192.77802968025, 'accumulated_eval_time': 9622.012517929077, 'accumulated_logging_time': 17.249467372894287}
I0304 00:00:05.752429 139758017697536 logging_writer.py:48] [270487] accumulated_eval_time=9622.012518, accumulated_logging_time=17.249467, accumulated_submission_time=120192.778030, global_step=270487, preemption_count=0, score=120192.778030, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=129845.860065, train/accuracy=0.887344, train/loss=0.416766, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:00:11.280932 139758009304832 logging_writer.py:48] [270500] global_step=270500, grad_norm=3.1461267471313477, loss=1.2618119716644287
I0304 00:00:52.530784 139758017697536 logging_writer.py:48] [270600] global_step=270600, grad_norm=3.043606758117676, loss=1.1043646335601807
I0304 00:01:37.699299 139758009304832 logging_writer.py:48] [270700] global_step=270700, grad_norm=3.032418966293335, loss=1.7464953660964966
I0304 00:02:23.046146 139758017697536 logging_writer.py:48] [270800] global_step=270800, grad_norm=3.1277623176574707, loss=1.4215004444122314
I0304 00:03:08.537280 139758009304832 logging_writer.py:48] [270900] global_step=270900, grad_norm=3.270052194595337, loss=1.1394387483596802
I0304 00:03:53.261705 139758017697536 logging_writer.py:48] [271000] global_step=271000, grad_norm=3.248398780822754, loss=1.873784065246582
I0304 00:04:38.154015 139758009304832 logging_writer.py:48] [271100] global_step=271100, grad_norm=2.895962715148926, loss=0.9807639718055725
I0304 00:05:23.414200 139758017697536 logging_writer.py:48] [271200] global_step=271200, grad_norm=2.7434399127960205, loss=1.2101657390594482
I0304 00:06:08.398311 139758009304832 logging_writer.py:48] [271300] global_step=271300, grad_norm=2.9862451553344727, loss=1.296854019165039
I0304 00:06:53.290803 139758017697536 logging_writer.py:48] [271400] global_step=271400, grad_norm=3.296893835067749, loss=2.516934633255005
I0304 00:07:05.705143 139953291118400 spec.py:321] Evaluating on the training split.
I0304 00:07:16.782499 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:07:41.892153 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:07:43.522366 139953291118400 submission_runner.py:411] Time since start: 130303.70s, 	Step: 271429, 	{'train/accuracy': 0.8888280987739563, 'train/loss': 0.41347870230674744, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 120612.67361688614, 'total_duration': 130303.69858121872, 'accumulated_submission_time': 120612.67361688614, 'accumulated_eval_time': 9659.829708576202, 'accumulated_logging_time': 17.32775592803955}
I0304 00:07:43.595312 139758009304832 logging_writer.py:48] [271429] accumulated_eval_time=9659.829709, accumulated_logging_time=17.327756, accumulated_submission_time=120612.673617, global_step=271429, preemption_count=0, score=120612.673617, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=130303.698581, train/accuracy=0.888828, train/loss=0.413479, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:08:12.019704 139758017697536 logging_writer.py:48] [271500] global_step=271500, grad_norm=3.2058095932006836, loss=1.16609787940979
I0304 00:08:55.996249 139758009304832 logging_writer.py:48] [271600] global_step=271600, grad_norm=3.534308910369873, loss=2.8420143127441406
I0304 00:09:40.914934 139758017697536 logging_writer.py:48] [271700] global_step=271700, grad_norm=3.294084310531616, loss=1.3580734729766846
I0304 00:10:25.777956 139758009304832 logging_writer.py:48] [271800] global_step=271800, grad_norm=3.133296251296997, loss=1.7946010828018188
I0304 00:11:10.576316 139758017697536 logging_writer.py:48] [271900] global_step=271900, grad_norm=3.2118892669677734, loss=1.1519525051116943
I0304 00:11:55.302391 139758009304832 logging_writer.py:48] [272000] global_step=272000, grad_norm=3.0390686988830566, loss=1.458709478378296
I0304 00:12:40.084962 139758017697536 logging_writer.py:48] [272100] global_step=272100, grad_norm=3.158090353012085, loss=1.1424965858459473
I0304 00:13:24.972377 139758009304832 logging_writer.py:48] [272200] global_step=272200, grad_norm=3.2746918201446533, loss=1.3887488842010498
I0304 00:14:09.595625 139758017697536 logging_writer.py:48] [272300] global_step=272300, grad_norm=3.1572701930999756, loss=2.322300672531128
I0304 00:14:43.821593 139953291118400 spec.py:321] Evaluating on the training split.
I0304 00:14:54.954463 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:15:15.304079 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:15:16.943595 139953291118400 submission_runner.py:411] Time since start: 130757.12s, 	Step: 272378, 	{'train/accuracy': 0.8880078196525574, 'train/loss': 0.42393773794174194, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 121032.8384103775, 'total_duration': 130757.11981844902, 'accumulated_submission_time': 121032.8384103775, 'accumulated_eval_time': 9692.951695919037, 'accumulated_logging_time': 17.413233041763306}
I0304 00:15:17.012258 139758009304832 logging_writer.py:48] [272378] accumulated_eval_time=9692.951696, accumulated_logging_time=17.413233, accumulated_submission_time=121032.838410, global_step=272378, preemption_count=0, score=121032.838410, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=130757.119818, train/accuracy=0.888008, train/loss=0.423938, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:15:26.148101 139758017697536 logging_writer.py:48] [272400] global_step=272400, grad_norm=3.250976324081421, loss=1.5266449451446533
I0304 00:16:08.056413 139758009304832 logging_writer.py:48] [272500] global_step=272500, grad_norm=3.1849703788757324, loss=1.0494240522384644
I0304 00:16:53.047174 139758017697536 logging_writer.py:48] [272600] global_step=272600, grad_norm=3.181072950363159, loss=1.2273643016815186
I0304 00:17:37.718557 139758009304832 logging_writer.py:48] [272700] global_step=272700, grad_norm=2.94388747215271, loss=1.579988956451416
I0304 00:18:23.007598 139758017697536 logging_writer.py:48] [272800] global_step=272800, grad_norm=3.141409397125244, loss=1.0989166498184204
I0304 00:19:07.927088 139758009304832 logging_writer.py:48] [272900] global_step=272900, grad_norm=3.2321743965148926, loss=1.0980108976364136
I0304 00:19:52.913354 139758017697536 logging_writer.py:48] [273000] global_step=273000, grad_norm=3.067969560623169, loss=2.2933881282806396
I0304 00:20:38.106815 139758009304832 logging_writer.py:48] [273100] global_step=273100, grad_norm=3.1139111518859863, loss=1.314071536064148
I0304 00:21:23.054178 139758017697536 logging_writer.py:48] [273200] global_step=273200, grad_norm=3.086050510406494, loss=1.3876099586486816
I0304 00:22:07.974143 139758009304832 logging_writer.py:48] [273300] global_step=273300, grad_norm=3.360191822052002, loss=1.1668204069137573
I0304 00:22:17.100652 139953291118400 spec.py:321] Evaluating on the training split.
I0304 00:22:28.326042 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:22:59.019808 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:23:00.643928 139953291118400 submission_runner.py:411] Time since start: 131220.82s, 	Step: 273322, 	{'train/accuracy': 0.886035144329071, 'train/loss': 0.42603519558906555, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 121452.86763739586, 'total_duration': 131220.82015681267, 'accumulated_submission_time': 121452.86763739586, 'accumulated_eval_time': 9736.4949696064, 'accumulated_logging_time': 17.49224090576172}
I0304 00:23:00.699009 139758017697536 logging_writer.py:48] [273322] accumulated_eval_time=9736.494970, accumulated_logging_time=17.492241, accumulated_submission_time=121452.867637, global_step=273322, preemption_count=0, score=121452.867637, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=131220.820157, train/accuracy=0.886035, train/loss=0.426035, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:23:31.861506 139758009304832 logging_writer.py:48] [273400] global_step=273400, grad_norm=3.6769659519195557, loss=3.222609281539917
I0304 00:24:15.766005 139758017697536 logging_writer.py:48] [273500] global_step=273500, grad_norm=2.8548898696899414, loss=1.363703966140747
I0304 00:25:00.567758 139758009304832 logging_writer.py:48] [273600] global_step=273600, grad_norm=3.1701056957244873, loss=1.1228768825531006
I0304 00:25:45.891654 139758017697536 logging_writer.py:48] [273700] global_step=273700, grad_norm=3.6518781185150146, loss=3.278956413269043
I0304 00:26:30.897731 139758009304832 logging_writer.py:48] [273800] global_step=273800, grad_norm=2.9813714027404785, loss=1.056976318359375
I0304 00:27:15.765394 139758017697536 logging_writer.py:48] [273900] global_step=273900, grad_norm=3.4493112564086914, loss=1.2511584758758545
I0304 00:28:00.821741 139758009304832 logging_writer.py:48] [274000] global_step=274000, grad_norm=2.8032548427581787, loss=1.5012896060943604
I0304 00:28:45.592170 139758017697536 logging_writer.py:48] [274100] global_step=274100, grad_norm=3.211677074432373, loss=1.5758157968521118
I0304 00:29:30.356227 139758009304832 logging_writer.py:48] [274200] global_step=274200, grad_norm=2.8055074214935303, loss=1.058248519897461
I0304 00:30:00.864261 139953291118400 spec.py:321] Evaluating on the training split.
I0304 00:30:11.839888 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:30:34.015775 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:30:35.648975 139953291118400 submission_runner.py:411] Time since start: 131675.83s, 	Step: 274270, 	{'train/accuracy': 0.8879492282867432, 'train/loss': 0.4197743535041809, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 121872.97571897507, 'total_duration': 131675.82518553734, 'accumulated_submission_time': 121872.97571897507, 'accumulated_eval_time': 9771.279657840729, 'accumulated_logging_time': 17.556384801864624}
I0304 00:30:35.720326 139758017697536 logging_writer.py:48] [274270] accumulated_eval_time=9771.279658, accumulated_logging_time=17.556385, accumulated_submission_time=121872.975719, global_step=274270, preemption_count=0, score=121872.975719, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=131675.825186, train/accuracy=0.887949, train/loss=0.419774, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:30:48.005052 139758009304832 logging_writer.py:48] [274300] global_step=274300, grad_norm=3.225145101547241, loss=1.1801636219024658
I0304 00:31:29.984260 139758017697536 logging_writer.py:48] [274400] global_step=274400, grad_norm=3.053621530532837, loss=1.1865533590316772
I0304 00:32:15.317688 139758009304832 logging_writer.py:48] [274500] global_step=274500, grad_norm=3.014718532562256, loss=1.1098523139953613
I0304 00:33:00.335956 139758017697536 logging_writer.py:48] [274600] global_step=274600, grad_norm=3.991995334625244, loss=3.161093235015869
I0304 00:33:45.295314 139758009304832 logging_writer.py:48] [274700] global_step=274700, grad_norm=2.8531289100646973, loss=2.04693603515625
I0304 00:34:30.362744 139758017697536 logging_writer.py:48] [274800] global_step=274800, grad_norm=3.0007636547088623, loss=1.3083679676055908
I0304 00:35:15.053102 139758009304832 logging_writer.py:48] [274900] global_step=274900, grad_norm=3.1660943031311035, loss=1.3891239166259766
I0304 00:36:00.044077 139758017697536 logging_writer.py:48] [275000] global_step=275000, grad_norm=3.0600404739379883, loss=2.0416853427886963
I0304 00:36:45.135653 139758009304832 logging_writer.py:48] [275100] global_step=275100, grad_norm=3.063021659851074, loss=1.0610969066619873
I0304 00:37:30.261348 139758017697536 logging_writer.py:48] [275200] global_step=275200, grad_norm=3.0576601028442383, loss=2.1392338275909424
I0304 00:37:36.052355 139953291118400 spec.py:321] Evaluating on the training split.
I0304 00:37:47.418734 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:38:10.546050 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:38:12.179132 139953291118400 submission_runner.py:411] Time since start: 132132.36s, 	Step: 275215, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.4141191244125366, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 122293.25101804733, 'total_duration': 132132.355342865, 'accumulated_submission_time': 122293.25101804733, 'accumulated_eval_time': 9807.406393289566, 'accumulated_logging_time': 17.63720178604126}
I0304 00:38:12.247573 139758009304832 logging_writer.py:48] [275215] accumulated_eval_time=9807.406393, accumulated_logging_time=17.637202, accumulated_submission_time=122293.251018, global_step=275215, preemption_count=0, score=122293.251018, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=132132.355343, train/accuracy=0.888144, train/loss=0.414119, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:38:46.351667 139758017697536 logging_writer.py:48] [275300] global_step=275300, grad_norm=3.1167995929718018, loss=1.2519173622131348
I0304 00:39:31.587065 139758009304832 logging_writer.py:48] [275400] global_step=275400, grad_norm=3.254591226577759, loss=1.0466935634613037
I0304 00:40:16.943059 139758017697536 logging_writer.py:48] [275500] global_step=275500, grad_norm=3.2458722591400146, loss=2.1285910606384277
I0304 00:41:02.635928 139758009304832 logging_writer.py:48] [275600] global_step=275600, grad_norm=2.976019859313965, loss=1.115050196647644
I0304 00:41:47.329360 139758017697536 logging_writer.py:48] [275700] global_step=275700, grad_norm=3.2377231121063232, loss=1.1324580907821655
I0304 00:42:32.553255 139758009304832 logging_writer.py:48] [275800] global_step=275800, grad_norm=3.1440837383270264, loss=1.3672665357589722
I0304 00:43:17.795162 139758017697536 logging_writer.py:48] [275900] global_step=275900, grad_norm=3.1972568035125732, loss=1.4884060621261597
I0304 00:44:02.862132 139758009304832 logging_writer.py:48] [276000] global_step=276000, grad_norm=3.2843267917633057, loss=1.183304786682129
I0304 00:44:47.366462 139758017697536 logging_writer.py:48] [276100] global_step=276100, grad_norm=3.071225643157959, loss=1.4642413854599
I0304 00:45:12.578978 139953291118400 spec.py:321] Evaluating on the training split.
I0304 00:45:23.541805 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:45:43.524294 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:45:45.165655 139953291118400 submission_runner.py:411] Time since start: 132585.34s, 	Step: 276158, 	{'train/accuracy': 0.8878515362739563, 'train/loss': 0.41557222604751587, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 122713.52501344681, 'total_duration': 132585.34187698364, 'accumulated_submission_time': 122713.52501344681, 'accumulated_eval_time': 9839.993040561676, 'accumulated_logging_time': 17.716108798980713}
I0304 00:45:45.235205 139758009304832 logging_writer.py:48] [276158] accumulated_eval_time=9839.993041, accumulated_logging_time=17.716109, accumulated_submission_time=122713.525013, global_step=276158, preemption_count=0, score=122713.525013, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=132585.341877, train/accuracy=0.887852, train/loss=0.415572, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:46:02.405516 139758017697536 logging_writer.py:48] [276200] global_step=276200, grad_norm=3.4138638973236084, loss=2.9579594135284424
I0304 00:46:45.544810 139758009304832 logging_writer.py:48] [276300] global_step=276300, grad_norm=3.1285881996154785, loss=1.1718474626541138
I0304 00:47:30.658223 139758017697536 logging_writer.py:48] [276400] global_step=276400, grad_norm=3.1709249019622803, loss=1.1043885946273804
I0304 00:48:15.837256 139758009304832 logging_writer.py:48] [276500] global_step=276500, grad_norm=3.349825143814087, loss=2.343099594116211
I0304 00:49:00.967927 139758017697536 logging_writer.py:48] [276600] global_step=276600, grad_norm=2.8997318744659424, loss=1.134805679321289
I0304 00:49:45.918653 139758009304832 logging_writer.py:48] [276700] global_step=276700, grad_norm=3.0789225101470947, loss=2.6057193279266357
I0304 00:50:30.893959 139758017697536 logging_writer.py:48] [276800] global_step=276800, grad_norm=3.311875343322754, loss=2.7445485591888428
I0304 00:51:15.940976 139758009304832 logging_writer.py:48] [276900] global_step=276900, grad_norm=3.376617670059204, loss=2.7542178630828857
I0304 00:52:00.935332 139758017697536 logging_writer.py:48] [277000] global_step=277000, grad_norm=3.4988291263580322, loss=2.6997249126434326
I0304 00:52:45.434561 139953291118400 spec.py:321] Evaluating on the training split.
I0304 00:52:56.453149 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 00:53:20.704004 139953291118400 spec.py:349] Evaluating on the test split.
I0304 00:53:22.344531 139953291118400 submission_runner.py:411] Time since start: 133042.52s, 	Step: 277100, 	{'train/accuracy': 0.8867968320846558, 'train/loss': 0.4192649722099304, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 123133.66612696648, 'total_duration': 133042.52073717117, 'accumulated_submission_time': 123133.66612696648, 'accumulated_eval_time': 9876.90296959877, 'accumulated_logging_time': 17.7959988117218}
I0304 00:53:22.414154 139758009304832 logging_writer.py:48] [277100] accumulated_eval_time=9876.902970, accumulated_logging_time=17.795999, accumulated_submission_time=123133.666127, global_step=277100, preemption_count=0, score=123133.666127, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=133042.520737, train/accuracy=0.886797, train/loss=0.419265, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 00:53:22.819752 139758017697536 logging_writer.py:48] [277100] global_step=277100, grad_norm=3.021838665008545, loss=1.1547186374664307
I0304 00:54:03.297172 139758009304832 logging_writer.py:48] [277200] global_step=277200, grad_norm=3.0140135288238525, loss=1.4016860723495483
I0304 00:54:48.185272 139758017697536 logging_writer.py:48] [277300] global_step=277300, grad_norm=3.6723427772521973, loss=3.1326327323913574
I0304 00:55:33.191056 139758009304832 logging_writer.py:48] [277400] global_step=277400, grad_norm=2.9664254188537598, loss=2.1339354515075684
I0304 00:56:18.593983 139758017697536 logging_writer.py:48] [277500] global_step=277500, grad_norm=3.0743567943573, loss=1.689622402191162
I0304 00:57:03.454296 139758009304832 logging_writer.py:48] [277600] global_step=277600, grad_norm=3.0897560119628906, loss=1.315675973892212
I0304 00:57:48.412365 139758017697536 logging_writer.py:48] [277700] global_step=277700, grad_norm=3.136760950088501, loss=1.0833014249801636
I0304 00:58:33.862070 139758009304832 logging_writer.py:48] [277800] global_step=277800, grad_norm=3.241701126098633, loss=1.0648231506347656
I0304 00:59:19.246185 139758017697536 logging_writer.py:48] [277900] global_step=277900, grad_norm=3.031968593597412, loss=1.9201345443725586
I0304 01:00:04.339511 139758009304832 logging_writer.py:48] [278000] global_step=278000, grad_norm=3.371931791305542, loss=1.695844054222107
I0304 01:00:22.369662 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:00:33.314644 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:00:59.700797 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:01:01.339318 139953291118400 submission_runner.py:411] Time since start: 133501.52s, 	Step: 278042, 	{'train/accuracy': 0.8861327767372131, 'train/loss': 0.4243049621582031, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 123553.5646944046, 'total_duration': 133501.51552557945, 'accumulated_submission_time': 123553.5646944046, 'accumulated_eval_time': 9915.872620105743, 'accumulated_logging_time': 17.875136137008667}
I0304 01:01:01.405730 139758017697536 logging_writer.py:48] [278042] accumulated_eval_time=9915.872620, accumulated_logging_time=17.875136, accumulated_submission_time=123553.564694, global_step=278042, preemption_count=0, score=123553.564694, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=133501.515526, train/accuracy=0.886133, train/loss=0.424305, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:01:24.669290 139758009304832 logging_writer.py:48] [278100] global_step=278100, grad_norm=3.2597100734710693, loss=1.2942866086959839
I0304 01:02:08.101556 139758017697536 logging_writer.py:48] [278200] global_step=278200, grad_norm=2.9919888973236084, loss=1.0798463821411133
I0304 01:02:53.010962 139758009304832 logging_writer.py:48] [278300] global_step=278300, grad_norm=3.2290453910827637, loss=1.1523137092590332
I0304 01:03:38.325740 139758017697536 logging_writer.py:48] [278400] global_step=278400, grad_norm=3.85834002494812, loss=3.0551939010620117
I0304 01:04:23.433630 139758009304832 logging_writer.py:48] [278500] global_step=278500, grad_norm=3.1687231063842773, loss=1.1509439945220947
I0304 01:05:08.407585 139758017697536 logging_writer.py:48] [278600] global_step=278600, grad_norm=3.3105666637420654, loss=2.9074485301971436
I0304 01:05:53.474083 139758009304832 logging_writer.py:48] [278700] global_step=278700, grad_norm=4.834256172180176, loss=3.198256492614746
I0304 01:06:38.669260 139758017697536 logging_writer.py:48] [278800] global_step=278800, grad_norm=2.9886043071746826, loss=1.408376693725586
I0304 01:07:23.524060 139758017697536 logging_writer.py:48] [278900] global_step=278900, grad_norm=3.096836566925049, loss=2.0967109203338623
I0304 01:08:01.390641 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:08:12.290053 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:08:36.656951 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:08:38.290281 139953291118400 submission_runner.py:411] Time since start: 133958.47s, 	Step: 278985, 	{'train/accuracy': 0.8908007740974426, 'train/loss': 0.41217437386512756, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 123973.49132466316, 'total_duration': 133958.46650099754, 'accumulated_submission_time': 123973.49132466316, 'accumulated_eval_time': 9952.77225279808, 'accumulated_logging_time': 17.952096462249756}
I0304 01:08:38.363163 139758009304832 logging_writer.py:48] [278985] accumulated_eval_time=9952.772253, accumulated_logging_time=17.952096, accumulated_submission_time=123973.491325, global_step=278985, preemption_count=0, score=123973.491325, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=133958.466501, train/accuracy=0.890801, train/loss=0.412174, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:08:44.691144 139758017697536 logging_writer.py:48] [279000] global_step=279000, grad_norm=3.062976121902466, loss=1.6113762855529785
I0304 01:09:26.089356 139758009304832 logging_writer.py:48] [279100] global_step=279100, grad_norm=2.9166696071624756, loss=1.1749534606933594
I0304 01:10:10.987359 139758017697536 logging_writer.py:48] [279200] global_step=279200, grad_norm=3.0830163955688477, loss=1.4673397541046143
I0304 01:10:55.883675 139758009304832 logging_writer.py:48] [279300] global_step=279300, grad_norm=3.0426506996154785, loss=1.1546825170516968
I0304 01:11:40.826516 139758017697536 logging_writer.py:48] [279400] global_step=279400, grad_norm=3.30584454536438, loss=1.0941907167434692
I0304 01:12:25.591718 139758009304832 logging_writer.py:48] [279500] global_step=279500, grad_norm=3.5235488414764404, loss=1.0690712928771973
I0304 01:13:10.498348 139758017697536 logging_writer.py:48] [279600] global_step=279600, grad_norm=3.0354738235473633, loss=1.1293394565582275
I0304 01:13:55.447206 139758009304832 logging_writer.py:48] [279700] global_step=279700, grad_norm=3.127214193344116, loss=1.1346594095230103
I0304 01:14:40.324803 139758017697536 logging_writer.py:48] [279800] global_step=279800, grad_norm=3.0511491298675537, loss=1.7049510478973389
I0304 01:15:25.158529 139758009304832 logging_writer.py:48] [279900] global_step=279900, grad_norm=2.9407460689544678, loss=1.5202381610870361
I0304 01:15:38.339138 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:15:49.608894 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:16:19.607210 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:16:21.232807 139953291118400 submission_runner.py:411] Time since start: 134421.41s, 	Step: 279931, 	{'train/accuracy': 0.8890624642372131, 'train/loss': 0.42041730880737305, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 124393.40948843956, 'total_duration': 134421.4090359211, 'accumulated_submission_time': 124393.40948843956, 'accumulated_eval_time': 9995.665901184082, 'accumulated_logging_time': 18.035025119781494}
I0304 01:16:21.289514 139758017697536 logging_writer.py:48] [279931] accumulated_eval_time=9995.665901, accumulated_logging_time=18.035025, accumulated_submission_time=124393.409488, global_step=279931, preemption_count=0, score=124393.409488, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=134421.409036, train/accuracy=0.889062, train/loss=0.420417, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:16:48.908049 139758009304832 logging_writer.py:48] [280000] global_step=280000, grad_norm=2.840524673461914, loss=1.0418329238891602
I0304 01:17:32.257727 139758017697536 logging_writer.py:48] [280100] global_step=280100, grad_norm=2.8145649433135986, loss=1.0002546310424805
I0304 01:18:17.261464 139758009304832 logging_writer.py:48] [280200] global_step=280200, grad_norm=2.9202897548675537, loss=1.8796688318252563
I0304 01:19:02.683200 139758017697536 logging_writer.py:48] [280300] global_step=280300, grad_norm=3.0448739528656006, loss=2.665648937225342
I0304 01:19:47.354213 139758009304832 logging_writer.py:48] [280400] global_step=280400, grad_norm=3.308236837387085, loss=2.566495418548584
I0304 01:20:32.438060 139758017697536 logging_writer.py:48] [280500] global_step=280500, grad_norm=3.6371262073516846, loss=3.020620822906494
I0304 01:21:17.374439 139758009304832 logging_writer.py:48] [280600] global_step=280600, grad_norm=3.1000046730041504, loss=1.105796217918396
I0304 01:22:02.216686 139758017697536 logging_writer.py:48] [280700] global_step=280700, grad_norm=3.530453681945801, loss=2.227567672729492
I0304 01:22:47.032094 139758009304832 logging_writer.py:48] [280800] global_step=280800, grad_norm=3.445568799972534, loss=2.902894973754883
I0304 01:23:21.297790 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:23:32.190796 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:23:53.130949 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:23:54.765062 139953291118400 submission_runner.py:411] Time since start: 134874.94s, 	Step: 280878, 	{'train/accuracy': 0.8887109160423279, 'train/loss': 0.41241180896759033, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 124813.36013317108, 'total_duration': 134874.94128251076, 'accumulated_submission_time': 124813.36013317108, 'accumulated_eval_time': 10029.1331782341, 'accumulated_logging_time': 18.101533889770508}
I0304 01:23:54.835561 139758017697536 logging_writer.py:48] [280878] accumulated_eval_time=10029.133178, accumulated_logging_time=18.101534, accumulated_submission_time=124813.360133, global_step=280878, preemption_count=0, score=124813.360133, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=134874.941283, train/accuracy=0.888711, train/loss=0.412412, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:24:03.926489 139758009304832 logging_writer.py:48] [280900] global_step=280900, grad_norm=3.0756590366363525, loss=1.1372666358947754
I0304 01:24:45.485915 139758017697536 logging_writer.py:48] [281000] global_step=281000, grad_norm=3.0407724380493164, loss=1.3174052238464355
I0304 01:25:30.239127 139758009304832 logging_writer.py:48] [281100] global_step=281100, grad_norm=3.1734812259674072, loss=1.1326112747192383
I0304 01:26:15.563948 139758017697536 logging_writer.py:48] [281200] global_step=281200, grad_norm=3.1525495052337646, loss=1.1410561800003052
I0304 01:27:00.663732 139758009304832 logging_writer.py:48] [281300] global_step=281300, grad_norm=2.9561522006988525, loss=1.3304859399795532
I0304 01:27:45.453023 139758017697536 logging_writer.py:48] [281400] global_step=281400, grad_norm=3.0929579734802246, loss=1.320549488067627
I0304 01:28:30.468977 139758009304832 logging_writer.py:48] [281500] global_step=281500, grad_norm=3.2042477130889893, loss=2.4763565063476562
I0304 01:29:15.544965 139758017697536 logging_writer.py:48] [281600] global_step=281600, grad_norm=3.088610887527466, loss=1.355160117149353
I0304 01:30:00.148566 139758009304832 logging_writer.py:48] [281700] global_step=281700, grad_norm=3.0907702445983887, loss=1.1170706748962402
I0304 01:30:45.317464 139758017697536 logging_writer.py:48] [281800] global_step=281800, grad_norm=3.1046836376190186, loss=1.1855101585388184
I0304 01:30:54.857338 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:31:06.285948 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:31:28.081927 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:31:29.745934 139953291118400 submission_runner.py:411] Time since start: 135329.92s, 	Step: 281823, 	{'train/accuracy': 0.8863085508346558, 'train/loss': 0.41746875643730164, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 125233.32454299927, 'total_duration': 135329.92215943336, 'accumulated_submission_time': 125233.32454299927, 'accumulated_eval_time': 10064.021770715714, 'accumulated_logging_time': 18.181446075439453}
I0304 01:31:29.802304 139758009304832 logging_writer.py:48] [281823] accumulated_eval_time=10064.021771, accumulated_logging_time=18.181446, accumulated_submission_time=125233.324543, global_step=281823, preemption_count=0, score=125233.324543, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=135329.922159, train/accuracy=0.886309, train/loss=0.417469, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:32:00.620559 139758017697536 logging_writer.py:48] [281900] global_step=281900, grad_norm=2.8839547634124756, loss=2.3521311283111572
I0304 01:32:44.280066 139758009304832 logging_writer.py:48] [282000] global_step=282000, grad_norm=3.190218925476074, loss=2.0183417797088623
I0304 01:33:29.066841 139758017697536 logging_writer.py:48] [282100] global_step=282100, grad_norm=2.8185815811157227, loss=1.3900924921035767
I0304 01:34:14.427975 139758009304832 logging_writer.py:48] [282200] global_step=282200, grad_norm=3.06046199798584, loss=2.0899815559387207
I0304 01:34:59.101649 139758017697536 logging_writer.py:48] [282300] global_step=282300, grad_norm=3.040032148361206, loss=1.5659699440002441
I0304 01:35:44.256650 139758009304832 logging_writer.py:48] [282400] global_step=282400, grad_norm=3.1606128215789795, loss=1.2282536029815674
I0304 01:36:29.561690 139758017697536 logging_writer.py:48] [282500] global_step=282500, grad_norm=3.1216485500335693, loss=2.4144392013549805
I0304 01:37:14.669168 139758009304832 logging_writer.py:48] [282600] global_step=282600, grad_norm=3.376038074493408, loss=2.937930107116699
I0304 01:37:59.728945 139758017697536 logging_writer.py:48] [282700] global_step=282700, grad_norm=3.012037515640259, loss=0.9868665933609009
I0304 01:38:30.036049 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:38:41.778033 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:38:59.932269 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:39:01.561433 139953291118400 submission_runner.py:411] Time since start: 135781.74s, 	Step: 282769, 	{'train/accuracy': 0.8883593678474426, 'train/loss': 0.4142705202102661, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 125653.50318288803, 'total_duration': 135781.73765468597, 'accumulated_submission_time': 125653.50318288803, 'accumulated_eval_time': 10095.547145366669, 'accumulated_logging_time': 18.245970249176025}
I0304 01:39:01.634583 139758009304832 logging_writer.py:48] [282769] accumulated_eval_time=10095.547145, accumulated_logging_time=18.245970, accumulated_submission_time=125653.503183, global_step=282769, preemption_count=0, score=125653.503183, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=135781.737655, train/accuracy=0.888359, train/loss=0.414271, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:39:14.302074 139758017697536 logging_writer.py:48] [282800] global_step=282800, grad_norm=3.135377883911133, loss=2.5743050575256348
I0304 01:39:56.866209 139758009304832 logging_writer.py:48] [282900] global_step=282900, grad_norm=3.061448574066162, loss=1.6347577571868896
I0304 01:40:42.460313 139758017697536 logging_writer.py:48] [283000] global_step=283000, grad_norm=3.2692620754241943, loss=1.065503716468811
I0304 01:41:27.694050 139758009304832 logging_writer.py:48] [283100] global_step=283100, grad_norm=2.9181506633758545, loss=1.0601040124893188
I0304 01:42:12.785881 139758017697536 logging_writer.py:48] [283200] global_step=283200, grad_norm=3.2137489318847656, loss=1.1334010362625122
I0304 01:42:57.971079 139758009304832 logging_writer.py:48] [283300] global_step=283300, grad_norm=3.155341863632202, loss=1.1390011310577393
I0304 01:43:42.906618 139758017697536 logging_writer.py:48] [283400] global_step=283400, grad_norm=3.3337903022766113, loss=1.1305265426635742
I0304 01:44:27.681782 139758009304832 logging_writer.py:48] [283500] global_step=283500, grad_norm=3.5118613243103027, loss=3.133525848388672
I0304 01:45:12.507103 139758017697536 logging_writer.py:48] [283600] global_step=283600, grad_norm=3.173617362976074, loss=1.983882188796997
I0304 01:45:57.471493 139758009304832 logging_writer.py:48] [283700] global_step=283700, grad_norm=3.0389208793640137, loss=1.1833856105804443
I0304 01:46:01.636929 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:46:13.092778 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:46:46.007792 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:46:47.627299 139953291118400 submission_runner.py:411] Time since start: 136247.80s, 	Step: 283711, 	{'train/accuracy': 0.8863866925239563, 'train/loss': 0.4193476140499115, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 126073.44761157036, 'total_duration': 136247.80353331566, 'accumulated_submission_time': 126073.44761157036, 'accumulated_eval_time': 10141.53751373291, 'accumulated_logging_time': 18.329392433166504}
I0304 01:46:47.683475 139758017697536 logging_writer.py:48] [283711] accumulated_eval_time=10141.537514, accumulated_logging_time=18.329392, accumulated_submission_time=126073.447612, global_step=283711, preemption_count=0, score=126073.447612, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=136247.803533, train/accuracy=0.886387, train/loss=0.419348, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:47:23.402415 139758009304832 logging_writer.py:48] [283800] global_step=283800, grad_norm=3.576535701751709, loss=2.027442455291748
I0304 01:48:07.720310 139758017697536 logging_writer.py:48] [283900] global_step=283900, grad_norm=3.76072359085083, loss=3.1388814449310303
I0304 01:48:52.773455 139758009304832 logging_writer.py:48] [284000] global_step=284000, grad_norm=3.4661505222320557, loss=2.128829002380371
I0304 01:49:38.460539 139758017697536 logging_writer.py:48] [284100] global_step=284100, grad_norm=3.19094181060791, loss=1.2914037704467773
I0304 01:50:23.374680 139758009304832 logging_writer.py:48] [284200] global_step=284200, grad_norm=3.0839056968688965, loss=1.2286430597305298
I0304 01:51:08.757485 139758017697536 logging_writer.py:48] [284300] global_step=284300, grad_norm=3.2453105449676514, loss=2.54175066947937
I0304 01:51:53.833750 139758009304832 logging_writer.py:48] [284400] global_step=284400, grad_norm=4.179361343383789, loss=1.1971423625946045
I0304 01:52:38.836477 139758017697536 logging_writer.py:48] [284500] global_step=284500, grad_norm=2.90911865234375, loss=1.2503645420074463
I0304 01:53:23.776758 139758009304832 logging_writer.py:48] [284600] global_step=284600, grad_norm=2.9220492839813232, loss=1.3186118602752686
I0304 01:53:47.795988 139953291118400 spec.py:321] Evaluating on the training split.
I0304 01:53:58.470407 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 01:54:19.355720 139953291118400 spec.py:349] Evaluating on the test split.
I0304 01:54:20.985533 139953291118400 submission_runner.py:411] Time since start: 136701.16s, 	Step: 284655, 	{'train/accuracy': 0.8861523270606995, 'train/loss': 0.4190988838672638, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 126493.50467848778, 'total_duration': 136701.16173362732, 'accumulated_submission_time': 126493.50467848778, 'accumulated_eval_time': 10174.727008581161, 'accumulated_logging_time': 18.393612146377563}
I0304 01:54:21.062091 139758017697536 logging_writer.py:48] [284655] accumulated_eval_time=10174.727009, accumulated_logging_time=18.393612, accumulated_submission_time=126493.504678, global_step=284655, preemption_count=0, score=126493.504678, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=136701.161734, train/accuracy=0.886152, train/loss=0.419099, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 01:54:39.240832 139758009304832 logging_writer.py:48] [284700] global_step=284700, grad_norm=3.146629571914673, loss=2.2674927711486816
I0304 01:55:22.256702 139758017697536 logging_writer.py:48] [284800] global_step=284800, grad_norm=3.5218214988708496, loss=2.6436448097229004
I0304 01:56:07.399433 139758009304832 logging_writer.py:48] [284900] global_step=284900, grad_norm=3.409166097640991, loss=2.76324725151062
I0304 01:56:52.622227 139758017697536 logging_writer.py:48] [285000] global_step=285000, grad_norm=2.9707419872283936, loss=1.0306297540664673
I0304 01:57:37.643635 139758009304832 logging_writer.py:48] [285100] global_step=285100, grad_norm=3.6203017234802246, loss=2.9379937648773193
I0304 01:58:22.535816 139758017697536 logging_writer.py:48] [285200] global_step=285200, grad_norm=3.1304996013641357, loss=1.6592674255371094
I0304 01:59:07.707549 139758009304832 logging_writer.py:48] [285300] global_step=285300, grad_norm=2.8447670936584473, loss=1.0962671041488647
I0304 01:59:52.480379 139758017697536 logging_writer.py:48] [285400] global_step=285400, grad_norm=3.978963613510132, loss=3.2056751251220703
I0304 02:00:37.407436 139758009304832 logging_writer.py:48] [285500] global_step=285500, grad_norm=3.0950217247009277, loss=2.0869131088256836
I0304 02:01:21.130766 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:01:32.424130 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:02:01.983047 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:02:03.615284 139953291118400 submission_runner.py:411] Time since start: 137163.79s, 	Step: 285599, 	{'train/accuracy': 0.8877733945846558, 'train/loss': 0.4184274971485138, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 126913.51318049431, 'total_duration': 137163.79151773453, 'accumulated_submission_time': 126913.51318049431, 'accumulated_eval_time': 10217.211532592773, 'accumulated_logging_time': 18.482458353042603}
I0304 02:02:03.676880 139758017697536 logging_writer.py:48] [285599] accumulated_eval_time=10217.211533, accumulated_logging_time=18.482458, accumulated_submission_time=126913.513180, global_step=285599, preemption_count=0, score=126913.513180, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=137163.791518, train/accuracy=0.887773, train/loss=0.418427, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:02:04.470378 139758009304832 logging_writer.py:48] [285600] global_step=285600, grad_norm=3.167259454727173, loss=2.003826856613159
I0304 02:02:44.198708 139758017697536 logging_writer.py:48] [285700] global_step=285700, grad_norm=3.3154475688934326, loss=1.1481081247329712
I0304 02:03:29.125974 139758009304832 logging_writer.py:48] [285800] global_step=285800, grad_norm=3.0394370555877686, loss=2.098207950592041
I0304 02:04:14.204282 139758017697536 logging_writer.py:48] [285900] global_step=285900, grad_norm=3.0358614921569824, loss=2.257880926132202
I0304 02:04:59.473295 139758009304832 logging_writer.py:48] [286000] global_step=286000, grad_norm=3.273198366165161, loss=1.154357671737671
I0304 02:05:44.263530 139758017697536 logging_writer.py:48] [286100] global_step=286100, grad_norm=3.343641996383667, loss=1.0852563381195068
I0304 02:06:29.368225 139758009304832 logging_writer.py:48] [286200] global_step=286200, grad_norm=2.9268126487731934, loss=1.1198190450668335
I0304 02:07:14.546905 139758017697536 logging_writer.py:48] [286300] global_step=286300, grad_norm=3.1642887592315674, loss=2.795600414276123
I0304 02:07:59.337138 139758009304832 logging_writer.py:48] [286400] global_step=286400, grad_norm=3.5175559520721436, loss=3.1353821754455566
I0304 02:08:44.669570 139758017697536 logging_writer.py:48] [286500] global_step=286500, grad_norm=2.9958620071411133, loss=1.4990265369415283
I0304 02:09:03.876883 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:09:14.994879 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:09:41.503502 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:09:43.127599 139953291118400 submission_runner.py:411] Time since start: 137623.30s, 	Step: 286544, 	{'train/accuracy': 0.8854687213897705, 'train/loss': 0.426918625831604, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 127333.65675115585, 'total_duration': 137623.30382800102, 'accumulated_submission_time': 127333.65675115585, 'accumulated_eval_time': 10256.46224308014, 'accumulated_logging_time': 18.553510189056396}
I0304 02:09:43.185613 139758009304832 logging_writer.py:48] [286544] accumulated_eval_time=10256.462243, accumulated_logging_time=18.553510, accumulated_submission_time=127333.656751, global_step=286544, preemption_count=0, score=127333.656751, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=137623.303828, train/accuracy=0.885469, train/loss=0.426919, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:10:05.688655 139758017697536 logging_writer.py:48] [286600] global_step=286600, grad_norm=3.176692008972168, loss=1.1692023277282715
I0304 02:10:48.340748 139758009304832 logging_writer.py:48] [286700] global_step=286700, grad_norm=3.004972457885742, loss=1.1244785785675049
I0304 02:11:33.092441 139758017697536 logging_writer.py:48] [286800] global_step=286800, grad_norm=3.5261735916137695, loss=1.1639577150344849
I0304 02:12:18.167544 139758009304832 logging_writer.py:48] [286900] global_step=286900, grad_norm=3.1864166259765625, loss=1.1267985105514526
I0304 02:13:03.405027 139758017697536 logging_writer.py:48] [287000] global_step=287000, grad_norm=2.9933950901031494, loss=1.3859033584594727
I0304 02:13:48.179739 139758009304832 logging_writer.py:48] [287100] global_step=287100, grad_norm=3.993784189224243, loss=3.2809641361236572
I0304 02:14:33.218602 139758017697536 logging_writer.py:48] [287200] global_step=287200, grad_norm=3.0544567108154297, loss=0.9744762182235718
I0304 02:15:17.988352 139758009304832 logging_writer.py:48] [287300] global_step=287300, grad_norm=3.3453431129455566, loss=2.8589911460876465
I0304 02:16:03.867340 139758017697536 logging_writer.py:48] [287400] global_step=287400, grad_norm=3.563204765319824, loss=2.9905757904052734
I0304 02:16:43.336902 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:16:54.865323 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:17:17.837778 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:17:19.479448 139953291118400 submission_runner.py:411] Time since start: 138079.66s, 	Step: 287489, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.4195753335952759, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 127753.75061297417, 'total_duration': 138079.65566945076, 'accumulated_submission_time': 127753.75061297417, 'accumulated_eval_time': 10292.60477733612, 'accumulated_logging_time': 18.62070345878601}
I0304 02:17:19.553693 139758009304832 logging_writer.py:48] [287489] accumulated_eval_time=10292.604777, accumulated_logging_time=18.620703, accumulated_submission_time=127753.750613, global_step=287489, preemption_count=0, score=127753.750613, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=138079.655669, train/accuracy=0.887461, train/loss=0.419575, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:17:24.324201 139758017697536 logging_writer.py:48] [287500] global_step=287500, grad_norm=3.4410533905029297, loss=1.6464061737060547
I0304 02:18:06.778508 139758009304832 logging_writer.py:48] [287600] global_step=287600, grad_norm=4.027263164520264, loss=3.2796597480773926
I0304 02:18:51.792819 139758017697536 logging_writer.py:48] [287700] global_step=287700, grad_norm=2.9432320594787598, loss=1.0086663961410522
I0304 02:19:37.411873 139758009304832 logging_writer.py:48] [287800] global_step=287800, grad_norm=3.557404041290283, loss=2.0189409255981445
I0304 02:20:22.772680 139758017697536 logging_writer.py:48] [287900] global_step=287900, grad_norm=3.0586633682250977, loss=1.4052050113677979
I0304 02:21:08.032540 139758009304832 logging_writer.py:48] [288000] global_step=288000, grad_norm=3.1583168506622314, loss=1.250863790512085
I0304 02:21:53.234775 139758017697536 logging_writer.py:48] [288100] global_step=288100, grad_norm=2.911829948425293, loss=2.154177188873291
I0304 02:22:38.518825 139758009304832 logging_writer.py:48] [288200] global_step=288200, grad_norm=3.5843400955200195, loss=2.835644006729126
I0304 02:23:24.031799 139758017697536 logging_writer.py:48] [288300] global_step=288300, grad_norm=3.0147173404693604, loss=1.3165191411972046
I0304 02:24:09.268610 139758009304832 logging_writer.py:48] [288400] global_step=288400, grad_norm=3.4317219257354736, loss=2.3860716819763184
I0304 02:24:19.872250 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:24:30.964674 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:24:57.888608 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:24:59.524563 139953291118400 submission_runner.py:411] Time since start: 138539.70s, 	Step: 288425, 	{'train/accuracy': 0.88525390625, 'train/loss': 0.42437833547592163, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 128174.01127171516, 'total_duration': 138539.70076584816, 'accumulated_submission_time': 128174.01127171516, 'accumulated_eval_time': 10332.257049798965, 'accumulated_logging_time': 18.705175638198853}
I0304 02:24:59.596040 139758017697536 logging_writer.py:48] [288425] accumulated_eval_time=10332.257050, accumulated_logging_time=18.705176, accumulated_submission_time=128174.011272, global_step=288425, preemption_count=0, score=128174.011272, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=138539.700766, train/accuracy=0.885254, train/loss=0.424378, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:25:29.617658 139758009304832 logging_writer.py:48] [288500] global_step=288500, grad_norm=2.9613406658172607, loss=1.6954848766326904
I0304 02:26:13.921483 139758017697536 logging_writer.py:48] [288600] global_step=288600, grad_norm=3.2443325519561768, loss=2.181746006011963
I0304 02:26:59.050732 139758009304832 logging_writer.py:48] [288700] global_step=288700, grad_norm=3.709000825881958, loss=3.4101107120513916
I0304 02:27:44.562017 139758017697536 logging_writer.py:48] [288800] global_step=288800, grad_norm=3.358590602874756, loss=1.1364682912826538
I0304 02:28:29.554575 139758009304832 logging_writer.py:48] [288900] global_step=288900, grad_norm=3.135190010070801, loss=1.0675015449523926
I0304 02:29:14.999844 139758017697536 logging_writer.py:48] [289000] global_step=289000, grad_norm=2.8777506351470947, loss=2.113241672515869
I0304 02:30:00.082908 139758009304832 logging_writer.py:48] [289100] global_step=289100, grad_norm=3.0674991607666016, loss=1.9607442617416382
I0304 02:30:44.983660 139758017697536 logging_writer.py:48] [289200] global_step=289200, grad_norm=3.5472214221954346, loss=1.1536785364151
I0304 02:31:29.956758 139758009304832 logging_writer.py:48] [289300] global_step=289300, grad_norm=3.2876925468444824, loss=1.6352159976959229
I0304 02:31:59.789106 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:32:11.011949 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:32:33.135442 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:32:34.768217 139953291118400 submission_runner.py:411] Time since start: 138994.94s, 	Step: 289368, 	{'train/accuracy': 0.8885741829872131, 'train/loss': 0.4138832092285156, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 128594.14718818665, 'total_duration': 138994.94444060326, 'accumulated_submission_time': 128594.14718818665, 'accumulated_eval_time': 10367.236153364182, 'accumulated_logging_time': 18.78646731376648}
I0304 02:32:34.838390 139758017697536 logging_writer.py:48] [289368] accumulated_eval_time=10367.236153, accumulated_logging_time=18.786467, accumulated_submission_time=128594.147188, global_step=289368, preemption_count=0, score=128594.147188, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=138994.944441, train/accuracy=0.888574, train/loss=0.413883, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:32:47.881639 139758009304832 logging_writer.py:48] [289400] global_step=289400, grad_norm=3.104379653930664, loss=1.339160680770874
I0304 02:33:30.821230 139758017697536 logging_writer.py:48] [289500] global_step=289500, grad_norm=3.04522442817688, loss=1.1938399076461792
I0304 02:34:15.657016 139758009304832 logging_writer.py:48] [289600] global_step=289600, grad_norm=3.1519277095794678, loss=1.3584102392196655
I0304 02:35:00.419823 139758017697536 logging_writer.py:48] [289700] global_step=289700, grad_norm=3.132319927215576, loss=1.4872596263885498
I0304 02:35:45.361330 139758009304832 logging_writer.py:48] [289800] global_step=289800, grad_norm=3.519819736480713, loss=3.063072443008423
I0304 02:36:30.285980 139758017697536 logging_writer.py:48] [289900] global_step=289900, grad_norm=3.025177478790283, loss=1.1310229301452637
I0304 02:37:15.340062 139758009304832 logging_writer.py:48] [290000] global_step=290000, grad_norm=2.868600606918335, loss=1.765669584274292
I0304 02:38:00.097266 139758017697536 logging_writer.py:48] [290100] global_step=290100, grad_norm=3.1722896099090576, loss=1.1659047603607178
I0304 02:38:45.226835 139758009304832 logging_writer.py:48] [290200] global_step=290200, grad_norm=2.791447401046753, loss=1.7776306867599487
I0304 02:39:30.265218 139758017697536 logging_writer.py:48] [290300] global_step=290300, grad_norm=3.307680130004883, loss=1.1923960447311401
I0304 02:39:34.872360 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:39:46.011197 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:40:09.038270 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:40:10.673727 139953291118400 submission_runner.py:411] Time since start: 139450.85s, 	Step: 290312, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.4155890643596649, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 129014.12380385399, 'total_duration': 139450.84994983673, 'accumulated_submission_time': 129014.12380385399, 'accumulated_eval_time': 10403.037517786026, 'accumulated_logging_time': 18.866474628448486}
I0304 02:40:10.747659 139758009304832 logging_writer.py:48] [290312] accumulated_eval_time=10403.037518, accumulated_logging_time=18.866475, accumulated_submission_time=129014.123804, global_step=290312, preemption_count=0, score=129014.123804, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=139450.849950, train/accuracy=0.888144, train/loss=0.415589, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:40:46.732486 139758017697536 logging_writer.py:48] [290400] global_step=290400, grad_norm=3.1992127895355225, loss=1.222904920578003
I0304 02:41:31.397088 139758009304832 logging_writer.py:48] [290500] global_step=290500, grad_norm=3.081944227218628, loss=1.0725574493408203
I0304 02:42:16.501152 139758017697536 logging_writer.py:48] [290600] global_step=290600, grad_norm=3.258167266845703, loss=1.0665850639343262
I0304 02:43:01.524376 139758009304832 logging_writer.py:48] [290700] global_step=290700, grad_norm=3.2164580821990967, loss=1.6997840404510498
I0304 02:43:46.392353 139758017697536 logging_writer.py:48] [290800] global_step=290800, grad_norm=3.2264750003814697, loss=1.2149771451950073
I0304 02:44:31.164314 139758009304832 logging_writer.py:48] [290900] global_step=290900, grad_norm=3.7029640674591064, loss=3.3382349014282227
I0304 02:45:16.131825 139758017697536 logging_writer.py:48] [291000] global_step=291000, grad_norm=3.2811429500579834, loss=2.5594136714935303
I0304 02:46:00.860839 139758009304832 logging_writer.py:48] [291100] global_step=291100, grad_norm=3.2473490238189697, loss=2.562993049621582
I0304 02:46:46.046033 139758017697536 logging_writer.py:48] [291200] global_step=291200, grad_norm=3.0099008083343506, loss=1.5325270891189575
I0304 02:47:10.868609 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:47:21.758474 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:47:53.690026 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:47:55.313595 139953291118400 submission_runner.py:411] Time since start: 139915.49s, 	Step: 291257, 	{'train/accuracy': 0.8851562142372131, 'train/loss': 0.4261019825935364, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 129434.1880440712, 'total_duration': 139915.48982930183, 'accumulated_submission_time': 129434.1880440712, 'accumulated_eval_time': 10447.48250246048, 'accumulated_logging_time': 18.949787139892578}
I0304 02:47:55.372257 139758009304832 logging_writer.py:48] [291257] accumulated_eval_time=10447.482502, accumulated_logging_time=18.949787, accumulated_submission_time=129434.188044, global_step=291257, preemption_count=0, score=129434.188044, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=139915.489829, train/accuracy=0.885156, train/loss=0.426102, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:48:12.717808 139758017697536 logging_writer.py:48] [291300] global_step=291300, grad_norm=3.3006551265716553, loss=1.2566115856170654
I0304 02:48:54.319359 139758009304832 logging_writer.py:48] [291400] global_step=291400, grad_norm=3.241291046142578, loss=2.198035717010498
I0304 02:49:39.697085 139758017697536 logging_writer.py:48] [291500] global_step=291500, grad_norm=3.2785885334014893, loss=2.436864137649536
I0304 02:50:25.091321 139758009304832 logging_writer.py:48] [291600] global_step=291600, grad_norm=3.1254072189331055, loss=1.0321857929229736
I0304 02:51:09.847682 139758017697536 logging_writer.py:48] [291700] global_step=291700, grad_norm=3.211491584777832, loss=1.1554672718048096
I0304 02:51:54.733678 139758009304832 logging_writer.py:48] [291800] global_step=291800, grad_norm=3.176799774169922, loss=2.514285087585449
I0304 02:52:40.035870 139758017697536 logging_writer.py:48] [291900] global_step=291900, grad_norm=3.6606016159057617, loss=1.1728113889694214
I0304 02:53:24.917320 139758009304832 logging_writer.py:48] [292000] global_step=292000, grad_norm=2.8562159538269043, loss=1.302695393562317
I0304 02:54:09.728626 139758017697536 logging_writer.py:48] [292100] global_step=292100, grad_norm=3.224385976791382, loss=1.1792402267456055
I0304 02:54:54.600550 139758009304832 logging_writer.py:48] [292200] global_step=292200, grad_norm=4.60094690322876, loss=3.219416856765747
I0304 02:54:55.647149 139953291118400 spec.py:321] Evaluating on the training split.
I0304 02:55:06.829785 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 02:55:29.854922 139953291118400 spec.py:349] Evaluating on the test split.
I0304 02:55:31.505682 139953291118400 submission_runner.py:411] Time since start: 140371.68s, 	Step: 292204, 	{'train/accuracy': 0.8864452838897705, 'train/loss': 0.4245300889015198, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 129854.40283584595, 'total_duration': 140371.68188858032, 'accumulated_submission_time': 129854.40283584595, 'accumulated_eval_time': 10483.340990066528, 'accumulated_logging_time': 19.0203800201416}
I0304 02:55:31.563605 139758017697536 logging_writer.py:48] [292204] accumulated_eval_time=10483.340990, accumulated_logging_time=19.020380, accumulated_submission_time=129854.402836, global_step=292204, preemption_count=0, score=129854.402836, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=140371.681889, train/accuracy=0.886445, train/loss=0.424530, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 02:56:09.905827 139758009304832 logging_writer.py:48] [292300] global_step=292300, grad_norm=3.2189135551452637, loss=1.1851683855056763
I0304 02:56:54.700694 139758017697536 logging_writer.py:48] [292400] global_step=292400, grad_norm=3.0019490718841553, loss=1.0824756622314453
I0304 02:57:39.680169 139758009304832 logging_writer.py:48] [292500] global_step=292500, grad_norm=3.1978743076324463, loss=2.7691400051116943
I0304 02:58:24.904095 139758017697536 logging_writer.py:48] [292600] global_step=292600, grad_norm=3.2610182762145996, loss=2.7940351963043213
I0304 02:59:09.821231 139758009304832 logging_writer.py:48] [292700] global_step=292700, grad_norm=3.4973626136779785, loss=2.5923686027526855
I0304 02:59:55.048891 139758017697536 logging_writer.py:48] [292800] global_step=292800, grad_norm=3.421264171600342, loss=1.0808826684951782
I0304 03:00:39.943346 139758009304832 logging_writer.py:48] [292900] global_step=292900, grad_norm=3.3391287326812744, loss=2.8908445835113525
I0304 03:01:25.095947 139758017697536 logging_writer.py:48] [293000] global_step=293000, grad_norm=3.4865939617156982, loss=1.06630277633667
I0304 03:02:09.949693 139758009304832 logging_writer.py:48] [293100] global_step=293100, grad_norm=3.1588878631591797, loss=1.9357508420944214
I0304 03:02:31.692079 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:02:43.131196 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:03:06.201597 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:03:07.835268 139953291118400 submission_runner.py:411] Time since start: 140828.01s, 	Step: 293150, 	{'train/accuracy': 0.8864452838897705, 'train/loss': 0.42006221413612366, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 130274.47477340698, 'total_duration': 140828.01147723198, 'accumulated_submission_time': 130274.47477340698, 'accumulated_eval_time': 10519.48413681984, 'accumulated_logging_time': 19.087130546569824}
I0304 03:03:07.907618 139758017697536 logging_writer.py:48] [293150] accumulated_eval_time=10519.484137, accumulated_logging_time=19.087131, accumulated_submission_time=130274.474773, global_step=293150, preemption_count=0, score=130274.474773, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=140828.011477, train/accuracy=0.886445, train/loss=0.420062, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:03:28.028723 139758009304832 logging_writer.py:48] [293200] global_step=293200, grad_norm=3.2617568969726562, loss=1.1704968214035034
I0304 03:04:11.811404 139758017697536 logging_writer.py:48] [293300] global_step=293300, grad_norm=3.119558811187744, loss=1.156507134437561
I0304 03:04:56.626592 139758009304832 logging_writer.py:48] [293400] global_step=293400, grad_norm=3.4388816356658936, loss=1.1986329555511475
I0304 03:05:41.837021 139758017697536 logging_writer.py:48] [293500] global_step=293500, grad_norm=3.031745195388794, loss=1.724645733833313
I0304 03:06:26.800583 139758009304832 logging_writer.py:48] [293600] global_step=293600, grad_norm=3.212841749191284, loss=1.2001018524169922
I0304 03:07:12.002042 139758017697536 logging_writer.py:48] [293700] global_step=293700, grad_norm=3.198976516723633, loss=1.1461488008499146
I0304 03:07:57.199724 139758009304832 logging_writer.py:48] [293800] global_step=293800, grad_norm=3.074892997741699, loss=2.233949899673462
I0304 03:08:42.333455 139758017697536 logging_writer.py:48] [293900] global_step=293900, grad_norm=3.319573163986206, loss=1.2716033458709717
I0304 03:09:27.616654 139758009304832 logging_writer.py:48] [294000] global_step=294000, grad_norm=3.4858574867248535, loss=1.096710443496704
I0304 03:10:07.903292 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:10:19.028917 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:10:43.625923 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:10:45.257571 139953291118400 submission_runner.py:411] Time since start: 141285.43s, 	Step: 294091, 	{'train/accuracy': 0.8884570002555847, 'train/loss': 0.4107588827610016, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 130694.41358494759, 'total_duration': 141285.43379950523, 'accumulated_submission_time': 130694.41358494759, 'accumulated_eval_time': 10556.838421106339, 'accumulated_logging_time': 19.169212818145752}
I0304 03:10:45.331634 139758017697536 logging_writer.py:48] [294091] accumulated_eval_time=10556.838421, accumulated_logging_time=19.169213, accumulated_submission_time=130694.413585, global_step=294091, preemption_count=0, score=130694.413585, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=141285.433800, train/accuracy=0.888457, train/loss=0.410759, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:10:49.288022 139758009304832 logging_writer.py:48] [294100] global_step=294100, grad_norm=3.1469461917877197, loss=1.1194732189178467
I0304 03:11:30.658689 139758017697536 logging_writer.py:48] [294200] global_step=294200, grad_norm=3.2734477519989014, loss=1.1239241361618042
I0304 03:12:15.706333 139758009304832 logging_writer.py:48] [294300] global_step=294300, grad_norm=3.1869733333587646, loss=1.1079705953598022
I0304 03:13:00.728019 139758017697536 logging_writer.py:48] [294400] global_step=294400, grad_norm=3.269702672958374, loss=1.2430107593536377
I0304 03:13:46.026551 139758009304832 logging_writer.py:48] [294500] global_step=294500, grad_norm=3.05086088180542, loss=1.251238226890564
I0304 03:14:31.167982 139758017697536 logging_writer.py:48] [294600] global_step=294600, grad_norm=3.0835609436035156, loss=1.7777405977249146
I0304 03:15:16.001693 139758009304832 logging_writer.py:48] [294700] global_step=294700, grad_norm=3.164949893951416, loss=1.1151610612869263
I0304 03:16:00.923468 139758017697536 logging_writer.py:48] [294800] global_step=294800, grad_norm=3.003236770629883, loss=1.3591957092285156
I0304 03:16:45.900912 139758009304832 logging_writer.py:48] [294900] global_step=294900, grad_norm=3.4483718872070312, loss=1.8177002668380737
I0304 03:17:30.856114 139758017697536 logging_writer.py:48] [295000] global_step=295000, grad_norm=3.281843662261963, loss=1.1471431255340576
I0304 03:17:45.332453 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:17:56.369791 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:18:30.970106 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:18:32.599214 139953291118400 submission_runner.py:411] Time since start: 141752.78s, 	Step: 295034, 	{'train/accuracy': 0.8865429759025574, 'train/loss': 0.4236370325088501, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 131114.35461211205, 'total_duration': 141752.77542972565, 'accumulated_submission_time': 131114.35461211205, 'accumulated_eval_time': 10604.105157375336, 'accumulated_logging_time': 19.256078243255615}
I0304 03:18:32.661915 139758009304832 logging_writer.py:48] [295034] accumulated_eval_time=10604.105157, accumulated_logging_time=19.256078, accumulated_submission_time=131114.354612, global_step=295034, preemption_count=0, score=131114.354612, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=141752.775430, train/accuracy=0.886543, train/loss=0.423637, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:18:59.081853 139758017697536 logging_writer.py:48] [295100] global_step=295100, grad_norm=3.6893563270568848, loss=3.064134120941162
I0304 03:19:42.385595 139758009304832 logging_writer.py:48] [295200] global_step=295200, grad_norm=4.133335590362549, loss=1.141573429107666
I0304 03:20:27.789649 139758017697536 logging_writer.py:48] [295300] global_step=295300, grad_norm=2.9352855682373047, loss=1.9141128063201904
I0304 03:21:12.889167 139758009304832 logging_writer.py:48] [295400] global_step=295400, grad_norm=3.2431323528289795, loss=1.1158771514892578
I0304 03:21:57.690465 139758017697536 logging_writer.py:48] [295500] global_step=295500, grad_norm=3.9267163276672363, loss=2.9341840744018555
I0304 03:22:42.617977 139758009304832 logging_writer.py:48] [295600] global_step=295600, grad_norm=3.7297744750976562, loss=3.0006558895111084
I0304 03:23:27.569983 139758017697536 logging_writer.py:48] [295700] global_step=295700, grad_norm=4.330264568328857, loss=3.2011592388153076
I0304 03:24:12.497270 139758009304832 logging_writer.py:48] [295800] global_step=295800, grad_norm=3.0512351989746094, loss=1.5736124515533447
I0304 03:24:57.620537 139758017697536 logging_writer.py:48] [295900] global_step=295900, grad_norm=3.0328352451324463, loss=2.046562433242798
I0304 03:25:32.787478 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:25:43.832534 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:26:11.817954 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:26:13.453054 139953291118400 submission_runner.py:411] Time since start: 142213.63s, 	Step: 295980, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.4216232895851135, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 131534.42352700233, 'total_duration': 142213.62927746773, 'accumulated_submission_time': 131534.42352700233, 'accumulated_eval_time': 10644.770728588104, 'accumulated_logging_time': 19.327077388763428}
I0304 03:26:13.512135 139758009304832 logging_writer.py:48] [295980] accumulated_eval_time=10644.770729, accumulated_logging_time=19.327077, accumulated_submission_time=131534.423527, global_step=295980, preemption_count=0, score=131534.423527, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=142213.629277, train/accuracy=0.888144, train/loss=0.421623, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:26:21.800732 139758017697536 logging_writer.py:48] [296000] global_step=296000, grad_norm=3.2197885513305664, loss=2.6189024448394775
I0304 03:27:02.804629 139758009304832 logging_writer.py:48] [296100] global_step=296100, grad_norm=3.203014373779297, loss=2.9073569774627686
I0304 03:27:47.779436 139758017697536 logging_writer.py:48] [296200] global_step=296200, grad_norm=3.3595640659332275, loss=1.3349543809890747
I0304 03:28:33.293756 139758009304832 logging_writer.py:48] [296300] global_step=296300, grad_norm=3.9814913272857666, loss=1.3614672422409058
I0304 03:29:18.629160 139758017697536 logging_writer.py:48] [296400] global_step=296400, grad_norm=3.0943961143493652, loss=1.084251046180725
I0304 03:30:03.675571 139758009304832 logging_writer.py:48] [296500] global_step=296500, grad_norm=2.8702621459960938, loss=1.7235057353973389
I0304 03:30:48.992178 139758017697536 logging_writer.py:48] [296600] global_step=296600, grad_norm=3.841383457183838, loss=3.1429948806762695
I0304 03:31:33.972043 139758009304832 logging_writer.py:48] [296700] global_step=296700, grad_norm=3.22017765045166, loss=1.3158639669418335
I0304 03:32:18.822741 139758017697536 logging_writer.py:48] [296800] global_step=296800, grad_norm=4.051361083984375, loss=3.1919164657592773
I0304 03:33:03.630576 139758009304832 logging_writer.py:48] [296900] global_step=296900, grad_norm=3.0946905612945557, loss=1.1659539937973022
I0304 03:33:13.800692 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:33:25.371632 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:33:53.600970 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:33:55.236342 139953291118400 submission_runner.py:411] Time since start: 142675.41s, 	Step: 296924, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.4217333495616913, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 131954.65556120872, 'total_duration': 142675.4125571251, 'accumulated_submission_time': 131954.65556120872, 'accumulated_eval_time': 10686.206349372864, 'accumulated_logging_time': 19.395113229751587}
I0304 03:33:55.306638 139758017697536 logging_writer.py:48] [296924] accumulated_eval_time=10686.206349, accumulated_logging_time=19.395113, accumulated_submission_time=131954.655561, global_step=296924, preemption_count=0, score=131954.655561, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=142675.412557, train/accuracy=0.887910, train/loss=0.421733, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:34:25.693140 139758009304832 logging_writer.py:48] [297000] global_step=297000, grad_norm=2.758857011795044, loss=1.873077392578125
I0304 03:35:10.330205 139758017697536 logging_writer.py:48] [297100] global_step=297100, grad_norm=3.2800369262695312, loss=2.651010751724243
I0304 03:35:55.424894 139758009304832 logging_writer.py:48] [297200] global_step=297200, grad_norm=3.33890438079834, loss=2.7715466022491455
I0304 03:36:40.726824 139758017697536 logging_writer.py:48] [297300] global_step=297300, grad_norm=3.0314855575561523, loss=2.4815144538879395
I0304 03:37:25.703696 139758009304832 logging_writer.py:48] [297400] global_step=297400, grad_norm=3.1771090030670166, loss=1.106161117553711
I0304 03:38:10.756650 139758017697536 logging_writer.py:48] [297500] global_step=297500, grad_norm=3.4948270320892334, loss=3.0735483169555664
I0304 03:38:55.551838 139758009304832 logging_writer.py:48] [297600] global_step=297600, grad_norm=3.3710556030273438, loss=1.2641947269439697
I0304 03:39:40.532240 139758017697536 logging_writer.py:48] [297700] global_step=297700, grad_norm=3.2554047107696533, loss=1.1032745838165283
I0304 03:40:25.927019 139758009304832 logging_writer.py:48] [297800] global_step=297800, grad_norm=2.8945868015289307, loss=1.3142955303192139
I0304 03:40:55.580627 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:41:07.062492 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:41:39.134879 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:41:40.759150 139953291118400 submission_runner.py:411] Time since start: 143140.94s, 	Step: 297867, 	{'train/accuracy': 0.8878710865974426, 'train/loss': 0.41872739791870117, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 132374.87281131744, 'total_duration': 143140.9353840351, 'accumulated_submission_time': 132374.87281131744, 'accumulated_eval_time': 10731.38487648964, 'accumulated_logging_time': 19.475355625152588}
I0304 03:41:40.817532 139758017697536 logging_writer.py:48] [297867] accumulated_eval_time=10731.384876, accumulated_logging_time=19.475356, accumulated_submission_time=132374.872811, global_step=297867, preemption_count=0, score=132374.872811, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=143140.935384, train/accuracy=0.887871, train/loss=0.418727, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:41:54.239391 139758009304832 logging_writer.py:48] [297900] global_step=297900, grad_norm=3.238797426223755, loss=2.526244640350342
I0304 03:42:36.288134 139758017697536 logging_writer.py:48] [298000] global_step=298000, grad_norm=3.2976694107055664, loss=2.7345635890960693
I0304 03:43:21.388160 139758009304832 logging_writer.py:48] [298100] global_step=298100, grad_norm=3.04087495803833, loss=2.5464723110198975
I0304 03:44:06.492661 139758017697536 logging_writer.py:48] [298200] global_step=298200, grad_norm=3.1607279777526855, loss=1.80724036693573
I0304 03:44:51.674443 139758009304832 logging_writer.py:48] [298300] global_step=298300, grad_norm=3.1526336669921875, loss=1.1784707307815552
I0304 03:45:36.693127 139758017697536 logging_writer.py:48] [298400] global_step=298400, grad_norm=3.71917986869812, loss=3.3065595626831055
I0304 03:46:21.912017 139758009304832 logging_writer.py:48] [298500] global_step=298500, grad_norm=3.3691775798797607, loss=2.807521343231201
I0304 03:47:06.818317 139758017697536 logging_writer.py:48] [298600] global_step=298600, grad_norm=3.1643259525299072, loss=1.7464569807052612
I0304 03:47:51.715017 139758009304832 logging_writer.py:48] [298700] global_step=298700, grad_norm=3.2266385555267334, loss=1.2688668966293335
I0304 03:48:36.689885 139758017697536 logging_writer.py:48] [298800] global_step=298800, grad_norm=3.0386338233947754, loss=1.9535157680511475
I0304 03:48:40.951994 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:48:52.200628 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:49:12.775266 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:49:14.399684 139953291118400 submission_runner.py:411] Time since start: 143594.58s, 	Step: 298811, 	{'train/accuracy': 0.8876953125, 'train/loss': 0.41470983624458313, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 132794.94854402542, 'total_duration': 143594.57590150833, 'accumulated_submission_time': 132794.94854402542, 'accumulated_eval_time': 10764.832551240921, 'accumulated_logging_time': 19.54459524154663}
I0304 03:49:14.472875 139758009304832 logging_writer.py:48] [298811] accumulated_eval_time=10764.832551, accumulated_logging_time=19.544595, accumulated_submission_time=132794.948544, global_step=298811, preemption_count=0, score=132794.948544, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=143594.575902, train/accuracy=0.887695, train/loss=0.414710, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:49:51.200005 139758017697536 logging_writer.py:48] [298900] global_step=298900, grad_norm=3.0899767875671387, loss=1.1966454982757568
I0304 03:50:36.162012 139758009304832 logging_writer.py:48] [299000] global_step=299000, grad_norm=3.1031336784362793, loss=1.8637386560440063
I0304 03:51:21.745582 139758017697536 logging_writer.py:48] [299100] global_step=299100, grad_norm=4.959102630615234, loss=3.2822422981262207
I0304 03:52:07.085330 139758009304832 logging_writer.py:48] [299200] global_step=299200, grad_norm=3.0549464225769043, loss=1.176796793937683
I0304 03:52:52.360023 139758017697536 logging_writer.py:48] [299300] global_step=299300, grad_norm=3.4548985958099365, loss=3.1799850463867188
I0304 03:53:37.324192 139758009304832 logging_writer.py:48] [299400] global_step=299400, grad_norm=3.132357358932495, loss=1.2451473474502563
I0304 03:54:22.430496 139758017697536 logging_writer.py:48] [299500] global_step=299500, grad_norm=3.0198819637298584, loss=1.1154987812042236
I0304 03:55:07.639261 139758009304832 logging_writer.py:48] [299600] global_step=299600, grad_norm=2.8347203731536865, loss=1.164501428604126
I0304 03:55:52.746052 139758017697536 logging_writer.py:48] [299700] global_step=299700, grad_norm=2.980161190032959, loss=1.124177098274231
I0304 03:56:14.781690 139953291118400 spec.py:321] Evaluating on the training split.
I0304 03:56:26.224398 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 03:56:49.498405 139953291118400 spec.py:349] Evaluating on the test split.
I0304 03:56:51.126289 139953291118400 submission_runner.py:411] Time since start: 144051.30s, 	Step: 299750, 	{'train/accuracy': 0.8880273103713989, 'train/loss': 0.4155641794204712, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 133215.20007777214, 'total_duration': 144051.30251002312, 'accumulated_submission_time': 133215.20007777214, 'accumulated_eval_time': 10801.17714715004, 'accumulated_logging_time': 19.628756284713745}
I0304 03:56:51.200017 139758009304832 logging_writer.py:48] [299750] accumulated_eval_time=10801.177147, accumulated_logging_time=19.628756, accumulated_submission_time=133215.200078, global_step=299750, preemption_count=0, score=133215.200078, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=144051.302510, train/accuracy=0.888027, train/loss=0.415564, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 03:57:11.364919 139758017697536 logging_writer.py:48] [299800] global_step=299800, grad_norm=3.303584337234497, loss=1.1242084503173828
I0304 03:57:54.884281 139758009304832 logging_writer.py:48] [299900] global_step=299900, grad_norm=2.979063034057617, loss=0.9946408271789551
I0304 03:58:39.899686 139758017697536 logging_writer.py:48] [300000] global_step=300000, grad_norm=2.9084324836730957, loss=1.1682908535003662
I0304 03:59:25.035212 139758009304832 logging_writer.py:48] [300100] global_step=300100, grad_norm=3.1032769680023193, loss=1.262256383895874
I0304 04:00:10.029735 139758017697536 logging_writer.py:48] [300200] global_step=300200, grad_norm=3.1134250164031982, loss=1.9922560453414917
I0304 04:00:55.396990 139758009304832 logging_writer.py:48] [300300] global_step=300300, grad_norm=3.195220708847046, loss=1.4076926708221436
I0304 04:01:40.972285 139758017697536 logging_writer.py:48] [300400] global_step=300400, grad_norm=3.182994842529297, loss=1.2323381900787354
I0304 04:02:26.075975 139758009304832 logging_writer.py:48] [300500] global_step=300500, grad_norm=2.9050707817077637, loss=1.1556850671768188
I0304 04:03:11.070543 139758017697536 logging_writer.py:48] [300600] global_step=300600, grad_norm=3.081233263015747, loss=1.3931115865707397
I0304 04:03:51.285410 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:04:02.532614 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:04:35.486497 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:04:37.104599 139953291118400 submission_runner.py:411] Time since start: 144517.28s, 	Step: 300691, 	{'train/accuracy': 0.8881640434265137, 'train/loss': 0.41772985458374023, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 133635.22816705704, 'total_duration': 144517.28083229065, 'accumulated_submission_time': 133635.22816705704, 'accumulated_eval_time': 10846.996324777603, 'accumulated_logging_time': 19.712132215499878}
I0304 04:04:37.163733 139758009304832 logging_writer.py:48] [300691] accumulated_eval_time=10846.996325, accumulated_logging_time=19.712132, accumulated_submission_time=133635.228167, global_step=300691, preemption_count=0, score=133635.228167, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=144517.280832, train/accuracy=0.888164, train/loss=0.417730, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:04:41.113742 139758017697536 logging_writer.py:48] [300700] global_step=300700, grad_norm=3.229555130004883, loss=1.1383538246154785
I0304 04:05:21.141318 139758009304832 logging_writer.py:48] [300800] global_step=300800, grad_norm=3.345071315765381, loss=1.2306489944458008
I0304 04:06:05.934361 139758017697536 logging_writer.py:48] [300900] global_step=300900, grad_norm=3.231393814086914, loss=2.3012707233428955
I0304 04:06:51.080386 139758009304832 logging_writer.py:48] [301000] global_step=301000, grad_norm=3.437171459197998, loss=1.4213777780532837
I0304 04:07:36.229920 139758017697536 logging_writer.py:48] [301100] global_step=301100, grad_norm=3.604226589202881, loss=1.181586742401123
I0304 04:08:21.161418 139758009304832 logging_writer.py:48] [301200] global_step=301200, grad_norm=3.4673964977264404, loss=2.806567430496216
I0304 04:09:06.104954 139758017697536 logging_writer.py:48] [301300] global_step=301300, grad_norm=3.570500612258911, loss=3.071836471557617
I0304 04:09:51.011804 139758009304832 logging_writer.py:48] [301400] global_step=301400, grad_norm=3.235628128051758, loss=2.5389199256896973
I0304 04:10:35.800341 139758017697536 logging_writer.py:48] [301500] global_step=301500, grad_norm=3.3741636276245117, loss=2.5906593799591064
I0304 04:11:21.094125 139758009304832 logging_writer.py:48] [301600] global_step=301600, grad_norm=3.1787452697753906, loss=1.2092700004577637
I0304 04:11:37.284367 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:11:48.321428 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:12:16.623730 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:12:18.238763 139953291118400 submission_runner.py:411] Time since start: 144978.41s, 	Step: 301638, 	{'train/accuracy': 0.8869531154632568, 'train/loss': 0.42130810022354126, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 134055.29154729843, 'total_duration': 144978.41498851776, 'accumulated_submission_time': 134055.29154729843, 'accumulated_eval_time': 10887.950706481934, 'accumulated_logging_time': 19.780964374542236}
I0304 04:12:18.300110 139758017697536 logging_writer.py:48] [301638] accumulated_eval_time=10887.950706, accumulated_logging_time=19.780964, accumulated_submission_time=134055.291547, global_step=301638, preemption_count=0, score=134055.291547, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=144978.414989, train/accuracy=0.886953, train/loss=0.421308, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:12:43.141503 139758009304832 logging_writer.py:48] [301700] global_step=301700, grad_norm=3.9752626419067383, loss=2.7883524894714355
I0304 04:13:26.234518 139758017697536 logging_writer.py:48] [301800] global_step=301800, grad_norm=3.2598955631256104, loss=2.5704429149627686
I0304 04:14:11.400756 139758009304832 logging_writer.py:48] [301900] global_step=301900, grad_norm=3.2514536380767822, loss=2.6655356884002686
I0304 04:14:56.715295 139758017697536 logging_writer.py:48] [302000] global_step=302000, grad_norm=3.1933043003082275, loss=1.273450255393982
I0304 04:15:41.728960 139758009304832 logging_writer.py:48] [302100] global_step=302100, grad_norm=3.2058699131011963, loss=1.0106451511383057
I0304 04:16:26.843261 139758017697536 logging_writer.py:48] [302200] global_step=302200, grad_norm=2.93464732170105, loss=1.2816376686096191
I0304 04:17:11.872575 139758009304832 logging_writer.py:48] [302300] global_step=302300, grad_norm=3.3081302642822266, loss=1.1647511720657349
I0304 04:17:56.717869 139758017697536 logging_writer.py:48] [302400] global_step=302400, grad_norm=3.3247296810150146, loss=2.0323636531829834
I0304 04:18:41.516811 139758009304832 logging_writer.py:48] [302500] global_step=302500, grad_norm=3.101764678955078, loss=1.1645535230636597
I0304 04:19:18.254181 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:19:29.725899 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:19:54.375196 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:19:56.014295 139953291118400 submission_runner.py:411] Time since start: 145436.19s, 	Step: 302583, 	{'train/accuracy': 0.8878515362739563, 'train/loss': 0.42307791113853455, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 134475.1889846325, 'total_duration': 145436.19050335884, 'accumulated_submission_time': 134475.1889846325, 'accumulated_eval_time': 10925.710918664932, 'accumulated_logging_time': 19.851025104522705}
I0304 04:19:56.089241 139758017697536 logging_writer.py:48] [302583] accumulated_eval_time=10925.710919, accumulated_logging_time=19.851025, accumulated_submission_time=134475.188985, global_step=302583, preemption_count=0, score=134475.188985, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=145436.190503, train/accuracy=0.887852, train/loss=0.423078, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:20:03.219036 139758009304832 logging_writer.py:48] [302600] global_step=302600, grad_norm=4.0110182762146, loss=3.310380220413208
I0304 04:20:45.205946 139758017697536 logging_writer.py:48] [302700] global_step=302700, grad_norm=3.001866102218628, loss=2.2744510173797607
I0304 04:21:30.356443 139758009304832 logging_writer.py:48] [302800] global_step=302800, grad_norm=3.040327787399292, loss=1.1330657005310059
I0304 04:22:15.334962 139758017697536 logging_writer.py:48] [302900] global_step=302900, grad_norm=3.7437191009521484, loss=2.5701122283935547
I0304 04:23:00.246142 139758009304832 logging_writer.py:48] [303000] global_step=303000, grad_norm=4.016357898712158, loss=2.985992908477783
I0304 04:23:45.279787 139758017697536 logging_writer.py:48] [303100] global_step=303100, grad_norm=3.473341703414917, loss=2.99784517288208
I0304 04:24:30.462442 139758009304832 logging_writer.py:48] [303200] global_step=303200, grad_norm=3.5182723999023438, loss=1.6713958978652954
I0304 04:25:15.916359 139758017697536 logging_writer.py:48] [303300] global_step=303300, grad_norm=3.3302323818206787, loss=1.1213849782943726
I0304 04:26:01.056040 139758009304832 logging_writer.py:48] [303400] global_step=303400, grad_norm=2.951270341873169, loss=1.4212448596954346
I0304 04:26:46.008598 139758017697536 logging_writer.py:48] [303500] global_step=303500, grad_norm=3.013537645339966, loss=1.1929832696914673
I0304 04:26:56.216443 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:27:07.738566 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:27:35.305635 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:27:36.934078 139953291118400 submission_runner.py:411] Time since start: 145897.11s, 	Step: 303524, 	{'train/accuracy': 0.8898828029632568, 'train/loss': 0.4145982563495636, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 134895.2553062439, 'total_duration': 145897.11030721664, 'accumulated_submission_time': 134895.2553062439, 'accumulated_eval_time': 10966.428569555283, 'accumulated_logging_time': 19.93898057937622}
I0304 04:27:36.994052 139758009304832 logging_writer.py:48] [303524] accumulated_eval_time=10966.428570, accumulated_logging_time=19.938981, accumulated_submission_time=134895.255306, global_step=303524, preemption_count=0, score=134895.255306, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=145897.110307, train/accuracy=0.889883, train/loss=0.414598, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:28:07.372305 139758017697536 logging_writer.py:48] [303600] global_step=303600, grad_norm=2.8656790256500244, loss=1.116511583328247
I0304 04:28:51.578462 139758009304832 logging_writer.py:48] [303700] global_step=303700, grad_norm=2.966264247894287, loss=2.043748140335083
I0304 04:29:36.259531 139758017697536 logging_writer.py:48] [303800] global_step=303800, grad_norm=3.010165214538574, loss=1.1708508729934692
I0304 04:30:21.461055 139758009304832 logging_writer.py:48] [303900] global_step=303900, grad_norm=3.0572657585144043, loss=1.1669076681137085
I0304 04:31:06.406919 139758017697536 logging_writer.py:48] [304000] global_step=304000, grad_norm=2.854884147644043, loss=1.142240047454834
I0304 04:31:51.560585 139758009304832 logging_writer.py:48] [304100] global_step=304100, grad_norm=2.999833106994629, loss=2.0176374912261963
I0304 04:32:36.622287 139758017697536 logging_writer.py:48] [304200] global_step=304200, grad_norm=3.8881075382232666, loss=3.1487317085266113
I0304 04:33:21.618991 139758009304832 logging_writer.py:48] [304300] global_step=304300, grad_norm=3.73049259185791, loss=3.003392219543457
I0304 04:34:06.683678 139758017697536 logging_writer.py:48] [304400] global_step=304400, grad_norm=3.1032915115356445, loss=1.1054933071136475
I0304 04:34:37.384831 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:34:48.395065 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:35:15.276952 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:35:16.913927 139953291118400 submission_runner.py:411] Time since start: 146357.09s, 	Step: 304470, 	{'train/accuracy': 0.8882812261581421, 'train/loss': 0.4124145805835724, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 135315.58999705315, 'total_duration': 146357.09014439583, 'accumulated_submission_time': 135315.58999705315, 'accumulated_eval_time': 11005.957649946213, 'accumulated_logging_time': 20.0074679851532}
I0304 04:35:16.986399 139758009304832 logging_writer.py:48] [304470] accumulated_eval_time=11005.957650, accumulated_logging_time=20.007468, accumulated_submission_time=135315.589997, global_step=304470, preemption_count=0, score=135315.589997, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=146357.090144, train/accuracy=0.888281, train/loss=0.412415, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:35:29.244430 139758017697536 logging_writer.py:48] [304500] global_step=304500, grad_norm=3.064248561859131, loss=2.0067708492279053
I0304 04:36:11.954357 139758009304832 logging_writer.py:48] [304600] global_step=304600, grad_norm=2.8582820892333984, loss=1.5594494342803955
I0304 04:36:56.947821 139758017697536 logging_writer.py:48] [304700] global_step=304700, grad_norm=3.0449886322021484, loss=1.3268187046051025
I0304 04:37:42.193203 139758009304832 logging_writer.py:48] [304800] global_step=304800, grad_norm=3.1697194576263428, loss=1.1559903621673584
I0304 04:38:27.435053 139758017697536 logging_writer.py:48] [304900] global_step=304900, grad_norm=3.0823252201080322, loss=2.5139613151550293
I0304 04:39:12.494890 139758009304832 logging_writer.py:48] [305000] global_step=305000, grad_norm=3.7182655334472656, loss=2.892141342163086
I0304 04:39:57.452288 139758017697536 logging_writer.py:48] [305100] global_step=305100, grad_norm=3.3288934230804443, loss=1.0999964475631714
I0304 04:40:42.805514 139758009304832 logging_writer.py:48] [305200] global_step=305200, grad_norm=3.315552234649658, loss=1.6652092933654785
I0304 04:41:28.022273 139758009304832 logging_writer.py:48] [305300] global_step=305300, grad_norm=3.280593156814575, loss=1.1999707221984863
I0304 04:42:13.038092 139758026090240 logging_writer.py:48] [305400] global_step=305400, grad_norm=3.18070650100708, loss=1.137723684310913
I0304 04:42:17.138473 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:42:28.449753 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:42:49.375473 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:42:51.007041 139953291118400 submission_runner.py:411] Time since start: 146811.18s, 	Step: 305411, 	{'train/accuracy': 0.8877733945846558, 'train/loss': 0.41617128252983093, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 135735.683208704, 'total_duration': 146811.18326807022, 'accumulated_submission_time': 135735.683208704, 'accumulated_eval_time': 11039.826193094254, 'accumulated_logging_time': 20.091625690460205}
I0304 04:42:51.087451 139758009304832 logging_writer.py:48] [305411] accumulated_eval_time=11039.826193, accumulated_logging_time=20.091626, accumulated_submission_time=135735.683209, global_step=305411, preemption_count=0, score=135735.683209, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=146811.183268, train/accuracy=0.887773, train/loss=0.416171, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:43:27.720797 139758026090240 logging_writer.py:48] [305500] global_step=305500, grad_norm=3.3024697303771973, loss=2.1975038051605225
I0304 04:44:12.594686 139758009304832 logging_writer.py:48] [305600] global_step=305600, grad_norm=3.5214710235595703, loss=1.232260823249817
I0304 04:44:57.402805 139758026090240 logging_writer.py:48] [305700] global_step=305700, grad_norm=3.2395763397216797, loss=1.1737509965896606
I0304 04:45:42.715186 139758009304832 logging_writer.py:48] [305800] global_step=305800, grad_norm=3.2109594345092773, loss=1.2351129055023193
I0304 04:46:27.897612 139758026090240 logging_writer.py:48] [305900] global_step=305900, grad_norm=2.8331856727600098, loss=1.5475176572799683
I0304 04:47:12.794193 139758009304832 logging_writer.py:48] [306000] global_step=306000, grad_norm=3.2892212867736816, loss=1.291002869606018
I0304 04:47:57.656905 139758026090240 logging_writer.py:48] [306100] global_step=306100, grad_norm=3.104088306427002, loss=1.2601687908172607
I0304 04:48:42.414991 139758009304832 logging_writer.py:48] [306200] global_step=306200, grad_norm=3.131993293762207, loss=1.3638644218444824
I0304 04:49:27.406837 139758026090240 logging_writer.py:48] [306300] global_step=306300, grad_norm=2.856036424636841, loss=2.2115674018859863
I0304 04:49:51.247791 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:50:03.303173 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:50:34.135027 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:50:35.755021 139953291118400 submission_runner.py:411] Time since start: 147275.93s, 	Step: 306355, 	{'train/accuracy': 0.8863866925239563, 'train/loss': 0.41925445199012756, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 136155.78617358208, 'total_duration': 147275.9312517643, 'accumulated_submission_time': 136155.78617358208, 'accumulated_eval_time': 11084.333412647247, 'accumulated_logging_time': 20.181591033935547}
I0304 04:50:35.816402 139758009304832 logging_writer.py:48] [306355] accumulated_eval_time=11084.333413, accumulated_logging_time=20.181591, accumulated_submission_time=136155.786174, global_step=306355, preemption_count=0, score=136155.786174, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=147275.931252, train/accuracy=0.886387, train/loss=0.419254, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:50:53.948108 139758026090240 logging_writer.py:48] [306400] global_step=306400, grad_norm=2.9940929412841797, loss=1.2465450763702393
I0304 04:51:35.742513 139758009304832 logging_writer.py:48] [306500] global_step=306500, grad_norm=3.154827356338501, loss=1.1444045305252075
I0304 04:52:21.046896 139758026090240 logging_writer.py:48] [306600] global_step=306600, grad_norm=3.310121774673462, loss=1.2170495986938477
I0304 04:53:06.431928 139758009304832 logging_writer.py:48] [306700] global_step=306700, grad_norm=3.0521020889282227, loss=1.5343289375305176
I0304 04:53:51.584969 139758026090240 logging_writer.py:48] [306800] global_step=306800, grad_norm=3.56144380569458, loss=2.8268895149230957
I0304 04:54:36.429028 139758009304832 logging_writer.py:48] [306900] global_step=306900, grad_norm=3.0661468505859375, loss=1.9155137538909912
I0304 04:55:21.210648 139758026090240 logging_writer.py:48] [307000] global_step=307000, grad_norm=2.9842872619628906, loss=1.280974268913269
I0304 04:56:06.214689 139758009304832 logging_writer.py:48] [307100] global_step=307100, grad_norm=3.829181671142578, loss=3.300138473510742
I0304 04:56:51.077447 139758026090240 logging_writer.py:48] [307200] global_step=307200, grad_norm=3.4469027519226074, loss=2.892429828643799
I0304 04:57:36.181975 139758009304832 logging_writer.py:48] [307300] global_step=307300, grad_norm=3.056480884552002, loss=1.1213690042495728
I0304 04:57:36.196074 139953291118400 spec.py:321] Evaluating on the training split.
I0304 04:57:47.240949 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 04:58:11.926036 139953291118400 spec.py:349] Evaluating on the test split.
I0304 04:58:13.558010 139953291118400 submission_runner.py:411] Time since start: 147733.73s, 	Step: 307301, 	{'train/accuracy': 0.8872460722923279, 'train/loss': 0.4167300760746002, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 136576.10743117332, 'total_duration': 147733.73422026634, 'accumulated_submission_time': 136576.10743117332, 'accumulated_eval_time': 11121.695330381393, 'accumulated_logging_time': 20.25333547592163}
I0304 04:58:13.637517 139758026090240 logging_writer.py:48] [307301] accumulated_eval_time=11121.695330, accumulated_logging_time=20.253335, accumulated_submission_time=136576.107431, global_step=307301, preemption_count=0, score=136576.107431, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=147733.734220, train/accuracy=0.887246, train/loss=0.416730, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 04:58:53.935907 139758009304832 logging_writer.py:48] [307400] global_step=307400, grad_norm=3.0598104000091553, loss=1.057987093925476
I0304 04:59:38.697324 139758026090240 logging_writer.py:48] [307500] global_step=307500, grad_norm=2.977726936340332, loss=1.652984380722046
I0304 05:00:23.782763 139758009304832 logging_writer.py:48] [307600] global_step=307600, grad_norm=2.9002270698547363, loss=1.8475308418273926
I0304 05:01:08.860049 139758026090240 logging_writer.py:48] [307700] global_step=307700, grad_norm=3.10032057762146, loss=1.1305121183395386
I0304 05:01:54.201233 139758009304832 logging_writer.py:48] [307800] global_step=307800, grad_norm=3.0814244747161865, loss=1.9304474592208862
I0304 05:02:39.694883 139758026090240 logging_writer.py:48] [307900] global_step=307900, grad_norm=3.139805316925049, loss=1.4768459796905518
I0304 05:03:24.953262 139758009304832 logging_writer.py:48] [308000] global_step=308000, grad_norm=2.829171895980835, loss=1.5696134567260742
I0304 05:04:10.059057 139758026090240 logging_writer.py:48] [308100] global_step=308100, grad_norm=3.078364133834839, loss=1.2380211353302002
I0304 05:04:55.170054 139758009304832 logging_writer.py:48] [308200] global_step=308200, grad_norm=3.0247349739074707, loss=1.4525249004364014
I0304 05:05:13.620775 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:05:25.063631 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:05:45.816099 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:05:47.456631 139953291118400 submission_runner.py:411] Time since start: 148187.63s, 	Step: 308242, 	{'train/accuracy': 0.8857812285423279, 'train/loss': 0.41916921734809875, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 136996.03312301636, 'total_duration': 148187.63279628754, 'accumulated_submission_time': 136996.03312301636, 'accumulated_eval_time': 11155.53110909462, 'accumulated_logging_time': 20.34227418899536}
I0304 05:05:47.531801 139758026090240 logging_writer.py:48] [308242] accumulated_eval_time=11155.531109, accumulated_logging_time=20.342274, accumulated_submission_time=136996.033123, global_step=308242, preemption_count=0, score=136996.033123, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=148187.632796, train/accuracy=0.885781, train/loss=0.419169, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:06:10.825318 139758009304832 logging_writer.py:48] [308300] global_step=308300, grad_norm=3.4357643127441406, loss=1.055588960647583
I0304 05:06:55.271241 139758026090240 logging_writer.py:48] [308400] global_step=308400, grad_norm=3.4839842319488525, loss=3.0495426654815674
I0304 05:07:40.420040 139758009304832 logging_writer.py:48] [308500] global_step=308500, grad_norm=3.149440050125122, loss=1.200092077255249
I0304 05:08:25.666965 139758026090240 logging_writer.py:48] [308600] global_step=308600, grad_norm=3.373371124267578, loss=1.3350995779037476
I0304 05:09:10.790247 139758009304832 logging_writer.py:48] [308700] global_step=308700, grad_norm=3.4606716632843018, loss=1.1098518371582031
I0304 05:09:56.175935 139758026090240 logging_writer.py:48] [308800] global_step=308800, grad_norm=3.1507205963134766, loss=2.4264206886291504
I0304 05:10:41.382760 139758009304832 logging_writer.py:48] [308900] global_step=308900, grad_norm=3.601208448410034, loss=2.274317979812622
I0304 05:11:26.904617 139758026090240 logging_writer.py:48] [309000] global_step=309000, grad_norm=2.9455361366271973, loss=1.1812251806259155
I0304 05:12:12.223916 139758009304832 logging_writer.py:48] [309100] global_step=309100, grad_norm=3.3913931846618652, loss=2.9367806911468506
I0304 05:12:47.621664 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:12:58.761659 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:13:26.598720 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:13:28.230378 139953291118400 submission_runner.py:411] Time since start: 148648.41s, 	Step: 309180, 	{'train/accuracy': 0.887988269329071, 'train/loss': 0.41947051882743835, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 137416.065836668, 'total_duration': 148648.40660881996, 'accumulated_submission_time': 137416.065836668, 'accumulated_eval_time': 11196.13981294632, 'accumulated_logging_time': 20.427332639694214}
I0304 05:13:28.295250 139758026090240 logging_writer.py:48] [309180] accumulated_eval_time=11196.139813, accumulated_logging_time=20.427333, accumulated_submission_time=137416.065837, global_step=309180, preemption_count=0, score=137416.065837, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=148648.406609, train/accuracy=0.887988, train/loss=0.419471, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:13:36.583403 139758009304832 logging_writer.py:48] [309200] global_step=309200, grad_norm=3.2148311138153076, loss=1.1039860248565674
I0304 05:14:17.535896 139758026090240 logging_writer.py:48] [309300] global_step=309300, grad_norm=3.036381244659424, loss=2.494166135787964
I0304 05:15:02.362653 139758009304832 logging_writer.py:48] [309400] global_step=309400, grad_norm=3.20251727104187, loss=1.4564018249511719
I0304 05:15:47.134931 139758026090240 logging_writer.py:48] [309500] global_step=309500, grad_norm=3.159834861755371, loss=1.4006961584091187
I0304 05:16:32.708919 139758009304832 logging_writer.py:48] [309600] global_step=309600, grad_norm=3.549333333969116, loss=3.053664445877075
I0304 05:17:17.307662 139758026090240 logging_writer.py:48] [309700] global_step=309700, grad_norm=2.9280261993408203, loss=1.0875530242919922
I0304 05:18:02.057041 139758009304832 logging_writer.py:48] [309800] global_step=309800, grad_norm=3.1762804985046387, loss=1.1470375061035156
I0304 05:18:47.067043 139758026090240 logging_writer.py:48] [309900] global_step=309900, grad_norm=3.349490165710449, loss=2.4274709224700928
I0304 05:19:32.040347 139758009304832 logging_writer.py:48] [310000] global_step=310000, grad_norm=3.3044869899749756, loss=1.1689199209213257
I0304 05:20:16.869086 139758026090240 logging_writer.py:48] [310100] global_step=310100, grad_norm=3.153592586517334, loss=1.1478829383850098
I0304 05:20:28.648559 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:20:39.693421 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:20:58.648014 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:21:00.286542 139953291118400 submission_runner.py:411] Time since start: 149100.46s, 	Step: 310128, 	{'train/accuracy': 0.8869140148162842, 'train/loss': 0.42429786920547485, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 137836.3591003418, 'total_duration': 149100.46276378632, 'accumulated_submission_time': 137836.3591003418, 'accumulated_eval_time': 11227.777802228928, 'accumulated_logging_time': 20.504528522491455}
I0304 05:21:00.363428 139758009304832 logging_writer.py:48] [310128] accumulated_eval_time=11227.777802, accumulated_logging_time=20.504529, accumulated_submission_time=137836.359100, global_step=310128, preemption_count=0, score=137836.359100, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=149100.462764, train/accuracy=0.886914, train/loss=0.424298, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:21:29.252350 139758026090240 logging_writer.py:48] [310200] global_step=310200, grad_norm=3.212994337081909, loss=1.2990261316299438
I0304 05:22:14.318674 139758009304832 logging_writer.py:48] [310300] global_step=310300, grad_norm=2.9907102584838867, loss=1.1012237071990967
I0304 05:22:59.564004 139758026090240 logging_writer.py:48] [310400] global_step=310400, grad_norm=3.1839826107025146, loss=1.170651912689209
I0304 05:23:45.017809 139758009304832 logging_writer.py:48] [310500] global_step=310500, grad_norm=2.882234811782837, loss=1.926795244216919
I0304 05:24:29.857297 139758026090240 logging_writer.py:48] [310600] global_step=310600, grad_norm=3.210801362991333, loss=1.9383095502853394
I0304 05:25:14.782648 139758009304832 logging_writer.py:48] [310700] global_step=310700, grad_norm=2.9693868160247803, loss=2.2540104389190674
I0304 05:25:59.971319 139758026090240 logging_writer.py:48] [310800] global_step=310800, grad_norm=3.050175189971924, loss=1.9748950004577637
I0304 05:26:45.040852 139758009304832 logging_writer.py:48] [310900] global_step=310900, grad_norm=3.06122088432312, loss=1.381088137626648
I0304 05:27:29.789353 139758026090240 logging_writer.py:48] [311000] global_step=311000, grad_norm=3.0765044689178467, loss=2.4221179485321045
I0304 05:28:00.338493 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:28:11.612727 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:28:38.083981 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:28:39.718076 139953291118400 submission_runner.py:411] Time since start: 149559.89s, 	Step: 311070, 	{'train/accuracy': 0.8864843845367432, 'train/loss': 0.4207232892513275, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 138256.27770638466, 'total_duration': 149559.89429020882, 'accumulated_submission_time': 138256.27770638466, 'accumulated_eval_time': 11267.157366037369, 'accumulated_logging_time': 20.590729236602783}
I0304 05:28:39.795424 139758009304832 logging_writer.py:48] [311070] accumulated_eval_time=11267.157366, accumulated_logging_time=20.590729, accumulated_submission_time=138256.277706, global_step=311070, preemption_count=0, score=138256.277706, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=149559.894290, train/accuracy=0.886484, train/loss=0.420723, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:28:52.044833 139758026090240 logging_writer.py:48] [311100] global_step=311100, grad_norm=3.1203434467315674, loss=1.5347306728363037
I0304 05:29:33.738340 139758009304832 logging_writer.py:48] [311200] global_step=311200, grad_norm=3.0232772827148438, loss=1.0577267408370972
I0304 05:30:18.804613 139758026090240 logging_writer.py:48] [311300] global_step=311300, grad_norm=3.457120418548584, loss=1.1243160963058472
I0304 05:31:03.845382 139758009304832 logging_writer.py:48] [311400] global_step=311400, grad_norm=3.2098548412323, loss=1.030349850654602
I0304 05:31:49.144812 139758026090240 logging_writer.py:48] [311500] global_step=311500, grad_norm=3.0025885105133057, loss=2.2128591537475586
I0304 05:32:34.332112 139758009304832 logging_writer.py:48] [311600] global_step=311600, grad_norm=3.4092671871185303, loss=3.0336716175079346
I0304 05:33:19.179850 139758026090240 logging_writer.py:48] [311700] global_step=311700, grad_norm=3.131887435913086, loss=2.8277499675750732
I0304 05:34:04.438114 139758009304832 logging_writer.py:48] [311800] global_step=311800, grad_norm=2.95796537399292, loss=1.083895206451416
I0304 05:34:49.381591 139758026090240 logging_writer.py:48] [311900] global_step=311900, grad_norm=3.013840913772583, loss=1.178775429725647
I0304 05:35:34.441846 139758009304832 logging_writer.py:48] [312000] global_step=312000, grad_norm=3.343763589859009, loss=1.2452291250228882
I0304 05:35:39.780172 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:35:50.683584 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:36:17.594087 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:36:19.225303 139953291118400 submission_runner.py:411] Time since start: 150019.40s, 	Step: 312014, 	{'train/accuracy': 0.8853515386581421, 'train/loss': 0.42565134167671204, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 138676.20446014404, 'total_duration': 150019.4015262127, 'accumulated_submission_time': 138676.20446014404, 'accumulated_eval_time': 11306.6024684906, 'accumulated_logging_time': 20.678019762039185}
I0304 05:36:19.301392 139758026090240 logging_writer.py:48] [312014] accumulated_eval_time=11306.602468, accumulated_logging_time=20.678020, accumulated_submission_time=138676.204460, global_step=312014, preemption_count=0, score=138676.204460, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=150019.401526, train/accuracy=0.885352, train/loss=0.425651, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:36:53.670783 139758009304832 logging_writer.py:48] [312100] global_step=312100, grad_norm=3.2146236896514893, loss=1.412602424621582
I0304 05:37:38.307008 139758026090240 logging_writer.py:48] [312200] global_step=312200, grad_norm=3.0790858268737793, loss=1.0745371580123901
I0304 05:38:23.526434 139758009304832 logging_writer.py:48] [312300] global_step=312300, grad_norm=3.2254085540771484, loss=2.385101795196533
I0304 05:39:08.659121 139758026090240 logging_writer.py:48] [312400] global_step=312400, grad_norm=3.0106513500213623, loss=1.5231579542160034
I0304 05:39:53.335758 139758009304832 logging_writer.py:48] [312500] global_step=312500, grad_norm=3.674809217453003, loss=3.1283886432647705
I0304 05:40:38.047559 139758026090240 logging_writer.py:48] [312600] global_step=312600, grad_norm=3.068326234817505, loss=1.3894203901290894
I0304 05:41:23.025805 139758009304832 logging_writer.py:48] [312700] global_step=312700, grad_norm=3.254018545150757, loss=1.2343090772628784
I0304 05:42:08.028856 139758026090240 logging_writer.py:48] [312800] global_step=312800, grad_norm=2.869971513748169, loss=1.3631527423858643
I0304 05:42:52.891560 139758009304832 logging_writer.py:48] [312900] global_step=312900, grad_norm=3.1063332557678223, loss=2.5421998500823975
I0304 05:43:19.632955 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:43:30.649610 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:43:52.572461 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:43:54.208799 139953291118400 submission_runner.py:411] Time since start: 150474.39s, 	Step: 312961, 	{'train/accuracy': 0.8886913657188416, 'train/loss': 0.41274601221084595, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 139096.4767267704, 'total_duration': 150474.38501358032, 'accumulated_submission_time': 139096.4767267704, 'accumulated_eval_time': 11341.178297281265, 'accumulated_logging_time': 20.76548171043396}
I0304 05:43:54.288599 139758026090240 logging_writer.py:48] [312961] accumulated_eval_time=11341.178297, accumulated_logging_time=20.765482, accumulated_submission_time=139096.476727, global_step=312961, preemption_count=0, score=139096.476727, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=150474.385014, train/accuracy=0.888691, train/loss=0.412746, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:44:10.116837 139758009304832 logging_writer.py:48] [313000] global_step=313000, grad_norm=3.0476558208465576, loss=1.5931079387664795
I0304 05:44:52.678136 139758026090240 logging_writer.py:48] [313100] global_step=313100, grad_norm=3.6705105304718018, loss=3.267970561981201
I0304 05:45:37.605926 139758009304832 logging_writer.py:48] [313200] global_step=313200, grad_norm=3.028806447982788, loss=1.4432058334350586
I0304 05:46:22.693521 139758026090240 logging_writer.py:48] [313300] global_step=313300, grad_norm=3.064697027206421, loss=1.1764947175979614
I0304 05:47:07.827604 139758009304832 logging_writer.py:48] [313400] global_step=313400, grad_norm=3.12650203704834, loss=1.910417079925537
I0304 05:47:52.749694 139758026090240 logging_writer.py:48] [313500] global_step=313500, grad_norm=3.4142699241638184, loss=1.2000099420547485
I0304 05:48:37.842958 139758009304832 logging_writer.py:48] [313600] global_step=313600, grad_norm=3.115460157394409, loss=1.09883713722229
I0304 05:49:22.838460 139758026090240 logging_writer.py:48] [313700] global_step=313700, grad_norm=3.0565109252929688, loss=1.5673713684082031
I0304 05:50:07.889757 139758009304832 logging_writer.py:48] [313800] global_step=313800, grad_norm=3.0967328548431396, loss=1.1416044235229492
I0304 05:50:53.032636 139758026090240 logging_writer.py:48] [313900] global_step=313900, grad_norm=4.245199203491211, loss=3.2431347370147705
I0304 05:50:54.470364 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:51:05.672484 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:51:31.099159 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:51:32.748476 139953291118400 submission_runner.py:411] Time since start: 150932.92s, 	Step: 313905, 	{'train/accuracy': 0.8878710865974426, 'train/loss': 0.4168930649757385, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 139516.60149145126, 'total_duration': 150932.9247033596, 'accumulated_submission_time': 139516.60149145126, 'accumulated_eval_time': 11379.45639872551, 'accumulated_logging_time': 20.855316400527954}
I0304 05:51:32.809603 139758009304832 logging_writer.py:48] [313905] accumulated_eval_time=11379.456399, accumulated_logging_time=20.855316, accumulated_submission_time=139516.601491, global_step=313905, preemption_count=0, score=139516.601491, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=150932.924703, train/accuracy=0.887871, train/loss=0.416893, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:52:10.724609 139758026090240 logging_writer.py:48] [314000] global_step=314000, grad_norm=3.3771350383758545, loss=2.627579927444458
I0304 05:52:55.621528 139758009304832 logging_writer.py:48] [314100] global_step=314100, grad_norm=3.1764886379241943, loss=1.4623304605484009
I0304 05:53:40.462335 139758026090240 logging_writer.py:48] [314200] global_step=314200, grad_norm=3.194554567337036, loss=2.8499772548675537
I0304 05:54:25.657418 139758009304832 logging_writer.py:48] [314300] global_step=314300, grad_norm=3.135589838027954, loss=1.6487281322479248
I0304 05:55:10.688097 139758026090240 logging_writer.py:48] [314400] global_step=314400, grad_norm=3.6551413536071777, loss=2.9910707473754883
I0304 05:55:55.474895 139758009304832 logging_writer.py:48] [314500] global_step=314500, grad_norm=3.4787604808807373, loss=3.051206588745117
I0304 05:56:40.821193 139758026090240 logging_writer.py:48] [314600] global_step=314600, grad_norm=3.65586519241333, loss=2.8976662158966064
I0304 05:57:25.841289 139758009304832 logging_writer.py:48] [314700] global_step=314700, grad_norm=3.0729074478149414, loss=1.6390191316604614
I0304 05:58:10.720469 139758026090240 logging_writer.py:48] [314800] global_step=314800, grad_norm=3.082520008087158, loss=1.0604904890060425
I0304 05:58:32.896387 139953291118400 spec.py:321] Evaluating on the training split.
I0304 05:58:43.851138 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 05:59:06.152686 139953291118400 spec.py:349] Evaluating on the test split.
I0304 05:59:07.783930 139953291118400 submission_runner.py:411] Time since start: 151387.96s, 	Step: 314851, 	{'train/accuracy': 0.8854687213897705, 'train/loss': 0.42337003350257874, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 139936.63247156143, 'total_duration': 151387.96013522148, 'accumulated_submission_time': 139936.63247156143, 'accumulated_eval_time': 11414.343953609467, 'accumulated_logging_time': 20.924494981765747}
I0304 05:59:07.860038 139758009304832 logging_writer.py:48] [314851] accumulated_eval_time=11414.343954, accumulated_logging_time=20.924495, accumulated_submission_time=139936.632472, global_step=314851, preemption_count=0, score=139936.632472, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=151387.960135, train/accuracy=0.885469, train/loss=0.423370, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 05:59:27.595698 139758026090240 logging_writer.py:48] [314900] global_step=314900, grad_norm=3.168696403503418, loss=1.1096946001052856
I0304 06:00:11.284679 139758009304832 logging_writer.py:48] [315000] global_step=315000, grad_norm=3.225872755050659, loss=2.9338600635528564
I0304 06:00:56.235162 139758026090240 logging_writer.py:48] [315100] global_step=315100, grad_norm=3.1199686527252197, loss=1.0937695503234863
I0304 06:01:41.364392 139758009304832 logging_writer.py:48] [315200] global_step=315200, grad_norm=3.207416534423828, loss=2.654106616973877
I0304 06:02:26.592747 139758026090240 logging_writer.py:48] [315300] global_step=315300, grad_norm=3.2993996143341064, loss=2.2471365928649902
I0304 06:03:11.744061 139758009304832 logging_writer.py:48] [315400] global_step=315400, grad_norm=3.086264133453369, loss=1.1126036643981934
I0304 06:03:56.658987 139758026090240 logging_writer.py:48] [315500] global_step=315500, grad_norm=3.4891672134399414, loss=3.058218479156494
I0304 06:04:41.903269 139758009304832 logging_writer.py:48] [315600] global_step=315600, grad_norm=3.1497251987457275, loss=1.0944197177886963
I0304 06:05:27.055677 139758026090240 logging_writer.py:48] [315700] global_step=315700, grad_norm=3.0880818367004395, loss=1.0331017971038818
I0304 06:06:08.058656 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:06:19.640493 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 06:06:49.656851 139953291118400 spec.py:349] Evaluating on the test split.
I0304 06:06:51.290786 139953291118400 submission_runner.py:411] Time since start: 151851.47s, 	Step: 315793, 	{'train/accuracy': 0.8864843845367432, 'train/loss': 0.4232950806617737, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 140356.7695221901, 'total_duration': 151851.4670085907, 'accumulated_submission_time': 140356.7695221901, 'accumulated_eval_time': 11457.576095819473, 'accumulated_logging_time': 21.0146746635437}
I0304 06:06:51.367831 139758009304832 logging_writer.py:48] [315793] accumulated_eval_time=11457.576096, accumulated_logging_time=21.014675, accumulated_submission_time=140356.769522, global_step=315793, preemption_count=0, score=140356.769522, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=151851.467009, train/accuracy=0.886484, train/loss=0.423295, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 06:06:54.528762 139758026090240 logging_writer.py:48] [315800] global_step=315800, grad_norm=3.024106979370117, loss=1.0564614534378052
I0304 06:07:34.648750 139758009304832 logging_writer.py:48] [315900] global_step=315900, grad_norm=3.1641974449157715, loss=1.0901278257369995
I0304 06:08:19.647367 139758026090240 logging_writer.py:48] [316000] global_step=316000, grad_norm=3.17543625831604, loss=1.4117107391357422
I0304 06:09:04.847257 139758009304832 logging_writer.py:48] [316100] global_step=316100, grad_norm=3.0667340755462646, loss=1.4924345016479492
I0304 06:09:50.155457 139758026090240 logging_writer.py:48] [316200] global_step=316200, grad_norm=4.049197673797607, loss=3.248469114303589
I0304 06:10:35.143549 139758009304832 logging_writer.py:48] [316300] global_step=316300, grad_norm=3.2745277881622314, loss=1.130123496055603
I0304 06:11:20.006868 139758026090240 logging_writer.py:48] [316400] global_step=316400, grad_norm=3.385112762451172, loss=1.998697280883789
I0304 06:12:04.922070 139758009304832 logging_writer.py:48] [316500] global_step=316500, grad_norm=3.234391689300537, loss=2.597154140472412
I0304 06:12:49.833281 139758026090240 logging_writer.py:48] [316600] global_step=316600, grad_norm=3.0385220050811768, loss=1.280458688735962
I0304 06:13:34.760149 139758009304832 logging_writer.py:48] [316700] global_step=316700, grad_norm=3.238635778427124, loss=1.2020951509475708
I0304 06:13:51.605983 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:14:02.554332 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 06:14:21.251483 139953291118400 spec.py:349] Evaluating on the test split.
I0304 06:14:22.889101 139953291118400 submission_runner.py:411] Time since start: 152303.07s, 	Step: 316739, 	{'train/accuracy': 0.8882226347923279, 'train/loss': 0.41662275791168213, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 140776.95079994202, 'total_duration': 152303.06532382965, 'accumulated_submission_time': 140776.95079994202, 'accumulated_eval_time': 11488.859185695648, 'accumulated_logging_time': 21.10109519958496}
I0304 06:14:22.967587 139758026090240 logging_writer.py:48] [316739] accumulated_eval_time=11488.859186, accumulated_logging_time=21.101095, accumulated_submission_time=140776.950800, global_step=316739, preemption_count=0, score=140776.950800, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=152303.065324, train/accuracy=0.888223, train/loss=0.416623, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 06:14:47.478420 139758009304832 logging_writer.py:48] [316800] global_step=316800, grad_norm=2.95510196685791, loss=1.049393653869629
I0304 06:15:31.968969 139758026090240 logging_writer.py:48] [316900] global_step=316900, grad_norm=3.401564121246338, loss=2.8104424476623535
I0304 06:16:17.143284 139758009304832 logging_writer.py:48] [317000] global_step=317000, grad_norm=3.277618408203125, loss=1.8100773096084595
I0304 06:17:02.181219 139758026090240 logging_writer.py:48] [317100] global_step=317100, grad_norm=3.0987753868103027, loss=2.073472023010254
I0304 06:17:46.986208 139758009304832 logging_writer.py:48] [317200] global_step=317200, grad_norm=3.2359564304351807, loss=2.7503883838653564
I0304 06:18:32.077942 139758026090240 logging_writer.py:48] [317300] global_step=317300, grad_norm=3.6764376163482666, loss=1.3550300598144531
I0304 06:19:16.999176 139758009304832 logging_writer.py:48] [317400] global_step=317400, grad_norm=2.9216179847717285, loss=1.135983943939209
I0304 06:20:02.284722 139758026090240 logging_writer.py:48] [317500] global_step=317500, grad_norm=3.2922120094299316, loss=1.1510707139968872
I0304 06:20:47.130907 139758009304832 logging_writer.py:48] [317600] global_step=317600, grad_norm=2.97406005859375, loss=1.0881680250167847
I0304 06:21:23.268786 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:21:34.528928 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 06:21:59.869562 139953291118400 spec.py:349] Evaluating on the test split.
I0304 06:22:01.509523 139953291118400 submission_runner.py:411] Time since start: 152761.69s, 	Step: 317682, 	{'train/accuracy': 0.8858593702316284, 'train/loss': 0.41918542981147766, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 141197.1936097145, 'total_duration': 152761.68574547768, 'accumulated_submission_time': 141197.1936097145, 'accumulated_eval_time': 11527.099912643433, 'accumulated_logging_time': 21.190728902816772}
I0304 06:22:01.615207 139758026090240 logging_writer.py:48] [317682] accumulated_eval_time=11527.099913, accumulated_logging_time=21.190729, accumulated_submission_time=141197.193610, global_step=317682, preemption_count=0, score=141197.193610, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=152761.685745, train/accuracy=0.885859, train/loss=0.419185, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 06:22:09.154023 139758009304832 logging_writer.py:48] [317700] global_step=317700, grad_norm=4.0557732582092285, loss=3.3346171379089355
I0304 06:22:51.343693 139758026090240 logging_writer.py:48] [317800] global_step=317800, grad_norm=3.4323320388793945, loss=1.6707568168640137
I0304 06:23:36.396159 139758009304832 logging_writer.py:48] [317900] global_step=317900, grad_norm=3.1578447818756104, loss=2.092758893966675
I0304 06:24:21.502210 139758026090240 logging_writer.py:48] [318000] global_step=318000, grad_norm=3.6873397827148438, loss=3.1059536933898926
I0304 06:25:07.008198 139758009304832 logging_writer.py:48] [318100] global_step=318100, grad_norm=3.1033682823181152, loss=1.191877841949463
I0304 06:25:51.971831 139758026090240 logging_writer.py:48] [318200] global_step=318200, grad_norm=3.018073797225952, loss=1.1703286170959473
I0304 06:26:37.488874 139758009304832 logging_writer.py:48] [318300] global_step=318300, grad_norm=3.2554054260253906, loss=2.2291150093078613
I0304 06:27:22.749197 139758026090240 logging_writer.py:48] [318400] global_step=318400, grad_norm=3.0460524559020996, loss=2.4931867122650146
I0304 06:28:07.776710 139758009304832 logging_writer.py:48] [318500] global_step=318500, grad_norm=2.8558695316314697, loss=1.867836833000183
I0304 06:28:52.699537 139758026090240 logging_writer.py:48] [318600] global_step=318600, grad_norm=3.2434005737304688, loss=1.139586329460144
I0304 06:29:01.779556 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:29:12.863927 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 06:29:44.287716 139953291118400 spec.py:349] Evaluating on the test split.
I0304 06:29:45.913878 139953291118400 submission_runner.py:411] Time since start: 153226.09s, 	Step: 318622, 	{'train/accuracy': 0.8885741829872131, 'train/loss': 0.4191855788230896, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 141617.29385328293, 'total_duration': 153226.09011101723, 'accumulated_submission_time': 141617.29385328293, 'accumulated_eval_time': 11571.23422384262, 'accumulated_logging_time': 21.31320881843567}
I0304 06:29:45.978330 139758009304832 logging_writer.py:48] [318622] accumulated_eval_time=11571.234224, accumulated_logging_time=21.313209, accumulated_submission_time=141617.293853, global_step=318622, preemption_count=0, score=141617.293853, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=153226.090111, train/accuracy=0.888574, train/loss=0.419186, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 06:30:17.161359 139758026090240 logging_writer.py:48] [318700] global_step=318700, grad_norm=3.082812786102295, loss=1.1649296283721924
I0304 06:31:00.774390 139758009304832 logging_writer.py:48] [318800] global_step=318800, grad_norm=3.415585517883301, loss=3.1155471801757812
I0304 06:31:45.927401 139758026090240 logging_writer.py:48] [318900] global_step=318900, grad_norm=3.905919313430786, loss=3.189448356628418
I0304 06:32:31.262375 139758009304832 logging_writer.py:48] [319000] global_step=319000, grad_norm=2.9313437938690186, loss=1.0534809827804565
I0304 06:33:16.230713 139758026090240 logging_writer.py:48] [319100] global_step=319100, grad_norm=3.8304197788238525, loss=3.1870198249816895
I0304 06:34:00.757330 139758009304832 logging_writer.py:48] [319200] global_step=319200, grad_norm=3.3684401512145996, loss=1.2273728847503662
I0304 06:34:45.711564 139758026090240 logging_writer.py:48] [319300] global_step=319300, grad_norm=3.3101329803466797, loss=1.1686508655548096
I0304 06:35:30.599561 139758009304832 logging_writer.py:48] [319400] global_step=319400, grad_norm=3.101048469543457, loss=1.3735027313232422
I0304 06:36:15.740280 139758026090240 logging_writer.py:48] [319500] global_step=319500, grad_norm=2.82554292678833, loss=1.0538114309310913
I0304 06:36:45.936615 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:36:56.959110 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 06:37:19.063661 139953291118400 spec.py:349] Evaluating on the test split.
I0304 06:37:20.708277 139953291118400 submission_runner.py:411] Time since start: 153680.88s, 	Step: 319569, 	{'train/accuracy': 0.8874022960662842, 'train/loss': 0.4200645089149475, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 142037.1958515644, 'total_duration': 153680.8844909668, 'accumulated_submission_time': 142037.1958515644, 'accumulated_eval_time': 11606.005845546722, 'accumulated_logging_time': 21.38654923439026}
I0304 06:37:20.788189 139758009304832 logging_writer.py:48] [319569] accumulated_eval_time=11606.005846, accumulated_logging_time=21.386549, accumulated_submission_time=142037.195852, global_step=319569, preemption_count=0, score=142037.195852, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=153680.884491, train/accuracy=0.887402, train/loss=0.420065, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 06:37:33.417396 139758026090240 logging_writer.py:48] [319600] global_step=319600, grad_norm=3.6486024856567383, loss=3.0623154640197754
I0304 06:38:15.320161 139758009304832 logging_writer.py:48] [319700] global_step=319700, grad_norm=3.0114479064941406, loss=1.1495623588562012
I0304 06:39:00.289167 139758026090240 logging_writer.py:48] [319800] global_step=319800, grad_norm=3.0171568393707275, loss=1.3523861169815063
I0304 06:39:45.273599 139758009304832 logging_writer.py:48] [319900] global_step=319900, grad_norm=4.895042419433594, loss=2.24666690826416
I0304 06:40:30.358481 139758026090240 logging_writer.py:48] [320000] global_step=320000, grad_norm=3.01717209815979, loss=1.509879469871521
I0304 06:41:15.196291 139758009304832 logging_writer.py:48] [320100] global_step=320100, grad_norm=3.18534255027771, loss=1.545425295829773
I0304 06:41:59.937904 139758026090240 logging_writer.py:48] [320200] global_step=320200, grad_norm=2.916533946990967, loss=1.2337521314620972
I0304 06:42:45.583240 139758009304832 logging_writer.py:48] [320300] global_step=320300, grad_norm=3.0156328678131104, loss=1.1026325225830078
I0304 06:43:30.587194 139758026090240 logging_writer.py:48] [320400] global_step=320400, grad_norm=3.0116217136383057, loss=1.3486042022705078
I0304 06:44:15.833263 139758009304832 logging_writer.py:48] [320500] global_step=320500, grad_norm=3.2763683795928955, loss=2.3720736503601074
I0304 06:44:20.957823 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:44:32.345034 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 06:44:54.860110 139953291118400 spec.py:349] Evaluating on the test split.
I0304 06:44:56.491046 139953291118400 submission_runner.py:411] Time since start: 154136.67s, 	Step: 320513, 	{'train/accuracy': 0.8875195384025574, 'train/loss': 0.4228684604167938, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 142457.30712151527, 'total_duration': 154136.66727113724, 'accumulated_submission_time': 142457.30712151527, 'accumulated_eval_time': 11641.539048671722, 'accumulated_logging_time': 21.477246522903442}
I0304 06:44:56.568712 139758026090240 logging_writer.py:48] [320513] accumulated_eval_time=11641.539049, accumulated_logging_time=21.477247, accumulated_submission_time=142457.307122, global_step=320513, preemption_count=0, score=142457.307122, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=154136.667271, train/accuracy=0.887520, train/loss=0.422868, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 06:45:32.049288 139758009304832 logging_writer.py:48] [320600] global_step=320600, grad_norm=3.072953224182129, loss=1.5424189567565918
I0304 06:46:16.786362 139758026090240 logging_writer.py:48] [320700] global_step=320700, grad_norm=4.106022834777832, loss=3.1957454681396484
I0304 06:47:02.101747 139758009304832 logging_writer.py:48] [320800] global_step=320800, grad_norm=3.112868309020996, loss=1.3968884944915771
I0304 06:47:47.265662 139758026090240 logging_writer.py:48] [320900] global_step=320900, grad_norm=3.4679222106933594, loss=3.115243673324585
I0304 06:48:32.094405 139758009304832 logging_writer.py:48] [321000] global_step=321000, grad_norm=2.715271472930908, loss=1.5338507890701294
I0304 06:49:17.214505 139758026090240 logging_writer.py:48] [321100] global_step=321100, grad_norm=3.1059861183166504, loss=1.1463661193847656
I0304 06:50:02.238118 139758009304832 logging_writer.py:48] [321200] global_step=321200, grad_norm=3.6070215702056885, loss=2.9891855716705322
I0304 06:50:46.810815 139758026090240 logging_writer.py:48] [321300] global_step=321300, grad_norm=3.4506654739379883, loss=2.927250623703003
I0304 06:51:31.949620 139758009304832 logging_writer.py:48] [321400] global_step=321400, grad_norm=2.9403040409088135, loss=1.074497103691101
I0304 06:51:56.993959 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:52:08.101038 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 06:52:39.366947 139953291118400 spec.py:349] Evaluating on the test split.
I0304 06:52:40.986920 139953291118400 submission_runner.py:411] Time since start: 154601.16s, 	Step: 321457, 	{'train/accuracy': 0.8886523246765137, 'train/loss': 0.41924482583999634, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 142877.6751279831, 'total_duration': 154601.16312241554, 'accumulated_submission_time': 142877.6751279831, 'accumulated_eval_time': 11685.531976222992, 'accumulated_logging_time': 21.564911127090454}
I0304 06:52:41.049376 139758026090240 logging_writer.py:48] [321457] accumulated_eval_time=11685.531976, accumulated_logging_time=21.564911, accumulated_submission_time=142877.675128, global_step=321457, preemption_count=0, score=142877.675128, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=154601.163122, train/accuracy=0.888652, train/loss=0.419245, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 06:52:58.400664 139758009304832 logging_writer.py:48] [321500] global_step=321500, grad_norm=3.1411046981811523, loss=2.675548553466797
I0304 06:53:40.437283 139758026090240 logging_writer.py:48] [321600] global_step=321600, grad_norm=3.5062098503112793, loss=1.0307185649871826
I0304 06:54:25.506863 139758009304832 logging_writer.py:48] [321700] global_step=321700, grad_norm=3.058406114578247, loss=1.4249632358551025
I0304 06:55:10.637486 139758026090240 logging_writer.py:48] [321800] global_step=321800, grad_norm=2.8790292739868164, loss=1.2731667757034302
I0304 06:55:55.600728 139758009304832 logging_writer.py:48] [321900] global_step=321900, grad_norm=3.598426580429077, loss=2.981159210205078
I0304 06:56:40.678048 139758026090240 logging_writer.py:48] [322000] global_step=322000, grad_norm=3.052309036254883, loss=1.1059541702270508
I0304 06:57:25.789019 139758009304832 logging_writer.py:48] [322100] global_step=322100, grad_norm=3.1827797889709473, loss=1.1998214721679688
I0304 06:58:10.981210 139758026090240 logging_writer.py:48] [322200] global_step=322200, grad_norm=3.0240323543548584, loss=1.863906741142273
I0304 06:58:55.719669 139758009304832 logging_writer.py:48] [322300] global_step=322300, grad_norm=3.2774529457092285, loss=2.2850286960601807
I0304 06:59:40.600119 139758026090240 logging_writer.py:48] [322400] global_step=322400, grad_norm=2.973266124725342, loss=2.1619913578033447
I0304 06:59:41.140304 139953291118400 spec.py:321] Evaluating on the training split.
I0304 06:59:52.150338 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:00:21.371850 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:00:22.993826 139953291118400 submission_runner.py:411] Time since start: 155063.17s, 	Step: 322403, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.42196181416511536, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 143297.70597314835, 'total_duration': 155063.17006206512, 'accumulated_submission_time': 143297.70597314835, 'accumulated_eval_time': 11727.38549900055, 'accumulated_logging_time': 21.639564275741577}
I0304 07:00:23.057883 139758009304832 logging_writer.py:48] [322403] accumulated_eval_time=11727.385499, accumulated_logging_time=21.639564, accumulated_submission_time=143297.705973, global_step=322403, preemption_count=0, score=143297.705973, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=155063.170062, train/accuracy=0.886465, train/loss=0.421962, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:01:02.003655 139758026090240 logging_writer.py:48] [322500] global_step=322500, grad_norm=3.1826601028442383, loss=1.0726262331008911
I0304 07:01:46.893287 139758009304832 logging_writer.py:48] [322600] global_step=322600, grad_norm=3.0862579345703125, loss=1.0620332956314087
I0304 07:02:32.035036 139758026090240 logging_writer.py:48] [322700] global_step=322700, grad_norm=3.6033079624176025, loss=3.150561809539795
I0304 07:03:17.412440 139758009304832 logging_writer.py:48] [322800] global_step=322800, grad_norm=3.0093142986297607, loss=1.1557817459106445
I0304 07:04:02.184010 139758026090240 logging_writer.py:48] [322900] global_step=322900, grad_norm=3.0984182357788086, loss=1.182399868965149
I0304 07:04:46.954151 139758009304832 logging_writer.py:48] [323000] global_step=323000, grad_norm=3.2272822856903076, loss=2.24173641204834
I0304 07:05:32.047029 139758026090240 logging_writer.py:48] [323100] global_step=323100, grad_norm=3.4108848571777344, loss=3.001544952392578
I0304 07:06:17.023248 139758009304832 logging_writer.py:48] [323200] global_step=323200, grad_norm=4.167128086090088, loss=3.1535239219665527
I0304 07:07:01.885254 139758026090240 logging_writer.py:48] [323300] global_step=323300, grad_norm=3.7536637783050537, loss=3.2559335231781006
I0304 07:07:23.133524 139953291118400 spec.py:321] Evaluating on the training split.
I0304 07:07:34.362344 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:07:54.439705 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:07:56.074521 139953291118400 submission_runner.py:411] Time since start: 155516.25s, 	Step: 323349, 	{'train/accuracy': 0.8867577910423279, 'train/loss': 0.4161965548992157, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 143717.72579455376, 'total_duration': 155516.2507390976, 'accumulated_submission_time': 143717.72579455376, 'accumulated_eval_time': 11760.326476812363, 'accumulated_logging_time': 21.712828397750854}
I0304 07:07:56.151666 139758009304832 logging_writer.py:48] [323349] accumulated_eval_time=11760.326477, accumulated_logging_time=21.712828, accumulated_submission_time=143717.725795, global_step=323349, preemption_count=0, score=143717.725795, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=155516.250739, train/accuracy=0.886758, train/loss=0.416197, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:08:16.693752 139758026090240 logging_writer.py:48] [323400] global_step=323400, grad_norm=3.2358009815216064, loss=1.2449268102645874
I0304 07:09:00.620297 139758009304832 logging_writer.py:48] [323500] global_step=323500, grad_norm=3.513965606689453, loss=2.310922384262085
I0304 07:09:45.747146 139758026090240 logging_writer.py:48] [323600] global_step=323600, grad_norm=3.043853282928467, loss=1.1209511756896973
I0304 07:10:30.785410 139758009304832 logging_writer.py:48] [323700] global_step=323700, grad_norm=3.8175480365753174, loss=1.0794618129730225
I0304 07:11:16.013244 139758026090240 logging_writer.py:48] [323800] global_step=323800, grad_norm=3.098740339279175, loss=1.1667671203613281
I0304 07:12:00.737864 139758009304832 logging_writer.py:48] [323900] global_step=323900, grad_norm=3.1278750896453857, loss=2.3359131813049316
I0304 07:12:45.921449 139758026090240 logging_writer.py:48] [324000] global_step=324000, grad_norm=2.945378541946411, loss=1.0749180316925049
I0304 07:13:31.475997 139758009304832 logging_writer.py:48] [324100] global_step=324100, grad_norm=3.093904495239258, loss=1.3251183032989502
I0304 07:14:16.479928 139758026090240 logging_writer.py:48] [324200] global_step=324200, grad_norm=3.484672784805298, loss=1.1277704238891602
I0304 07:14:56.425212 139953291118400 spec.py:321] Evaluating on the training split.
I0304 07:15:08.049019 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:15:38.719480 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:15:40.346831 139953291118400 submission_runner.py:411] Time since start: 155980.52s, 	Step: 324290, 	{'train/accuracy': 0.8874022960662842, 'train/loss': 0.41827842593193054, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 144137.9409184456, 'total_duration': 155980.52302742004, 'accumulated_submission_time': 144137.9409184456, 'accumulated_eval_time': 11804.248053789139, 'accumulated_logging_time': 21.801358461380005}
I0304 07:15:40.420621 139758009304832 logging_writer.py:48] [324290] accumulated_eval_time=11804.248054, accumulated_logging_time=21.801358, accumulated_submission_time=144137.940918, global_step=324290, preemption_count=0, score=144137.940918, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=155980.523027, train/accuracy=0.887402, train/loss=0.418278, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:15:44.763404 139758026090240 logging_writer.py:48] [324300] global_step=324300, grad_norm=3.25925874710083, loss=1.193698525428772
I0304 07:16:25.454148 139758009304832 logging_writer.py:48] [324400] global_step=324400, grad_norm=3.4469704627990723, loss=2.9771084785461426
I0304 07:17:10.402374 139758026090240 logging_writer.py:48] [324500] global_step=324500, grad_norm=3.3263282775878906, loss=2.4288737773895264
I0304 07:17:55.420650 139758009304832 logging_writer.py:48] [324600] global_step=324600, grad_norm=3.1813600063323975, loss=1.0242900848388672
I0304 07:18:40.549743 139758026090240 logging_writer.py:48] [324700] global_step=324700, grad_norm=3.2272298336029053, loss=2.6270804405212402
I0304 07:19:25.435863 139758009304832 logging_writer.py:48] [324800] global_step=324800, grad_norm=3.0096685886383057, loss=1.1119331121444702
I0304 07:20:10.383240 139758026090240 logging_writer.py:48] [324900] global_step=324900, grad_norm=3.084348440170288, loss=2.6854166984558105
I0304 07:20:55.296770 139758009304832 logging_writer.py:48] [325000] global_step=325000, grad_norm=3.4039838314056396, loss=2.2875189781188965
I0304 07:21:40.177394 139758026090240 logging_writer.py:48] [325100] global_step=325100, grad_norm=3.092282295227051, loss=1.2664440870285034
I0304 07:22:24.915377 139758009304832 logging_writer.py:48] [325200] global_step=325200, grad_norm=3.134955644607544, loss=1.357062578201294
I0304 07:22:40.936544 139953291118400 spec.py:321] Evaluating on the training split.
I0304 07:22:51.845297 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:23:12.568155 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:23:14.199101 139953291118400 submission_runner.py:411] Time since start: 156434.38s, 	Step: 325237, 	{'train/accuracy': 0.8866991996765137, 'train/loss': 0.4203983545303345, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 144558.39869880676, 'total_duration': 156434.3753077984, 'accumulated_submission_time': 144558.39869880676, 'accumulated_eval_time': 11837.51058626175, 'accumulated_logging_time': 21.88632369041443}
I0304 07:23:14.275366 139758026090240 logging_writer.py:48] [325237] accumulated_eval_time=11837.510586, accumulated_logging_time=21.886324, accumulated_submission_time=144558.398699, global_step=325237, preemption_count=0, score=144558.398699, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=156434.375308, train/accuracy=0.886699, train/loss=0.420398, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:23:39.564129 139758009304832 logging_writer.py:48] [325300] global_step=325300, grad_norm=3.199904203414917, loss=1.1550567150115967
I0304 07:24:23.563435 139758026090240 logging_writer.py:48] [325400] global_step=325400, grad_norm=2.8103418350219727, loss=1.7373260259628296
I0304 07:25:09.087921 139758009304832 logging_writer.py:48] [325500] global_step=325500, grad_norm=3.043870687484741, loss=1.1555395126342773
I0304 07:25:54.670313 139758026090240 logging_writer.py:48] [325600] global_step=325600, grad_norm=3.1951780319213867, loss=1.1992790699005127
I0304 07:26:39.891867 139758009304832 logging_writer.py:48] [325700] global_step=325700, grad_norm=3.038398027420044, loss=1.249835729598999
I0304 07:27:25.176810 139758026090240 logging_writer.py:48] [325800] global_step=325800, grad_norm=3.1647067070007324, loss=1.1184892654418945
I0304 07:28:10.600969 139758009304832 logging_writer.py:48] [325900] global_step=325900, grad_norm=2.916796922683716, loss=0.9604810476303101
I0304 07:28:55.446379 139758026090240 logging_writer.py:48] [326000] global_step=326000, grad_norm=3.1370790004730225, loss=1.196977138519287
I0304 07:29:40.482448 139758009304832 logging_writer.py:48] [326100] global_step=326100, grad_norm=2.931663990020752, loss=2.027900218963623
I0304 07:30:14.569479 139953291118400 spec.py:321] Evaluating on the training split.
I0304 07:30:25.968392 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:30:49.158684 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:30:50.791327 139953291118400 submission_runner.py:411] Time since start: 156890.97s, 	Step: 326177, 	{'train/accuracy': 0.88916015625, 'train/loss': 0.4168655574321747, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 144978.63285660744, 'total_duration': 156890.96754074097, 'accumulated_submission_time': 144978.63285660744, 'accumulated_eval_time': 11873.732411623001, 'accumulated_logging_time': 21.974764585494995}
I0304 07:30:50.873145 139758026090240 logging_writer.py:48] [326177] accumulated_eval_time=11873.732412, accumulated_logging_time=21.974765, accumulated_submission_time=144978.632857, global_step=326177, preemption_count=0, score=144978.632857, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=156890.967541, train/accuracy=0.889160, train/loss=0.416866, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:31:00.347761 139758009304832 logging_writer.py:48] [326200] global_step=326200, grad_norm=3.16870379447937, loss=1.2246334552764893
I0304 07:31:42.169484 139758026090240 logging_writer.py:48] [326300] global_step=326300, grad_norm=3.3939590454101562, loss=2.9675941467285156
I0304 07:32:27.187417 139758009304832 logging_writer.py:48] [326400] global_step=326400, grad_norm=3.8802623748779297, loss=3.0858302116394043
I0304 07:33:12.391827 139758026090240 logging_writer.py:48] [326500] global_step=326500, grad_norm=3.286585807800293, loss=2.4826254844665527
I0304 07:33:57.742681 139758009304832 logging_writer.py:48] [326600] global_step=326600, grad_norm=3.3308181762695312, loss=2.8228161334991455
I0304 07:34:42.598537 139758026090240 logging_writer.py:48] [326700] global_step=326700, grad_norm=2.849998712539673, loss=1.0623029470443726
I0304 07:35:27.517474 139758009304832 logging_writer.py:48] [326800] global_step=326800, grad_norm=3.2779428958892822, loss=1.8905359506607056
I0304 07:36:12.923439 139758026090240 logging_writer.py:48] [326900] global_step=326900, grad_norm=3.3904759883880615, loss=2.42280912399292
I0304 07:36:57.781387 139758009304832 logging_writer.py:48] [327000] global_step=327000, grad_norm=3.4426121711730957, loss=2.7919867038726807
I0304 07:37:42.752861 139758026090240 logging_writer.py:48] [327100] global_step=327100, grad_norm=3.054982900619507, loss=1.2202081680297852
I0304 07:37:50.888206 139953291118400 spec.py:321] Evaluating on the training split.
I0304 07:38:01.897335 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:38:25.685716 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:38:27.343060 139953291118400 submission_runner.py:411] Time since start: 157347.52s, 	Step: 327120, 	{'train/accuracy': 0.8898046612739563, 'train/loss': 0.4155591130256653, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 145398.58534121513, 'total_duration': 157347.51926136017, 'accumulated_submission_time': 145398.58534121513, 'accumulated_eval_time': 11910.187224626541, 'accumulated_logging_time': 22.070751667022705}
I0304 07:38:27.432700 139758009304832 logging_writer.py:48] [327120] accumulated_eval_time=11910.187225, accumulated_logging_time=22.070752, accumulated_submission_time=145398.585341, global_step=327120, preemption_count=0, score=145398.585341, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=157347.519261, train/accuracy=0.889805, train/loss=0.415559, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:38:59.415357 139758026090240 logging_writer.py:48] [327200] global_step=327200, grad_norm=3.018174886703491, loss=1.3889539241790771
I0304 07:39:43.743421 139758009304832 logging_writer.py:48] [327300] global_step=327300, grad_norm=3.16841983795166, loss=1.1891595125198364
I0304 07:40:28.896541 139758026090240 logging_writer.py:48] [327400] global_step=327400, grad_norm=3.488348960876465, loss=3.1470911502838135
I0304 07:41:14.068852 139758009304832 logging_writer.py:48] [327500] global_step=327500, grad_norm=2.898453712463379, loss=1.2209267616271973
I0304 07:41:59.484405 139758026090240 logging_writer.py:48] [327600] global_step=327600, grad_norm=3.5124545097351074, loss=3.1658201217651367
I0304 07:42:44.371018 139758009304832 logging_writer.py:48] [327700] global_step=327700, grad_norm=3.029069423675537, loss=1.5449316501617432
I0304 07:43:29.850325 139758026090240 logging_writer.py:48] [327800] global_step=327800, grad_norm=3.02561616897583, loss=1.3403370380401611
I0304 07:44:15.119539 139758009304832 logging_writer.py:48] [327900] global_step=327900, grad_norm=3.152817726135254, loss=1.1074692010879517
I0304 07:44:59.889864 139758026090240 logging_writer.py:48] [328000] global_step=328000, grad_norm=2.778912305831909, loss=1.0852808952331543
I0304 07:45:27.570216 139953291118400 spec.py:321] Evaluating on the training split.
I0304 07:45:38.578823 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:46:01.151296 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:46:02.793462 139953291118400 submission_runner.py:411] Time since start: 157802.97s, 	Step: 328063, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.4140132665634155, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 145818.65999770164, 'total_duration': 157802.96967935562, 'accumulated_submission_time': 145818.65999770164, 'accumulated_eval_time': 11945.410465955734, 'accumulated_logging_time': 22.175304174423218}
I0304 07:46:02.876311 139758009304832 logging_writer.py:48] [328063] accumulated_eval_time=11945.410466, accumulated_logging_time=22.175304, accumulated_submission_time=145818.659998, global_step=328063, preemption_count=0, score=145818.659998, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=157802.969679, train/accuracy=0.888438, train/loss=0.414013, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:46:17.897812 139758026090240 logging_writer.py:48] [328100] global_step=328100, grad_norm=3.7697041034698486, loss=3.2529008388519287
I0304 07:47:00.530564 139758009304832 logging_writer.py:48] [328200] global_step=328200, grad_norm=2.9123892784118652, loss=1.5644453763961792
I0304 07:47:45.722000 139758026090240 logging_writer.py:48] [328300] global_step=328300, grad_norm=2.928293228149414, loss=1.4246902465820312
I0304 07:48:30.897102 139758009304832 logging_writer.py:48] [328400] global_step=328400, grad_norm=3.42490816116333, loss=1.9286781549453735
I0304 07:49:15.971189 139758026090240 logging_writer.py:48] [328500] global_step=328500, grad_norm=3.2945094108581543, loss=1.1517350673675537
I0304 07:50:00.725324 139758009304832 logging_writer.py:48] [328600] global_step=328600, grad_norm=3.229611396789551, loss=1.180799126625061
I0304 07:50:45.519236 139758026090240 logging_writer.py:48] [328700] global_step=328700, grad_norm=3.236302614212036, loss=1.1209604740142822
I0304 07:51:30.401557 139758009304832 logging_writer.py:48] [328800] global_step=328800, grad_norm=3.094458818435669, loss=1.047447681427002
I0304 07:52:15.563734 139758026090240 logging_writer.py:48] [328900] global_step=328900, grad_norm=3.0914344787597656, loss=1.0851495265960693
I0304 07:53:00.496112 139758009304832 logging_writer.py:48] [329000] global_step=329000, grad_norm=3.5487992763519287, loss=1.0854313373565674
I0304 07:53:02.996562 139953291118400 spec.py:321] Evaluating on the training split.
I0304 07:53:14.131257 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 07:53:36.033889 139953291118400 spec.py:349] Evaluating on the test split.
I0304 07:53:37.668689 139953291118400 submission_runner.py:411] Time since start: 158257.84s, 	Step: 329007, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.41430145502090454, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 146238.7226538658, 'total_duration': 158257.84491205215, 'accumulated_submission_time': 146238.7226538658, 'accumulated_eval_time': 11980.082593917847, 'accumulated_logging_time': 22.268385410308838}
I0304 07:53:37.748952 139758026090240 logging_writer.py:48] [329007] accumulated_eval_time=11980.082594, accumulated_logging_time=22.268385, accumulated_submission_time=146238.722654, global_step=329007, preemption_count=0, score=146238.722654, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=158257.844912, train/accuracy=0.887227, train/loss=0.414301, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 07:54:15.763905 139758009304832 logging_writer.py:48] [329100] global_step=329100, grad_norm=3.016024112701416, loss=1.1591981649398804
I0304 07:55:00.364699 139758026090240 logging_writer.py:48] [329200] global_step=329200, grad_norm=2.9401321411132812, loss=1.7946281433105469
I0304 07:55:45.894523 139758009304832 logging_writer.py:48] [329300] global_step=329300, grad_norm=3.136171579360962, loss=1.2860796451568604
I0304 07:56:31.577782 139758026090240 logging_writer.py:48] [329400] global_step=329400, grad_norm=4.568605899810791, loss=2.9750075340270996
I0304 07:57:16.121865 139758009304832 logging_writer.py:48] [329500] global_step=329500, grad_norm=3.6141207218170166, loss=2.7121429443359375
I0304 07:58:01.027429 139758026090240 logging_writer.py:48] [329600] global_step=329600, grad_norm=3.100832462310791, loss=2.226604461669922
I0304 07:58:45.762509 139758009304832 logging_writer.py:48] [329700] global_step=329700, grad_norm=2.932779550552368, loss=1.6414856910705566
I0304 07:59:30.821954 139758026090240 logging_writer.py:48] [329800] global_step=329800, grad_norm=3.0106632709503174, loss=1.7731143236160278
I0304 08:00:15.939331 139758009304832 logging_writer.py:48] [329900] global_step=329900, grad_norm=3.5991907119750977, loss=1.135108232498169
I0304 08:00:38.117256 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:00:49.864923 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:01:20.592725 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:01:22.229269 139953291118400 submission_runner.py:411] Time since start: 158722.41s, 	Step: 329951, 	{'train/accuracy': 0.8880859017372131, 'train/loss': 0.4180927276611328, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 146659.0313911438, 'total_duration': 158722.40548229218, 'accumulated_submission_time': 146659.0313911438, 'accumulated_eval_time': 12024.194583177567, 'accumulated_logging_time': 22.361082553863525}
I0304 08:01:22.305483 139758026090240 logging_writer.py:48] [329951] accumulated_eval_time=12024.194583, accumulated_logging_time=22.361083, accumulated_submission_time=146659.031391, global_step=329951, preemption_count=0, score=146659.031391, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=158722.405482, train/accuracy=0.888086, train/loss=0.418093, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:01:42.019932 139758009304832 logging_writer.py:48] [330000] global_step=330000, grad_norm=3.1312131881713867, loss=1.0572646856307983
I0304 08:02:23.846864 139758026090240 logging_writer.py:48] [330100] global_step=330100, grad_norm=3.0411221981048584, loss=1.0488803386688232
I0304 08:03:08.946522 139758009304832 logging_writer.py:48] [330200] global_step=330200, grad_norm=2.8501129150390625, loss=1.1884323358535767
I0304 08:03:54.197896 139758026090240 logging_writer.py:48] [330300] global_step=330300, grad_norm=3.18109393119812, loss=1.2084383964538574
I0304 08:04:39.057019 139758009304832 logging_writer.py:48] [330400] global_step=330400, grad_norm=3.0729901790618896, loss=1.1071144342422485
I0304 08:05:23.874135 139758026090240 logging_writer.py:48] [330500] global_step=330500, grad_norm=3.3225622177124023, loss=1.2320343255996704
I0304 08:06:08.927364 139758009304832 logging_writer.py:48] [330600] global_step=330600, grad_norm=2.8645758628845215, loss=1.7228704690933228
I0304 08:06:53.956485 139758026090240 logging_writer.py:48] [330700] global_step=330700, grad_norm=2.9910390377044678, loss=1.348902702331543
I0304 08:07:38.863765 139758009304832 logging_writer.py:48] [330800] global_step=330800, grad_norm=3.074978828430176, loss=1.0936362743377686
I0304 08:08:22.589871 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:08:33.693866 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:08:58.089828 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:08:59.724337 139953291118400 submission_runner.py:411] Time since start: 159179.90s, 	Step: 330899, 	{'train/accuracy': 0.8866601586341858, 'train/loss': 0.4193836450576782, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 147079.2585787773, 'total_duration': 159179.90055942535, 'accumulated_submission_time': 147079.2585787773, 'accumulated_eval_time': 12061.329034805298, 'accumulated_logging_time': 22.44697642326355}
I0304 08:08:59.805222 139758026090240 logging_writer.py:48] [330899] accumulated_eval_time=12061.329035, accumulated_logging_time=22.446976, accumulated_submission_time=147079.258579, global_step=330899, preemption_count=0, score=147079.258579, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=159179.900559, train/accuracy=0.886660, train/loss=0.419384, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:09:01.387760 139758009304832 logging_writer.py:48] [330900] global_step=330900, grad_norm=3.0464656352996826, loss=1.3703099489212036
I0304 08:09:42.016286 139758026090240 logging_writer.py:48] [331000] global_step=331000, grad_norm=5.285651683807373, loss=2.785122871398926
I0304 08:10:26.802332 139758009304832 logging_writer.py:48] [331100] global_step=331100, grad_norm=3.6868937015533447, loss=3.083979606628418
I0304 08:11:11.908785 139758026090240 logging_writer.py:48] [331200] global_step=331200, grad_norm=3.234985589981079, loss=1.2060191631317139
I0304 08:11:57.136143 139758009304832 logging_writer.py:48] [331300] global_step=331300, grad_norm=3.3852200508117676, loss=2.9661617279052734
I0304 08:12:42.202778 139758026090240 logging_writer.py:48] [331400] global_step=331400, grad_norm=3.158738374710083, loss=1.0957508087158203
I0304 08:13:27.054278 139758009304832 logging_writer.py:48] [331500] global_step=331500, grad_norm=2.7903523445129395, loss=1.1146756410598755
I0304 08:14:12.562933 139758026090240 logging_writer.py:48] [331600] global_step=331600, grad_norm=2.9332497119903564, loss=1.218209147453308
I0304 08:14:57.728224 139758009304832 logging_writer.py:48] [331700] global_step=331700, grad_norm=3.1638917922973633, loss=1.2144030332565308
I0304 08:15:42.924093 139758026090240 logging_writer.py:48] [331800] global_step=331800, grad_norm=3.2936439514160156, loss=1.1760859489440918
I0304 08:16:00.069264 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:16:11.514756 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:16:44.562559 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:16:46.187933 139953291118400 submission_runner.py:411] Time since start: 159646.36s, 	Step: 331840, 	{'train/accuracy': 0.8866406083106995, 'train/loss': 0.4111728072166443, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 147498.69048261642, 'total_duration': 159646.3641116619, 'accumulated_submission_time': 147498.69048261642, 'accumulated_eval_time': 12107.44764471054, 'accumulated_logging_time': 23.31242060661316}
I0304 08:16:46.263226 139758009304832 logging_writer.py:48] [331840] accumulated_eval_time=12107.447645, accumulated_logging_time=23.312421, accumulated_submission_time=147498.690483, global_step=331840, preemption_count=0, score=147498.690483, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=159646.364112, train/accuracy=0.886641, train/loss=0.411173, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:17:10.324084 139758026090240 logging_writer.py:48] [331900] global_step=331900, grad_norm=3.064602851867676, loss=1.8775403499603271
I0304 08:17:53.240599 139758009304832 logging_writer.py:48] [332000] global_step=332000, grad_norm=3.281806230545044, loss=1.1574207544326782
I0304 08:18:38.086681 139758026090240 logging_writer.py:48] [332100] global_step=332100, grad_norm=2.9933314323425293, loss=1.0080336332321167
I0304 08:19:23.124854 139758009304832 logging_writer.py:48] [332200] global_step=332200, grad_norm=3.1527063846588135, loss=1.2002942562103271
I0304 08:20:08.079818 139758026090240 logging_writer.py:48] [332300] global_step=332300, grad_norm=3.2093212604522705, loss=1.7158534526824951
I0304 08:20:52.811826 139758009304832 logging_writer.py:48] [332400] global_step=332400, grad_norm=2.903120279312134, loss=1.0977015495300293
I0304 08:21:37.987236 139758026090240 logging_writer.py:48] [332500] global_step=332500, grad_norm=3.1035759449005127, loss=1.139049768447876
I0304 08:22:23.065663 139758009304832 logging_writer.py:48] [332600] global_step=332600, grad_norm=3.211132526397705, loss=2.4869136810302734
I0304 08:23:07.980302 139758026090240 logging_writer.py:48] [332700] global_step=332700, grad_norm=3.0535101890563965, loss=2.3844337463378906
I0304 08:23:46.619944 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:23:57.695701 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:24:19.089907 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:24:20.721043 139953291118400 submission_runner.py:411] Time since start: 160100.90s, 	Step: 332787, 	{'train/accuracy': 0.8870898485183716, 'train/loss': 0.42718014121055603, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 147918.98912215233, 'total_duration': 160100.89725995064, 'accumulated_submission_time': 147918.98912215233, 'accumulated_eval_time': 12141.548724412918, 'accumulated_logging_time': 23.3977952003479}
I0304 08:24:20.802314 139758009304832 logging_writer.py:48] [332787] accumulated_eval_time=12141.548724, accumulated_logging_time=23.397795, accumulated_submission_time=147918.989122, global_step=332787, preemption_count=0, score=147918.989122, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=160100.897260, train/accuracy=0.887090, train/loss=0.427180, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:24:26.356392 139758026090240 logging_writer.py:48] [332800] global_step=332800, grad_norm=2.965852737426758, loss=1.5548579692840576
I0304 08:25:08.487809 139758009304832 logging_writer.py:48] [332900] global_step=332900, grad_norm=3.1662940979003906, loss=1.125427007675171
I0304 08:25:53.442813 139758026090240 logging_writer.py:48] [333000] global_step=333000, grad_norm=3.916680097579956, loss=3.309607982635498
I0304 08:26:39.061953 139758009304832 logging_writer.py:48] [333100] global_step=333100, grad_norm=2.8642630577087402, loss=1.397652268409729
I0304 08:27:24.751929 139758026090240 logging_writer.py:48] [333200] global_step=333200, grad_norm=2.830125331878662, loss=1.8070392608642578
I0304 08:28:10.112456 139758009304832 logging_writer.py:48] [333300] global_step=333300, grad_norm=2.936690092086792, loss=1.3314911127090454
I0304 08:28:55.013633 139758026090240 logging_writer.py:48] [333400] global_step=333400, grad_norm=3.3834869861602783, loss=2.9370970726013184
I0304 08:29:40.432490 139758009304832 logging_writer.py:48] [333500] global_step=333500, grad_norm=3.182115316390991, loss=1.5113369226455688
I0304 08:30:25.711576 139758026090240 logging_writer.py:48] [333600] global_step=333600, grad_norm=4.2126264572143555, loss=2.920962333679199
I0304 08:31:10.935148 139758009304832 logging_writer.py:48] [333700] global_step=333700, grad_norm=2.8983466625213623, loss=1.3770575523376465
I0304 08:31:20.792333 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:31:32.543694 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:32:03.142037 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:32:04.773851 139953291118400 submission_runner.py:411] Time since start: 160564.95s, 	Step: 333723, 	{'train/accuracy': 0.8864062428474426, 'train/loss': 0.4243050217628479, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 148338.922219038, 'total_duration': 160564.95006656647, 'accumulated_submission_time': 148338.922219038, 'accumulated_eval_time': 12185.530223608017, 'accumulated_logging_time': 23.488813161849976}
I0304 08:32:04.858215 139758026090240 logging_writer.py:48] [333723] accumulated_eval_time=12185.530224, accumulated_logging_time=23.488813, accumulated_submission_time=148338.922219, global_step=333723, preemption_count=0, score=148338.922219, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=160564.950067, train/accuracy=0.886406, train/loss=0.424305, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:32:35.833685 139758009304832 logging_writer.py:48] [333800] global_step=333800, grad_norm=2.9704813957214355, loss=1.3173638582229614
I0304 08:33:20.887434 139758026090240 logging_writer.py:48] [333900] global_step=333900, grad_norm=3.1885781288146973, loss=0.9536136388778687
I0304 08:34:06.448397 139758009304832 logging_writer.py:48] [334000] global_step=334000, grad_norm=2.820030927658081, loss=1.9054052829742432
I0304 08:34:51.826095 139758026090240 logging_writer.py:48] [334100] global_step=334100, grad_norm=2.817734956741333, loss=2.0761892795562744
I0304 08:35:36.972784 139758009304832 logging_writer.py:48] [334200] global_step=334200, grad_norm=3.1861376762390137, loss=1.2115905284881592
I0304 08:36:21.964329 139758026090240 logging_writer.py:48] [334300] global_step=334300, grad_norm=3.0374703407287598, loss=1.1167601346969604
I0304 08:37:07.180685 139758009304832 logging_writer.py:48] [334400] global_step=334400, grad_norm=3.3435258865356445, loss=1.9613362550735474
I0304 08:37:51.986170 139758026090240 logging_writer.py:48] [334500] global_step=334500, grad_norm=3.7818262577056885, loss=3.2778842449188232
I0304 08:38:37.223289 139758009304832 logging_writer.py:48] [334600] global_step=334600, grad_norm=3.060736894607544, loss=2.066098690032959
I0304 08:39:04.858427 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:39:15.882711 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:39:44.449934 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:39:46.088840 139953291118400 submission_runner.py:411] Time since start: 161026.27s, 	Step: 334663, 	{'train/accuracy': 0.8871679306030273, 'train/loss': 0.4189110994338989, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 148758.86404037476, 'total_duration': 161026.26504921913, 'accumulated_submission_time': 148758.86404037476, 'accumulated_eval_time': 12226.760622501373, 'accumulated_logging_time': 23.583487033843994}
I0304 08:39:46.166569 139758026090240 logging_writer.py:48] [334663] accumulated_eval_time=12226.760623, accumulated_logging_time=23.583487, accumulated_submission_time=148758.864040, global_step=334663, preemption_count=0, score=148758.864040, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=161026.265049, train/accuracy=0.887168, train/loss=0.418911, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:40:01.177714 139758009304832 logging_writer.py:48] [334700] global_step=334700, grad_norm=3.102181911468506, loss=1.3329546451568604
I0304 08:40:43.404147 139758026090240 logging_writer.py:48] [334800] global_step=334800, grad_norm=2.9092769622802734, loss=1.1502090692520142
I0304 08:41:28.607749 139758009304832 logging_writer.py:48] [334900] global_step=334900, grad_norm=3.0319433212280273, loss=2.232158899307251
I0304 08:42:13.710514 139758026090240 logging_writer.py:48] [335000] global_step=335000, grad_norm=4.2104291915893555, loss=2.0342884063720703
I0304 08:42:58.868055 139758009304832 logging_writer.py:48] [335100] global_step=335100, grad_norm=3.061476707458496, loss=1.0855964422225952
I0304 08:43:43.743132 139758026090240 logging_writer.py:48] [335200] global_step=335200, grad_norm=2.9000773429870605, loss=1.3768731355667114
I0304 08:44:29.209015 139758009304832 logging_writer.py:48] [335300] global_step=335300, grad_norm=2.765697956085205, loss=1.1103339195251465
I0304 08:45:14.152852 139758026090240 logging_writer.py:48] [335400] global_step=335400, grad_norm=3.685188055038452, loss=3.1711344718933105
I0304 08:45:59.112162 139758009304832 logging_writer.py:48] [335500] global_step=335500, grad_norm=3.756397008895874, loss=3.152855634689331
I0304 08:46:44.447492 139758026090240 logging_writer.py:48] [335600] global_step=335600, grad_norm=3.0806353092193604, loss=1.430395245552063
I0304 08:46:46.426911 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:46:57.852415 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:47:22.529735 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:47:24.158065 139953291118400 submission_runner.py:411] Time since start: 161484.33s, 	Step: 335606, 	{'train/accuracy': 0.88623046875, 'train/loss': 0.4251594543457031, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 149179.06500458717, 'total_duration': 161484.33428955078, 'accumulated_submission_time': 149179.06500458717, 'accumulated_eval_time': 12264.491759061813, 'accumulated_logging_time': 23.673017024993896}
I0304 08:47:24.241405 139758009304832 logging_writer.py:48] [335606] accumulated_eval_time=12264.491759, accumulated_logging_time=23.673017, accumulated_submission_time=149179.065005, global_step=335606, preemption_count=0, score=149179.065005, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=161484.334290, train/accuracy=0.886230, train/loss=0.425159, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:48:03.388603 139758026090240 logging_writer.py:48] [335700] global_step=335700, grad_norm=3.0071494579315186, loss=1.2580201625823975
I0304 08:48:47.894231 139758009304832 logging_writer.py:48] [335800] global_step=335800, grad_norm=3.357389450073242, loss=2.2580785751342773
I0304 08:49:32.931291 139758026090240 logging_writer.py:48] [335900] global_step=335900, grad_norm=3.2801406383514404, loss=1.1784533262252808
I0304 08:50:18.037322 139758009304832 logging_writer.py:48] [336000] global_step=336000, grad_norm=3.2784175872802734, loss=3.1378321647644043
I0304 08:51:03.137183 139758026090240 logging_writer.py:48] [336100] global_step=336100, grad_norm=3.00801682472229, loss=1.1249401569366455
I0304 08:51:48.116562 139758009304832 logging_writer.py:48] [336200] global_step=336200, grad_norm=2.927541494369507, loss=1.1165368556976318
I0304 08:52:33.295356 139758026090240 logging_writer.py:48] [336300] global_step=336300, grad_norm=3.6212308406829834, loss=1.0479363203048706
I0304 08:53:18.501059 139758009304832 logging_writer.py:48] [336400] global_step=336400, grad_norm=3.229308843612671, loss=1.1089234352111816
I0304 08:54:03.447116 139758026090240 logging_writer.py:48] [336500] global_step=336500, grad_norm=3.4860787391662598, loss=1.0916125774383545
I0304 08:54:24.465700 139953291118400 spec.py:321] Evaluating on the training split.
I0304 08:54:35.809247 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 08:55:04.527698 139953291118400 spec.py:349] Evaluating on the test split.
I0304 08:55:06.158229 139953291118400 submission_runner.py:411] Time since start: 161946.33s, 	Step: 336548, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.4107557237148285, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 149599.2316122055, 'total_duration': 161946.33445000648, 'accumulated_submission_time': 149599.2316122055, 'accumulated_eval_time': 12306.18427157402, 'accumulated_logging_time': 23.765666007995605}
I0304 08:55:06.240547 139758009304832 logging_writer.py:48] [336548] accumulated_eval_time=12306.184272, accumulated_logging_time=23.765666, accumulated_submission_time=149599.231612, global_step=336548, preemption_count=0, score=149599.231612, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=161946.334450, train/accuracy=0.888379, train/loss=0.410756, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 08:55:27.173336 139758026090240 logging_writer.py:48] [336600] global_step=336600, grad_norm=3.2281980514526367, loss=1.089684247970581
I0304 08:56:11.047662 139758009304832 logging_writer.py:48] [336700] global_step=336700, grad_norm=3.2131330966949463, loss=1.2272465229034424
I0304 08:56:56.217824 139758026090240 logging_writer.py:48] [336800] global_step=336800, grad_norm=3.2913503646850586, loss=1.3696879148483276
I0304 08:57:41.254133 139758009304832 logging_writer.py:48] [336900] global_step=336900, grad_norm=3.2286500930786133, loss=1.072577953338623
I0304 08:58:26.177983 139758026090240 logging_writer.py:48] [337000] global_step=337000, grad_norm=3.4791011810302734, loss=3.155622959136963
I0304 08:59:11.221232 139758009304832 logging_writer.py:48] [337100] global_step=337100, grad_norm=3.3409762382507324, loss=2.881526470184326
I0304 08:59:56.343600 139758026090240 logging_writer.py:48] [337200] global_step=337200, grad_norm=3.845653533935547, loss=3.2228479385375977
I0304 09:00:41.485742 139758009304832 logging_writer.py:48] [337300] global_step=337300, grad_norm=3.001840353012085, loss=1.892256736755371
I0304 09:01:26.491386 139758026090240 logging_writer.py:48] [337400] global_step=337400, grad_norm=3.0463569164276123, loss=2.6584184169769287
I0304 09:02:06.261298 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:02:17.377360 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:02:49.629881 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:02:51.266917 139953291118400 submission_runner.py:411] Time since start: 162411.44s, 	Step: 337490, 	{'train/accuracy': 0.8858007788658142, 'train/loss': 0.4200242757797241, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 150019.19176864624, 'total_duration': 162411.44314026833, 'accumulated_submission_time': 150019.19176864624, 'accumulated_eval_time': 12351.189871788025, 'accumulated_logging_time': 23.861356258392334}
I0304 09:02:51.346480 139758009304832 logging_writer.py:48] [337490] accumulated_eval_time=12351.189872, accumulated_logging_time=23.861356, accumulated_submission_time=150019.191769, global_step=337490, preemption_count=0, score=150019.191769, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=162411.443140, train/accuracy=0.885801, train/loss=0.420024, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:02:55.691045 139758026090240 logging_writer.py:48] [337500] global_step=337500, grad_norm=3.2418904304504395, loss=1.2544169425964355
I0304 09:03:36.972384 139758009304832 logging_writer.py:48] [337600] global_step=337600, grad_norm=3.348961114883423, loss=1.1749776601791382
I0304 09:04:21.942428 139758026090240 logging_writer.py:48] [337700] global_step=337700, grad_norm=3.17545223236084, loss=1.1449599266052246
I0304 09:05:07.351565 139758009304832 logging_writer.py:48] [337800] global_step=337800, grad_norm=2.954174280166626, loss=1.0743589401245117
I0304 09:05:52.602077 139758026090240 logging_writer.py:48] [337900] global_step=337900, grad_norm=3.1515204906463623, loss=1.0828492641448975
I0304 09:06:37.777761 139758009304832 logging_writer.py:48] [338000] global_step=338000, grad_norm=3.078681230545044, loss=1.2227729558944702
I0304 09:07:22.976247 139758026090240 logging_writer.py:48] [338100] global_step=338100, grad_norm=3.3076484203338623, loss=2.794060707092285
I0304 09:08:08.197440 139758009304832 logging_writer.py:48] [338200] global_step=338200, grad_norm=3.1168558597564697, loss=1.0820865631103516
I0304 09:08:53.495805 139758026090240 logging_writer.py:48] [338300] global_step=338300, grad_norm=3.123734474182129, loss=2.438803195953369
I0304 09:09:38.567126 139758009304832 logging_writer.py:48] [338400] global_step=338400, grad_norm=3.176966428756714, loss=2.792947769165039
I0304 09:09:51.351535 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:10:02.733845 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:10:24.391523 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:10:26.033969 139953291118400 submission_runner.py:411] Time since start: 162866.21s, 	Step: 338430, 	{'train/accuracy': 0.8881054520606995, 'train/loss': 0.4224624037742615, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 150439.1379084587, 'total_duration': 162866.21015238762, 'accumulated_submission_time': 150439.1379084587, 'accumulated_eval_time': 12385.872237205505, 'accumulated_logging_time': 23.952771425247192}
I0304 09:10:26.165499 139758026090240 logging_writer.py:48] [338430] accumulated_eval_time=12385.872237, accumulated_logging_time=23.952771, accumulated_submission_time=150439.137908, global_step=338430, preemption_count=0, score=150439.137908, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=162866.210152, train/accuracy=0.888105, train/loss=0.422462, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:10:54.428364 139758009304832 logging_writer.py:48] [338500] global_step=338500, grad_norm=3.5049660205841064, loss=1.1570117473602295
I0304 09:11:39.299812 139758026090240 logging_writer.py:48] [338600] global_step=338600, grad_norm=3.0868563652038574, loss=1.6614121198654175
I0304 09:12:24.408101 139758009304832 logging_writer.py:48] [338700] global_step=338700, grad_norm=3.199470043182373, loss=2.6707308292388916
I0304 09:13:09.848547 139758026090240 logging_writer.py:48] [338800] global_step=338800, grad_norm=3.228654146194458, loss=1.6492491960525513
I0304 09:13:55.133075 139758009304832 logging_writer.py:48] [338900] global_step=338900, grad_norm=2.9765782356262207, loss=1.176084280014038
I0304 09:14:40.203506 139758026090240 logging_writer.py:48] [339000] global_step=339000, grad_norm=3.0010526180267334, loss=1.0798832178115845
I0304 09:15:25.441649 139758009304832 logging_writer.py:48] [339100] global_step=339100, grad_norm=3.102316379547119, loss=1.2511581182479858
I0304 09:16:10.487580 139758026090240 logging_writer.py:48] [339200] global_step=339200, grad_norm=3.342669725418091, loss=1.0907127857208252
I0304 09:16:55.572639 139758009304832 logging_writer.py:48] [339300] global_step=339300, grad_norm=3.572739601135254, loss=2.9805688858032227
I0304 09:17:26.320909 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:17:37.527863 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:18:00.725619 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:18:02.373887 139953291118400 submission_runner.py:411] Time since start: 163322.55s, 	Step: 339370, 	{'train/accuracy': 0.8855859041213989, 'train/loss': 0.42482203245162964, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 150859.23227977753, 'total_duration': 163322.5501112938, 'accumulated_submission_time': 150859.23227977753, 'accumulated_eval_time': 12421.925200462341, 'accumulated_logging_time': 24.09778380393982}
I0304 09:18:02.455475 139758026090240 logging_writer.py:48] [339370] accumulated_eval_time=12421.925200, accumulated_logging_time=24.097784, accumulated_submission_time=150859.232280, global_step=339370, preemption_count=0, score=150859.232280, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=163322.550111, train/accuracy=0.885586, train/loss=0.424822, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:18:14.706956 139758009304832 logging_writer.py:48] [339400] global_step=339400, grad_norm=2.6838788986206055, loss=1.6384780406951904
I0304 09:18:57.305892 139758026090240 logging_writer.py:48] [339500] global_step=339500, grad_norm=3.5965046882629395, loss=3.128861665725708
I0304 09:19:42.424073 139758009304832 logging_writer.py:48] [339600] global_step=339600, grad_norm=4.825577735900879, loss=3.1046319007873535
I0304 09:20:27.411353 139758026090240 logging_writer.py:48] [339700] global_step=339700, grad_norm=3.0649526119232178, loss=1.0786950588226318
I0304 09:21:12.720161 139758009304832 logging_writer.py:48] [339800] global_step=339800, grad_norm=3.165553569793701, loss=1.5750515460968018
I0304 09:21:57.558246 139758026090240 logging_writer.py:48] [339900] global_step=339900, grad_norm=3.0224175453186035, loss=1.7544357776641846
I0304 09:22:42.594002 139758009304832 logging_writer.py:48] [340000] global_step=340000, grad_norm=2.9587786197662354, loss=1.3954565525054932
I0304 09:23:27.996097 139758026090240 logging_writer.py:48] [340100] global_step=340100, grad_norm=2.940488338470459, loss=1.4726771116256714
I0304 09:24:12.771749 139758009304832 logging_writer.py:48] [340200] global_step=340200, grad_norm=2.988677501678467, loss=1.1687489748001099
I0304 09:24:58.041378 139758026090240 logging_writer.py:48] [340300] global_step=340300, grad_norm=3.135591745376587, loss=1.1118165254592896
I0304 09:25:02.467506 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:25:13.606394 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:25:38.272340 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:25:39.900090 139953291118400 submission_runner.py:411] Time since start: 163780.08s, 	Step: 340311, 	{'train/accuracy': 0.8870312571525574, 'train/loss': 0.4190521538257599, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 151279.18514490128, 'total_duration': 163780.07631373405, 'accumulated_submission_time': 151279.18514490128, 'accumulated_eval_time': 12459.357788085938, 'accumulated_logging_time': 24.190918445587158}
I0304 09:25:39.984524 139758009304832 logging_writer.py:48] [340311] accumulated_eval_time=12459.357788, accumulated_logging_time=24.190918, accumulated_submission_time=151279.185145, global_step=340311, preemption_count=0, score=151279.185145, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=163780.076314, train/accuracy=0.887031, train/loss=0.419052, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:26:16.384577 139758026090240 logging_writer.py:48] [340400] global_step=340400, grad_norm=3.309450626373291, loss=2.6963999271392822
I0304 09:27:01.166414 139758009304832 logging_writer.py:48] [340500] global_step=340500, grad_norm=3.178802490234375, loss=1.6815112829208374
I0304 09:27:46.013085 139758026090240 logging_writer.py:48] [340600] global_step=340600, grad_norm=2.9613099098205566, loss=1.1328309774398804
I0304 09:28:31.033657 139758009304832 logging_writer.py:48] [340700] global_step=340700, grad_norm=3.308659076690674, loss=1.1073966026306152
I0304 09:29:15.571451 139758026090240 logging_writer.py:48] [340800] global_step=340800, grad_norm=3.6294569969177246, loss=1.0455257892608643
I0304 09:30:00.245982 139758009304832 logging_writer.py:48] [340900] global_step=340900, grad_norm=3.1245553493499756, loss=1.7735134363174438
I0304 09:30:45.556216 139758026090240 logging_writer.py:48] [341000] global_step=341000, grad_norm=3.1175625324249268, loss=1.1705756187438965
I0304 09:31:30.601817 139758009304832 logging_writer.py:48] [341100] global_step=341100, grad_norm=2.9375500679016113, loss=1.284837245941162
I0304 09:32:15.478583 139758026090240 logging_writer.py:48] [341200] global_step=341200, grad_norm=3.6067183017730713, loss=3.216132164001465
I0304 09:32:39.974427 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:32:50.981558 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:33:23.292628 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:33:24.916879 139953291118400 submission_runner.py:411] Time since start: 164245.09s, 	Step: 341256, 	{'train/accuracy': 0.8864062428474426, 'train/loss': 0.41553565859794617, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 151699.11443638802, 'total_duration': 164245.09310364723, 'accumulated_submission_time': 151699.11443638802, 'accumulated_eval_time': 12504.30022096634, 'accumulated_logging_time': 24.288305044174194}
I0304 09:33:24.997978 139758009304832 logging_writer.py:48] [341256] accumulated_eval_time=12504.300221, accumulated_logging_time=24.288305, accumulated_submission_time=151699.114436, global_step=341256, preemption_count=0, score=151699.114436, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=164245.093104, train/accuracy=0.886406, train/loss=0.415536, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:33:42.813027 139758026090240 logging_writer.py:48] [341300] global_step=341300, grad_norm=3.261897563934326, loss=0.9966078996658325
I0304 09:34:24.800024 139758009304832 logging_writer.py:48] [341400] global_step=341400, grad_norm=3.6915483474731445, loss=1.2479820251464844
I0304 09:35:09.725511 139758026090240 logging_writer.py:48] [341500] global_step=341500, grad_norm=2.982414484024048, loss=1.0725200176239014
I0304 09:35:55.132136 139758009304832 logging_writer.py:48] [341600] global_step=341600, grad_norm=3.605161666870117, loss=3.1260900497436523
I0304 09:36:40.775876 139758026090240 logging_writer.py:48] [341700] global_step=341700, grad_norm=3.0508816242218018, loss=1.071606993675232
I0304 09:37:25.457125 139758009304832 logging_writer.py:48] [341800] global_step=341800, grad_norm=2.908143997192383, loss=2.0100603103637695
I0304 09:38:10.550145 139758026090240 logging_writer.py:48] [341900] global_step=341900, grad_norm=3.5637001991271973, loss=2.979935884475708
I0304 09:38:55.502953 139758009304832 logging_writer.py:48] [342000] global_step=342000, grad_norm=4.107649326324463, loss=1.3746886253356934
I0304 09:39:40.458439 139758026090240 logging_writer.py:48] [342100] global_step=342100, grad_norm=3.1742210388183594, loss=1.3392609357833862
I0304 09:40:25.213900 139758009304832 logging_writer.py:48] [342200] global_step=342200, grad_norm=3.616270065307617, loss=3.1064867973327637
I0304 09:40:25.230797 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:40:36.564666 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:41:03.559651 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:41:05.186804 139953291118400 submission_runner.py:411] Time since start: 164705.36s, 	Step: 342201, 	{'train/accuracy': 0.8872656226158142, 'train/loss': 0.4203912913799286, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 152119.28486824036, 'total_duration': 164705.3630282879, 'accumulated_submission_time': 152119.28486824036, 'accumulated_eval_time': 12544.256209850311, 'accumulated_logging_time': 24.38241219520569}
I0304 09:41:05.269163 139758026090240 logging_writer.py:48] [342201] accumulated_eval_time=12544.256210, accumulated_logging_time=24.382412, accumulated_submission_time=152119.284868, global_step=342201, preemption_count=0, score=152119.284868, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=164705.363028, train/accuracy=0.887266, train/loss=0.420391, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:41:45.837538 139758009304832 logging_writer.py:48] [342300] global_step=342300, grad_norm=2.9727962017059326, loss=1.0597009658813477
I0304 09:42:30.610103 139758026090240 logging_writer.py:48] [342400] global_step=342400, grad_norm=3.0717761516571045, loss=1.1533548831939697
I0304 09:43:15.786665 139758009304832 logging_writer.py:48] [342500] global_step=342500, grad_norm=2.9844160079956055, loss=1.2463593482971191
I0304 09:44:00.825011 139758026090240 logging_writer.py:48] [342600] global_step=342600, grad_norm=3.086251735687256, loss=1.0930790901184082
I0304 09:44:45.709269 139758009304832 logging_writer.py:48] [342700] global_step=342700, grad_norm=3.175410747528076, loss=1.1580100059509277
I0304 09:45:30.843003 139758026090240 logging_writer.py:48] [342800] global_step=342800, grad_norm=3.427297592163086, loss=1.0588037967681885
I0304 09:46:16.029333 139758009304832 logging_writer.py:48] [342900] global_step=342900, grad_norm=2.923725128173828, loss=1.4423718452453613
I0304 09:47:00.801728 139758026090240 logging_writer.py:48] [343000] global_step=343000, grad_norm=2.973745346069336, loss=1.1110918521881104
I0304 09:47:45.759453 139758009304832 logging_writer.py:48] [343100] global_step=343100, grad_norm=3.1593308448791504, loss=2.291560649871826
I0304 09:48:05.391630 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:48:16.863853 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:48:46.556404 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:48:48.191060 139953291118400 submission_runner.py:411] Time since start: 165168.37s, 	Step: 343145, 	{'train/accuracy': 0.8889843821525574, 'train/loss': 0.41941213607788086, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 152539.3480424881, 'total_duration': 165168.36728596687, 'accumulated_submission_time': 152539.3480424881, 'accumulated_eval_time': 12587.055959939957, 'accumulated_logging_time': 24.475526571273804}
I0304 09:48:48.259269 139758026090240 logging_writer.py:48] [343145] accumulated_eval_time=12587.055960, accumulated_logging_time=24.475527, accumulated_submission_time=152539.348042, global_step=343145, preemption_count=0, score=152539.348042, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=165168.367286, train/accuracy=0.888984, train/loss=0.419412, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:49:10.551872 139758009304832 logging_writer.py:48] [343200] global_step=343200, grad_norm=2.9585413932800293, loss=1.4489049911499023
I0304 09:49:53.682597 139758026090240 logging_writer.py:48] [343300] global_step=343300, grad_norm=3.0021049976348877, loss=1.2265374660491943
I0304 09:50:38.511001 139758009304832 logging_writer.py:48] [343400] global_step=343400, grad_norm=3.368013381958008, loss=1.110214114189148
I0304 09:51:23.566542 139758026090240 logging_writer.py:48] [343500] global_step=343500, grad_norm=2.9313864707946777, loss=1.0188474655151367
I0304 09:52:08.450821 139758009304832 logging_writer.py:48] [343600] global_step=343600, grad_norm=2.9916651248931885, loss=2.109764814376831
I0304 09:52:53.265730 139758026090240 logging_writer.py:48] [343700] global_step=343700, grad_norm=3.0787434577941895, loss=1.0634278059005737
I0304 09:53:38.357415 139758009304832 logging_writer.py:48] [343800] global_step=343800, grad_norm=3.5958962440490723, loss=1.1072196960449219
I0304 09:54:23.564099 139758026090240 logging_writer.py:48] [343900] global_step=343900, grad_norm=3.0243465900421143, loss=1.1085110902786255
I0304 09:55:08.420597 139758009304832 logging_writer.py:48] [344000] global_step=344000, grad_norm=3.184307813644409, loss=2.4749717712402344
I0304 09:55:48.439083 139953291118400 spec.py:321] Evaluating on the training split.
I0304 09:55:59.743735 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 09:56:22.710662 139953291118400 spec.py:349] Evaluating on the test split.
I0304 09:56:24.339230 139953291118400 submission_runner.py:411] Time since start: 165624.52s, 	Step: 344090, 	{'train/accuracy': 0.8886132836341858, 'train/loss': 0.4171028733253479, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 152959.46968698502, 'total_duration': 165624.51542139053, 'accumulated_submission_time': 152959.46968698502, 'accumulated_eval_time': 12622.95605802536, 'accumulated_logging_time': 24.554410457611084}
I0304 09:56:24.431957 139758026090240 logging_writer.py:48] [344090] accumulated_eval_time=12622.956058, accumulated_logging_time=24.554410, accumulated_submission_time=152959.469687, global_step=344090, preemption_count=0, score=152959.469687, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=165624.515421, train/accuracy=0.888613, train/loss=0.417103, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 09:56:28.790892 139758009304832 logging_writer.py:48] [344100] global_step=344100, grad_norm=3.0523252487182617, loss=1.0496530532836914
I0304 09:57:10.647573 139758026090240 logging_writer.py:48] [344200] global_step=344200, grad_norm=3.0588669776916504, loss=1.3295135498046875
I0304 09:57:55.561292 139758009304832 logging_writer.py:48] [344300] global_step=344300, grad_norm=3.460569381713867, loss=1.122302770614624
I0304 09:58:40.649517 139758026090240 logging_writer.py:48] [344400] global_step=344400, grad_norm=3.5282299518585205, loss=1.2056121826171875
I0304 09:59:25.735392 139758009304832 logging_writer.py:48] [344500] global_step=344500, grad_norm=2.9368555545806885, loss=2.4693737030029297
I0304 10:00:10.759865 139758026090240 logging_writer.py:48] [344600] global_step=344600, grad_norm=2.902642011642456, loss=1.1736407279968262
I0304 10:00:55.557113 139758009304832 logging_writer.py:48] [344700] global_step=344700, grad_norm=3.2310099601745605, loss=2.907579183578491
I0304 10:01:40.661545 139758026090240 logging_writer.py:48] [344800] global_step=344800, grad_norm=3.120175361633301, loss=1.1673046350479126
I0304 10:02:25.598128 139758009304832 logging_writer.py:48] [344900] global_step=344900, grad_norm=3.090005397796631, loss=1.2075071334838867
I0304 10:03:10.506344 139758026090240 logging_writer.py:48] [345000] global_step=345000, grad_norm=3.2457072734832764, loss=2.2876040935516357
I0304 10:03:24.621851 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:03:35.833837 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:04:05.436842 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:04:07.076179 139953291118400 submission_runner.py:411] Time since start: 166087.25s, 	Step: 345033, 	{'train/accuracy': 0.8860741853713989, 'train/loss': 0.42673414945602417, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 153379.60203409195, 'total_duration': 166087.2524061203, 'accumulated_submission_time': 153379.60203409195, 'accumulated_eval_time': 12665.410373926163, 'accumulated_logging_time': 24.657466411590576}
I0304 10:04:07.159766 139758009304832 logging_writer.py:48] [345033] accumulated_eval_time=12665.410374, accumulated_logging_time=24.657466, accumulated_submission_time=153379.602034, global_step=345033, preemption_count=0, score=153379.602034, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=166087.252406, train/accuracy=0.886074, train/loss=0.426734, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:04:33.996568 139758026090240 logging_writer.py:48] [345100] global_step=345100, grad_norm=3.0977163314819336, loss=1.203957200050354
I0304 10:05:17.983910 139758009304832 logging_writer.py:48] [345200] global_step=345200, grad_norm=3.2473599910736084, loss=2.6673624515533447
I0304 10:06:03.319164 139758026090240 logging_writer.py:48] [345300] global_step=345300, grad_norm=3.861576557159424, loss=1.122403621673584
I0304 10:06:48.526002 139758009304832 logging_writer.py:48] [345400] global_step=345400, grad_norm=2.9872190952301025, loss=1.1696218252182007
I0304 10:07:33.368123 139758026090240 logging_writer.py:48] [345500] global_step=345500, grad_norm=3.6265852451324463, loss=3.2337646484375
I0304 10:08:18.581807 139758009304832 logging_writer.py:48] [345600] global_step=345600, grad_norm=3.99871563911438, loss=3.204637289047241
I0304 10:09:03.648074 139758026090240 logging_writer.py:48] [345700] global_step=345700, grad_norm=2.921123743057251, loss=1.476668357849121
I0304 10:09:48.338845 139758009304832 logging_writer.py:48] [345800] global_step=345800, grad_norm=3.7049124240875244, loss=3.076356887817383
I0304 10:10:33.359499 139758026090240 logging_writer.py:48] [345900] global_step=345900, grad_norm=3.1513831615448, loss=1.052765965461731
I0304 10:11:07.312570 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:11:18.240176 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:11:40.219925 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:11:41.851686 139953291118400 submission_runner.py:411] Time since start: 166542.03s, 	Step: 345977, 	{'train/accuracy': 0.8871288895606995, 'train/loss': 0.4171859622001648, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 153799.6966097355, 'total_duration': 166542.02790880203, 'accumulated_submission_time': 153799.6966097355, 'accumulated_eval_time': 12699.949487686157, 'accumulated_logging_time': 24.752000331878662}
I0304 10:11:41.935001 139758009304832 logging_writer.py:48] [345977] accumulated_eval_time=12699.949488, accumulated_logging_time=24.752000, accumulated_submission_time=153799.696610, global_step=345977, preemption_count=0, score=153799.696610, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=166542.027909, train/accuracy=0.887129, train/loss=0.417186, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:11:51.434800 139758026090240 logging_writer.py:48] [346000] global_step=346000, grad_norm=3.334995985031128, loss=1.1255695819854736
I0304 10:12:33.776625 139758009304832 logging_writer.py:48] [346100] global_step=346100, grad_norm=2.9161593914031982, loss=1.4251556396484375
I0304 10:13:18.618474 139758026090240 logging_writer.py:48] [346200] global_step=346200, grad_norm=3.35379958152771, loss=1.2138738632202148
I0304 10:14:03.729823 139758009304832 logging_writer.py:48] [346300] global_step=346300, grad_norm=3.029407024383545, loss=2.0017385482788086
I0304 10:14:48.872512 139758026090240 logging_writer.py:48] [346400] global_step=346400, grad_norm=2.8284003734588623, loss=2.208922863006592
I0304 10:15:33.861979 139758009304832 logging_writer.py:48] [346500] global_step=346500, grad_norm=3.6083357334136963, loss=2.228522300720215
I0304 10:16:19.360925 139758026090240 logging_writer.py:48] [346600] global_step=346600, grad_norm=3.061522960662842, loss=1.8980876207351685
I0304 10:17:04.699887 139758009304832 logging_writer.py:48] [346700] global_step=346700, grad_norm=2.93923020362854, loss=1.73810875415802
I0304 10:17:49.721008 139758026090240 logging_writer.py:48] [346800] global_step=346800, grad_norm=3.192072868347168, loss=1.0861788988113403
I0304 10:18:34.662784 139758009304832 logging_writer.py:48] [346900] global_step=346900, grad_norm=3.2411158084869385, loss=2.7019920349121094
I0304 10:18:42.118191 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:18:53.304335 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:19:27.044224 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:19:28.679586 139953291118400 submission_runner.py:411] Time since start: 167008.86s, 	Step: 346918, 	{'train/accuracy': 0.887988269329071, 'train/loss': 0.4203246533870697, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 154219.81880021095, 'total_duration': 167008.85578632355, 'accumulated_submission_time': 154219.81880021095, 'accumulated_eval_time': 12746.510839700699, 'accumulated_logging_time': 24.84833550453186}
I0304 10:19:28.760907 139758026090240 logging_writer.py:48] [346918] accumulated_eval_time=12746.510840, accumulated_logging_time=24.848336, accumulated_submission_time=154219.818800, global_step=346918, preemption_count=0, score=154219.818800, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=167008.855786, train/accuracy=0.887988, train/loss=0.420325, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:20:01.533895 139758009304832 logging_writer.py:48] [347000] global_step=347000, grad_norm=3.6401760578155518, loss=3.192625045776367
I0304 10:20:45.769563 139758026090240 logging_writer.py:48] [347100] global_step=347100, grad_norm=3.777189254760742, loss=3.211768627166748
I0304 10:21:30.736640 139758009304832 logging_writer.py:48] [347200] global_step=347200, grad_norm=3.5017311573028564, loss=3.087528705596924
I0304 10:22:15.736705 139758026090240 logging_writer.py:48] [347300] global_step=347300, grad_norm=3.1455583572387695, loss=2.682863235473633
I0304 10:23:00.394208 139758009304832 logging_writer.py:48] [347400] global_step=347400, grad_norm=3.4667434692382812, loss=3.102004051208496
I0304 10:23:45.278152 139758026090240 logging_writer.py:48] [347500] global_step=347500, grad_norm=3.0630991458892822, loss=1.1194489002227783
I0304 10:24:30.627817 139758009304832 logging_writer.py:48] [347600] global_step=347600, grad_norm=3.1128900051116943, loss=1.570875644683838
I0304 10:25:15.377240 139758026090240 logging_writer.py:48] [347700] global_step=347700, grad_norm=3.136721611022949, loss=1.152653694152832
I0304 10:26:00.325028 139758009304832 logging_writer.py:48] [347800] global_step=347800, grad_norm=2.828650712966919, loss=1.3723665475845337
I0304 10:26:28.781599 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:26:39.774461 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:27:05.313472 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:27:06.943183 139953291118400 submission_runner.py:411] Time since start: 167467.12s, 	Step: 347864, 	{'train/accuracy': 0.8874804377555847, 'train/loss': 0.4153309464454651, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 154639.78215909004, 'total_duration': 167467.11938381195, 'accumulated_submission_time': 154639.78215909004, 'accumulated_eval_time': 12784.672406435013, 'accumulated_logging_time': 24.939489126205444}
I0304 10:27:07.024548 139758026090240 logging_writer.py:48] [347864] accumulated_eval_time=12784.672406, accumulated_logging_time=24.939489, accumulated_submission_time=154639.782159, global_step=347864, preemption_count=0, score=154639.782159, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=167467.119384, train/accuracy=0.887480, train/loss=0.415331, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:27:21.643558 139758009304832 logging_writer.py:48] [347900] global_step=347900, grad_norm=3.277913808822632, loss=1.934639573097229
I0304 10:28:03.421576 139758026090240 logging_writer.py:48] [348000] global_step=348000, grad_norm=3.3950576782226562, loss=1.5965272188186646
I0304 10:28:48.085377 139758009304832 logging_writer.py:48] [348100] global_step=348100, grad_norm=3.1268506050109863, loss=1.1934826374053955
I0304 10:29:33.500798 139758026090240 logging_writer.py:48] [348200] global_step=348200, grad_norm=3.1280035972595215, loss=1.0805556774139404
I0304 10:30:18.764890 139758009304832 logging_writer.py:48] [348300] global_step=348300, grad_norm=3.0857901573181152, loss=1.396130084991455
I0304 10:31:03.582700 139758026090240 logging_writer.py:48] [348400] global_step=348400, grad_norm=3.2758843898773193, loss=1.4989373683929443
I0304 10:31:48.392967 139758009304832 logging_writer.py:48] [348500] global_step=348500, grad_norm=3.2637386322021484, loss=1.1475460529327393
I0304 10:32:33.360177 139758026090240 logging_writer.py:48] [348600] global_step=348600, grad_norm=3.344082832336426, loss=1.264733076095581
I0304 10:33:18.539429 139758009304832 logging_writer.py:48] [348700] global_step=348700, grad_norm=2.8295230865478516, loss=2.1888089179992676
I0304 10:34:03.361865 139758026090240 logging_writer.py:48] [348800] global_step=348800, grad_norm=3.251809597015381, loss=1.1286109685897827
I0304 10:34:07.127330 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:34:18.873995 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:34:40.056326 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:34:41.699729 139953291118400 submission_runner.py:411] Time since start: 167921.88s, 	Step: 348810, 	{'train/accuracy': 0.8859374523162842, 'train/loss': 0.4238024055957794, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 155059.82725691795, 'total_duration': 167921.87595415115, 'accumulated_submission_time': 155059.82725691795, 'accumulated_eval_time': 12819.244787454605, 'accumulated_logging_time': 25.030781984329224}
I0304 10:34:41.784675 139758009304832 logging_writer.py:48] [348810] accumulated_eval_time=12819.244787, accumulated_logging_time=25.030782, accumulated_submission_time=155059.827257, global_step=348810, preemption_count=0, score=155059.827257, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=167921.875954, train/accuracy=0.885937, train/loss=0.423802, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:35:19.039060 139758026090240 logging_writer.py:48] [348900] global_step=348900, grad_norm=3.1645591259002686, loss=1.1263699531555176
I0304 10:36:03.979075 139758009304832 logging_writer.py:48] [349000] global_step=349000, grad_norm=2.8774256706237793, loss=1.4779584407806396
I0304 10:36:49.204227 139758026090240 logging_writer.py:48] [349100] global_step=349100, grad_norm=3.823242664337158, loss=3.3022713661193848
I0304 10:37:34.183319 139758009304832 logging_writer.py:48] [349200] global_step=349200, grad_norm=3.054111957550049, loss=1.5674155950546265
I0304 10:38:19.182778 139758026090240 logging_writer.py:48] [349300] global_step=349300, grad_norm=3.2033298015594482, loss=0.9842014312744141
I0304 10:39:04.082334 139758009304832 logging_writer.py:48] [349400] global_step=349400, grad_norm=3.5673892498016357, loss=0.9828731417655945
I0304 10:39:49.082244 139758026090240 logging_writer.py:48] [349500] global_step=349500, grad_norm=3.1730222702026367, loss=1.1846776008605957
I0304 10:40:34.094298 139758009304832 logging_writer.py:48] [349600] global_step=349600, grad_norm=3.009678840637207, loss=2.717531681060791
I0304 10:41:19.082299 139758026090240 logging_writer.py:48] [349700] global_step=349700, grad_norm=3.72880220413208, loss=3.1778364181518555
I0304 10:41:42.144444 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:41:53.573745 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:42:16.489478 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:42:18.121978 139953291118400 submission_runner.py:411] Time since start: 168378.30s, 	Step: 349753, 	{'train/accuracy': 0.8904492259025574, 'train/loss': 0.4134562611579895, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 155480.12934875488, 'total_duration': 168378.29820513725, 'accumulated_submission_time': 155480.12934875488, 'accumulated_eval_time': 12855.2223072052, 'accumulated_logging_time': 25.12555241584778}
I0304 10:42:18.205913 139758009304832 logging_writer.py:48] [349753] accumulated_eval_time=12855.222307, accumulated_logging_time=25.125552, accumulated_submission_time=155480.129349, global_step=349753, preemption_count=0, score=155480.129349, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=168378.298205, train/accuracy=0.890449, train/loss=0.413456, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:42:37.175476 139758026090240 logging_writer.py:48] [349800] global_step=349800, grad_norm=3.0870730876922607, loss=1.1587473154067993
I0304 10:43:20.493209 139758009304832 logging_writer.py:48] [349900] global_step=349900, grad_norm=3.1202564239501953, loss=1.259676218032837
I0304 10:44:05.600451 139758026090240 logging_writer.py:48] [350000] global_step=350000, grad_norm=2.945624828338623, loss=1.1887797117233276
I0304 10:44:50.904014 139758009304832 logging_writer.py:48] [350100] global_step=350100, grad_norm=2.8536462783813477, loss=2.043630599975586
I0304 10:45:36.206627 139758026090240 logging_writer.py:48] [350200] global_step=350200, grad_norm=3.2062346935272217, loss=1.2167271375656128
I0304 10:46:21.160864 139758009304832 logging_writer.py:48] [350300] global_step=350300, grad_norm=3.601278066635132, loss=1.4916133880615234
I0304 10:47:06.372211 139758026090240 logging_writer.py:48] [350400] global_step=350400, grad_norm=3.3169615268707275, loss=1.141038417816162
I0304 10:47:51.375312 139758009304832 logging_writer.py:48] [350500] global_step=350500, grad_norm=3.0209858417510986, loss=1.2609889507293701
I0304 10:48:36.360496 139758026090240 logging_writer.py:48] [350600] global_step=350600, grad_norm=2.9279849529266357, loss=2.112353563308716
I0304 10:49:18.183593 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:49:29.189826 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:50:00.321190 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:50:01.957043 139953291118400 submission_runner.py:411] Time since start: 168842.13s, 	Step: 350694, 	{'train/accuracy': 0.8905858993530273, 'train/loss': 0.4152538478374481, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 155900.0498933792, 'total_duration': 168842.13325691223, 'accumulated_submission_time': 155900.0498933792, 'accumulated_eval_time': 12898.995729207993, 'accumulated_logging_time': 25.21956491470337}
I0304 10:50:02.041819 139758009304832 logging_writer.py:48] [350694] accumulated_eval_time=12898.995729, accumulated_logging_time=25.219565, accumulated_submission_time=155900.049893, global_step=350694, preemption_count=0, score=155900.049893, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=168842.133257, train/accuracy=0.890586, train/loss=0.415254, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:50:04.808887 139758026090240 logging_writer.py:48] [350700] global_step=350700, grad_norm=3.615715742111206, loss=1.0862797498703003
I0304 10:50:45.246682 139758009304832 logging_writer.py:48] [350800] global_step=350800, grad_norm=3.1877803802490234, loss=1.252754807472229
I0304 10:51:29.798271 139758026090240 logging_writer.py:48] [350900] global_step=350900, grad_norm=3.2071197032928467, loss=1.263055682182312
I0304 10:52:14.809847 139758009304832 logging_writer.py:48] [351000] global_step=351000, grad_norm=3.1163740158081055, loss=1.30132257938385
I0304 10:52:59.849869 139758026090240 logging_writer.py:48] [351100] global_step=351100, grad_norm=3.837238311767578, loss=1.148038625717163
I0304 10:53:44.603327 139758009304832 logging_writer.py:48] [351200] global_step=351200, grad_norm=3.194793939590454, loss=1.1569006443023682
I0304 10:54:29.573829 139758026090240 logging_writer.py:48] [351300] global_step=351300, grad_norm=3.1338000297546387, loss=1.4825445413589478
I0304 10:55:14.961186 139758009304832 logging_writer.py:48] [351400] global_step=351400, grad_norm=3.0757546424865723, loss=1.091374397277832
I0304 10:55:59.784167 139758026090240 logging_writer.py:48] [351500] global_step=351500, grad_norm=2.933056592941284, loss=1.2808501720428467
I0304 10:56:45.146429 139758009304832 logging_writer.py:48] [351600] global_step=351600, grad_norm=6.623192310333252, loss=3.2744839191436768
I0304 10:57:02.448790 139953291118400 spec.py:321] Evaluating on the training split.
I0304 10:57:13.407328 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 10:57:38.141799 139953291118400 spec.py:349] Evaluating on the test split.
I0304 10:57:39.774027 139953291118400 submission_runner.py:411] Time since start: 169299.95s, 	Step: 351640, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.41611334681510925, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 156320.398665905, 'total_duration': 169299.9502491951, 'accumulated_submission_time': 156320.398665905, 'accumulated_eval_time': 12936.320994138718, 'accumulated_logging_time': 25.31429362297058}
I0304 10:57:39.865641 139758026090240 logging_writer.py:48] [351640] accumulated_eval_time=12936.320994, accumulated_logging_time=25.314294, accumulated_submission_time=156320.398666, global_step=351640, preemption_count=0, score=156320.398666, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=169299.950249, train/accuracy=0.887500, train/loss=0.416113, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 10:58:03.948102 139758009304832 logging_writer.py:48] [351700] global_step=351700, grad_norm=3.4492697715759277, loss=2.724433422088623
I0304 10:58:47.925111 139758026090240 logging_writer.py:48] [351800] global_step=351800, grad_norm=3.4395816326141357, loss=3.0038604736328125
I0304 10:59:32.876412 139758009304832 logging_writer.py:48] [351900] global_step=351900, grad_norm=3.0300607681274414, loss=1.9073426723480225
I0304 11:00:18.136415 139758026090240 logging_writer.py:48] [352000] global_step=352000, grad_norm=3.306170701980591, loss=1.485174536705017
I0304 11:01:03.261832 139758009304832 logging_writer.py:48] [352100] global_step=352100, grad_norm=2.90630841255188, loss=2.2574262619018555
I0304 11:01:48.314782 139758026090240 logging_writer.py:48] [352200] global_step=352200, grad_norm=3.3932793140411377, loss=2.6417579650878906
I0304 11:02:33.390811 139758009304832 logging_writer.py:48] [352300] global_step=352300, grad_norm=2.986865282058716, loss=2.259110450744629
I0304 11:03:18.180200 139758026090240 logging_writer.py:48] [352400] global_step=352400, grad_norm=3.047947645187378, loss=1.3893018960952759
I0304 11:04:03.274479 139758009304832 logging_writer.py:48] [352500] global_step=352500, grad_norm=3.361525058746338, loss=1.71474027633667
I0304 11:04:39.810769 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:04:51.024734 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:05:23.287679 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:05:24.919826 139953291118400 submission_runner.py:411] Time since start: 169765.10s, 	Step: 352583, 	{'train/accuracy': 0.88587886095047, 'train/loss': 0.4204886257648468, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 156740.2870953083, 'total_duration': 169765.09603238106, 'accumulated_submission_time': 156740.2870953083, 'accumulated_eval_time': 12981.430022001266, 'accumulated_logging_time': 25.415513277053833}
I0304 11:05:25.001159 139758026090240 logging_writer.py:48] [352583] accumulated_eval_time=12981.430022, accumulated_logging_time=25.415513, accumulated_submission_time=156740.287095, global_step=352583, preemption_count=0, score=156740.287095, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=169765.096032, train/accuracy=0.885879, train/loss=0.420489, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:05:32.096517 139758009304832 logging_writer.py:48] [352600] global_step=352600, grad_norm=2.873464584350586, loss=1.353717565536499
I0304 11:06:13.765213 139758026090240 logging_writer.py:48] [352700] global_step=352700, grad_norm=3.3845572471618652, loss=1.1380894184112549
I0304 11:06:58.834366 139758009304832 logging_writer.py:48] [352800] global_step=352800, grad_norm=3.5502660274505615, loss=3.0599539279937744
I0304 11:07:44.231003 139758026090240 logging_writer.py:48] [352900] global_step=352900, grad_norm=3.5005664825439453, loss=1.1462550163269043
I0304 11:08:29.590360 139758009304832 logging_writer.py:48] [353000] global_step=353000, grad_norm=3.366354465484619, loss=1.1187965869903564
I0304 11:09:14.576269 139758026090240 logging_writer.py:48] [353100] global_step=353100, grad_norm=3.808084487915039, loss=3.31557035446167
I0304 11:09:59.360969 139758009304832 logging_writer.py:48] [353200] global_step=353200, grad_norm=3.233586549758911, loss=1.1025493144989014
I0304 11:10:44.429851 139758026090240 logging_writer.py:48] [353300] global_step=353300, grad_norm=3.0048162937164307, loss=2.274395704269409
I0304 11:11:29.445554 139758009304832 logging_writer.py:48] [353400] global_step=353400, grad_norm=2.9832475185394287, loss=1.3597688674926758
I0304 11:12:14.513673 139758026090240 logging_writer.py:48] [353500] global_step=353500, grad_norm=3.6227262020111084, loss=2.342686176300049
I0304 11:12:24.933990 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:12:36.635693 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:13:03.655998 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:13:05.293039 139953291118400 submission_runner.py:411] Time since start: 170225.47s, 	Step: 353525, 	{'train/accuracy': 0.8861718773841858, 'train/loss': 0.41957274079322815, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 157160.15752458572, 'total_duration': 170225.4692606926, 'accumulated_submission_time': 157160.15752458572, 'accumulated_eval_time': 13021.789062738419, 'accumulated_logging_time': 25.50675082206726}
I0304 11:13:05.378570 139758009304832 logging_writer.py:48] [353525] accumulated_eval_time=13021.789063, accumulated_logging_time=25.506751, accumulated_submission_time=157160.157525, global_step=353525, preemption_count=0, score=157160.157525, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=170225.469261, train/accuracy=0.886172, train/loss=0.419573, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:13:35.375881 139758026090240 logging_writer.py:48] [353600] global_step=353600, grad_norm=3.413276195526123, loss=1.3409886360168457
I0304 11:14:20.053691 139758009304832 logging_writer.py:48] [353700] global_step=353700, grad_norm=2.961843729019165, loss=1.1352359056472778
I0304 11:15:04.881812 139758026090240 logging_writer.py:48] [353800] global_step=353800, grad_norm=2.905384063720703, loss=1.0575799942016602
I0304 11:15:50.228454 139758009304832 logging_writer.py:48] [353900] global_step=353900, grad_norm=3.3270680904388428, loss=2.490363597869873
I0304 11:16:35.389358 139758026090240 logging_writer.py:48] [354000] global_step=354000, grad_norm=3.3170926570892334, loss=1.0126663446426392
I0304 11:17:20.645905 139758009304832 logging_writer.py:48] [354100] global_step=354100, grad_norm=3.011502981185913, loss=2.462092399597168
I0304 11:18:05.489963 139758026090240 logging_writer.py:48] [354200] global_step=354200, grad_norm=3.575542449951172, loss=2.9587528705596924
I0304 11:18:50.596220 139758009304832 logging_writer.py:48] [354300] global_step=354300, grad_norm=3.165468692779541, loss=1.1677247285842896
I0304 11:19:35.455173 139758026090240 logging_writer.py:48] [354400] global_step=354400, grad_norm=3.314969539642334, loss=1.1292829513549805
I0304 11:20:05.405545 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:20:16.934344 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:20:42.826276 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:20:44.462064 139953291118400 submission_runner.py:411] Time since start: 170684.64s, 	Step: 354468, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.4124457836151123, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 157580.12749171257, 'total_duration': 170684.63828587532, 'accumulated_submission_time': 157580.12749171257, 'accumulated_eval_time': 13060.845579624176, 'accumulated_logging_time': 25.601975679397583}
I0304 11:20:44.545712 139758009304832 logging_writer.py:48] [354468] accumulated_eval_time=13060.845580, accumulated_logging_time=25.601976, accumulated_submission_time=157580.127492, global_step=354468, preemption_count=0, score=157580.127492, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=170684.638286, train/accuracy=0.887734, train/loss=0.412446, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:20:57.573379 139758026090240 logging_writer.py:48] [354500] global_step=354500, grad_norm=3.2470149993896484, loss=1.1620500087738037
I0304 11:21:40.519057 139758009304832 logging_writer.py:48] [354600] global_step=354600, grad_norm=3.395824909210205, loss=1.2469285726547241
I0304 11:22:25.714530 139758026090240 logging_writer.py:48] [354700] global_step=354700, grad_norm=3.134971857070923, loss=2.4200022220611572
I0304 11:23:10.794031 139758009304832 logging_writer.py:48] [354800] global_step=354800, grad_norm=2.8578786849975586, loss=1.9642231464385986
I0304 11:23:55.651117 139758026090240 logging_writer.py:48] [354900] global_step=354900, grad_norm=2.807168960571289, loss=1.6838264465332031
I0304 11:24:40.483411 139758009304832 logging_writer.py:48] [355000] global_step=355000, grad_norm=3.200737714767456, loss=1.1315343379974365
I0304 11:25:25.547541 139758026090240 logging_writer.py:48] [355100] global_step=355100, grad_norm=3.3717198371887207, loss=1.1671582460403442
I0304 11:26:10.664894 139758009304832 logging_writer.py:48] [355200] global_step=355200, grad_norm=3.1224350929260254, loss=1.127083659172058
I0304 11:26:55.741943 139758026090240 logging_writer.py:48] [355300] global_step=355300, grad_norm=3.120116949081421, loss=2.7115182876586914
I0304 11:27:41.085778 139758009304832 logging_writer.py:48] [355400] global_step=355400, grad_norm=2.962024450302124, loss=1.0988837480545044
I0304 11:27:44.896747 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:27:56.008316 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:28:24.307885 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:28:25.949776 139953291118400 submission_runner.py:411] Time since start: 171146.13s, 	Step: 355410, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.42098310589790344, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 158000.41928219795, 'total_duration': 171146.12599873543, 'accumulated_submission_time': 158000.41928219795, 'accumulated_eval_time': 13101.89858865738, 'accumulated_logging_time': 25.696571111679077}
I0304 11:28:26.034923 139758026090240 logging_writer.py:48] [355410] accumulated_eval_time=13101.898589, accumulated_logging_time=25.696571, accumulated_submission_time=158000.419282, global_step=355410, preemption_count=0, score=158000.419282, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=171146.125999, train/accuracy=0.886465, train/loss=0.420983, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:29:02.994641 139758009304832 logging_writer.py:48] [355500] global_step=355500, grad_norm=3.4856817722320557, loss=2.9073562622070312
I0304 11:29:47.618215 139758026090240 logging_writer.py:48] [355600] global_step=355600, grad_norm=2.964484453201294, loss=1.5041894912719727
I0304 11:30:32.713869 139758009304832 logging_writer.py:48] [355700] global_step=355700, grad_norm=3.9476711750030518, loss=1.1710087060928345
I0304 11:31:18.180280 139758026090240 logging_writer.py:48] [355800] global_step=355800, grad_norm=3.1269826889038086, loss=1.067960262298584
I0304 11:32:03.166789 139758009304832 logging_writer.py:48] [355900] global_step=355900, grad_norm=3.127495288848877, loss=1.0629336833953857
I0304 11:32:47.903722 139758026090240 logging_writer.py:48] [356000] global_step=356000, grad_norm=3.3192663192749023, loss=1.2647062540054321
I0304 11:33:32.943256 139758009304832 logging_writer.py:48] [356100] global_step=356100, grad_norm=3.4046192169189453, loss=3.0846920013427734
I0304 11:34:17.974616 139758026090240 logging_writer.py:48] [356200] global_step=356200, grad_norm=3.746222734451294, loss=2.8990626335144043
I0304 11:35:03.362507 139758009304832 logging_writer.py:48] [356300] global_step=356300, grad_norm=3.2552249431610107, loss=1.203590989112854
I0304 11:35:26.293250 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:35:37.384277 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:36:07.675205 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:36:09.308162 139953291118400 submission_runner.py:411] Time since start: 171609.48s, 	Step: 356353, 	{'train/accuracy': 0.8862890601158142, 'train/loss': 0.4223797619342804, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 158420.6190032959, 'total_duration': 171609.484395504, 'accumulated_submission_time': 158420.6190032959, 'accumulated_eval_time': 13144.91348528862, 'accumulated_logging_time': 25.793184995651245}
I0304 11:36:09.381172 139758026090240 logging_writer.py:48] [356353] accumulated_eval_time=13144.913485, accumulated_logging_time=25.793185, accumulated_submission_time=158420.619003, global_step=356353, preemption_count=0, score=158420.619003, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=171609.484396, train/accuracy=0.886289, train/loss=0.422380, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:36:28.332374 139758009304832 logging_writer.py:48] [356400] global_step=356400, grad_norm=4.024259090423584, loss=3.2414793968200684
I0304 11:37:10.687259 139758026090240 logging_writer.py:48] [356500] global_step=356500, grad_norm=3.1581058502197266, loss=2.789698839187622
I0304 11:37:55.806511 139758009304832 logging_writer.py:48] [356600] global_step=356600, grad_norm=2.9328973293304443, loss=1.1342941522598267
I0304 11:38:40.795457 139758026090240 logging_writer.py:48] [356700] global_step=356700, grad_norm=3.1655263900756836, loss=1.3832255601882935
I0304 11:39:25.875129 139758009304832 logging_writer.py:48] [356800] global_step=356800, grad_norm=3.219104528427124, loss=2.749791145324707
I0304 11:40:10.749548 139758026090240 logging_writer.py:48] [356900] global_step=356900, grad_norm=2.9820570945739746, loss=1.1773604154586792
I0304 11:40:55.894969 139758009304832 logging_writer.py:48] [357000] global_step=357000, grad_norm=3.3227317333221436, loss=1.1774487495422363
I0304 11:41:40.835869 139758026090240 logging_writer.py:48] [357100] global_step=357100, grad_norm=2.9615912437438965, loss=2.177215099334717
I0304 11:42:25.610670 139758009304832 logging_writer.py:48] [357200] global_step=357200, grad_norm=3.06093430519104, loss=1.3843822479248047
I0304 11:43:09.337422 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:43:20.328159 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:43:41.951375 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:43:43.588950 139953291118400 submission_runner.py:411] Time since start: 172063.77s, 	Step: 357299, 	{'train/accuracy': 0.8887499570846558, 'train/loss': 0.41850852966308594, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 158840.51721048355, 'total_duration': 172063.7651720047, 'accumulated_submission_time': 158840.51721048355, 'accumulated_eval_time': 13179.165003061295, 'accumulated_logging_time': 25.876455068588257}
I0304 11:43:43.673968 139758026090240 logging_writer.py:48] [357299] accumulated_eval_time=13179.165003, accumulated_logging_time=25.876455, accumulated_submission_time=158840.517210, global_step=357299, preemption_count=0, score=158840.517210, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=172063.765172, train/accuracy=0.888750, train/loss=0.418509, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:43:44.475713 139758009304832 logging_writer.py:48] [357300] global_step=357300, grad_norm=3.243896961212158, loss=1.0595579147338867
I0304 11:44:25.493786 139758026090240 logging_writer.py:48] [357400] global_step=357400, grad_norm=3.7627851963043213, loss=2.7048566341400146
I0304 11:45:10.430502 139758009304832 logging_writer.py:48] [357500] global_step=357500, grad_norm=2.984079122543335, loss=1.110856056213379
I0304 11:45:55.646062 139758026090240 logging_writer.py:48] [357600] global_step=357600, grad_norm=3.078397750854492, loss=1.0344709157943726
I0304 11:46:41.278460 139758009304832 logging_writer.py:48] [357700] global_step=357700, grad_norm=3.128580331802368, loss=1.076985239982605
I0304 11:47:26.221155 139758026090240 logging_writer.py:48] [357800] global_step=357800, grad_norm=3.164320945739746, loss=1.0943421125411987
I0304 11:48:11.577501 139758009304832 logging_writer.py:48] [357900] global_step=357900, grad_norm=2.96317195892334, loss=1.6672292947769165
I0304 11:48:56.655936 139758026090240 logging_writer.py:48] [358000] global_step=358000, grad_norm=2.8933067321777344, loss=1.8886849880218506
I0304 11:49:41.984258 139758009304832 logging_writer.py:48] [358100] global_step=358100, grad_norm=3.208263397216797, loss=1.1567447185516357
I0304 11:50:27.149049 139758026090240 logging_writer.py:48] [358200] global_step=358200, grad_norm=3.356581687927246, loss=2.581373453140259
I0304 11:50:43.908990 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:50:55.217966 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:51:27.626965 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:51:29.254433 139953291118400 submission_runner.py:411] Time since start: 172529.43s, 	Step: 358239, 	{'train/accuracy': 0.8867577910423279, 'train/loss': 0.42192044854164124, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 159260.69488954544, 'total_duration': 172529.43064379692, 'accumulated_submission_time': 159260.69488954544, 'accumulated_eval_time': 13224.510422706604, 'accumulated_logging_time': 25.971724033355713}
I0304 11:51:29.334891 139758009304832 logging_writer.py:48] [358239] accumulated_eval_time=13224.510423, accumulated_logging_time=25.971724, accumulated_submission_time=159260.694890, global_step=358239, preemption_count=0, score=159260.694890, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=172529.430644, train/accuracy=0.886758, train/loss=0.421920, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:51:53.926393 139758026090240 logging_writer.py:48] [358300] global_step=358300, grad_norm=2.9164466857910156, loss=1.7752552032470703
I0304 11:52:37.459608 139758009304832 logging_writer.py:48] [358400] global_step=358400, grad_norm=4.048757076263428, loss=3.069601535797119
I0304 11:53:22.416307 139758026090240 logging_writer.py:48] [358500] global_step=358500, grad_norm=4.756197452545166, loss=3.2597153186798096
I0304 11:54:07.807459 139758009304832 logging_writer.py:48] [358600] global_step=358600, grad_norm=4.315003395080566, loss=3.2370617389678955
I0304 11:54:52.806356 139758026090240 logging_writer.py:48] [358700] global_step=358700, grad_norm=2.9821577072143555, loss=1.062267780303955
I0304 11:55:37.785259 139758009304832 logging_writer.py:48] [358800] global_step=358800, grad_norm=2.9803874492645264, loss=1.1452009677886963
I0304 11:56:23.118519 139758026090240 logging_writer.py:48] [358900] global_step=358900, grad_norm=3.1372129917144775, loss=1.2532354593276978
I0304 11:57:08.165350 139758009304832 logging_writer.py:48] [359000] global_step=359000, grad_norm=3.6273608207702637, loss=1.1758618354797363
I0304 11:57:53.218729 139758026090240 logging_writer.py:48] [359100] global_step=359100, grad_norm=2.949723482131958, loss=1.0075350999832153
I0304 11:58:29.405668 139953291118400 spec.py:321] Evaluating on the training split.
I0304 11:58:40.453929 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 11:59:03.633988 139953291118400 spec.py:349] Evaluating on the test split.
I0304 11:59:05.270034 139953291118400 submission_runner.py:411] Time since start: 172985.45s, 	Step: 359182, 	{'train/accuracy': 0.8855664134025574, 'train/loss': 0.42376503348350525, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 159680.70743894577, 'total_duration': 172985.44624853134, 'accumulated_submission_time': 159680.70743894577, 'accumulated_eval_time': 13260.374766349792, 'accumulated_logging_time': 26.063395261764526}
I0304 11:59:05.358075 139758009304832 logging_writer.py:48] [359182] accumulated_eval_time=13260.374766, accumulated_logging_time=26.063395, accumulated_submission_time=159680.707439, global_step=359182, preemption_count=0, score=159680.707439, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=172985.446249, train/accuracy=0.885566, train/loss=0.423765, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 11:59:12.866512 139758026090240 logging_writer.py:48] [359200] global_step=359200, grad_norm=3.047933578491211, loss=2.3526930809020996
I0304 11:59:54.333127 139758009304832 logging_writer.py:48] [359300] global_step=359300, grad_norm=2.8656582832336426, loss=1.1539947986602783
I0304 12:00:39.077219 139758026090240 logging_writer.py:48] [359400] global_step=359400, grad_norm=3.2164418697357178, loss=1.2572495937347412
I0304 12:01:24.220652 139758009304832 logging_writer.py:48] [359500] global_step=359500, grad_norm=2.9038162231445312, loss=1.1575261354446411
I0304 12:02:09.728685 139758026090240 logging_writer.py:48] [359600] global_step=359600, grad_norm=3.041759967803955, loss=2.003589630126953
I0304 12:02:54.533413 139758009304832 logging_writer.py:48] [359700] global_step=359700, grad_norm=3.021040201187134, loss=1.097468614578247
I0304 12:03:39.364990 139758026090240 logging_writer.py:48] [359800] global_step=359800, grad_norm=3.3357715606689453, loss=1.110929012298584
I0304 12:04:24.137624 139758009304832 logging_writer.py:48] [359900] global_step=359900, grad_norm=3.48911714553833, loss=1.1636278629302979
I0304 12:05:08.849760 139758026090240 logging_writer.py:48] [360000] global_step=360000, grad_norm=3.233689308166504, loss=1.133085012435913
I0304 12:05:53.851500 139758009304832 logging_writer.py:48] [360100] global_step=360100, grad_norm=3.0832064151763916, loss=2.2303781509399414
I0304 12:06:05.381567 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:06:16.814469 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 12:06:40.819581 139953291118400 spec.py:349] Evaluating on the test split.
I0304 12:06:42.453794 139953291118400 submission_runner.py:411] Time since start: 173442.63s, 	Step: 360127, 	{'train/accuracy': 0.8892382383346558, 'train/loss': 0.414288729429245, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 160100.66970348358, 'total_duration': 173442.63001036644, 'accumulated_submission_time': 160100.66970348358, 'accumulated_eval_time': 13297.446984291077, 'accumulated_logging_time': 26.16198706626892}
I0304 12:06:42.541566 139758026090240 logging_writer.py:48] [360127] accumulated_eval_time=13297.446984, accumulated_logging_time=26.161987, accumulated_submission_time=160100.669703, global_step=360127, preemption_count=0, score=160100.669703, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=173442.630010, train/accuracy=0.889238, train/loss=0.414289, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 12:07:11.775100 139758009304832 logging_writer.py:48] [360200] global_step=360200, grad_norm=3.304166316986084, loss=1.3789206743240356
I0304 12:07:56.175819 139758026090240 logging_writer.py:48] [360300] global_step=360300, grad_norm=3.327180862426758, loss=2.1619162559509277
I0304 12:08:41.563113 139758009304832 logging_writer.py:48] [360400] global_step=360400, grad_norm=2.9134700298309326, loss=2.3868215084075928
I0304 12:09:26.721718 139758026090240 logging_writer.py:48] [360500] global_step=360500, grad_norm=3.02932071685791, loss=1.7411670684814453
I0304 12:10:11.770676 139758009304832 logging_writer.py:48] [360600] global_step=360600, grad_norm=3.086146831512451, loss=0.9751406311988831
I0304 12:10:56.669331 139758026090240 logging_writer.py:48] [360700] global_step=360700, grad_norm=3.7599093914031982, loss=3.222546100616455
I0304 12:11:41.654416 139758009304832 logging_writer.py:48] [360800] global_step=360800, grad_norm=3.439422607421875, loss=2.7269158363342285
I0304 12:12:26.601797 139758026090240 logging_writer.py:48] [360900] global_step=360900, grad_norm=3.352334499359131, loss=1.1282809972763062
I0304 12:13:11.669913 139758009304832 logging_writer.py:48] [361000] global_step=361000, grad_norm=3.2428581714630127, loss=1.054510474205017
I0304 12:13:42.486937 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:13:53.543295 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 12:14:14.330269 139953291118400 spec.py:349] Evaluating on the test split.
I0304 12:14:15.970700 139953291118400 submission_runner.py:411] Time since start: 173896.15s, 	Step: 361070, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.41199439764022827, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 160520.55683374405, 'total_duration': 173896.1469092369, 'accumulated_submission_time': 160520.55683374405, 'accumulated_eval_time': 13330.930730581284, 'accumulated_logging_time': 26.26072931289673}
I0304 12:14:16.057697 139758026090240 logging_writer.py:48] [361070] accumulated_eval_time=13330.930731, accumulated_logging_time=26.260729, accumulated_submission_time=160520.556834, global_step=361070, preemption_count=0, score=160520.556834, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=173896.146909, train/accuracy=0.888320, train/loss=0.411994, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 12:14:28.312696 139758009304832 logging_writer.py:48] [361100] global_step=361100, grad_norm=3.1379332542419434, loss=1.2125004529953003
I0304 12:15:10.864112 139758026090240 logging_writer.py:48] [361200] global_step=361200, grad_norm=3.7802939414978027, loss=3.1193368434906006
I0304 12:15:55.884610 139758009304832 logging_writer.py:48] [361300] global_step=361300, grad_norm=3.027355909347534, loss=1.002636194229126
I0304 12:16:41.076059 139758026090240 logging_writer.py:48] [361400] global_step=361400, grad_norm=3.227976083755493, loss=1.8436298370361328
I0304 12:17:26.072727 139758009304832 logging_writer.py:48] [361500] global_step=361500, grad_norm=2.8408102989196777, loss=2.1765053272247314
I0304 12:18:11.150718 139758026090240 logging_writer.py:48] [361600] global_step=361600, grad_norm=3.025934934616089, loss=1.0572624206542969
I0304 12:18:55.955785 139758009304832 logging_writer.py:48] [361700] global_step=361700, grad_norm=2.9807493686676025, loss=2.1968941688537598
I0304 12:19:40.747783 139758026090240 logging_writer.py:48] [361800] global_step=361800, grad_norm=3.520930528640747, loss=1.0754995346069336
I0304 12:20:25.332080 139758009304832 logging_writer.py:48] [361900] global_step=361900, grad_norm=3.156763792037964, loss=1.8027796745300293
I0304 12:21:10.245527 139758026090240 logging_writer.py:48] [362000] global_step=362000, grad_norm=3.163722038269043, loss=2.3950088024139404
I0304 12:21:16.265036 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:21:27.427944 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 12:22:00.016910 139953291118400 spec.py:349] Evaluating on the test split.
I0304 12:22:01.652888 139953291118400 submission_runner.py:411] Time since start: 174361.83s, 	Step: 362015, 	{'train/accuracy': 0.8843945264816284, 'train/loss': 0.42653587460517883, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 160940.7024629116, 'total_duration': 174361.82907938957, 'accumulated_submission_time': 160940.7024629116, 'accumulated_eval_time': 13376.318539857864, 'accumulated_logging_time': 26.357743978500366}
I0304 12:22:01.774992 139758009304832 logging_writer.py:48] [362015] accumulated_eval_time=13376.318540, accumulated_logging_time=26.357744, accumulated_submission_time=160940.702463, global_step=362015, preemption_count=0, score=160940.702463, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=174361.829079, train/accuracy=0.884395, train/loss=0.426536, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 12:22:35.743569 139758026090240 logging_writer.py:48] [362100] global_step=362100, grad_norm=3.3340635299682617, loss=1.2296780347824097
I0304 12:23:19.871727 139758009304832 logging_writer.py:48] [362200] global_step=362200, grad_norm=3.0322110652923584, loss=2.2265238761901855
I0304 12:24:04.504697 139758026090240 logging_writer.py:48] [362300] global_step=362300, grad_norm=2.959354877471924, loss=1.281969428062439
I0304 12:24:49.498585 139758009304832 logging_writer.py:48] [362400] global_step=362400, grad_norm=3.6006429195404053, loss=2.012099266052246
I0304 12:25:34.569540 139758026090240 logging_writer.py:48] [362500] global_step=362500, grad_norm=4.943394660949707, loss=2.687391996383667
I0304 12:26:19.823708 139758009304832 logging_writer.py:48] [362600] global_step=362600, grad_norm=3.2867650985717773, loss=2.7805466651916504
I0304 12:27:04.977001 139758026090240 logging_writer.py:48] [362700] global_step=362700, grad_norm=2.9332876205444336, loss=1.7173361778259277
I0304 12:27:49.894735 139758009304832 logging_writer.py:48] [362800] global_step=362800, grad_norm=2.9561946392059326, loss=1.59047269821167
I0304 12:28:35.709582 139758026090240 logging_writer.py:48] [362900] global_step=362900, grad_norm=2.9958302974700928, loss=1.2307145595550537
I0304 12:29:02.163765 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:29:13.172195 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 12:29:33.899051 139953291118400 spec.py:349] Evaluating on the test split.
I0304 12:29:35.533375 139953291118400 submission_runner.py:411] Time since start: 174815.71s, 	Step: 362960, 	{'train/accuracy': 0.8865624666213989, 'train/loss': 0.4253043234348297, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 161361.03342723846, 'total_duration': 174815.7095863819, 'accumulated_submission_time': 161361.03342723846, 'accumulated_eval_time': 13409.688135623932, 'accumulated_logging_time': 26.49013066291809}
I0304 12:29:35.616991 139758009304832 logging_writer.py:48] [362960] accumulated_eval_time=13409.688136, accumulated_logging_time=26.490131, accumulated_submission_time=161361.033427, global_step=362960, preemption_count=0, score=161361.033427, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=174815.709586, train/accuracy=0.886562, train/loss=0.425304, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 12:29:51.821515 139758026090240 logging_writer.py:48] [363000] global_step=363000, grad_norm=3.1171464920043945, loss=1.861574411392212
I0304 12:30:35.103836 139758009304832 logging_writer.py:48] [363100] global_step=363100, grad_norm=3.8919100761413574, loss=2.839843988418579
I0304 12:31:20.144063 139758026090240 logging_writer.py:48] [363200] global_step=363200, grad_norm=4.099938869476318, loss=3.2246792316436768
I0304 12:32:05.457884 139758009304832 logging_writer.py:48] [363300] global_step=363300, grad_norm=3.476494789123535, loss=1.187821626663208
I0304 12:32:50.484592 139758026090240 logging_writer.py:48] [363400] global_step=363400, grad_norm=3.171373128890991, loss=1.0769284963607788
I0304 12:33:35.621631 139758009304832 logging_writer.py:48] [363500] global_step=363500, grad_norm=3.287306547164917, loss=1.1350692510604858
I0304 12:34:20.535805 139758026090240 logging_writer.py:48] [363600] global_step=363600, grad_norm=3.084005117416382, loss=1.1344313621520996
I0304 12:35:05.837676 139758009304832 logging_writer.py:48] [363700] global_step=363700, grad_norm=3.081882953643799, loss=2.6918210983276367
I0304 12:35:50.896710 139758026090240 logging_writer.py:48] [363800] global_step=363800, grad_norm=3.079455614089966, loss=2.719306707382202
I0304 12:36:36.143670 139758009304832 logging_writer.py:48] [363900] global_step=363900, grad_norm=3.032461404800415, loss=1.2795774936676025
I0304 12:36:36.157077 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:36:47.456449 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 12:37:14.192251 139953291118400 spec.py:349] Evaluating on the test split.
I0304 12:37:15.821664 139953291118400 submission_runner.py:411] Time since start: 175276.00s, 	Step: 363901, 	{'train/accuracy': 0.8876562118530273, 'train/loss': 0.41838622093200684, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 161781.51662492752, 'total_duration': 175275.9978826046, 'accumulated_submission_time': 161781.51662492752, 'accumulated_eval_time': 13449.352699279785, 'accumulated_logging_time': 26.583407163619995}
I0304 12:37:15.907972 139758026090240 logging_writer.py:48] [363901] accumulated_eval_time=13449.352699, accumulated_logging_time=26.583407, accumulated_submission_time=161781.516625, global_step=363901, preemption_count=0, score=161781.516625, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=175275.997883, train/accuracy=0.887656, train/loss=0.418386, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 12:37:55.927541 139758009304832 logging_writer.py:48] [364000] global_step=364000, grad_norm=3.6092543601989746, loss=2.9693310260772705
I0304 12:38:41.093284 139758026090240 logging_writer.py:48] [364100] global_step=364100, grad_norm=3.0585458278656006, loss=1.1322600841522217
I0304 12:39:26.283024 139758009304832 logging_writer.py:48] [364200] global_step=364200, grad_norm=3.801515817642212, loss=3.2777678966522217
I0304 12:40:11.692289 139758026090240 logging_writer.py:48] [364300] global_step=364300, grad_norm=3.3027093410491943, loss=1.288589596748352
I0304 12:40:56.479586 139758009304832 logging_writer.py:48] [364400] global_step=364400, grad_norm=3.310413122177124, loss=3.09139347076416
I0304 12:41:41.630781 139758026090240 logging_writer.py:48] [364500] global_step=364500, grad_norm=3.2012217044830322, loss=2.2349469661712646
I0304 12:42:26.946190 139758009304832 logging_writer.py:48] [364600] global_step=364600, grad_norm=3.551393508911133, loss=1.0554265975952148
I0304 12:43:11.657762 139758026090240 logging_writer.py:48] [364700] global_step=364700, grad_norm=3.0703747272491455, loss=2.685378313064575
I0304 12:43:56.454290 139758009304832 logging_writer.py:48] [364800] global_step=364800, grad_norm=3.1680963039398193, loss=1.2154603004455566
I0304 12:44:16.013975 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:44:26.841670 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 12:44:50.299054 139953291118400 spec.py:349] Evaluating on the test split.
I0304 12:44:51.936859 139953291118400 submission_runner.py:411] Time since start: 175732.11s, 	Step: 364845, 	{'train/accuracy': 0.8862695097923279, 'train/loss': 0.41619616746902466, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 162201.56584835052, 'total_duration': 175732.1130809784, 'accumulated_submission_time': 162201.56584835052, 'accumulated_eval_time': 13485.275573015213, 'accumulated_logging_time': 26.678946018218994}
I0304 12:44:52.025012 139758026090240 logging_writer.py:48] [364845] accumulated_eval_time=13485.275573, accumulated_logging_time=26.678946, accumulated_submission_time=162201.565848, global_step=364845, preemption_count=0, score=162201.565848, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=175732.113081, train/accuracy=0.886270, train/loss=0.416196, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 12:45:14.137049 139758009304832 logging_writer.py:48] [364900] global_step=364900, grad_norm=3.0132861137390137, loss=1.0783939361572266
I0304 12:45:57.386055 139758026090240 logging_writer.py:48] [365000] global_step=365000, grad_norm=2.8791229724884033, loss=1.3782371282577515
I0304 12:46:42.378650 139758009304832 logging_writer.py:48] [365100] global_step=365100, grad_norm=3.1277599334716797, loss=1.14395010471344
I0304 12:47:27.461781 139758026090240 logging_writer.py:48] [365200] global_step=365200, grad_norm=2.8723690509796143, loss=1.1085773706436157
I0304 12:48:12.413989 139758009304832 logging_writer.py:48] [365300] global_step=365300, grad_norm=3.1324169635772705, loss=2.5316457748413086
I0304 12:48:57.658136 139758026090240 logging_writer.py:48] [365400] global_step=365400, grad_norm=3.254695415496826, loss=2.691960334777832
I0304 12:49:42.722192 139758009304832 logging_writer.py:48] [365500] global_step=365500, grad_norm=3.3378610610961914, loss=1.445601224899292
I0304 12:50:27.991982 139758026090240 logging_writer.py:48] [365600] global_step=365600, grad_norm=3.083636522293091, loss=1.485317587852478
I0304 12:51:13.174273 139758009304832 logging_writer.py:48] [365700] global_step=365700, grad_norm=3.6895954608917236, loss=1.4867175817489624
I0304 12:51:52.281823 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:52:03.566735 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 12:52:24.243501 139953291118400 spec.py:349] Evaluating on the test split.
I0304 12:52:25.884319 139953291118400 submission_runner.py:411] Time since start: 176186.06s, 	Step: 365789, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.41998276114463806, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 162621.76594257355, 'total_duration': 176186.0605404377, 'accumulated_submission_time': 162621.76594257355, 'accumulated_eval_time': 13518.878060102463, 'accumulated_logging_time': 26.776683807373047}
I0304 12:52:25.971338 139758026090240 logging_writer.py:48] [365789] accumulated_eval_time=13518.878060, accumulated_logging_time=26.776684, accumulated_submission_time=162621.765943, global_step=365789, preemption_count=0, score=162621.765943, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=176186.060540, train/accuracy=0.888144, train/loss=0.419983, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 12:52:30.723948 139758009304832 logging_writer.py:48] [365800] global_step=365800, grad_norm=3.024430990219116, loss=1.1233327388763428
I0304 12:53:12.303562 139758026090240 logging_writer.py:48] [365900] global_step=365900, grad_norm=3.1640915870666504, loss=2.002636194229126
I0304 12:53:57.097418 139758009304832 logging_writer.py:48] [366000] global_step=366000, grad_norm=3.292402744293213, loss=1.1868518590927124
I0304 12:54:41.922471 139758026090240 logging_writer.py:48] [366100] global_step=366100, grad_norm=3.1287708282470703, loss=1.0685275793075562
I0304 12:55:27.114595 139758009304832 logging_writer.py:48] [366200] global_step=366200, grad_norm=3.215435266494751, loss=1.0844252109527588
I0304 12:56:12.026324 139758026090240 logging_writer.py:48] [366300] global_step=366300, grad_norm=3.0852746963500977, loss=1.2116433382034302
I0304 12:56:57.104573 139758009304832 logging_writer.py:48] [366400] global_step=366400, grad_norm=3.795229911804199, loss=3.2553093433380127
I0304 12:57:42.194259 139758026090240 logging_writer.py:48] [366500] global_step=366500, grad_norm=3.1309947967529297, loss=1.1754608154296875
I0304 12:58:27.527412 139758009304832 logging_writer.py:48] [366600] global_step=366600, grad_norm=2.838015556335449, loss=1.112594723701477
I0304 12:59:12.326549 139758026090240 logging_writer.py:48] [366700] global_step=366700, grad_norm=3.159660816192627, loss=1.358137845993042
I0304 12:59:26.414971 139953291118400 spec.py:321] Evaluating on the training split.
I0304 12:59:37.491545 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:00:13.738703 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:00:15.367793 139953291118400 submission_runner.py:411] Time since start: 176655.54s, 	Step: 366733, 	{'train/accuracy': 0.8887109160423279, 'train/loss': 0.416282057762146, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 163042.15055036545, 'total_duration': 176655.54402661324, 'accumulated_submission_time': 163042.15055036545, 'accumulated_eval_time': 13567.830877304077, 'accumulated_logging_time': 26.87555503845215}
I0304 13:00:15.437445 139758009304832 logging_writer.py:48] [366733] accumulated_eval_time=13567.830877, accumulated_logging_time=26.875555, accumulated_submission_time=163042.150550, global_step=366733, preemption_count=0, score=163042.150550, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=176655.544027, train/accuracy=0.888711, train/loss=0.416282, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:00:42.285360 139758026090240 logging_writer.py:48] [366800] global_step=366800, grad_norm=2.818786382675171, loss=1.087789535522461
I0304 13:01:25.309576 139758009304832 logging_writer.py:48] [366900] global_step=366900, grad_norm=3.2238380908966064, loss=1.1117007732391357
I0304 13:02:10.009616 139758026090240 logging_writer.py:48] [367000] global_step=367000, grad_norm=2.9300942420959473, loss=1.6585922241210938
I0304 13:02:54.943245 139758009304832 logging_writer.py:48] [367100] global_step=367100, grad_norm=3.1368091106414795, loss=1.177148699760437
I0304 13:03:39.701683 139758026090240 logging_writer.py:48] [367200] global_step=367200, grad_norm=3.3852272033691406, loss=2.863877058029175
I0304 13:04:24.557374 139758009304832 logging_writer.py:48] [367300] global_step=367300, grad_norm=3.209498405456543, loss=2.020840644836426
I0304 13:05:09.276663 139758026090240 logging_writer.py:48] [367400] global_step=367400, grad_norm=2.9361915588378906, loss=1.1564550399780273
I0304 13:05:53.836969 139758009304832 logging_writer.py:48] [367500] global_step=367500, grad_norm=3.1788039207458496, loss=1.1658222675323486
I0304 13:06:39.153398 139758026090240 logging_writer.py:48] [367600] global_step=367600, grad_norm=3.247868537902832, loss=1.3866387605667114
I0304 13:07:15.610805 139953291118400 spec.py:321] Evaluating on the training split.
I0304 13:07:26.549156 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:07:54.824523 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:07:56.456751 139953291118400 submission_runner.py:411] Time since start: 177116.63s, 	Step: 367683, 	{'train/accuracy': 0.8882421851158142, 'train/loss': 0.41900691390037537, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 163462.26739168167, 'total_duration': 177116.63298726082, 'accumulated_submission_time': 163462.26739168167, 'accumulated_eval_time': 13608.676812171936, 'accumulated_logging_time': 26.954416275024414}
I0304 13:07:56.527075 139758009304832 logging_writer.py:48] [367683] accumulated_eval_time=13608.676812, accumulated_logging_time=26.954416, accumulated_submission_time=163462.267392, global_step=367683, preemption_count=0, score=163462.267392, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=177116.632987, train/accuracy=0.888242, train/loss=0.419007, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:08:03.636398 139758026090240 logging_writer.py:48] [367700] global_step=367700, grad_norm=3.185389995574951, loss=1.673414945602417
I0304 13:08:44.632331 139758009304832 logging_writer.py:48] [367800] global_step=367800, grad_norm=3.508186101913452, loss=2.8021113872528076
I0304 13:09:29.792559 139758026090240 logging_writer.py:48] [367900] global_step=367900, grad_norm=3.4239792823791504, loss=2.344928026199341
I0304 13:10:14.887122 139758009304832 logging_writer.py:48] [368000] global_step=368000, grad_norm=2.8785762786865234, loss=1.0902431011199951
I0304 13:11:00.198315 139758026090240 logging_writer.py:48] [368100] global_step=368100, grad_norm=3.844367742538452, loss=2.7027246952056885
I0304 13:11:45.215101 139758009304832 logging_writer.py:48] [368200] global_step=368200, grad_norm=3.2497901916503906, loss=2.8121018409729004
I0304 13:12:30.143332 139758026090240 logging_writer.py:48] [368300] global_step=368300, grad_norm=2.9765658378601074, loss=1.9109768867492676
I0304 13:13:15.142841 139758009304832 logging_writer.py:48] [368400] global_step=368400, grad_norm=3.209782361984253, loss=1.1018650531768799
I0304 13:14:00.050225 139758026090240 logging_writer.py:48] [368500] global_step=368500, grad_norm=3.1763243675231934, loss=2.2779226303100586
I0304 13:14:45.428860 139758009304832 logging_writer.py:48] [368600] global_step=368600, grad_norm=3.236299514770508, loss=1.7798947095870972
I0304 13:14:56.700564 139953291118400 spec.py:321] Evaluating on the training split.
I0304 13:15:08.211285 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:15:42.381232 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:15:44.003987 139953291118400 submission_runner.py:411] Time since start: 177584.18s, 	Step: 368627, 	{'train/accuracy': 0.8858202695846558, 'train/loss': 0.4272821247577667, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 163882.3846206665, 'total_duration': 177584.1802227497, 'accumulated_submission_time': 163882.3846206665, 'accumulated_eval_time': 13655.980248212814, 'accumulated_logging_time': 27.03390669822693}
I0304 13:15:44.073093 139758026090240 logging_writer.py:48] [368627] accumulated_eval_time=13655.980248, accumulated_logging_time=27.033907, accumulated_submission_time=163882.384621, global_step=368627, preemption_count=0, score=163882.384621, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=177584.180223, train/accuracy=0.885820, train/loss=0.427282, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:16:13.262215 139758009304832 logging_writer.py:48] [368700] global_step=368700, grad_norm=3.1248369216918945, loss=1.0748823881149292
I0304 13:16:57.488618 139758026090240 logging_writer.py:48] [368800] global_step=368800, grad_norm=3.249389410018921, loss=1.2547404766082764
I0304 13:17:42.511814 139758009304832 logging_writer.py:48] [368900] global_step=368900, grad_norm=3.3670222759246826, loss=1.4739669561386108
I0304 13:18:27.757391 139758026090240 logging_writer.py:48] [369000] global_step=369000, grad_norm=3.70145845413208, loss=3.3604705333709717
I0304 13:19:12.931501 139758009304832 logging_writer.py:48] [369100] global_step=369100, grad_norm=3.135786771774292, loss=1.1332621574401855
I0304 13:19:58.061554 139758026090240 logging_writer.py:48] [369200] global_step=369200, grad_norm=2.9714183807373047, loss=1.436920404434204
I0304 13:20:42.908041 139758009304832 logging_writer.py:48] [369300] global_step=369300, grad_norm=2.9910125732421875, loss=1.5739257335662842
I0304 13:21:28.227582 139758026090240 logging_writer.py:48] [369400] global_step=369400, grad_norm=2.976693630218506, loss=1.0212687253952026
I0304 13:22:13.070281 139758009304832 logging_writer.py:48] [369500] global_step=369500, grad_norm=3.166003704071045, loss=1.7425386905670166
I0304 13:22:44.072484 139953291118400 spec.py:321] Evaluating on the training split.
I0304 13:22:55.334105 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:23:15.896800 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:23:17.534121 139953291118400 submission_runner.py:411] Time since start: 178037.71s, 	Step: 369571, 	{'train/accuracy': 0.8865429759025574, 'train/loss': 0.41984260082244873, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 164302.32819080353, 'total_duration': 178037.7103281021, 'accumulated_submission_time': 164302.32819080353, 'accumulated_eval_time': 13689.44184088707, 'accumulated_logging_time': 27.11146354675293}
I0304 13:23:17.619157 139758026090240 logging_writer.py:48] [369571] accumulated_eval_time=13689.441841, accumulated_logging_time=27.111464, accumulated_submission_time=164302.328191, global_step=369571, preemption_count=0, score=164302.328191, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=178037.710328, train/accuracy=0.886543, train/loss=0.419843, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:23:29.477081 139758009304832 logging_writer.py:48] [369600] global_step=369600, grad_norm=3.8725194931030273, loss=3.3698177337646484
I0304 13:24:12.628564 139758026090240 logging_writer.py:48] [369700] global_step=369700, grad_norm=3.0593113899230957, loss=1.2384212017059326
I0304 13:24:57.426268 139758009304832 logging_writer.py:48] [369800] global_step=369800, grad_norm=2.8770792484283447, loss=1.2023367881774902
I0304 13:25:42.543589 139758026090240 logging_writer.py:48] [369900] global_step=369900, grad_norm=2.836787462234497, loss=1.0628480911254883
I0304 13:26:27.903055 139758009304832 logging_writer.py:48] [370000] global_step=370000, grad_norm=3.733393669128418, loss=3.093271255493164
I0304 13:27:12.855451 139758026090240 logging_writer.py:48] [370100] global_step=370100, grad_norm=2.995382308959961, loss=1.4016094207763672
I0304 13:27:57.925036 139758009304832 logging_writer.py:48] [370200] global_step=370200, grad_norm=3.0452001094818115, loss=1.2273757457733154
I0304 13:28:43.132710 139758026090240 logging_writer.py:48] [370300] global_step=370300, grad_norm=2.99399733543396, loss=1.2006759643554688
I0304 13:29:28.294926 139758009304832 logging_writer.py:48] [370400] global_step=370400, grad_norm=2.9588072299957275, loss=1.256151556968689
I0304 13:30:13.242897 139758026090240 logging_writer.py:48] [370500] global_step=370500, grad_norm=2.9914190769195557, loss=1.1501681804656982
I0304 13:30:17.835991 139953291118400 spec.py:321] Evaluating on the training split.
I0304 13:30:29.165874 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:30:53.136558 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:30:54.766944 139953291118400 submission_runner.py:411] Time since start: 178494.94s, 	Step: 370512, 	{'train/accuracy': 0.8881640434265137, 'train/loss': 0.4155753254890442, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 164722.48730134964, 'total_duration': 178494.94316363335, 'accumulated_submission_time': 164722.48730134964, 'accumulated_eval_time': 13726.37277674675, 'accumulated_logging_time': 27.207013607025146}
I0304 13:30:54.853594 139758009304832 logging_writer.py:48] [370512] accumulated_eval_time=13726.372777, accumulated_logging_time=27.207014, accumulated_submission_time=164722.487301, global_step=370512, preemption_count=0, score=164722.487301, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=178494.943164, train/accuracy=0.888164, train/loss=0.415575, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:31:30.931964 139758026090240 logging_writer.py:48] [370600] global_step=370600, grad_norm=3.113879680633545, loss=1.0104355812072754
I0304 13:32:15.734625 139758009304832 logging_writer.py:48] [370700] global_step=370700, grad_norm=2.8905746936798096, loss=1.1329764127731323
I0304 13:33:00.723190 139758026090240 logging_writer.py:48] [370800] global_step=370800, grad_norm=2.984297037124634, loss=1.8482955694198608
I0304 13:33:45.821722 139758009304832 logging_writer.py:48] [370900] global_step=370900, grad_norm=2.9494755268096924, loss=1.2835650444030762
I0304 13:34:30.706720 139758026090240 logging_writer.py:48] [371000] global_step=371000, grad_norm=3.1489944458007812, loss=1.1121900081634521
I0304 13:35:15.778194 139758009304832 logging_writer.py:48] [371100] global_step=371100, grad_norm=2.955929756164551, loss=1.1349414587020874
I0304 13:36:00.567963 139758026090240 logging_writer.py:48] [371200] global_step=371200, grad_norm=2.9777004718780518, loss=1.16048264503479
I0304 13:36:45.689283 139758009304832 logging_writer.py:48] [371300] global_step=371300, grad_norm=3.202834129333496, loss=1.1101717948913574
I0304 13:37:30.965150 139758026090240 logging_writer.py:48] [371400] global_step=371400, grad_norm=2.969285011291504, loss=1.19686758518219
I0304 13:37:54.917705 139953291118400 spec.py:321] Evaluating on the training split.
I0304 13:38:06.112309 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:38:33.839152 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:38:35.487696 139953291118400 submission_runner.py:411] Time since start: 178955.66s, 	Step: 371455, 	{'train/accuracy': 0.88916015625, 'train/loss': 0.41313526034355164, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 165142.49481630325, 'total_duration': 178955.66393136978, 'accumulated_submission_time': 165142.49481630325, 'accumulated_eval_time': 13766.942764282227, 'accumulated_logging_time': 27.30364155769348}
I0304 13:38:35.557420 139758009304832 logging_writer.py:48] [371455] accumulated_eval_time=13766.942764, accumulated_logging_time=27.303642, accumulated_submission_time=165142.494816, global_step=371455, preemption_count=0, score=165142.494816, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=178955.663931, train/accuracy=0.889160, train/loss=0.413135, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:38:53.725902 139758026090240 logging_writer.py:48] [371500] global_step=371500, grad_norm=3.129248857498169, loss=1.4944026470184326
I0304 13:39:35.843420 139758009304832 logging_writer.py:48] [371600] global_step=371600, grad_norm=2.909327268600464, loss=1.2883191108703613
I0304 13:40:20.875197 139758026090240 logging_writer.py:48] [371700] global_step=371700, grad_norm=2.99054217338562, loss=1.0802226066589355
I0304 13:41:06.088493 139758009304832 logging_writer.py:48] [371800] global_step=371800, grad_norm=3.0463223457336426, loss=1.0962146520614624
I0304 13:41:50.979664 139758026090240 logging_writer.py:48] [371900] global_step=371900, grad_norm=2.9888439178466797, loss=1.0877989530563354
I0304 13:42:36.048870 139758009304832 logging_writer.py:48] [372000] global_step=372000, grad_norm=3.686842441558838, loss=2.18593692779541
I0304 13:43:20.955136 139758026090240 logging_writer.py:48] [372100] global_step=372100, grad_norm=3.2251343727111816, loss=1.240814208984375
I0304 13:44:05.787604 139758009304832 logging_writer.py:48] [372200] global_step=372200, grad_norm=2.9848711490631104, loss=1.018302083015442
I0304 13:44:50.722803 139758026090240 logging_writer.py:48] [372300] global_step=372300, grad_norm=3.6592302322387695, loss=3.304814100265503
I0304 13:45:35.744276 139758009304832 logging_writer.py:48] [372400] global_step=372400, grad_norm=2.854252576828003, loss=1.078385591506958
I0304 13:45:35.757550 139953291118400 spec.py:321] Evaluating on the training split.
I0304 13:45:46.881022 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:46:07.911804 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:46:09.547040 139953291118400 submission_runner.py:411] Time since start: 179409.72s, 	Step: 372401, 	{'train/accuracy': 0.88525390625, 'train/loss': 0.42474669218063354, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 165562.63774585724, 'total_duration': 179409.72325754166, 'accumulated_submission_time': 165562.63774585724, 'accumulated_eval_time': 13800.732230424881, 'accumulated_logging_time': 27.383100271224976}
I0304 13:46:09.636802 139758026090240 logging_writer.py:48] [372401] accumulated_eval_time=13800.732230, accumulated_logging_time=27.383100, accumulated_submission_time=165562.637746, global_step=372401, preemption_count=0, score=165562.637746, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=179409.723258, train/accuracy=0.885254, train/loss=0.424747, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:46:50.823221 139758009304832 logging_writer.py:48] [372500] global_step=372500, grad_norm=3.2896203994750977, loss=2.819934368133545
I0304 13:47:36.161686 139758026090240 logging_writer.py:48] [372600] global_step=372600, grad_norm=3.076667308807373, loss=1.0620514154434204
I0304 13:48:20.984179 139758009304832 logging_writer.py:48] [372700] global_step=372700, grad_norm=3.2396867275238037, loss=2.306148052215576
I0304 13:49:05.948492 139758026090240 logging_writer.py:48] [372800] global_step=372800, grad_norm=3.29913330078125, loss=2.324648380279541
I0304 13:49:51.241399 139758009304832 logging_writer.py:48] [372900] global_step=372900, grad_norm=3.220977306365967, loss=2.773637056350708
I0304 13:50:36.302169 139758026090240 logging_writer.py:48] [373000] global_step=373000, grad_norm=3.1030726432800293, loss=1.1835094690322876
I0304 13:51:21.599347 139758009304832 logging_writer.py:48] [373100] global_step=373100, grad_norm=3.4562454223632812, loss=2.7823526859283447
I0304 13:52:06.578893 139758026090240 logging_writer.py:48] [373200] global_step=373200, grad_norm=2.8544843196868896, loss=1.457695722579956
I0304 13:52:51.730923 139758009304832 logging_writer.py:48] [373300] global_step=373300, grad_norm=3.4147579669952393, loss=2.946449041366577
I0304 13:53:09.969261 139953291118400 spec.py:321] Evaluating on the training split.
I0304 13:53:21.281826 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 13:53:50.880520 139953291118400 spec.py:349] Evaluating on the test split.
I0304 13:53:52.506704 139953291118400 submission_runner.py:411] Time since start: 179872.68s, 	Step: 373342, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.4191824495792389, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 165982.9108800888, 'total_duration': 179872.6829378605, 'accumulated_submission_time': 165982.9108800888, 'accumulated_eval_time': 13843.269656419754, 'accumulated_logging_time': 27.484456300735474}
I0304 13:53:52.577896 139758026090240 logging_writer.py:48] [373342] accumulated_eval_time=13843.269656, accumulated_logging_time=27.484456, accumulated_submission_time=165982.910880, global_step=373342, preemption_count=0, score=165982.910880, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=179872.682938, train/accuracy=0.888438, train/loss=0.419182, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 13:54:15.873311 139758009304832 logging_writer.py:48] [373400] global_step=373400, grad_norm=4.100619316101074, loss=2.30338191986084
I0304 13:54:58.909203 139758026090240 logging_writer.py:48] [373500] global_step=373500, grad_norm=3.094498872756958, loss=1.160101056098938
I0304 13:55:44.345906 139758009304832 logging_writer.py:48] [373600] global_step=373600, grad_norm=3.536789655685425, loss=2.9806737899780273
I0304 13:56:29.686116 139758026090240 logging_writer.py:48] [373700] global_step=373700, grad_norm=2.9607200622558594, loss=1.1508843898773193
I0304 13:57:14.658940 139758009304832 logging_writer.py:48] [373800] global_step=373800, grad_norm=3.4221019744873047, loss=1.0898557901382446
I0304 13:57:59.371283 139758026090240 logging_writer.py:48] [373900] global_step=373900, grad_norm=2.8375377655029297, loss=1.9702808856964111
I0304 13:58:44.314397 139758009304832 logging_writer.py:48] [374000] global_step=374000, grad_norm=2.9580631256103516, loss=1.0486841201782227
I0304 13:59:29.476112 139758026090240 logging_writer.py:48] [374100] global_step=374100, grad_norm=3.109761953353882, loss=1.094686508178711
I0304 14:00:14.334837 139758009304832 logging_writer.py:48] [374200] global_step=374200, grad_norm=3.3412797451019287, loss=1.9620791673660278
I0304 14:00:52.741199 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:01:03.854011 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:01:33.920295 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:01:35.540146 139953291118400 submission_runner.py:411] Time since start: 180335.72s, 	Step: 374287, 	{'train/accuracy': 0.8906054496765137, 'train/loss': 0.41553640365600586, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 166403.01735568047, 'total_duration': 180335.7163796425, 'accumulated_submission_time': 166403.01735568047, 'accumulated_eval_time': 13886.068606615067, 'accumulated_logging_time': 27.56479525566101}
I0304 14:01:35.610337 139758026090240 logging_writer.py:48] [374287] accumulated_eval_time=13886.068607, accumulated_logging_time=27.564795, accumulated_submission_time=166403.017356, global_step=374287, preemption_count=0, score=166403.017356, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=180335.716380, train/accuracy=0.890605, train/loss=0.415536, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:01:41.390438 139758009304832 logging_writer.py:48] [374300] global_step=374300, grad_norm=3.063516139984131, loss=1.427903652191162
I0304 14:02:21.997199 139758026090240 logging_writer.py:48] [374400] global_step=374400, grad_norm=3.1595468521118164, loss=2.737776756286621
I0304 14:03:06.795622 139758009304832 logging_writer.py:48] [374500] global_step=374500, grad_norm=3.002328634262085, loss=1.1208200454711914
I0304 14:03:52.041732 139758026090240 logging_writer.py:48] [374600] global_step=374600, grad_norm=3.583522081375122, loss=3.081909656524658
I0304 14:04:37.416982 139758009304832 logging_writer.py:48] [374700] global_step=374700, grad_norm=4.862329483032227, loss=3.312084913253784
I0304 14:05:22.463225 139758026090240 logging_writer.py:48] [374800] global_step=374800, grad_norm=3.237565040588379, loss=1.0884928703308105
I0304 14:06:07.638910 139758009304832 logging_writer.py:48] [374900] global_step=374900, grad_norm=2.895890235900879, loss=1.305348515510559
I0304 14:06:52.997664 139758026090240 logging_writer.py:48] [375000] global_step=375000, grad_norm=3.1067912578582764, loss=2.1209001541137695
I0304 14:07:38.244480 139758009304832 logging_writer.py:48] [375100] global_step=375100, grad_norm=3.0897293090820312, loss=2.3682680130004883
I0304 14:08:22.964853 139758026090240 logging_writer.py:48] [375200] global_step=375200, grad_norm=3.070175886154175, loss=1.908808708190918
I0304 14:08:35.714675 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:08:47.234236 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:09:05.874510 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:09:07.512747 139953291118400 submission_runner.py:411] Time since start: 180787.69s, 	Step: 375230, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.4109485149383545, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 166822.80471730232, 'total_duration': 180787.6889693737, 'accumulated_submission_time': 166822.80471730232, 'accumulated_eval_time': 13917.866647958755, 'accumulated_logging_time': 27.90357255935669}
I0304 14:09:07.601993 139758009304832 logging_writer.py:48] [375230] accumulated_eval_time=13917.866648, accumulated_logging_time=27.903573, accumulated_submission_time=166822.804717, global_step=375230, preemption_count=0, score=166822.804717, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=180787.688969, train/accuracy=0.888730, train/loss=0.410949, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:09:35.971810 139758026090240 logging_writer.py:48] [375300] global_step=375300, grad_norm=2.8964691162109375, loss=1.087158441543579
I0304 14:10:21.052060 139758009304832 logging_writer.py:48] [375400] global_step=375400, grad_norm=3.1422646045684814, loss=1.158745288848877
I0304 14:11:05.853645 139758026090240 logging_writer.py:48] [375500] global_step=375500, grad_norm=3.218545913696289, loss=1.246948480606079
I0304 14:11:50.985394 139758009304832 logging_writer.py:48] [375600] global_step=375600, grad_norm=3.6462206840515137, loss=3.0214953422546387
I0304 14:12:36.102097 139758026090240 logging_writer.py:48] [375700] global_step=375700, grad_norm=3.3159773349761963, loss=2.811206579208374
I0304 14:13:20.895888 139758009304832 logging_writer.py:48] [375800] global_step=375800, grad_norm=3.1756174564361572, loss=1.839339256286621
I0304 14:14:06.004872 139758026090240 logging_writer.py:48] [375900] global_step=375900, grad_norm=3.02026104927063, loss=1.8945837020874023
I0304 14:14:50.964149 139758009304832 logging_writer.py:48] [376000] global_step=376000, grad_norm=3.0881094932556152, loss=1.0924310684204102
I0304 14:15:36.193284 139758026090240 logging_writer.py:48] [376100] global_step=376100, grad_norm=3.0915687084198, loss=1.1717814207077026
I0304 14:16:07.878003 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:16:19.454398 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:16:51.220200 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:16:52.855401 139953291118400 submission_runner.py:411] Time since start: 181253.03s, 	Step: 376172, 	{'train/accuracy': 0.88587886095047, 'train/loss': 0.42292648553848267, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 167243.02319812775, 'total_duration': 181253.0316066742, 'accumulated_submission_time': 167243.02319812775, 'accumulated_eval_time': 13962.844014406204, 'accumulated_logging_time': 28.00294804573059}
I0304 14:16:52.944194 139758009304832 logging_writer.py:48] [376172] accumulated_eval_time=13962.844014, accumulated_logging_time=28.002948, accumulated_submission_time=167243.023198, global_step=376172, preemption_count=0, score=167243.023198, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=181253.031607, train/accuracy=0.885879, train/loss=0.422926, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:17:04.420271 139758026090240 logging_writer.py:48] [376200] global_step=376200, grad_norm=3.1157066822052, loss=1.0902868509292603
I0304 14:17:45.985760 139758009304832 logging_writer.py:48] [376300] global_step=376300, grad_norm=3.3427374362945557, loss=2.6653175354003906
I0304 14:18:30.982044 139758026090240 logging_writer.py:48] [376400] global_step=376400, grad_norm=3.158385753631592, loss=1.1481199264526367
I0304 14:19:15.871858 139758009304832 logging_writer.py:48] [376500] global_step=376500, grad_norm=3.0196073055267334, loss=2.0347352027893066
I0304 14:20:00.830774 139758026090240 logging_writer.py:48] [376600] global_step=376600, grad_norm=3.374755859375, loss=1.848757028579712
I0304 14:20:45.658710 139758009304832 logging_writer.py:48] [376700] global_step=376700, grad_norm=3.184107780456543, loss=1.1562594175338745
I0304 14:21:30.664162 139758026090240 logging_writer.py:48] [376800] global_step=376800, grad_norm=2.8806185722351074, loss=1.289335012435913
I0304 14:22:15.657281 139758009304832 logging_writer.py:48] [376900] global_step=376900, grad_norm=3.387115001678467, loss=1.2053228616714478
I0304 14:23:00.416242 139758026090240 logging_writer.py:48] [377000] global_step=377000, grad_norm=3.013817310333252, loss=2.6532981395721436
I0304 14:23:45.238344 139758009304832 logging_writer.py:48] [377100] global_step=377100, grad_norm=3.140357494354248, loss=1.0944361686706543
I0304 14:23:52.989281 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:24:04.899792 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:24:35.624236 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:24:37.252142 139953291118400 submission_runner.py:411] Time since start: 181717.43s, 	Step: 377119, 	{'train/accuracy': 0.8873242139816284, 'train/loss': 0.4139610826969147, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 167663.00806236267, 'total_duration': 181717.42837500572, 'accumulated_submission_time': 167663.00806236267, 'accumulated_eval_time': 14007.10686326027, 'accumulated_logging_time': 28.104105710983276}
I0304 14:24:37.323490 139758026090240 logging_writer.py:48] [377119] accumulated_eval_time=14007.106863, accumulated_logging_time=28.104106, accumulated_submission_time=167663.008062, global_step=377119, preemption_count=0, score=167663.008062, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=181717.428375, train/accuracy=0.887324, train/loss=0.413961, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:25:09.706485 139758009304832 logging_writer.py:48] [377200] global_step=377200, grad_norm=3.6515302658081055, loss=2.8776917457580566
I0304 14:25:53.733742 139758026090240 logging_writer.py:48] [377300] global_step=377300, grad_norm=3.4545319080352783, loss=1.182381510734558
I0304 14:26:39.147396 139758009304832 logging_writer.py:48] [377400] global_step=377400, grad_norm=3.025954246520996, loss=1.2582414150238037
I0304 14:27:24.279844 139758026090240 logging_writer.py:48] [377500] global_step=377500, grad_norm=3.174276113510132, loss=2.627890110015869
I0304 14:28:09.703497 139758009304832 logging_writer.py:48] [377600] global_step=377600, grad_norm=2.9083447456359863, loss=2.19032883644104
I0304 14:28:54.384161 139758026090240 logging_writer.py:48] [377700] global_step=377700, grad_norm=2.8884425163269043, loss=1.9546360969543457
I0304 14:29:39.543140 139758009304832 logging_writer.py:48] [377800] global_step=377800, grad_norm=3.0234320163726807, loss=1.3965561389923096
I0304 14:30:24.832208 139758026090240 logging_writer.py:48] [377900] global_step=377900, grad_norm=3.1099328994750977, loss=1.1428043842315674
I0304 14:31:09.811602 139758009304832 logging_writer.py:48] [378000] global_step=378000, grad_norm=4.0137505531311035, loss=3.100094795227051
I0304 14:31:37.324138 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:31:48.959499 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:32:09.552712 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:32:11.185707 139953291118400 submission_runner.py:411] Time since start: 182171.36s, 	Step: 378063, 	{'train/accuracy': 0.8871679306030273, 'train/loss': 0.41757646203041077, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 168082.953353405, 'total_duration': 182171.36193203926, 'accumulated_submission_time': 168082.953353405, 'accumulated_eval_time': 14040.968413114548, 'accumulated_logging_time': 28.18370485305786}
I0304 14:32:11.275368 139758026090240 logging_writer.py:48] [378063] accumulated_eval_time=14040.968413, accumulated_logging_time=28.183705, accumulated_submission_time=168082.953353, global_step=378063, preemption_count=0, score=168082.953353, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=182171.361932, train/accuracy=0.887168, train/loss=0.417576, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:32:26.292147 139758009304832 logging_writer.py:48] [378100] global_step=378100, grad_norm=3.093407392501831, loss=1.3117181062698364
I0304 14:33:09.961430 139758026090240 logging_writer.py:48] [378200] global_step=378200, grad_norm=4.159212112426758, loss=3.059535026550293
I0304 14:33:54.977608 139758009304832 logging_writer.py:48] [378300] global_step=378300, grad_norm=3.122011661529541, loss=1.7355852127075195
I0304 14:34:40.286828 139758026090240 logging_writer.py:48] [378400] global_step=378400, grad_norm=3.1554417610168457, loss=1.6355894804000854
I0304 14:35:25.506328 139758009304832 logging_writer.py:48] [378500] global_step=378500, grad_norm=2.9214541912078857, loss=1.094475507736206
I0304 14:36:11.021064 139758026090240 logging_writer.py:48] [378600] global_step=378600, grad_norm=3.8333590030670166, loss=3.2755041122436523
I0304 14:36:56.152245 139758009304832 logging_writer.py:48] [378700] global_step=378700, grad_norm=3.8613603115081787, loss=3.257718563079834
I0304 14:37:41.586871 139758026090240 logging_writer.py:48] [378800] global_step=378800, grad_norm=3.7756621837615967, loss=1.0730695724487305
I0304 14:38:26.802820 139758009304832 logging_writer.py:48] [378900] global_step=378900, grad_norm=3.1147356033325195, loss=1.1403931379318237
I0304 14:39:11.284632 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:39:22.751168 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:39:46.055287 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:39:47.685717 139953291118400 submission_runner.py:411] Time since start: 182627.86s, 	Step: 379000, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.4216572046279907, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 168502.90359401703, 'total_duration': 182627.8619401455, 'accumulated_submission_time': 168502.90359401703, 'accumulated_eval_time': 14077.369477033615, 'accumulated_logging_time': 28.28520369529724}
I0304 14:39:47.775153 139758026090240 logging_writer.py:48] [379000] accumulated_eval_time=14077.369477, accumulated_logging_time=28.285204, accumulated_submission_time=168502.903594, global_step=379000, preemption_count=0, score=168502.903594, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=182627.861940, train/accuracy=0.886738, train/loss=0.421657, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:39:48.194772 139758009304832 logging_writer.py:48] [379000] global_step=379000, grad_norm=3.203038215637207, loss=2.251232147216797
I0304 14:40:29.487167 139758026090240 logging_writer.py:48] [379100] global_step=379100, grad_norm=2.9336185455322266, loss=1.3342283964157104
I0304 14:41:14.523208 139758009304832 logging_writer.py:48] [379200] global_step=379200, grad_norm=3.0623021125793457, loss=1.1058375835418701
I0304 14:41:59.629769 139758026090240 logging_writer.py:48] [379300] global_step=379300, grad_norm=2.9867382049560547, loss=1.1006897687911987
I0304 14:42:45.377290 139758009304832 logging_writer.py:48] [379400] global_step=379400, grad_norm=3.0924923419952393, loss=1.8964617252349854
I0304 14:43:30.435374 139758026090240 logging_writer.py:48] [379500] global_step=379500, grad_norm=3.228983163833618, loss=1.7084219455718994
I0304 14:44:15.566797 139758009304832 logging_writer.py:48] [379600] global_step=379600, grad_norm=3.0277276039123535, loss=1.0599743127822876
I0304 14:45:00.535391 139758026090240 logging_writer.py:48] [379700] global_step=379700, grad_norm=3.0317938327789307, loss=1.1033629179000854
I0304 14:45:45.498712 139758009304832 logging_writer.py:48] [379800] global_step=379800, grad_norm=3.1452431678771973, loss=1.1392682790756226
I0304 14:46:30.626758 139758026090240 logging_writer.py:48] [379900] global_step=379900, grad_norm=3.024235725402832, loss=1.1968964338302612
I0304 14:46:48.100554 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:46:59.035527 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:47:33.587851 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:47:35.216305 139953291118400 submission_runner.py:411] Time since start: 183095.39s, 	Step: 379940, 	{'train/accuracy': 0.8876171708106995, 'train/loss': 0.4176125228404999, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 168923.17162704468, 'total_duration': 183095.3925318718, 'accumulated_submission_time': 168923.17162704468, 'accumulated_eval_time': 14124.485233306885, 'accumulated_logging_time': 28.38457489013672}
I0304 14:47:35.292949 139758009304832 logging_writer.py:48] [379940] accumulated_eval_time=14124.485233, accumulated_logging_time=28.384575, accumulated_submission_time=168923.171627, global_step=379940, preemption_count=0, score=168923.171627, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=183095.392532, train/accuracy=0.887617, train/loss=0.417613, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:47:59.381810 139758026090240 logging_writer.py:48] [380000] global_step=380000, grad_norm=3.029076099395752, loss=1.1080130338668823
I0304 14:48:42.261176 139758009304832 logging_writer.py:48] [380100] global_step=380100, grad_norm=3.0558152198791504, loss=1.2874444723129272
I0304 14:49:27.275451 139758026090240 logging_writer.py:48] [380200] global_step=380200, grad_norm=3.0549495220184326, loss=2.7422966957092285
I0304 14:50:12.977343 139758009304832 logging_writer.py:48] [380300] global_step=380300, grad_norm=3.258122444152832, loss=2.8796679973602295
I0304 14:50:58.152757 139758026090240 logging_writer.py:48] [380400] global_step=380400, grad_norm=2.9693338871002197, loss=1.0732992887496948
I0304 14:51:43.089819 139758009304832 logging_writer.py:48] [380500] global_step=380500, grad_norm=2.8919641971588135, loss=2.1992855072021484
I0304 14:52:28.108396 139758026090240 logging_writer.py:48] [380600] global_step=380600, grad_norm=3.0784616470336914, loss=1.1987128257751465
I0304 14:53:13.043546 139758009304832 logging_writer.py:48] [380700] global_step=380700, grad_norm=3.355278491973877, loss=2.1901967525482178
I0304 14:53:57.970301 139758026090240 logging_writer.py:48] [380800] global_step=380800, grad_norm=2.949791431427002, loss=1.1199933290481567
I0304 14:54:35.586399 139953291118400 spec.py:321] Evaluating on the training split.
I0304 14:54:46.753084 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 14:55:12.627811 139953291118400 spec.py:349] Evaluating on the test split.
I0304 14:55:14.266690 139953291118400 submission_runner.py:411] Time since start: 183554.44s, 	Step: 380885, 	{'train/accuracy': 0.8860155940055847, 'train/loss': 0.42614930868148804, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 169343.40920114517, 'total_duration': 183554.44291687012, 'accumulated_submission_time': 169343.40920114517, 'accumulated_eval_time': 14163.1655189991, 'accumulated_logging_time': 28.470067501068115}
I0304 14:55:14.338707 139758009304832 logging_writer.py:48] [380885] accumulated_eval_time=14163.165519, accumulated_logging_time=28.470068, accumulated_submission_time=169343.409201, global_step=380885, preemption_count=0, score=169343.409201, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=183554.442917, train/accuracy=0.886016, train/loss=0.426149, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 14:55:20.655926 139758026090240 logging_writer.py:48] [380900] global_step=380900, grad_norm=2.9098329544067383, loss=1.9779963493347168
I0304 14:56:01.303808 139758009304832 logging_writer.py:48] [381000] global_step=381000, grad_norm=3.033341884613037, loss=1.026091456413269
I0304 14:56:46.502287 139758026090240 logging_writer.py:48] [381100] global_step=381100, grad_norm=4.268845081329346, loss=3.1278202533721924
I0304 14:57:31.171469 139758009304832 logging_writer.py:48] [381200] global_step=381200, grad_norm=4.246474742889404, loss=2.455085515975952
I0304 14:58:16.605828 139758026090240 logging_writer.py:48] [381300] global_step=381300, grad_norm=3.179054021835327, loss=2.2378108501434326
I0304 14:59:01.295706 139758009304832 logging_writer.py:48] [381400] global_step=381400, grad_norm=3.3367791175842285, loss=1.106972336769104
I0304 14:59:46.245814 139758026090240 logging_writer.py:48] [381500] global_step=381500, grad_norm=2.9522032737731934, loss=1.1777000427246094
I0304 15:00:31.721870 139758009304832 logging_writer.py:48] [381600] global_step=381600, grad_norm=3.5461008548736572, loss=2.959149122238159
I0304 15:01:16.526988 139758026090240 logging_writer.py:48] [381700] global_step=381700, grad_norm=2.972986936569214, loss=1.0468195676803589
I0304 15:02:01.598636 139758009304832 logging_writer.py:48] [381800] global_step=381800, grad_norm=3.2166945934295654, loss=2.062743902206421
I0304 15:02:14.388415 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:02:25.699582 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:02:51.575443 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:02:53.202746 139953291118400 submission_runner.py:411] Time since start: 184013.38s, 	Step: 381830, 	{'train/accuracy': 0.8877539038658142, 'train/loss': 0.41753143072128296, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 169763.40131759644, 'total_duration': 184013.37898135185, 'accumulated_submission_time': 169763.40131759644, 'accumulated_eval_time': 14201.979838609695, 'accumulated_logging_time': 28.55268931388855}
I0304 15:02:53.275295 139758026090240 logging_writer.py:48] [381830] accumulated_eval_time=14201.979839, accumulated_logging_time=28.552689, accumulated_submission_time=169763.401318, global_step=381830, preemption_count=0, score=169763.401318, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=184013.378981, train/accuracy=0.887754, train/loss=0.417531, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:03:21.346018 139758009304832 logging_writer.py:48] [381900] global_step=381900, grad_norm=3.4418628215789795, loss=2.616853952407837
I0304 15:04:05.328993 139758026090240 logging_writer.py:48] [382000] global_step=382000, grad_norm=3.1713976860046387, loss=1.2127410173416138
I0304 15:04:50.507895 139758009304832 logging_writer.py:48] [382100] global_step=382100, grad_norm=2.90118408203125, loss=2.276608943939209
I0304 15:05:35.977604 139758026090240 logging_writer.py:48] [382200] global_step=382200, grad_norm=3.85783052444458, loss=3.3236935138702393
I0304 15:06:21.281954 139758009304832 logging_writer.py:48] [382300] global_step=382300, grad_norm=2.9961435794830322, loss=1.0275671482086182
I0304 15:07:06.258895 139758026090240 logging_writer.py:48] [382400] global_step=382400, grad_norm=3.1298880577087402, loss=2.4692132472991943
I0304 15:07:51.372159 139758009304832 logging_writer.py:48] [382500] global_step=382500, grad_norm=3.453824520111084, loss=3.0486958026885986
I0304 15:08:36.477324 139758026090240 logging_writer.py:48] [382600] global_step=382600, grad_norm=2.8870980739593506, loss=1.931663990020752
I0304 15:09:21.327999 139758009304832 logging_writer.py:48] [382700] global_step=382700, grad_norm=3.25421404838562, loss=1.0688352584838867
I0304 15:09:53.617372 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:10:05.145388 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:10:32.095669 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:10:33.725991 139953291118400 submission_runner.py:411] Time since start: 184473.90s, 	Step: 382773, 	{'train/accuracy': 0.88636714220047, 'train/loss': 0.42174169421195984, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 170183.68056845665, 'total_duration': 184473.9022257328, 'accumulated_submission_time': 170183.68056845665, 'accumulated_eval_time': 14242.088454008102, 'accumulated_logging_time': 28.640817880630493}
I0304 15:10:33.799346 139758026090240 logging_writer.py:48] [382773] accumulated_eval_time=14242.088454, accumulated_logging_time=28.640818, accumulated_submission_time=170183.680568, global_step=382773, preemption_count=0, score=170183.680568, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=184473.902226, train/accuracy=0.886367, train/loss=0.421742, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:10:44.853753 139758009304832 logging_writer.py:48] [382800] global_step=382800, grad_norm=2.976438283920288, loss=1.021091103553772
I0304 15:11:26.592780 139758026090240 logging_writer.py:48] [382900] global_step=382900, grad_norm=3.33093523979187, loss=2.494434356689453
I0304 15:12:11.240323 139758009304832 logging_writer.py:48] [383000] global_step=383000, grad_norm=3.005903482437134, loss=1.1437729597091675
I0304 15:12:56.500333 139758026090240 logging_writer.py:48] [383100] global_step=383100, grad_norm=2.999568223953247, loss=1.1563891172409058
I0304 15:13:41.882350 139758009304832 logging_writer.py:48] [383200] global_step=383200, grad_norm=2.98344087600708, loss=2.0626397132873535
I0304 15:14:26.605217 139758026090240 logging_writer.py:48] [383300] global_step=383300, grad_norm=3.524383783340454, loss=1.3468360900878906
I0304 15:15:11.520325 139758009304832 logging_writer.py:48] [383400] global_step=383400, grad_norm=3.2283124923706055, loss=2.3228893280029297
I0304 15:15:56.521097 139758026090240 logging_writer.py:48] [383500] global_step=383500, grad_norm=3.0648348331451416, loss=1.0788445472717285
I0304 15:16:41.616114 139758009304832 logging_writer.py:48] [383600] global_step=383600, grad_norm=3.3777313232421875, loss=1.2025883197784424
I0304 15:17:26.726813 139758026090240 logging_writer.py:48] [383700] global_step=383700, grad_norm=3.2746078968048096, loss=2.594388246536255
I0304 15:17:33.730724 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:17:45.003936 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:18:10.235646 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:18:11.873362 139953291118400 submission_runner.py:411] Time since start: 184932.05s, 	Step: 383717, 	{'train/accuracy': 0.8875781297683716, 'train/loss': 0.41898149251937866, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 170603.55612325668, 'total_duration': 184932.04956531525, 'accumulated_submission_time': 170603.55612325668, 'accumulated_eval_time': 14280.231041908264, 'accumulated_logging_time': 28.722613096237183}
I0304 15:18:11.959751 139758009304832 logging_writer.py:48] [383717] accumulated_eval_time=14280.231042, accumulated_logging_time=28.722613, accumulated_submission_time=170603.556123, global_step=383717, preemption_count=0, score=170603.556123, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=184932.049565, train/accuracy=0.887578, train/loss=0.418981, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:18:45.714059 139758026090240 logging_writer.py:48] [383800] global_step=383800, grad_norm=3.177447557449341, loss=1.455661416053772
I0304 15:19:30.362478 139758009304832 logging_writer.py:48] [383900] global_step=383900, grad_norm=3.97831654548645, loss=2.7206616401672363
I0304 15:20:15.285033 139758026090240 logging_writer.py:48] [384000] global_step=384000, grad_norm=3.486994743347168, loss=2.30712890625
I0304 15:21:00.550712 139758009304832 logging_writer.py:48] [384100] global_step=384100, grad_norm=4.311052322387695, loss=3.316577434539795
I0304 15:21:46.049884 139758026090240 logging_writer.py:48] [384200] global_step=384200, grad_norm=3.1163723468780518, loss=2.394507884979248
I0304 15:22:31.327028 139758009304832 logging_writer.py:48] [384300] global_step=384300, grad_norm=3.731701135635376, loss=2.9468350410461426
I0304 15:23:16.727228 139758026090240 logging_writer.py:48] [384400] global_step=384400, grad_norm=2.988239288330078, loss=2.1678695678710938
I0304 15:24:01.885902 139758009304832 logging_writer.py:48] [384500] global_step=384500, grad_norm=3.2419915199279785, loss=1.1834906339645386
I0304 15:24:47.068171 139758026090240 logging_writer.py:48] [384600] global_step=384600, grad_norm=3.305642604827881, loss=1.2687126398086548
I0304 15:25:12.110831 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:25:23.394533 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:25:47.920371 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:25:49.556410 139953291118400 submission_runner.py:411] Time since start: 185389.73s, 	Step: 384657, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.4142645299434662, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 171023.6480166912, 'total_duration': 185389.73262786865, 'accumulated_submission_time': 171023.6480166912, 'accumulated_eval_time': 14317.676630496979, 'accumulated_logging_time': 28.820887088775635}
I0304 15:25:49.645934 139758009304832 logging_writer.py:48] [384657] accumulated_eval_time=14317.676630, accumulated_logging_time=28.820887, accumulated_submission_time=171023.648017, global_step=384657, preemption_count=0, score=171023.648017, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=185389.732628, train/accuracy=0.887500, train/loss=0.414265, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:26:07.032029 139758026090240 logging_writer.py:48] [384700] global_step=384700, grad_norm=3.8339004516601562, loss=3.3067867755889893
I0304 15:26:50.625866 139758009304832 logging_writer.py:48] [384800] global_step=384800, grad_norm=3.117511749267578, loss=1.1303279399871826
I0304 15:27:35.625658 139758026090240 logging_writer.py:48] [384900] global_step=384900, grad_norm=2.993492841720581, loss=1.252427339553833
I0304 15:28:21.052207 139758009304832 logging_writer.py:48] [385000] global_step=385000, grad_norm=4.269877910614014, loss=3.2438762187957764
I0304 15:29:06.425088 139758026090240 logging_writer.py:48] [385100] global_step=385100, grad_norm=2.9787936210632324, loss=2.633880138397217
I0304 15:29:51.295784 139758009304832 logging_writer.py:48] [385200] global_step=385200, grad_norm=3.3658645153045654, loss=2.8367083072662354
I0304 15:30:36.280600 139758026090240 logging_writer.py:48] [385300] global_step=385300, grad_norm=3.0133533477783203, loss=1.1552908420562744
I0304 15:31:21.381863 139758009304832 logging_writer.py:48] [385400] global_step=385400, grad_norm=3.1627936363220215, loss=1.2742960453033447
I0304 15:32:06.160324 139758026090240 logging_writer.py:48] [385500] global_step=385500, grad_norm=3.352382183074951, loss=1.199384331703186
I0304 15:32:49.871226 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:33:01.029546 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:33:32.931002 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:33:34.545301 139953291118400 submission_runner.py:411] Time since start: 185854.72s, 	Step: 385599, 	{'train/accuracy': 0.8870898485183716, 'train/loss': 0.4226619601249695, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 171443.81467032433, 'total_duration': 185854.72153401375, 'accumulated_submission_time': 171443.81467032433, 'accumulated_eval_time': 14362.350728034973, 'accumulated_logging_time': 28.92026162147522}
I0304 15:33:34.618069 139758009304832 logging_writer.py:48] [385599] accumulated_eval_time=14362.350728, accumulated_logging_time=28.920262, accumulated_submission_time=171443.814670, global_step=385599, preemption_count=0, score=171443.814670, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=185854.721534, train/accuracy=0.887090, train/loss=0.422662, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:33:35.410742 139758026090240 logging_writer.py:48] [385600] global_step=385600, grad_norm=3.2251358032226562, loss=1.2416934967041016
I0304 15:34:15.535422 139758009304832 logging_writer.py:48] [385700] global_step=385700, grad_norm=2.895393133163452, loss=1.0052473545074463
I0304 15:35:00.118479 139758026090240 logging_writer.py:48] [385800] global_step=385800, grad_norm=3.0873098373413086, loss=1.1923613548278809
I0304 15:35:45.091812 139758009304832 logging_writer.py:48] [385900] global_step=385900, grad_norm=2.886690139770508, loss=1.1771055459976196
I0304 15:36:30.399735 139758026090240 logging_writer.py:48] [386000] global_step=386000, grad_norm=3.6129302978515625, loss=3.2351574897766113
I0304 15:37:15.259528 139758009304832 logging_writer.py:48] [386100] global_step=386100, grad_norm=3.3385865688323975, loss=2.5784807205200195
I0304 15:38:00.272996 139758026090240 logging_writer.py:48] [386200] global_step=386200, grad_norm=2.8705132007598877, loss=1.6906309127807617
I0304 15:38:45.463417 139758009304832 logging_writer.py:48] [386300] global_step=386300, grad_norm=3.9554836750030518, loss=3.212103843688965
I0304 15:39:30.428191 139758026090240 logging_writer.py:48] [386400] global_step=386400, grad_norm=3.2301077842712402, loss=2.365048408508301
I0304 15:40:15.549978 139758009304832 logging_writer.py:48] [386500] global_step=386500, grad_norm=3.3410115242004395, loss=1.2118480205535889
I0304 15:40:34.838310 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:40:45.769345 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:41:05.738980 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:41:07.367534 139953291118400 submission_runner.py:411] Time since start: 186307.54s, 	Step: 386545, 	{'train/accuracy': 0.886035144329071, 'train/loss': 0.42348942160606384, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 171863.97700834274, 'total_duration': 186307.54375863075, 'accumulated_submission_time': 171863.97700834274, 'accumulated_eval_time': 14394.879940986633, 'accumulated_logging_time': 29.00299835205078}
I0304 15:41:07.458922 139758026090240 logging_writer.py:48] [386545] accumulated_eval_time=14394.879941, accumulated_logging_time=29.002998, accumulated_submission_time=171863.977008, global_step=386545, preemption_count=0, score=171863.977008, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=186307.543759, train/accuracy=0.886035, train/loss=0.423489, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:41:29.586942 139758009304832 logging_writer.py:48] [386600] global_step=386600, grad_norm=3.1135661602020264, loss=1.2765675783157349
I0304 15:42:13.400037 139758026090240 logging_writer.py:48] [386700] global_step=386700, grad_norm=3.0529754161834717, loss=1.2197988033294678
I0304 15:42:58.310153 139758009304832 logging_writer.py:48] [386800] global_step=386800, grad_norm=3.3073577880859375, loss=1.2558661699295044
I0304 15:43:43.674896 139758026090240 logging_writer.py:48] [386900] global_step=386900, grad_norm=3.0132064819335938, loss=2.421597719192505
I0304 15:44:28.898355 139758009304832 logging_writer.py:48] [387000] global_step=387000, grad_norm=3.0466058254241943, loss=1.20688796043396
I0304 15:45:13.936263 139758026090240 logging_writer.py:48] [387100] global_step=387100, grad_norm=3.5215392112731934, loss=1.1942713260650635
I0304 15:45:58.796936 139758009304832 logging_writer.py:48] [387200] global_step=387200, grad_norm=3.24328351020813, loss=1.115564227104187
I0304 15:46:43.934615 139758026090240 logging_writer.py:48] [387300] global_step=387300, grad_norm=2.9470224380493164, loss=2.1486825942993164
I0304 15:47:28.986881 139758009304832 logging_writer.py:48] [387400] global_step=387400, grad_norm=2.9985742568969727, loss=1.2987104654312134
I0304 15:48:07.701331 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:48:19.089061 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:48:43.735575 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:48:45.371319 139953291118400 submission_runner.py:411] Time since start: 186765.55s, 	Step: 387487, 	{'train/accuracy': 0.8861913681030273, 'train/loss': 0.4212893843650818, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 172284.1622555256, 'total_duration': 186765.54754209518, 'accumulated_submission_time': 172284.1622555256, 'accumulated_eval_time': 14432.549918174744, 'accumulated_logging_time': 29.103593349456787}
I0304 15:48:45.460093 139758026090240 logging_writer.py:48] [387487] accumulated_eval_time=14432.549918, accumulated_logging_time=29.103593, accumulated_submission_time=172284.162256, global_step=387487, preemption_count=0, score=172284.162256, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=186765.547542, train/accuracy=0.886191, train/loss=0.421289, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:48:51.001037 139758009304832 logging_writer.py:48] [387500] global_step=387500, grad_norm=3.0185728073120117, loss=2.1275668144226074
I0304 15:49:32.226863 139758026090240 logging_writer.py:48] [387600] global_step=387600, grad_norm=2.9149365425109863, loss=1.0610320568084717
I0304 15:50:17.048751 139758009304832 logging_writer.py:48] [387700] global_step=387700, grad_norm=2.7529003620147705, loss=1.963836908340454
I0304 15:51:02.291212 139758026090240 logging_writer.py:48] [387800] global_step=387800, grad_norm=3.1501569747924805, loss=1.12924063205719
I0304 15:51:47.695400 139758009304832 logging_writer.py:48] [387900] global_step=387900, grad_norm=2.779266595840454, loss=1.5750470161437988
I0304 15:52:32.611833 139758026090240 logging_writer.py:48] [388000] global_step=388000, grad_norm=3.237061023712158, loss=1.1189637184143066
I0304 15:53:17.596033 139758009304832 logging_writer.py:48] [388100] global_step=388100, grad_norm=2.9074923992156982, loss=1.121941089630127
I0304 15:54:02.542206 139758026090240 logging_writer.py:48] [388200] global_step=388200, grad_norm=2.9388790130615234, loss=2.0410244464874268
I0304 15:54:47.277026 139758009304832 logging_writer.py:48] [388300] global_step=388300, grad_norm=3.2433061599731445, loss=1.0574249029159546
I0304 15:55:32.245425 139758026090240 logging_writer.py:48] [388400] global_step=388400, grad_norm=3.6082935333251953, loss=1.2133578062057495
I0304 15:55:45.767600 139953291118400 spec.py:321] Evaluating on the training split.
I0304 15:55:56.819983 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 15:56:21.952350 139953291118400 spec.py:349] Evaluating on the test split.
I0304 15:56:23.593211 139953291118400 submission_runner.py:411] Time since start: 187223.77s, 	Step: 388432, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.41491618752479553, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 172704.41179394722, 'total_duration': 187223.76943206787, 'accumulated_submission_time': 172704.41179394722, 'accumulated_eval_time': 14470.37551188469, 'accumulated_logging_time': 29.203126668930054}
I0304 15:56:23.683160 139758009304832 logging_writer.py:48] [388432] accumulated_eval_time=14470.375512, accumulated_logging_time=29.203127, accumulated_submission_time=172704.411794, global_step=388432, preemption_count=0, score=172704.411794, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=187223.769432, train/accuracy=0.887500, train/loss=0.414916, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 15:56:50.968000 139758026090240 logging_writer.py:48] [388500] global_step=388500, grad_norm=2.8950083255767822, loss=2.054363489151001
I0304 15:57:35.204715 139758009304832 logging_writer.py:48] [388600] global_step=388600, grad_norm=3.0408108234405518, loss=1.3048301935195923
I0304 15:58:20.047701 139758026090240 logging_writer.py:48] [388700] global_step=388700, grad_norm=3.157468557357788, loss=1.7301695346832275
I0304 15:59:05.003754 139758009304832 logging_writer.py:48] [388800] global_step=388800, grad_norm=2.934717893600464, loss=1.3023791313171387
I0304 15:59:49.742781 139758026090240 logging_writer.py:48] [388900] global_step=388900, grad_norm=3.3059189319610596, loss=1.3731549978256226
I0304 16:00:34.720131 139758009304832 logging_writer.py:48] [389000] global_step=389000, grad_norm=2.953531265258789, loss=1.054961085319519
I0304 16:01:20.023236 139758026090240 logging_writer.py:48] [389100] global_step=389100, grad_norm=3.6891586780548096, loss=2.949685573577881
I0304 16:02:04.759732 139758009304832 logging_writer.py:48] [389200] global_step=389200, grad_norm=2.9737613201141357, loss=1.0882344245910645
I0304 16:02:49.709303 139758026090240 logging_writer.py:48] [389300] global_step=389300, grad_norm=3.0529162883758545, loss=1.0608456134796143
I0304 16:03:23.677797 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:03:34.856475 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:03:57.210055 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:03:58.843711 139953291118400 submission_runner.py:411] Time since start: 187679.02s, 	Step: 389377, 	{'train/accuracy': 0.8874413967132568, 'train/loss': 0.4166697859764099, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 173124.3463385105, 'total_duration': 187679.0199213028, 'accumulated_submission_time': 173124.3463385105, 'accumulated_eval_time': 14505.541404247284, 'accumulated_logging_time': 29.304492712020874}
I0304 16:03:58.936480 139758009304832 logging_writer.py:48] [389377] accumulated_eval_time=14505.541404, accumulated_logging_time=29.304493, accumulated_submission_time=173124.346339, global_step=389377, preemption_count=0, score=173124.346339, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=187679.019921, train/accuracy=0.887441, train/loss=0.416670, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:04:08.414576 139758026090240 logging_writer.py:48] [389400] global_step=389400, grad_norm=3.9166452884674072, loss=3.1800079345703125
I0304 16:04:50.174759 139758009304832 logging_writer.py:48] [389500] global_step=389500, grad_norm=3.132655143737793, loss=1.1549403667449951
I0304 16:05:35.338507 139758026090240 logging_writer.py:48] [389600] global_step=389600, grad_norm=3.5467512607574463, loss=2.9207072257995605
I0304 16:06:20.485694 139758009304832 logging_writer.py:48] [389700] global_step=389700, grad_norm=2.808116912841797, loss=1.6178476810455322
I0304 16:07:05.559590 139758026090240 logging_writer.py:48] [389800] global_step=389800, grad_norm=3.193114995956421, loss=1.1537550687789917
I0304 16:07:50.161339 139758009304832 logging_writer.py:48] [389900] global_step=389900, grad_norm=9.637663841247559, loss=2.3750767707824707
I0304 16:08:35.196491 139758026090240 logging_writer.py:48] [390000] global_step=390000, grad_norm=3.14990234375, loss=1.23639714717865
I0304 16:09:20.163252 139758009304832 logging_writer.py:48] [390100] global_step=390100, grad_norm=3.038168430328369, loss=1.2059329748153687
I0304 16:10:05.334880 139758026090240 logging_writer.py:48] [390200] global_step=390200, grad_norm=2.9016096591949463, loss=1.0830236673355103
I0304 16:10:50.195777 139758009304832 logging_writer.py:48] [390300] global_step=390300, grad_norm=3.2529876232147217, loss=1.1525875329971313
I0304 16:10:58.857662 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:11:09.931454 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:11:36.979337 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:11:38.612977 139953291118400 submission_runner.py:411] Time since start: 188138.79s, 	Step: 390321, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.4215186536312103, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 173544.2095386982, 'total_duration': 188138.7891843319, 'accumulated_submission_time': 173544.2095386982, 'accumulated_eval_time': 14545.296684980392, 'accumulated_logging_time': 29.407959461212158}
I0304 16:11:38.691206 139758026090240 logging_writer.py:48] [390321] accumulated_eval_time=14545.296685, accumulated_logging_time=29.407959, accumulated_submission_time=173544.209539, global_step=390321, preemption_count=0, score=173544.209539, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=188138.789184, train/accuracy=0.887227, train/loss=0.421519, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:12:10.284375 139758009304832 logging_writer.py:48] [390400] global_step=390400, grad_norm=2.8651692867279053, loss=1.022616982460022
I0304 16:12:54.002733 139758026090240 logging_writer.py:48] [390500] global_step=390500, grad_norm=3.096259832382202, loss=1.2211673259735107
I0304 16:13:38.994186 139758009304832 logging_writer.py:48] [390600] global_step=390600, grad_norm=3.3435325622558594, loss=2.7339940071105957
I0304 16:14:24.268695 139758026090240 logging_writer.py:48] [390700] global_step=390700, grad_norm=3.434796094894409, loss=1.20840585231781
I0304 16:15:09.071286 139758009304832 logging_writer.py:48] [390800] global_step=390800, grad_norm=3.6505374908447266, loss=3.16847825050354
I0304 16:15:54.085467 139758026090240 logging_writer.py:48] [390900] global_step=390900, grad_norm=2.9623687267303467, loss=1.4888405799865723
I0304 16:16:39.345083 139758009304832 logging_writer.py:48] [391000] global_step=391000, grad_norm=3.2106356620788574, loss=1.0704193115234375
I0304 16:17:24.228977 139758026090240 logging_writer.py:48] [391100] global_step=391100, grad_norm=3.0360207557678223, loss=1.4417585134506226
I0304 16:18:09.459545 139758009304832 logging_writer.py:48] [391200] global_step=391200, grad_norm=3.122521162033081, loss=1.8566397428512573
I0304 16:18:38.844678 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:18:49.895305 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:19:11.014280 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:19:12.645976 139953291118400 submission_runner.py:411] Time since start: 188592.82s, 	Step: 391267, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.42420926690101624, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 173964.30621051788, 'total_duration': 188592.82219815254, 'accumulated_submission_time': 173964.30621051788, 'accumulated_eval_time': 14579.097965717316, 'accumulated_logging_time': 29.495544910430908}
I0304 16:19:12.740264 139758026090240 logging_writer.py:48] [391267] accumulated_eval_time=14579.097966, accumulated_logging_time=29.495545, accumulated_submission_time=173964.306211, global_step=391267, preemption_count=0, score=173964.306211, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=188592.822198, train/accuracy=0.888438, train/loss=0.424209, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:19:26.182954 139758009304832 logging_writer.py:48] [391300] global_step=391300, grad_norm=3.010018825531006, loss=1.1245691776275635
I0304 16:20:09.113806 139758026090240 logging_writer.py:48] [391400] global_step=391400, grad_norm=3.078275203704834, loss=1.3101743459701538
I0304 16:20:54.111557 139758009304832 logging_writer.py:48] [391500] global_step=391500, grad_norm=3.9351608753204346, loss=3.155414581298828
I0304 16:21:39.571275 139758026090240 logging_writer.py:48] [391600] global_step=391600, grad_norm=3.22540545463562, loss=1.319322109222412
I0304 16:22:24.998451 139758009304832 logging_writer.py:48] [391700] global_step=391700, grad_norm=3.106388568878174, loss=1.1692038774490356
I0304 16:23:10.108642 139758026090240 logging_writer.py:48] [391800] global_step=391800, grad_norm=3.061197280883789, loss=1.2439967393875122
I0304 16:23:54.702307 139758009304832 logging_writer.py:48] [391900] global_step=391900, grad_norm=3.0824854373931885, loss=1.0690072774887085
I0304 16:24:39.623871 139758026090240 logging_writer.py:48] [392000] global_step=392000, grad_norm=3.2154033184051514, loss=1.1456199884414673
I0304 16:25:24.606213 139758009304832 logging_writer.py:48] [392100] global_step=392100, grad_norm=3.105633497238159, loss=1.1273112297058105
I0304 16:26:10.303972 139758026090240 logging_writer.py:48] [392200] global_step=392200, grad_norm=3.233877420425415, loss=1.1361300945281982
I0304 16:26:12.816590 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:26:24.157590 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:26:50.148128 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:26:51.784602 139953291118400 submission_runner.py:411] Time since start: 189051.96s, 	Step: 392207, 	{'train/accuracy': 0.8878905773162842, 'train/loss': 0.4217130243778229, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 174384.32402396202, 'total_duration': 189051.96081399918, 'accumulated_submission_time': 174384.32402396202, 'accumulated_eval_time': 14618.065967798233, 'accumulated_logging_time': 29.601163387298584}
I0304 16:26:51.875394 139758009304832 logging_writer.py:48] [392207] accumulated_eval_time=14618.065968, accumulated_logging_time=29.601163, accumulated_submission_time=174384.324024, global_step=392207, preemption_count=0, score=174384.324024, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=189051.960814, train/accuracy=0.887891, train/loss=0.421713, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:27:29.799766 139758026090240 logging_writer.py:48] [392300] global_step=392300, grad_norm=2.9728639125823975, loss=2.3159122467041016
I0304 16:28:14.458665 139758009304832 logging_writer.py:48] [392400] global_step=392400, grad_norm=2.992812395095825, loss=1.1322813034057617
I0304 16:28:59.622371 139758026090240 logging_writer.py:48] [392500] global_step=392500, grad_norm=2.9718198776245117, loss=2.3645613193511963
I0304 16:29:44.696963 139758009304832 logging_writer.py:48] [392600] global_step=392600, grad_norm=5.4764885902404785, loss=1.7660717964172363
I0304 16:30:29.750885 139758026090240 logging_writer.py:48] [392700] global_step=392700, grad_norm=3.576516628265381, loss=1.5549588203430176
I0304 16:31:14.822140 139758009304832 logging_writer.py:48] [392800] global_step=392800, grad_norm=3.076465129852295, loss=1.7122149467468262
I0304 16:32:00.387279 139758026090240 logging_writer.py:48] [392900] global_step=392900, grad_norm=3.978949546813965, loss=1.201707363128662
I0304 16:32:45.341827 139758009304832 logging_writer.py:48] [393000] global_step=393000, grad_norm=5.005619525909424, loss=3.1535329818725586
I0304 16:33:30.541041 139758026090240 logging_writer.py:48] [393100] global_step=393100, grad_norm=3.476184606552124, loss=1.0920467376708984
I0304 16:33:51.828240 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:34:03.001192 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:34:27.837877 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:34:29.503265 139953291118400 submission_runner.py:411] Time since start: 189509.68s, 	Step: 393149, 	{'train/accuracy': 0.8867577910423279, 'train/loss': 0.4197116792201996, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 174804.2192106247, 'total_duration': 189509.67946982384, 'accumulated_submission_time': 174804.2192106247, 'accumulated_eval_time': 14655.7409658432, 'accumulated_logging_time': 29.702680110931396}
I0304 16:34:29.592738 139758009304832 logging_writer.py:48] [393149] accumulated_eval_time=14655.740966, accumulated_logging_time=29.702680, accumulated_submission_time=174804.219211, global_step=393149, preemption_count=0, score=174804.219211, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=189509.679470, train/accuracy=0.886758, train/loss=0.419712, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:34:50.129371 139758026090240 logging_writer.py:48] [393200] global_step=393200, grad_norm=3.1533706188201904, loss=1.0848793983459473
I0304 16:35:32.379892 139758009304832 logging_writer.py:48] [393300] global_step=393300, grad_norm=3.2560930252075195, loss=1.390434980392456
I0304 16:36:17.861499 139758026090240 logging_writer.py:48] [393400] global_step=393400, grad_norm=3.073840856552124, loss=1.3974542617797852
I0304 16:37:03.322919 139758009304832 logging_writer.py:48] [393500] global_step=393500, grad_norm=3.4699583053588867, loss=2.69364333152771
I0304 16:37:48.385963 139758026090240 logging_writer.py:48] [393600] global_step=393600, grad_norm=3.5017645359039307, loss=1.1931957006454468
I0304 16:38:33.328439 139758009304832 logging_writer.py:48] [393700] global_step=393700, grad_norm=3.1324307918548584, loss=2.0934691429138184
I0304 16:39:18.295707 139758026090240 logging_writer.py:48] [393800] global_step=393800, grad_norm=3.1450564861297607, loss=1.1924303770065308
I0304 16:40:03.373754 139758009304832 logging_writer.py:48] [393900] global_step=393900, grad_norm=3.2377407550811768, loss=1.070081353187561
I0304 16:40:48.185660 139758026090240 logging_writer.py:48] [394000] global_step=394000, grad_norm=3.380190134048462, loss=1.1299164295196533
I0304 16:41:29.536591 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:41:40.694782 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:42:09.753937 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:42:11.389955 139953291118400 submission_runner.py:411] Time since start: 189971.57s, 	Step: 394093, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.416228324174881, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 175224.10652852058, 'total_duration': 189971.56618881226, 'accumulated_submission_time': 175224.10652852058, 'accumulated_eval_time': 14697.594356775284, 'accumulated_logging_time': 29.80150079727173}
I0304 16:42:11.463212 139758009304832 logging_writer.py:48] [394093] accumulated_eval_time=14697.594357, accumulated_logging_time=29.801501, accumulated_submission_time=175224.106529, global_step=394093, preemption_count=0, score=175224.106529, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=189971.566189, train/accuracy=0.887676, train/loss=0.416228, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:42:14.645176 139758026090240 logging_writer.py:48] [394100] global_step=394100, grad_norm=3.794121265411377, loss=3.001976728439331
I0304 16:42:55.089649 139758009304832 logging_writer.py:48] [394200] global_step=394200, grad_norm=3.605496644973755, loss=3.2410128116607666
I0304 16:43:39.877176 139758026090240 logging_writer.py:48] [394300] global_step=394300, grad_norm=3.3270208835601807, loss=2.9493725299835205
I0304 16:44:24.960898 139758009304832 logging_writer.py:48] [394400] global_step=394400, grad_norm=3.0350680351257324, loss=1.4107112884521484
I0304 16:45:10.073224 139758026090240 logging_writer.py:48] [394500] global_step=394500, grad_norm=3.457843065261841, loss=1.225559949874878
I0304 16:45:55.013045 139758009304832 logging_writer.py:48] [394600] global_step=394600, grad_norm=3.105593204498291, loss=1.4891457557678223
I0304 16:46:40.177093 139758026090240 logging_writer.py:48] [394700] global_step=394700, grad_norm=2.984943389892578, loss=1.0374324321746826
I0304 16:47:25.212838 139758009304832 logging_writer.py:48] [394800] global_step=394800, grad_norm=2.9197211265563965, loss=1.1013470888137817
I0304 16:48:10.418960 139758026090240 logging_writer.py:48] [394900] global_step=394900, grad_norm=3.0663461685180664, loss=1.3713252544403076
I0304 16:48:55.257696 139758009304832 logging_writer.py:48] [395000] global_step=395000, grad_norm=3.0507185459136963, loss=1.130161166191101
I0304 16:49:11.743412 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:49:23.211190 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:49:48.736939 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:49:50.360614 139953291118400 submission_runner.py:411] Time since start: 190430.54s, 	Step: 395038, 	{'train/accuracy': 0.8874413967132568, 'train/loss': 0.41833654046058655, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 175644.32959270477, 'total_duration': 190430.5368359089, 'accumulated_submission_time': 175644.32959270477, 'accumulated_eval_time': 14736.211544752121, 'accumulated_logging_time': 29.8844575881958}
I0304 16:49:50.452762 139758026090240 logging_writer.py:48] [395038] accumulated_eval_time=14736.211545, accumulated_logging_time=29.884458, accumulated_submission_time=175644.329593, global_step=395038, preemption_count=0, score=175644.329593, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=190430.536836, train/accuracy=0.887441, train/loss=0.418337, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:50:15.335413 139758009304832 logging_writer.py:48] [395100] global_step=395100, grad_norm=2.9464430809020996, loss=1.04243004322052
I0304 16:50:59.242458 139758026090240 logging_writer.py:48] [395200] global_step=395200, grad_norm=3.3473825454711914, loss=1.111016035079956
I0304 16:51:44.179556 139758009304832 logging_writer.py:48] [395300] global_step=395300, grad_norm=3.004075527191162, loss=1.0206351280212402
I0304 16:52:29.826344 139758026090240 logging_writer.py:48] [395400] global_step=395400, grad_norm=3.7501742839813232, loss=2.23881196975708
I0304 16:53:14.831008 139758009304832 logging_writer.py:48] [395500] global_step=395500, grad_norm=3.0187599658966064, loss=1.9010112285614014
I0304 16:54:00.139539 139758026090240 logging_writer.py:48] [395600] global_step=395600, grad_norm=3.0129647254943848, loss=1.1158844232559204
I0304 16:54:44.973898 139758009304832 logging_writer.py:48] [395700] global_step=395700, grad_norm=2.95099139213562, loss=1.461977243423462
I0304 16:55:29.863610 139758026090240 logging_writer.py:48] [395800] global_step=395800, grad_norm=4.1494526863098145, loss=3.1659669876098633
I0304 16:56:14.912042 139758009304832 logging_writer.py:48] [395900] global_step=395900, grad_norm=3.2354187965393066, loss=1.1324042081832886
I0304 16:56:50.630405 139953291118400 spec.py:321] Evaluating on the training split.
I0304 16:57:02.001355 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 16:57:32.002177 139953291118400 spec.py:349] Evaluating on the test split.
I0304 16:57:33.623231 139953291118400 submission_runner.py:411] Time since start: 190893.80s, 	Step: 395981, 	{'train/accuracy': 0.8874804377555847, 'train/loss': 0.4170241057872772, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 176064.4482076168, 'total_duration': 190893.79946780205, 'accumulated_submission_time': 176064.4482076168, 'accumulated_eval_time': 14779.204402923584, 'accumulated_logging_time': 29.988526344299316}
I0304 16:57:33.696324 139758026090240 logging_writer.py:48] [395981] accumulated_eval_time=14779.204403, accumulated_logging_time=29.988526, accumulated_submission_time=176064.448208, global_step=395981, preemption_count=0, score=176064.448208, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=190893.799468, train/accuracy=0.887480, train/loss=0.417024, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 16:57:41.593898 139758009304832 logging_writer.py:48] [396000] global_step=396000, grad_norm=3.530669927597046, loss=1.1617275476455688
I0304 16:58:22.751907 139758026090240 logging_writer.py:48] [396100] global_step=396100, grad_norm=2.8325674533843994, loss=1.1072924137115479
I0304 16:59:07.763858 139758009304832 logging_writer.py:48] [396200] global_step=396200, grad_norm=3.096843719482422, loss=1.093935489654541
I0304 16:59:52.727595 139758026090240 logging_writer.py:48] [396300] global_step=396300, grad_norm=3.529036045074463, loss=2.8936009407043457
I0304 17:00:38.237052 139758009304832 logging_writer.py:48] [396400] global_step=396400, grad_norm=3.1705217361450195, loss=1.1857752799987793
I0304 17:01:23.102343 139758026090240 logging_writer.py:48] [396500] global_step=396500, grad_norm=3.1283786296844482, loss=1.5060299634933472
I0304 17:02:08.405269 139758009304832 logging_writer.py:48] [396600] global_step=396600, grad_norm=3.367872953414917, loss=2.629873514175415
I0304 17:02:53.559564 139758026090240 logging_writer.py:48] [396700] global_step=396700, grad_norm=3.102193832397461, loss=1.1586045026779175
I0304 17:03:38.540069 139758009304832 logging_writer.py:48] [396800] global_step=396800, grad_norm=3.056016206741333, loss=1.1609184741973877
I0304 17:04:23.667545 139758026090240 logging_writer.py:48] [396900] global_step=396900, grad_norm=3.288860559463501, loss=2.8292224407196045
I0304 17:04:33.680599 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:04:44.907288 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:05:10.457251 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:05:12.083778 139953291118400 submission_runner.py:411] Time since start: 191352.26s, 	Step: 396924, 	{'train/accuracy': 0.8891991972923279, 'train/loss': 0.41723695397377014, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 176484.37260246277, 'total_duration': 191352.2600080967, 'accumulated_submission_time': 176484.37260246277, 'accumulated_eval_time': 14817.607572078705, 'accumulated_logging_time': 30.07315492630005}
I0304 17:05:12.157463 139758009304832 logging_writer.py:48] [396924] accumulated_eval_time=14817.607572, accumulated_logging_time=30.073155, accumulated_submission_time=176484.372602, global_step=396924, preemption_count=0, score=176484.372602, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=191352.260008, train/accuracy=0.889199, train/loss=0.417237, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:05:42.567529 139758026090240 logging_writer.py:48] [397000] global_step=397000, grad_norm=3.018893241882324, loss=1.1234362125396729
I0304 17:06:26.601589 139758009304832 logging_writer.py:48] [397100] global_step=397100, grad_norm=3.2105724811553955, loss=1.0257503986358643
I0304 17:07:11.495096 139758026090240 logging_writer.py:48] [397200] global_step=397200, grad_norm=3.909130334854126, loss=3.26224684715271
I0304 17:07:56.683434 139758009304832 logging_writer.py:48] [397300] global_step=397300, grad_norm=3.0053982734680176, loss=1.0820549726486206
I0304 17:08:41.771911 139758026090240 logging_writer.py:48] [397400] global_step=397400, grad_norm=2.9023547172546387, loss=1.9640839099884033
I0304 17:09:26.544696 139758009304832 logging_writer.py:48] [397500] global_step=397500, grad_norm=2.8139445781707764, loss=1.098595380783081
I0304 17:10:11.736672 139758026090240 logging_writer.py:48] [397600] global_step=397600, grad_norm=3.1556475162506104, loss=1.0506970882415771
I0304 17:10:56.500425 139758009304832 logging_writer.py:48] [397700] global_step=397700, grad_norm=2.6683762073516846, loss=1.6356146335601807
I0304 17:11:41.378818 139758026090240 logging_writer.py:48] [397800] global_step=397800, grad_norm=2.9228017330169678, loss=1.180582880973816
I0304 17:12:12.397261 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:12:23.690711 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:12:46.583807 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:12:48.219358 139953291118400 submission_runner.py:411] Time since start: 191808.40s, 	Step: 397870, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.42179781198501587, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 176904.55462956429, 'total_duration': 191808.3955821991, 'accumulated_submission_time': 176904.55462956429, 'accumulated_eval_time': 14853.429702758789, 'accumulated_logging_time': 30.155625104904175}
I0304 17:12:48.310443 139758009304832 logging_writer.py:48] [397870] accumulated_eval_time=14853.429703, accumulated_logging_time=30.155625, accumulated_submission_time=176904.554630, global_step=397870, preemption_count=0, score=176904.554630, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=191808.395582, train/accuracy=0.887227, train/loss=0.421798, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:13:00.560420 139758026090240 logging_writer.py:48] [397900] global_step=397900, grad_norm=3.093334674835205, loss=1.5081615447998047
I0304 17:13:43.095023 139758009304832 logging_writer.py:48] [398000] global_step=398000, grad_norm=3.2277169227600098, loss=2.7156357765197754
I0304 17:14:27.918767 139758026090240 logging_writer.py:48] [398100] global_step=398100, grad_norm=3.204127788543701, loss=2.16925048828125
I0304 17:15:12.852550 139758009304832 logging_writer.py:48] [398200] global_step=398200, grad_norm=4.076113700866699, loss=3.132734775543213
I0304 17:15:57.964767 139758026090240 logging_writer.py:48] [398300] global_step=398300, grad_norm=3.1573171615600586, loss=1.217217206954956
I0304 17:16:42.983643 139758009304832 logging_writer.py:48] [398400] global_step=398400, grad_norm=3.043055295944214, loss=1.2065588235855103
I0304 17:17:28.228343 139758026090240 logging_writer.py:48] [398500] global_step=398500, grad_norm=3.106079578399658, loss=1.5912784337997437
I0304 17:18:13.548209 139758009304832 logging_writer.py:48] [398600] global_step=398600, grad_norm=3.551835536956787, loss=2.9266836643218994
I0304 17:18:58.373207 139758026090240 logging_writer.py:48] [398700] global_step=398700, grad_norm=2.941296339035034, loss=1.7006657123565674
I0304 17:19:43.104397 139758009304832 logging_writer.py:48] [398800] global_step=398800, grad_norm=3.251749038696289, loss=1.2229301929473877
I0304 17:19:48.695425 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:20:00.015128 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:20:22.220055 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:20:23.858028 139953291118400 submission_runner.py:411] Time since start: 192264.03s, 	Step: 398814, 	{'train/accuracy': 0.8900976181030273, 'train/loss': 0.4069123864173889, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 177324.88240146637, 'total_duration': 192264.03425312042, 'accumulated_submission_time': 177324.88240146637, 'accumulated_eval_time': 14888.592317581177, 'accumulated_logging_time': 30.25603485107422}
I0304 17:20:23.948467 139758026090240 logging_writer.py:48] [398814] accumulated_eval_time=14888.592318, accumulated_logging_time=30.256035, accumulated_submission_time=177324.882401, global_step=398814, preemption_count=0, score=177324.882401, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=192264.034253, train/accuracy=0.890098, train/loss=0.406912, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:20:59.349944 139758009304832 logging_writer.py:48] [398900] global_step=398900, grad_norm=3.907845973968506, loss=3.164788007736206
I0304 17:21:44.268356 139758026090240 logging_writer.py:48] [399000] global_step=399000, grad_norm=3.054185390472412, loss=1.2726517915725708
I0304 17:22:29.482212 139758009304832 logging_writer.py:48] [399100] global_step=399100, grad_norm=2.9541821479797363, loss=1.0724375247955322
I0304 17:23:15.346262 139758026090240 logging_writer.py:48] [399200] global_step=399200, grad_norm=2.9009814262390137, loss=1.791668176651001
I0304 17:24:00.563117 139758009304832 logging_writer.py:48] [399300] global_step=399300, grad_norm=3.1247546672821045, loss=2.7153923511505127
I0304 17:24:45.584068 139758026090240 logging_writer.py:48] [399400] global_step=399400, grad_norm=3.350607395172119, loss=1.225447416305542
I0304 17:25:31.008535 139758009304832 logging_writer.py:48] [399500] global_step=399500, grad_norm=2.9300310611724854, loss=1.5034888982772827
I0304 17:26:16.443356 139758026090240 logging_writer.py:48] [399600] global_step=399600, grad_norm=3.0110206604003906, loss=1.1609019041061401
I0304 17:27:01.637723 139758009304832 logging_writer.py:48] [399700] global_step=399700, grad_norm=3.2862069606781006, loss=2.8334550857543945
I0304 17:27:24.128158 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:27:35.086949 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:28:00.845758 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:28:02.472323 139953291118400 submission_runner.py:411] Time since start: 192722.65s, 	Step: 399751, 	{'train/accuracy': 0.8873632550239563, 'train/loss': 0.41892704367637634, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 177745.00523638725, 'total_duration': 192722.6485464573, 'accumulated_submission_time': 177745.00523638725, 'accumulated_eval_time': 14926.936472415924, 'accumulated_logging_time': 30.356215715408325}
I0304 17:28:02.574408 139758026090240 logging_writer.py:48] [399751] accumulated_eval_time=14926.936472, accumulated_logging_time=30.356216, accumulated_submission_time=177745.005236, global_step=399751, preemption_count=0, score=177745.005236, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=192722.648546, train/accuracy=0.887363, train/loss=0.418927, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:28:22.389028 139758009304832 logging_writer.py:48] [399800] global_step=399800, grad_norm=3.1717140674591064, loss=1.0874874591827393
I0304 17:29:05.540469 139758026090240 logging_writer.py:48] [399900] global_step=399900, grad_norm=2.970590353012085, loss=1.0814809799194336
I0304 17:29:50.518959 139758009304832 logging_writer.py:48] [400000] global_step=400000, grad_norm=3.424288034439087, loss=2.85239839553833
I0304 17:30:35.489662 139758026090240 logging_writer.py:48] [400100] global_step=400100, grad_norm=3.174095869064331, loss=2.564507007598877
I0304 17:31:20.503263 139758009304832 logging_writer.py:48] [400200] global_step=400200, grad_norm=2.866448402404785, loss=1.3020339012145996
I0304 17:32:05.286716 139758026090240 logging_writer.py:48] [400300] global_step=400300, grad_norm=3.127753257751465, loss=1.953595757484436
I0304 17:32:50.738867 139758009304832 logging_writer.py:48] [400400] global_step=400400, grad_norm=2.942312717437744, loss=1.157747745513916
I0304 17:33:35.839623 139758026090240 logging_writer.py:48] [400500] global_step=400500, grad_norm=3.487013101577759, loss=2.9752776622772217
I0304 17:34:21.532250 139758009304832 logging_writer.py:48] [400600] global_step=400600, grad_norm=3.1464662551879883, loss=2.4588398933410645
I0304 17:35:02.511382 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:35:14.318329 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:35:39.047192 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:35:40.685350 139953291118400 submission_runner.py:411] Time since start: 193180.86s, 	Step: 400693, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.4117428958415985, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 178164.88333821297, 'total_duration': 193180.86157727242, 'accumulated_submission_time': 178164.88333821297, 'accumulated_eval_time': 14965.110442399979, 'accumulated_logging_time': 30.468629837036133}
I0304 17:35:40.778382 139758026090240 logging_writer.py:48] [400693] accumulated_eval_time=14965.110442, accumulated_logging_time=30.468630, accumulated_submission_time=178164.883338, global_step=400693, preemption_count=0, score=178164.883338, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=193180.861577, train/accuracy=0.888379, train/loss=0.411743, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:35:43.969502 139758009304832 logging_writer.py:48] [400700] global_step=400700, grad_norm=3.026522397994995, loss=1.0801595449447632
I0304 17:36:24.994053 139758026090240 logging_writer.py:48] [400800] global_step=400800, grad_norm=3.110069751739502, loss=1.8118315935134888
I0304 17:37:09.790095 139758009304832 logging_writer.py:48] [400900] global_step=400900, grad_norm=3.3435068130493164, loss=1.4690850973129272
I0304 17:37:54.450025 139758026090240 logging_writer.py:48] [401000] global_step=401000, grad_norm=2.9214799404144287, loss=1.2195571660995483
I0304 17:38:39.561145 139758009304832 logging_writer.py:48] [401100] global_step=401100, grad_norm=3.2892024517059326, loss=1.2271441221237183
I0304 17:39:24.434299 139758026090240 logging_writer.py:48] [401200] global_step=401200, grad_norm=2.9861042499542236, loss=1.1806039810180664
I0304 17:40:09.394609 139758009304832 logging_writer.py:48] [401300] global_step=401300, grad_norm=3.1478500366210938, loss=1.1653677225112915
I0304 17:40:54.260249 139758026090240 logging_writer.py:48] [401400] global_step=401400, grad_norm=3.377852201461792, loss=1.5086910724639893
I0304 17:41:39.355593 139758009304832 logging_writer.py:48] [401500] global_step=401500, grad_norm=3.7662460803985596, loss=3.221667766571045
I0304 17:42:24.529301 139758026090240 logging_writer.py:48] [401600] global_step=401600, grad_norm=3.1902787685394287, loss=2.2178807258605957
I0304 17:42:40.957686 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:42:52.007783 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:43:22.092285 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:43:23.720659 139953291118400 submission_runner.py:411] Time since start: 193643.90s, 	Step: 401638, 	{'train/accuracy': 0.8850390315055847, 'train/loss': 0.42585670948028564, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 178585.00466036797, 'total_duration': 193643.89689183235, 'accumulated_submission_time': 178585.00466036797, 'accumulated_eval_time': 15007.873401165009, 'accumulated_logging_time': 30.571869134902954}
I0304 17:43:23.795430 139758009304832 logging_writer.py:48] [401638] accumulated_eval_time=15007.873401, accumulated_logging_time=30.571869, accumulated_submission_time=178585.004660, global_step=401638, preemption_count=0, score=178585.004660, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=193643.896892, train/accuracy=0.885039, train/loss=0.425857, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:43:48.643575 139758026090240 logging_writer.py:48] [401700] global_step=401700, grad_norm=2.993173599243164, loss=1.1670829057693481
I0304 17:44:31.562498 139758009304832 logging_writer.py:48] [401800] global_step=401800, grad_norm=3.801711320877075, loss=3.262320041656494
I0304 17:45:16.698049 139758026090240 logging_writer.py:48] [401900] global_step=401900, grad_norm=3.26247239112854, loss=1.2285314798355103
I0304 17:46:01.635591 139758009304832 logging_writer.py:48] [402000] global_step=402000, grad_norm=2.9628591537475586, loss=1.1492509841918945
I0304 17:46:46.734684 139758026090240 logging_writer.py:48] [402100] global_step=402100, grad_norm=3.2104623317718506, loss=2.677858829498291
I0304 17:47:31.664652 139758009304832 logging_writer.py:48] [402200] global_step=402200, grad_norm=3.219277858734131, loss=2.8768200874328613
I0304 17:48:16.638122 139758026090240 logging_writer.py:48] [402300] global_step=402300, grad_norm=3.3668580055236816, loss=3.068638801574707
I0304 17:49:01.624034 139758009304832 logging_writer.py:48] [402400] global_step=402400, grad_norm=2.9663898944854736, loss=1.7192144393920898
I0304 17:49:46.451284 139758026090240 logging_writer.py:48] [402500] global_step=402500, grad_norm=4.311823844909668, loss=3.2340540885925293
I0304 17:50:23.813714 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:50:34.922162 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:50:56.795238 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:50:58.429268 139953291118400 submission_runner.py:411] Time since start: 194098.61s, 	Step: 402585, 	{'train/accuracy': 0.8865624666213989, 'train/loss': 0.4191708266735077, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 179004.96719145775, 'total_duration': 194098.60548830032, 'accumulated_submission_time': 179004.96719145775, 'accumulated_eval_time': 15042.488958358765, 'accumulated_logging_time': 30.655258893966675}
I0304 17:50:58.523890 139758009304832 logging_writer.py:48] [402585] accumulated_eval_time=15042.488958, accumulated_logging_time=30.655259, accumulated_submission_time=179004.967191, global_step=402585, preemption_count=0, score=179004.967191, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=194098.605488, train/accuracy=0.886562, train/loss=0.419171, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:51:05.027055 139758026090240 logging_writer.py:48] [402600] global_step=402600, grad_norm=3.2118773460388184, loss=1.081872820854187
I0304 17:51:46.497157 139758009304832 logging_writer.py:48] [402700] global_step=402700, grad_norm=3.9716498851776123, loss=3.270103931427002
I0304 17:52:31.653676 139758026090240 logging_writer.py:48] [402800] global_step=402800, grad_norm=2.9687483310699463, loss=1.0964833498001099
I0304 17:53:16.997978 139758009304832 logging_writer.py:48] [402900] global_step=402900, grad_norm=2.922407865524292, loss=1.1534805297851562
I0304 17:54:02.268968 139758026090240 logging_writer.py:48] [403000] global_step=403000, grad_norm=3.679104804992676, loss=1.4102821350097656
I0304 17:54:47.397922 139758009304832 logging_writer.py:48] [403100] global_step=403100, grad_norm=3.366739273071289, loss=1.1654812097549438
I0304 17:55:32.678690 139758026090240 logging_writer.py:48] [403200] global_step=403200, grad_norm=3.0104804039001465, loss=2.0153331756591797
I0304 17:56:17.990613 139758009304832 logging_writer.py:48] [403300] global_step=403300, grad_norm=3.3029353618621826, loss=1.0799263715744019
I0304 17:57:03.182059 139758026090240 logging_writer.py:48] [403400] global_step=403400, grad_norm=3.901937484741211, loss=3.17221999168396
I0304 17:57:47.933713 139758009304832 logging_writer.py:48] [403500] global_step=403500, grad_norm=2.8147647380828857, loss=1.392849087715149
I0304 17:57:58.818085 139953291118400 spec.py:321] Evaluating on the training split.
I0304 17:58:09.939683 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 17:58:43.077738 139953291118400 spec.py:349] Evaluating on the test split.
I0304 17:58:44.713084 139953291118400 submission_runner.py:411] Time since start: 194564.89s, 	Step: 403526, 	{'train/accuracy': 0.8875585794448853, 'train/loss': 0.41977009177207947, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 179425.1990661621, 'total_duration': 194564.88929629326, 'accumulated_submission_time': 179425.1990661621, 'accumulated_eval_time': 15088.383921384811, 'accumulated_logging_time': 30.7644944190979}
I0304 17:58:44.802522 139758026090240 logging_writer.py:48] [403526] accumulated_eval_time=15088.383921, accumulated_logging_time=30.764494, accumulated_submission_time=179425.199066, global_step=403526, preemption_count=0, score=179425.199066, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=194564.889296, train/accuracy=0.887559, train/loss=0.419770, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 17:59:14.410462 139758009304832 logging_writer.py:48] [403600] global_step=403600, grad_norm=2.990976333618164, loss=1.0893926620483398
I0304 17:59:58.633604 139758026090240 logging_writer.py:48] [403700] global_step=403700, grad_norm=3.1765072345733643, loss=1.2537128925323486
I0304 18:00:43.707095 139758009304832 logging_writer.py:48] [403800] global_step=403800, grad_norm=2.9426774978637695, loss=0.9934005737304688
I0304 18:01:29.245136 139758026090240 logging_writer.py:48] [403900] global_step=403900, grad_norm=3.060323715209961, loss=1.326767921447754
I0304 18:02:14.540931 139758009304832 logging_writer.py:48] [404000] global_step=404000, grad_norm=5.152493000030518, loss=3.0733931064605713
I0304 18:02:59.736780 139758026090240 logging_writer.py:48] [404100] global_step=404100, grad_norm=3.123199462890625, loss=1.3520879745483398
I0304 18:03:45.200033 139758009304832 logging_writer.py:48] [404200] global_step=404200, grad_norm=3.238186836242676, loss=1.4678829908370972
I0304 18:04:30.298156 139758026090240 logging_writer.py:48] [404300] global_step=404300, grad_norm=3.186143398284912, loss=2.079343318939209
I0304 18:05:15.451293 139758009304832 logging_writer.py:48] [404400] global_step=404400, grad_norm=3.0478506088256836, loss=2.0733301639556885
I0304 18:05:44.960154 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:05:56.022215 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:06:26.037949 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:06:27.679757 139953291118400 submission_runner.py:411] Time since start: 195027.86s, 	Step: 404467, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.41914647817611694, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 179845.30004048347, 'total_duration': 195027.85599136353, 'accumulated_submission_time': 179845.30004048347, 'accumulated_eval_time': 15131.103526830673, 'accumulated_logging_time': 30.86377716064453}
I0304 18:06:27.755816 139758026090240 logging_writer.py:48] [404467] accumulated_eval_time=15131.103527, accumulated_logging_time=30.863777, accumulated_submission_time=179845.300040, global_step=404467, preemption_count=0, score=179845.300040, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=195027.855991, train/accuracy=0.887227, train/loss=0.419146, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 18:06:41.175625 139758009304832 logging_writer.py:48] [404500] global_step=404500, grad_norm=3.2464919090270996, loss=1.1618915796279907
I0304 18:07:23.006364 139758026090240 logging_writer.py:48] [404600] global_step=404600, grad_norm=3.0885045528411865, loss=2.1879944801330566
I0304 18:08:07.933586 139758009304832 logging_writer.py:48] [404700] global_step=404700, grad_norm=3.0288608074188232, loss=1.3029371500015259
I0304 18:08:52.803470 139758026090240 logging_writer.py:48] [404800] global_step=404800, grad_norm=3.065931797027588, loss=1.8566038608551025
I0304 18:09:38.179469 139758009304832 logging_writer.py:48] [404900] global_step=404900, grad_norm=3.4317893981933594, loss=1.1210625171661377
I0304 18:10:23.146238 139758026090240 logging_writer.py:48] [405000] global_step=405000, grad_norm=3.059739351272583, loss=1.1130666732788086
I0304 18:11:08.165384 139758009304832 logging_writer.py:48] [405100] global_step=405100, grad_norm=3.0760843753814697, loss=1.1183981895446777
I0304 18:11:53.245085 139758026090240 logging_writer.py:48] [405200] global_step=405200, grad_norm=3.180572509765625, loss=1.1668943166732788
I0304 18:12:38.385703 139758009304832 logging_writer.py:48] [405300] global_step=405300, grad_norm=3.376234292984009, loss=1.1608085632324219
I0304 18:13:23.566043 139758026090240 logging_writer.py:48] [405400] global_step=405400, grad_norm=3.000711679458618, loss=1.935517430305481
I0304 18:13:27.687187 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:13:39.237270 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:14:01.346803 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:14:02.976488 139953291118400 submission_runner.py:411] Time since start: 195483.15s, 	Step: 405411, 	{'train/accuracy': 0.8865624666213989, 'train/loss': 0.4221104681491852, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 180265.17570757866, 'total_duration': 195483.1527121067, 'accumulated_submission_time': 180265.17570757866, 'accumulated_eval_time': 15166.39280295372, 'accumulated_logging_time': 30.94795870780945}
I0304 18:14:03.072746 139758009304832 logging_writer.py:48] [405411] accumulated_eval_time=15166.392803, accumulated_logging_time=30.947959, accumulated_submission_time=180265.175708, global_step=405411, preemption_count=0, score=180265.175708, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=195483.152712, train/accuracy=0.886562, train/loss=0.422110, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 18:14:39.523460 139758026090240 logging_writer.py:48] [405500] global_step=405500, grad_norm=3.025740623474121, loss=1.150723934173584
I0304 18:15:24.676275 139758009304832 logging_writer.py:48] [405600] global_step=405600, grad_norm=3.153313398361206, loss=1.166721224784851
I0304 18:16:10.140275 139758026090240 logging_writer.py:48] [405700] global_step=405700, grad_norm=3.3508591651916504, loss=1.1041263341903687
I0304 18:16:55.618884 139758009304832 logging_writer.py:48] [405800] global_step=405800, grad_norm=3.0154221057891846, loss=1.1784770488739014
I0304 18:17:40.591344 139758026090240 logging_writer.py:48] [405900] global_step=405900, grad_norm=3.057657480239868, loss=1.2620519399642944
I0304 18:18:25.931422 139758009304832 logging_writer.py:48] [406000] global_step=406000, grad_norm=3.803501605987549, loss=3.1005146503448486
I0304 18:19:11.143727 139758026090240 logging_writer.py:48] [406100] global_step=406100, grad_norm=4.720556735992432, loss=1.1336472034454346
I0304 18:19:56.218962 139758009304832 logging_writer.py:48] [406200] global_step=406200, grad_norm=3.4150235652923584, loss=1.368664026260376
I0304 18:20:41.461529 139758026090240 logging_writer.py:48] [406300] global_step=406300, grad_norm=3.284154176712036, loss=1.128395676612854
I0304 18:21:03.310266 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:21:14.720737 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:21:41.802909 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:21:43.431945 139953291118400 submission_runner.py:411] Time since start: 195943.61s, 	Step: 406350, 	{'train/accuracy': 0.8861327767372131, 'train/loss': 0.4223325252532959, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 180685.35479688644, 'total_duration': 195943.60817050934, 'accumulated_submission_time': 180685.35479688644, 'accumulated_eval_time': 15206.514477968216, 'accumulated_logging_time': 31.055206060409546}
I0304 18:21:43.525894 139758009304832 logging_writer.py:48] [406350] accumulated_eval_time=15206.514478, accumulated_logging_time=31.055206, accumulated_submission_time=180685.354797, global_step=406350, preemption_count=0, score=180685.354797, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=195943.608171, train/accuracy=0.886133, train/loss=0.422333, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 18:22:03.678489 139758026090240 logging_writer.py:48] [406400] global_step=406400, grad_norm=2.9877054691314697, loss=1.5392683744430542
I0304 18:22:47.314371 139758009304832 logging_writer.py:48] [406500] global_step=406500, grad_norm=3.063847780227661, loss=1.1326980590820312
I0304 18:23:32.542642 139758026090240 logging_writer.py:48] [406600] global_step=406600, grad_norm=3.055724859237671, loss=1.0336592197418213
I0304 18:24:18.724373 139758009304832 logging_writer.py:48] [406700] global_step=406700, grad_norm=3.12106990814209, loss=1.1418921947479248
I0304 18:25:04.026910 139758026090240 logging_writer.py:48] [406800] global_step=406800, grad_norm=3.0491628646850586, loss=1.479060173034668
I0304 18:25:49.088784 139758009304832 logging_writer.py:48] [406900] global_step=406900, grad_norm=3.015495777130127, loss=1.0683389902114868
I0304 18:26:34.417708 139758026090240 logging_writer.py:48] [407000] global_step=407000, grad_norm=4.935304641723633, loss=2.8746774196624756
I0304 18:27:19.707845 139758009304832 logging_writer.py:48] [407100] global_step=407100, grad_norm=3.0469508171081543, loss=2.363405227661133
I0304 18:28:04.803131 139758026090240 logging_writer.py:48] [407200] global_step=407200, grad_norm=3.2064599990844727, loss=1.0530927181243896
I0304 18:28:43.550155 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:28:54.793070 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:29:19.966752 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:29:21.608184 139953291118400 submission_runner.py:411] Time since start: 196401.78s, 	Step: 407288, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.41762080788612366, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 181105.31928634644, 'total_duration': 196401.7843978405, 'accumulated_submission_time': 181105.31928634644, 'accumulated_eval_time': 15244.572483301163, 'accumulated_logging_time': 31.16160798072815}
I0304 18:29:21.703261 139758009304832 logging_writer.py:48] [407288] accumulated_eval_time=15244.572483, accumulated_logging_time=31.161608, accumulated_submission_time=181105.319286, global_step=407288, preemption_count=0, score=181105.319286, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=196401.784398, train/accuracy=0.888477, train/loss=0.417621, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 18:29:26.856957 139758026090240 logging_writer.py:48] [407300] global_step=407300, grad_norm=2.9084255695343018, loss=2.1647448539733887
I0304 18:30:08.308477 139758009304832 logging_writer.py:48] [407400] global_step=407400, grad_norm=3.946171760559082, loss=3.3633615970611572
I0304 18:30:53.307352 139758026090240 logging_writer.py:48] [407500] global_step=407500, grad_norm=3.318080425262451, loss=1.6348936557769775
I0304 18:31:38.840877 139758009304832 logging_writer.py:48] [407600] global_step=407600, grad_norm=2.995521068572998, loss=1.9604175090789795
I0304 18:32:24.279330 139758026090240 logging_writer.py:48] [407700] global_step=407700, grad_norm=3.1327970027923584, loss=1.2338041067123413
I0304 18:33:09.443679 139758009304832 logging_writer.py:48] [407800] global_step=407800, grad_norm=3.1784589290618896, loss=1.2115986347198486
I0304 18:33:54.499615 139758026090240 logging_writer.py:48] [407900] global_step=407900, grad_norm=3.094709873199463, loss=1.2883384227752686
I0304 18:34:39.730756 139758009304832 logging_writer.py:48] [408000] global_step=408000, grad_norm=3.235389471054077, loss=1.112367868423462
I0304 18:35:24.607877 139758026090240 logging_writer.py:48] [408100] global_step=408100, grad_norm=3.057156801223755, loss=1.7943799495697021
I0304 18:36:09.813146 139758009304832 logging_writer.py:48] [408200] global_step=408200, grad_norm=2.9594318866729736, loss=1.0250580310821533
I0304 18:36:21.611007 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:36:32.732152 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:36:58.647531 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:37:00.277368 139953291118400 submission_runner.py:411] Time since start: 196860.45s, 	Step: 408228, 	{'train/accuracy': 0.8869140148162842, 'train/loss': 0.4151829779148102, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 181525.16959023476, 'total_duration': 196860.4535934925, 'accumulated_submission_time': 181525.16959023476, 'accumulated_eval_time': 15283.238829135895, 'accumulated_logging_time': 31.26688051223755}
I0304 18:37:00.372718 139758026090240 logging_writer.py:48] [408228] accumulated_eval_time=15283.238829, accumulated_logging_time=31.266881, accumulated_submission_time=181525.169590, global_step=408228, preemption_count=0, score=181525.169590, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=196860.453593, train/accuracy=0.886914, train/loss=0.415183, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 18:37:29.213401 139758009304832 logging_writer.py:48] [408300] global_step=408300, grad_norm=2.955658197402954, loss=1.6648412942886353
I0304 18:38:13.913232 139758026090240 logging_writer.py:48] [408400] global_step=408400, grad_norm=3.371030807495117, loss=3.0445306301116943
I0304 18:38:58.887615 139758009304832 logging_writer.py:48] [408500] global_step=408500, grad_norm=3.4736669063568115, loss=1.1840777397155762
I0304 18:39:43.984102 139758026090240 logging_writer.py:48] [408600] global_step=408600, grad_norm=3.3974087238311768, loss=3.103543281555176
I0304 18:40:28.921935 139758009304832 logging_writer.py:48] [408700] global_step=408700, grad_norm=3.083991289138794, loss=1.289077877998352
I0304 18:41:13.822713 139758026090240 logging_writer.py:48] [408800] global_step=408800, grad_norm=3.0710480213165283, loss=1.1414642333984375
I0304 18:41:58.792662 139758009304832 logging_writer.py:48] [408900] global_step=408900, grad_norm=5.324401378631592, loss=1.4640793800354004
I0304 18:42:43.750505 139758026090240 logging_writer.py:48] [409000] global_step=409000, grad_norm=3.2192437648773193, loss=1.1335381269454956
I0304 18:43:28.603694 139758009304832 logging_writer.py:48] [409100] global_step=409100, grad_norm=3.270426034927368, loss=2.491907835006714
I0304 18:44:00.704809 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:44:11.863192 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:44:40.340065 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:44:41.964493 139953291118400 submission_runner.py:411] Time since start: 197322.14s, 	Step: 409172, 	{'train/accuracy': 0.8871874809265137, 'train/loss': 0.42278429865837097, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 181945.43846178055, 'total_duration': 197322.14072799683, 'accumulated_submission_time': 181945.43846178055, 'accumulated_eval_time': 15324.498523712158, 'accumulated_logging_time': 31.37296724319458}
I0304 18:44:42.041975 139758026090240 logging_writer.py:48] [409172] accumulated_eval_time=15324.498524, accumulated_logging_time=31.372967, accumulated_submission_time=181945.438462, global_step=409172, preemption_count=0, score=181945.438462, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=197322.140728, train/accuracy=0.887187, train/loss=0.422784, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 18:44:53.479718 139758009304832 logging_writer.py:48] [409200] global_step=409200, grad_norm=3.6841297149658203, loss=2.745792865753174
I0304 18:45:34.738289 139758026090240 logging_writer.py:48] [409300] global_step=409300, grad_norm=3.1632890701293945, loss=2.265211582183838
I0304 18:46:19.880010 139758009304832 logging_writer.py:48] [409400] global_step=409400, grad_norm=3.564788579940796, loss=3.0681605339050293
I0304 18:47:04.683878 139758026090240 logging_writer.py:48] [409500] global_step=409500, grad_norm=2.9548187255859375, loss=1.9645822048187256
I0304 18:47:49.781117 139758009304832 logging_writer.py:48] [409600] global_step=409600, grad_norm=3.20542573928833, loss=1.551727056503296
I0304 18:48:34.336628 139758026090240 logging_writer.py:48] [409700] global_step=409700, grad_norm=3.3042540550231934, loss=1.1986374855041504
I0304 18:49:19.258075 139758009304832 logging_writer.py:48] [409800] global_step=409800, grad_norm=3.0823490619659424, loss=1.760377049446106
I0304 18:50:04.277875 139758026090240 logging_writer.py:48] [409900] global_step=409900, grad_norm=3.515282154083252, loss=3.008587121963501
I0304 18:50:49.110681 139758009304832 logging_writer.py:48] [410000] global_step=410000, grad_norm=3.0045483112335205, loss=1.8886768817901611
I0304 18:51:34.039894 139758026090240 logging_writer.py:48] [410100] global_step=410100, grad_norm=2.9601924419403076, loss=1.529163122177124
I0304 18:51:42.350424 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:51:53.490806 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:52:22.869934 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:52:24.500696 139953291118400 submission_runner.py:411] Time since start: 197784.68s, 	Step: 410120, 	{'train/accuracy': 0.8855859041213989, 'train/loss': 0.42344149947166443, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 182365.68975257874, 'total_duration': 197784.67691898346, 'accumulated_submission_time': 182365.68975257874, 'accumulated_eval_time': 15366.648778438568, 'accumulated_logging_time': 31.45956587791443}
I0304 18:52:24.596114 139758009304832 logging_writer.py:48] [410120] accumulated_eval_time=15366.648778, accumulated_logging_time=31.459566, accumulated_submission_time=182365.689753, global_step=410120, preemption_count=0, score=182365.689753, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=197784.676919, train/accuracy=0.885586, train/loss=0.423441, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 18:52:57.020030 139758026090240 logging_writer.py:48] [410200] global_step=410200, grad_norm=2.959988594055176, loss=1.1386581659317017
I0304 18:53:41.540309 139758009304832 logging_writer.py:48] [410300] global_step=410300, grad_norm=2.9407577514648438, loss=1.0143425464630127
I0304 18:54:27.020615 139758026090240 logging_writer.py:48] [410400] global_step=410400, grad_norm=2.7912771701812744, loss=1.1738815307617188
I0304 18:55:12.805451 139758009304832 logging_writer.py:48] [410500] global_step=410500, grad_norm=2.992945432662964, loss=1.147369623184204
I0304 18:55:58.073160 139758026090240 logging_writer.py:48] [410600] global_step=410600, grad_norm=2.9579849243164062, loss=2.3028016090393066
I0304 18:56:43.328656 139758009304832 logging_writer.py:48] [410700] global_step=410700, grad_norm=2.935112237930298, loss=2.5508792400360107
I0304 18:57:28.531597 139758026090240 logging_writer.py:48] [410800] global_step=410800, grad_norm=2.8875207901000977, loss=1.7539641857147217
I0304 18:58:13.640653 139758009304832 logging_writer.py:48] [410900] global_step=410900, grad_norm=3.1360087394714355, loss=1.164438247680664
I0304 18:58:58.460995 139758026090240 logging_writer.py:48] [411000] global_step=411000, grad_norm=3.078106641769409, loss=1.1466264724731445
I0304 18:59:24.729474 139953291118400 spec.py:321] Evaluating on the training split.
I0304 18:59:35.851238 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 18:59:58.077159 139953291118400 spec.py:349] Evaluating on the test split.
I0304 18:59:59.719779 139953291118400 submission_runner.py:411] Time since start: 198239.90s, 	Step: 411060, 	{'train/accuracy': 0.8866015672683716, 'train/loss': 0.4224465787410736, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 182785.76449751854, 'total_duration': 198239.89599585533, 'accumulated_submission_time': 182785.76449751854, 'accumulated_eval_time': 15401.639070272446, 'accumulated_logging_time': 31.566688537597656}
I0304 18:59:59.816882 139758009304832 logging_writer.py:48] [411060] accumulated_eval_time=15401.639070, accumulated_logging_time=31.566689, accumulated_submission_time=182785.764498, global_step=411060, preemption_count=0, score=182785.764498, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=198239.895996, train/accuracy=0.886602, train/loss=0.422447, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:00:16.012354 139758026090240 logging_writer.py:48] [411100] global_step=411100, grad_norm=3.1715118885040283, loss=1.2603025436401367
I0304 19:00:59.508273 139758009304832 logging_writer.py:48] [411200] global_step=411200, grad_norm=3.0906789302825928, loss=2.0721349716186523
I0304 19:01:44.795897 139758026090240 logging_writer.py:48] [411300] global_step=411300, grad_norm=3.1053895950317383, loss=1.958553433418274
I0304 19:02:30.047364 139758009304832 logging_writer.py:48] [411400] global_step=411400, grad_norm=3.1770687103271484, loss=2.8772196769714355
I0304 19:03:15.238276 139758026090240 logging_writer.py:48] [411500] global_step=411500, grad_norm=2.8142781257629395, loss=1.942246437072754
I0304 19:04:00.412563 139758009304832 logging_writer.py:48] [411600] global_step=411600, grad_norm=3.1316399574279785, loss=1.273978352546692
I0304 19:04:45.833847 139758026090240 logging_writer.py:48] [411700] global_step=411700, grad_norm=2.9568443298339844, loss=1.059224247932434
I0304 19:05:30.868273 139758009304832 logging_writer.py:48] [411800] global_step=411800, grad_norm=3.2637689113616943, loss=1.1561520099639893
I0304 19:06:16.082805 139758026090240 logging_writer.py:48] [411900] global_step=411900, grad_norm=3.019197940826416, loss=1.76666259765625
I0304 19:07:00.187211 139953291118400 spec.py:321] Evaluating on the training split.
I0304 19:07:11.685506 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 19:07:41.395807 139953291118400 spec.py:349] Evaluating on the test split.
I0304 19:07:43.020683 139953291118400 submission_runner.py:411] Time since start: 198703.20s, 	Step: 411999, 	{'train/accuracy': 0.8878124952316284, 'train/loss': 0.41147294640541077, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 183206.07600712776, 'total_duration': 198703.19691753387, 'accumulated_submission_time': 183206.07600712776, 'accumulated_eval_time': 15444.472546577454, 'accumulated_logging_time': 31.67509889602661}
I0304 19:07:43.095955 139758009304832 logging_writer.py:48] [411999] accumulated_eval_time=15444.472547, accumulated_logging_time=31.675099, accumulated_submission_time=183206.076007, global_step=411999, preemption_count=0, score=183206.076007, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=198703.196918, train/accuracy=0.887812, train/loss=0.411473, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:07:43.887994 139758026090240 logging_writer.py:48] [412000] global_step=412000, grad_norm=3.2298591136932373, loss=1.1465204954147339
I0304 19:08:24.142647 139758009304832 logging_writer.py:48] [412100] global_step=412100, grad_norm=3.1512563228607178, loss=1.441092848777771
I0304 19:09:08.701358 139758026090240 logging_writer.py:48] [412200] global_step=412200, grad_norm=2.992530345916748, loss=2.2039592266082764
I0304 19:09:53.596544 139758009304832 logging_writer.py:48] [412300] global_step=412300, grad_norm=3.1791152954101562, loss=1.403969168663025
I0304 19:10:38.720640 139758026090240 logging_writer.py:48] [412400] global_step=412400, grad_norm=2.898224115371704, loss=1.2945307493209839
I0304 19:11:23.631100 139758009304832 logging_writer.py:48] [412500] global_step=412500, grad_norm=3.3867084980010986, loss=1.163478970527649
I0304 19:12:08.522853 139758026090240 logging_writer.py:48] [412600] global_step=412600, grad_norm=3.630692720413208, loss=3.288067102432251
I0304 19:12:53.944879 139758009304832 logging_writer.py:48] [412700] global_step=412700, grad_norm=2.932720184326172, loss=1.167764663696289
I0304 19:13:38.910095 139758026090240 logging_writer.py:48] [412800] global_step=412800, grad_norm=3.0514137744903564, loss=1.0562565326690674
I0304 19:14:24.455673 139758009304832 logging_writer.py:48] [412900] global_step=412900, grad_norm=3.084824323654175, loss=1.1581475734710693
I0304 19:14:43.145219 139953291118400 spec.py:321] Evaluating on the training split.
I0304 19:14:54.137042 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 19:15:15.626346 139953291118400 spec.py:349] Evaluating on the test split.
I0304 19:15:17.267221 139953291118400 submission_runner.py:411] Time since start: 199157.44s, 	Step: 412943, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.419604629278183, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 183626.06824731827, 'total_duration': 199157.44343042374, 'accumulated_submission_time': 183626.06824731827, 'accumulated_eval_time': 15478.594518899918, 'accumulated_logging_time': 31.759069442749023}
I0304 19:15:17.363654 139758026090240 logging_writer.py:48] [412943] accumulated_eval_time=15478.594519, accumulated_logging_time=31.759069, accumulated_submission_time=183626.068247, global_step=412943, preemption_count=0, score=183626.068247, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=199157.443430, train/accuracy=0.887461, train/loss=0.419605, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:15:40.291732 139758009304832 logging_writer.py:48] [413000] global_step=413000, grad_norm=3.770568609237671, loss=3.198726177215576
I0304 19:16:24.601301 139758026090240 logging_writer.py:48] [413100] global_step=413100, grad_norm=2.9749484062194824, loss=1.0612863302230835
I0304 19:17:09.722849 139758009304832 logging_writer.py:48] [413200] global_step=413200, grad_norm=3.3179657459259033, loss=1.10868501663208
I0304 19:17:54.518264 139758026090240 logging_writer.py:48] [413300] global_step=413300, grad_norm=3.2249951362609863, loss=1.1210718154907227
I0304 19:18:39.385761 139758009304832 logging_writer.py:48] [413400] global_step=413400, grad_norm=3.4097673892974854, loss=2.8748347759246826
I0304 19:19:24.457203 139758026090240 logging_writer.py:48] [413500] global_step=413500, grad_norm=3.7851858139038086, loss=3.1927490234375
I0304 19:20:09.517320 139758009304832 logging_writer.py:48] [413600] global_step=413600, grad_norm=3.4510674476623535, loss=1.62942636013031
I0304 19:20:54.254900 139758026090240 logging_writer.py:48] [413700] global_step=413700, grad_norm=2.878004789352417, loss=1.1109178066253662
I0304 19:21:39.153756 139758009304832 logging_writer.py:48] [413800] global_step=413800, grad_norm=3.136997938156128, loss=2.326690673828125
I0304 19:22:17.292871 139953291118400 spec.py:321] Evaluating on the training split.
I0304 19:22:28.455768 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 19:22:54.084737 139953291118400 spec.py:349] Evaluating on the test split.
I0304 19:22:55.716345 139953291118400 submission_runner.py:411] Time since start: 199615.89s, 	Step: 413886, 	{'train/accuracy': 0.8876367211341858, 'train/loss': 0.42231327295303345, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 184045.93671751022, 'total_duration': 199615.89252972603, 'accumulated_submission_time': 184045.93671751022, 'accumulated_eval_time': 15517.017944574356, 'accumulated_logging_time': 31.868417978286743}
I0304 19:22:55.815416 139758026090240 logging_writer.py:48] [413886] accumulated_eval_time=15517.017945, accumulated_logging_time=31.868418, accumulated_submission_time=184045.936718, global_step=413886, preemption_count=0, score=184045.936718, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=199615.892530, train/accuracy=0.887637, train/loss=0.422313, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:23:01.742286 139758009304832 logging_writer.py:48] [413900] global_step=413900, grad_norm=3.969388246536255, loss=2.7248971462249756
I0304 19:23:43.300750 139758026090240 logging_writer.py:48] [414000] global_step=414000, grad_norm=3.008263111114502, loss=1.2524425983428955
I0304 19:24:28.320706 139758009304832 logging_writer.py:48] [414100] global_step=414100, grad_norm=2.76002836227417, loss=1.0595709085464478
I0304 19:25:14.113734 139758026090240 logging_writer.py:48] [414200] global_step=414200, grad_norm=3.2927277088165283, loss=2.850191831588745
I0304 19:25:59.396654 139758009304832 logging_writer.py:48] [414300] global_step=414300, grad_norm=3.016643524169922, loss=1.1173893213272095
I0304 19:26:44.431539 139758026090240 logging_writer.py:48] [414400] global_step=414400, grad_norm=3.4191834926605225, loss=2.3630971908569336
I0304 19:27:29.647617 139758009304832 logging_writer.py:48] [414500] global_step=414500, grad_norm=3.1279947757720947, loss=1.2261096239089966
I0304 19:28:14.732334 139758026090240 logging_writer.py:48] [414600] global_step=414600, grad_norm=3.340714931488037, loss=1.067123293876648
I0304 19:28:59.732483 139758009304832 logging_writer.py:48] [414700] global_step=414700, grad_norm=2.8854172229766846, loss=1.0235353708267212
I0304 19:29:44.803293 139758026090240 logging_writer.py:48] [414800] global_step=414800, grad_norm=3.217329502105713, loss=1.3362501859664917
I0304 19:29:55.753491 139953291118400 spec.py:321] Evaluating on the training split.
I0304 19:30:06.999018 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 19:30:35.353610 139953291118400 spec.py:349] Evaluating on the test split.
I0304 19:30:36.990386 139953291118400 submission_runner.py:411] Time since start: 200077.17s, 	Step: 414826, 	{'train/accuracy': 0.8863281011581421, 'train/loss': 0.427275151014328, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 184465.8177063465, 'total_duration': 200077.16662049294, 'accumulated_submission_time': 184465.8177063465, 'accumulated_eval_time': 15558.254828453064, 'accumulated_logging_time': 31.97731304168701}
I0304 19:30:37.066142 139758009304832 logging_writer.py:48] [414826] accumulated_eval_time=15558.254828, accumulated_logging_time=31.977313, accumulated_submission_time=184465.817706, global_step=414826, preemption_count=0, score=184465.817706, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=200077.166620, train/accuracy=0.886328, train/loss=0.427275, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:31:06.664308 139758026090240 logging_writer.py:48] [414900] global_step=414900, grad_norm=3.48342227935791, loss=2.4491453170776367
I0304 19:31:50.279866 139758009304832 logging_writer.py:48] [415000] global_step=415000, grad_norm=3.0513508319854736, loss=1.1853357553482056
I0304 19:32:35.255267 139758026090240 logging_writer.py:48] [415100] global_step=415100, grad_norm=3.1438076496124268, loss=1.231630563735962
I0304 19:33:20.491686 139758009304832 logging_writer.py:48] [415200] global_step=415200, grad_norm=3.1868808269500732, loss=1.1866755485534668
I0304 19:34:05.501828 139758026090240 logging_writer.py:48] [415300] global_step=415300, grad_norm=3.2228450775146484, loss=1.154109001159668
I0304 19:34:50.704451 139758009304832 logging_writer.py:48] [415400] global_step=415400, grad_norm=3.222659111022949, loss=2.2249855995178223
I0304 19:35:35.861570 139758026090240 logging_writer.py:48] [415500] global_step=415500, grad_norm=3.2117459774017334, loss=2.4878978729248047
I0304 19:36:20.856422 139758009304832 logging_writer.py:48] [415600] global_step=415600, grad_norm=3.0704963207244873, loss=1.1707878112792969
I0304 19:37:05.834771 139758026090240 logging_writer.py:48] [415700] global_step=415700, grad_norm=3.1083438396453857, loss=1.1255730390548706
I0304 19:37:37.100797 139953291118400 spec.py:321] Evaluating on the training split.
I0304 19:37:48.033907 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 19:38:10.499879 139953291118400 spec.py:349] Evaluating on the test split.
I0304 19:38:12.140210 139953291118400 submission_runner.py:411] Time since start: 200532.32s, 	Step: 415771, 	{'train/accuracy': 0.8896093368530273, 'train/loss': 0.41564708948135376, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 184885.7917456627, 'total_duration': 200532.31643295288, 'accumulated_submission_time': 184885.7917456627, 'accumulated_eval_time': 15593.294227838516, 'accumulated_logging_time': 32.06606459617615}
I0304 19:38:12.240280 139758009304832 logging_writer.py:48] [415771] accumulated_eval_time=15593.294228, accumulated_logging_time=32.066065, accumulated_submission_time=184885.791746, global_step=415771, preemption_count=0, score=184885.791746, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=200532.316433, train/accuracy=0.889609, train/loss=0.415647, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:38:24.101918 139758026090240 logging_writer.py:48] [415800] global_step=415800, grad_norm=2.891420364379883, loss=1.7099580764770508
I0304 19:39:06.330666 139758009304832 logging_writer.py:48] [415900] global_step=415900, grad_norm=3.093092441558838, loss=1.0985318422317505
I0304 19:39:51.339280 139758026090240 logging_writer.py:48] [416000] global_step=416000, grad_norm=3.501150131225586, loss=2.9128828048706055
I0304 19:40:36.965127 139758009304832 logging_writer.py:48] [416100] global_step=416100, grad_norm=3.703916549682617, loss=3.1544554233551025
I0304 19:41:22.457012 139758026090240 logging_writer.py:48] [416200] global_step=416200, grad_norm=3.270779848098755, loss=2.832070827484131
I0304 19:42:07.378956 139758009304832 logging_writer.py:48] [416300] global_step=416300, grad_norm=3.8217623233795166, loss=3.3504791259765625
I0304 19:42:52.655102 139758026090240 logging_writer.py:48] [416400] global_step=416400, grad_norm=3.0726332664489746, loss=1.8407751321792603
I0304 19:43:38.095713 139758009304832 logging_writer.py:48] [416500] global_step=416500, grad_norm=3.0594873428344727, loss=1.230983853340149
I0304 19:44:23.302363 139758026090240 logging_writer.py:48] [416600] global_step=416600, grad_norm=3.0792112350463867, loss=1.1544115543365479
I0304 19:45:09.141829 139758009304832 logging_writer.py:48] [416700] global_step=416700, grad_norm=2.9520256519317627, loss=1.8571836948394775
I0304 19:45:12.427655 139953291118400 spec.py:321] Evaluating on the training split.
I0304 19:45:23.590698 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 19:45:46.062582 139953291118400 spec.py:349] Evaluating on the test split.
I0304 19:45:47.695404 139953291118400 submission_runner.py:411] Time since start: 200987.87s, 	Step: 416709, 	{'train/accuracy': 0.8847265243530273, 'train/loss': 0.4236800968647003, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 185305.9206287861, 'total_duration': 200987.87162804604, 'accumulated_submission_time': 185305.9206287861, 'accumulated_eval_time': 15628.56196141243, 'accumulated_logging_time': 32.17793083190918}
I0304 19:45:47.794131 139758026090240 logging_writer.py:48] [416709] accumulated_eval_time=15628.561961, accumulated_logging_time=32.177931, accumulated_submission_time=185305.920629, global_step=416709, preemption_count=0, score=185305.920629, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=200987.871628, train/accuracy=0.884727, train/loss=0.423680, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:46:25.585731 139758009304832 logging_writer.py:48] [416800] global_step=416800, grad_norm=3.0747437477111816, loss=1.1162811517715454
I0304 19:47:10.623691 139758026090240 logging_writer.py:48] [416900] global_step=416900, grad_norm=3.869900703430176, loss=1.1179410219192505
I0304 19:47:55.739247 139758009304832 logging_writer.py:48] [417000] global_step=417000, grad_norm=2.922175645828247, loss=1.4169590473175049
I0304 19:48:41.053796 139758026090240 logging_writer.py:48] [417100] global_step=417100, grad_norm=3.285930871963501, loss=2.9391067028045654
I0304 19:49:26.090768 139758009304832 logging_writer.py:48] [417200] global_step=417200, grad_norm=3.2082571983337402, loss=2.788512945175171
I0304 19:50:11.242169 139758026090240 logging_writer.py:48] [417300] global_step=417300, grad_norm=3.2243292331695557, loss=2.20228910446167
I0304 19:50:56.308647 139758009304832 logging_writer.py:48] [417400] global_step=417400, grad_norm=3.0168631076812744, loss=1.1011508703231812
I0304 19:51:41.572982 139758026090240 logging_writer.py:48] [417500] global_step=417500, grad_norm=3.1771669387817383, loss=1.9168541431427002
I0304 19:52:26.593207 139758009304832 logging_writer.py:48] [417600] global_step=417600, grad_norm=3.0500388145446777, loss=1.7673816680908203
I0304 19:52:48.005187 139953291118400 spec.py:321] Evaluating on the training split.
I0304 19:52:58.918607 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 19:53:23.312600 139953291118400 spec.py:349] Evaluating on the test split.
I0304 19:53:24.942471 139953291118400 submission_runner.py:411] Time since start: 201445.12s, 	Step: 417649, 	{'train/accuracy': 0.8902343511581421, 'train/loss': 0.4112899601459503, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 185726.07363700867, 'total_duration': 201445.11868214607, 'accumulated_submission_time': 185726.07363700867, 'accumulated_eval_time': 15665.49923491478, 'accumulated_logging_time': 32.28747606277466}
I0304 19:53:25.036432 139758026090240 logging_writer.py:48] [417649] accumulated_eval_time=15665.499235, accumulated_logging_time=32.287476, accumulated_submission_time=185726.073637, global_step=417649, preemption_count=0, score=185726.073637, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=201445.118682, train/accuracy=0.890234, train/loss=0.411290, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 19:53:45.574750 139758009304832 logging_writer.py:48] [417700] global_step=417700, grad_norm=3.651790142059326, loss=3.0121805667877197
I0304 19:54:29.133783 139758026090240 logging_writer.py:48] [417800] global_step=417800, grad_norm=2.928657054901123, loss=1.8267083168029785
I0304 19:55:15.754481 139758009304832 logging_writer.py:48] [417900] global_step=417900, grad_norm=3.470046281814575, loss=3.0340538024902344
I0304 19:56:01.108716 139758026090240 logging_writer.py:48] [418000] global_step=418000, grad_norm=3.8978984355926514, loss=3.1875903606414795
I0304 19:56:46.302773 139758009304832 logging_writer.py:48] [418100] global_step=418100, grad_norm=3.2328386306762695, loss=3.0079925060272217
I0304 19:57:31.510055 139758026090240 logging_writer.py:48] [418200] global_step=418200, grad_norm=3.003636360168457, loss=1.1371859312057495
I0304 19:58:16.751797 139758009304832 logging_writer.py:48] [418300] global_step=418300, grad_norm=3.943769931793213, loss=3.228891134262085
I0304 19:59:01.808362 139758026090240 logging_writer.py:48] [418400] global_step=418400, grad_norm=3.120954751968384, loss=1.1825900077819824
I0304 19:59:46.820409 139758009304832 logging_writer.py:48] [418500] global_step=418500, grad_norm=3.1269679069519043, loss=1.1821118593215942
I0304 20:00:25.161304 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:00:36.457799 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:01:07.573978 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:01:09.197394 139953291118400 submission_runner.py:411] Time since start: 201909.37s, 	Step: 418587, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.4170810580253601, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 186146.1403939724, 'total_duration': 201909.37362527847, 'accumulated_submission_time': 186146.1403939724, 'accumulated_eval_time': 15709.535342693329, 'accumulated_logging_time': 32.39239454269409}
I0304 20:01:09.278195 139758026090240 logging_writer.py:48] [418587] accumulated_eval_time=15709.535343, accumulated_logging_time=32.392395, accumulated_submission_time=186146.140394, global_step=418587, preemption_count=0, score=186146.140394, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=201909.373625, train/accuracy=0.887500, train/loss=0.417081, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:01:14.803610 139758009304832 logging_writer.py:48] [418600] global_step=418600, grad_norm=3.16286301612854, loss=2.1495838165283203
I0304 20:01:55.019424 139758026090240 logging_writer.py:48] [418700] global_step=418700, grad_norm=3.458826780319214, loss=1.8853963613510132
I0304 20:02:40.281443 139758009304832 logging_writer.py:48] [418800] global_step=418800, grad_norm=3.237943410873413, loss=2.6764678955078125
I0304 20:03:25.531910 139758026090240 logging_writer.py:48] [418900] global_step=418900, grad_norm=3.067716360092163, loss=1.2292762994766235
I0304 20:04:11.035751 139758009304832 logging_writer.py:48] [419000] global_step=419000, grad_norm=3.3093950748443604, loss=2.222641944885254
I0304 20:04:55.765182 139758026090240 logging_writer.py:48] [419100] global_step=419100, grad_norm=3.211646795272827, loss=1.0913269519805908
I0304 20:05:42.657168 139758009304832 logging_writer.py:48] [419200] global_step=419200, grad_norm=3.046053171157837, loss=1.1225872039794922
I0304 20:06:29.305505 139758026090240 logging_writer.py:48] [419300] global_step=419300, grad_norm=3.1241092681884766, loss=1.0586410760879517
I0304 20:07:14.469902 139758009304832 logging_writer.py:48] [419400] global_step=419400, grad_norm=2.9756507873535156, loss=1.3777775764465332
I0304 20:07:59.671330 139758026090240 logging_writer.py:48] [419500] global_step=419500, grad_norm=3.001736640930176, loss=1.5629395246505737
I0304 20:08:09.426620 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:08:20.566074 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:08:49.637838 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:08:51.264437 139953291118400 submission_runner.py:411] Time since start: 202371.44s, 	Step: 419523, 	{'train/accuracy': 0.8847265243530273, 'train/loss': 0.42488616704940796, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 186566.229950428, 'total_duration': 202371.4406733513, 'accumulated_submission_time': 186566.229950428, 'accumulated_eval_time': 15751.373156309128, 'accumulated_logging_time': 32.48406267166138}
I0304 20:08:51.342730 139758009304832 logging_writer.py:48] [419523] accumulated_eval_time=15751.373156, accumulated_logging_time=32.484063, accumulated_submission_time=186566.229950, global_step=419523, preemption_count=0, score=186566.229950, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=202371.440673, train/accuracy=0.884727, train/loss=0.424886, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:09:22.131280 139758026090240 logging_writer.py:48] [419600] global_step=419600, grad_norm=3.1967074871063232, loss=1.9762547016143799
I0304 20:10:06.166325 139758009304832 logging_writer.py:48] [419700] global_step=419700, grad_norm=2.9667298793792725, loss=1.7635031938552856
I0304 20:10:51.209714 139758026090240 logging_writer.py:48] [419800] global_step=419800, grad_norm=3.275628089904785, loss=1.1413437128067017
I0304 20:11:36.384413 139758009304832 logging_writer.py:48] [419900] global_step=419900, grad_norm=3.520157814025879, loss=3.0573010444641113
I0304 20:12:21.285969 139758026090240 logging_writer.py:48] [420000] global_step=420000, grad_norm=2.9389498233795166, loss=1.8953213691711426
I0304 20:13:06.386778 139758009304832 logging_writer.py:48] [420100] global_step=420100, grad_norm=3.092881917953491, loss=1.3030481338500977
I0304 20:13:51.407658 139758026090240 logging_writer.py:48] [420200] global_step=420200, grad_norm=3.093280553817749, loss=1.151381254196167
I0304 20:14:36.349797 139758009304832 logging_writer.py:48] [420300] global_step=420300, grad_norm=3.2344281673431396, loss=1.128995418548584
I0304 20:15:21.694259 139758026090240 logging_writer.py:48] [420400] global_step=420400, grad_norm=2.978191614151001, loss=1.2615058422088623
I0304 20:15:51.649262 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:16:03.212799 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:16:23.356706 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:16:24.999267 139953291118400 submission_runner.py:411] Time since start: 202825.18s, 	Step: 420468, 	{'train/accuracy': 0.8904687166213989, 'train/loss': 0.41411322355270386, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 186986.4781191349, 'total_duration': 202825.1754875183, 'accumulated_submission_time': 186986.4781191349, 'accumulated_eval_time': 15784.72314286232, 'accumulated_logging_time': 32.571659564971924}
I0304 20:16:25.096176 139758009304832 logging_writer.py:48] [420468] accumulated_eval_time=15784.723143, accumulated_logging_time=32.571660, accumulated_submission_time=186986.478119, global_step=420468, preemption_count=0, score=186986.478119, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=202825.175488, train/accuracy=0.890469, train/loss=0.414113, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:16:38.162407 139758026090240 logging_writer.py:48] [420500] global_step=420500, grad_norm=3.0734426975250244, loss=1.1669702529907227
I0304 20:17:21.098419 139758009304832 logging_writer.py:48] [420600] global_step=420600, grad_norm=3.2135703563690186, loss=1.1398547887802124
I0304 20:18:06.455392 139758026090240 logging_writer.py:48] [420700] global_step=420700, grad_norm=3.4478936195373535, loss=1.2013546228408813
I0304 20:18:51.614044 139758009304832 logging_writer.py:48] [420800] global_step=420800, grad_norm=3.0818400382995605, loss=2.7739133834838867
I0304 20:19:36.876035 139758026090240 logging_writer.py:48] [420900] global_step=420900, grad_norm=3.431615114212036, loss=1.7748265266418457
I0304 20:20:22.063517 139758009304832 logging_writer.py:48] [421000] global_step=421000, grad_norm=3.2927048206329346, loss=1.1163522005081177
I0304 20:21:07.242342 139758026090240 logging_writer.py:48] [421100] global_step=421100, grad_norm=3.0945212841033936, loss=1.4620610475540161
I0304 20:21:52.208227 139758009304832 logging_writer.py:48] [421200] global_step=421200, grad_norm=3.114266872406006, loss=1.2192637920379639
I0304 20:22:37.214435 139758026090240 logging_writer.py:48] [421300] global_step=421300, grad_norm=3.7568247318267822, loss=3.2520599365234375
I0304 20:23:22.338444 139758009304832 logging_writer.py:48] [421400] global_step=421400, grad_norm=3.454833745956421, loss=2.82291316986084
I0304 20:23:25.119798 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:23:36.392133 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:24:03.856223 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:24:05.500304 139953291118400 submission_runner.py:411] Time since start: 203285.68s, 	Step: 421408, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.4225490093231201, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 187406.4428319931, 'total_duration': 203285.67652893066, 'accumulated_submission_time': 187406.4428319931, 'accumulated_eval_time': 15825.103631973267, 'accumulated_logging_time': 32.67925763130188}
I0304 20:24:05.597579 139758026090240 logging_writer.py:48] [421408] accumulated_eval_time=15825.103632, accumulated_logging_time=32.679258, accumulated_submission_time=187406.442832, global_step=421408, preemption_count=0, score=187406.442832, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=203285.676529, train/accuracy=0.888398, train/loss=0.422549, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:24:43.090022 139758009304832 logging_writer.py:48] [421500] global_step=421500, grad_norm=3.2600414752960205, loss=2.8605895042419434
I0304 20:25:27.901009 139758026090240 logging_writer.py:48] [421600] global_step=421600, grad_norm=3.1700141429901123, loss=1.2782015800476074
I0304 20:26:13.516550 139758009304832 logging_writer.py:48] [421700] global_step=421700, grad_norm=3.070621967315674, loss=1.1120188236236572
I0304 20:26:58.536076 139758026090240 logging_writer.py:48] [421800] global_step=421800, grad_norm=3.823568820953369, loss=3.3199052810668945
I0304 20:27:43.388431 139758009304832 logging_writer.py:48] [421900] global_step=421900, grad_norm=2.96756649017334, loss=1.1192331314086914
I0304 20:28:28.379186 139758026090240 logging_writer.py:48] [422000] global_step=422000, grad_norm=3.213559627532959, loss=2.679837942123413
I0304 20:29:13.318163 139758009304832 logging_writer.py:48] [422100] global_step=422100, grad_norm=3.342984914779663, loss=2.7201521396636963
I0304 20:29:58.058367 139758026090240 logging_writer.py:48] [422200] global_step=422200, grad_norm=3.4116904735565186, loss=2.8404903411865234
I0304 20:30:43.006842 139758009304832 logging_writer.py:48] [422300] global_step=422300, grad_norm=2.9181363582611084, loss=1.9862548112869263
I0304 20:31:05.724565 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:31:16.688406 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:31:44.362969 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:31:45.996388 139953291118400 submission_runner.py:411] Time since start: 203746.17s, 	Step: 422352, 	{'train/accuracy': 0.8893554210662842, 'train/loss': 0.4090215563774109, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 187826.50917100906, 'total_duration': 203746.17261266708, 'accumulated_submission_time': 187826.50917100906, 'accumulated_eval_time': 15865.375450849533, 'accumulated_logging_time': 32.78850722312927}
I0304 20:31:46.094896 139758026090240 logging_writer.py:48] [422352] accumulated_eval_time=15865.375451, accumulated_logging_time=32.788507, accumulated_submission_time=187826.509171, global_step=422352, preemption_count=0, score=187826.509171, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=203746.172613, train/accuracy=0.889355, train/loss=0.409022, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:32:05.450859 139758009304832 logging_writer.py:48] [422400] global_step=422400, grad_norm=3.2964141368865967, loss=2.7655224800109863
I0304 20:32:48.342855 139758026090240 logging_writer.py:48] [422500] global_step=422500, grad_norm=3.0958635807037354, loss=1.2023274898529053
I0304 20:33:33.215764 139758009304832 logging_writer.py:48] [422600] global_step=422600, grad_norm=5.921454906463623, loss=1.2151330709457397
I0304 20:34:18.467041 139758026090240 logging_writer.py:48] [422700] global_step=422700, grad_norm=2.984484910964966, loss=1.864546298980713
I0304 20:35:03.514435 139758009304832 logging_writer.py:48] [422800] global_step=422800, grad_norm=2.8924074172973633, loss=1.006462812423706
I0304 20:35:48.506172 139758026090240 logging_writer.py:48] [422900] global_step=422900, grad_norm=3.2121119499206543, loss=1.5497008562088013
I0304 20:36:33.688015 139758009304832 logging_writer.py:48] [423000] global_step=423000, grad_norm=3.6247081756591797, loss=3.1266422271728516
I0304 20:37:18.863122 139758026090240 logging_writer.py:48] [423100] global_step=423100, grad_norm=3.0161101818084717, loss=1.2300996780395508
I0304 20:38:03.829960 139758009304832 logging_writer.py:48] [423200] global_step=423200, grad_norm=3.3616204261779785, loss=1.3003120422363281
I0304 20:38:46.092868 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:38:57.224871 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:39:25.300456 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:39:26.934400 139953291118400 submission_runner.py:411] Time since start: 204207.11s, 	Step: 423296, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.4170146882534027, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 188246.44891786575, 'total_duration': 204207.1106221676, 'accumulated_submission_time': 188246.44891786575, 'accumulated_eval_time': 15906.216959238052, 'accumulated_logging_time': 32.89739751815796}
I0304 20:39:27.048107 139758026090240 logging_writer.py:48] [423296] accumulated_eval_time=15906.216959, accumulated_logging_time=32.897398, accumulated_submission_time=188246.448918, global_step=423296, preemption_count=0, score=188246.448918, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=204207.110622, train/accuracy=0.887734, train/loss=0.417015, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:39:29.051877 139758009304832 logging_writer.py:48] [423300] global_step=423300, grad_norm=3.0905864238739014, loss=1.293381690979004
I0304 20:40:09.925384 139758026090240 logging_writer.py:48] [423400] global_step=423400, grad_norm=2.8491549491882324, loss=1.661327600479126
I0304 20:40:54.617698 139758009304832 logging_writer.py:48] [423500] global_step=423500, grad_norm=2.943516254425049, loss=1.6239789724349976
I0304 20:41:39.476231 139758026090240 logging_writer.py:48] [423600] global_step=423600, grad_norm=3.720634698867798, loss=3.228584051132202
I0304 20:42:24.676143 139758009304832 logging_writer.py:48] [423700] global_step=423700, grad_norm=3.196563243865967, loss=1.180580735206604
I0304 20:43:09.511742 139758026090240 logging_writer.py:48] [423800] global_step=423800, grad_norm=3.393373489379883, loss=2.300231456756592
I0304 20:43:54.533330 139758009304832 logging_writer.py:48] [423900] global_step=423900, grad_norm=3.189270257949829, loss=1.080474853515625
I0304 20:44:39.581592 139758026090240 logging_writer.py:48] [424000] global_step=424000, grad_norm=3.238250732421875, loss=1.121226191520691
I0304 20:45:24.762910 139758009304832 logging_writer.py:48] [424100] global_step=424100, grad_norm=3.1353397369384766, loss=1.6732425689697266
I0304 20:46:09.836830 139758026090240 logging_writer.py:48] [424200] global_step=424200, grad_norm=3.0428342819213867, loss=1.254460096359253
I0304 20:46:27.323148 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:46:39.211532 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:47:01.374782 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:47:03.016799 139953291118400 submission_runner.py:411] Time since start: 204663.19s, 	Step: 424240, 	{'train/accuracy': 0.8865820169448853, 'train/loss': 0.41705602407455444, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 188666.66090917587, 'total_duration': 204663.19302153587, 'accumulated_submission_time': 188666.66090917587, 'accumulated_eval_time': 15941.91059589386, 'accumulated_logging_time': 33.02621150016785}
I0304 20:47:03.115006 139758009304832 logging_writer.py:48] [424240] accumulated_eval_time=15941.910596, accumulated_logging_time=33.026212, accumulated_submission_time=188666.660909, global_step=424240, preemption_count=0, score=188666.660909, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=204663.193022, train/accuracy=0.886582, train/loss=0.417056, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:47:27.215391 139758026090240 logging_writer.py:48] [424300] global_step=424300, grad_norm=3.0561699867248535, loss=1.455535888671875
I0304 20:48:11.655479 139758009304832 logging_writer.py:48] [424400] global_step=424400, grad_norm=3.1439130306243896, loss=2.7208943367004395
I0304 20:48:56.518049 139758026090240 logging_writer.py:48] [424500] global_step=424500, grad_norm=2.9275856018066406, loss=1.1838616132736206
I0304 20:49:41.734855 139758009304832 logging_writer.py:48] [424600] global_step=424600, grad_norm=3.225245475769043, loss=1.1956273317337036
I0304 20:50:26.669249 139758026090240 logging_writer.py:48] [424700] global_step=424700, grad_norm=3.333502769470215, loss=2.7383036613464355
I0304 20:51:11.644797 139758009304832 logging_writer.py:48] [424800] global_step=424800, grad_norm=3.3380093574523926, loss=1.1561338901519775
I0304 20:51:56.611870 139758026090240 logging_writer.py:48] [424900] global_step=424900, grad_norm=3.163132429122925, loss=1.0655721426010132
I0304 20:52:41.577663 139758009304832 logging_writer.py:48] [425000] global_step=425000, grad_norm=3.213257074356079, loss=1.9595683813095093
I0304 20:53:26.692657 139758026090240 logging_writer.py:48] [425100] global_step=425100, grad_norm=3.2008681297302246, loss=1.7681171894073486
I0304 20:54:03.398847 139953291118400 spec.py:321] Evaluating on the training split.
I0304 20:54:14.528948 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 20:54:41.694866 139953291118400 spec.py:349] Evaluating on the test split.
I0304 20:54:43.331909 139953291118400 submission_runner.py:411] Time since start: 205123.51s, 	Step: 425183, 	{'train/accuracy': 0.8876562118530273, 'train/loss': 0.41626375913619995, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 189086.88722491264, 'total_duration': 205123.508122921, 'accumulated_submission_time': 189086.88722491264, 'accumulated_eval_time': 15981.843644618988, 'accumulated_logging_time': 33.13454604148865}
I0304 20:54:43.430700 139758009304832 logging_writer.py:48] [425183] accumulated_eval_time=15981.843645, accumulated_logging_time=33.134546, accumulated_submission_time=189086.887225, global_step=425183, preemption_count=0, score=189086.887225, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=205123.508123, train/accuracy=0.887656, train/loss=0.416264, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 20:54:50.536673 139758026090240 logging_writer.py:48] [425200] global_step=425200, grad_norm=3.3951613903045654, loss=1.5038800239562988
I0304 20:55:32.205025 139758009304832 logging_writer.py:48] [425300] global_step=425300, grad_norm=3.765378952026367, loss=2.8398451805114746
I0304 20:56:17.938121 139758026090240 logging_writer.py:48] [425400] global_step=425400, grad_norm=3.085047960281372, loss=1.0704269409179688
I0304 20:57:04.086684 139758009304832 logging_writer.py:48] [425500] global_step=425500, grad_norm=3.956204891204834, loss=3.2555878162384033
I0304 20:57:49.352786 139758026090240 logging_writer.py:48] [425600] global_step=425600, grad_norm=3.382291555404663, loss=2.873131275177002
I0304 20:58:34.527203 139758009304832 logging_writer.py:48] [425700] global_step=425700, grad_norm=3.052359104156494, loss=1.1541386842727661
I0304 20:59:19.850064 139758026090240 logging_writer.py:48] [425800] global_step=425800, grad_norm=3.284850597381592, loss=1.9778363704681396
I0304 21:00:05.421016 139758009304832 logging_writer.py:48] [425900] global_step=425900, grad_norm=2.838495969772339, loss=1.0785325765609741
I0304 21:00:50.655555 139758026090240 logging_writer.py:48] [426000] global_step=426000, grad_norm=2.8697094917297363, loss=1.2624965906143188
I0304 21:01:35.846525 139758009304832 logging_writer.py:48] [426100] global_step=426100, grad_norm=3.592130184173584, loss=1.1315317153930664
I0304 21:01:43.680814 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:01:54.643345 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:02:26.986904 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:02:28.608734 139953291118400 submission_runner.py:411] Time since start: 205588.78s, 	Step: 426119, 	{'train/accuracy': 0.8857812285423279, 'train/loss': 0.4212409257888794, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 189507.0796597004, 'total_duration': 205588.78497099876, 'accumulated_submission_time': 189507.0796597004, 'accumulated_eval_time': 16026.771565198898, 'accumulated_logging_time': 33.24440002441406}
I0304 21:02:28.689874 139758026090240 logging_writer.py:48] [426119] accumulated_eval_time=16026.771565, accumulated_logging_time=33.244400, accumulated_submission_time=189507.079660, global_step=426119, preemption_count=0, score=189507.079660, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=205588.784971, train/accuracy=0.885781, train/loss=0.421241, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:03:01.051672 139758009304832 logging_writer.py:48] [426200] global_step=426200, grad_norm=2.9913954734802246, loss=2.2793431282043457
I0304 21:03:45.441136 139758026090240 logging_writer.py:48] [426300] global_step=426300, grad_norm=3.2205469608306885, loss=1.2918143272399902
I0304 21:04:30.868735 139758009304832 logging_writer.py:48] [426400] global_step=426400, grad_norm=3.096688985824585, loss=2.2738535404205322
I0304 21:05:16.346616 139758026090240 logging_writer.py:48] [426500] global_step=426500, grad_norm=3.32609486579895, loss=1.1628086566925049
I0304 21:06:01.147742 139758009304832 logging_writer.py:48] [426600] global_step=426600, grad_norm=3.417917490005493, loss=1.3817784786224365
I0304 21:06:46.283275 139758026090240 logging_writer.py:48] [426700] global_step=426700, grad_norm=2.975496768951416, loss=2.0934996604919434
I0304 21:07:31.259186 139758009304832 logging_writer.py:48] [426800] global_step=426800, grad_norm=2.7867162227630615, loss=1.351943016052246
I0304 21:08:16.033329 139758026090240 logging_writer.py:48] [426900] global_step=426900, grad_norm=2.9717001914978027, loss=1.082861065864563
I0304 21:09:01.002877 139758009304832 logging_writer.py:48] [427000] global_step=427000, grad_norm=3.553739309310913, loss=1.0824791193008423
I0304 21:09:29.035114 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:09:40.080028 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:10:03.705551 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:10:05.338351 139953291118400 submission_runner.py:411] Time since start: 206045.51s, 	Step: 427064, 	{'train/accuracy': 0.8869726657867432, 'train/loss': 0.4184642732143402, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 189927.36776423454, 'total_duration': 206045.51457452774, 'accumulated_submission_time': 189927.36776423454, 'accumulated_eval_time': 16063.074809551239, 'accumulated_logging_time': 33.3340208530426}
I0304 21:10:05.436978 139758026090240 logging_writer.py:48] [427064] accumulated_eval_time=16063.074810, accumulated_logging_time=33.334021, accumulated_submission_time=189927.367764, global_step=427064, preemption_count=0, score=189927.367764, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=206045.514575, train/accuracy=0.886973, train/loss=0.418464, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:10:20.061509 139758009304832 logging_writer.py:48] [427100] global_step=427100, grad_norm=3.93906307220459, loss=1.9084445238113403
I0304 21:11:02.636097 139758026090240 logging_writer.py:48] [427200] global_step=427200, grad_norm=3.024524688720703, loss=1.0818086862564087
I0304 21:11:47.550419 139758009304832 logging_writer.py:48] [427300] global_step=427300, grad_norm=2.7847213745117188, loss=1.539055347442627
I0304 21:12:32.625764 139758026090240 logging_writer.py:48] [427400] global_step=427400, grad_norm=3.3197147846221924, loss=2.606235980987549
I0304 21:13:17.572750 139758009304832 logging_writer.py:48] [427500] global_step=427500, grad_norm=3.0990424156188965, loss=1.0679064989089966
I0304 21:14:02.607923 139758026090240 logging_writer.py:48] [427600] global_step=427600, grad_norm=3.4352023601531982, loss=1.3715158700942993
I0304 21:14:47.601928 139758009304832 logging_writer.py:48] [427700] global_step=427700, grad_norm=3.1465349197387695, loss=2.7703135013580322
I0304 21:15:32.799170 139758026090240 logging_writer.py:48] [427800] global_step=427800, grad_norm=4.293600559234619, loss=3.195239305496216
I0304 21:16:18.164948 139758009304832 logging_writer.py:48] [427900] global_step=427900, grad_norm=3.101545572280884, loss=1.6204657554626465
I0304 21:17:03.236658 139758026090240 logging_writer.py:48] [428000] global_step=428000, grad_norm=2.930168867111206, loss=1.0754597187042236
I0304 21:17:05.725475 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:17:17.170035 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:17:39.473146 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:17:41.103065 139953291118400 submission_runner.py:411] Time since start: 206501.28s, 	Step: 428007, 	{'train/accuracy': 0.8869726657867432, 'train/loss': 0.42542001605033875, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 190347.5967078209, 'total_duration': 206501.27928853035, 'accumulated_submission_time': 190347.5967078209, 'accumulated_eval_time': 16098.452381849289, 'accumulated_logging_time': 33.44491386413574}
I0304 21:17:41.202948 139758009304832 logging_writer.py:48] [428007] accumulated_eval_time=16098.452382, accumulated_logging_time=33.444914, accumulated_submission_time=190347.596708, global_step=428007, preemption_count=0, score=190347.596708, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=206501.279289, train/accuracy=0.886973, train/loss=0.425420, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:18:19.488424 139758026090240 logging_writer.py:48] [428100] global_step=428100, grad_norm=2.889043092727661, loss=1.1529110670089722
I0304 21:19:04.650222 139758009304832 logging_writer.py:48] [428200] global_step=428200, grad_norm=3.001220941543579, loss=1.1178158521652222
I0304 21:19:49.565907 139758026090240 logging_writer.py:48] [428300] global_step=428300, grad_norm=3.213782787322998, loss=1.0472444295883179
I0304 21:20:34.797273 139758009304832 logging_writer.py:48] [428400] global_step=428400, grad_norm=2.9743268489837646, loss=2.0581929683685303
I0304 21:21:19.813699 139758026090240 logging_writer.py:48] [428500] global_step=428500, grad_norm=2.8707194328308105, loss=2.1414999961853027
I0304 21:22:04.713222 139758009304832 logging_writer.py:48] [428600] global_step=428600, grad_norm=3.8041248321533203, loss=3.069824695587158
I0304 21:22:49.591490 139758026090240 logging_writer.py:48] [428700] global_step=428700, grad_norm=2.8968985080718994, loss=1.1484946012496948
I0304 21:23:34.672285 139758009304832 logging_writer.py:48] [428800] global_step=428800, grad_norm=3.0092272758483887, loss=1.2929096221923828
I0304 21:24:19.548079 139758026090240 logging_writer.py:48] [428900] global_step=428900, grad_norm=3.1970787048339844, loss=2.507802963256836
I0304 21:24:41.383970 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:24:52.293706 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:25:26.298977 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:25:27.919340 139953291118400 submission_runner.py:411] Time since start: 206968.10s, 	Step: 428950, 	{'train/accuracy': 0.8871093392372131, 'train/loss': 0.42015156149864197, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 190767.7202951908, 'total_duration': 206968.0955746174, 'accumulated_submission_time': 190767.7202951908, 'accumulated_eval_time': 16144.987778663635, 'accumulated_logging_time': 33.55448365211487}
I0304 21:25:27.999781 139758009304832 logging_writer.py:48] [428950] accumulated_eval_time=16144.987779, accumulated_logging_time=33.554484, accumulated_submission_time=190767.720295, global_step=428950, preemption_count=0, score=190767.720295, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=206968.095575, train/accuracy=0.887109, train/loss=0.420152, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:25:48.117673 139758026090240 logging_writer.py:48] [429000] global_step=429000, grad_norm=2.9376614093780518, loss=1.4079934358596802
I0304 21:26:30.566446 139758009304832 logging_writer.py:48] [429100] global_step=429100, grad_norm=3.2369837760925293, loss=1.259286880493164
I0304 21:27:15.929785 139758026090240 logging_writer.py:48] [429200] global_step=429200, grad_norm=2.950098991394043, loss=1.9266297817230225
I0304 21:28:00.916533 139758009304832 logging_writer.py:48] [429300] global_step=429300, grad_norm=3.1914451122283936, loss=2.462576150894165
I0304 21:28:45.965318 139758026090240 logging_writer.py:48] [429400] global_step=429400, grad_norm=3.2832868099212646, loss=1.171217441558838
I0304 21:29:30.856204 139758009304832 logging_writer.py:48] [429500] global_step=429500, grad_norm=3.18768572807312, loss=1.2343889474868774
I0304 21:30:15.766959 139758026090240 logging_writer.py:48] [429600] global_step=429600, grad_norm=3.372218608856201, loss=1.1286243200302124
I0304 21:31:00.715096 139758009304832 logging_writer.py:48] [429700] global_step=429700, grad_norm=3.035525321960449, loss=1.0638831853866577
I0304 21:31:45.627384 139758026090240 logging_writer.py:48] [429800] global_step=429800, grad_norm=3.4713568687438965, loss=2.988065719604492
I0304 21:32:27.957053 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:32:38.869264 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:33:02.250964 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:33:03.896075 139953291118400 submission_runner.py:411] Time since start: 207424.07s, 	Step: 429896, 	{'train/accuracy': 0.8857030868530273, 'train/loss': 0.42628130316734314, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 191187.62019228935, 'total_duration': 207424.07229161263, 'accumulated_submission_time': 191187.62019228935, 'accumulated_eval_time': 16180.926808357239, 'accumulated_logging_time': 33.644153118133545}
I0304 21:33:03.994906 139758009304832 logging_writer.py:48] [429896] accumulated_eval_time=16180.926808, accumulated_logging_time=33.644153, accumulated_submission_time=191187.620192, global_step=429896, preemption_count=0, score=191187.620192, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=207424.072292, train/accuracy=0.885703, train/loss=0.426281, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:33:05.975374 139758026090240 logging_writer.py:48] [429900] global_step=429900, grad_norm=2.8795478343963623, loss=1.044663429260254
I0304 21:33:46.624867 139758009304832 logging_writer.py:48] [430000] global_step=430000, grad_norm=3.2004668712615967, loss=1.0843658447265625
I0304 21:34:31.539205 139758026090240 logging_writer.py:48] [430100] global_step=430100, grad_norm=3.1778082847595215, loss=1.5736123323440552
I0304 21:35:16.696719 139758009304832 logging_writer.py:48] [430200] global_step=430200, grad_norm=2.981459617614746, loss=1.7539048194885254
I0304 21:36:01.737042 139758026090240 logging_writer.py:48] [430300] global_step=430300, grad_norm=3.2658233642578125, loss=2.831775665283203
I0304 21:36:47.235340 139758009304832 logging_writer.py:48] [430400] global_step=430400, grad_norm=3.107280731201172, loss=1.615236759185791
I0304 21:37:32.039054 139758026090240 logging_writer.py:48] [430500] global_step=430500, grad_norm=3.6550450325012207, loss=1.1495989561080933
I0304 21:38:16.875074 139758009304832 logging_writer.py:48] [430600] global_step=430600, grad_norm=3.142235279083252, loss=1.5272955894470215
I0304 21:39:01.659182 139758026090240 logging_writer.py:48] [430700] global_step=430700, grad_norm=3.1702091693878174, loss=1.1568951606750488
I0304 21:39:46.543287 139758009304832 logging_writer.py:48] [430800] global_step=430800, grad_norm=2.982508420944214, loss=1.46842360496521
I0304 21:40:04.339053 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:40:15.900172 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:40:39.149808 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:40:40.776444 139953291118400 submission_runner.py:411] Time since start: 207880.95s, 	Step: 430841, 	{'train/accuracy': 0.8873046636581421, 'train/loss': 0.41407421231269836, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 191607.90561056137, 'total_duration': 207880.95266985893, 'accumulated_submission_time': 191607.90561056137, 'accumulated_eval_time': 16217.364193677902, 'accumulated_logging_time': 33.7524573802948}
I0304 21:40:40.873351 139758026090240 logging_writer.py:48] [430841] accumulated_eval_time=16217.364194, accumulated_logging_time=33.752457, accumulated_submission_time=191607.905611, global_step=430841, preemption_count=0, score=191607.905611, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=207880.952670, train/accuracy=0.887305, train/loss=0.414074, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:41:04.573256 139758009304832 logging_writer.py:48] [430900] global_step=430900, grad_norm=2.989779472351074, loss=1.8150393962860107
I0304 21:41:48.773622 139758026090240 logging_writer.py:48] [431000] global_step=431000, grad_norm=2.9309916496276855, loss=1.3895589113235474
I0304 21:42:33.835323 139758009304832 logging_writer.py:48] [431100] global_step=431100, grad_norm=3.2786734104156494, loss=1.1091142892837524
I0304 21:43:18.691364 139758026090240 logging_writer.py:48] [431200] global_step=431200, grad_norm=4.079798698425293, loss=2.803182363510132
I0304 21:44:03.685379 139758009304832 logging_writer.py:48] [431300] global_step=431300, grad_norm=3.9044532775878906, loss=3.347773551940918
I0304 21:44:48.549211 139758026090240 logging_writer.py:48] [431400] global_step=431400, grad_norm=3.075540065765381, loss=2.61881947517395
I0304 21:45:33.651393 139758009304832 logging_writer.py:48] [431500] global_step=431500, grad_norm=3.1762290000915527, loss=1.015241265296936
I0304 21:46:18.633819 139758026090240 logging_writer.py:48] [431600] global_step=431600, grad_norm=2.9349124431610107, loss=1.0902057886123657
I0304 21:47:04.006143 139758009304832 logging_writer.py:48] [431700] global_step=431700, grad_norm=2.886606216430664, loss=1.077798843383789
I0304 21:47:40.907876 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:47:51.903717 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:48:21.803376 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:48:23.436669 139953291118400 submission_runner.py:411] Time since start: 208343.61s, 	Step: 431784, 	{'train/accuracy': 0.8875781297683716, 'train/loss': 0.4148840606212616, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 192027.8820848465, 'total_duration': 208343.61290049553, 'accumulated_submission_time': 192027.8820848465, 'accumulated_eval_time': 16259.892963647842, 'accumulated_logging_time': 33.86008358001709}
I0304 21:48:23.516915 139758026090240 logging_writer.py:48] [431784] accumulated_eval_time=16259.892964, accumulated_logging_time=33.860084, accumulated_submission_time=192027.882085, global_step=431784, preemption_count=0, score=192027.882085, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=208343.612900, train/accuracy=0.887578, train/loss=0.414884, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:48:30.226612 139758009304832 logging_writer.py:48] [431800] global_step=431800, grad_norm=3.668905258178711, loss=1.2036141157150269
I0304 21:49:10.843561 139758026090240 logging_writer.py:48] [431900] global_step=431900, grad_norm=3.377274513244629, loss=1.206872820854187
I0304 21:49:55.499303 139758009304832 logging_writer.py:48] [432000] global_step=432000, grad_norm=6.035220623016357, loss=3.143765926361084
I0304 21:50:40.561794 139758026090240 logging_writer.py:48] [432100] global_step=432100, grad_norm=3.2952229976654053, loss=1.211817741394043
I0304 21:51:25.806249 139758009304832 logging_writer.py:48] [432200] global_step=432200, grad_norm=3.4020187854766846, loss=1.420127034187317
I0304 21:52:10.452074 139758026090240 logging_writer.py:48] [432300] global_step=432300, grad_norm=3.107161045074463, loss=1.2015182971954346
I0304 21:52:55.270230 139758009304832 logging_writer.py:48] [432400] global_step=432400, grad_norm=3.075911521911621, loss=2.046231985092163
I0304 21:53:40.099425 139758026090240 logging_writer.py:48] [432500] global_step=432500, grad_norm=2.9882779121398926, loss=1.4040850400924683
I0304 21:54:24.907850 139758009304832 logging_writer.py:48] [432600] global_step=432600, grad_norm=2.998436212539673, loss=1.1100716590881348
I0304 21:55:10.241128 139758026090240 logging_writer.py:48] [432700] global_step=432700, grad_norm=3.297156572341919, loss=1.1231330633163452
I0304 21:55:23.476014 139953291118400 spec.py:321] Evaluating on the training split.
I0304 21:55:34.356033 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 21:55:56.747199 139953291118400 spec.py:349] Evaluating on the test split.
I0304 21:55:58.384723 139953291118400 submission_runner.py:411] Time since start: 208798.56s, 	Step: 432731, 	{'train/accuracy': 0.8882616758346558, 'train/loss': 0.42090845108032227, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 192447.78442716599, 'total_duration': 208798.56092476845, 'accumulated_submission_time': 192447.78442716599, 'accumulated_eval_time': 16294.801630496979, 'accumulated_logging_time': 33.95030069351196}
I0304 21:55:58.524703 139758009304832 logging_writer.py:48] [432731] accumulated_eval_time=16294.801630, accumulated_logging_time=33.950301, accumulated_submission_time=192447.784427, global_step=432731, preemption_count=0, score=192447.784427, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=208798.560925, train/accuracy=0.888262, train/loss=0.420908, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 21:56:26.187961 139758026090240 logging_writer.py:48] [432800] global_step=432800, grad_norm=3.1889894008636475, loss=2.191483974456787
I0304 21:57:10.889115 139758009304832 logging_writer.py:48] [432900] global_step=432900, grad_norm=3.5501770973205566, loss=3.1587138175964355
I0304 21:57:55.906848 139758026090240 logging_writer.py:48] [433000] global_step=433000, grad_norm=3.199989080429077, loss=1.09336519241333
I0304 21:58:41.016296 139758009304832 logging_writer.py:48] [433100] global_step=433100, grad_norm=3.6039512157440186, loss=2.076241970062256
I0304 21:59:26.203817 139758026090240 logging_writer.py:48] [433200] global_step=433200, grad_norm=3.109917402267456, loss=2.5737385749816895
I0304 22:00:10.908226 139758009304832 logging_writer.py:48] [433300] global_step=433300, grad_norm=3.487837553024292, loss=2.617194414138794
I0304 22:00:55.945522 139758026090240 logging_writer.py:48] [433400] global_step=433400, grad_norm=3.5346412658691406, loss=3.118138074874878
I0304 22:01:41.021445 139758009304832 logging_writer.py:48] [433500] global_step=433500, grad_norm=3.0325698852539062, loss=1.1939589977264404
I0304 22:02:26.221232 139758026090240 logging_writer.py:48] [433600] global_step=433600, grad_norm=3.5270683765411377, loss=1.8658382892608643
I0304 22:02:58.725948 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:03:10.144779 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:03:34.504416 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:03:36.142403 139953291118400 submission_runner.py:411] Time since start: 209256.32s, 	Step: 433674, 	{'train/accuracy': 0.8856444954872131, 'train/loss': 0.42597851157188416, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 192867.92846989632, 'total_duration': 209256.31863760948, 'accumulated_submission_time': 192867.92846989632, 'accumulated_eval_time': 16332.21807217598, 'accumulated_logging_time': 34.1000452041626}
I0304 22:03:36.220714 139758009304832 logging_writer.py:48] [433674] accumulated_eval_time=16332.218072, accumulated_logging_time=34.100045, accumulated_submission_time=192867.928470, global_step=433674, preemption_count=0, score=192867.928470, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=209256.318638, train/accuracy=0.885644, train/loss=0.425979, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:03:46.880351 139758026090240 logging_writer.py:48] [433700] global_step=433700, grad_norm=3.6703615188598633, loss=3.2550902366638184
I0304 22:04:28.212820 139758009304832 logging_writer.py:48] [433800] global_step=433800, grad_norm=3.3757526874542236, loss=1.056885838508606
I0304 22:05:13.616289 139758026090240 logging_writer.py:48] [433900] global_step=433900, grad_norm=4.1286845207214355, loss=3.336625099182129
I0304 22:05:58.766345 139758009304832 logging_writer.py:48] [434000] global_step=434000, grad_norm=3.392425298690796, loss=2.5944926738739014
I0304 22:06:44.305449 139758026090240 logging_writer.py:48] [434100] global_step=434100, grad_norm=2.9803903102874756, loss=1.7736293077468872
I0304 22:07:29.907851 139758009304832 logging_writer.py:48] [434200] global_step=434200, grad_norm=3.017057180404663, loss=1.3817449808120728
I0304 22:08:14.935924 139758026090240 logging_writer.py:48] [434300] global_step=434300, grad_norm=3.0383918285369873, loss=1.1046650409698486
I0304 22:09:00.275788 139758009304832 logging_writer.py:48] [434400] global_step=434400, grad_norm=2.8279104232788086, loss=1.1270066499710083
I0304 22:09:45.141777 139758026090240 logging_writer.py:48] [434500] global_step=434500, grad_norm=3.039674758911133, loss=2.3617773056030273
I0304 22:10:30.226415 139758009304832 logging_writer.py:48] [434600] global_step=434600, grad_norm=2.974344491958618, loss=2.136897325515747
I0304 22:10:36.393768 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:10:47.441210 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:11:08.558979 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:11:10.196645 139953291118400 submission_runner.py:411] Time since start: 209710.37s, 	Step: 434615, 	{'train/accuracy': 0.8866601586341858, 'train/loss': 0.4217454791069031, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 193288.04555511475, 'total_duration': 209710.3728477955, 'accumulated_submission_time': 193288.04555511475, 'accumulated_eval_time': 16366.020912408829, 'accumulated_logging_time': 34.186774015426636}
I0304 22:11:10.299715 139758026090240 logging_writer.py:48] [434615] accumulated_eval_time=16366.020912, accumulated_logging_time=34.186774, accumulated_submission_time=193288.045555, global_step=434615, preemption_count=0, score=193288.045555, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=209710.372848, train/accuracy=0.886660, train/loss=0.421745, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:11:45.093524 139758009304832 logging_writer.py:48] [434700] global_step=434700, grad_norm=3.0548319816589355, loss=1.2472537755966187
I0304 22:12:30.023621 139758026090240 logging_writer.py:48] [434800] global_step=434800, grad_norm=4.226931571960449, loss=2.9865100383758545
I0304 22:13:15.133401 139758009304832 logging_writer.py:48] [434900] global_step=434900, grad_norm=3.4116437435150146, loss=3.1678459644317627
I0304 22:14:00.500679 139758026090240 logging_writer.py:48] [435000] global_step=435000, grad_norm=3.225940704345703, loss=1.1079106330871582
I0304 22:14:45.401640 139758009304832 logging_writer.py:48] [435100] global_step=435100, grad_norm=3.153846263885498, loss=1.1475961208343506
I0304 22:15:30.419779 139758026090240 logging_writer.py:48] [435200] global_step=435200, grad_norm=3.211914300918579, loss=1.2763806581497192
I0304 22:16:15.602974 139758009304832 logging_writer.py:48] [435300] global_step=435300, grad_norm=3.699530601501465, loss=3.2578976154327393
I0304 22:17:00.778505 139758026090240 logging_writer.py:48] [435400] global_step=435400, grad_norm=3.06834077835083, loss=1.271971344947815
I0304 22:17:45.758057 139758009304832 logging_writer.py:48] [435500] global_step=435500, grad_norm=3.4987006187438965, loss=2.819154739379883
I0304 22:18:10.474128 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:18:21.669098 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:18:52.238885 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:18:53.864577 139953291118400 submission_runner.py:411] Time since start: 210174.04s, 	Step: 435556, 	{'train/accuracy': 0.8860546946525574, 'train/loss': 0.4153732657432556, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 193708.16326212883, 'total_duration': 210174.040797472, 'accumulated_submission_time': 193708.16326212883, 'accumulated_eval_time': 16409.411342144012, 'accumulated_logging_time': 34.299379110336304}
I0304 22:18:53.951631 139758026090240 logging_writer.py:48] [435556] accumulated_eval_time=16409.411342, accumulated_logging_time=34.299379, accumulated_submission_time=193708.163262, global_step=435556, preemption_count=0, score=193708.163262, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=210174.040797, train/accuracy=0.886055, train/loss=0.415373, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:19:11.705952 139758009304832 logging_writer.py:48] [435600] global_step=435600, grad_norm=2.8859355449676514, loss=1.9387538433074951
I0304 22:19:53.819228 139758026090240 logging_writer.py:48] [435700] global_step=435700, grad_norm=3.1352360248565674, loss=1.4479037523269653
I0304 22:20:38.936754 139758009304832 logging_writer.py:48] [435800] global_step=435800, grad_norm=2.9952967166900635, loss=1.1802983283996582
I0304 22:21:24.239845 139758026090240 logging_writer.py:48] [435900] global_step=435900, grad_norm=3.033555030822754, loss=1.336106538772583
I0304 22:22:09.468522 139758009304832 logging_writer.py:48] [436000] global_step=436000, grad_norm=3.120267868041992, loss=2.0821313858032227
I0304 22:22:54.533976 139758026090240 logging_writer.py:48] [436100] global_step=436100, grad_norm=3.22314715385437, loss=2.446669816970825
I0304 22:23:39.606079 139758009304832 logging_writer.py:48] [436200] global_step=436200, grad_norm=3.1138999462127686, loss=1.0310288667678833
I0304 22:24:24.519537 139758026090240 logging_writer.py:48] [436300] global_step=436300, grad_norm=3.019666910171509, loss=1.6921213865280151
I0304 22:25:10.006927 139758009304832 logging_writer.py:48] [436400] global_step=436400, grad_norm=3.1001741886138916, loss=1.097365379333496
I0304 22:25:54.077126 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:26:05.091043 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:26:29.886531 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:26:31.541965 139953291118400 submission_runner.py:411] Time since start: 210631.72s, 	Step: 436500, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.41910815238952637, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 194128.2306342125, 'total_duration': 210631.71815299988, 'accumulated_submission_time': 194128.2306342125, 'accumulated_eval_time': 16446.87612438202, 'accumulated_logging_time': 34.396831035614014}
I0304 22:26:31.642398 139758026090240 logging_writer.py:48] [436500] accumulated_eval_time=16446.876124, accumulated_logging_time=34.396831, accumulated_submission_time=194128.230634, global_step=436500, preemption_count=0, score=194128.230634, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=210631.718153, train/accuracy=0.888418, train/loss=0.419108, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:26:32.039237 139758009304832 logging_writer.py:48] [436500] global_step=436500, grad_norm=3.2789506912231445, loss=2.5960605144500732
I0304 22:27:11.946288 139758026090240 logging_writer.py:48] [436600] global_step=436600, grad_norm=3.1563000679016113, loss=1.2802908420562744
I0304 22:27:56.794864 139758009304832 logging_writer.py:48] [436700] global_step=436700, grad_norm=3.0202975273132324, loss=2.3059756755828857
I0304 22:28:42.122229 139758026090240 logging_writer.py:48] [436800] global_step=436800, grad_norm=2.9565799236297607, loss=1.2234601974487305
I0304 22:29:27.229633 139758009304832 logging_writer.py:48] [436900] global_step=436900, grad_norm=3.1400022506713867, loss=1.288328766822815
I0304 22:30:11.840055 139758026090240 logging_writer.py:48] [437000] global_step=437000, grad_norm=2.8940627574920654, loss=1.1714755296707153
I0304 22:30:56.523858 139758009304832 logging_writer.py:48] [437100] global_step=437100, grad_norm=4.698123931884766, loss=3.1749215126037598
I0304 22:31:41.506783 139758026090240 logging_writer.py:48] [437200] global_step=437200, grad_norm=3.121953010559082, loss=1.6425771713256836
I0304 22:32:26.375145 139758009304832 logging_writer.py:48] [437300] global_step=437300, grad_norm=3.5879387855529785, loss=2.8809030055999756
I0304 22:33:11.390934 139758026090240 logging_writer.py:48] [437400] global_step=437400, grad_norm=3.3919379711151123, loss=1.8052048683166504
I0304 22:33:31.755587 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:33:43.175929 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:34:07.013284 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:34:08.640953 139953291118400 submission_runner.py:411] Time since start: 211088.82s, 	Step: 437447, 	{'train/accuracy': 0.8879492282867432, 'train/loss': 0.42137834429740906, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 194548.28590345383, 'total_duration': 211088.81717801094, 'accumulated_submission_time': 194548.28590345383, 'accumulated_eval_time': 16483.761477947235, 'accumulated_logging_time': 34.50777578353882}
I0304 22:34:08.741858 139758009304832 logging_writer.py:48] [437447] accumulated_eval_time=16483.761478, accumulated_logging_time=34.507776, accumulated_submission_time=194548.285903, global_step=437447, preemption_count=0, score=194548.285903, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=211088.817178, train/accuracy=0.887949, train/loss=0.421378, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:34:30.081367 139758026090240 logging_writer.py:48] [437500] global_step=437500, grad_norm=3.6810011863708496, loss=3.0698659420013428
I0304 22:35:13.854515 139758009304832 logging_writer.py:48] [437600] global_step=437600, grad_norm=3.1312403678894043, loss=1.0996484756469727
I0304 22:35:58.896740 139758026090240 logging_writer.py:48] [437700] global_step=437700, grad_norm=3.0999057292938232, loss=1.9253627061843872
I0304 22:36:44.150317 139758009304832 logging_writer.py:48] [437800] global_step=437800, grad_norm=2.978318691253662, loss=2.0553488731384277
I0304 22:37:29.559497 139758026090240 logging_writer.py:48] [437900] global_step=437900, grad_norm=3.0658724308013916, loss=1.2287453413009644
I0304 22:38:14.373859 139758009304832 logging_writer.py:48] [438000] global_step=438000, grad_norm=3.0507214069366455, loss=1.2354694604873657
I0304 22:38:59.460611 139758026090240 logging_writer.py:48] [438100] global_step=438100, grad_norm=3.3284261226654053, loss=1.1251288652420044
I0304 22:39:44.691014 139758009304832 logging_writer.py:48] [438200] global_step=438200, grad_norm=3.8244283199310303, loss=3.247114419937134
I0304 22:40:29.990791 139758026090240 logging_writer.py:48] [438300] global_step=438300, grad_norm=3.0066797733306885, loss=1.4646074771881104
I0304 22:41:08.852447 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:41:20.141156 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:41:52.069990 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:41:53.701432 139953291118400 submission_runner.py:411] Time since start: 211553.88s, 	Step: 438388, 	{'train/accuracy': 0.8866991996765137, 'train/loss': 0.4202461242675781, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 194968.3395268917, 'total_duration': 211553.87763905525, 'accumulated_submission_time': 194968.3395268917, 'accumulated_eval_time': 16528.610441684723, 'accumulated_logging_time': 34.61800146102905}
I0304 22:41:53.799046 139758009304832 logging_writer.py:48] [438388] accumulated_eval_time=16528.610442, accumulated_logging_time=34.618001, accumulated_submission_time=194968.339527, global_step=438388, preemption_count=0, score=194968.339527, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=211553.877639, train/accuracy=0.886699, train/loss=0.420246, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:41:58.931077 139758026090240 logging_writer.py:48] [438400] global_step=438400, grad_norm=3.2709953784942627, loss=2.374866247177124
I0304 22:42:39.737111 139758009304832 logging_writer.py:48] [438500] global_step=438500, grad_norm=3.250582695007324, loss=1.6403791904449463
I0304 22:43:24.751243 139758026090240 logging_writer.py:48] [438600] global_step=438600, grad_norm=2.905799150466919, loss=1.0340514183044434
I0304 22:44:09.904099 139758009304832 logging_writer.py:48] [438700] global_step=438700, grad_norm=3.1841769218444824, loss=1.6428186893463135
I0304 22:44:55.377020 139758026090240 logging_writer.py:48] [438800] global_step=438800, grad_norm=3.3072078227996826, loss=1.2086364030838013
I0304 22:45:40.250018 139758009304832 logging_writer.py:48] [438900] global_step=438900, grad_norm=3.2827835083007812, loss=1.1715221405029297
I0304 22:46:25.573224 139758026090240 logging_writer.py:48] [439000] global_step=439000, grad_norm=3.031184434890747, loss=1.3816394805908203
I0304 22:47:10.397523 139758009304832 logging_writer.py:48] [439100] global_step=439100, grad_norm=3.053572177886963, loss=1.5192162990570068
I0304 22:47:55.522948 139758026090240 logging_writer.py:48] [439200] global_step=439200, grad_norm=3.3962807655334473, loss=2.883955955505371
I0304 22:48:40.520820 139758009304832 logging_writer.py:48] [439300] global_step=439300, grad_norm=3.2923502922058105, loss=1.7562332153320312
I0304 22:48:54.040829 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:49:05.351304 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:49:35.439744 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:49:37.063079 139953291118400 submission_runner.py:411] Time since start: 212017.24s, 	Step: 439332, 	{'train/accuracy': 0.8890234231948853, 'train/loss': 0.4170263707637787, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 195388.52269601822, 'total_duration': 212017.23931241035, 'accumulated_submission_time': 195388.52269601822, 'accumulated_eval_time': 16571.6326918602, 'accumulated_logging_time': 34.726662397384644}
I0304 22:49:37.143846 139758026090240 logging_writer.py:48] [439332] accumulated_eval_time=16571.632692, accumulated_logging_time=34.726662, accumulated_submission_time=195388.522696, global_step=439332, preemption_count=0, score=195388.522696, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=212017.239312, train/accuracy=0.889023, train/loss=0.417026, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:50:04.384644 139758009304832 logging_writer.py:48] [439400] global_step=439400, grad_norm=3.0520074367523193, loss=1.071052074432373
I0304 22:50:47.946537 139758026090240 logging_writer.py:48] [439500] global_step=439500, grad_norm=3.222508430480957, loss=1.1513190269470215
I0304 22:51:32.973167 139758009304832 logging_writer.py:48] [439600] global_step=439600, grad_norm=3.0394701957702637, loss=1.605240821838379
I0304 22:52:18.153097 139758026090240 logging_writer.py:48] [439700] global_step=439700, grad_norm=3.379850387573242, loss=2.2903060913085938
I0304 22:53:03.087660 139758009304832 logging_writer.py:48] [439800] global_step=439800, grad_norm=3.4498066902160645, loss=1.0621581077575684
I0304 22:53:47.861928 139758026090240 logging_writer.py:48] [439900] global_step=439900, grad_norm=4.434455394744873, loss=3.1956787109375
I0304 22:54:32.739900 139758009304832 logging_writer.py:48] [440000] global_step=440000, grad_norm=2.8977017402648926, loss=1.2769547700881958
I0304 22:55:18.058838 139758026090240 logging_writer.py:48] [440100] global_step=440100, grad_norm=3.145190715789795, loss=0.976956844329834
I0304 22:56:02.851078 139758009304832 logging_writer.py:48] [440200] global_step=440200, grad_norm=2.9168291091918945, loss=1.0868958234786987
I0304 22:56:37.214920 139953291118400 spec.py:321] Evaluating on the training split.
I0304 22:56:48.484798 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 22:57:13.778143 139953291118400 spec.py:349] Evaluating on the test split.
I0304 22:57:15.424683 139953291118400 submission_runner.py:411] Time since start: 212475.60s, 	Step: 440278, 	{'train/accuracy': 0.8864843845367432, 'train/loss': 0.4210885167121887, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 195808.53741788864, 'total_duration': 212475.60088419914, 'accumulated_submission_time': 195808.53741788864, 'accumulated_eval_time': 16609.84241771698, 'accumulated_logging_time': 34.8164746761322}
I0304 22:57:15.521505 139758026090240 logging_writer.py:48] [440278] accumulated_eval_time=16609.842418, accumulated_logging_time=34.816475, accumulated_submission_time=195808.537418, global_step=440278, preemption_count=0, score=195808.537418, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=212475.600884, train/accuracy=0.886484, train/loss=0.421089, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 22:57:24.606653 139758009304832 logging_writer.py:48] [440300] global_step=440300, grad_norm=2.734809637069702, loss=1.1106237173080444
I0304 22:58:07.056619 139758026090240 logging_writer.py:48] [440400] global_step=440400, grad_norm=3.210097312927246, loss=1.2386808395385742
I0304 22:58:51.749768 139758009304832 logging_writer.py:48] [440500] global_step=440500, grad_norm=3.000368595123291, loss=1.1948796510696411
I0304 22:59:36.835587 139758026090240 logging_writer.py:48] [440600] global_step=440600, grad_norm=3.1355819702148438, loss=1.2010443210601807
I0304 23:00:21.944167 139758009304832 logging_writer.py:48] [440700] global_step=440700, grad_norm=2.8551833629608154, loss=1.5614039897918701
I0304 23:01:06.863789 139758026090240 logging_writer.py:48] [440800] global_step=440800, grad_norm=3.266352653503418, loss=2.7618324756622314
I0304 23:01:51.894665 139758009304832 logging_writer.py:48] [440900] global_step=440900, grad_norm=3.1632299423217773, loss=1.173873782157898
I0304 23:02:37.019235 139758026090240 logging_writer.py:48] [441000] global_step=441000, grad_norm=3.447348117828369, loss=2.998960494995117
I0304 23:03:21.905597 139758009304832 logging_writer.py:48] [441100] global_step=441100, grad_norm=3.043003559112549, loss=1.5205682516098022
I0304 23:04:06.955754 139758026090240 logging_writer.py:48] [441200] global_step=441200, grad_norm=3.5160629749298096, loss=1.2675150632858276
I0304 23:04:15.669810 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:04:26.897565 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:05:00.907809 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:05:02.536716 139953291118400 submission_runner.py:411] Time since start: 212942.71s, 	Step: 441221, 	{'train/accuracy': 0.8875195384025574, 'train/loss': 0.4173341393470764, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 196228.62652277946, 'total_duration': 212942.71294903755, 'accumulated_submission_time': 196228.62652277946, 'accumulated_eval_time': 16656.709317207336, 'accumulated_logging_time': 34.92500853538513}
I0304 23:05:02.616898 139758009304832 logging_writer.py:48] [441221] accumulated_eval_time=16656.709317, accumulated_logging_time=34.925009, accumulated_submission_time=196228.626523, global_step=441221, preemption_count=0, score=196228.626523, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=212942.712949, train/accuracy=0.887520, train/loss=0.417334, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:05:34.172863 139758026090240 logging_writer.py:48] [441300] global_step=441300, grad_norm=3.6485185623168945, loss=2.933255910873413
I0304 23:06:19.109959 139758009304832 logging_writer.py:48] [441400] global_step=441400, grad_norm=3.393861770629883, loss=1.1702239513397217
I0304 23:07:04.716127 139758026090240 logging_writer.py:48] [441500] global_step=441500, grad_norm=3.0438737869262695, loss=1.1730413436889648
I0304 23:07:50.177303 139758009304832 logging_writer.py:48] [441600] global_step=441600, grad_norm=3.3519113063812256, loss=2.7866244316101074
I0304 23:08:35.463027 139758026090240 logging_writer.py:48] [441700] global_step=441700, grad_norm=3.723545789718628, loss=2.7622766494750977
I0304 23:09:20.737344 139758009304832 logging_writer.py:48] [441800] global_step=441800, grad_norm=2.9082040786743164, loss=1.142990231513977
I0304 23:10:06.441217 139758026090240 logging_writer.py:48] [441900] global_step=441900, grad_norm=3.8426105976104736, loss=3.3634462356567383
I0304 23:10:51.593906 139758009304832 logging_writer.py:48] [442000] global_step=442000, grad_norm=3.249011754989624, loss=1.5586309432983398
I0304 23:11:36.591730 139758026090240 logging_writer.py:48] [442100] global_step=442100, grad_norm=3.2977418899536133, loss=2.8328051567077637
I0304 23:12:02.677675 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:12:13.964586 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:12:45.234289 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:12:46.851501 139953291118400 submission_runner.py:411] Time since start: 213407.03s, 	Step: 442159, 	{'train/accuracy': 0.8889257907867432, 'train/loss': 0.4166601002216339, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 196648.6313741207, 'total_duration': 213407.027728796, 'accumulated_submission_time': 196648.6313741207, 'accumulated_eval_time': 16700.883150815964, 'accumulated_logging_time': 35.01406455039978}
I0304 23:12:46.931604 139758009304832 logging_writer.py:48] [442159] accumulated_eval_time=16700.883151, accumulated_logging_time=35.014065, accumulated_submission_time=196648.631374, global_step=442159, preemption_count=0, score=196648.631374, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=213407.027729, train/accuracy=0.888926, train/loss=0.416660, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:13:03.512884 139758026090240 logging_writer.py:48] [442200] global_step=442200, grad_norm=3.35882306098938, loss=1.1795073747634888
I0304 23:13:46.017537 139758009304832 logging_writer.py:48] [442300] global_step=442300, grad_norm=3.5151357650756836, loss=1.227839469909668
I0304 23:14:31.098749 139758026090240 logging_writer.py:48] [442400] global_step=442400, grad_norm=3.120816707611084, loss=1.3063859939575195
I0304 23:15:16.369016 139758009304832 logging_writer.py:48] [442500] global_step=442500, grad_norm=3.5113797187805176, loss=1.1981371641159058
I0304 23:16:01.434540 139758026090240 logging_writer.py:48] [442600] global_step=442600, grad_norm=3.261058807373047, loss=1.772208571434021
I0304 23:16:46.522281 139758009304832 logging_writer.py:48] [442700] global_step=442700, grad_norm=3.2657718658447266, loss=1.1211791038513184
I0304 23:17:31.803032 139758026090240 logging_writer.py:48] [442800] global_step=442800, grad_norm=2.885399580001831, loss=1.927018165588379
I0304 23:18:17.314852 139758009304832 logging_writer.py:48] [442900] global_step=442900, grad_norm=2.9434168338775635, loss=1.373317837715149
I0304 23:19:02.220011 139758026090240 logging_writer.py:48] [443000] global_step=443000, grad_norm=3.0219430923461914, loss=1.5402181148529053
I0304 23:19:47.477711 139758009304832 logging_writer.py:48] [443100] global_step=443100, grad_norm=3.292246103286743, loss=1.304605484008789
I0304 23:19:47.490099 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:19:59.163427 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:20:29.608134 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:20:31.233288 139953291118400 submission_runner.py:411] Time since start: 213871.41s, 	Step: 443101, 	{'train/accuracy': 0.8854296803474426, 'train/loss': 0.422122985124588, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 197069.13176488876, 'total_duration': 213871.40952277184, 'accumulated_submission_time': 197069.13176488876, 'accumulated_eval_time': 16744.626331090927, 'accumulated_logging_time': 35.10526466369629}
I0304 23:20:31.314468 139758026090240 logging_writer.py:48] [443101] accumulated_eval_time=16744.626331, accumulated_logging_time=35.105265, accumulated_submission_time=197069.131765, global_step=443101, preemption_count=0, score=197069.131765, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=213871.409523, train/accuracy=0.885430, train/loss=0.422123, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:21:11.814394 139758009304832 logging_writer.py:48] [443200] global_step=443200, grad_norm=3.0601046085357666, loss=1.763468861579895
I0304 23:21:56.549618 139758026090240 logging_writer.py:48] [443300] global_step=443300, grad_norm=3.2861833572387695, loss=1.186335802078247
I0304 23:22:41.794833 139758009304832 logging_writer.py:48] [443400] global_step=443400, grad_norm=3.349464178085327, loss=2.989811420440674
I0304 23:23:27.122466 139758026090240 logging_writer.py:48] [443500] global_step=443500, grad_norm=3.045346975326538, loss=1.7284554243087769
I0304 23:24:12.084696 139758009304832 logging_writer.py:48] [443600] global_step=443600, grad_norm=3.2995193004608154, loss=1.064436674118042
I0304 23:24:57.016182 139758026090240 logging_writer.py:48] [443700] global_step=443700, grad_norm=3.4524824619293213, loss=1.1909656524658203
I0304 23:25:42.146302 139758009304832 logging_writer.py:48] [443800] global_step=443800, grad_norm=3.0283987522125244, loss=1.6720163822174072
I0304 23:26:27.524716 139758026090240 logging_writer.py:48] [443900] global_step=443900, grad_norm=3.0545997619628906, loss=1.1612027883529663
I0304 23:27:12.596839 139758009304832 logging_writer.py:48] [444000] global_step=444000, grad_norm=3.7506959438323975, loss=3.2946550846099854
I0304 23:27:31.264093 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:27:42.618210 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:28:10.020764 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:28:11.652611 139953291118400 submission_runner.py:411] Time since start: 214331.83s, 	Step: 444043, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.42198917269706726, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 197489.02456712723, 'total_duration': 214331.82880949974, 'accumulated_submission_time': 197489.02456712723, 'accumulated_eval_time': 16785.014815568924, 'accumulated_logging_time': 35.19585084915161}
I0304 23:28:11.734300 139758026090240 logging_writer.py:48] [444043] accumulated_eval_time=16785.014816, accumulated_logging_time=35.195851, accumulated_submission_time=197489.024567, global_step=444043, preemption_count=0, score=197489.024567, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=214331.828809, train/accuracy=0.888418, train/loss=0.421989, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:28:34.621378 139758009304832 logging_writer.py:48] [444100] global_step=444100, grad_norm=3.8301525115966797, loss=2.9999961853027344
I0304 23:29:18.378109 139758026090240 logging_writer.py:48] [444200] global_step=444200, grad_norm=3.1570422649383545, loss=1.0655304193496704
I0304 23:30:03.291726 139758009304832 logging_writer.py:48] [444300] global_step=444300, grad_norm=3.9214274883270264, loss=1.152442216873169
I0304 23:30:48.220643 139758026090240 logging_writer.py:48] [444400] global_step=444400, grad_norm=3.2040910720825195, loss=1.1597962379455566
I0304 23:31:33.169495 139758009304832 logging_writer.py:48] [444500] global_step=444500, grad_norm=2.9606785774230957, loss=1.0097354650497437
I0304 23:32:18.008136 139758026090240 logging_writer.py:48] [444600] global_step=444600, grad_norm=3.190863609313965, loss=1.3802103996276855
I0304 23:33:03.110499 139758009304832 logging_writer.py:48] [444700] global_step=444700, grad_norm=4.209822654724121, loss=3.1363983154296875
I0304 23:33:48.020265 139758026090240 logging_writer.py:48] [444800] global_step=444800, grad_norm=3.1572229862213135, loss=1.251400351524353
I0304 23:34:33.027202 139758009304832 logging_writer.py:48] [444900] global_step=444900, grad_norm=3.1621603965759277, loss=1.0786497592926025
I0304 23:35:11.836816 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:35:23.239375 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:35:53.138278 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:35:54.759997 139953291118400 submission_runner.py:411] Time since start: 214794.94s, 	Step: 444988, 	{'train/accuracy': 0.8905078172683716, 'train/loss': 0.4116933345794678, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 197909.07106089592, 'total_duration': 214794.9362232685, 'accumulated_submission_time': 197909.07106089592, 'accumulated_eval_time': 16827.93798494339, 'accumulated_logging_time': 35.28695893287659}
I0304 23:35:54.843989 139758026090240 logging_writer.py:48] [444988] accumulated_eval_time=16827.937985, accumulated_logging_time=35.286959, accumulated_submission_time=197909.071061, global_step=444988, preemption_count=0, score=197909.071061, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=214794.936223, train/accuracy=0.890508, train/loss=0.411693, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:35:59.973817 139758009304832 logging_writer.py:48] [445000] global_step=445000, grad_norm=2.983025550842285, loss=1.0793557167053223
I0304 23:36:40.997183 139758026090240 logging_writer.py:48] [445100] global_step=445100, grad_norm=3.4446218013763428, loss=3.1874842643737793
I0304 23:37:25.652769 139758009304832 logging_writer.py:48] [445200] global_step=445200, grad_norm=3.27522349357605, loss=2.7971079349517822
I0304 23:38:10.558458 139758026090240 logging_writer.py:48] [445300] global_step=445300, grad_norm=3.032089948654175, loss=2.3244733810424805
I0304 23:38:55.824763 139758009304832 logging_writer.py:48] [445400] global_step=445400, grad_norm=3.1207242012023926, loss=2.326892614364624
I0304 23:39:40.991312 139758026090240 logging_writer.py:48] [445500] global_step=445500, grad_norm=3.1975693702697754, loss=2.2628612518310547
I0304 23:40:26.387182 139758009304832 logging_writer.py:48] [445600] global_step=445600, grad_norm=3.194979190826416, loss=2.9030818939208984
I0304 23:41:11.608662 139758026090240 logging_writer.py:48] [445700] global_step=445700, grad_norm=3.0593810081481934, loss=1.0273255109786987
I0304 23:41:56.898839 139758009304832 logging_writer.py:48] [445800] global_step=445800, grad_norm=2.9846811294555664, loss=1.2368394136428833
I0304 23:42:41.989630 139758026090240 logging_writer.py:48] [445900] global_step=445900, grad_norm=3.2363152503967285, loss=1.2217376232147217
I0304 23:42:55.051938 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:43:06.204311 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:43:36.398406 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:43:38.016912 139953291118400 submission_runner.py:411] Time since start: 215258.19s, 	Step: 445931, 	{'train/accuracy': 0.8903515338897705, 'train/loss': 0.40741580724716187, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 198329.22270989418, 'total_duration': 215258.19314956665, 'accumulated_submission_time': 198329.22270989418, 'accumulated_eval_time': 16870.90295481682, 'accumulated_logging_time': 35.37960910797119}
I0304 23:43:38.099492 139758009304832 logging_writer.py:48] [445931] accumulated_eval_time=16870.902955, accumulated_logging_time=35.379609, accumulated_submission_time=198329.222710, global_step=445931, preemption_count=0, score=198329.222710, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=215258.193150, train/accuracy=0.890352, train/loss=0.407416, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:44:05.716907 139758026090240 logging_writer.py:48] [446000] global_step=446000, grad_norm=2.8842666149139404, loss=1.6350178718566895
I0304 23:44:49.607189 139758009304832 logging_writer.py:48] [446100] global_step=446100, grad_norm=3.184847354888916, loss=1.2010278701782227
I0304 23:45:34.601093 139758026090240 logging_writer.py:48] [446200] global_step=446200, grad_norm=2.988748073577881, loss=1.00504469871521
I0304 23:46:20.130065 139758009304832 logging_writer.py:48] [446300] global_step=446300, grad_norm=3.0921337604522705, loss=1.0344016551971436
I0304 23:47:05.354209 139758026090240 logging_writer.py:48] [446400] global_step=446400, grad_norm=3.8613014221191406, loss=2.8711466789245605
I0304 23:47:50.290893 139758009304832 logging_writer.py:48] [446500] global_step=446500, grad_norm=3.2427804470062256, loss=1.3047326803207397
I0304 23:48:35.145411 139758026090240 logging_writer.py:48] [446600] global_step=446600, grad_norm=3.041318416595459, loss=1.1214970350265503
I0304 23:49:20.103699 139758009304832 logging_writer.py:48] [446700] global_step=446700, grad_norm=3.7157084941864014, loss=3.2640860080718994
I0304 23:50:04.792607 139758026090240 logging_writer.py:48] [446800] global_step=446800, grad_norm=3.1781809329986572, loss=2.656266212463379
I0304 23:50:38.463135 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:50:49.888912 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:51:21.244902 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:51:22.864315 139953291118400 submission_runner.py:411] Time since start: 215723.04s, 	Step: 446876, 	{'train/accuracy': 0.885546863079071, 'train/loss': 0.42118769884109497, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 198749.53037691116, 'total_duration': 215723.04054903984, 'accumulated_submission_time': 198749.53037691116, 'accumulated_eval_time': 16915.30412220955, 'accumulated_logging_time': 35.47115755081177}
I0304 23:51:22.947685 139758009304832 logging_writer.py:48] [446876] accumulated_eval_time=16915.304122, accumulated_logging_time=35.471158, accumulated_submission_time=198749.530377, global_step=446876, preemption_count=0, score=198749.530377, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=215723.040549, train/accuracy=0.885547, train/loss=0.421188, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:51:32.804611 139758026090240 logging_writer.py:48] [446900] global_step=446900, grad_norm=3.389744281768799, loss=2.3957180976867676
I0304 23:52:14.163298 139758009304832 logging_writer.py:48] [447000] global_step=447000, grad_norm=3.6634926795959473, loss=1.2078992128372192
I0304 23:52:58.940781 139758026090240 logging_writer.py:48] [447100] global_step=447100, grad_norm=3.254228353500366, loss=1.2277235984802246
I0304 23:53:44.030437 139758009304832 logging_writer.py:48] [447200] global_step=447200, grad_norm=3.208285331726074, loss=1.0623975992202759
I0304 23:54:29.057417 139758026090240 logging_writer.py:48] [447300] global_step=447300, grad_norm=4.4315104484558105, loss=3.043344736099243
I0304 23:55:13.903941 139758009304832 logging_writer.py:48] [447400] global_step=447400, grad_norm=3.0536158084869385, loss=1.0937292575836182
I0304 23:55:58.590867 139758026090240 logging_writer.py:48] [447500] global_step=447500, grad_norm=3.1526618003845215, loss=1.1352338790893555
I0304 23:56:43.681087 139758009304832 logging_writer.py:48] [447600] global_step=447600, grad_norm=3.9278571605682373, loss=3.2531650066375732
I0304 23:57:28.472742 139758026090240 logging_writer.py:48] [447700] global_step=447700, grad_norm=2.9081335067749023, loss=1.3309346437454224
I0304 23:58:13.455225 139758009304832 logging_writer.py:48] [447800] global_step=447800, grad_norm=3.7984776496887207, loss=3.221560478210449
I0304 23:58:22.993327 139953291118400 spec.py:321] Evaluating on the training split.
I0304 23:58:34.870534 139953291118400 spec.py:333] Evaluating on the validation split.
I0304 23:58:58.260582 139953291118400 spec.py:349] Evaluating on the test split.
I0304 23:58:59.899181 139953291118400 submission_runner.py:411] Time since start: 216180.08s, 	Step: 447823, 	{'train/accuracy': 0.887011706829071, 'train/loss': 0.41940078139305115, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 199169.5191576481, 'total_duration': 216180.07539200783, 'accumulated_submission_time': 199169.5191576481, 'accumulated_eval_time': 16952.20995235443, 'accumulated_logging_time': 35.563923597335815}
I0304 23:58:59.993415 139758026090240 logging_writer.py:48] [447823] accumulated_eval_time=16952.209952, accumulated_logging_time=35.563924, accumulated_submission_time=199169.519158, global_step=447823, preemption_count=0, score=199169.519158, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=216180.075392, train/accuracy=0.887012, train/loss=0.419401, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0304 23:59:31.212188 139758009304832 logging_writer.py:48] [447900] global_step=447900, grad_norm=3.1553776264190674, loss=1.2878178358078003
I0305 00:00:16.042662 139758026090240 logging_writer.py:48] [448000] global_step=448000, grad_norm=3.168912172317505, loss=2.0478830337524414
I0305 00:01:01.456797 139758009304832 logging_writer.py:48] [448100] global_step=448100, grad_norm=3.3300817012786865, loss=1.6745773553848267
I0305 00:01:46.857968 139758026090240 logging_writer.py:48] [448200] global_step=448200, grad_norm=3.4764435291290283, loss=1.3347892761230469
I0305 00:02:32.097229 139758009304832 logging_writer.py:48] [448300] global_step=448300, grad_norm=2.7370290756225586, loss=1.3203446865081787
I0305 00:03:17.523184 139758026090240 logging_writer.py:48] [448400] global_step=448400, grad_norm=3.1790192127227783, loss=1.211623191833496
I0305 00:04:02.884819 139758009304832 logging_writer.py:48] [448500] global_step=448500, grad_norm=3.788313865661621, loss=1.1099694967269897
I0305 00:04:47.972935 139758026090240 logging_writer.py:48] [448600] global_step=448600, grad_norm=2.991260290145874, loss=1.109115481376648
I0305 00:05:33.235701 139758009304832 logging_writer.py:48] [448700] global_step=448700, grad_norm=3.2778143882751465, loss=1.0289397239685059
I0305 00:05:59.903418 139953291118400 spec.py:321] Evaluating on the training split.
I0305 00:06:11.568021 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 00:06:36.433403 139953291118400 spec.py:349] Evaluating on the test split.
I0305 00:06:38.069894 139953291118400 submission_runner.py:411] Time since start: 216638.25s, 	Step: 448761, 	{'train/accuracy': 0.8859765529632568, 'train/loss': 0.42136865854263306, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 199589.37185049057, 'total_duration': 216638.24611639977, 'accumulated_submission_time': 199589.37185049057, 'accumulated_eval_time': 16990.376428365707, 'accumulated_logging_time': 35.668083906173706}
I0305 00:06:38.152956 139758026090240 logging_writer.py:48] [448761] accumulated_eval_time=16990.376428, accumulated_logging_time=35.668084, accumulated_submission_time=199589.371850, global_step=448761, preemption_count=0, score=199589.371850, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=216638.246116, train/accuracy=0.885977, train/loss=0.421369, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 00:06:53.943979 139758009304832 logging_writer.py:48] [448800] global_step=448800, grad_norm=3.191732883453369, loss=1.3511146306991577
I0305 00:07:36.465379 139758026090240 logging_writer.py:48] [448900] global_step=448900, grad_norm=3.1428489685058594, loss=1.1320903301239014
I0305 00:08:21.642336 139758009304832 logging_writer.py:48] [449000] global_step=449000, grad_norm=3.118044853210449, loss=1.9194700717926025
I0305 00:09:06.946896 139758026090240 logging_writer.py:48] [449100] global_step=449100, grad_norm=3.2568588256835938, loss=2.9836673736572266
I0305 00:09:52.385541 139758009304832 logging_writer.py:48] [449200] global_step=449200, grad_norm=3.2927823066711426, loss=1.1180630922317505
I0305 00:10:37.341440 139758026090240 logging_writer.py:48] [449300] global_step=449300, grad_norm=2.8590757846832275, loss=1.0489076375961304
I0305 00:11:22.422911 139758009304832 logging_writer.py:48] [449400] global_step=449400, grad_norm=3.4345624446868896, loss=2.752434730529785
I0305 00:12:07.792757 139758026090240 logging_writer.py:48] [449500] global_step=449500, grad_norm=2.9503393173217773, loss=1.9492037296295166
I0305 00:12:52.963350 139758009304832 logging_writer.py:48] [449600] global_step=449600, grad_norm=3.7031779289245605, loss=2.9185447692871094
I0305 00:13:38.256772 139758026090240 logging_writer.py:48] [449700] global_step=449700, grad_norm=3.253852605819702, loss=1.139000415802002
I0305 00:13:38.269063 139953291118400 spec.py:321] Evaluating on the training split.
I0305 00:13:49.512665 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 00:14:21.493606 139953291118400 spec.py:349] Evaluating on the test split.
I0305 00:14:23.118125 139953291118400 submission_runner.py:411] Time since start: 217103.29s, 	Step: 449701, 	{'train/accuracy': 0.8870702981948853, 'train/loss': 0.4166412651538849, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 200009.43146896362, 'total_duration': 217103.29435062408, 'accumulated_submission_time': 200009.43146896362, 'accumulated_eval_time': 17035.225475549698, 'accumulated_logging_time': 35.76078271865845}
I0305 00:14:23.200817 139758009304832 logging_writer.py:48] [449701] accumulated_eval_time=17035.225476, accumulated_logging_time=35.760783, accumulated_submission_time=200009.431469, global_step=449701, preemption_count=0, score=200009.431469, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=217103.294351, train/accuracy=0.887070, train/loss=0.416641, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 00:15:03.227620 139758026090240 logging_writer.py:48] [449800] global_step=449800, grad_norm=3.3067471981048584, loss=1.0794320106506348
I0305 00:15:47.963528 139758009304832 logging_writer.py:48] [449900] global_step=449900, grad_norm=5.1982316970825195, loss=2.734863519668579
I0305 00:16:33.041511 139758026090240 logging_writer.py:48] [450000] global_step=450000, grad_norm=3.157736301422119, loss=1.0847325325012207
I0305 00:17:18.371618 139758009304832 logging_writer.py:48] [450100] global_step=450100, grad_norm=3.0996856689453125, loss=1.12459397315979
I0305 00:18:03.198882 139758026090240 logging_writer.py:48] [450200] global_step=450200, grad_norm=3.2973382472991943, loss=1.1461536884307861
I0305 00:18:48.049031 139758009304832 logging_writer.py:48] [450300] global_step=450300, grad_norm=3.188840389251709, loss=1.148141622543335
I0305 00:19:33.389577 139758026090240 logging_writer.py:48] [450400] global_step=450400, grad_norm=3.1365654468536377, loss=1.1521728038787842
I0305 00:20:18.334451 139758009304832 logging_writer.py:48] [450500] global_step=450500, grad_norm=3.143437147140503, loss=2.7728447914123535
I0305 00:21:03.616144 139758026090240 logging_writer.py:48] [450600] global_step=450600, grad_norm=3.1253137588500977, loss=1.2294061183929443
I0305 00:21:23.245754 139953291118400 spec.py:321] Evaluating on the training split.
I0305 00:21:34.445531 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 00:21:58.162352 139953291118400 spec.py:349] Evaluating on the test split.
I0305 00:21:59.798274 139953291118400 submission_runner.py:411] Time since start: 217559.97s, 	Step: 450645, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.41623160243034363, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 200429.42027401924, 'total_duration': 217559.97447752953, 'accumulated_submission_time': 200429.42027401924, 'accumulated_eval_time': 17071.777951478958, 'accumulated_logging_time': 35.85300397872925}
I0305 00:21:59.902282 139758009304832 logging_writer.py:48] [450645] accumulated_eval_time=17071.777951, accumulated_logging_time=35.853004, accumulated_submission_time=200429.420274, global_step=450645, preemption_count=0, score=200429.420274, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=217559.974478, train/accuracy=0.888144, train/loss=0.416232, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 00:22:22.005648 139758026090240 logging_writer.py:48] [450700] global_step=450700, grad_norm=3.009626865386963, loss=2.2040343284606934
I0305 00:23:06.391583 139758009304832 logging_writer.py:48] [450800] global_step=450800, grad_norm=3.2552783489227295, loss=1.2564500570297241
I0305 00:23:51.275130 139758026090240 logging_writer.py:48] [450900] global_step=450900, grad_norm=3.0642263889312744, loss=1.0315881967544556
I0305 00:24:36.434202 139758009304832 logging_writer.py:48] [451000] global_step=451000, grad_norm=2.9147796630859375, loss=1.4299525022506714
I0305 00:25:21.299788 139758026090240 logging_writer.py:48] [451100] global_step=451100, grad_norm=3.831662654876709, loss=3.310534954071045
I0305 00:26:06.250640 139758009304832 logging_writer.py:48] [451200] global_step=451200, grad_norm=3.1736061573028564, loss=1.08625066280365
I0305 00:26:51.629707 139758026090240 logging_writer.py:48] [451300] global_step=451300, grad_norm=3.1254072189331055, loss=1.1314212083816528
I0305 00:27:36.645410 139758009304832 logging_writer.py:48] [451400] global_step=451400, grad_norm=3.2080183029174805, loss=2.5796053409576416
I0305 00:28:21.641245 139758026090240 logging_writer.py:48] [451500] global_step=451500, grad_norm=3.1823933124542236, loss=1.170103907585144
I0305 00:28:59.912095 139953291118400 spec.py:321] Evaluating on the training split.
I0305 00:29:11.263548 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 00:29:48.530050 139953291118400 spec.py:349] Evaluating on the test split.
I0305 00:29:50.149269 139953291118400 submission_runner.py:411] Time since start: 218030.33s, 	Step: 451587, 	{'train/accuracy': 0.8881054520606995, 'train/loss': 0.42101213335990906, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 200849.3727684021, 'total_duration': 218030.3255007267, 'accumulated_submission_time': 200849.3727684021, 'accumulated_eval_time': 17122.015122890472, 'accumulated_logging_time': 35.96689581871033}
I0305 00:29:50.232672 139758009304832 logging_writer.py:48] [451587] accumulated_eval_time=17122.015123, accumulated_logging_time=35.966896, accumulated_submission_time=200849.372768, global_step=451587, preemption_count=0, score=200849.372768, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=218030.325501, train/accuracy=0.888105, train/loss=0.421012, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 00:29:55.751094 139758026090240 logging_writer.py:48] [451600] global_step=451600, grad_norm=3.126598834991455, loss=2.908416748046875
I0305 00:30:36.589908 139758009304832 logging_writer.py:48] [451700] global_step=451700, grad_norm=3.7970542907714844, loss=1.626603126525879
I0305 00:31:21.383820 139758026090240 logging_writer.py:48] [451800] global_step=451800, grad_norm=3.567800521850586, loss=3.1611907482147217
I0305 00:32:06.512724 139758009304832 logging_writer.py:48] [451900] global_step=451900, grad_norm=3.0283315181732178, loss=2.0121824741363525
I0305 00:32:51.703709 139758026090240 logging_writer.py:48] [452000] global_step=452000, grad_norm=3.102531909942627, loss=1.0976738929748535
I0305 00:33:36.681911 139758009304832 logging_writer.py:48] [452100] global_step=452100, grad_norm=3.0620036125183105, loss=1.136256217956543
I0305 00:34:21.585664 139758026090240 logging_writer.py:48] [452200] global_step=452200, grad_norm=3.3016011714935303, loss=1.0810725688934326
I0305 00:35:06.788912 139758009304832 logging_writer.py:48] [452300] global_step=452300, grad_norm=3.2278761863708496, loss=1.1367666721343994
I0305 00:35:51.498721 139758026090240 logging_writer.py:48] [452400] global_step=452400, grad_norm=3.393066167831421, loss=1.6145620346069336
I0305 00:36:36.802745 139758009304832 logging_writer.py:48] [452500] global_step=452500, grad_norm=3.2896039485931396, loss=2.901653289794922
I0305 00:36:50.391141 139953291118400 spec.py:321] Evaluating on the training split.
I0305 00:37:01.479608 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 00:37:24.201420 139953291118400 spec.py:349] Evaluating on the test split.
I0305 00:37:25.836572 139953291118400 submission_runner.py:411] Time since start: 218486.01s, 	Step: 452532, 	{'train/accuracy': 0.8839452862739563, 'train/loss': 0.4290750026702881, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 201269.47407794, 'total_duration': 218486.01278042793, 'accumulated_submission_time': 201269.47407794, 'accumulated_eval_time': 17157.460511684418, 'accumulated_logging_time': 36.06063795089722}
I0305 00:37:25.946654 139758026090240 logging_writer.py:48] [452532] accumulated_eval_time=17157.460512, accumulated_logging_time=36.060638, accumulated_submission_time=201269.474078, global_step=452532, preemption_count=0, score=201269.474078, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=218486.012780, train/accuracy=0.883945, train/loss=0.429075, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 00:37:53.427850 139758009304832 logging_writer.py:48] [452600] global_step=452600, grad_norm=3.3533809185028076, loss=2.9036097526550293
I0305 00:38:38.347358 139758026090240 logging_writer.py:48] [452700] global_step=452700, grad_norm=3.3196051120758057, loss=2.6187005043029785
I0305 00:39:23.323767 139758009304832 logging_writer.py:48] [452800] global_step=452800, grad_norm=3.5820493698120117, loss=2.758880615234375
I0305 00:40:08.747217 139758026090240 logging_writer.py:48] [452900] global_step=452900, grad_norm=3.0936615467071533, loss=1.1855100393295288
I0305 00:40:53.566434 139758009304832 logging_writer.py:48] [453000] global_step=453000, grad_norm=3.6970012187957764, loss=3.114351511001587
I0305 00:41:38.537116 139758026090240 logging_writer.py:48] [453100] global_step=453100, grad_norm=3.182631254196167, loss=1.242695689201355
I0305 00:42:23.485457 139758009304832 logging_writer.py:48] [453200] global_step=453200, grad_norm=2.8391311168670654, loss=0.9608082175254822
I0305 00:43:08.642176 139758026090240 logging_writer.py:48] [453300] global_step=453300, grad_norm=3.0533015727996826, loss=1.101497769355774
I0305 00:43:53.790045 139758009304832 logging_writer.py:48] [453400] global_step=453400, grad_norm=3.16510009765625, loss=1.607967734336853
I0305 00:44:26.003489 139953291118400 spec.py:321] Evaluating on the training split.
I0305 00:44:37.469670 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 00:45:02.990173 139953291118400 spec.py:349] Evaluating on the test split.
I0305 00:45:04.627240 139953291118400 submission_runner.py:411] Time since start: 218944.80s, 	Step: 453473, 	{'train/accuracy': 0.8886913657188416, 'train/loss': 0.4158783555030823, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 201689.47282075882, 'total_duration': 218944.8034465313, 'accumulated_submission_time': 201689.47282075882, 'accumulated_eval_time': 17196.084241628647, 'accumulated_logging_time': 36.18183422088623}
I0305 00:45:04.725972 139758026090240 logging_writer.py:48] [453473] accumulated_eval_time=17196.084242, accumulated_logging_time=36.181834, accumulated_submission_time=201689.472821, global_step=453473, preemption_count=0, score=201689.472821, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=218944.803447, train/accuracy=0.888691, train/loss=0.415878, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 00:45:15.788647 139758009304832 logging_writer.py:48] [453500] global_step=453500, grad_norm=3.356245517730713, loss=2.184924364089966
I0305 00:45:58.461609 139758026090240 logging_writer.py:48] [453600] global_step=453600, grad_norm=2.9218907356262207, loss=1.6048426628112793
I0305 00:46:43.642333 139758009304832 logging_writer.py:48] [453700] global_step=453700, grad_norm=3.1225693225860596, loss=1.1150673627853394
I0305 00:47:28.667035 139758026090240 logging_writer.py:48] [453800] global_step=453800, grad_norm=3.2055933475494385, loss=1.5816967487335205
I0305 00:48:13.905843 139758009304832 logging_writer.py:48] [453900] global_step=453900, grad_norm=3.00282883644104, loss=2.1080150604248047
I0305 00:48:58.620235 139758026090240 logging_writer.py:48] [454000] global_step=454000, grad_norm=3.3765642642974854, loss=3.0514631271362305
I0305 00:49:43.778245 139758009304832 logging_writer.py:48] [454100] global_step=454100, grad_norm=3.1706740856170654, loss=1.0858107805252075
I0305 00:50:29.104811 139758026090240 logging_writer.py:48] [454200] global_step=454200, grad_norm=3.055623769760132, loss=2.0222740173339844
I0305 00:51:13.999866 139758009304832 logging_writer.py:48] [454300] global_step=454300, grad_norm=3.0350024700164795, loss=1.156040072441101
I0305 00:51:59.027688 139758026090240 logging_writer.py:48] [454400] global_step=454400, grad_norm=3.0464487075805664, loss=1.6177787780761719
I0305 00:52:04.701826 139953291118400 spec.py:321] Evaluating on the training split.
I0305 00:52:15.551497 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 00:52:48.760235 139953291118400 spec.py:349] Evaluating on the test split.
I0305 00:52:50.384424 139953291118400 submission_runner.py:411] Time since start: 219410.56s, 	Step: 454414, 	{'train/accuracy': 0.8854491710662842, 'train/loss': 0.4210602045059204, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 202109.38947105408, 'total_duration': 219410.560652256, 'accumulated_submission_time': 202109.38947105408, 'accumulated_eval_time': 17241.766832351685, 'accumulated_logging_time': 36.29235625267029}
I0305 00:52:50.466023 139758009304832 logging_writer.py:48] [454414] accumulated_eval_time=17241.766832, accumulated_logging_time=36.292356, accumulated_submission_time=202109.389471, global_step=454414, preemption_count=0, score=202109.389471, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=219410.560652, train/accuracy=0.885449, train/loss=0.421060, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 00:53:24.883542 139758026090240 logging_writer.py:48] [454500] global_step=454500, grad_norm=3.5557570457458496, loss=2.488229274749756
I0305 00:54:08.801419 139758009304832 logging_writer.py:48] [454600] global_step=454600, grad_norm=3.262495517730713, loss=1.1579649448394775
I0305 00:54:53.906656 139758026090240 logging_writer.py:48] [454700] global_step=454700, grad_norm=2.9887800216674805, loss=1.9280081987380981
I0305 00:55:39.309005 139758009304832 logging_writer.py:48] [454800] global_step=454800, grad_norm=3.7014410495758057, loss=3.2594871520996094
I0305 00:56:24.440898 139758026090240 logging_writer.py:48] [454900] global_step=454900, grad_norm=2.9191462993621826, loss=2.0675621032714844
I0305 00:57:09.453516 139758009304832 logging_writer.py:48] [455000] global_step=455000, grad_norm=3.363849639892578, loss=1.1217939853668213
I0305 00:57:54.364636 139758026090240 logging_writer.py:48] [455100] global_step=455100, grad_norm=2.9764881134033203, loss=1.6889266967773438
I0305 00:58:39.596362 139758009304832 logging_writer.py:48] [455200] global_step=455200, grad_norm=3.2127346992492676, loss=1.1428616046905518
I0305 00:59:24.406543 139758026090240 logging_writer.py:48] [455300] global_step=455300, grad_norm=3.5788261890411377, loss=1.2305727005004883
I0305 00:59:50.619393 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:00:01.722197 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:00:25.267100 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:00:26.895247 139953291118400 submission_runner.py:411] Time since start: 219867.07s, 	Step: 455360, 	{'train/accuracy': 0.8898632526397705, 'train/loss': 0.41212984919548035, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 202529.48514270782, 'total_duration': 219867.0714662075, 'accumulated_submission_time': 202529.48514270782, 'accumulated_eval_time': 17278.042666196823, 'accumulated_logging_time': 36.3836932182312}
I0305 01:00:26.998735 139758009304832 logging_writer.py:48] [455360] accumulated_eval_time=17278.042666, accumulated_logging_time=36.383693, accumulated_submission_time=202529.485143, global_step=455360, preemption_count=0, score=202529.485143, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=219867.071466, train/accuracy=0.889863, train/loss=0.412130, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:00:43.201683 139758026090240 logging_writer.py:48] [455400] global_step=455400, grad_norm=3.1057143211364746, loss=1.0878479480743408
I0305 01:01:25.567172 139758009304832 logging_writer.py:48] [455500] global_step=455500, grad_norm=3.2993061542510986, loss=1.1895289421081543
I0305 01:02:10.358492 139758026090240 logging_writer.py:48] [455600] global_step=455600, grad_norm=3.72590708732605, loss=3.177701234817505
I0305 01:02:55.697721 139758009304832 logging_writer.py:48] [455700] global_step=455700, grad_norm=2.9393179416656494, loss=1.152458906173706
I0305 01:03:41.049934 139758026090240 logging_writer.py:48] [455800] global_step=455800, grad_norm=3.094207525253296, loss=1.5002150535583496
I0305 01:04:25.900117 139758009304832 logging_writer.py:48] [455900] global_step=455900, grad_norm=3.1003942489624023, loss=2.205787181854248
I0305 01:05:10.728720 139758026090240 logging_writer.py:48] [456000] global_step=456000, grad_norm=3.1738405227661133, loss=1.1491957902908325
I0305 01:05:55.576753 139758009304832 logging_writer.py:48] [456100] global_step=456100, grad_norm=3.06492018699646, loss=1.2043054103851318
I0305 01:06:40.855052 139758026090240 logging_writer.py:48] [456200] global_step=456200, grad_norm=3.6356942653656006, loss=3.1904449462890625
I0305 01:07:25.879189 139758009304832 logging_writer.py:48] [456300] global_step=456300, grad_norm=2.9706742763519287, loss=1.9106864929199219
I0305 01:07:26.977749 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:07:38.453114 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:08:04.453238 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:08:06.084478 139953291118400 submission_runner.py:411] Time since start: 220326.26s, 	Step: 456304, 	{'train/accuracy': 0.8844726085662842, 'train/loss': 0.427636057138443, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 202949.4070637226, 'total_duration': 220326.2607011795, 'accumulated_submission_time': 202949.4070637226, 'accumulated_eval_time': 17317.149385929108, 'accumulated_logging_time': 36.49660277366638}
I0305 01:08:06.187194 139758026090240 logging_writer.py:48] [456304] accumulated_eval_time=17317.149386, accumulated_logging_time=36.496603, accumulated_submission_time=202949.407064, global_step=456304, preemption_count=0, score=202949.407064, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=220326.260701, train/accuracy=0.884473, train/loss=0.427636, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:08:45.767596 139758009304832 logging_writer.py:48] [456400] global_step=456400, grad_norm=3.0423898696899414, loss=1.0690184831619263
I0305 01:09:30.545839 139758026090240 logging_writer.py:48] [456500] global_step=456500, grad_norm=4.960237503051758, loss=3.2032270431518555
I0305 01:10:15.549571 139758009304832 logging_writer.py:48] [456600] global_step=456600, grad_norm=3.195659875869751, loss=2.6264984607696533
I0305 01:11:00.983757 139758026090240 logging_writer.py:48] [456700] global_step=456700, grad_norm=3.3078935146331787, loss=2.833117961883545
I0305 01:11:46.186956 139758009304832 logging_writer.py:48] [456800] global_step=456800, grad_norm=3.642998218536377, loss=3.2462680339813232
I0305 01:12:31.577415 139758026090240 logging_writer.py:48] [456900] global_step=456900, grad_norm=3.3505077362060547, loss=3.0536134243011475
I0305 01:13:17.130459 139758009304832 logging_writer.py:48] [457000] global_step=457000, grad_norm=3.1214723587036133, loss=1.3687394857406616
I0305 01:14:02.272077 139758026090240 logging_writer.py:48] [457100] global_step=457100, grad_norm=3.580507755279541, loss=2.6281301975250244
I0305 01:14:47.957866 139758009304832 logging_writer.py:48] [457200] global_step=457200, grad_norm=3.026167869567871, loss=1.039567470550537
I0305 01:15:06.144104 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:15:17.491961 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:15:42.641375 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:15:44.279406 139953291118400 submission_runner.py:411] Time since start: 220784.46s, 	Step: 457242, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.4146224856376648, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 203369.30669617653, 'total_duration': 220784.45562553406, 'accumulated_submission_time': 203369.30669617653, 'accumulated_eval_time': 17355.284680366516, 'accumulated_logging_time': 36.609949350357056}
I0305 01:15:44.384433 139758026090240 logging_writer.py:48] [457242] accumulated_eval_time=17355.284680, accumulated_logging_time=36.609949, accumulated_submission_time=203369.306696, global_step=457242, preemption_count=0, score=203369.306696, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=220784.455626, train/accuracy=0.888438, train/loss=0.414622, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:16:07.673474 139758009304832 logging_writer.py:48] [457300] global_step=457300, grad_norm=3.083580493927002, loss=1.2314772605895996
I0305 01:16:51.998433 139758026090240 logging_writer.py:48] [457400] global_step=457400, grad_norm=2.924644947052002, loss=2.118708848953247
I0305 01:17:37.082653 139758009304832 logging_writer.py:48] [457500] global_step=457500, grad_norm=3.1136343479156494, loss=1.0402557849884033
I0305 01:18:22.354989 139758026090240 logging_writer.py:48] [457600] global_step=457600, grad_norm=3.2857439517974854, loss=1.1164952516555786
I0305 01:19:07.476010 139758009304832 logging_writer.py:48] [457700] global_step=457700, grad_norm=3.275606393814087, loss=2.2903342247009277
I0305 01:19:52.448105 139758026090240 logging_writer.py:48] [457800] global_step=457800, grad_norm=3.6085450649261475, loss=2.4669065475463867
I0305 01:20:38.015304 139758009304832 logging_writer.py:48] [457900] global_step=457900, grad_norm=3.087043285369873, loss=1.1662757396697998
I0305 01:21:23.172063 139758026090240 logging_writer.py:48] [458000] global_step=458000, grad_norm=3.442035675048828, loss=1.1786890029907227
I0305 01:22:07.872012 139758009304832 logging_writer.py:48] [458100] global_step=458100, grad_norm=3.3787848949432373, loss=2.491274356842041
I0305 01:22:44.377832 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:22:55.457090 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:23:25.069772 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:23:26.706579 139953291118400 submission_runner.py:411] Time since start: 221246.88s, 	Step: 458183, 	{'train/accuracy': 0.88685542345047, 'train/loss': 0.4204631745815277, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 203789.2432193756, 'total_duration': 221246.88278746605, 'accumulated_submission_time': 203789.2432193756, 'accumulated_eval_time': 17397.613396406174, 'accumulated_logging_time': 36.72454309463501}
I0305 01:23:26.810935 139758026090240 logging_writer.py:48] [458183] accumulated_eval_time=17397.613396, accumulated_logging_time=36.724543, accumulated_submission_time=203789.243219, global_step=458183, preemption_count=0, score=203789.243219, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=221246.882787, train/accuracy=0.886855, train/loss=0.420463, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:23:33.932075 139758009304832 logging_writer.py:48] [458200] global_step=458200, grad_norm=3.123512029647827, loss=2.0516042709350586
I0305 01:24:14.906202 139758026090240 logging_writer.py:48] [458300] global_step=458300, grad_norm=3.080495834350586, loss=1.0532112121582031
I0305 01:24:59.863133 139758009304832 logging_writer.py:48] [458400] global_step=458400, grad_norm=2.9688527584075928, loss=1.2417510747909546
I0305 01:25:44.923833 139758026090240 logging_writer.py:48] [458500] global_step=458500, grad_norm=3.203448534011841, loss=1.5533424615859985
I0305 01:26:30.043487 139758009304832 logging_writer.py:48] [458600] global_step=458600, grad_norm=3.125915288925171, loss=1.2478212118148804
I0305 01:27:14.761779 139758026090240 logging_writer.py:48] [458700] global_step=458700, grad_norm=2.9388844966888428, loss=1.5721218585968018
I0305 01:27:59.667513 139758009304832 logging_writer.py:48] [458800] global_step=458800, grad_norm=3.425989866256714, loss=1.108738899230957
I0305 01:28:44.651761 139758026090240 logging_writer.py:48] [458900] global_step=458900, grad_norm=3.5403876304626465, loss=2.3694956302642822
I0305 01:29:29.570303 139758009304832 logging_writer.py:48] [459000] global_step=459000, grad_norm=3.0095181465148926, loss=1.0279655456542969
I0305 01:30:14.512460 139758026090240 logging_writer.py:48] [459100] global_step=459100, grad_norm=2.9570417404174805, loss=1.0736312866210938
I0305 01:30:26.762652 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:30:38.343414 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:31:04.050010 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:31:05.682495 139953291118400 submission_runner.py:411] Time since start: 221705.86s, 	Step: 459129, 	{'train/accuracy': 0.8864452838897705, 'train/loss': 0.4202134609222412, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 204209.13581633568, 'total_duration': 221705.85871863365, 'accumulated_submission_time': 204209.13581633568, 'accumulated_eval_time': 17436.533225536346, 'accumulated_logging_time': 36.84003710746765}
I0305 01:31:05.788226 139758009304832 logging_writer.py:48] [459129] accumulated_eval_time=17436.533226, accumulated_logging_time=36.840037, accumulated_submission_time=204209.135816, global_step=459129, preemption_count=0, score=204209.135816, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=221705.858719, train/accuracy=0.886445, train/loss=0.420213, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:31:34.265354 139758026090240 logging_writer.py:48] [459200] global_step=459200, grad_norm=3.1438350677490234, loss=1.0445549488067627
I0305 01:32:18.873744 139758009304832 logging_writer.py:48] [459300] global_step=459300, grad_norm=3.74337100982666, loss=3.04377818107605
I0305 01:33:04.009392 139758026090240 logging_writer.py:48] [459400] global_step=459400, grad_norm=2.9040544033050537, loss=1.161685824394226
I0305 01:33:49.107383 139758009304832 logging_writer.py:48] [459500] global_step=459500, grad_norm=3.4127626419067383, loss=1.1780751943588257
I0305 01:34:34.100789 139758026090240 logging_writer.py:48] [459600] global_step=459600, grad_norm=3.292454719543457, loss=3.0486390590667725
I0305 01:35:18.989207 139758009304832 logging_writer.py:48] [459700] global_step=459700, grad_norm=3.086007833480835, loss=2.670724868774414
I0305 01:36:04.315766 139758026090240 logging_writer.py:48] [459800] global_step=459800, grad_norm=3.267712116241455, loss=1.2254031896591187
I0305 01:36:49.526369 139758009304832 logging_writer.py:48] [459900] global_step=459900, grad_norm=3.0887503623962402, loss=1.1261658668518066
I0305 01:37:34.353861 139758026090240 logging_writer.py:48] [460000] global_step=460000, grad_norm=3.2672271728515625, loss=2.1652135848999023
I0305 01:38:06.107087 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:38:17.500851 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:38:49.371658 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:38:51.005493 139953291118400 submission_runner.py:411] Time since start: 222171.18s, 	Step: 460072, 	{'train/accuracy': 0.8882030844688416, 'train/loss': 0.416919469833374, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 204629.39767479897, 'total_duration': 222171.1817200184, 'accumulated_submission_time': 204629.39767479897, 'accumulated_eval_time': 17481.431627988815, 'accumulated_logging_time': 36.955846309661865}
I0305 01:38:51.089288 139758009304832 logging_writer.py:48] [460072] accumulated_eval_time=17481.431628, accumulated_logging_time=36.955846, accumulated_submission_time=204629.397675, global_step=460072, preemption_count=0, score=204629.397675, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=222171.181720, train/accuracy=0.888203, train/loss=0.416919, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:39:02.531425 139758026090240 logging_writer.py:48] [460100] global_step=460100, grad_norm=2.9779794216156006, loss=1.0669052600860596
I0305 01:39:44.361088 139758009304832 logging_writer.py:48] [460200] global_step=460200, grad_norm=2.9353115558624268, loss=1.887916088104248
I0305 01:40:29.510814 139758026090240 logging_writer.py:48] [460300] global_step=460300, grad_norm=3.076754093170166, loss=1.095166802406311
I0305 01:41:14.599189 139758009304832 logging_writer.py:48] [460400] global_step=460400, grad_norm=3.848484516143799, loss=3.358342170715332
I0305 01:42:00.006936 139758026090240 logging_writer.py:48] [460500] global_step=460500, grad_norm=3.866025686264038, loss=3.225341320037842
I0305 01:42:45.065890 139758009304832 logging_writer.py:48] [460600] global_step=460600, grad_norm=3.0600900650024414, loss=2.1561660766601562
I0305 01:43:30.156990 139758026090240 logging_writer.py:48] [460700] global_step=460700, grad_norm=3.067807674407959, loss=1.6679637432098389
I0305 01:44:15.319402 139758009304832 logging_writer.py:48] [460800] global_step=460800, grad_norm=2.9633231163024902, loss=1.2877185344696045
I0305 01:45:00.162930 139758026090240 logging_writer.py:48] [460900] global_step=460900, grad_norm=2.90165376663208, loss=1.6133215427398682
I0305 01:45:45.204349 139758009304832 logging_writer.py:48] [461000] global_step=461000, grad_norm=2.960019588470459, loss=2.29775333404541
I0305 01:45:51.269529 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:46:02.506440 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:46:33.143945 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:46:34.768601 139953291118400 submission_runner.py:411] Time since start: 222634.94s, 	Step: 461015, 	{'train/accuracy': 0.8881054520606995, 'train/loss': 0.4188825786113739, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 205049.5205335617, 'total_duration': 222634.9448349476, 'accumulated_submission_time': 205049.5205335617, 'accumulated_eval_time': 17524.9306910038, 'accumulated_logging_time': 37.0502290725708}
I0305 01:46:34.853040 139758026090240 logging_writer.py:48] [461015] accumulated_eval_time=17524.930691, accumulated_logging_time=37.050229, accumulated_submission_time=205049.520534, global_step=461015, preemption_count=0, score=205049.520534, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=222634.944835, train/accuracy=0.888105, train/loss=0.418883, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:47:08.798620 139758009304832 logging_writer.py:48] [461100] global_step=461100, grad_norm=3.01499342918396, loss=1.106024980545044
I0305 01:47:53.372524 139758026090240 logging_writer.py:48] [461200] global_step=461200, grad_norm=3.1435585021972656, loss=1.0822244882583618
I0305 01:48:38.630612 139758009304832 logging_writer.py:48] [461300] global_step=461300, grad_norm=2.9773223400115967, loss=1.8795299530029297
I0305 01:49:23.683918 139758026090240 logging_writer.py:48] [461400] global_step=461400, grad_norm=2.991854429244995, loss=2.2069358825683594
I0305 01:50:08.757530 139758009304832 logging_writer.py:48] [461500] global_step=461500, grad_norm=3.0649077892303467, loss=1.2606559991836548
I0305 01:50:54.859585 139758026090240 logging_writer.py:48] [461600] global_step=461600, grad_norm=3.269685745239258, loss=1.6700671911239624
I0305 01:51:39.927025 139758009304832 logging_writer.py:48] [461700] global_step=461700, grad_norm=3.314012289047241, loss=3.007514476776123
I0305 01:52:24.959073 139758026090240 logging_writer.py:48] [461800] global_step=461800, grad_norm=3.638474702835083, loss=3.1513266563415527
I0305 01:53:09.782757 139758009304832 logging_writer.py:48] [461900] global_step=461900, grad_norm=3.036284923553467, loss=1.129723072052002
I0305 01:53:35.149764 139953291118400 spec.py:321] Evaluating on the training split.
I0305 01:53:46.478117 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 01:54:10.664442 139953291118400 spec.py:349] Evaluating on the test split.
I0305 01:54:12.308722 139953291118400 submission_runner.py:411] Time since start: 223092.48s, 	Step: 461958, 	{'train/accuracy': 0.8861327767372131, 'train/loss': 0.42851343750953674, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 205469.76189637184, 'total_duration': 223092.48494267464, 'accumulated_submission_time': 205469.76189637184, 'accumulated_eval_time': 17562.089664697647, 'accumulated_logging_time': 37.14282035827637}
I0305 01:54:12.414710 139758026090240 logging_writer.py:48] [461958] accumulated_eval_time=17562.089665, accumulated_logging_time=37.142820, accumulated_submission_time=205469.761896, global_step=461958, preemption_count=0, score=205469.761896, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=223092.484943, train/accuracy=0.886133, train/loss=0.428513, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 01:54:29.553798 139758009304832 logging_writer.py:48] [462000] global_step=462000, grad_norm=3.2149839401245117, loss=1.606311559677124
I0305 01:55:12.787775 139758026090240 logging_writer.py:48] [462100] global_step=462100, grad_norm=3.294194221496582, loss=1.1487027406692505
I0305 01:55:57.647584 139758009304832 logging_writer.py:48] [462200] global_step=462200, grad_norm=2.9918479919433594, loss=1.0486831665039062
I0305 01:56:43.077180 139758026090240 logging_writer.py:48] [462300] global_step=462300, grad_norm=2.88128924369812, loss=1.109415054321289
I0305 01:57:27.740201 139758009304832 logging_writer.py:48] [462400] global_step=462400, grad_norm=3.0791168212890625, loss=1.2440731525421143
I0305 01:58:12.759576 139758026090240 logging_writer.py:48] [462500] global_step=462500, grad_norm=2.922717332839966, loss=1.7583792209625244
I0305 01:58:57.664847 139758009304832 logging_writer.py:48] [462600] global_step=462600, grad_norm=3.1566834449768066, loss=2.364105224609375
I0305 01:59:42.892971 139758026090240 logging_writer.py:48] [462700] global_step=462700, grad_norm=2.8202338218688965, loss=1.8429197072982788
I0305 02:00:27.992172 139758009304832 logging_writer.py:48] [462800] global_step=462800, grad_norm=3.1900408267974854, loss=1.1622031927108765
I0305 02:01:12.857030 139758026090240 logging_writer.py:48] [462900] global_step=462900, grad_norm=3.385425329208374, loss=3.115704298019409
I0305 02:01:12.868949 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:01:23.840418 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:01:54.613406 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:01:56.255689 139953291118400 submission_runner.py:411] Time since start: 223556.43s, 	Step: 462901, 	{'train/accuracy': 0.8883007764816284, 'train/loss': 0.41499701142311096, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 205890.15830087662, 'total_duration': 223556.43191599846, 'accumulated_submission_time': 205890.15830087662, 'accumulated_eval_time': 17605.4763879776, 'accumulated_logging_time': 37.25931525230408}
I0305 02:01:56.361029 139758009304832 logging_writer.py:48] [462901] accumulated_eval_time=17605.476388, accumulated_logging_time=37.259315, accumulated_submission_time=205890.158301, global_step=462901, preemption_count=0, score=205890.158301, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=223556.431916, train/accuracy=0.888301, train/loss=0.414997, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:02:36.952000 139758026090240 logging_writer.py:48] [463000] global_step=463000, grad_norm=3.0446250438690186, loss=2.530010938644409
I0305 02:03:21.831881 139758009304832 logging_writer.py:48] [463100] global_step=463100, grad_norm=2.9758076667785645, loss=1.6601653099060059
I0305 02:04:07.053514 139758026090240 logging_writer.py:48] [463200] global_step=463200, grad_norm=3.3272600173950195, loss=2.962846040725708
I0305 02:04:52.401906 139758009304832 logging_writer.py:48] [463300] global_step=463300, grad_norm=3.6956095695495605, loss=2.8494436740875244
I0305 02:05:37.687502 139758026090240 logging_writer.py:48] [463400] global_step=463400, grad_norm=3.0747971534729004, loss=1.1691378355026245
I0305 02:06:22.933429 139758009304832 logging_writer.py:48] [463500] global_step=463500, grad_norm=2.982572317123413, loss=1.1970927715301514
I0305 02:07:08.088557 139758026090240 logging_writer.py:48] [463600] global_step=463600, grad_norm=3.073866605758667, loss=1.178053379058838
I0305 02:07:53.049271 139758009304832 logging_writer.py:48] [463700] global_step=463700, grad_norm=2.7785913944244385, loss=1.6715056896209717
I0305 02:08:38.047218 139758026090240 logging_writer.py:48] [463800] global_step=463800, grad_norm=3.0719332695007324, loss=1.8153131008148193
I0305 02:08:56.646292 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:09:07.905256 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:09:33.174505 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:09:34.841174 139953291118400 submission_runner.py:411] Time since start: 224015.02s, 	Step: 463843, 	{'train/accuracy': 0.887011706829071, 'train/loss': 0.4187023341655731, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 206310.38519096375, 'total_duration': 224015.01740431786, 'accumulated_submission_time': 206310.38519096375, 'accumulated_eval_time': 17643.671263217926, 'accumulated_logging_time': 37.37636876106262}
I0305 02:09:34.926321 139758009304832 logging_writer.py:48] [463843] accumulated_eval_time=17643.671263, accumulated_logging_time=37.376369, accumulated_submission_time=206310.385191, global_step=463843, preemption_count=0, score=206310.385191, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=224015.017404, train/accuracy=0.887012, train/loss=0.418702, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:09:57.832695 139758026090240 logging_writer.py:48] [463900] global_step=463900, grad_norm=3.3929619789123535, loss=2.73044753074646
I0305 02:10:41.092810 139758009304832 logging_writer.py:48] [464000] global_step=464000, grad_norm=3.1746926307678223, loss=1.15461003780365
I0305 02:11:26.123152 139758026090240 logging_writer.py:48] [464100] global_step=464100, grad_norm=3.8552825450897217, loss=2.966698169708252
I0305 02:12:11.754174 139758009304832 logging_writer.py:48] [464200] global_step=464200, grad_norm=3.637737512588501, loss=3.0032992362976074
I0305 02:12:56.783048 139758026090240 logging_writer.py:48] [464300] global_step=464300, grad_norm=3.3452205657958984, loss=1.5601242780685425
I0305 02:13:42.007876 139758009304832 logging_writer.py:48] [464400] global_step=464400, grad_norm=3.2467141151428223, loss=1.2695882320404053
I0305 02:14:27.360197 139758026090240 logging_writer.py:48] [464500] global_step=464500, grad_norm=2.7807722091674805, loss=1.5031468868255615
I0305 02:15:12.544841 139758009304832 logging_writer.py:48] [464600] global_step=464600, grad_norm=3.6234264373779297, loss=1.4341806173324585
I0305 02:15:57.271678 139758026090240 logging_writer.py:48] [464700] global_step=464700, grad_norm=3.69657301902771, loss=1.175506830215454
I0305 02:16:35.140971 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:16:46.369462 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:17:09.173402 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:17:10.809077 139953291118400 submission_runner.py:411] Time since start: 224470.99s, 	Step: 464785, 	{'train/accuracy': 0.8866406083106995, 'train/loss': 0.4217980206012726, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 206730.53880548477, 'total_duration': 224470.98530101776, 'accumulated_submission_time': 206730.53880548477, 'accumulated_eval_time': 17679.339367866516, 'accumulated_logging_time': 37.474828243255615}
I0305 02:17:10.917577 139758009304832 logging_writer.py:48] [464785] accumulated_eval_time=17679.339368, accumulated_logging_time=37.474828, accumulated_submission_time=206730.538805, global_step=464785, preemption_count=0, score=206730.538805, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=224470.985301, train/accuracy=0.886641, train/loss=0.421798, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:17:17.252111 139758026090240 logging_writer.py:48] [464800] global_step=464800, grad_norm=3.2167935371398926, loss=2.5928893089294434
I0305 02:17:59.165360 139758009304832 logging_writer.py:48] [464900] global_step=464900, grad_norm=3.819087266921997, loss=3.143183708190918
I0305 02:18:43.647543 139758026090240 logging_writer.py:48] [465000] global_step=465000, grad_norm=3.0155270099639893, loss=2.468538761138916
I0305 02:19:28.743724 139758009304832 logging_writer.py:48] [465100] global_step=465100, grad_norm=3.0613136291503906, loss=1.967293381690979
I0305 02:20:14.149380 139758026090240 logging_writer.py:48] [465200] global_step=465200, grad_norm=3.489194869995117, loss=3.0088160037994385
I0305 02:20:58.944614 139758009304832 logging_writer.py:48] [465300] global_step=465300, grad_norm=3.9826905727386475, loss=3.1486198902130127
I0305 02:21:43.995400 139758026090240 logging_writer.py:48] [465400] global_step=465400, grad_norm=3.179276943206787, loss=1.0969561338424683
I0305 02:22:29.510432 139758009304832 logging_writer.py:48] [465500] global_step=465500, grad_norm=3.149570941925049, loss=1.192517638206482
I0305 02:23:14.317486 139758026090240 logging_writer.py:48] [465600] global_step=465600, grad_norm=3.1495063304901123, loss=1.2259595394134521
I0305 02:23:59.461016 139758009304832 logging_writer.py:48] [465700] global_step=465700, grad_norm=3.0152761936187744, loss=1.1376789808273315
I0305 02:24:10.827422 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:24:22.223966 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:24:48.452242 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:24:50.089516 139953291118400 submission_runner.py:411] Time since start: 224930.27s, 	Step: 465727, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.4204729497432709, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 207150.38817048073, 'total_duration': 224930.26573109627, 'accumulated_submission_time': 207150.38817048073, 'accumulated_eval_time': 17718.601448774338, 'accumulated_logging_time': 37.595885038375854}
I0305 02:24:50.196034 139758026090240 logging_writer.py:48] [465727] accumulated_eval_time=17718.601449, accumulated_logging_time=37.595885, accumulated_submission_time=207150.388170, global_step=465727, preemption_count=0, score=207150.388170, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=224930.265731, train/accuracy=0.887461, train/loss=0.420473, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:25:19.412421 139758009304832 logging_writer.py:48] [465800] global_step=465800, grad_norm=3.048412561416626, loss=1.0493677854537964
I0305 02:26:04.457281 139758026090240 logging_writer.py:48] [465900] global_step=465900, grad_norm=3.421571969985962, loss=1.1511001586914062
I0305 02:26:49.759037 139758009304832 logging_writer.py:48] [466000] global_step=466000, grad_norm=3.0157690048217773, loss=1.2592744827270508
I0305 02:27:35.113680 139758026090240 logging_writer.py:48] [466100] global_step=466100, grad_norm=3.5972111225128174, loss=2.8120977878570557
I0305 02:28:19.977234 139758009304832 logging_writer.py:48] [466200] global_step=466200, grad_norm=3.3106369972229004, loss=1.2410814762115479
I0305 02:29:05.059649 139758026090240 logging_writer.py:48] [466300] global_step=466300, grad_norm=3.4280316829681396, loss=1.2569794654846191
I0305 02:29:50.183147 139758009304832 logging_writer.py:48] [466400] global_step=466400, grad_norm=3.4493064880371094, loss=2.41931414604187
I0305 02:30:35.231820 139758026090240 logging_writer.py:48] [466500] global_step=466500, grad_norm=3.3191640377044678, loss=1.2187191247940063
I0305 02:31:20.318162 139758009304832 logging_writer.py:48] [466600] global_step=466600, grad_norm=3.349820137023926, loss=1.2211636304855347
I0305 02:31:50.412769 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:32:01.172723 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:32:27.638006 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:32:29.299675 139953291118400 submission_runner.py:411] Time since start: 225389.48s, 	Step: 466668, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.4182624816894531, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 207570.5442082882, 'total_duration': 225389.47584223747, 'accumulated_submission_time': 207570.5442082882, 'accumulated_eval_time': 17757.488273620605, 'accumulated_logging_time': 37.715657234191895}
I0305 02:32:29.465428 139758026090240 logging_writer.py:48] [466668] accumulated_eval_time=17757.488274, accumulated_logging_time=37.715657, accumulated_submission_time=207570.544208, global_step=466668, preemption_count=0, score=207570.544208, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=225389.475842, train/accuracy=0.887227, train/loss=0.418262, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:32:42.520218 139758009304832 logging_writer.py:48] [466700] global_step=466700, grad_norm=2.9908761978149414, loss=1.1801090240478516
I0305 02:33:24.149549 139758026090240 logging_writer.py:48] [466800] global_step=466800, grad_norm=2.9265589714050293, loss=1.0804718732833862
I0305 02:34:09.056422 139758009304832 logging_writer.py:48] [466900] global_step=466900, grad_norm=2.9520206451416016, loss=1.1716914176940918
I0305 02:34:54.089114 139758026090240 logging_writer.py:48] [467000] global_step=467000, grad_norm=3.1626970767974854, loss=1.0808614492416382
I0305 02:35:39.304045 139758009304832 logging_writer.py:48] [467100] global_step=467100, grad_norm=3.0901012420654297, loss=1.2395273447036743
I0305 02:36:24.289317 139758026090240 logging_writer.py:48] [467200] global_step=467200, grad_norm=3.0167768001556396, loss=2.166727304458618
I0305 02:37:09.572737 139758009304832 logging_writer.py:48] [467300] global_step=467300, grad_norm=3.063288450241089, loss=1.1022427082061768
I0305 02:37:54.626278 139758026090240 logging_writer.py:48] [467400] global_step=467400, grad_norm=3.269218683242798, loss=2.5714104175567627
I0305 02:38:39.475786 139758009304832 logging_writer.py:48] [467500] global_step=467500, grad_norm=2.823366641998291, loss=2.0241856575012207
I0305 02:39:24.491436 139758026090240 logging_writer.py:48] [467600] global_step=467600, grad_norm=3.5573458671569824, loss=2.736910104751587
I0305 02:39:29.661189 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:39:40.677723 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:40:11.497784 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:40:13.128987 139953291118400 submission_runner.py:411] Time since start: 225853.31s, 	Step: 467613, 	{'train/accuracy': 0.88978511095047, 'train/loss': 0.4156844913959503, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 207990.6780860424, 'total_duration': 225853.3052201271, 'accumulated_submission_time': 207990.6780860424, 'accumulated_eval_time': 17800.95606303215, 'accumulated_logging_time': 37.89576005935669}
I0305 02:40:13.215625 139758009304832 logging_writer.py:48] [467613] accumulated_eval_time=17800.956063, accumulated_logging_time=37.895760, accumulated_submission_time=207990.678086, global_step=467613, preemption_count=0, score=207990.678086, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=225853.305220, train/accuracy=0.889785, train/loss=0.415684, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:40:47.961894 139758026090240 logging_writer.py:48] [467700] global_step=467700, grad_norm=2.8710780143737793, loss=1.1715888977050781
I0305 02:41:32.370311 139758009304832 logging_writer.py:48] [467800] global_step=467800, grad_norm=3.2363197803497314, loss=1.161933422088623
I0305 02:42:17.425917 139758026090240 logging_writer.py:48] [467900] global_step=467900, grad_norm=3.1719305515289307, loss=2.6131811141967773
I0305 02:43:03.028716 139758009304832 logging_writer.py:48] [468000] global_step=468000, grad_norm=3.298175811767578, loss=1.2311574220657349
I0305 02:43:47.658946 139758026090240 logging_writer.py:48] [468100] global_step=468100, grad_norm=2.9715256690979004, loss=2.1188113689422607
I0305 02:44:32.962107 139758009304832 logging_writer.py:48] [468200] global_step=468200, grad_norm=2.8613290786743164, loss=1.1581075191497803
I0305 02:45:18.205829 139758026090240 logging_writer.py:48] [468300] global_step=468300, grad_norm=3.3050525188446045, loss=1.1421546936035156
I0305 02:46:03.218348 139758009304832 logging_writer.py:48] [468400] global_step=468400, grad_norm=3.024015188217163, loss=1.8818711042404175
I0305 02:46:48.348039 139758026090240 logging_writer.py:48] [468500] global_step=468500, grad_norm=3.5396018028259277, loss=2.9694395065307617
I0305 02:47:13.323197 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:47:24.585233 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:47:51.858946 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:47:53.480304 139953291118400 submission_runner.py:411] Time since start: 226313.66s, 	Step: 468557, 	{'train/accuracy': 0.8885741829872131, 'train/loss': 0.41781237721443176, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 208410.72726297379, 'total_duration': 226313.65653896332, 'accumulated_submission_time': 208410.72726297379, 'accumulated_eval_time': 17841.113161325455, 'accumulated_logging_time': 37.99327063560486}
I0305 02:47:53.564953 139758009304832 logging_writer.py:48] [468557] accumulated_eval_time=17841.113161, accumulated_logging_time=37.993271, accumulated_submission_time=208410.727263, global_step=468557, preemption_count=0, score=208410.727263, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=226313.656539, train/accuracy=0.888574, train/loss=0.417812, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:48:10.922825 139758026090240 logging_writer.py:48] [468600] global_step=468600, grad_norm=3.329427719116211, loss=2.7173237800598145
I0305 02:48:53.206488 139758009304832 logging_writer.py:48] [468700] global_step=468700, grad_norm=2.964756965637207, loss=1.1595027446746826
I0305 02:49:38.330161 139758026090240 logging_writer.py:48] [468800] global_step=468800, grad_norm=3.12235164642334, loss=1.0408631563186646
I0305 02:50:23.611336 139758009304832 logging_writer.py:48] [468900] global_step=468900, grad_norm=3.4259486198425293, loss=1.4081178903579712
I0305 02:51:08.802346 139758026090240 logging_writer.py:48] [469000] global_step=469000, grad_norm=3.11972975730896, loss=1.0695695877075195
I0305 02:51:53.798264 139758009304832 logging_writer.py:48] [469100] global_step=469100, grad_norm=3.4435079097747803, loss=2.821441888809204
I0305 02:52:38.954203 139758026090240 logging_writer.py:48] [469200] global_step=469200, grad_norm=3.064020872116089, loss=1.3089661598205566
I0305 02:53:23.940141 139758009304832 logging_writer.py:48] [469300] global_step=469300, grad_norm=3.352285861968994, loss=1.7938768863677979
I0305 02:54:08.880344 139758026090240 logging_writer.py:48] [469400] global_step=469400, grad_norm=3.0993525981903076, loss=2.3637475967407227
I0305 02:54:53.685523 139758009304832 logging_writer.py:48] [469500] global_step=469500, grad_norm=2.9786715507507324, loss=1.0051207542419434
I0305 02:54:53.697658 139953291118400 spec.py:321] Evaluating on the training split.
I0305 02:55:05.048485 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 02:55:39.089974 139953291118400 spec.py:349] Evaluating on the test split.
I0305 02:55:40.713493 139953291118400 submission_runner.py:411] Time since start: 226780.89s, 	Step: 469501, 	{'train/accuracy': 0.8895312547683716, 'train/loss': 0.41012680530548096, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 208830.80399012566, 'total_duration': 226780.88972759247, 'accumulated_submission_time': 208830.80399012566, 'accumulated_eval_time': 17888.128987550735, 'accumulated_logging_time': 38.08624720573425}
I0305 02:55:40.798545 139758026090240 logging_writer.py:48] [469501] accumulated_eval_time=17888.128988, accumulated_logging_time=38.086247, accumulated_submission_time=208830.803990, global_step=469501, preemption_count=0, score=208830.803990, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=226780.889728, train/accuracy=0.889531, train/loss=0.410127, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 02:56:21.142809 139758009304832 logging_writer.py:48] [469600] global_step=469600, grad_norm=3.5428566932678223, loss=1.7342040538787842
I0305 02:57:06.227093 139758026090240 logging_writer.py:48] [469700] global_step=469700, grad_norm=3.191654920578003, loss=1.1751708984375
I0305 02:57:51.210303 139758009304832 logging_writer.py:48] [469800] global_step=469800, grad_norm=2.922332763671875, loss=1.3680702447891235
I0305 02:58:36.349395 139758026090240 logging_writer.py:48] [469900] global_step=469900, grad_norm=3.4108874797821045, loss=2.4943437576293945
I0305 02:59:20.962541 139758009304832 logging_writer.py:48] [470000] global_step=470000, grad_norm=3.6100666522979736, loss=3.1530590057373047
I0305 03:00:06.025312 139758026090240 logging_writer.py:48] [470100] global_step=470100, grad_norm=3.006641387939453, loss=1.2064423561096191
I0305 03:00:50.941211 139758009304832 logging_writer.py:48] [470200] global_step=470200, grad_norm=3.167766571044922, loss=1.128293514251709
I0305 03:01:35.792344 139758026090240 logging_writer.py:48] [470300] global_step=470300, grad_norm=3.219174385070801, loss=2.911336898803711
I0305 03:02:20.492413 139758009304832 logging_writer.py:48] [470400] global_step=470400, grad_norm=2.9598870277404785, loss=1.3685688972473145
I0305 03:02:40.960381 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:02:52.393364 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:03:17.526499 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:03:19.154485 139953291118400 submission_runner.py:411] Time since start: 227239.33s, 	Step: 470446, 	{'train/accuracy': 0.8869921565055847, 'train/loss': 0.4194200932979584, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 209250.91027021408, 'total_duration': 227239.33070850372, 'accumulated_submission_time': 209250.91027021408, 'accumulated_eval_time': 17926.32308101654, 'accumulated_logging_time': 38.17964243888855}
I0305 03:03:19.261370 139758026090240 logging_writer.py:48] [470446] accumulated_eval_time=17926.323081, accumulated_logging_time=38.179642, accumulated_submission_time=209250.910270, global_step=470446, preemption_count=0, score=209250.910270, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=227239.330709, train/accuracy=0.886992, train/loss=0.419420, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:03:40.977002 139758009304832 logging_writer.py:48] [470500] global_step=470500, grad_norm=3.122642993927002, loss=1.8023172616958618
I0305 03:04:25.703358 139758026090240 logging_writer.py:48] [470600] global_step=470600, grad_norm=3.013576030731201, loss=1.4984389543533325
I0305 03:05:10.855328 139758009304832 logging_writer.py:48] [470700] global_step=470700, grad_norm=3.0653369426727295, loss=2.557628631591797
I0305 03:05:55.960698 139758026090240 logging_writer.py:48] [470800] global_step=470800, grad_norm=3.043917655944824, loss=1.1448719501495361
I0305 03:06:41.436294 139758009304832 logging_writer.py:48] [470900] global_step=470900, grad_norm=3.184340476989746, loss=2.583865165710449
I0305 03:07:26.659216 139758026090240 logging_writer.py:48] [471000] global_step=471000, grad_norm=2.9551665782928467, loss=1.1197130680084229
I0305 03:08:12.065811 139758009304832 logging_writer.py:48] [471100] global_step=471100, grad_norm=3.2769699096679688, loss=2.417179584503174
I0305 03:08:57.136458 139758026090240 logging_writer.py:48] [471200] global_step=471200, grad_norm=3.119006633758545, loss=2.239333152770996
I0305 03:09:42.516030 139758009304832 logging_writer.py:48] [471300] global_step=471300, grad_norm=2.9612350463867188, loss=1.3495628833770752
I0305 03:10:19.527772 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:10:31.763737 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:10:58.817170 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:11:00.445871 139953291118400 submission_runner.py:411] Time since start: 227700.62s, 	Step: 471383, 	{'train/accuracy': 0.8870898485183716, 'train/loss': 0.41675370931625366, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 209671.11908245087, 'total_duration': 227700.62208509445, 'accumulated_submission_time': 209671.11908245087, 'accumulated_eval_time': 17967.24115753174, 'accumulated_logging_time': 38.296884059906006}
I0305 03:11:00.553825 139758026090240 logging_writer.py:48] [471383] accumulated_eval_time=17967.241158, accumulated_logging_time=38.296884, accumulated_submission_time=209671.119082, global_step=471383, preemption_count=0, score=209671.119082, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=227700.622085, train/accuracy=0.887090, train/loss=0.416754, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:11:07.681851 139758009304832 logging_writer.py:48] [471400] global_step=471400, grad_norm=3.1411609649658203, loss=1.063538908958435
I0305 03:11:49.434583 139758026090240 logging_writer.py:48] [471500] global_step=471500, grad_norm=3.5097923278808594, loss=1.1587550640106201
I0305 03:12:34.658767 139758009304832 logging_writer.py:48] [471600] global_step=471600, grad_norm=3.632951021194458, loss=3.176359176635742
I0305 03:13:20.070062 139758026090240 logging_writer.py:48] [471700] global_step=471700, grad_norm=3.235055685043335, loss=2.240122079849243
I0305 03:14:05.397418 139758009304832 logging_writer.py:48] [471800] global_step=471800, grad_norm=3.0706470012664795, loss=1.0734187364578247
I0305 03:14:50.370856 139758026090240 logging_writer.py:48] [471900] global_step=471900, grad_norm=3.339801073074341, loss=1.5132638216018677
I0305 03:15:35.725677 139758009304832 logging_writer.py:48] [472000] global_step=472000, grad_norm=3.520160436630249, loss=3.2021853923797607
I0305 03:16:20.957951 139758026090240 logging_writer.py:48] [472100] global_step=472100, grad_norm=3.7838294506073, loss=2.922405242919922
I0305 03:17:06.026006 139758009304832 logging_writer.py:48] [472200] global_step=472200, grad_norm=3.341095447540283, loss=1.993232250213623
I0305 03:17:51.092673 139758026090240 logging_writer.py:48] [472300] global_step=472300, grad_norm=3.182884931564331, loss=1.123054027557373
I0305 03:18:00.731577 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:18:12.078897 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:18:39.354497 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:18:40.971465 139953291118400 submission_runner.py:411] Time since start: 228161.15s, 	Step: 472323, 	{'train/accuracy': 0.8866991996765137, 'train/loss': 0.41834941506385803, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 210091.2394402027, 'total_duration': 228161.14769411087, 'accumulated_submission_time': 210091.2394402027, 'accumulated_eval_time': 18007.481026172638, 'accumulated_logging_time': 38.41466212272644}
I0305 03:18:41.059016 139758009304832 logging_writer.py:48] [472323] accumulated_eval_time=18007.481026, accumulated_logging_time=38.414662, accumulated_submission_time=210091.239440, global_step=472323, preemption_count=0, score=210091.239440, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=228161.147694, train/accuracy=0.886699, train/loss=0.418349, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:19:11.853561 139758026090240 logging_writer.py:48] [472400] global_step=472400, grad_norm=3.2633745670318604, loss=1.785306692123413
I0305 03:19:55.627150 139758009304832 logging_writer.py:48] [472500] global_step=472500, grad_norm=3.2506232261657715, loss=1.0854878425598145
I0305 03:20:40.821695 139758026090240 logging_writer.py:48] [472600] global_step=472600, grad_norm=3.5248093605041504, loss=1.0597246885299683
I0305 03:21:26.125777 139758009304832 logging_writer.py:48] [472700] global_step=472700, grad_norm=2.962116003036499, loss=1.8517788648605347
I0305 03:22:10.992795 139758026090240 logging_writer.py:48] [472800] global_step=472800, grad_norm=3.6766884326934814, loss=1.1620327234268188
I0305 03:22:56.022993 139758009304832 logging_writer.py:48] [472900] global_step=472900, grad_norm=3.7843635082244873, loss=1.3102405071258545
I0305 03:23:41.715980 139758026090240 logging_writer.py:48] [473000] global_step=473000, grad_norm=3.3355484008789062, loss=2.6450355052948
I0305 03:24:26.907312 139758009304832 logging_writer.py:48] [473100] global_step=473100, grad_norm=3.4943034648895264, loss=3.0245180130004883
I0305 03:25:12.072141 139758026090240 logging_writer.py:48] [473200] global_step=473200, grad_norm=2.7925891876220703, loss=1.9991073608398438
I0305 03:25:41.063028 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:25:52.246119 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:26:16.031992 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:26:17.673154 139953291118400 submission_runner.py:411] Time since start: 228617.85s, 	Step: 473266, 	{'train/accuracy': 0.8862109184265137, 'train/loss': 0.41933897137641907, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 210511.18789815903, 'total_duration': 228617.84938049316, 'accumulated_submission_time': 210511.18789815903, 'accumulated_eval_time': 18044.091156482697, 'accumulated_logging_time': 38.51059150695801}
I0305 03:26:17.778997 139758009304832 logging_writer.py:48] [473266] accumulated_eval_time=18044.091156, accumulated_logging_time=38.510592, accumulated_submission_time=210511.187898, global_step=473266, preemption_count=0, score=210511.187898, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=228617.849380, train/accuracy=0.886211, train/loss=0.419339, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:26:31.587639 139758026090240 logging_writer.py:48] [473300] global_step=473300, grad_norm=3.366879940032959, loss=1.0149266719818115
I0305 03:27:14.194681 139758009304832 logging_writer.py:48] [473400] global_step=473400, grad_norm=3.237746477127075, loss=1.4235926866531372
I0305 03:27:59.223262 139758026090240 logging_writer.py:48] [473500] global_step=473500, grad_norm=3.0311245918273926, loss=1.7882335186004639
I0305 03:28:44.331690 139758009304832 logging_writer.py:48] [473600] global_step=473600, grad_norm=3.018021583557129, loss=1.2467427253723145
I0305 03:29:29.602669 139758026090240 logging_writer.py:48] [473700] global_step=473700, grad_norm=3.000610113143921, loss=1.6076874732971191
I0305 03:30:14.572247 139758009304832 logging_writer.py:48] [473800] global_step=473800, grad_norm=3.290814161300659, loss=1.2346067428588867
I0305 03:30:59.383382 139758026090240 logging_writer.py:48] [473900] global_step=473900, grad_norm=3.203026294708252, loss=2.202237367630005
I0305 03:31:44.872457 139758009304832 logging_writer.py:48] [474000] global_step=474000, grad_norm=2.978635311126709, loss=2.351013422012329
I0305 03:32:29.997924 139758026090240 logging_writer.py:48] [474100] global_step=474100, grad_norm=3.2481164932250977, loss=1.1067167520523071
I0305 03:33:15.343112 139758009304832 logging_writer.py:48] [474200] global_step=474200, grad_norm=3.24204421043396, loss=1.1686617136001587
I0305 03:33:17.726061 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:33:29.211705 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:33:53.899235 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:33:55.539571 139953291118400 submission_runner.py:411] Time since start: 229075.72s, 	Step: 474207, 	{'train/accuracy': 0.8871679306030273, 'train/loss': 0.42013782262802124, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 210931.07780385017, 'total_duration': 229075.71579408646, 'accumulated_submission_time': 210931.07780385017, 'accumulated_eval_time': 18081.904654741287, 'accumulated_logging_time': 38.62590575218201}
I0305 03:33:55.648251 139758026090240 logging_writer.py:48] [474207] accumulated_eval_time=18081.904655, accumulated_logging_time=38.625906, accumulated_submission_time=210931.077804, global_step=474207, preemption_count=0, score=210931.077804, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=229075.715794, train/accuracy=0.887168, train/loss=0.420138, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:34:33.690649 139758009304832 logging_writer.py:48] [474300] global_step=474300, grad_norm=3.8343091011047363, loss=2.971808910369873
I0305 03:35:18.604029 139758026090240 logging_writer.py:48] [474400] global_step=474400, grad_norm=2.8734798431396484, loss=2.021967887878418
I0305 03:36:03.750346 139758009304832 logging_writer.py:48] [474500] global_step=474500, grad_norm=3.0900115966796875, loss=1.0999141931533813
I0305 03:36:49.192072 139758026090240 logging_writer.py:48] [474600] global_step=474600, grad_norm=3.1350347995758057, loss=1.170199990272522
I0305 03:37:34.259545 139758009304832 logging_writer.py:48] [474700] global_step=474700, grad_norm=3.2232563495635986, loss=1.1513168811798096
I0305 03:38:19.372141 139758026090240 logging_writer.py:48] [474800] global_step=474800, grad_norm=2.9651386737823486, loss=1.8668763637542725
I0305 03:39:04.738785 139758009304832 logging_writer.py:48] [474900] global_step=474900, grad_norm=3.0749197006225586, loss=1.150406837463379
I0305 03:39:49.704458 139758026090240 logging_writer.py:48] [475000] global_step=475000, grad_norm=3.021023988723755, loss=1.1015892028808594
I0305 03:40:34.807424 139758009304832 logging_writer.py:48] [475100] global_step=475100, grad_norm=3.3419461250305176, loss=2.4739110469818115
I0305 03:40:55.799887 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:41:07.081594 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:41:34.486368 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:41:36.131737 139953291118400 submission_runner.py:411] Time since start: 229536.31s, 	Step: 475148, 	{'train/accuracy': 0.8871874809265137, 'train/loss': 0.42228221893310547, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 211351.17332220078, 'total_duration': 229536.30795049667, 'accumulated_submission_time': 211351.17332220078, 'accumulated_eval_time': 18122.236476182938, 'accumulated_logging_time': 38.743818521499634}
I0305 03:41:36.218766 139758026090240 logging_writer.py:48] [475148] accumulated_eval_time=18122.236476, accumulated_logging_time=38.743819, accumulated_submission_time=211351.173322, global_step=475148, preemption_count=0, score=211351.173322, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=229536.307950, train/accuracy=0.887187, train/loss=0.422282, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:41:57.134813 139758009304832 logging_writer.py:48] [475200] global_step=475200, grad_norm=3.2098021507263184, loss=1.5671812295913696
I0305 03:42:39.926194 139758026090240 logging_writer.py:48] [475300] global_step=475300, grad_norm=2.9856467247009277, loss=1.2318854331970215
I0305 03:43:24.725217 139758009304832 logging_writer.py:48] [475400] global_step=475400, grad_norm=3.0731327533721924, loss=2.3288822174072266
I0305 03:44:10.514962 139758026090240 logging_writer.py:48] [475500] global_step=475500, grad_norm=2.937944173812866, loss=1.1066160202026367
I0305 03:44:55.668261 139758009304832 logging_writer.py:48] [475600] global_step=475600, grad_norm=3.9471018314361572, loss=3.215832233428955
I0305 03:45:40.600674 139758026090240 logging_writer.py:48] [475700] global_step=475700, grad_norm=2.9644205570220947, loss=1.6200329065322876
I0305 03:46:25.993675 139758009304832 logging_writer.py:48] [475800] global_step=475800, grad_norm=3.304328680038452, loss=1.6581146717071533
I0305 03:47:11.176074 139758026090240 logging_writer.py:48] [475900] global_step=475900, grad_norm=2.995241165161133, loss=1.1667325496673584
I0305 03:47:56.051400 139758009304832 logging_writer.py:48] [476000] global_step=476000, grad_norm=2.852172613143921, loss=1.4123635292053223
I0305 03:48:36.354205 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:48:47.457212 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:49:08.767427 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:49:10.405201 139953291118400 submission_runner.py:411] Time since start: 229990.58s, 	Step: 476091, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.42178910970687866, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 211771.25239276886, 'total_duration': 229990.58141207695, 'accumulated_submission_time': 211771.25239276886, 'accumulated_eval_time': 18156.287446975708, 'accumulated_logging_time': 38.8391637802124}
I0305 03:49:10.508387 139758026090240 logging_writer.py:48] [476091] accumulated_eval_time=18156.287447, accumulated_logging_time=38.839164, accumulated_submission_time=211771.252393, global_step=476091, preemption_count=0, score=211771.252393, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=229990.581412, train/accuracy=0.887500, train/loss=0.421789, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:49:14.471148 139758009304832 logging_writer.py:48] [476100] global_step=476100, grad_norm=3.0604538917541504, loss=1.3433501720428467
I0305 03:49:55.769942 139758026090240 logging_writer.py:48] [476200] global_step=476200, grad_norm=3.1959710121154785, loss=1.1144229173660278
I0305 03:50:40.554622 139758009304832 logging_writer.py:48] [476300] global_step=476300, grad_norm=2.9357666969299316, loss=2.1663036346435547
I0305 03:51:25.637671 139758026090240 logging_writer.py:48] [476400] global_step=476400, grad_norm=2.9655981063842773, loss=1.2711784839630127
I0305 03:52:10.962553 139758009304832 logging_writer.py:48] [476500] global_step=476500, grad_norm=3.155869483947754, loss=2.5328688621520996
I0305 03:52:55.744974 139758026090240 logging_writer.py:48] [476600] global_step=476600, grad_norm=3.3619930744171143, loss=1.3400481939315796
I0305 03:53:41.107847 139758009304832 logging_writer.py:48] [476700] global_step=476700, grad_norm=3.0577712059020996, loss=2.3766486644744873
I0305 03:54:26.329085 139758026090240 logging_writer.py:48] [476800] global_step=476800, grad_norm=2.9938063621520996, loss=1.5631499290466309
I0305 03:55:11.243973 139758009304832 logging_writer.py:48] [476900] global_step=476900, grad_norm=2.983511447906494, loss=1.4112794399261475
I0305 03:55:56.178009 139758026090240 logging_writer.py:48] [477000] global_step=477000, grad_norm=2.930438280105591, loss=1.3847423791885376
I0305 03:56:10.753160 139953291118400 spec.py:321] Evaluating on the training split.
I0305 03:56:22.295029 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 03:56:48.319440 139953291118400 spec.py:349] Evaluating on the test split.
I0305 03:56:49.951833 139953291118400 submission_runner.py:411] Time since start: 230450.13s, 	Step: 477034, 	{'train/accuracy': 0.8870702981948853, 'train/loss': 0.42077821493148804, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 212191.43901252747, 'total_duration': 230450.12804293633, 'accumulated_submission_time': 212191.43901252747, 'accumulated_eval_time': 18195.48608493805, 'accumulated_logging_time': 38.95311379432678}
I0305 03:56:50.063880 139758009304832 logging_writer.py:48] [477034] accumulated_eval_time=18195.486085, accumulated_logging_time=38.953114, accumulated_submission_time=212191.439013, global_step=477034, preemption_count=0, score=212191.439013, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=230450.128043, train/accuracy=0.887070, train/loss=0.420778, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 03:57:16.506961 139758026090240 logging_writer.py:48] [477100] global_step=477100, grad_norm=2.7551305294036865, loss=1.5548542737960815
I0305 03:58:00.519163 139758009304832 logging_writer.py:48] [477200] global_step=477200, grad_norm=4.516902446746826, loss=3.282689094543457
I0305 03:58:45.614779 139758026090240 logging_writer.py:48] [477300] global_step=477300, grad_norm=3.9346585273742676, loss=1.96963632106781
I0305 03:59:30.926297 139758009304832 logging_writer.py:48] [477400] global_step=477400, grad_norm=3.405755043029785, loss=1.0253190994262695
I0305 04:00:15.920118 139758026090240 logging_writer.py:48] [477500] global_step=477500, grad_norm=2.829178810119629, loss=2.0437562465667725
I0305 04:01:00.774890 139758009304832 logging_writer.py:48] [477600] global_step=477600, grad_norm=3.0913002490997314, loss=1.2868684530258179
I0305 04:01:46.071031 139758026090240 logging_writer.py:48] [477700] global_step=477700, grad_norm=2.941683292388916, loss=1.0601162910461426
I0305 04:02:31.318814 139758009304832 logging_writer.py:48] [477800] global_step=477800, grad_norm=3.900498390197754, loss=3.1653223037719727
I0305 04:03:16.663891 139758026090240 logging_writer.py:48] [477900] global_step=477900, grad_norm=3.443629026412964, loss=1.232466220855713
I0305 04:03:50.274899 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:04:01.386700 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:04:21.603994 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:04:23.237946 139953291118400 submission_runner.py:411] Time since start: 230903.41s, 	Step: 477976, 	{'train/accuracy': 0.8859765529632568, 'train/loss': 0.42003005743026733, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 212611.59212899208, 'total_duration': 230903.41416811943, 'accumulated_submission_time': 212611.59212899208, 'accumulated_eval_time': 18228.449116706848, 'accumulated_logging_time': 39.075315952301025}
I0305 04:04:23.345354 139758009304832 logging_writer.py:48] [477976] accumulated_eval_time=18228.449117, accumulated_logging_time=39.075316, accumulated_submission_time=212611.592129, global_step=477976, preemption_count=0, score=212611.592129, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=230903.414168, train/accuracy=0.885977, train/loss=0.420030, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:04:33.238695 139758026090240 logging_writer.py:48] [478000] global_step=478000, grad_norm=4.107140064239502, loss=3.1208176612854004
I0305 04:05:15.830017 139758009304832 logging_writer.py:48] [478100] global_step=478100, grad_norm=3.5737671852111816, loss=2.8885955810546875
I0305 04:06:00.723101 139758026090240 logging_writer.py:48] [478200] global_step=478200, grad_norm=3.0599303245544434, loss=1.1907546520233154
I0305 04:06:45.999997 139758009304832 logging_writer.py:48] [478300] global_step=478300, grad_norm=2.925241231918335, loss=1.0750408172607422
I0305 04:07:30.958311 139758026090240 logging_writer.py:48] [478400] global_step=478400, grad_norm=2.8543026447296143, loss=2.276444673538208
I0305 04:08:15.887920 139758009304832 logging_writer.py:48] [478500] global_step=478500, grad_norm=3.6293582916259766, loss=3.270596981048584
I0305 04:09:00.598723 139758026090240 logging_writer.py:48] [478600] global_step=478600, grad_norm=3.081913709640503, loss=1.0951873064041138
I0305 04:09:45.940789 139758009304832 logging_writer.py:48] [478700] global_step=478700, grad_norm=3.314847946166992, loss=1.175480604171753
I0305 04:10:30.712946 139758026090240 logging_writer.py:48] [478800] global_step=478800, grad_norm=3.3956828117370605, loss=1.7209547758102417
I0305 04:11:15.687533 139758009304832 logging_writer.py:48] [478900] global_step=478900, grad_norm=3.6827523708343506, loss=3.2679038047790527
I0305 04:11:23.459835 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:11:34.553385 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:11:58.710630 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:12:00.349030 139953291118400 submission_runner.py:411] Time since start: 231360.53s, 	Step: 478919, 	{'train/accuracy': 0.8873242139816284, 'train/loss': 0.41377246379852295, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 213031.64986252785, 'total_duration': 231360.52522921562, 'accumulated_submission_time': 213031.64986252785, 'accumulated_eval_time': 18265.338276863098, 'accumulated_logging_time': 39.19279146194458}
I0305 04:12:00.456084 139758026090240 logging_writer.py:48] [478919] accumulated_eval_time=18265.338277, accumulated_logging_time=39.192791, accumulated_submission_time=213031.649863, global_step=478919, preemption_count=0, score=213031.649863, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=231360.525229, train/accuracy=0.887324, train/loss=0.413772, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:12:32.905530 139758009304832 logging_writer.py:48] [479000] global_step=479000, grad_norm=3.1398186683654785, loss=1.1129133701324463
I0305 04:13:17.851436 139758026090240 logging_writer.py:48] [479100] global_step=479100, grad_norm=3.585988759994507, loss=1.6727938652038574
I0305 04:14:03.298016 139758009304832 logging_writer.py:48] [479200] global_step=479200, grad_norm=3.19343638420105, loss=1.1606193780899048
I0305 04:14:48.346658 139758026090240 logging_writer.py:48] [479300] global_step=479300, grad_norm=3.3360238075256348, loss=1.1069321632385254
I0305 04:15:33.430928 139758009304832 logging_writer.py:48] [479400] global_step=479400, grad_norm=3.430938959121704, loss=2.6555252075195312
I0305 04:16:18.466088 139758026090240 logging_writer.py:48] [479500] global_step=479500, grad_norm=3.2505040168762207, loss=1.4762545824050903
I0305 04:17:03.423082 139758009304832 logging_writer.py:48] [479600] global_step=479600, grad_norm=3.309194326400757, loss=2.409614324569702
I0305 04:17:48.240124 139758026090240 logging_writer.py:48] [479700] global_step=479700, grad_norm=3.339374303817749, loss=1.947585105895996
I0305 04:18:33.241577 139758009304832 logging_writer.py:48] [479800] global_step=479800, grad_norm=3.045248508453369, loss=1.9421894550323486
I0305 04:19:00.715287 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:19:11.745332 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:19:42.049709 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:19:43.674849 139953291118400 submission_runner.py:411] Time since start: 231823.85s, 	Step: 479863, 	{'train/accuracy': 0.8858593702316284, 'train/loss': 0.42393580079078674, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 213451.85127067566, 'total_duration': 231823.8510775566, 'accumulated_submission_time': 213451.85127067566, 'accumulated_eval_time': 18308.297819375992, 'accumulated_logging_time': 39.30975008010864}
I0305 04:19:43.762297 139758026090240 logging_writer.py:48] [479863] accumulated_eval_time=18308.297819, accumulated_logging_time=39.309750, accumulated_submission_time=213451.851271, global_step=479863, preemption_count=0, score=213451.851271, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=231823.851078, train/accuracy=0.885859, train/loss=0.423936, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:19:58.762141 139758009304832 logging_writer.py:48] [479900] global_step=479900, grad_norm=2.8353395462036133, loss=1.5777539014816284
I0305 04:20:39.834383 139758026090240 logging_writer.py:48] [480000] global_step=480000, grad_norm=2.8238813877105713, loss=1.6239495277404785
I0305 04:21:24.752150 139758009304832 logging_writer.py:48] [480100] global_step=480100, grad_norm=2.768538236618042, loss=1.2931169271469116
I0305 04:22:09.837826 139758026090240 logging_writer.py:48] [480200] global_step=480200, grad_norm=3.1066641807556152, loss=1.212100863456726
I0305 04:22:54.641314 139758009304832 logging_writer.py:48] [480300] global_step=480300, grad_norm=3.0845868587493896, loss=1.9794995784759521
I0305 04:23:39.611423 139758026090240 logging_writer.py:48] [480400] global_step=480400, grad_norm=3.374717950820923, loss=1.1096434593200684
I0305 04:24:24.831712 139758009304832 logging_writer.py:48] [480500] global_step=480500, grad_norm=3.4321320056915283, loss=1.155515432357788
I0305 04:25:09.882142 139758026090240 logging_writer.py:48] [480600] global_step=480600, grad_norm=2.940483331680298, loss=1.073920726776123
I0305 04:25:55.093352 139758009304832 logging_writer.py:48] [480700] global_step=480700, grad_norm=3.8152213096618652, loss=3.2976534366607666
I0305 04:26:40.227636 139758026090240 logging_writer.py:48] [480800] global_step=480800, grad_norm=2.9096713066101074, loss=1.9929442405700684
I0305 04:26:43.902673 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:26:54.938953 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:27:24.247174 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:27:25.870125 139953291118400 submission_runner.py:411] Time since start: 232286.05s, 	Step: 480810, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.4194519817829132, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 213871.92631745338, 'total_duration': 232286.0463590622, 'accumulated_submission_time': 213871.92631745338, 'accumulated_eval_time': 18350.265253067017, 'accumulated_logging_time': 39.414989948272705}
I0305 04:27:25.956909 139758009304832 logging_writer.py:48] [480810] accumulated_eval_time=18350.265253, accumulated_logging_time=39.414990, accumulated_submission_time=213871.926317, global_step=480810, preemption_count=0, score=213871.926317, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=232286.046359, train/accuracy=0.888340, train/loss=0.419452, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:28:01.946471 139758026090240 logging_writer.py:48] [480900] global_step=480900, grad_norm=3.187398910522461, loss=2.178029775619507
I0305 04:28:46.677629 139758009304832 logging_writer.py:48] [481000] global_step=481000, grad_norm=3.3181962966918945, loss=1.0848991870880127
I0305 04:29:31.772127 139758026090240 logging_writer.py:48] [481100] global_step=481100, grad_norm=3.8449103832244873, loss=3.1415069103240967
I0305 04:30:17.378419 139758009304832 logging_writer.py:48] [481200] global_step=481200, grad_norm=3.1534295082092285, loss=2.297071695327759
I0305 04:31:02.436375 139758026090240 logging_writer.py:48] [481300] global_step=481300, grad_norm=3.0731985569000244, loss=1.2026739120483398
I0305 04:31:47.609610 139758009304832 logging_writer.py:48] [481400] global_step=481400, grad_norm=3.6625900268554688, loss=1.1540319919586182
I0305 04:32:32.940784 139758026090240 logging_writer.py:48] [481500] global_step=481500, grad_norm=3.78800892829895, loss=2.998603582382202
I0305 04:33:17.915109 139758009304832 logging_writer.py:48] [481600] global_step=481600, grad_norm=2.8556244373321533, loss=1.3409842252731323
I0305 04:34:03.267593 139758026090240 logging_writer.py:48] [481700] global_step=481700, grad_norm=3.049433708190918, loss=1.1933667659759521
I0305 04:34:25.918293 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:34:37.319184 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:35:04.278256 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:35:05.909349 139953291118400 submission_runner.py:411] Time since start: 232746.09s, 	Step: 481752, 	{'train/accuracy': 0.8857226371765137, 'train/loss': 0.42439019680023193, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 214291.83063435555, 'total_duration': 232746.0855693817, 'accumulated_submission_time': 214291.83063435555, 'accumulated_eval_time': 18390.25630378723, 'accumulated_logging_time': 39.5118944644928}
I0305 04:35:06.019923 139758009304832 logging_writer.py:48] [481752] accumulated_eval_time=18390.256304, accumulated_logging_time=39.511894, accumulated_submission_time=214291.830634, global_step=481752, preemption_count=0, score=214291.830634, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=232746.085569, train/accuracy=0.885723, train/loss=0.424390, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:35:25.366360 139758026090240 logging_writer.py:48] [481800] global_step=481800, grad_norm=3.267557382583618, loss=1.1362732648849487
I0305 04:36:08.456313 139758009304832 logging_writer.py:48] [481900] global_step=481900, grad_norm=3.1740829944610596, loss=1.2110013961791992
I0305 04:36:53.752852 139758026090240 logging_writer.py:48] [482000] global_step=482000, grad_norm=3.994680404663086, loss=3.2322182655334473
I0305 04:37:39.162757 139758009304832 logging_writer.py:48] [482100] global_step=482100, grad_norm=3.028259038925171, loss=1.139309287071228
I0305 04:38:24.523551 139758026090240 logging_writer.py:48] [482200] global_step=482200, grad_norm=3.1239001750946045, loss=1.154129981994629
I0305 04:39:09.669307 139758009304832 logging_writer.py:48] [482300] global_step=482300, grad_norm=2.9841082096099854, loss=1.1320977210998535
I0305 04:39:54.661665 139758026090240 logging_writer.py:48] [482400] global_step=482400, grad_norm=3.024824380874634, loss=1.359677791595459
I0305 04:40:39.938886 139758009304832 logging_writer.py:48] [482500] global_step=482500, grad_norm=2.938131093978882, loss=1.640506386756897
I0305 04:41:25.052040 139758026090240 logging_writer.py:48] [482600] global_step=482600, grad_norm=3.161867141723633, loss=2.1760149002075195
I0305 04:42:06.082389 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:42:17.444576 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:42:35.997427 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:42:37.633034 139953291118400 submission_runner.py:411] Time since start: 233197.81s, 	Step: 482692, 	{'train/accuracy': 0.8866796493530273, 'train/loss': 0.42034804821014404, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 214711.83514642715, 'total_duration': 233197.8092508316, 'accumulated_submission_time': 214711.83514642715, 'accumulated_eval_time': 18421.80694413185, 'accumulated_logging_time': 39.632933139801025}
I0305 04:42:37.745196 139758009304832 logging_writer.py:48] [482692] accumulated_eval_time=18421.806944, accumulated_logging_time=39.632933, accumulated_submission_time=214711.835146, global_step=482692, preemption_count=0, score=214711.835146, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=233197.809251, train/accuracy=0.886680, train/loss=0.420348, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:42:41.324280 139758026090240 logging_writer.py:48] [482700] global_step=482700, grad_norm=3.3192529678344727, loss=2.6791372299194336
I0305 04:43:23.243683 139758009304832 logging_writer.py:48] [482800] global_step=482800, grad_norm=3.6584951877593994, loss=3.1701178550720215
I0305 04:44:08.132433 139758026090240 logging_writer.py:48] [482900] global_step=482900, grad_norm=3.0669209957122803, loss=1.6642879247665405
I0305 04:44:52.849318 139758009304832 logging_writer.py:48] [483000] global_step=483000, grad_norm=3.3544483184814453, loss=1.1606802940368652
I0305 04:45:37.901031 139758026090240 logging_writer.py:48] [483100] global_step=483100, grad_norm=3.171903133392334, loss=1.4872503280639648
I0305 04:46:22.818683 139758009304832 logging_writer.py:48] [483200] global_step=483200, grad_norm=4.060083389282227, loss=3.386688232421875
I0305 04:47:07.763039 139758026090240 logging_writer.py:48] [483300] global_step=483300, grad_norm=3.238037109375, loss=1.319766879081726
I0305 04:47:52.579494 139758009304832 logging_writer.py:48] [483400] global_step=483400, grad_norm=2.9488162994384766, loss=1.1347278356552124
I0305 04:48:37.584848 139758026090240 logging_writer.py:48] [483500] global_step=483500, grad_norm=3.949098587036133, loss=3.189415693283081
I0305 04:49:22.583285 139758009304832 logging_writer.py:48] [483600] global_step=483600, grad_norm=3.1887049674987793, loss=1.1513557434082031
I0305 04:49:37.957276 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:49:49.142543 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:50:22.803400 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:50:24.427039 139953291118400 submission_runner.py:411] Time since start: 233664.60s, 	Step: 483636, 	{'train/accuracy': 0.8885937333106995, 'train/loss': 0.41571399569511414, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 215131.989664793, 'total_duration': 233664.60327482224, 'accumulated_submission_time': 215131.989664793, 'accumulated_eval_time': 18468.276699066162, 'accumulated_logging_time': 39.75440168380737}
I0305 04:50:24.516483 139758026090240 logging_writer.py:48] [483636] accumulated_eval_time=18468.276699, accumulated_logging_time=39.754402, accumulated_submission_time=215131.989665, global_step=483636, preemption_count=0, score=215131.989665, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=233664.603275, train/accuracy=0.888594, train/loss=0.415714, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:50:50.156133 139758009304832 logging_writer.py:48] [483700] global_step=483700, grad_norm=3.6093804836273193, loss=2.9284720420837402
I0305 04:51:33.304866 139758026090240 logging_writer.py:48] [483800] global_step=483800, grad_norm=3.5426056385040283, loss=3.1392767429351807
I0305 04:52:18.925880 139758009304832 logging_writer.py:48] [483900] global_step=483900, grad_norm=3.8777084350585938, loss=3.182081460952759
I0305 04:53:04.757965 139758026090240 logging_writer.py:48] [484000] global_step=484000, grad_norm=3.153771162033081, loss=1.6359364986419678
I0305 04:53:49.991885 139758009304832 logging_writer.py:48] [484100] global_step=484100, grad_norm=3.190972328186035, loss=1.962705373764038
I0305 04:54:35.111723 139758026090240 logging_writer.py:48] [484200] global_step=484200, grad_norm=3.2265052795410156, loss=1.5276880264282227
I0305 04:55:20.277616 139758009304832 logging_writer.py:48] [484300] global_step=484300, grad_norm=3.3688948154449463, loss=1.963678002357483
I0305 04:56:05.320151 139758026090240 logging_writer.py:48] [484400] global_step=484400, grad_norm=3.8504867553710938, loss=2.8754396438598633
I0305 04:56:50.494282 139758009304832 logging_writer.py:48] [484500] global_step=484500, grad_norm=3.128228187561035, loss=1.707655668258667
I0305 04:57:24.557475 139953291118400 spec.py:321] Evaluating on the training split.
I0305 04:57:35.594153 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 04:58:02.959395 139953291118400 spec.py:349] Evaluating on the test split.
I0305 04:58:04.582571 139953291118400 submission_runner.py:411] Time since start: 234124.76s, 	Step: 484577, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.42053094506263733, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 215551.972063303, 'total_duration': 234124.75880336761, 'accumulated_submission_time': 215551.972063303, 'accumulated_eval_time': 18508.301794052124, 'accumulated_logging_time': 39.85543179512024}
I0305 04:58:04.670164 139758026090240 logging_writer.py:48] [484577] accumulated_eval_time=18508.301794, accumulated_logging_time=39.855432, accumulated_submission_time=215551.972063, global_step=484577, preemption_count=0, score=215551.972063, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=234124.758803, train/accuracy=0.888066, train/loss=0.420531, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 04:58:14.136721 139758009304832 logging_writer.py:48] [484600] global_step=484600, grad_norm=3.0107100009918213, loss=1.1163996458053589
I0305 04:58:54.986221 139758026090240 logging_writer.py:48] [484700] global_step=484700, grad_norm=3.277636766433716, loss=2.110963821411133
I0305 04:59:40.114781 139758009304832 logging_writer.py:48] [484800] global_step=484800, grad_norm=3.152768135070801, loss=1.1651023626327515
I0305 05:00:25.421295 139758026090240 logging_writer.py:48] [484900] global_step=484900, grad_norm=3.2673707008361816, loss=1.1525514125823975
I0305 05:01:10.793251 139758009304832 logging_writer.py:48] [485000] global_step=485000, grad_norm=3.2466037273406982, loss=1.374662160873413
I0305 05:01:55.951367 139758026090240 logging_writer.py:48] [485100] global_step=485100, grad_norm=3.0715126991271973, loss=2.0970163345336914
I0305 05:02:41.191519 139758009304832 logging_writer.py:48] [485200] global_step=485200, grad_norm=3.0295047760009766, loss=1.5309162139892578
I0305 05:03:26.795007 139758026090240 logging_writer.py:48] [485300] global_step=485300, grad_norm=3.049208164215088, loss=1.2622463703155518
I0305 05:04:11.848341 139758009304832 logging_writer.py:48] [485400] global_step=485400, grad_norm=3.205793857574463, loss=1.1229534149169922
I0305 05:04:57.347078 139758026090240 logging_writer.py:48] [485500] global_step=485500, grad_norm=3.4245975017547607, loss=1.155694842338562
I0305 05:05:04.890060 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:05:16.417083 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:05:35.978976 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:05:37.617495 139953291118400 submission_runner.py:411] Time since start: 234577.79s, 	Step: 485518, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.41701841354370117, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 215972.13434648514, 'total_duration': 234577.79371976852, 'accumulated_submission_time': 215972.13434648514, 'accumulated_eval_time': 18541.02921271324, 'accumulated_logging_time': 39.95377564430237}
I0305 05:05:37.726315 139758009304832 logging_writer.py:48] [485518] accumulated_eval_time=18541.029213, accumulated_logging_time=39.953776, accumulated_submission_time=215972.134346, global_step=485518, preemption_count=0, score=215972.134346, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=234577.793720, train/accuracy=0.887461, train/loss=0.417018, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 05:06:11.364129 139758026090240 logging_writer.py:48] [485600] global_step=485600, grad_norm=3.8979759216308594, loss=3.299738883972168
I0305 05:06:56.433392 139758009304832 logging_writer.py:48] [485700] global_step=485700, grad_norm=2.9424688816070557, loss=1.1187429428100586
I0305 05:07:41.648477 139758026090240 logging_writer.py:48] [485800] global_step=485800, grad_norm=3.552994728088379, loss=1.0534738302230835
I0305 05:08:26.697341 139758009304832 logging_writer.py:48] [485900] global_step=485900, grad_norm=3.1140267848968506, loss=1.1443811655044556
I0305 05:09:11.615429 139758026090240 logging_writer.py:48] [486000] global_step=486000, grad_norm=3.128321409225464, loss=2.65256929397583
I0305 05:09:56.694901 139758009304832 logging_writer.py:48] [486100] global_step=486100, grad_norm=3.0579843521118164, loss=1.0982705354690552
I0305 05:10:41.999686 139758026090240 logging_writer.py:48] [486200] global_step=486200, grad_norm=3.4688148498535156, loss=1.8500206470489502
I0305 05:11:27.126073 139758009304832 logging_writer.py:48] [486300] global_step=486300, grad_norm=3.0942258834838867, loss=1.2967983484268188
I0305 05:12:11.986043 139758026090240 logging_writer.py:48] [486400] global_step=486400, grad_norm=3.5011980533599854, loss=1.2582734823226929
I0305 05:12:38.027821 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:12:49.427663 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:13:19.898081 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:13:21.533054 139953291118400 submission_runner.py:411] Time since start: 235041.71s, 	Step: 486459, 	{'train/accuracy': 0.8861523270606995, 'train/loss': 0.42731788754463196, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 216392.37596464157, 'total_duration': 235041.70927786827, 'accumulated_submission_time': 216392.37596464157, 'accumulated_eval_time': 18584.534476995468, 'accumulated_logging_time': 40.07387638092041}
I0305 05:13:21.622084 139758009304832 logging_writer.py:48] [486459] accumulated_eval_time=18584.534477, accumulated_logging_time=40.073876, accumulated_submission_time=216392.375965, global_step=486459, preemption_count=0, score=216392.375965, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=235041.709278, train/accuracy=0.886152, train/loss=0.427318, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 05:13:38.187237 139758026090240 logging_writer.py:48] [486500] global_step=486500, grad_norm=3.158493995666504, loss=1.9839736223220825
I0305 05:14:20.312040 139758009304832 logging_writer.py:48] [486600] global_step=486600, grad_norm=3.3376305103302, loss=1.0721298456192017
I0305 05:15:05.394903 139758026090240 logging_writer.py:48] [486700] global_step=486700, grad_norm=3.209765911102295, loss=2.5716495513916016
I0305 05:15:50.532063 139758009304832 logging_writer.py:48] [486800] global_step=486800, grad_norm=3.862584352493286, loss=3.248537302017212
I0305 05:16:35.965880 139758026090240 logging_writer.py:48] [486900] global_step=486900, grad_norm=3.278427839279175, loss=1.2588679790496826
I0305 05:17:20.847084 139758009304832 logging_writer.py:48] [487000] global_step=487000, grad_norm=2.983964681625366, loss=1.1799774169921875
I0305 05:18:05.948557 139758026090240 logging_writer.py:48] [487100] global_step=487100, grad_norm=3.0206849575042725, loss=1.8870997428894043
I0305 05:18:50.873916 139758009304832 logging_writer.py:48] [487200] global_step=487200, grad_norm=3.294868230819702, loss=1.1434592008590698
I0305 05:19:35.926272 139758026090240 logging_writer.py:48] [487300] global_step=487300, grad_norm=3.5238516330718994, loss=2.88295578956604
I0305 05:20:20.743214 139758009304832 logging_writer.py:48] [487400] global_step=487400, grad_norm=3.0015995502471924, loss=1.343432068824768
I0305 05:20:21.778748 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:20:32.658719 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:20:59.340815 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:21:00.981341 139953291118400 submission_runner.py:411] Time since start: 235501.16s, 	Step: 487404, 	{'train/accuracy': 0.8877733945846558, 'train/loss': 0.4160880446434021, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 216812.47675943375, 'total_duration': 235501.1575639248, 'accumulated_submission_time': 216812.47675943375, 'accumulated_eval_time': 18623.737052679062, 'accumulated_logging_time': 40.17147946357727}
I0305 05:21:01.092614 139758026090240 logging_writer.py:48] [487404] accumulated_eval_time=18623.737053, accumulated_logging_time=40.171479, accumulated_submission_time=216812.476759, global_step=487404, preemption_count=0, score=216812.476759, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=235501.157564, train/accuracy=0.887773, train/loss=0.416088, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 05:21:40.562902 139758009304832 logging_writer.py:48] [487500] global_step=487500, grad_norm=3.357456684112549, loss=2.995687484741211
I0305 05:22:25.423848 139758026090240 logging_writer.py:48] [487600] global_step=487600, grad_norm=3.0966439247131348, loss=2.0594847202301025
I0305 05:23:10.457255 139758009304832 logging_writer.py:48] [487700] global_step=487700, grad_norm=3.064720869064331, loss=2.0733261108398438
I0305 05:23:55.661847 139758026090240 logging_writer.py:48] [487800] global_step=487800, grad_norm=3.514756202697754, loss=2.2372686862945557
I0305 05:24:40.490225 139758009304832 logging_writer.py:48] [487900] global_step=487900, grad_norm=2.813333749771118, loss=1.0125761032104492
I0305 05:25:25.961150 139758026090240 logging_writer.py:48] [488000] global_step=488000, grad_norm=3.182258367538452, loss=1.1472364664077759
I0305 05:26:10.875873 139758009304832 logging_writer.py:48] [488100] global_step=488100, grad_norm=3.1292166709899902, loss=2.540562391281128
I0305 05:26:55.642422 139758026090240 logging_writer.py:48] [488200] global_step=488200, grad_norm=3.0319323539733887, loss=1.4507653713226318
I0305 05:27:41.089608 139758009304832 logging_writer.py:48] [488300] global_step=488300, grad_norm=3.867527961730957, loss=3.1386704444885254
I0305 05:28:01.023770 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:28:12.630766 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:28:43.846724 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:28:45.463122 139953291118400 submission_runner.py:411] Time since start: 235965.64s, 	Step: 488346, 	{'train/accuracy': 0.8884570002555847, 'train/loss': 0.4186307489871979, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 217232.34973955154, 'total_duration': 235965.63935542107, 'accumulated_submission_time': 217232.34973955154, 'accumulated_eval_time': 18668.176402807236, 'accumulated_logging_time': 40.29322910308838}
I0305 05:28:45.551693 139758026090240 logging_writer.py:48] [488346] accumulated_eval_time=18668.176403, accumulated_logging_time=40.293229, accumulated_submission_time=217232.349740, global_step=488346, preemption_count=0, score=217232.349740, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=235965.639355, train/accuracy=0.888457, train/loss=0.418631, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 05:29:07.237534 139758009304832 logging_writer.py:48] [488400] global_step=488400, grad_norm=3.434530735015869, loss=1.1889322996139526
I0305 05:29:50.327972 139758026090240 logging_writer.py:48] [488500] global_step=488500, grad_norm=3.1935853958129883, loss=1.0398555994033813
I0305 05:30:35.252720 139758009304832 logging_writer.py:48] [488600] global_step=488600, grad_norm=3.047687530517578, loss=2.043503761291504
I0305 05:31:20.771081 139758026090240 logging_writer.py:48] [488700] global_step=488700, grad_norm=3.1262001991271973, loss=1.2207212448120117
I0305 05:32:05.822401 139758009304832 logging_writer.py:48] [488800] global_step=488800, grad_norm=3.4132754802703857, loss=2.626093626022339
I0305 05:32:50.659089 139758026090240 logging_writer.py:48] [488900] global_step=488900, grad_norm=5.738804340362549, loss=2.9619202613830566
I0305 05:33:35.827745 139758009304832 logging_writer.py:48] [489000] global_step=489000, grad_norm=3.003215789794922, loss=1.0955859422683716
I0305 05:34:20.787104 139758026090240 logging_writer.py:48] [489100] global_step=489100, grad_norm=2.7396886348724365, loss=1.5293245315551758
I0305 05:35:05.926431 139758009304832 logging_writer.py:48] [489200] global_step=489200, grad_norm=3.12831711769104, loss=1.1501495838165283
I0305 05:35:45.913101 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:35:57.110415 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:36:21.309607 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:36:22.944833 139953291118400 submission_runner.py:411] Time since start: 236423.12s, 	Step: 489290, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.4156650900840759, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 217652.6532354355, 'total_duration': 236423.1210463047, 'accumulated_submission_time': 217652.6532354355, 'accumulated_eval_time': 18705.208114624023, 'accumulated_logging_time': 40.391053676605225}
I0305 05:36:23.064320 139758026090240 logging_writer.py:48] [489290] accumulated_eval_time=18705.208115, accumulated_logging_time=40.391054, accumulated_submission_time=217652.653235, global_step=489290, preemption_count=0, score=217652.653235, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=236423.121046, train/accuracy=0.888438, train/loss=0.415665, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 05:36:27.428972 139758009304832 logging_writer.py:48] [489300] global_step=489300, grad_norm=2.962754011154175, loss=1.2139065265655518
I0305 05:37:09.210283 139758026090240 logging_writer.py:48] [489400] global_step=489400, grad_norm=2.9762113094329834, loss=2.0754802227020264
I0305 05:37:54.035480 139758009304832 logging_writer.py:48] [489500] global_step=489500, grad_norm=3.0908749103546143, loss=1.717867374420166
I0305 05:38:39.090695 139758026090240 logging_writer.py:48] [489600] global_step=489600, grad_norm=3.0069708824157715, loss=1.3720722198486328
I0305 05:39:24.355034 139758009304832 logging_writer.py:48] [489700] global_step=489700, grad_norm=3.5333712100982666, loss=3.2107772827148438
I0305 05:40:09.166420 139758026090240 logging_writer.py:48] [489800] global_step=489800, grad_norm=3.5606026649475098, loss=2.171766757965088
I0305 05:40:53.933886 139758009304832 logging_writer.py:48] [489900] global_step=489900, grad_norm=3.9616403579711914, loss=3.3691325187683105
I0305 05:41:39.093052 139758026090240 logging_writer.py:48] [490000] global_step=490000, grad_norm=2.9595730304718018, loss=1.0841153860092163
I0305 05:42:24.237651 139758009304832 logging_writer.py:48] [490100] global_step=490100, grad_norm=3.1260969638824463, loss=1.2945364713668823
I0305 05:43:09.042613 139758026090240 logging_writer.py:48] [490200] global_step=490200, grad_norm=3.1620142459869385, loss=1.0970386266708374
I0305 05:43:23.086731 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:43:34.473621 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:44:07.864452 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:44:09.496825 139953291118400 submission_runner.py:411] Time since start: 236889.67s, 	Step: 490233, 	{'train/accuracy': 0.8855859041213989, 'train/loss': 0.41885122656822205, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 218072.61851358414, 'total_duration': 236889.67304754257, 'accumulated_submission_time': 218072.61851358414, 'accumulated_eval_time': 18751.618181467056, 'accumulated_logging_time': 40.52058506011963}
I0305 05:44:09.609224 139758009304832 logging_writer.py:48] [490233] accumulated_eval_time=18751.618181, accumulated_logging_time=40.520585, accumulated_submission_time=218072.618514, global_step=490233, preemption_count=0, score=218072.618514, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=236889.673048, train/accuracy=0.885586, train/loss=0.418851, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 05:44:36.432363 139758026090240 logging_writer.py:48] [490300] global_step=490300, grad_norm=3.146056890487671, loss=1.1775249242782593
I0305 05:45:20.212463 139758009304832 logging_writer.py:48] [490400] global_step=490400, grad_norm=3.25718355178833, loss=2.479836940765381
I0305 05:46:05.377893 139758026090240 logging_writer.py:48] [490500] global_step=490500, grad_norm=3.1013145446777344, loss=1.4382046461105347
I0305 05:46:50.748580 139758009304832 logging_writer.py:48] [490600] global_step=490600, grad_norm=3.1761794090270996, loss=2.346820831298828
I0305 05:47:35.882399 139758026090240 logging_writer.py:48] [490700] global_step=490700, grad_norm=2.9831018447875977, loss=2.143052577972412
I0305 05:48:20.985311 139758009304832 logging_writer.py:48] [490800] global_step=490800, grad_norm=3.352783679962158, loss=1.11017906665802
I0305 05:49:06.088707 139758026090240 logging_writer.py:48] [490900] global_step=490900, grad_norm=3.111178398132324, loss=1.1240031719207764
I0305 05:49:50.826873 139758009304832 logging_writer.py:48] [491000] global_step=491000, grad_norm=3.156193256378174, loss=2.42319393157959
I0305 05:50:35.960349 139758026090240 logging_writer.py:48] [491100] global_step=491100, grad_norm=3.3172521591186523, loss=2.3487136363983154
I0305 05:51:10.238581 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:51:21.544587 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:51:50.192813 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:51:51.821180 139953291118400 submission_runner.py:411] Time since start: 237352.00s, 	Step: 491177, 	{'train/accuracy': 0.8892577886581421, 'train/loss': 0.41707324981689453, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 218493.1903386116, 'total_duration': 237351.99741578102, 'accumulated_submission_time': 218493.1903386116, 'accumulated_eval_time': 18793.20076608658, 'accumulated_logging_time': 40.64298367500305}
I0305 05:51:51.909348 139758009304832 logging_writer.py:48] [491177] accumulated_eval_time=18793.200766, accumulated_logging_time=40.642984, accumulated_submission_time=218493.190339, global_step=491177, preemption_count=0, score=218493.190339, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=237351.997416, train/accuracy=0.889258, train/loss=0.417073, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 05:52:01.379670 139758026090240 logging_writer.py:48] [491200] global_step=491200, grad_norm=3.0400872230529785, loss=1.1834080219268799
I0305 05:52:42.676673 139758009304832 logging_writer.py:48] [491300] global_step=491300, grad_norm=3.0778298377990723, loss=1.4199719429016113
I0305 05:53:27.618183 139758026090240 logging_writer.py:48] [491400] global_step=491400, grad_norm=3.1895458698272705, loss=1.1825021505355835
I0305 05:54:12.849718 139758009304832 logging_writer.py:48] [491500] global_step=491500, grad_norm=3.157759189605713, loss=2.0539278984069824
I0305 05:54:57.973308 139758026090240 logging_writer.py:48] [491600] global_step=491600, grad_norm=3.4190030097961426, loss=1.2052091360092163
I0305 05:55:43.144650 139758009304832 logging_writer.py:48] [491700] global_step=491700, grad_norm=3.333892345428467, loss=1.191698431968689
I0305 05:56:28.312789 139758026090240 logging_writer.py:48] [491800] global_step=491800, grad_norm=3.5784900188446045, loss=2.623382806777954
I0305 05:57:13.574890 139758009304832 logging_writer.py:48] [491900] global_step=491900, grad_norm=3.347221612930298, loss=1.1765637397766113
I0305 05:57:58.343297 139758026090240 logging_writer.py:48] [492000] global_step=492000, grad_norm=3.0533549785614014, loss=1.1355422735214233
I0305 05:58:43.215436 139758009304832 logging_writer.py:48] [492100] global_step=492100, grad_norm=3.138364791870117, loss=1.3633853197097778
I0305 05:58:51.925309 139953291118400 spec.py:321] Evaluating on the training split.
I0305 05:59:03.445563 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 05:59:26.484251 139953291118400 spec.py:349] Evaluating on the test split.
I0305 05:59:28.120907 139953291118400 submission_runner.py:411] Time since start: 237808.30s, 	Step: 492121, 	{'train/accuracy': 0.8887695074081421, 'train/loss': 0.4192838668823242, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 218913.1488711834, 'total_duration': 237808.29712486267, 'accumulated_submission_time': 218913.1488711834, 'accumulated_eval_time': 18829.3963367939, 'accumulated_logging_time': 40.741400957107544}
I0305 05:59:28.261176 139758026090240 logging_writer.py:48] [492121] accumulated_eval_time=18829.396337, accumulated_logging_time=40.741401, accumulated_submission_time=218913.148871, global_step=492121, preemption_count=0, score=218913.148871, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=237808.297125, train/accuracy=0.888770, train/loss=0.419284, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:00:00.678701 139758009304832 logging_writer.py:48] [492200] global_step=492200, grad_norm=2.9416801929473877, loss=1.5866498947143555
I0305 06:00:45.560447 139758026090240 logging_writer.py:48] [492300] global_step=492300, grad_norm=3.0919454097747803, loss=1.2371821403503418
I0305 06:01:30.542825 139758009304832 logging_writer.py:48] [492400] global_step=492400, grad_norm=3.1322073936462402, loss=2.7882015705108643
I0305 06:02:15.833140 139758026090240 logging_writer.py:48] [492500] global_step=492500, grad_norm=3.2592811584472656, loss=1.0529170036315918
I0305 06:03:00.630606 139758009304832 logging_writer.py:48] [492600] global_step=492600, grad_norm=3.1392788887023926, loss=1.771366000175476
I0305 06:03:45.747200 139758026090240 logging_writer.py:48] [492700] global_step=492700, grad_norm=3.0280508995056152, loss=1.1603926420211792
I0305 06:04:30.673204 139758009304832 logging_writer.py:48] [492800] global_step=492800, grad_norm=3.108078956604004, loss=1.2262043952941895
I0305 06:05:15.778540 139758026090240 logging_writer.py:48] [492900] global_step=492900, grad_norm=2.818129301071167, loss=1.531692385673523
I0305 06:06:01.131375 139758009304832 logging_writer.py:48] [493000] global_step=493000, grad_norm=3.7141222953796387, loss=3.1957056522369385
I0305 06:06:28.489223 139953291118400 spec.py:321] Evaluating on the training split.
I0305 06:06:39.729813 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 06:07:05.996381 139953291118400 spec.py:349] Evaluating on the test split.
I0305 06:07:07.633115 139953291118400 submission_runner.py:411] Time since start: 238267.81s, 	Step: 493062, 	{'train/accuracy': 0.8889257907867432, 'train/loss': 0.41226324439048767, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 219333.3186454773, 'total_duration': 238267.8093366623, 'accumulated_submission_time': 219333.3186454773, 'accumulated_eval_time': 18868.54022550583, 'accumulated_logging_time': 40.892817974090576}
I0305 06:07:07.747189 139758026090240 logging_writer.py:48] [493062] accumulated_eval_time=18868.540226, accumulated_logging_time=40.892818, accumulated_submission_time=219333.318645, global_step=493062, preemption_count=0, score=219333.318645, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=238267.809337, train/accuracy=0.888926, train/loss=0.412263, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:07:23.161190 139758009304832 logging_writer.py:48] [493100] global_step=493100, grad_norm=4.038342475891113, loss=3.204505681991577
I0305 06:08:06.259566 139758026090240 logging_writer.py:48] [493200] global_step=493200, grad_norm=3.780872106552124, loss=3.383819103240967
I0305 06:08:51.255548 139758009304832 logging_writer.py:48] [493300] global_step=493300, grad_norm=3.10731840133667, loss=1.1166441440582275
I0305 06:09:36.277773 139758026090240 logging_writer.py:48] [493400] global_step=493400, grad_norm=2.858532667160034, loss=1.0980448722839355
I0305 06:10:21.383188 139758009304832 logging_writer.py:48] [493500] global_step=493500, grad_norm=2.991767406463623, loss=1.3765065670013428
I0305 06:11:06.402008 139758026090240 logging_writer.py:48] [493600] global_step=493600, grad_norm=3.012604236602783, loss=1.0873819589614868
I0305 06:11:51.337518 139758009304832 logging_writer.py:48] [493700] global_step=493700, grad_norm=3.1727418899536133, loss=1.4856364727020264
I0305 06:12:36.776598 139758026090240 logging_writer.py:48] [493800] global_step=493800, grad_norm=3.184283971786499, loss=1.2813538312911987
I0305 06:13:21.712302 139758009304832 logging_writer.py:48] [493900] global_step=493900, grad_norm=3.0657992362976074, loss=1.8025028705596924
I0305 06:14:07.190123 139758026090240 logging_writer.py:48] [494000] global_step=494000, grad_norm=3.152143955230713, loss=1.1275463104248047
I0305 06:14:07.810503 139953291118400 spec.py:321] Evaluating on the training split.
I0305 06:14:19.050154 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 06:14:43.721554 139953291118400 spec.py:349] Evaluating on the test split.
I0305 06:14:45.353683 139953291118400 submission_runner.py:411] Time since start: 238725.53s, 	Step: 494003, 	{'train/accuracy': 0.8864257335662842, 'train/loss': 0.4204651415348053, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 219753.3205792904, 'total_duration': 238725.52990865707, 'accumulated_submission_time': 219753.3205792904, 'accumulated_eval_time': 18906.0834171772, 'accumulated_logging_time': 41.02065348625183}
I0305 06:14:45.464180 139758009304832 logging_writer.py:48] [494003] accumulated_eval_time=18906.083417, accumulated_logging_time=41.020653, accumulated_submission_time=219753.320579, global_step=494003, preemption_count=0, score=219753.320579, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=238725.529909, train/accuracy=0.886426, train/loss=0.420465, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:15:25.522710 139758026090240 logging_writer.py:48] [494100] global_step=494100, grad_norm=3.2128565311431885, loss=1.0695827007293701
I0305 06:16:10.993985 139758009304832 logging_writer.py:48] [494200] global_step=494200, grad_norm=3.0281200408935547, loss=1.2140058279037476
I0305 06:16:56.403699 139758026090240 logging_writer.py:48] [494300] global_step=494300, grad_norm=3.338961124420166, loss=2.9283034801483154
I0305 06:17:41.783817 139758009304832 logging_writer.py:48] [494400] global_step=494400, grad_norm=3.8615193367004395, loss=3.2989370822906494
I0305 06:18:26.698612 139758026090240 logging_writer.py:48] [494500] global_step=494500, grad_norm=3.0579540729522705, loss=1.1197319030761719
I0305 06:19:11.972209 139758009304832 logging_writer.py:48] [494600] global_step=494600, grad_norm=3.1429054737091064, loss=1.0580726861953735
I0305 06:19:57.355598 139758026090240 logging_writer.py:48] [494700] global_step=494700, grad_norm=3.26570200920105, loss=2.361393690109253
I0305 06:20:42.670142 139758009304832 logging_writer.py:48] [494800] global_step=494800, grad_norm=3.547329902648926, loss=2.8298399448394775
I0305 06:21:27.629312 139758026090240 logging_writer.py:48] [494900] global_step=494900, grad_norm=2.900390148162842, loss=1.4739234447479248
I0305 06:21:45.458042 139953291118400 spec.py:321] Evaluating on the training split.
I0305 06:21:57.467495 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 06:22:22.603672 139953291118400 spec.py:349] Evaluating on the test split.
I0305 06:22:24.236697 139953291118400 submission_runner.py:411] Time since start: 239184.41s, 	Step: 494941, 	{'train/accuracy': 0.8876562118530273, 'train/loss': 0.41569972038269043, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 220173.25746822357, 'total_duration': 239184.4129190445, 'accumulated_submission_time': 220173.25746822357, 'accumulated_eval_time': 18944.862055540085, 'accumulated_logging_time': 41.14168167114258}
I0305 06:22:24.346586 139758009304832 logging_writer.py:48] [494941] accumulated_eval_time=18944.862056, accumulated_logging_time=41.141682, accumulated_submission_time=220173.257468, global_step=494941, preemption_count=0, score=220173.257468, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=239184.412919, train/accuracy=0.887656, train/loss=0.415700, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:22:48.061131 139758026090240 logging_writer.py:48] [495000] global_step=495000, grad_norm=3.2215332984924316, loss=2.37567400932312
I0305 06:23:31.950618 139758009304832 logging_writer.py:48] [495100] global_step=495100, grad_norm=3.1361098289489746, loss=1.2278157472610474
I0305 06:24:17.284049 139758026090240 logging_writer.py:48] [495200] global_step=495200, grad_norm=3.005328416824341, loss=1.2576401233673096
I0305 06:25:02.427251 139758009304832 logging_writer.py:48] [495300] global_step=495300, grad_norm=3.3372669219970703, loss=1.1600499153137207
I0305 06:25:47.410940 139758026090240 logging_writer.py:48] [495400] global_step=495400, grad_norm=2.8703644275665283, loss=1.1016778945922852
I0305 06:26:33.093606 139758009304832 logging_writer.py:48] [495500] global_step=495500, grad_norm=2.8299264907836914, loss=1.0687429904937744
I0305 06:27:18.059826 139758026090240 logging_writer.py:48] [495600] global_step=495600, grad_norm=3.164823055267334, loss=1.0977962017059326
I0305 06:28:02.841266 139758009304832 logging_writer.py:48] [495700] global_step=495700, grad_norm=3.102579355239868, loss=1.108776330947876
I0305 06:28:47.830206 139758026090240 logging_writer.py:48] [495800] global_step=495800, grad_norm=2.9977869987487793, loss=1.6253845691680908
I0305 06:29:24.486757 139953291118400 spec.py:321] Evaluating on the training split.
I0305 06:29:35.722794 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 06:30:02.649413 139953291118400 spec.py:349] Evaluating on the test split.
I0305 06:30:04.279815 139953291118400 submission_runner.py:411] Time since start: 239644.46s, 	Step: 495883, 	{'train/accuracy': 0.8883593678474426, 'train/loss': 0.414913535118103, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 220593.34018707275, 'total_duration': 239644.45602679253, 'accumulated_submission_time': 220593.34018707275, 'accumulated_eval_time': 18984.655094623566, 'accumulated_logging_time': 41.261394739151}
I0305 06:30:04.393345 139758009304832 logging_writer.py:48] [495883] accumulated_eval_time=18984.655095, accumulated_logging_time=41.261395, accumulated_submission_time=220593.340187, global_step=495883, preemption_count=0, score=220593.340187, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=239644.456027, train/accuracy=0.888359, train/loss=0.414914, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:30:11.532366 139758026090240 logging_writer.py:48] [495900] global_step=495900, grad_norm=3.2235653400421143, loss=2.8400161266326904
I0305 06:30:53.163478 139758009304832 logging_writer.py:48] [496000] global_step=496000, grad_norm=3.0325918197631836, loss=1.094229817390442
I0305 06:31:38.130451 139758026090240 logging_writer.py:48] [496100] global_step=496100, grad_norm=2.9641764163970947, loss=1.0902745723724365
I0305 06:32:23.120984 139758009304832 logging_writer.py:48] [496200] global_step=496200, grad_norm=3.0524582862854004, loss=1.9454103708267212
I0305 06:33:08.205629 139758026090240 logging_writer.py:48] [496300] global_step=496300, grad_norm=2.724187135696411, loss=1.1426503658294678
I0305 06:33:53.000630 139758009304832 logging_writer.py:48] [496400] global_step=496400, grad_norm=2.9994876384735107, loss=1.3074047565460205
I0305 06:34:37.866791 139758026090240 logging_writer.py:48] [496500] global_step=496500, grad_norm=2.9565038681030273, loss=1.0762276649475098
I0305 06:35:22.803129 139758009304832 logging_writer.py:48] [496600] global_step=496600, grad_norm=3.3231310844421387, loss=1.203317403793335
I0305 06:36:07.904396 139758026090240 logging_writer.py:48] [496700] global_step=496700, grad_norm=2.870818614959717, loss=1.5801680088043213
I0305 06:36:53.096409 139758009304832 logging_writer.py:48] [496800] global_step=496800, grad_norm=2.9461166858673096, loss=1.2191336154937744
I0305 06:37:04.572753 139953291118400 spec.py:321] Evaluating on the training split.
I0305 06:37:15.602190 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 06:37:41.038514 139953291118400 spec.py:349] Evaluating on the test split.
I0305 06:37:42.667427 139953291118400 submission_runner.py:411] Time since start: 240102.84s, 	Step: 496827, 	{'train/accuracy': 0.8857421875, 'train/loss': 0.4213462769985199, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 221013.46103596687, 'total_duration': 240102.84364795685, 'accumulated_submission_time': 221013.46103596687, 'accumulated_eval_time': 19022.749748706818, 'accumulated_logging_time': 41.385963916778564}
I0305 06:37:42.782641 139758026090240 logging_writer.py:48] [496827] accumulated_eval_time=19022.749749, accumulated_logging_time=41.385964, accumulated_submission_time=221013.461036, global_step=496827, preemption_count=0, score=221013.461036, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=240102.843648, train/accuracy=0.885742, train/loss=0.421346, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:38:12.010180 139758009304832 logging_writer.py:48] [496900] global_step=496900, grad_norm=3.2795355319976807, loss=1.1728147268295288
I0305 06:38:56.735199 139758026090240 logging_writer.py:48] [497000] global_step=497000, grad_norm=3.118083953857422, loss=1.1416360139846802
I0305 06:39:41.589544 139758009304832 logging_writer.py:48] [497100] global_step=497100, grad_norm=3.536229133605957, loss=2.91992449760437
I0305 06:40:26.658904 139758026090240 logging_writer.py:48] [497200] global_step=497200, grad_norm=3.090423822402954, loss=1.636374592781067
I0305 06:41:11.303844 139758009304832 logging_writer.py:48] [497300] global_step=497300, grad_norm=2.946622371673584, loss=1.1910099983215332
I0305 06:41:56.109777 139758026090240 logging_writer.py:48] [497400] global_step=497400, grad_norm=3.790449380874634, loss=1.163494348526001
I0305 06:42:41.058989 139758009304832 logging_writer.py:48] [497500] global_step=497500, grad_norm=3.4196789264678955, loss=1.1908131837844849
I0305 06:43:25.826007 139758026090240 logging_writer.py:48] [497600] global_step=497600, grad_norm=3.8372700214385986, loss=3.289236068725586
I0305 06:44:10.859015 139758009304832 logging_writer.py:48] [497700] global_step=497700, grad_norm=3.6182496547698975, loss=3.358664035797119
I0305 06:44:43.083617 139953291118400 spec.py:321] Evaluating on the training split.
I0305 06:44:54.272397 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 06:45:24.635934 139953291118400 spec.py:349] Evaluating on the test split.
I0305 06:45:26.272890 139953291118400 submission_runner.py:411] Time since start: 240566.45s, 	Step: 497773, 	{'train/accuracy': 0.8886523246765137, 'train/loss': 0.4136727452278137, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 221433.70231842995, 'total_duration': 240566.44911289215, 'accumulated_submission_time': 221433.70231842995, 'accumulated_eval_time': 19065.939003944397, 'accumulated_logging_time': 41.512983322143555}
I0305 06:45:26.385298 139758026090240 logging_writer.py:48] [497773] accumulated_eval_time=19065.939004, accumulated_logging_time=41.512983, accumulated_submission_time=221433.702318, global_step=497773, preemption_count=0, score=221433.702318, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=240566.449113, train/accuracy=0.888652, train/loss=0.413673, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:45:37.455121 139758009304832 logging_writer.py:48] [497800] global_step=497800, grad_norm=5.141709804534912, loss=2.1695668697357178
I0305 06:46:19.421493 139758026090240 logging_writer.py:48] [497900] global_step=497900, grad_norm=3.020777702331543, loss=1.4407998323440552
I0305 06:47:04.971285 139758009304832 logging_writer.py:48] [498000] global_step=498000, grad_norm=2.980132579803467, loss=1.7145628929138184
I0305 06:47:50.647445 139758026090240 logging_writer.py:48] [498100] global_step=498100, grad_norm=3.265244722366333, loss=1.1311695575714111
I0305 06:48:36.205070 139758009304832 logging_writer.py:48] [498200] global_step=498200, grad_norm=3.0078139305114746, loss=1.1201071739196777
I0305 06:49:21.126914 139758026090240 logging_writer.py:48] [498300] global_step=498300, grad_norm=3.162748098373413, loss=1.149497389793396
I0305 06:50:06.373536 139758009304832 logging_writer.py:48] [498400] global_step=498400, grad_norm=3.015397548675537, loss=1.1923143863677979
I0305 06:50:51.995184 139758026090240 logging_writer.py:48] [498500] global_step=498500, grad_norm=3.218363046646118, loss=2.5527830123901367
I0305 06:51:36.793709 139758009304832 logging_writer.py:48] [498600] global_step=498600, grad_norm=3.3763978481292725, loss=3.007810354232788
I0305 06:52:22.082732 139758026090240 logging_writer.py:48] [498700] global_step=498700, grad_norm=3.181185722351074, loss=1.1258361339569092
I0305 06:52:26.693037 139953291118400 spec.py:321] Evaluating on the training split.
I0305 06:52:37.831928 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 06:53:08.158847 139953291118400 spec.py:349] Evaluating on the test split.
I0305 06:53:09.793470 139953291118400 submission_runner.py:411] Time since start: 241029.97s, 	Step: 498712, 	{'train/accuracy': 0.8863085508346558, 'train/loss': 0.4256725311279297, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 221853.9527220726, 'total_duration': 241029.9697060585, 'accumulated_submission_time': 221853.9527220726, 'accumulated_eval_time': 19109.039420604706, 'accumulated_logging_time': 41.63520693778992}
I0305 06:53:09.882524 139758009304832 logging_writer.py:48] [498712] accumulated_eval_time=19109.039421, accumulated_logging_time=41.635207, accumulated_submission_time=221853.952722, global_step=498712, preemption_count=0, score=221853.952722, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=241029.969706, train/accuracy=0.886309, train/loss=0.425673, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 06:53:45.136850 139758026090240 logging_writer.py:48] [498800] global_step=498800, grad_norm=3.0886974334716797, loss=1.3047316074371338
I0305 06:54:29.977509 139758009304832 logging_writer.py:48] [498900] global_step=498900, grad_norm=2.8855690956115723, loss=1.6580840349197388
I0305 06:55:15.108548 139758026090240 logging_writer.py:48] [499000] global_step=499000, grad_norm=3.3204119205474854, loss=1.415570616722107
I0305 06:56:00.269616 139758009304832 logging_writer.py:48] [499100] global_step=499100, grad_norm=2.8398613929748535, loss=1.744916319847107
I0305 06:56:45.500421 139758026090240 logging_writer.py:48] [499200] global_step=499200, grad_norm=3.014200448989868, loss=2.6827340126037598
I0305 06:57:30.405851 139758009304832 logging_writer.py:48] [499300] global_step=499300, grad_norm=3.8487887382507324, loss=3.191138982772827
I0305 06:58:15.505599 139758026090240 logging_writer.py:48] [499400] global_step=499400, grad_norm=3.5631422996520996, loss=3.0472636222839355
I0305 06:59:00.356408 139758009304832 logging_writer.py:48] [499500] global_step=499500, grad_norm=3.029177188873291, loss=1.1379826068878174
I0305 06:59:45.286751 139758026090240 logging_writer.py:48] [499600] global_step=499600, grad_norm=3.455349922180176, loss=1.5749808549880981
I0305 07:00:10.062888 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:00:21.684828 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:00:49.324383 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:00:50.938546 139953291118400 submission_runner.py:411] Time since start: 241491.11s, 	Step: 499657, 	{'train/accuracy': 0.8865820169448853, 'train/loss': 0.4248594641685486, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 222274.07694411278, 'total_duration': 241491.11478090286, 'accumulated_submission_time': 222274.07694411278, 'accumulated_eval_time': 19149.91508102417, 'accumulated_logging_time': 41.732800245285034}
I0305 07:00:51.027196 139758009304832 logging_writer.py:48] [499657] accumulated_eval_time=19149.915081, accumulated_logging_time=41.732800, accumulated_submission_time=222274.076944, global_step=499657, preemption_count=0, score=222274.076944, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=241491.114781, train/accuracy=0.886582, train/loss=0.424859, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:01:08.384773 139758026090240 logging_writer.py:48] [499700] global_step=499700, grad_norm=3.2722795009613037, loss=2.8231048583984375
I0305 07:01:50.617989 139758009304832 logging_writer.py:48] [499800] global_step=499800, grad_norm=3.314589738845825, loss=2.5592167377471924
I0305 07:02:35.469760 139758026090240 logging_writer.py:48] [499900] global_step=499900, grad_norm=3.01278018951416, loss=2.244358777999878
I0305 07:03:20.322051 139758009304832 logging_writer.py:48] [500000] global_step=500000, grad_norm=3.156914710998535, loss=1.4445252418518066
I0305 07:04:05.240339 139758026090240 logging_writer.py:48] [500100] global_step=500100, grad_norm=3.129807710647583, loss=2.5169806480407715
I0305 07:04:50.095921 139758009304832 logging_writer.py:48] [500200] global_step=500200, grad_norm=3.2390599250793457, loss=2.0962374210357666
I0305 07:05:35.115255 139758026090240 logging_writer.py:48] [500300] global_step=500300, grad_norm=2.9935078620910645, loss=1.0829252004623413
I0305 07:06:20.347759 139758009304832 logging_writer.py:48] [500400] global_step=500400, grad_norm=3.1020314693450928, loss=1.685031771659851
I0305 07:07:05.490222 139758026090240 logging_writer.py:48] [500500] global_step=500500, grad_norm=3.2257399559020996, loss=1.6567736864089966
I0305 07:07:50.543130 139758009304832 logging_writer.py:48] [500600] global_step=500600, grad_norm=2.7594051361083984, loss=1.100890040397644
I0305 07:07:51.154527 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:08:02.686193 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:08:24.652144 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:08:26.290877 139953291118400 submission_runner.py:411] Time since start: 241946.47s, 	Step: 500603, 	{'train/accuracy': 0.8859961032867432, 'train/loss': 0.41997671127319336, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 222694.147285223, 'total_duration': 241946.46710276604, 'accumulated_submission_time': 222694.147285223, 'accumulated_eval_time': 19185.05141544342, 'accumulated_logging_time': 41.83038401603699}
I0305 07:08:26.408607 139758026090240 logging_writer.py:48] [500603] accumulated_eval_time=19185.051415, accumulated_logging_time=41.830384, accumulated_submission_time=222694.147285, global_step=500603, preemption_count=0, score=222694.147285, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=241946.467103, train/accuracy=0.885996, train/loss=0.419977, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:09:06.794818 139758009304832 logging_writer.py:48] [500700] global_step=500700, grad_norm=3.66080904006958, loss=2.897305488586426
I0305 07:09:51.583443 139758026090240 logging_writer.py:48] [500800] global_step=500800, grad_norm=3.3267781734466553, loss=1.0623222589492798
I0305 07:10:36.842534 139758009304832 logging_writer.py:48] [500900] global_step=500900, grad_norm=3.0029516220092773, loss=1.0802972316741943
I0305 07:11:22.085946 139758026090240 logging_writer.py:48] [501000] global_step=501000, grad_norm=3.7418622970581055, loss=3.319206953048706
I0305 07:12:07.210651 139758009304832 logging_writer.py:48] [501100] global_step=501100, grad_norm=3.690706253051758, loss=3.147341251373291
I0305 07:12:52.272768 139758026090240 logging_writer.py:48] [501200] global_step=501200, grad_norm=3.243748903274536, loss=1.0361164808273315
I0305 07:13:37.352274 139758009304832 logging_writer.py:48] [501300] global_step=501300, grad_norm=3.3438353538513184, loss=1.104865550994873
I0305 07:14:22.547613 139758026090240 logging_writer.py:48] [501400] global_step=501400, grad_norm=2.9182515144348145, loss=1.48428213596344
I0305 07:15:07.848363 139758009304832 logging_writer.py:48] [501500] global_step=501500, grad_norm=3.848421573638916, loss=3.025817632675171
I0305 07:15:26.560211 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:15:37.928358 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:16:04.493619 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:16:06.123160 139953291118400 submission_runner.py:411] Time since start: 242406.30s, 	Step: 501543, 	{'train/accuracy': 0.8876171708106995, 'train/loss': 0.42056307196617126, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 223114.2418487072, 'total_duration': 242406.29938435555, 'accumulated_submission_time': 223114.2418487072, 'accumulated_eval_time': 19224.614339590073, 'accumulated_logging_time': 41.95796823501587}
I0305 07:16:06.238086 139758026090240 logging_writer.py:48] [501543] accumulated_eval_time=19224.614340, accumulated_logging_time=41.957968, accumulated_submission_time=223114.241849, global_step=501543, preemption_count=0, score=223114.241849, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=242406.299384, train/accuracy=0.887617, train/loss=0.420563, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:16:29.113690 139758009304832 logging_writer.py:48] [501600] global_step=501600, grad_norm=3.6180272102355957, loss=3.2024080753326416
I0305 07:17:12.957049 139758026090240 logging_writer.py:48] [501700] global_step=501700, grad_norm=3.7494089603424072, loss=3.0315630435943604
I0305 07:17:58.269101 139758009304832 logging_writer.py:48] [501800] global_step=501800, grad_norm=3.1249706745147705, loss=2.4819464683532715
I0305 07:18:43.712637 139758026090240 logging_writer.py:48] [501900] global_step=501900, grad_norm=3.1641452312469482, loss=1.0527105331420898
I0305 07:19:29.002857 139758009304832 logging_writer.py:48] [502000] global_step=502000, grad_norm=3.6153831481933594, loss=1.1196638345718384
I0305 07:20:14.088127 139758026090240 logging_writer.py:48] [502100] global_step=502100, grad_norm=3.4374313354492188, loss=1.1566097736358643
I0305 07:20:59.257035 139758009304832 logging_writer.py:48] [502200] global_step=502200, grad_norm=3.7592074871063232, loss=1.8830833435058594
I0305 07:21:44.486872 139758026090240 logging_writer.py:48] [502300] global_step=502300, grad_norm=2.813591241836548, loss=1.0218521356582642
I0305 07:22:29.539111 139758009304832 logging_writer.py:48] [502400] global_step=502400, grad_norm=2.9492504596710205, loss=1.0421497821807861
I0305 07:23:06.177156 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:23:17.192793 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:23:45.390805 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:23:47.035666 139953291118400 submission_runner.py:411] Time since start: 242867.21s, 	Step: 502483, 	{'train/accuracy': 0.8876757621765137, 'train/loss': 0.41353800892829895, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 223534.12419629097, 'total_duration': 242867.21188783646, 'accumulated_submission_time': 223534.12419629097, 'accumulated_eval_time': 19265.472824811935, 'accumulated_logging_time': 42.08222556114197}
I0305 07:23:47.149316 139758026090240 logging_writer.py:48] [502483] accumulated_eval_time=19265.472825, accumulated_logging_time=42.082226, accumulated_submission_time=223534.124196, global_step=502483, preemption_count=0, score=223534.124196, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=242867.211888, train/accuracy=0.887676, train/loss=0.413538, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:23:54.259341 139758009304832 logging_writer.py:48] [502500] global_step=502500, grad_norm=3.1523895263671875, loss=1.0387578010559082
I0305 07:24:35.418547 139758026090240 logging_writer.py:48] [502600] global_step=502600, grad_norm=3.2220258712768555, loss=1.2546195983886719
I0305 07:25:20.294305 139758009304832 logging_writer.py:48] [502700] global_step=502700, grad_norm=3.0694329738616943, loss=1.6958283185958862
I0305 07:26:05.215806 139758026090240 logging_writer.py:48] [502800] global_step=502800, grad_norm=2.9850239753723145, loss=1.6588290929794312
I0305 07:26:50.552089 139758009304832 logging_writer.py:48] [502900] global_step=502900, grad_norm=3.1801419258117676, loss=1.1293063163757324
I0305 07:27:51.394797 139758026090240 logging_writer.py:48] [503000] global_step=503000, grad_norm=2.7663538455963135, loss=1.9752154350280762
I0305 07:28:41.905024 139758009304832 logging_writer.py:48] [503100] global_step=503100, grad_norm=2.8687195777893066, loss=1.9234613180160522
I0305 07:29:26.811895 139758026090240 logging_writer.py:48] [503200] global_step=503200, grad_norm=3.6888082027435303, loss=3.2726614475250244
I0305 07:30:11.781789 139758009304832 logging_writer.py:48] [503300] global_step=503300, grad_norm=3.380542039871216, loss=1.2006734609603882
I0305 07:30:47.401300 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:30:58.755931 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:31:31.279763 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:31:32.898411 139953291118400 submission_runner.py:411] Time since start: 243333.07s, 	Step: 503381, 	{'train/accuracy': 0.8858984112739563, 'train/loss': 0.4253036081790924, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 223954.3198173046, 'total_duration': 243333.07464551926, 'accumulated_submission_time': 223954.3198173046, 'accumulated_eval_time': 19310.969926834106, 'accumulated_logging_time': 42.20741128921509}
I0305 07:31:32.988878 139758026090240 logging_writer.py:48] [503381] accumulated_eval_time=19310.969927, accumulated_logging_time=42.207411, accumulated_submission_time=223954.319817, global_step=503381, preemption_count=0, score=223954.319817, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=243333.074646, train/accuracy=0.885898, train/loss=0.425304, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:31:40.872270 139758009304832 logging_writer.py:48] [503400] global_step=503400, grad_norm=2.9556102752685547, loss=1.1178615093231201
I0305 07:32:22.067615 139758026090240 logging_writer.py:48] [503500] global_step=503500, grad_norm=3.8957979679107666, loss=3.248368501663208
I0305 07:33:07.008559 139758009304832 logging_writer.py:48] [503600] global_step=503600, grad_norm=3.5214223861694336, loss=1.1892489194869995
I0305 07:33:52.210353 139758026090240 logging_writer.py:48] [503700] global_step=503700, grad_norm=3.302276372909546, loss=2.5395376682281494
I0305 07:34:37.484304 139758009304832 logging_writer.py:48] [503800] global_step=503800, grad_norm=3.099510431289673, loss=1.632981777191162
I0305 07:35:22.473255 139758026090240 logging_writer.py:48] [503900] global_step=503900, grad_norm=3.4814929962158203, loss=1.1174570322036743
I0305 07:36:07.919176 139758009304832 logging_writer.py:48] [504000] global_step=504000, grad_norm=3.1382808685302734, loss=1.3042819499969482
I0305 07:36:52.996374 139758026090240 logging_writer.py:48] [504100] global_step=504100, grad_norm=3.303581476211548, loss=2.8354673385620117
I0305 07:37:37.914003 139758009304832 logging_writer.py:48] [504200] global_step=504200, grad_norm=3.465791702270508, loss=1.230363130569458
I0305 07:38:22.995108 139758026090240 logging_writer.py:48] [504300] global_step=504300, grad_norm=3.037951946258545, loss=1.4476985931396484
I0305 07:38:33.313171 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:38:44.534183 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:39:16.877387 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:39:18.519323 139953291118400 submission_runner.py:411] Time since start: 243798.70s, 	Step: 504325, 	{'train/accuracy': 0.8860546946525574, 'train/loss': 0.4211524724960327, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 224374.5869781971, 'total_duration': 243798.6955487728, 'accumulated_submission_time': 224374.5869781971, 'accumulated_eval_time': 19356.176063776016, 'accumulated_logging_time': 42.30738377571106}
I0305 07:39:18.632346 139758009304832 logging_writer.py:48] [504325] accumulated_eval_time=19356.176064, accumulated_logging_time=42.307384, accumulated_submission_time=224374.586978, global_step=504325, preemption_count=0, score=224374.586978, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=243798.695549, train/accuracy=0.886055, train/loss=0.421152, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:39:48.643748 139758026090240 logging_writer.py:48] [504400] global_step=504400, grad_norm=2.8471341133117676, loss=1.9289042949676514
I0305 07:40:33.161414 139758009304832 logging_writer.py:48] [504500] global_step=504500, grad_norm=3.942464590072632, loss=3.2924118041992188
I0305 07:41:18.415148 139758026090240 logging_writer.py:48] [504600] global_step=504600, grad_norm=3.2953896522521973, loss=1.08529531955719
I0305 07:42:03.947080 139758009304832 logging_writer.py:48] [504700] global_step=504700, grad_norm=3.175391435623169, loss=1.1483571529388428
I0305 07:42:48.947756 139758026090240 logging_writer.py:48] [504800] global_step=504800, grad_norm=3.0551226139068604, loss=1.0348235368728638
I0305 07:43:34.048160 139758009304832 logging_writer.py:48] [504900] global_step=504900, grad_norm=3.3628931045532227, loss=1.1680147647857666
I0305 07:44:19.396689 139758026090240 logging_writer.py:48] [505000] global_step=505000, grad_norm=3.137094736099243, loss=1.2362940311431885
I0305 07:45:04.409840 139758009304832 logging_writer.py:48] [505100] global_step=505100, grad_norm=3.4870052337646484, loss=3.1301491260528564
I0305 07:45:50.361566 139758026090240 logging_writer.py:48] [505200] global_step=505200, grad_norm=2.9753055572509766, loss=1.1143786907196045
I0305 07:46:18.586893 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:46:29.931161 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:46:55.577739 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:46:57.213153 139953291118400 submission_runner.py:411] Time since start: 244257.39s, 	Step: 505264, 	{'train/accuracy': 0.8863866925239563, 'train/loss': 0.42183637619018555, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 224794.48518443108, 'total_duration': 244257.38936328888, 'accumulated_submission_time': 224794.48518443108, 'accumulated_eval_time': 19394.80228829384, 'accumulated_logging_time': 42.43042516708374}
I0305 07:46:57.328962 139758009304832 logging_writer.py:48] [505264] accumulated_eval_time=19394.802288, accumulated_logging_time=42.430425, accumulated_submission_time=224794.485184, global_step=505264, preemption_count=0, score=224794.485184, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=244257.389363, train/accuracy=0.886387, train/loss=0.421836, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:47:11.934037 139758026090240 logging_writer.py:48] [505300] global_step=505300, grad_norm=2.90224027633667, loss=1.6070955991744995
I0305 07:47:55.685140 139758009304832 logging_writer.py:48] [505400] global_step=505400, grad_norm=3.1932389736175537, loss=1.1400705575942993
I0305 07:48:41.276834 139758026090240 logging_writer.py:48] [505500] global_step=505500, grad_norm=4.505362510681152, loss=2.8636486530303955
I0305 07:49:26.648950 139758009304832 logging_writer.py:48] [505600] global_step=505600, grad_norm=3.157750129699707, loss=1.1170564889907837
I0305 07:50:12.055282 139758026090240 logging_writer.py:48] [505700] global_step=505700, grad_norm=4.183270454406738, loss=3.277280569076538
I0305 07:50:57.431238 139758009304832 logging_writer.py:48] [505800] global_step=505800, grad_norm=3.102139711380005, loss=1.1554067134857178
I0305 07:51:42.654878 139758026090240 logging_writer.py:48] [505900] global_step=505900, grad_norm=3.512511730194092, loss=1.9122812747955322
I0305 07:52:28.148960 139758009304832 logging_writer.py:48] [506000] global_step=506000, grad_norm=3.144810914993286, loss=1.2645103931427002
I0305 07:53:13.504823 139758026090240 logging_writer.py:48] [506100] global_step=506100, grad_norm=3.1064612865448, loss=1.3566383123397827
I0305 07:53:57.584865 139953291118400 spec.py:321] Evaluating on the training split.
I0305 07:54:09.070958 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 07:54:36.079043 139953291118400 spec.py:349] Evaluating on the test split.
I0305 07:54:37.721208 139953291118400 submission_runner.py:411] Time since start: 244717.90s, 	Step: 506199, 	{'train/accuracy': 0.8872656226158142, 'train/loss': 0.4188918173313141, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 225214.68184113503, 'total_duration': 244717.8974416256, 'accumulated_submission_time': 225214.68184113503, 'accumulated_eval_time': 19434.938640117645, 'accumulated_logging_time': 42.55869674682617}
I0305 07:54:37.813192 139758009304832 logging_writer.py:48] [506199] accumulated_eval_time=19434.938640, accumulated_logging_time=42.558697, accumulated_submission_time=225214.681841, global_step=506199, preemption_count=0, score=225214.681841, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=244717.897442, train/accuracy=0.887266, train/loss=0.418892, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 07:54:38.607404 139758026090240 logging_writer.py:48] [506200] global_step=506200, grad_norm=3.4780235290527344, loss=3.092325448989868
I0305 07:55:19.342106 139758009304832 logging_writer.py:48] [506300] global_step=506300, grad_norm=3.968378782272339, loss=3.2878329753875732
I0305 07:56:04.041922 139758026090240 logging_writer.py:48] [506400] global_step=506400, grad_norm=3.18957257270813, loss=1.0409642457962036
I0305 07:56:49.590758 139758009304832 logging_writer.py:48] [506500] global_step=506500, grad_norm=3.3259963989257812, loss=2.7725095748901367
I0305 07:57:35.281456 139758026090240 logging_writer.py:48] [506600] global_step=506600, grad_norm=3.2430777549743652, loss=1.2162976264953613
I0305 07:58:20.604804 139758009304832 logging_writer.py:48] [506700] global_step=506700, grad_norm=2.7879765033721924, loss=1.5150625705718994
I0305 07:59:05.792420 139758026090240 logging_writer.py:48] [506800] global_step=506800, grad_norm=3.1798229217529297, loss=1.1784977912902832
I0305 07:59:51.096962 139758009304832 logging_writer.py:48] [506900] global_step=506900, grad_norm=3.1790130138397217, loss=1.733306646347046
I0305 08:00:36.416892 139758026090240 logging_writer.py:48] [507000] global_step=507000, grad_norm=3.373775005340576, loss=3.0326919555664062
I0305 08:01:21.536085 139758009304832 logging_writer.py:48] [507100] global_step=507100, grad_norm=3.3439276218414307, loss=3.00423526763916
I0305 08:01:37.920878 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:01:49.148735 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:02:12.834425 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:02:14.467859 139953291118400 submission_runner.py:411] Time since start: 245174.64s, 	Step: 507138, 	{'train/accuracy': 0.8887499570846558, 'train/loss': 0.4152712821960449, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 225634.73275995255, 'total_duration': 245174.64408445358, 'accumulated_submission_time': 225634.73275995255, 'accumulated_eval_time': 19471.485607862473, 'accumulated_logging_time': 42.659632205963135}
I0305 08:02:14.579784 139758026090240 logging_writer.py:48] [507138] accumulated_eval_time=19471.485608, accumulated_logging_time=42.659632, accumulated_submission_time=225634.732760, global_step=507138, preemption_count=0, score=225634.732760, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=245174.644084, train/accuracy=0.888750, train/loss=0.415271, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:02:39.469388 139758009304832 logging_writer.py:48] [507200] global_step=507200, grad_norm=2.9845547676086426, loss=1.0356143712997437
I0305 08:03:23.977259 139758026090240 logging_writer.py:48] [507300] global_step=507300, grad_norm=3.0897607803344727, loss=1.2095119953155518
I0305 08:04:09.199577 139758009304832 logging_writer.py:48] [507400] global_step=507400, grad_norm=3.256302833557129, loss=1.1673351526260376
I0305 08:04:54.425272 139758026090240 logging_writer.py:48] [507500] global_step=507500, grad_norm=3.3416130542755127, loss=1.6138564348220825
I0305 08:05:39.515161 139758009304832 logging_writer.py:48] [507600] global_step=507600, grad_norm=3.6292760372161865, loss=2.971468925476074
I0305 08:06:24.567830 139758026090240 logging_writer.py:48] [507700] global_step=507700, grad_norm=3.2204179763793945, loss=1.2663871049880981
I0305 08:07:09.879958 139758009304832 logging_writer.py:48] [507800] global_step=507800, grad_norm=2.991225242614746, loss=1.8173977136611938
I0305 08:07:54.589128 139758026090240 logging_writer.py:48] [507900] global_step=507900, grad_norm=3.8860971927642822, loss=3.1767542362213135
I0305 08:08:39.708996 139758009304832 logging_writer.py:48] [508000] global_step=508000, grad_norm=3.790435314178467, loss=1.2686208486557007
I0305 08:09:14.667207 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:09:26.107240 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:09:51.326040 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:09:52.954060 139953291118400 submission_runner.py:411] Time since start: 245633.13s, 	Step: 508079, 	{'train/accuracy': 0.8889843821525574, 'train/loss': 0.41836822032928467, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 226054.76191449165, 'total_duration': 245633.13028097153, 'accumulated_submission_time': 226054.76191449165, 'accumulated_eval_time': 19509.77243232727, 'accumulated_logging_time': 42.783602476119995}
I0305 08:09:53.071164 139758026090240 logging_writer.py:48] [508079] accumulated_eval_time=19509.772432, accumulated_logging_time=42.783602, accumulated_submission_time=226054.761914, global_step=508079, preemption_count=0, score=226054.761914, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=245633.130281, train/accuracy=0.888984, train/loss=0.418368, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:10:01.757098 139758009304832 logging_writer.py:48] [508100] global_step=508100, grad_norm=2.9760446548461914, loss=1.3259986639022827
I0305 08:10:43.664750 139758026090240 logging_writer.py:48] [508200] global_step=508200, grad_norm=3.082679271697998, loss=1.5478590726852417
I0305 08:11:28.531561 139758009304832 logging_writer.py:48] [508300] global_step=508300, grad_norm=3.408294200897217, loss=2.7988805770874023
I0305 08:12:13.546371 139758026090240 logging_writer.py:48] [508400] global_step=508400, grad_norm=3.8107848167419434, loss=3.1135597229003906
I0305 08:12:58.651636 139758009304832 logging_writer.py:48] [508500] global_step=508500, grad_norm=3.9972877502441406, loss=3.3219213485717773
I0305 08:13:43.613656 139758026090240 logging_writer.py:48] [508600] global_step=508600, grad_norm=3.6382951736450195, loss=3.1307990550994873
I0305 08:14:28.531437 139758009304832 logging_writer.py:48] [508700] global_step=508700, grad_norm=3.096444845199585, loss=1.1496678590774536
I0305 08:15:13.507167 139758026090240 logging_writer.py:48] [508800] global_step=508800, grad_norm=2.966010570526123, loss=1.5692813396453857
I0305 08:15:58.464066 139758009304832 logging_writer.py:48] [508900] global_step=508900, grad_norm=3.714627981185913, loss=3.2212164402008057
I0305 08:16:43.674957 139758026090240 logging_writer.py:48] [509000] global_step=509000, grad_norm=2.8948733806610107, loss=1.6284089088439941
I0305 08:16:53.567838 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:17:04.872243 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:17:40.509657 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:17:42.133275 139953291118400 submission_runner.py:411] Time since start: 246102.31s, 	Step: 509023, 	{'train/accuracy': 0.88525390625, 'train/loss': 0.4223649799823761, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 226475.2010500431, 'total_duration': 246102.30951094627, 'accumulated_submission_time': 226475.2010500431, 'accumulated_eval_time': 19558.337856054306, 'accumulated_logging_time': 42.91069960594177}
I0305 08:17:42.223999 139758009304832 logging_writer.py:48] [509023] accumulated_eval_time=19558.337856, accumulated_logging_time=42.910700, accumulated_submission_time=226475.201050, global_step=509023, preemption_count=0, score=226475.201050, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=246102.309511, train/accuracy=0.885254, train/loss=0.422365, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:18:12.970389 139758026090240 logging_writer.py:48] [509100] global_step=509100, grad_norm=3.0663585662841797, loss=1.109370470046997
I0305 08:18:57.061680 139758009304832 logging_writer.py:48] [509200] global_step=509200, grad_norm=3.4406960010528564, loss=2.8670947551727295
I0305 08:19:42.576591 139758026090240 logging_writer.py:48] [509300] global_step=509300, grad_norm=2.9070799350738525, loss=1.0949867963790894
I0305 08:20:28.352728 139758009304832 logging_writer.py:48] [509400] global_step=509400, grad_norm=3.330787181854248, loss=1.3277586698532104
I0305 08:21:13.421711 139758026090240 logging_writer.py:48] [509500] global_step=509500, grad_norm=3.1489222049713135, loss=1.0560835599899292
I0305 08:21:58.346305 139758009304832 logging_writer.py:48] [509600] global_step=509600, grad_norm=3.3413143157958984, loss=1.3163584470748901
I0305 08:22:43.301333 139758026090240 logging_writer.py:48] [509700] global_step=509700, grad_norm=3.410224676132202, loss=2.77082896232605
I0305 08:23:28.052644 139758009304832 logging_writer.py:48] [509800] global_step=509800, grad_norm=3.8580892086029053, loss=3.224022388458252
I0305 08:24:13.294315 139758026090240 logging_writer.py:48] [509900] global_step=509900, grad_norm=3.4262802600860596, loss=1.164825677871704
I0305 08:24:42.196738 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:24:53.667920 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:25:15.687468 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:25:17.320618 139953291118400 submission_runner.py:411] Time since start: 246557.50s, 	Step: 509966, 	{'train/accuracy': 0.8899023532867432, 'train/loss': 0.4177020490169525, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 226895.11728739738, 'total_duration': 246557.4968225956, 'accumulated_submission_time': 226895.11728739738, 'accumulated_eval_time': 19593.461698532104, 'accumulated_logging_time': 43.01064705848694}
I0305 08:25:17.433835 139758009304832 logging_writer.py:48] [509966] accumulated_eval_time=19593.461699, accumulated_logging_time=43.010647, accumulated_submission_time=226895.117287, global_step=509966, preemption_count=0, score=226895.117287, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=246557.496823, train/accuracy=0.889902, train/loss=0.417702, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:25:31.273323 139758026090240 logging_writer.py:48] [510000] global_step=510000, grad_norm=3.308356285095215, loss=2.800893783569336
I0305 08:26:13.751938 139758009304832 logging_writer.py:48] [510100] global_step=510100, grad_norm=3.0753347873687744, loss=1.167414665222168
I0305 08:26:58.594123 139758026090240 logging_writer.py:48] [510200] global_step=510200, grad_norm=3.7345049381256104, loss=2.7730205059051514
I0305 08:27:43.795232 139758009304832 logging_writer.py:48] [510300] global_step=510300, grad_norm=3.143146514892578, loss=1.0488451719284058
I0305 08:28:29.119930 139758026090240 logging_writer.py:48] [510400] global_step=510400, grad_norm=3.297694683074951, loss=1.2221510410308838
I0305 08:29:14.281922 139758009304832 logging_writer.py:48] [510500] global_step=510500, grad_norm=2.922208786010742, loss=1.7669140100479126
I0305 08:29:59.279726 139758026090240 logging_writer.py:48] [510600] global_step=510600, grad_norm=3.497941732406616, loss=1.1159720420837402
I0305 08:30:44.765809 139758009304832 logging_writer.py:48] [510700] global_step=510700, grad_norm=3.196259021759033, loss=2.56024169921875
I0305 08:31:29.791617 139758026090240 logging_writer.py:48] [510800] global_step=510800, grad_norm=3.5725367069244385, loss=2.8872413635253906
I0305 08:32:14.919546 139758009304832 logging_writer.py:48] [510900] global_step=510900, grad_norm=3.047912120819092, loss=1.6788952350616455
I0305 08:32:17.732782 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:32:29.316398 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:32:52.940985 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:32:54.574448 139953291118400 submission_runner.py:411] Time since start: 247014.75s, 	Step: 510908, 	{'train/accuracy': 0.8851757645606995, 'train/loss': 0.42348289489746094, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 227315.35199666023, 'total_duration': 247014.7506687641, 'accumulated_submission_time': 227315.35199666023, 'accumulated_eval_time': 19630.303337335587, 'accumulated_logging_time': 43.14096117019653}
I0305 08:32:54.688701 139758026090240 logging_writer.py:48] [510908] accumulated_eval_time=19630.303337, accumulated_logging_time=43.140961, accumulated_submission_time=227315.351997, global_step=510908, preemption_count=0, score=227315.351997, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=247014.750669, train/accuracy=0.885176, train/loss=0.423483, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:33:32.159275 139758009304832 logging_writer.py:48] [511000] global_step=511000, grad_norm=3.449660062789917, loss=3.066739559173584
I0305 08:34:17.178524 139758026090240 logging_writer.py:48] [511100] global_step=511100, grad_norm=2.840393304824829, loss=1.9433610439300537
I0305 08:35:02.336638 139758009304832 logging_writer.py:48] [511200] global_step=511200, grad_norm=3.3160057067871094, loss=1.1812536716461182
I0305 08:35:47.511318 139758026090240 logging_writer.py:48] [511300] global_step=511300, grad_norm=2.8931937217712402, loss=2.1072299480438232
I0305 08:36:32.647973 139758009304832 logging_writer.py:48] [511400] global_step=511400, grad_norm=3.4410853385925293, loss=3.0523033142089844
I0305 08:37:18.173810 139758026090240 logging_writer.py:48] [511500] global_step=511500, grad_norm=3.238497257232666, loss=1.0662518739700317
I0305 08:38:03.032598 139758009304832 logging_writer.py:48] [511600] global_step=511600, grad_norm=3.1659388542175293, loss=1.116228461265564
I0305 08:38:48.344166 139758026090240 logging_writer.py:48] [511700] global_step=511700, grad_norm=3.455988645553589, loss=2.788221597671509
I0305 08:39:33.216979 139758009304832 logging_writer.py:48] [511800] global_step=511800, grad_norm=2.776658058166504, loss=1.7141426801681519
I0305 08:39:54.872148 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:40:06.092584 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:40:37.840647 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:40:39.464335 139953291118400 submission_runner.py:411] Time since start: 247479.64s, 	Step: 511850, 	{'train/accuracy': 0.8869335651397705, 'train/loss': 0.4181903004646301, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 227735.47498559952, 'total_duration': 247479.6405696869, 'accumulated_submission_time': 227735.47498559952, 'accumulated_eval_time': 19674.895520925522, 'accumulated_logging_time': 43.26824116706848}
I0305 08:40:39.559028 139758026090240 logging_writer.py:48] [511850] accumulated_eval_time=19674.895521, accumulated_logging_time=43.268241, accumulated_submission_time=227735.474986, global_step=511850, preemption_count=0, score=227735.474986, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=247479.640570, train/accuracy=0.886934, train/loss=0.418190, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:40:59.665186 139758009304832 logging_writer.py:48] [511900] global_step=511900, grad_norm=3.415302038192749, loss=1.133091688156128
I0305 08:41:41.884755 139758026090240 logging_writer.py:48] [512000] global_step=512000, grad_norm=3.136265516281128, loss=2.765221357345581
I0305 08:42:26.619077 139758009304832 logging_writer.py:48] [512100] global_step=512100, grad_norm=3.1591482162475586, loss=1.2373993396759033
I0305 08:43:11.663315 139758026090240 logging_writer.py:48] [512200] global_step=512200, grad_norm=3.003401041030884, loss=2.346759080886841
I0305 08:43:56.447725 139758009304832 logging_writer.py:48] [512300] global_step=512300, grad_norm=3.024862766265869, loss=1.3902157545089722
I0305 08:44:41.461781 139758026090240 logging_writer.py:48] [512400] global_step=512400, grad_norm=3.6602699756622314, loss=2.9285290241241455
I0305 08:45:26.072294 139758009304832 logging_writer.py:48] [512500] global_step=512500, grad_norm=3.4322586059570312, loss=3.0255918502807617
I0305 08:46:11.090955 139758026090240 logging_writer.py:48] [512600] global_step=512600, grad_norm=3.11596417427063, loss=1.134292483329773
I0305 08:46:55.870997 139758009304832 logging_writer.py:48] [512700] global_step=512700, grad_norm=3.0764148235321045, loss=1.0753412246704102
I0305 08:47:39.658444 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:47:50.783086 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:48:20.610034 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:48:22.236729 139953291118400 submission_runner.py:411] Time since start: 247942.41s, 	Step: 512799, 	{'train/accuracy': 0.8880273103713989, 'train/loss': 0.4198199510574341, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 228155.5176768303, 'total_duration': 247942.41296219826, 'accumulated_submission_time': 228155.5176768303, 'accumulated_eval_time': 19717.473808526993, 'accumulated_logging_time': 43.37141489982605}
I0305 08:48:22.329572 139758026090240 logging_writer.py:48] [512799] accumulated_eval_time=19717.473809, accumulated_logging_time=43.371415, accumulated_submission_time=228155.517677, global_step=512799, preemption_count=0, score=228155.517677, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=247942.412962, train/accuracy=0.888027, train/loss=0.419820, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:48:23.125090 139758009304832 logging_writer.py:48] [512800] global_step=512800, grad_norm=3.102396011352539, loss=1.200545072555542
I0305 08:49:03.570885 139758026090240 logging_writer.py:48] [512900] global_step=512900, grad_norm=3.370893716812134, loss=1.1299583911895752
I0305 08:49:48.606035 139758009304832 logging_writer.py:48] [513000] global_step=513000, grad_norm=3.7285923957824707, loss=3.1273887157440186
I0305 08:50:33.667115 139758026090240 logging_writer.py:48] [513100] global_step=513100, grad_norm=2.9497387409210205, loss=1.1034915447235107
I0305 08:51:18.804861 139758009304832 logging_writer.py:48] [513200] global_step=513200, grad_norm=2.9952263832092285, loss=1.6786041259765625
I0305 08:52:03.494296 139758026090240 logging_writer.py:48] [513300] global_step=513300, grad_norm=2.878136157989502, loss=1.3766247034072876
I0305 08:52:48.102809 139758009304832 logging_writer.py:48] [513400] global_step=513400, grad_norm=3.069244623184204, loss=1.5757989883422852
I0305 08:53:33.267497 139758026090240 logging_writer.py:48] [513500] global_step=513500, grad_norm=2.888282537460327, loss=1.048636555671692
I0305 08:54:18.225184 139758009304832 logging_writer.py:48] [513600] global_step=513600, grad_norm=3.1391758918762207, loss=1.1939952373504639
I0305 08:55:03.333197 139758026090240 logging_writer.py:48] [513700] global_step=513700, grad_norm=3.32511043548584, loss=2.890359878540039
I0305 08:55:22.285094 139953291118400 spec.py:321] Evaluating on the training split.
I0305 08:55:33.769376 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 08:55:59.663480 139953291118400 spec.py:349] Evaluating on the test split.
I0305 08:56:01.303730 139953291118400 submission_runner.py:411] Time since start: 248401.48s, 	Step: 513744, 	{'train/accuracy': 0.8875195384025574, 'train/loss': 0.4158684015274048, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 228575.4135878086, 'total_duration': 248401.4799234867, 'accumulated_submission_time': 228575.4135878086, 'accumulated_eval_time': 19756.49240231514, 'accumulated_logging_time': 43.47539925575256}
I0305 08:56:01.444833 139758009304832 logging_writer.py:48] [513744] accumulated_eval_time=19756.492402, accumulated_logging_time=43.475399, accumulated_submission_time=228575.413588, global_step=513744, preemption_count=0, score=228575.413588, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=248401.479923, train/accuracy=0.887520, train/loss=0.415868, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 08:56:23.947776 139758026090240 logging_writer.py:48] [513800] global_step=513800, grad_norm=3.1953999996185303, loss=1.0388038158416748
I0305 08:57:08.152418 139758009304832 logging_writer.py:48] [513900] global_step=513900, grad_norm=3.2129764556884766, loss=1.3867629766464233
I0305 08:57:53.058489 139758026090240 logging_writer.py:48] [514000] global_step=514000, grad_norm=3.068652629852295, loss=1.0415289402008057
I0305 08:58:38.323592 139758009304832 logging_writer.py:48] [514100] global_step=514100, grad_norm=3.0131592750549316, loss=1.8909335136413574
I0305 08:59:23.412054 139758026090240 logging_writer.py:48] [514200] global_step=514200, grad_norm=3.7978897094726562, loss=3.0656776428222656
I0305 09:00:08.817369 139758009304832 logging_writer.py:48] [514300] global_step=514300, grad_norm=2.800412178039551, loss=1.6579222679138184
I0305 09:00:53.661993 139758026090240 logging_writer.py:48] [514400] global_step=514400, grad_norm=2.819504737854004, loss=1.0888521671295166
I0305 09:01:38.777345 139758009304832 logging_writer.py:48] [514500] global_step=514500, grad_norm=3.1312479972839355, loss=1.2487679719924927
I0305 09:02:23.860944 139758026090240 logging_writer.py:48] [514600] global_step=514600, grad_norm=3.058546543121338, loss=1.1916738748550415
I0305 09:03:01.741362 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:03:13.161801 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:03:44.095569 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:03:45.723678 139953291118400 submission_runner.py:411] Time since start: 248865.90s, 	Step: 514686, 	{'train/accuracy': 0.8874218463897705, 'train/loss': 0.4217660427093506, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 228995.65171909332, 'total_duration': 248865.89991259575, 'accumulated_submission_time': 228995.65171909332, 'accumulated_eval_time': 19800.474741220474, 'accumulated_logging_time': 43.627443075180054}
I0305 09:03:45.815855 139758009304832 logging_writer.py:48] [514686] accumulated_eval_time=19800.474741, accumulated_logging_time=43.627443, accumulated_submission_time=228995.651719, global_step=514686, preemption_count=0, score=228995.651719, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=248865.899913, train/accuracy=0.887422, train/loss=0.421766, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:03:51.734053 139758026090240 logging_writer.py:48] [514700] global_step=514700, grad_norm=3.0281589031219482, loss=1.728295922279358
I0305 09:04:32.708051 139758009304832 logging_writer.py:48] [514800] global_step=514800, grad_norm=3.5656630992889404, loss=2.306501865386963
I0305 09:05:17.664313 139758026090240 logging_writer.py:48] [514900] global_step=514900, grad_norm=3.40561842918396, loss=1.1991798877716064
I0305 09:06:03.408383 139758009304832 logging_writer.py:48] [515000] global_step=515000, grad_norm=2.9727561473846436, loss=1.7735369205474854
I0305 09:06:49.016038 139758026090240 logging_writer.py:48] [515100] global_step=515100, grad_norm=2.9268317222595215, loss=1.0461698770523071
I0305 09:07:34.118674 139758009304832 logging_writer.py:48] [515200] global_step=515200, grad_norm=3.783665418624878, loss=3.229628562927246
I0305 09:08:19.622831 139758026090240 logging_writer.py:48] [515300] global_step=515300, grad_norm=3.003330945968628, loss=1.0304473638534546
I0305 09:09:04.974640 139758009304832 logging_writer.py:48] [515400] global_step=515400, grad_norm=2.9758903980255127, loss=1.2063966989517212
I0305 09:09:50.116677 139758026090240 logging_writer.py:48] [515500] global_step=515500, grad_norm=3.6275699138641357, loss=3.018056869506836
I0305 09:10:35.285647 139758009304832 logging_writer.py:48] [515600] global_step=515600, grad_norm=3.237955093383789, loss=1.133279800415039
I0305 09:10:45.727863 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:10:57.025664 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:11:18.097400 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:11:19.728890 139953291118400 submission_runner.py:411] Time since start: 249319.91s, 	Step: 515625, 	{'train/accuracy': 0.8893554210662842, 'train/loss': 0.4156787693500519, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 229415.50728487968, 'total_duration': 249319.9051039219, 'accumulated_submission_time': 229415.50728487968, 'accumulated_eval_time': 19834.475734710693, 'accumulated_logging_time': 43.72905158996582}
I0305 09:11:19.845741 139758026090240 logging_writer.py:48] [515625] accumulated_eval_time=19834.475735, accumulated_logging_time=43.729052, accumulated_submission_time=229415.507285, global_step=515625, preemption_count=0, score=229415.507285, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=249319.905104, train/accuracy=0.889355, train/loss=0.415679, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:11:50.187160 139758009304832 logging_writer.py:48] [515700] global_step=515700, grad_norm=3.045614719390869, loss=1.1376302242279053
I0305 09:12:35.142878 139758026090240 logging_writer.py:48] [515800] global_step=515800, grad_norm=3.6440274715423584, loss=2.9965810775756836
I0305 09:13:20.158900 139758009304832 logging_writer.py:48] [515900] global_step=515900, grad_norm=2.8766512870788574, loss=1.1682872772216797
I0305 09:14:05.289413 139758026090240 logging_writer.py:48] [516000] global_step=516000, grad_norm=3.2348763942718506, loss=1.346980333328247
I0305 09:14:50.351295 139758009304832 logging_writer.py:48] [516100] global_step=516100, grad_norm=3.125967502593994, loss=1.141796588897705
I0305 09:15:35.266963 139758026090240 logging_writer.py:48] [516200] global_step=516200, grad_norm=2.886634588241577, loss=1.1771386861801147
I0305 09:16:20.562088 139758009304832 logging_writer.py:48] [516300] global_step=516300, grad_norm=3.1142523288726807, loss=1.034004807472229
I0305 09:17:05.568149 139758026090240 logging_writer.py:48] [516400] global_step=516400, grad_norm=2.875800132751465, loss=1.7385754585266113
I0305 09:17:50.496300 139758009304832 logging_writer.py:48] [516500] global_step=516500, grad_norm=3.387364149093628, loss=1.3395906686782837
I0305 09:18:19.986433 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:18:31.494091 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:18:56.855022 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:18:58.484764 139953291118400 submission_runner.py:411] Time since start: 249778.66s, 	Step: 516567, 	{'train/accuracy': 0.8910155892372131, 'train/loss': 0.40818679332733154, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 229835.58886671066, 'total_duration': 249778.6609852314, 'accumulated_submission_time': 229835.58886671066, 'accumulated_eval_time': 19872.974060058594, 'accumulated_logging_time': 43.85731816291809}
I0305 09:18:58.600705 139758026090240 logging_writer.py:48] [516567] accumulated_eval_time=19872.974060, accumulated_logging_time=43.857318, accumulated_submission_time=229835.588867, global_step=516567, preemption_count=0, score=229835.588867, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=249778.660985, train/accuracy=0.891016, train/loss=0.408187, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:19:12.032959 139758009304832 logging_writer.py:48] [516600] global_step=516600, grad_norm=3.1150407791137695, loss=1.1617814302444458
I0305 09:19:54.585900 139758026090240 logging_writer.py:48] [516700] global_step=516700, grad_norm=3.2480783462524414, loss=1.0685808658599854
I0305 09:20:39.886031 139758009304832 logging_writer.py:48] [516800] global_step=516800, grad_norm=3.1880340576171875, loss=1.2060078382492065
I0305 09:21:24.938775 139758026090240 logging_writer.py:48] [516900] global_step=516900, grad_norm=3.266432046890259, loss=2.314612865447998
I0305 09:22:10.368821 139758009304832 logging_writer.py:48] [517000] global_step=517000, grad_norm=3.410033702850342, loss=3.1401870250701904
I0305 09:22:55.494831 139758026090240 logging_writer.py:48] [517100] global_step=517100, grad_norm=3.009782075881958, loss=1.7399712800979614
I0305 09:23:40.647003 139758009304832 logging_writer.py:48] [517200] global_step=517200, grad_norm=3.1368634700775146, loss=1.1588057279586792
I0305 09:24:25.660261 139758026090240 logging_writer.py:48] [517300] global_step=517300, grad_norm=3.0698394775390625, loss=1.1173863410949707
I0305 09:25:10.539384 139758009304832 logging_writer.py:48] [517400] global_step=517400, grad_norm=4.190573692321777, loss=3.2793660163879395
I0305 09:25:55.578513 139758026090240 logging_writer.py:48] [517500] global_step=517500, grad_norm=3.117841958999634, loss=2.5309250354766846
I0305 09:25:58.830122 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:26:10.030408 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:26:40.591969 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:26:42.219756 139953291118400 submission_runner.py:411] Time since start: 250242.40s, 	Step: 517509, 	{'train/accuracy': 0.8847851157188416, 'train/loss': 0.4224032461643219, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 230255.75998997688, 'total_duration': 250242.39598941803, 'accumulated_submission_time': 230255.75998997688, 'accumulated_eval_time': 19916.36367583275, 'accumulated_logging_time': 43.98423504829407}
I0305 09:26:42.315928 139758009304832 logging_writer.py:48] [517509] accumulated_eval_time=19916.363676, accumulated_logging_time=43.984235, accumulated_submission_time=230255.759990, global_step=517509, preemption_count=0, score=230255.759990, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=250242.395989, train/accuracy=0.884785, train/loss=0.422403, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:27:18.646812 139758026090240 logging_writer.py:48] [517600] global_step=517600, grad_norm=2.8386363983154297, loss=2.0437142848968506
I0305 09:28:03.498844 139758009304832 logging_writer.py:48] [517700] global_step=517700, grad_norm=3.1850500106811523, loss=1.1005655527114868
I0305 09:28:48.551015 139758026090240 logging_writer.py:48] [517800] global_step=517800, grad_norm=3.2934491634368896, loss=1.0529751777648926
I0305 09:29:33.960634 139758009304832 logging_writer.py:48] [517900] global_step=517900, grad_norm=2.9920754432678223, loss=1.0892956256866455
I0305 09:30:19.044260 139758026090240 logging_writer.py:48] [518000] global_step=518000, grad_norm=3.217628240585327, loss=1.0863685607910156
I0305 09:31:04.069066 139758009304832 logging_writer.py:48] [518100] global_step=518100, grad_norm=3.9268219470977783, loss=3.1664137840270996
I0305 09:31:49.149078 139758026090240 logging_writer.py:48] [518200] global_step=518200, grad_norm=3.0883560180664062, loss=1.082846999168396
I0305 09:32:34.082367 139758009304832 logging_writer.py:48] [518300] global_step=518300, grad_norm=3.5729761123657227, loss=3.1258859634399414
I0305 09:33:19.072017 139758026090240 logging_writer.py:48] [518400] global_step=518400, grad_norm=3.0510716438293457, loss=1.18003511428833
I0305 09:33:42.658019 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:33:54.843132 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:34:16.633836 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:34:18.275098 139953291118400 submission_runner.py:411] Time since start: 250698.45s, 	Step: 518454, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.41247648000717163, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 230676.0453734398, 'total_duration': 250698.45132374763, 'accumulated_submission_time': 230676.0453734398, 'accumulated_eval_time': 19951.98074555397, 'accumulated_logging_time': 44.089574098587036}
I0305 09:34:18.392324 139758009304832 logging_writer.py:48] [518454] accumulated_eval_time=19951.980746, accumulated_logging_time=44.089574, accumulated_submission_time=230676.045373, global_step=518454, preemption_count=0, score=230676.045373, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=250698.451324, train/accuracy=0.888906, train/loss=0.412476, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:34:36.944878 139758026090240 logging_writer.py:48] [518500] global_step=518500, grad_norm=3.5267868041992188, loss=3.1387906074523926
I0305 09:35:20.493398 139758009304832 logging_writer.py:48] [518600] global_step=518600, grad_norm=3.061734914779663, loss=1.179372787475586
I0305 09:36:05.322408 139758026090240 logging_writer.py:48] [518700] global_step=518700, grad_norm=3.223344087600708, loss=1.1835256814956665
I0305 09:36:50.440492 139758009304832 logging_writer.py:48] [518800] global_step=518800, grad_norm=3.03898024559021, loss=2.4534823894500732
I0305 09:37:35.656726 139758026090240 logging_writer.py:48] [518900] global_step=518900, grad_norm=2.925257921218872, loss=1.0267667770385742
I0305 09:38:20.727756 139758009304832 logging_writer.py:48] [519000] global_step=519000, grad_norm=3.6362931728363037, loss=3.0796501636505127
I0305 09:39:05.907742 139758026090240 logging_writer.py:48] [519100] global_step=519100, grad_norm=3.418342113494873, loss=2.9164531230926514
I0305 09:39:50.895985 139758009304832 logging_writer.py:48] [519200] global_step=519200, grad_norm=3.020660400390625, loss=1.0805959701538086
I0305 09:40:36.035737 139758026090240 logging_writer.py:48] [519300] global_step=519300, grad_norm=3.282893657684326, loss=1.1470366716384888
I0305 09:41:18.495619 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:41:29.882140 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:41:58.831756 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:42:00.465753 139953291118400 submission_runner.py:411] Time since start: 251160.64s, 	Step: 519396, 	{'train/accuracy': 0.8869726657867432, 'train/loss': 0.41832152009010315, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 231096.0907754898, 'total_duration': 251160.64197206497, 'accumulated_submission_time': 231096.0907754898, 'accumulated_eval_time': 19993.950864076614, 'accumulated_logging_time': 44.21716904640198}
I0305 09:42:00.581784 139758009304832 logging_writer.py:48] [519396] accumulated_eval_time=19993.950864, accumulated_logging_time=44.217169, accumulated_submission_time=231096.090775, global_step=519396, preemption_count=0, score=231096.090775, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=251160.641972, train/accuracy=0.886973, train/loss=0.418322, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:42:02.582950 139758026090240 logging_writer.py:48] [519400] global_step=519400, grad_norm=3.3460583686828613, loss=1.2231446504592896
I0305 09:42:43.246399 139758009304832 logging_writer.py:48] [519500] global_step=519500, grad_norm=3.8829433917999268, loss=3.3830394744873047
I0305 09:43:28.288730 139758026090240 logging_writer.py:48] [519600] global_step=519600, grad_norm=2.8614861965179443, loss=1.8799536228179932
I0305 09:44:13.383937 139758009304832 logging_writer.py:48] [519700] global_step=519700, grad_norm=3.998366594314575, loss=3.1317150592803955
I0305 09:44:58.818226 139758026090240 logging_writer.py:48] [519800] global_step=519800, grad_norm=3.0666701793670654, loss=1.12222158908844
I0305 09:45:43.865529 139758009304832 logging_writer.py:48] [519900] global_step=519900, grad_norm=3.2897210121154785, loss=2.8100810050964355
I0305 09:46:28.856209 139758026090240 logging_writer.py:48] [520000] global_step=520000, grad_norm=2.983517646789551, loss=1.6394859552383423
I0305 09:47:13.949826 139758009304832 logging_writer.py:48] [520100] global_step=520100, grad_norm=3.375507354736328, loss=1.5211879014968872
I0305 09:47:59.057192 139758026090240 logging_writer.py:48] [520200] global_step=520200, grad_norm=3.262983798980713, loss=1.200527310371399
I0305 09:48:44.318111 139758009304832 logging_writer.py:48] [520300] global_step=520300, grad_norm=2.9785966873168945, loss=1.8286582231521606
I0305 09:49:00.716065 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:49:12.025411 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:49:40.762175 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:49:42.392412 139953291118400 submission_runner.py:411] Time since start: 251622.57s, 	Step: 520338, 	{'train/accuracy': 0.8862890601158142, 'train/loss': 0.4208606481552124, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 231516.16703391075, 'total_duration': 251622.56864404678, 'accumulated_submission_time': 231516.16703391075, 'accumulated_eval_time': 20035.627217292786, 'accumulated_logging_time': 44.343384742736816}
I0305 09:49:42.487782 139758026090240 logging_writer.py:48] [520338] accumulated_eval_time=20035.627217, accumulated_logging_time=44.343385, accumulated_submission_time=231516.167034, global_step=520338, preemption_count=0, score=231516.167034, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=251622.568644, train/accuracy=0.886289, train/loss=0.420861, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:50:07.448231 139758009304832 logging_writer.py:48] [520400] global_step=520400, grad_norm=2.789137363433838, loss=1.553990125656128
I0305 09:50:51.050037 139758026090240 logging_writer.py:48] [520500] global_step=520500, grad_norm=4.071000576019287, loss=3.0882558822631836
I0305 09:51:36.599939 139758009304832 logging_writer.py:48] [520600] global_step=520600, grad_norm=3.024566173553467, loss=1.9133038520812988
I0305 09:52:22.432516 139758026090240 logging_writer.py:48] [520700] global_step=520700, grad_norm=4.393525123596191, loss=3.2738966941833496
I0305 09:53:07.737829 139758009304832 logging_writer.py:48] [520800] global_step=520800, grad_norm=4.22819709777832, loss=3.214383125305176
I0305 09:53:52.699286 139758026090240 logging_writer.py:48] [520900] global_step=520900, grad_norm=3.0562617778778076, loss=1.1518597602844238
I0305 09:54:38.113801 139758009304832 logging_writer.py:48] [521000] global_step=521000, grad_norm=3.1704773902893066, loss=1.1329594850540161
I0305 09:55:23.295022 139758026090240 logging_writer.py:48] [521100] global_step=521100, grad_norm=4.005761623382568, loss=3.3950164318084717
I0305 09:56:08.362713 139758009304832 logging_writer.py:48] [521200] global_step=521200, grad_norm=3.050762414932251, loss=1.6608772277832031
I0305 09:56:42.763215 139953291118400 spec.py:321] Evaluating on the training split.
I0305 09:56:54.235014 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 09:57:24.306550 139953291118400 spec.py:349] Evaluating on the test split.
I0305 09:57:25.925396 139953291118400 submission_runner.py:411] Time since start: 252086.10s, 	Step: 521278, 	{'train/accuracy': 0.8882226347923279, 'train/loss': 0.4174492061138153, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 231936.3868584633, 'total_duration': 252086.10162854195, 'accumulated_submission_time': 231936.3868584633, 'accumulated_eval_time': 20078.789390325546, 'accumulated_logging_time': 44.4472975730896}
I0305 09:57:26.018698 139758026090240 logging_writer.py:48] [521278] accumulated_eval_time=20078.789390, accumulated_logging_time=44.447298, accumulated_submission_time=231936.386858, global_step=521278, preemption_count=0, score=231936.386858, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=252086.101629, train/accuracy=0.888223, train/loss=0.417449, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 09:57:35.093375 139758009304832 logging_writer.py:48] [521300] global_step=521300, grad_norm=3.4496469497680664, loss=2.509246826171875
I0305 09:58:16.944195 139758026090240 logging_writer.py:48] [521400] global_step=521400, grad_norm=3.394526481628418, loss=2.5766305923461914
I0305 09:59:02.282160 139758009304832 logging_writer.py:48] [521500] global_step=521500, grad_norm=4.05537748336792, loss=3.068159341812134
I0305 09:59:47.660151 139758026090240 logging_writer.py:48] [521600] global_step=521600, grad_norm=3.051877975463867, loss=1.584368109703064
I0305 10:00:32.782645 139758009304832 logging_writer.py:48] [521700] global_step=521700, grad_norm=3.2931535243988037, loss=2.2023355960845947
I0305 10:01:17.715196 139758026090240 logging_writer.py:48] [521800] global_step=521800, grad_norm=3.234325408935547, loss=2.590562343597412
I0305 10:02:02.954517 139758009304832 logging_writer.py:48] [521900] global_step=521900, grad_norm=3.5730323791503906, loss=3.0594284534454346
I0305 10:02:48.436348 139758026090240 logging_writer.py:48] [522000] global_step=522000, grad_norm=3.160043954849243, loss=1.1245381832122803
I0305 10:03:33.458823 139758009304832 logging_writer.py:48] [522100] global_step=522100, grad_norm=3.11753511428833, loss=1.1695733070373535
I0305 10:04:18.388041 139758026090240 logging_writer.py:48] [522200] global_step=522200, grad_norm=2.993760585784912, loss=1.084738850593567
I0305 10:04:26.145938 139953291118400 spec.py:321] Evaluating on the training split.
I0305 10:04:37.453339 139953291118400 spec.py:333] Evaluating on the validation split.
I0305 10:05:04.817310 139953291118400 spec.py:349] Evaluating on the test split.
I0305 10:05:06.446358 139953291118400 submission_runner.py:411] Time since start: 252546.62s, 	Step: 522219, 	{'train/accuracy': 0.8867968320846558, 'train/loss': 0.42232993245124817, 'validation/accuracy': 0.7803199887275696, 'validation/loss': 0.8548135757446289, 'validation/num_examples': 50000, 'test/accuracy': 0.6648000478744507, 'test/loss': 1.4506032466888428, 'test/num_examples': 10000, 'score': 232356.45809936523, 'total_duration': 252546.62259054184, 'accumulated_submission_time': 232356.45809936523, 'accumulated_eval_time': 20119.089794397354, 'accumulated_logging_time': 44.54976439476013}
I0305 10:05:06.540118 139758009304832 logging_writer.py:48] [522219] accumulated_eval_time=20119.089794, accumulated_logging_time=44.549764, accumulated_submission_time=232356.458099, global_step=522219, preemption_count=0, score=232356.458099, test/accuracy=0.664800, test/loss=1.450603, test/num_examples=10000, total_duration=252546.622591, train/accuracy=0.886797, train/loss=0.422330, validation/accuracy=0.780320, validation/loss=0.854814, validation/num_examples=50000
I0305 10:05:38.899861 139758026090240 logging_writer.py:48] [522300] global_step=522300, grad_norm=3.140801191329956, loss=2.342925548553467
I0305 10:06:23.656197 139758009304832 logging_writer.py:48] [522400] global_step=522400, grad_norm=4.009039878845215, loss=2.89280104637146
I0305 10:07:08.928001 139758026090240 logging_writer.py:48] [522500] global_step=522500, grad_norm=3.065382242202759, loss=1.1144640445709229
I0305 10:07:54.084751 139758009304832 logging_writer.py:48] [522600] global_step=522600, grad_norm=4.595930099487305, loss=3.0881881713867188
I0305 10:08:30.412173 139758026090240 logging_writer.py:48] [522682] global_step=522682, preemption_count=0, score=232560.160981
I0305 10:08:30.937677 139953291118400 checkpoints.py:490] Saving checkpoint at step: 522682
I0305 10:08:32.303372 139953291118400 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification_self_tuning/study_1/imagenet_vit_jax/trial_1/checkpoint_522682
I0305 10:08:32.324455 139953291118400 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification_self_tuning/study_1/imagenet_vit_jax/trial_1/checkpoint_522682.
I0305 10:08:33.091436 139953291118400 submission_runner.py:676] Final imagenet_vit score: 232560.16098117828
