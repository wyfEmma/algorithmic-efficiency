python3 submission_runner.py --framework=jax --workload=imagenet_vit --submission_path=prize_qualification_baselines/self_tuning/jax_nadamw_full_budget.py --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=prize_qualification_self_tuning/study_3 --overwrite=true --save_checkpoints=false --rng_seed=2946000045 --max_global_steps=559998 --imagenet_v2_data_dir=/data/imagenet/jax --tuning_ruleset=self 2>&1 | tee -a /logs/imagenet_vit_jax_03-02-2024-11-31-55.log
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0302 11:32:16.710785 140437341357888 logger_utils.py:76] Creating experiment directory at /experiment_runs/prize_qualification_self_tuning/study_3/imagenet_vit_jax.
I0302 11:32:17.745232 140437341357888 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0302 11:32:17.745979 140437341357888 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0302 11:32:17.746103 140437341357888 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0302 11:32:18.681000 140437341357888 submission_runner.py:605] Creating directory at /experiment_runs/prize_qualification_self_tuning/study_3/imagenet_vit_jax/trial_1.
I0302 11:32:18.882737 140437341357888 submission_runner.py:206] Initializing dataset.
I0302 11:32:18.898832 140437341357888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:32:18.909368 140437341357888 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:32:19.287280 140437341357888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:32:27.617269 140437341357888 submission_runner.py:213] Initializing model.
I0302 11:32:36.768104 140437341357888 submission_runner.py:255] Initializing optimizer.
I0302 11:32:37.779942 140437341357888 submission_runner.py:262] Initializing metrics bundle.
I0302 11:32:37.780136 140437341357888 submission_runner.py:280] Initializing checkpoint and logger.
I0302 11:32:37.781050 140437341357888 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification_self_tuning/study_3/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0302 11:32:37.781196 140437341357888 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification_self_tuning/study_3/imagenet_vit_jax/trial_1/meta_data_0.json.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0302 11:32:38.126712 140437341357888 logger_utils.py:220] Unable to record git information. Continuing without it.
I0302 11:32:38.438688 140437341357888 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification_self_tuning/study_3/imagenet_vit_jax/trial_1/flags_0.json.
I0302 11:32:38.448450 140437341357888 submission_runner.py:314] Starting training loop.
I0302 11:33:20.932443 140275435431680 logging_writer.py:48] [0] global_step=0, grad_norm=0.3829880952835083, loss=6.9077558517456055
I0302 11:33:20.950755 140437341357888 spec.py:321] Evaluating on the training split.
I0302 11:33:21.153318 140437341357888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:33:21.162729 140437341357888 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:33:21.248720 140437341357888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:33:38.339187 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 11:33:38.350954 140437341357888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:33:38.371382 140437341357888 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0302 11:33:38.441258 140437341357888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0302 11:33:55.996279 140437341357888 spec.py:349] Evaluating on the test split.
I0302 11:33:56.004192 140437341357888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0302 11:33:56.009607 140437341357888 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0302 11:33:56.060401 140437341357888 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0302 11:34:01.279316 140437341357888 submission_runner.py:411] Time since start: 82.83s, 	Step: 1, 	{'train/accuracy': 0.0008789062267169356, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 42.50220847129822, 'total_duration': 82.83079028129578, 'accumulated_submission_time': 42.50220847129822, 'accumulated_eval_time': 40.32848334312439, 'accumulated_logging_time': 0}
I0302 11:34:01.296799 140239834171136 logging_writer.py:48] [1] accumulated_eval_time=40.328483, accumulated_logging_time=0, accumulated_submission_time=42.502208, global_step=1, preemption_count=0, score=42.502208, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=82.830790, train/accuracy=0.000879, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0302 11:35:04.083671 140274235832064 logging_writer.py:48] [100] global_step=100, grad_norm=0.5005055665969849, loss=6.873180389404297
I0302 11:35:46.799135 140274244224768 logging_writer.py:48] [200] global_step=200, grad_norm=0.7011339068412781, loss=6.756557941436768
I0302 11:36:31.647747 140274235832064 logging_writer.py:48] [300] global_step=300, grad_norm=0.761466920375824, loss=6.734745979309082
I0302 11:37:16.410227 140274244224768 logging_writer.py:48] [400] global_step=400, grad_norm=1.1094402074813843, loss=6.7266082763671875
I0302 11:38:00.968219 140274235832064 logging_writer.py:48] [500] global_step=500, grad_norm=1.3051015138626099, loss=6.511037826538086
I0302 11:38:45.547436 140274244224768 logging_writer.py:48] [600] global_step=600, grad_norm=1.0015510320663452, loss=6.361763954162598
I0302 11:39:30.492803 140274235832064 logging_writer.py:48] [700] global_step=700, grad_norm=1.1283841133117676, loss=6.259181022644043
I0302 11:40:15.162277 140274244224768 logging_writer.py:48] [800] global_step=800, grad_norm=1.2762572765350342, loss=6.16037130355835
I0302 11:40:59.800459 140274235832064 logging_writer.py:48] [900] global_step=900, grad_norm=1.3492511510849, loss=6.122115135192871
I0302 11:41:01.463483 140437341357888 spec.py:321] Evaluating on the training split.
I0302 11:41:13.292011 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 11:41:21.391506 140437341357888 spec.py:349] Evaluating on the test split.
I0302 11:41:23.171535 140437341357888 submission_runner.py:411] Time since start: 524.72s, 	Step: 905, 	{'train/accuracy': 0.03554687276482582, 'train/loss': 5.822093486785889, 'validation/accuracy': 0.03659999743103981, 'validation/loss': 5.84222936630249, 'validation/num_examples': 50000, 'test/accuracy': 0.027300002053380013, 'test/loss': 5.976207733154297, 'test/num_examples': 10000, 'score': 462.60794973373413, 'total_duration': 524.7230081558228, 'accumulated_submission_time': 462.60794973373413, 'accumulated_eval_time': 62.036508321762085, 'accumulated_logging_time': 0.027024507522583008}
I0302 11:41:23.188843 140239842563840 logging_writer.py:48] [905] accumulated_eval_time=62.036508, accumulated_logging_time=0.027025, accumulated_submission_time=462.607950, global_step=905, preemption_count=0, score=462.607950, test/accuracy=0.027300, test/loss=5.976208, test/num_examples=10000, total_duration=524.723008, train/accuracy=0.035547, train/loss=5.822093, validation/accuracy=0.036600, validation/loss=5.842229, validation/num_examples=50000
I0302 11:42:01.255808 140239850956544 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.6092238426208496, loss=6.064470291137695
I0302 11:42:45.161884 140239842563840 logging_writer.py:48] [1100] global_step=1100, grad_norm=1.3658030033111572, loss=5.991452217102051
I0302 11:43:29.711706 140239850956544 logging_writer.py:48] [1200] global_step=1200, grad_norm=1.642936110496521, loss=5.995937347412109
I0302 11:44:14.221118 140239842563840 logging_writer.py:48] [1300] global_step=1300, grad_norm=1.1735769510269165, loss=6.682716369628906
I0302 11:44:58.607846 140239850956544 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.893357515335083, loss=6.112025737762451
I0302 11:45:43.015927 140239842563840 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.1369004249572754, loss=5.846339225769043
I0302 11:46:27.457262 140239850956544 logging_writer.py:48] [1600] global_step=1600, grad_norm=1.255796194076538, loss=5.8866658210754395
I0302 11:47:12.021486 140239842563840 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.2336695194244385, loss=5.697193145751953
I0302 11:47:56.524363 140239850956544 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.9547751545906067, loss=6.314009189605713
I0302 11:48:23.380141 140437341357888 spec.py:321] Evaluating on the training split.
I0302 11:48:35.062770 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 11:48:43.187684 140437341357888 spec.py:349] Evaluating on the test split.
I0302 11:48:44.837371 140437341357888 submission_runner.py:411] Time since start: 966.39s, 	Step: 1862, 	{'train/accuracy': 0.0798046886920929, 'train/loss': 5.190312385559082, 'validation/accuracy': 0.07631999999284744, 'validation/loss': 5.234590530395508, 'validation/num_examples': 50000, 'test/accuracy': 0.059700001031160355, 'test/loss': 5.4772138595581055, 'test/num_examples': 10000, 'score': 882.7354953289032, 'total_duration': 966.3888356685638, 'accumulated_submission_time': 882.7354953289032, 'accumulated_eval_time': 83.49371838569641, 'accumulated_logging_time': 0.054917097091674805}
I0302 11:48:44.854013 140239842563840 logging_writer.py:48] [1862] accumulated_eval_time=83.493718, accumulated_logging_time=0.054917, accumulated_submission_time=882.735495, global_step=1862, preemption_count=0, score=882.735495, test/accuracy=0.059700, test/loss=5.477214, test/num_examples=10000, total_duration=966.388836, train/accuracy=0.079805, train/loss=5.190312, validation/accuracy=0.076320, validation/loss=5.234591, validation/num_examples=50000
I0302 11:49:00.383018 140239850956544 logging_writer.py:48] [1900] global_step=1900, grad_norm=1.1192595958709717, loss=6.2866129875183105
I0302 11:49:41.778338 140239842563840 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.270922064781189, loss=5.697625637054443
I0302 11:50:25.940685 140239850956544 logging_writer.py:48] [2100] global_step=2100, grad_norm=1.1933186054229736, loss=6.323116779327393
I0302 11:51:10.720907 140239842563840 logging_writer.py:48] [2200] global_step=2200, grad_norm=1.3534677028656006, loss=5.536617279052734
I0302 11:51:54.970650 140239850956544 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.9842321872711182, loss=5.54166841506958
I0302 11:52:39.285558 140239842563840 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.9216930866241455, loss=6.069952011108398
I0302 11:53:23.822808 140239850956544 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.9981909990310669, loss=5.369122505187988
I0302 11:54:08.289898 140239842563840 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.8093570470809937, loss=6.481212615966797
I0302 11:54:52.649011 140239850956544 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.8702111840248108, loss=5.277936935424805
I0302 11:55:36.992380 140239842563840 logging_writer.py:48] [2800] global_step=2800, grad_norm=1.095269799232483, loss=5.238292694091797
I0302 11:55:45.016648 140437341357888 spec.py:321] Evaluating on the training split.
I0302 11:55:56.893387 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 11:56:05.061860 140437341357888 spec.py:349] Evaluating on the test split.
I0302 11:56:06.704030 140437341357888 submission_runner.py:411] Time since start: 1408.26s, 	Step: 2820, 	{'train/accuracy': 0.14707030355930328, 'train/loss': 4.55432653427124, 'validation/accuracy': 0.13609999418258667, 'validation/loss': 4.649452209472656, 'validation/num_examples': 50000, 'test/accuracy': 0.10690000653266907, 'test/loss': 4.9579620361328125, 'test/num_examples': 10000, 'score': 1302.8323924541473, 'total_duration': 1408.2555124759674, 'accumulated_submission_time': 1302.8323924541473, 'accumulated_eval_time': 105.18109583854675, 'accumulated_logging_time': 0.08419084548950195}
I0302 11:56:06.720997 140239850956544 logging_writer.py:48] [2820] accumulated_eval_time=105.181096, accumulated_logging_time=0.084191, accumulated_submission_time=1302.832392, global_step=2820, preemption_count=0, score=1302.832392, test/accuracy=0.106900, test/loss=4.957962, test/num_examples=10000, total_duration=1408.255512, train/accuracy=0.147070, train/loss=4.554327, validation/accuracy=0.136100, validation/loss=4.649452, validation/num_examples=50000
I0302 11:56:38.928356 140239842563840 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.7838850021362305, loss=5.46610164642334
I0302 11:57:21.836489 140239850956544 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.0748579502105713, loss=5.182511806488037
I0302 11:58:06.521846 140239842563840 logging_writer.py:48] [3100] global_step=3100, grad_norm=1.0267328023910522, loss=6.521856784820557
I0302 11:58:50.935941 140239850956544 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.8825456500053406, loss=4.89658784866333
I0302 11:59:35.031030 140239842563840 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.8524522185325623, loss=5.016838073730469
I0302 12:00:19.506307 140239850956544 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.6427421569824219, loss=6.194312572479248
I0302 12:01:03.849506 140239842563840 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.8390930891036987, loss=4.935817718505859
I0302 12:01:48.119366 140239850956544 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.8363797664642334, loss=5.606818199157715
I0302 12:02:32.356594 140239842563840 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.9079563617706299, loss=5.187622547149658
I0302 12:03:06.848784 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:03:18.677107 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:03:26.802541 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:03:28.445727 140437341357888 submission_runner.py:411] Time since start: 1850.00s, 	Step: 3779, 	{'train/accuracy': 0.20310546457767487, 'train/loss': 4.117558002471924, 'validation/accuracy': 0.1888599991798401, 'validation/loss': 4.196497440338135, 'validation/num_examples': 50000, 'test/accuracy': 0.14640000462532043, 'test/loss': 4.582161903381348, 'test/num_examples': 10000, 'score': 1722.8942482471466, 'total_duration': 1849.997201681137, 'accumulated_submission_time': 1722.8942482471466, 'accumulated_eval_time': 126.77802324295044, 'accumulated_logging_time': 0.11354184150695801}
I0302 12:03:28.462397 140239850956544 logging_writer.py:48] [3779] accumulated_eval_time=126.778023, accumulated_logging_time=0.113542, accumulated_submission_time=1722.894248, global_step=3779, preemption_count=0, score=1722.894248, test/accuracy=0.146400, test/loss=4.582162, test/num_examples=10000, total_duration=1849.997202, train/accuracy=0.203105, train/loss=4.117558, validation/accuracy=0.188860, validation/loss=4.196497, validation/num_examples=50000
I0302 12:03:38.906322 140239842563840 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.8824358582496643, loss=5.8390092849731445
I0302 12:04:20.389494 140239850956544 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.9139003753662109, loss=5.150338649749756
I0302 12:05:04.808585 140239842563840 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.864567756652832, loss=4.901705741882324
I0302 12:05:49.030425 140239850956544 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.9755605459213257, loss=5.163089752197266
I0302 12:06:33.753706 140239842563840 logging_writer.py:48] [4200] global_step=4200, grad_norm=1.069621205329895, loss=4.6611104011535645
I0302 12:07:18.211257 140239850956544 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.8617081642150879, loss=6.206757545471191
I0302 12:08:02.550315 140239842563840 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.7388527989387512, loss=5.734652042388916
I0302 12:08:47.034443 140239850956544 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.7750657200813293, loss=4.599539756774902
I0302 12:09:31.923128 140239842563840 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.9934520125389099, loss=4.622594356536865
I0302 12:10:16.402255 140239850956544 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.5687587261199951, loss=6.214859485626221
I0302 12:10:28.713176 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:10:40.536780 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:10:48.931169 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:10:50.560564 140437341357888 submission_runner.py:411] Time since start: 2292.11s, 	Step: 4723, 	{'train/accuracy': 0.26109373569488525, 'train/loss': 3.6418685913085938, 'validation/accuracy': 0.2449599951505661, 'validation/loss': 3.743607997894287, 'validation/num_examples': 50000, 'test/accuracy': 0.18580001592636108, 'test/loss': 4.2058210372924805, 'test/num_examples': 10000, 'score': 2143.081571817398, 'total_duration': 2292.112045764923, 'accumulated_submission_time': 2143.081571817398, 'accumulated_eval_time': 148.62538933753967, 'accumulated_logging_time': 0.1412358283996582}
I0302 12:10:50.578512 140239842563840 logging_writer.py:48] [4723] accumulated_eval_time=148.625389, accumulated_logging_time=0.141236, accumulated_submission_time=2143.081572, global_step=4723, preemption_count=0, score=2143.081572, test/accuracy=0.185800, test/loss=4.205821, test/num_examples=10000, total_duration=2292.112046, train/accuracy=0.261094, train/loss=3.641869, validation/accuracy=0.244960, validation/loss=3.743608, validation/num_examples=50000
I0302 12:11:21.515053 140239850956544 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.9362884163856506, loss=4.356508255004883
I0302 12:12:04.827475 140239842563840 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.679894208908081, loss=5.667918682098389
I0302 12:12:49.501048 140239850956544 logging_writer.py:48] [5000] global_step=5000, grad_norm=1.000535011291504, loss=4.361759662628174
I0302 12:13:34.210570 140239842563840 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.6325433850288391, loss=5.791783809661865
I0302 12:14:18.889989 140239850956544 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.7135804891586304, loss=5.7742695808410645
I0302 12:15:03.472326 140239842563840 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.7562062740325928, loss=5.969594478607178
I0302 12:15:48.015412 140239850956544 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.9958623647689819, loss=4.225274562835693
I0302 12:16:32.647888 140239842563840 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.8128880858421326, loss=4.176560878753662
I0302 12:17:17.394308 140239850956544 logging_writer.py:48] [5600] global_step=5600, grad_norm=1.1626356840133667, loss=4.152880668640137
I0302 12:17:50.667549 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:18:02.621031 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:18:10.755551 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:18:12.396656 140437341357888 submission_runner.py:411] Time since start: 2733.95s, 	Step: 5677, 	{'train/accuracy': 0.32023435831069946, 'train/loss': 3.211933135986328, 'validation/accuracy': 0.2983799874782562, 'validation/loss': 3.3576674461364746, 'validation/num_examples': 50000, 'test/accuracy': 0.22990001738071442, 'test/loss': 3.89674711227417, 'test/num_examples': 10000, 'score': 2563.1050510406494, 'total_duration': 2733.9481399059296, 'accumulated_submission_time': 2563.1050510406494, 'accumulated_eval_time': 170.35447335243225, 'accumulated_logging_time': 0.17062067985534668}
I0302 12:18:12.414512 140239842563840 logging_writer.py:48] [5677] accumulated_eval_time=170.354473, accumulated_logging_time=0.170621, accumulated_submission_time=2563.105051, global_step=5677, preemption_count=0, score=2563.105051, test/accuracy=0.229900, test/loss=3.896747, test/num_examples=10000, total_duration=2733.948140, train/accuracy=0.320234, train/loss=3.211933, validation/accuracy=0.298380, validation/loss=3.357667, validation/num_examples=50000
I0302 12:18:21.972525 140239850956544 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.6981228590011597, loss=5.889019012451172
I0302 12:19:02.430201 140239842563840 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.9449736475944519, loss=4.132819652557373
I0302 12:19:46.954037 140239850956544 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.9154593348503113, loss=4.093621253967285
I0302 12:20:31.778441 140239842563840 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.8971524238586426, loss=4.121603012084961
I0302 12:21:16.404131 140239850956544 logging_writer.py:48] [6100] global_step=6100, grad_norm=1.1184581518173218, loss=4.285213470458984
I0302 12:22:00.858226 140239842563840 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.6456550359725952, loss=5.867560386657715
I0302 12:22:46.155785 140239850956544 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.910300612449646, loss=4.326431751251221
I0302 12:23:30.762132 140239842563840 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.9596251249313354, loss=4.006878852844238
I0302 12:24:15.659108 140239850956544 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.6881359219551086, loss=6.049872398376465
I0302 12:25:00.413666 140239842563840 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.8406105637550354, loss=4.73117208480835
I0302 12:25:12.646732 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:25:24.543112 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:25:32.712271 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:25:34.345980 140437341357888 submission_runner.py:411] Time since start: 3175.90s, 	Step: 6629, 	{'train/accuracy': 0.36552733182907104, 'train/loss': 2.978093147277832, 'validation/accuracy': 0.32933998107910156, 'validation/loss': 3.1722586154937744, 'validation/num_examples': 50000, 'test/accuracy': 0.2574000060558319, 'test/loss': 3.7208309173583984, 'test/num_examples': 10000, 'score': 2983.2663242816925, 'total_duration': 3175.8974702358246, 'accumulated_submission_time': 2983.2663242816925, 'accumulated_eval_time': 192.05371141433716, 'accumulated_logging_time': 0.20076274871826172}
I0302 12:25:34.364133 140239850956544 logging_writer.py:48] [6629] accumulated_eval_time=192.053711, accumulated_logging_time=0.200763, accumulated_submission_time=2983.266324, global_step=6629, preemption_count=0, score=2983.266324, test/accuracy=0.257400, test/loss=3.720831, test/num_examples=10000, total_duration=3175.897470, train/accuracy=0.365527, train/loss=2.978093, validation/accuracy=0.329340, validation/loss=3.172259, validation/num_examples=50000
I0302 12:26:02.953792 140239842563840 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.9966864585876465, loss=3.9600565433502197
I0302 12:26:46.763648 140239850956544 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.6026954054832458, loss=6.006199836730957
I0302 12:27:31.150984 140239842563840 logging_writer.py:48] [6900] global_step=6900, grad_norm=1.0008066892623901, loss=3.9587714672088623
I0302 12:28:15.801199 140239850956544 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.9485716819763184, loss=3.7732622623443604
I0302 12:29:00.583630 140239842563840 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.9880208373069763, loss=3.869427442550659
I0302 12:29:45.064766 140239850956544 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.7699708938598633, loss=4.375579357147217
I0302 12:30:29.721794 140239842563840 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.8854593634605408, loss=3.7429583072662354
I0302 12:31:14.463490 140239850956544 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.8753278851509094, loss=3.8576579093933105
I0302 12:31:59.626981 140239842563840 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.7372294664382935, loss=4.141473770141602
I0302 12:32:34.550989 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:32:46.307821 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:32:59.599811 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:33:01.260927 140437341357888 submission_runner.py:411] Time since start: 3622.81s, 	Step: 7578, 	{'train/accuracy': 0.39238280057907104, 'train/loss': 2.8480987548828125, 'validation/accuracy': 0.3620399832725525, 'validation/loss': 2.98736834526062, 'validation/num_examples': 50000, 'test/accuracy': 0.27720001339912415, 'test/loss': 3.57218599319458, 'test/num_examples': 10000, 'score': 3403.3904716968536, 'total_duration': 3622.8114750385284, 'accumulated_submission_time': 3403.3904716968536, 'accumulated_eval_time': 218.76269936561584, 'accumulated_logging_time': 0.22899770736694336}
I0302 12:33:01.292181 140239850956544 logging_writer.py:48] [7578] accumulated_eval_time=218.762699, accumulated_logging_time=0.228998, accumulated_submission_time=3403.390472, global_step=7578, preemption_count=0, score=3403.390472, test/accuracy=0.277200, test/loss=3.572186, test/num_examples=10000, total_duration=3622.811475, train/accuracy=0.392383, train/loss=2.848099, validation/accuracy=0.362040, validation/loss=2.987368, validation/num_examples=50000
I0302 12:33:10.445317 140239842563840 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.7966439723968506, loss=4.190182209014893
I0302 12:33:52.064111 140239850956544 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.9593566060066223, loss=3.724109411239624
I0302 12:34:36.636231 140239842563840 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.7817544937133789, loss=4.963695049285889
I0302 12:35:21.230058 140239850956544 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.9202883839607239, loss=3.7189507484436035
I0302 12:36:05.740350 140239842563840 logging_writer.py:48] [8000] global_step=8000, grad_norm=1.0093917846679688, loss=3.8692476749420166
I0302 12:36:50.421950 140239850956544 logging_writer.py:48] [8100] global_step=8100, grad_norm=1.0410164594650269, loss=3.5878541469573975
I0302 12:37:35.370348 140239842563840 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.8887695074081421, loss=3.613563299179077
I0302 12:38:20.117030 140239850956544 logging_writer.py:48] [8300] global_step=8300, grad_norm=1.0541977882385254, loss=6.040867805480957
I0302 12:39:05.113826 140239842563840 logging_writer.py:48] [8400] global_step=8400, grad_norm=1.0136090517044067, loss=3.5600197315216064
I0302 12:39:49.565135 140239850956544 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.9396311640739441, loss=3.5420336723327637
I0302 12:40:01.274317 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:40:13.737933 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:40:26.145211 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:40:27.765160 140437341357888 submission_runner.py:411] Time since start: 4069.32s, 	Step: 8528, 	{'train/accuracy': 0.42042967677116394, 'train/loss': 2.6367781162261963, 'validation/accuracy': 0.38628000020980835, 'validation/loss': 2.8177895545959473, 'validation/num_examples': 50000, 'test/accuracy': 0.2962000072002411, 'test/loss': 3.4249939918518066, 'test/num_examples': 10000, 'score': 3823.300567626953, 'total_duration': 4069.3166477680206, 'accumulated_submission_time': 3823.300567626953, 'accumulated_eval_time': 245.2535297870636, 'accumulated_logging_time': 0.27889108657836914}
I0302 12:40:27.788654 140239842563840 logging_writer.py:48] [8528] accumulated_eval_time=245.253530, accumulated_logging_time=0.278891, accumulated_submission_time=3823.300568, global_step=8528, preemption_count=0, score=3823.300568, test/accuracy=0.296200, test/loss=3.424994, test/num_examples=10000, total_duration=4069.316648, train/accuracy=0.420430, train/loss=2.636778, validation/accuracy=0.386280, validation/loss=2.817790, validation/num_examples=50000
I0302 12:40:56.822929 140239850956544 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.7064874768257141, loss=4.6720170974731445
I0302 12:41:40.345217 140239842563840 logging_writer.py:48] [8700] global_step=8700, grad_norm=1.010204553604126, loss=3.3985934257507324
I0302 12:42:25.364197 140239850956544 logging_writer.py:48] [8800] global_step=8800, grad_norm=1.0540670156478882, loss=3.5133283138275146
I0302 12:43:10.088909 140239842563840 logging_writer.py:48] [8900] global_step=8900, grad_norm=1.014290690422058, loss=3.5956544876098633
I0302 12:43:54.731564 140239850956544 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.7342707514762878, loss=4.343333721160889
I0302 12:44:39.568938 140239842563840 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.9162381887435913, loss=3.747659683227539
I0302 12:45:24.454568 140239850956544 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.9465615153312683, loss=3.5482094287872314
I0302 12:46:09.111881 140239842563840 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.850430965423584, loss=4.270470142364502
I0302 12:46:53.661381 140239850956544 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.9746763706207275, loss=5.827300548553467
I0302 12:47:28.015598 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:47:40.610826 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:47:52.096869 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:47:53.730700 140437341357888 submission_runner.py:411] Time since start: 4515.28s, 	Step: 9478, 	{'train/accuracy': 0.45830076932907104, 'train/loss': 2.420060396194458, 'validation/accuracy': 0.41509997844696045, 'validation/loss': 2.6546177864074707, 'validation/num_examples': 50000, 'test/accuracy': 0.3241000175476074, 'test/loss': 3.2569079399108887, 'test/num_examples': 10000, 'score': 4243.458779096603, 'total_duration': 4515.28219127655, 'accumulated_submission_time': 4243.458779096603, 'accumulated_eval_time': 270.96862721443176, 'accumulated_logging_time': 0.31832003593444824}
I0302 12:47:53.753254 140239842563840 logging_writer.py:48] [9478] accumulated_eval_time=270.968627, accumulated_logging_time=0.318320, accumulated_submission_time=4243.458779, global_step=9478, preemption_count=0, score=4243.458779, test/accuracy=0.324100, test/loss=3.256908, test/num_examples=10000, total_duration=4515.282191, train/accuracy=0.458301, train/loss=2.420060, validation/accuracy=0.415100, validation/loss=2.654618, validation/num_examples=50000
I0302 12:48:02.910223 140239850956544 logging_writer.py:48] [9500] global_step=9500, grad_norm=1.0212881565093994, loss=3.774773359298706
I0302 12:48:44.323126 140239842563840 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.8982263207435608, loss=3.4602952003479004
I0302 12:49:29.220918 140239850956544 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.8949556946754456, loss=5.327859401702881
I0302 12:50:14.671102 140239842563840 logging_writer.py:48] [9800] global_step=9800, grad_norm=1.1058887243270874, loss=3.545407772064209
I0302 12:50:59.602397 140239850956544 logging_writer.py:48] [9900] global_step=9900, grad_norm=1.0110756158828735, loss=3.571183681488037
I0302 12:51:44.812779 140239842563840 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.9914096593856812, loss=3.4089181423187256
I0302 12:52:29.824006 140239850956544 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.8126949071884155, loss=4.365210056304932
I0302 12:53:14.668547 140239842563840 logging_writer.py:48] [10200] global_step=10200, grad_norm=1.0560308694839478, loss=3.4325459003448486
I0302 12:53:59.336101 140239850956544 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.8961960077285767, loss=3.436338186264038
I0302 12:54:44.238430 140239842563840 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.715890645980835, loss=5.764720916748047
I0302 12:54:54.123090 140437341357888 spec.py:321] Evaluating on the training split.
I0302 12:55:06.796894 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 12:55:18.891036 140437341357888 spec.py:349] Evaluating on the test split.
I0302 12:55:20.530148 140437341357888 submission_runner.py:411] Time since start: 4962.08s, 	Step: 10424, 	{'train/accuracy': 0.4592382609844208, 'train/loss': 2.421598434448242, 'validation/accuracy': 0.4288399815559387, 'validation/loss': 2.58870530128479, 'validation/num_examples': 50000, 'test/accuracy': 0.32450002431869507, 'test/loss': 3.2115306854248047, 'test/num_examples': 10000, 'score': 4663.765017032623, 'total_duration': 4962.0816378593445, 'accumulated_submission_time': 4663.765017032623, 'accumulated_eval_time': 297.37568044662476, 'accumulated_logging_time': 0.35201382637023926}
I0302 12:55:20.549195 140239850956544 logging_writer.py:48] [10424] accumulated_eval_time=297.375680, accumulated_logging_time=0.352014, accumulated_submission_time=4663.765017, global_step=10424, preemption_count=0, score=4663.765017, test/accuracy=0.324500, test/loss=3.211531, test/num_examples=10000, total_duration=4962.081638, train/accuracy=0.459238, train/loss=2.421598, validation/accuracy=0.428840, validation/loss=2.588705, validation/num_examples=50000
I0302 12:55:51.132049 140239842563840 logging_writer.py:48] [10500] global_step=10500, grad_norm=1.175643801689148, loss=3.4766685962677
I0302 12:56:34.909860 140239850956544 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.7468108534812927, loss=5.334751605987549
I0302 12:57:19.584532 140239842563840 logging_writer.py:48] [10700] global_step=10700, grad_norm=1.1938287019729614, loss=3.4376726150512695
I0302 12:58:04.559093 140239850956544 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.9404244422912598, loss=3.608335494995117
I0302 12:58:49.439324 140239842563840 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.750495433807373, loss=4.980507850646973
I0302 12:59:34.134782 140239850956544 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.9185575246810913, loss=3.449523448944092
I0302 13:00:18.784914 140239842563840 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.668583869934082, loss=5.736700057983398
I0302 13:01:03.751267 140239850956544 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.8162118196487427, loss=5.731654644012451
I0302 13:01:48.614388 140239842563840 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.9737588167190552, loss=3.384260416030884
I0302 13:02:20.554817 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:02:33.216632 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:02:47.288197 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:02:48.926402 140437341357888 submission_runner.py:411] Time since start: 5410.48s, 	Step: 11373, 	{'train/accuracy': 0.47648435831069946, 'train/loss': 2.326941728591919, 'validation/accuracy': 0.44207999110221863, 'validation/loss': 2.498100519180298, 'validation/num_examples': 50000, 'test/accuracy': 0.34390002489089966, 'test/loss': 3.133396625518799, 'test/num_examples': 10000, 'score': 5083.707577466965, 'total_duration': 5410.477880477905, 'accumulated_submission_time': 5083.707577466965, 'accumulated_eval_time': 325.7472426891327, 'accumulated_logging_time': 0.38140106201171875}
I0302 13:02:48.945848 140239850956544 logging_writer.py:48] [11373] accumulated_eval_time=325.747243, accumulated_logging_time=0.381401, accumulated_submission_time=5083.707577, global_step=11373, preemption_count=0, score=5083.707577, test/accuracy=0.343900, test/loss=3.133397, test/num_examples=10000, total_duration=5410.477880, train/accuracy=0.476484, train/loss=2.326942, validation/accuracy=0.442080, validation/loss=2.498101, validation/num_examples=50000
I0302 13:03:00.058598 140239842563840 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.7803218364715576, loss=4.55192232131958
I0302 13:03:41.466927 140239850956544 logging_writer.py:48] [11500] global_step=11500, grad_norm=1.0563851594924927, loss=3.318615674972534
I0302 13:04:26.026530 140239842563840 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.9780824780464172, loss=3.7756881713867188
I0302 13:05:11.346286 140239850956544 logging_writer.py:48] [11700] global_step=11700, grad_norm=1.12057363986969, loss=3.2384045124053955
I0302 13:05:56.270386 140239842563840 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.98731529712677, loss=3.6684014797210693
I0302 13:06:41.199196 140239850956544 logging_writer.py:48] [11900] global_step=11900, grad_norm=1.0056599378585815, loss=3.788219928741455
I0302 13:07:25.916688 140239842563840 logging_writer.py:48] [12000] global_step=12000, grad_norm=1.0313316583633423, loss=3.1448917388916016
I0302 13:08:10.560614 140239850956544 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.7557284832000732, loss=4.243832111358643
I0302 13:08:55.025283 140239842563840 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.8340322971343994, loss=5.681955337524414
I0302 13:09:40.009186 140239850956544 logging_writer.py:48] [12300] global_step=12300, grad_norm=1.0248967409133911, loss=4.269565582275391
I0302 13:09:49.056551 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:10:01.937084 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:10:15.138529 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:10:16.777981 140437341357888 submission_runner.py:411] Time since start: 5858.33s, 	Step: 12322, 	{'train/accuracy': 0.5114062428474426, 'train/loss': 2.1223716735839844, 'validation/accuracy': 0.4688199758529663, 'validation/loss': 2.3403637409210205, 'validation/num_examples': 50000, 'test/accuracy': 0.36250001192092896, 'test/loss': 3.0175158977508545, 'test/num_examples': 10000, 'score': 5503.754225730896, 'total_duration': 5858.329460859299, 'accumulated_submission_time': 5503.754225730896, 'accumulated_eval_time': 353.4686424732208, 'accumulated_logging_time': 0.4112565517425537}
I0302 13:10:16.797637 140239842563840 logging_writer.py:48] [12322] accumulated_eval_time=353.468642, accumulated_logging_time=0.411257, accumulated_submission_time=5503.754226, global_step=12322, preemption_count=0, score=5503.754226, test/accuracy=0.362500, test/loss=3.017516, test/num_examples=10000, total_duration=5858.329461, train/accuracy=0.511406, train/loss=2.122372, validation/accuracy=0.468820, validation/loss=2.340364, validation/num_examples=50000
I0302 13:10:48.154987 140239850956544 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.8500574827194214, loss=5.833484649658203
I0302 13:11:32.761432 140239842563840 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.9691016674041748, loss=3.203922748565674
I0302 13:12:18.727446 140239850956544 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.9695534706115723, loss=3.4879825115203857
I0302 13:13:04.453168 140239842563840 logging_writer.py:48] [12700] global_step=12700, grad_norm=1.0383890867233276, loss=3.3110885620117188
I0302 13:13:50.092195 140239850956544 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.9294177293777466, loss=4.047180652618408
I0302 13:14:35.239144 140239842563840 logging_writer.py:48] [12900] global_step=12900, grad_norm=1.003609299659729, loss=3.214998245239258
I0302 13:15:20.300585 140239850956544 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.9493525624275208, loss=4.888681411743164
I0302 13:16:04.838297 140239842563840 logging_writer.py:48] [13100] global_step=13100, grad_norm=1.025982141494751, loss=3.4684243202209473
I0302 13:16:49.493183 140239850956544 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.7408168315887451, loss=4.548574924468994
I0302 13:17:17.071042 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:17:29.932723 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:17:44.127008 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:17:45.774359 140437341357888 submission_runner.py:411] Time since start: 6307.33s, 	Step: 13263, 	{'train/accuracy': 0.5409570336341858, 'train/loss': 2.0211377143859863, 'validation/accuracy': 0.47293999791145325, 'validation/loss': 2.332581043243408, 'validation/num_examples': 50000, 'test/accuracy': 0.3637000024318695, 'test/loss': 2.9906363487243652, 'test/num_examples': 10000, 'score': 5923.964722394943, 'total_duration': 6307.325840473175, 'accumulated_submission_time': 5923.964722394943, 'accumulated_eval_time': 382.17194390296936, 'accumulated_logging_time': 0.4417285919189453}
I0302 13:17:45.795210 140239842563840 logging_writer.py:48] [13263] accumulated_eval_time=382.171944, accumulated_logging_time=0.441729, accumulated_submission_time=5923.964722, global_step=13263, preemption_count=0, score=5923.964722, test/accuracy=0.363700, test/loss=2.990636, test/num_examples=10000, total_duration=6307.325840, train/accuracy=0.540957, train/loss=2.021138, validation/accuracy=0.472940, validation/loss=2.332581, validation/num_examples=50000
I0302 13:18:00.889250 140239850956544 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.9421168565750122, loss=5.362637519836426
I0302 13:18:43.016351 140239842563840 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.8600848317146301, loss=5.630124092102051
I0302 13:19:28.065977 140239850956544 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.9999251961708069, loss=3.257819652557373
I0302 13:20:14.034091 140239842563840 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.9859152436256409, loss=3.72585391998291
I0302 13:20:59.367899 140239850956544 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.96080082654953, loss=3.0462863445281982
I0302 13:21:44.508556 140239842563840 logging_writer.py:48] [13800] global_step=13800, grad_norm=1.135523796081543, loss=3.2018070220947266
I0302 13:22:29.095240 140239850956544 logging_writer.py:48] [13900] global_step=13900, grad_norm=1.1327039003372192, loss=3.207606792449951
I0302 13:23:13.837950 140239842563840 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.8330926895141602, loss=4.698027610778809
I0302 13:23:58.219896 140239850956544 logging_writer.py:48] [14100] global_step=14100, grad_norm=1.1543476581573486, loss=3.5365209579467773
I0302 13:24:43.105729 140239842563840 logging_writer.py:48] [14200] global_step=14200, grad_norm=1.1899621486663818, loss=3.0327162742614746
I0302 13:24:46.141824 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:24:59.600027 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:25:15.726986 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:25:17.368927 140437341357888 submission_runner.py:411] Time since start: 6758.92s, 	Step: 14209, 	{'train/accuracy': 0.5172070264816284, 'train/loss': 2.0955166816711426, 'validation/accuracy': 0.4853599965572357, 'validation/loss': 2.272596597671509, 'validation/num_examples': 50000, 'test/accuracy': 0.38050001859664917, 'test/loss': 2.9285807609558105, 'test/num_examples': 10000, 'score': 6344.242172241211, 'total_duration': 6758.920413732529, 'accumulated_submission_time': 6344.242172241211, 'accumulated_eval_time': 413.3990566730499, 'accumulated_logging_time': 0.4788401126861572}
I0302 13:25:17.388666 140239850956544 logging_writer.py:48] [14209] accumulated_eval_time=413.399057, accumulated_logging_time=0.478840, accumulated_submission_time=6344.242172, global_step=14209, preemption_count=0, score=6344.242172, test/accuracy=0.380500, test/loss=2.928581, test/num_examples=10000, total_duration=6758.920414, train/accuracy=0.517207, train/loss=2.095517, validation/accuracy=0.485360, validation/loss=2.272597, validation/num_examples=50000
I0302 13:25:54.012623 140239842563840 logging_writer.py:48] [14300] global_step=14300, grad_norm=1.0464212894439697, loss=4.415710926055908
I0302 13:26:39.240192 140239850956544 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.9619741439819336, loss=3.22117018699646
I0302 13:27:24.294328 140239842563840 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.007240891456604, loss=3.8211591243743896
I0302 13:28:09.414977 140239850956544 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.9961532950401306, loss=3.0341343879699707
I0302 13:28:54.216859 140239842563840 logging_writer.py:48] [14700] global_step=14700, grad_norm=1.0294923782348633, loss=3.1646599769592285
I0302 13:29:39.525309 140239850956544 logging_writer.py:48] [14800] global_step=14800, grad_norm=1.06196928024292, loss=3.0075478553771973
I0302 13:30:24.502606 140239842563840 logging_writer.py:48] [14900] global_step=14900, grad_norm=1.0537614822387695, loss=3.146906852722168
I0302 13:31:09.568171 140239850956544 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.0520654916763306, loss=2.9853663444519043
I0302 13:31:54.302946 140239842563840 logging_writer.py:48] [15100] global_step=15100, grad_norm=1.130768060684204, loss=3.1223669052124023
I0302 13:32:17.643082 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:32:31.054718 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:32:48.772244 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:32:50.395841 140437341357888 submission_runner.py:411] Time since start: 7211.95s, 	Step: 15153, 	{'train/accuracy': 0.53125, 'train/loss': 2.0604982376098633, 'validation/accuracy': 0.49181997776031494, 'validation/loss': 2.2550272941589355, 'validation/num_examples': 50000, 'test/accuracy': 0.3815000057220459, 'test/loss': 2.920339822769165, 'test/num_examples': 10000, 'score': 6764.433388948441, 'total_duration': 7211.947317838669, 'accumulated_submission_time': 6764.433388948441, 'accumulated_eval_time': 446.1518096923828, 'accumulated_logging_time': 0.5089349746704102}
I0302 13:32:50.418486 140239850956544 logging_writer.py:48] [15153] accumulated_eval_time=446.151810, accumulated_logging_time=0.508935, accumulated_submission_time=6764.433389, global_step=15153, preemption_count=0, score=6764.433389, test/accuracy=0.381500, test/loss=2.920340, test/num_examples=10000, total_duration=7211.947318, train/accuracy=0.531250, train/loss=2.060498, validation/accuracy=0.491820, validation/loss=2.255027, validation/num_examples=50000
I0302 13:33:09.487808 140239842563840 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.9107077717781067, loss=3.7909252643585205
I0302 13:33:52.234771 140239850956544 logging_writer.py:48] [15300] global_step=15300, grad_norm=1.1876349449157715, loss=2.939455270767212
I0302 13:34:37.583473 140239842563840 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.9526992440223694, loss=3.390979528427124
I0302 13:35:22.848246 140239850956544 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.220779538154602, loss=3.1388185024261475
I0302 13:36:08.099525 140239842563840 logging_writer.py:48] [15600] global_step=15600, grad_norm=1.1046252250671387, loss=3.145965576171875
I0302 13:36:53.284769 140239850956544 logging_writer.py:48] [15700] global_step=15700, grad_norm=1.135343074798584, loss=3.0305817127227783
I0302 13:37:38.404520 140239842563840 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.9175342321395874, loss=3.6792709827423096
I0302 13:38:22.969449 140239850956544 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.8589310646057129, loss=4.066981315612793
I0302 13:39:08.083359 140239842563840 logging_writer.py:48] [16000] global_step=16000, grad_norm=1.0998058319091797, loss=2.9637303352355957
I0302 13:39:50.491888 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:40:04.902472 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:40:18.629902 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:40:20.257237 140437341357888 submission_runner.py:411] Time since start: 7661.81s, 	Step: 16096, 	{'train/accuracy': 0.5531249642372131, 'train/loss': 1.9234681129455566, 'validation/accuracy': 0.5004400014877319, 'validation/loss': 2.1823103427886963, 'validation/num_examples': 50000, 'test/accuracy': 0.3912000060081482, 'test/loss': 2.838825225830078, 'test/num_examples': 10000, 'score': 7184.445158958435, 'total_duration': 7661.808724164963, 'accumulated_submission_time': 7184.445158958435, 'accumulated_eval_time': 475.9171495437622, 'accumulated_logging_time': 0.5414671897888184}
I0302 13:40:20.278448 140239850956544 logging_writer.py:48] [16096] accumulated_eval_time=475.917150, accumulated_logging_time=0.541467, accumulated_submission_time=7184.445159, global_step=16096, preemption_count=0, score=7184.445159, test/accuracy=0.391200, test/loss=2.838825, test/num_examples=10000, total_duration=7661.808724, train/accuracy=0.553125, train/loss=1.923468, validation/accuracy=0.500440, validation/loss=2.182310, validation/num_examples=50000
I0302 13:40:22.269896 140239842563840 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.7839321494102478, loss=4.5835466384887695
I0302 13:41:03.412946 140239850956544 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.8851370215415955, loss=4.511744499206543
I0302 13:41:48.915118 140239842563840 logging_writer.py:48] [16300] global_step=16300, grad_norm=1.0721209049224854, loss=3.0678763389587402
I0302 13:42:34.206589 140239850956544 logging_writer.py:48] [16400] global_step=16400, grad_norm=1.3012875318527222, loss=3.0606184005737305
I0302 13:43:19.273702 140239842563840 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.898696780204773, loss=5.180576324462891
I0302 13:44:04.547268 140239850956544 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.9310175776481628, loss=3.350482940673828
I0302 13:44:49.275913 140239842563840 logging_writer.py:48] [16700] global_step=16700, grad_norm=1.0689146518707275, loss=3.123728036880493
I0302 13:45:34.570272 140239850956544 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.848116934299469, loss=4.711905002593994
I0302 13:46:19.832671 140239842563840 logging_writer.py:48] [16900] global_step=16900, grad_norm=1.0370092391967773, loss=3.664203643798828
I0302 13:47:05.498830 140239850956544 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.1332365274429321, loss=3.6861660480499268
I0302 13:47:20.444962 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:47:34.320423 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:47:48.859620 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:47:50.480350 140437341357888 submission_runner.py:411] Time since start: 8112.03s, 	Step: 17035, 	{'train/accuracy': 0.5389062166213989, 'train/loss': 2.0137147903442383, 'validation/accuracy': 0.5019400119781494, 'validation/loss': 2.185546398162842, 'validation/num_examples': 50000, 'test/accuracy': 0.3888000249862671, 'test/loss': 2.8619396686553955, 'test/num_examples': 10000, 'score': 7604.548624038696, 'total_duration': 8112.031835079193, 'accumulated_submission_time': 7604.548624038696, 'accumulated_eval_time': 505.95252656936646, 'accumulated_logging_time': 0.5746691226959229}
I0302 13:47:50.504835 140239842563840 logging_writer.py:48] [17035] accumulated_eval_time=505.952527, accumulated_logging_time=0.574669, accumulated_submission_time=7604.548624, global_step=17035, preemption_count=0, score=7604.548624, test/accuracy=0.388800, test/loss=2.861940, test/num_examples=10000, total_duration=8112.031835, train/accuracy=0.538906, train/loss=2.013715, validation/accuracy=0.501940, validation/loss=2.185546, validation/num_examples=50000
I0302 13:48:16.684433 140239850956544 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.9933336973190308, loss=2.935112953186035
I0302 13:49:00.510067 140239842563840 logging_writer.py:48] [17200] global_step=17200, grad_norm=1.1242867708206177, loss=2.8299100399017334
I0302 13:49:45.111131 140239850956544 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.9681901335716248, loss=5.093947410583496
I0302 13:50:30.087850 140239842563840 logging_writer.py:48] [17400] global_step=17400, grad_norm=1.0601589679718018, loss=4.529597282409668
I0302 13:51:15.535836 140239850956544 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.9120472073554993, loss=3.76501727104187
I0302 13:52:00.709082 140239842563840 logging_writer.py:48] [17600] global_step=17600, grad_norm=1.0623114109039307, loss=3.141624927520752
I0302 13:52:45.844569 140239850956544 logging_writer.py:48] [17700] global_step=17700, grad_norm=1.0648502111434937, loss=2.870023250579834
I0302 13:53:31.066978 140239842563840 logging_writer.py:48] [17800] global_step=17800, grad_norm=1.0287630558013916, loss=2.9434187412261963
I0302 13:54:16.140211 140239850956544 logging_writer.py:48] [17900] global_step=17900, grad_norm=1.087275505065918, loss=2.9466376304626465
I0302 13:54:50.908707 140437341357888 spec.py:321] Evaluating on the training split.
I0302 13:55:05.332469 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 13:55:19.721244 140437341357888 spec.py:349] Evaluating on the test split.
I0302 13:55:21.363306 140437341357888 submission_runner.py:411] Time since start: 8562.91s, 	Step: 17979, 	{'train/accuracy': 0.5502538681030273, 'train/loss': 1.9661774635314941, 'validation/accuracy': 0.5148800015449524, 'validation/loss': 2.137053966522217, 'validation/num_examples': 50000, 'test/accuracy': 0.403300017118454, 'test/loss': 2.80226469039917, 'test/num_examples': 10000, 'score': 8024.889421463013, 'total_duration': 8562.914777040482, 'accumulated_submission_time': 8024.889421463013, 'accumulated_eval_time': 536.4071035385132, 'accumulated_logging_time': 0.6097869873046875}
I0302 13:55:21.383875 140239842563840 logging_writer.py:48] [17979] accumulated_eval_time=536.407104, accumulated_logging_time=0.609787, accumulated_submission_time=8024.889421, global_step=17979, preemption_count=0, score=8024.889421, test/accuracy=0.403300, test/loss=2.802265, test/num_examples=10000, total_duration=8562.914777, train/accuracy=0.550254, train/loss=1.966177, validation/accuracy=0.514880, validation/loss=2.137054, validation/num_examples=50000
I0302 13:55:30.116987 140239850956544 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.7923965454101562, loss=5.403167724609375
I0302 13:56:12.164414 140239842563840 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.999980628490448, loss=3.4063916206359863
I0302 13:56:57.308402 140239850956544 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.8323512077331543, loss=4.555857181549072
I0302 13:57:42.210959 140239842563840 logging_writer.py:48] [18300] global_step=18300, grad_norm=1.0824317932128906, loss=2.9259915351867676
I0302 13:58:27.395762 140239850956544 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.9402858018875122, loss=4.03543758392334
I0302 13:59:12.197268 140239842563840 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.258385181427002, loss=3.0267860889434814
I0302 13:59:57.141072 140239850956544 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.902988612651825, loss=3.920058488845825
I0302 14:00:42.275352 140239842563840 logging_writer.py:48] [18700] global_step=18700, grad_norm=1.1743608713150024, loss=2.9478461742401123
I0302 14:01:27.605530 140239850956544 logging_writer.py:48] [18800] global_step=18800, grad_norm=1.0659065246582031, loss=2.9471323490142822
I0302 14:02:12.656987 140239842563840 logging_writer.py:48] [18900] global_step=18900, grad_norm=1.0451411008834839, loss=2.8466315269470215
I0302 14:02:21.688888 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:02:34.857304 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:02:50.877242 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:02:52.495745 140437341357888 submission_runner.py:411] Time since start: 9014.05s, 	Step: 18922, 	{'train/accuracy': 0.5723046660423279, 'train/loss': 1.7916992902755737, 'validation/accuracy': 0.5268599987030029, 'validation/loss': 2.0302014350891113, 'validation/num_examples': 50000, 'test/accuracy': 0.40700000524520874, 'test/loss': 2.7275853157043457, 'test/num_examples': 10000, 'score': 8445.13327217102, 'total_duration': 9014.047230482101, 'accumulated_submission_time': 8445.13327217102, 'accumulated_eval_time': 567.2139377593994, 'accumulated_logging_time': 0.6404788494110107}
I0302 14:02:52.517315 140239850956544 logging_writer.py:48] [18922] accumulated_eval_time=567.213938, accumulated_logging_time=0.640479, accumulated_submission_time=8445.133272, global_step=18922, preemption_count=0, score=8445.133272, test/accuracy=0.407000, test/loss=2.727585, test/num_examples=10000, total_duration=9014.047230, train/accuracy=0.572305, train/loss=1.791699, validation/accuracy=0.526860, validation/loss=2.030201, validation/num_examples=50000
I0302 14:03:24.079264 140239842563840 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.9091652035713196, loss=4.279497146606445
I0302 14:04:09.032582 140239850956544 logging_writer.py:48] [19100] global_step=19100, grad_norm=1.0927963256835938, loss=2.9334003925323486
I0302 14:04:54.102054 140239842563840 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.9939299821853638, loss=5.162319660186768
I0302 14:05:39.172747 140239850956544 logging_writer.py:48] [19300] global_step=19300, grad_norm=1.259743332862854, loss=2.8156862258911133
I0302 14:06:24.375383 140239842563840 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.9161642789840698, loss=4.711758136749268
I0302 14:07:09.670140 140239850956544 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.032944917678833, loss=2.969292640686035
I0302 14:07:54.674574 140239842563840 logging_writer.py:48] [19600] global_step=19600, grad_norm=1.1896436214447021, loss=2.8519206047058105
I0302 14:08:39.582072 140239850956544 logging_writer.py:48] [19700] global_step=19700, grad_norm=1.0825356245040894, loss=3.079136610031128
I0302 14:09:24.589562 140239842563840 logging_writer.py:48] [19800] global_step=19800, grad_norm=1.0654817819595337, loss=2.9214508533477783
I0302 14:09:52.793739 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:10:05.949628 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:10:21.432757 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:10:23.062389 140437341357888 submission_runner.py:411] Time since start: 9464.61s, 	Step: 19865, 	{'train/accuracy': 0.5950781106948853, 'train/loss': 1.7214692831039429, 'validation/accuracy': 0.5264599919319153, 'validation/loss': 2.04833984375, 'validation/num_examples': 50000, 'test/accuracy': 0.41440001130104065, 'test/loss': 2.6935672760009766, 'test/num_examples': 10000, 'score': 8865.34806394577, 'total_duration': 9464.613876342773, 'accumulated_submission_time': 8865.34806394577, 'accumulated_eval_time': 597.48259973526, 'accumulated_logging_time': 0.6718833446502686}
I0302 14:10:23.086675 140239850956544 logging_writer.py:48] [19865] accumulated_eval_time=597.482600, accumulated_logging_time=0.671883, accumulated_submission_time=8865.348064, global_step=19865, preemption_count=0, score=8865.348064, test/accuracy=0.414400, test/loss=2.693567, test/num_examples=10000, total_duration=9464.613876, train/accuracy=0.595078, train/loss=1.721469, validation/accuracy=0.526460, validation/loss=2.048340, validation/num_examples=50000
I0302 14:10:37.402470 140239842563840 logging_writer.py:48] [19900] global_step=19900, grad_norm=1.193687915802002, loss=2.8366241455078125
I0302 14:11:20.024392 140239850956544 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.9957329630851746, loss=2.8201563358306885
I0302 14:12:05.218906 140239842563840 logging_writer.py:48] [20100] global_step=20100, grad_norm=1.1838643550872803, loss=2.830533027648926
I0302 14:12:49.827867 140239850956544 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.8326639533042908, loss=4.24080753326416
I0302 14:13:34.906360 140239842563840 logging_writer.py:48] [20300] global_step=20300, grad_norm=1.1456271409988403, loss=2.7550413608551025
I0302 14:14:19.917459 140239850956544 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.9828786849975586, loss=3.0401549339294434
I0302 14:15:05.006560 140239842563840 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.8297384977340698, loss=5.4743733406066895
I0302 14:15:50.074240 140239850956544 logging_writer.py:48] [20600] global_step=20600, grad_norm=1.1290078163146973, loss=3.024029493331909
I0302 14:16:35.254298 140239842563840 logging_writer.py:48] [20700] global_step=20700, grad_norm=1.2210410833358765, loss=2.8737566471099854
I0302 14:17:20.298271 140239850956544 logging_writer.py:48] [20800] global_step=20800, grad_norm=1.0232242345809937, loss=3.018874168395996
I0302 14:17:23.090239 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:17:36.302014 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:17:53.068979 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:17:54.698786 140437341357888 submission_runner.py:411] Time since start: 9916.25s, 	Step: 20808, 	{'train/accuracy': 0.5799609422683716, 'train/loss': 1.7857638597488403, 'validation/accuracy': 0.5396199822425842, 'validation/loss': 1.978995442390442, 'validation/num_examples': 50000, 'test/accuracy': 0.4191000163555145, 'test/loss': 2.663177728652954, 'test/num_examples': 10000, 'score': 9285.290144205093, 'total_duration': 9916.250267505646, 'accumulated_submission_time': 9285.290144205093, 'accumulated_eval_time': 629.0911407470703, 'accumulated_logging_time': 0.7059800624847412}
I0302 14:17:54.726763 140239842563840 logging_writer.py:48] [20808] accumulated_eval_time=629.091141, accumulated_logging_time=0.705980, accumulated_submission_time=9285.290144, global_step=20808, preemption_count=0, score=9285.290144, test/accuracy=0.419100, test/loss=2.663178, test/num_examples=10000, total_duration=9916.250268, train/accuracy=0.579961, train/loss=1.785764, validation/accuracy=0.539620, validation/loss=1.978995, validation/num_examples=50000
I0302 14:18:32.223860 140239850956544 logging_writer.py:48] [20900] global_step=20900, grad_norm=1.3664186000823975, loss=2.8227286338806152
I0302 14:19:16.925083 140239842563840 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.241054892539978, loss=2.8910539150238037
I0302 14:20:01.272144 140239850956544 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.8910431861877441, loss=3.6503543853759766
I0302 14:20:46.369654 140239842563840 logging_writer.py:48] [21200] global_step=21200, grad_norm=1.1211836338043213, loss=2.9561214447021484
I0302 14:21:32.146318 140239850956544 logging_writer.py:48] [21300] global_step=21300, grad_norm=1.104905366897583, loss=2.954920768737793
I0302 14:22:17.603561 140239842563840 logging_writer.py:48] [21400] global_step=21400, grad_norm=1.0365545749664307, loss=5.385592937469482
I0302 14:23:02.678887 140239850956544 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.1207855939865112, loss=2.9336366653442383
I0302 14:23:47.799333 140239842563840 logging_writer.py:48] [21600] global_step=21600, grad_norm=1.167428731918335, loss=2.9196391105651855
I0302 14:24:33.034204 140239850956544 logging_writer.py:48] [21700] global_step=21700, grad_norm=1.1192835569381714, loss=3.0004892349243164
I0302 14:24:55.050298 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:25:08.880768 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:25:24.013118 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:25:25.662882 140437341357888 submission_runner.py:411] Time since start: 10367.21s, 	Step: 21750, 	{'train/accuracy': 0.5848437547683716, 'train/loss': 1.772911548614502, 'validation/accuracy': 0.5408999919891357, 'validation/loss': 1.9920196533203125, 'validation/num_examples': 50000, 'test/accuracy': 0.4229000210762024, 'test/loss': 2.649247407913208, 'test/num_examples': 10000, 'score': 9705.551045656204, 'total_duration': 10367.21435379982, 'accumulated_submission_time': 9705.551045656204, 'accumulated_eval_time': 659.7037007808685, 'accumulated_logging_time': 0.7450652122497559}
I0302 14:25:25.686754 140239842563840 logging_writer.py:48] [21750] accumulated_eval_time=659.703701, accumulated_logging_time=0.745065, accumulated_submission_time=9705.551046, global_step=21750, preemption_count=0, score=9705.551046, test/accuracy=0.422900, test/loss=2.649247, test/num_examples=10000, total_duration=10367.214354, train/accuracy=0.584844, train/loss=1.772912, validation/accuracy=0.540900, validation/loss=1.992020, validation/num_examples=50000
I0302 14:25:45.951188 140239850956544 logging_writer.py:48] [21800] global_step=21800, grad_norm=1.1823008060455322, loss=2.8130760192871094
I0302 14:26:29.747727 140239842563840 logging_writer.py:48] [21900] global_step=21900, grad_norm=1.0511163473129272, loss=2.766608238220215
I0302 14:27:15.146648 140239850956544 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.2090263366699219, loss=2.819352388381958
I0302 14:28:00.070278 140239842563840 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.8809207677841187, loss=5.2549872398376465
I0302 14:28:45.468796 140239850956544 logging_writer.py:48] [22200] global_step=22200, grad_norm=1.0616259574890137, loss=2.8877100944519043
I0302 14:29:30.521801 140239842563840 logging_writer.py:48] [22300] global_step=22300, grad_norm=1.2235665321350098, loss=2.6486191749572754
I0302 14:30:15.751677 140239850956544 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.9341937303543091, loss=5.504859924316406
I0302 14:31:01.176962 140239842563840 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.884852409362793, loss=4.894181728363037
I0302 14:31:46.404362 140239850956544 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.9679498076438904, loss=5.37467098236084
I0302 14:32:26.002449 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:32:35.582944 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:32:54.212429 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:32:55.838263 140437341357888 submission_runner.py:411] Time since start: 10817.39s, 	Step: 22689, 	{'train/accuracy': 0.5935742259025574, 'train/loss': 1.716032862663269, 'validation/accuracy': 0.5404399633407593, 'validation/loss': 1.9941846132278442, 'validation/num_examples': 50000, 'test/accuracy': 0.4222000241279602, 'test/loss': 2.663605213165283, 'test/num_examples': 10000, 'score': 10125.80424952507, 'total_duration': 10817.389746904373, 'accumulated_submission_time': 10125.80424952507, 'accumulated_eval_time': 689.5395059585571, 'accumulated_logging_time': 0.7798676490783691}
I0302 14:32:55.861067 140239842563840 logging_writer.py:48] [22689] accumulated_eval_time=689.539506, accumulated_logging_time=0.779868, accumulated_submission_time=10125.804250, global_step=22689, preemption_count=0, score=10125.804250, test/accuracy=0.422200, test/loss=2.663605, test/num_examples=10000, total_duration=10817.389747, train/accuracy=0.593574, train/loss=1.716033, validation/accuracy=0.540440, validation/loss=1.994185, validation/num_examples=50000
I0302 14:33:00.641637 140239850956544 logging_writer.py:48] [22700] global_step=22700, grad_norm=1.1728626489639282, loss=2.8096845149993896
I0302 14:33:40.879846 140239842563840 logging_writer.py:48] [22800] global_step=22800, grad_norm=1.1306227445602417, loss=3.062854766845703
I0302 14:34:26.049319 140239850956544 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.9887314438819885, loss=2.815887451171875
I0302 14:35:11.179851 140239842563840 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.9146830439567566, loss=5.382688999176025
I0302 14:35:56.483783 140239850956544 logging_writer.py:48] [23100] global_step=23100, grad_norm=1.076876163482666, loss=2.678382635116577
I0302 14:36:41.940670 140239842563840 logging_writer.py:48] [23200] global_step=23200, grad_norm=1.060124397277832, loss=2.5301527976989746
I0302 14:37:27.447790 140239850956544 logging_writer.py:48] [23300] global_step=23300, grad_norm=1.1381627321243286, loss=2.6171646118164062
I0302 14:38:12.812656 140239842563840 logging_writer.py:48] [23400] global_step=23400, grad_norm=1.0307146310806274, loss=5.293744087219238
I0302 14:38:57.982162 140239850956544 logging_writer.py:48] [23500] global_step=23500, grad_norm=1.1570898294448853, loss=3.02357816696167
I0302 14:39:43.513310 140239842563840 logging_writer.py:48] [23600] global_step=23600, grad_norm=1.216748833656311, loss=2.6983094215393066
I0302 14:39:55.915509 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:40:05.712424 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:40:29.416568 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:40:31.025905 140437341357888 submission_runner.py:411] Time since start: 11272.58s, 	Step: 23629, 	{'train/accuracy': 0.5935351252555847, 'train/loss': 1.7091354131698608, 'validation/accuracy': 0.5555399656295776, 'validation/loss': 1.896039366722107, 'validation/num_examples': 50000, 'test/accuracy': 0.4326000213623047, 'test/loss': 2.574949026107788, 'test/num_examples': 10000, 'score': 10545.795673847198, 'total_duration': 11272.577404022217, 'accumulated_submission_time': 10545.795673847198, 'accumulated_eval_time': 724.6498851776123, 'accumulated_logging_time': 0.8144900798797607}
I0302 14:40:31.051593 140239850956544 logging_writer.py:48] [23629] accumulated_eval_time=724.649885, accumulated_logging_time=0.814490, accumulated_submission_time=10545.795674, global_step=23629, preemption_count=0, score=10545.795674, test/accuracy=0.432600, test/loss=2.574949, test/num_examples=10000, total_duration=11272.577404, train/accuracy=0.593535, train/loss=1.709135, validation/accuracy=0.555540, validation/loss=1.896039, validation/num_examples=50000
I0302 14:40:59.595579 140239842563840 logging_writer.py:48] [23700] global_step=23700, grad_norm=1.1413803100585938, loss=3.4358718395233154
I0302 14:41:42.123779 140239850956544 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.9294666051864624, loss=4.474648475646973
I0302 14:42:27.071951 140239842563840 logging_writer.py:48] [23900] global_step=23900, grad_norm=1.0279099941253662, loss=2.97511887550354
I0302 14:43:12.142762 140239850956544 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.8236515522003174, loss=4.581740379333496
I0302 14:43:57.043578 140239842563840 logging_writer.py:48] [24100] global_step=24100, grad_norm=1.0748237371444702, loss=3.597317934036255
I0302 14:44:42.018973 140239850956544 logging_writer.py:48] [24200] global_step=24200, grad_norm=1.0552808046340942, loss=2.7665302753448486
I0302 14:45:27.193649 140239842563840 logging_writer.py:48] [24300] global_step=24300, grad_norm=1.0041762590408325, loss=2.8626248836517334
I0302 14:46:12.180088 140239850956544 logging_writer.py:48] [24400] global_step=24400, grad_norm=1.2033324241638184, loss=2.8028411865234375
I0302 14:46:57.309551 140239842563840 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.2044622898101807, loss=2.6278252601623535
I0302 14:47:31.463503 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:47:41.060503 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:48:02.078014 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:48:03.727969 140437341357888 submission_runner.py:411] Time since start: 11725.28s, 	Step: 24578, 	{'train/accuracy': 0.5988476276397705, 'train/loss': 1.6850430965423584, 'validation/accuracy': 0.5579400062561035, 'validation/loss': 1.8976974487304688, 'validation/num_examples': 50000, 'test/accuracy': 0.4345000088214874, 'test/loss': 2.592747926712036, 'test/num_examples': 10000, 'score': 10966.144136667252, 'total_duration': 11725.279448986053, 'accumulated_submission_time': 10966.144136667252, 'accumulated_eval_time': 756.9143693447113, 'accumulated_logging_time': 0.8506224155426025}
I0302 14:48:03.752470 140239850956544 logging_writer.py:48] [24578] accumulated_eval_time=756.914369, accumulated_logging_time=0.850622, accumulated_submission_time=10966.144137, global_step=24578, preemption_count=0, score=10966.144137, test/accuracy=0.434500, test/loss=2.592748, test/num_examples=10000, total_duration=11725.279449, train/accuracy=0.598848, train/loss=1.685043, validation/accuracy=0.557940, validation/loss=1.897697, validation/num_examples=50000
I0302 14:48:12.888817 140239842563840 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.9133098721504211, loss=4.082695007324219
I0302 14:48:53.158563 140239850956544 logging_writer.py:48] [24700] global_step=24700, grad_norm=1.0801687240600586, loss=3.2416629791259766
I0302 14:49:37.505777 140239842563840 logging_writer.py:48] [24800] global_step=24800, grad_norm=1.068358302116394, loss=2.918471336364746
I0302 14:50:22.477542 140239850956544 logging_writer.py:48] [24900] global_step=24900, grad_norm=1.1960231065750122, loss=2.593912124633789
I0302 14:51:07.561508 140239842563840 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.9772937893867493, loss=3.085703134536743
I0302 14:51:53.204631 140239850956544 logging_writer.py:48] [25100] global_step=25100, grad_norm=1.1446192264556885, loss=2.6612799167633057
I0302 14:52:38.556268 140239842563840 logging_writer.py:48] [25200] global_step=25200, grad_norm=1.1322388648986816, loss=2.7735543251037598
I0302 14:53:24.101296 140239850956544 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.8416191339492798, loss=4.33247184753418
I0302 14:54:08.861235 140239842563840 logging_writer.py:48] [25400] global_step=25400, grad_norm=1.0028356313705444, loss=5.207640171051025
I0302 14:54:53.855191 140239850956544 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.9573014974594116, loss=5.116683006286621
I0302 14:55:04.026577 140437341357888 spec.py:321] Evaluating on the training split.
I0302 14:55:14.158172 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 14:55:33.957503 140437341357888 spec.py:349] Evaluating on the test split.
I0302 14:55:35.585716 140437341357888 submission_runner.py:411] Time since start: 12177.14s, 	Step: 25524, 	{'train/accuracy': 0.6112499833106995, 'train/loss': 1.6054291725158691, 'validation/accuracy': 0.5604999661445618, 'validation/loss': 1.8555995225906372, 'validation/num_examples': 50000, 'test/accuracy': 0.4425000250339508, 'test/loss': 2.5231847763061523, 'test/num_examples': 10000, 'score': 11386.355078458786, 'total_duration': 12177.137206077576, 'accumulated_submission_time': 11386.355078458786, 'accumulated_eval_time': 788.4734981060028, 'accumulated_logging_time': 0.8868091106414795}
I0302 14:55:35.609370 140239842563840 logging_writer.py:48] [25524] accumulated_eval_time=788.473498, accumulated_logging_time=0.886809, accumulated_submission_time=11386.355078, global_step=25524, preemption_count=0, score=11386.355078, test/accuracy=0.442500, test/loss=2.523185, test/num_examples=10000, total_duration=12177.137206, train/accuracy=0.611250, train/loss=1.605429, validation/accuracy=0.560500, validation/loss=1.855600, validation/num_examples=50000
I0302 14:56:07.461955 140239850956544 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.9255965352058411, loss=3.4167652130126953
I0302 14:56:52.523049 140239842563840 logging_writer.py:48] [25700] global_step=25700, grad_norm=1.1681171655654907, loss=2.768120765686035
I0302 14:57:37.779532 140239850956544 logging_writer.py:48] [25800] global_step=25800, grad_norm=1.1995187997817993, loss=2.7709898948669434
I0302 14:58:22.645279 140239842563840 logging_writer.py:48] [25900] global_step=25900, grad_norm=1.2317159175872803, loss=2.6852822303771973
I0302 14:59:07.749429 140239850956544 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.9994193911552429, loss=4.581423282623291
I0302 14:59:52.561353 140239842563840 logging_writer.py:48] [26100] global_step=26100, grad_norm=1.2335211038589478, loss=2.8524396419525146
I0302 15:00:37.590297 140239850956544 logging_writer.py:48] [26200] global_step=26200, grad_norm=1.0277470350265503, loss=4.968560218811035
I0302 15:01:22.915729 140239842563840 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.9959285855293274, loss=3.7410192489624023
I0302 15:02:08.091376 140239850956544 logging_writer.py:48] [26400] global_step=26400, grad_norm=1.0349431037902832, loss=4.629692077636719
I0302 15:02:35.743932 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:02:45.897809 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:03:05.815057 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:03:07.471825 140437341357888 submission_runner.py:411] Time since start: 12629.02s, 	Step: 26463, 	{'train/accuracy': 0.6207422018051147, 'train/loss': 1.6242880821228027, 'validation/accuracy': 0.5597000122070312, 'validation/loss': 1.9110122919082642, 'validation/num_examples': 50000, 'test/accuracy': 0.443200021982193, 'test/loss': 2.5797505378723145, 'test/num_examples': 10000, 'score': 11805.259394168854, 'total_duration': 12629.023286819458, 'accumulated_submission_time': 11805.259394168854, 'accumulated_eval_time': 820.2013580799103, 'accumulated_logging_time': 2.0886545181274414}
I0302 15:03:07.497276 140239842563840 logging_writer.py:48] [26463] accumulated_eval_time=820.201358, accumulated_logging_time=2.088655, accumulated_submission_time=11805.259394, global_step=26463, preemption_count=0, score=11805.259394, test/accuracy=0.443200, test/loss=2.579751, test/num_examples=10000, total_duration=12629.023287, train/accuracy=0.620742, train/loss=1.624288, validation/accuracy=0.559700, validation/loss=1.911012, validation/num_examples=50000
I0302 15:03:22.607373 140239850956544 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.9973542094230652, loss=5.116875171661377
I0302 15:04:04.964009 140239842563840 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.9284414649009705, loss=4.303155899047852
I0302 15:04:50.210526 140239850956544 logging_writer.py:48] [26700] global_step=26700, grad_norm=1.0963877439498901, loss=2.7300925254821777
I0302 15:05:35.329101 140239842563840 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.9601930975914001, loss=4.700165748596191
I0302 15:06:20.726557 140239850956544 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.901665210723877, loss=4.463224411010742
I0302 15:07:06.002024 140239842563840 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.183577060699463, loss=2.4966139793395996
I0302 15:07:51.007870 140239850956544 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.980872631072998, loss=5.22531795501709
I0302 15:08:36.102973 140239842563840 logging_writer.py:48] [27200] global_step=27200, grad_norm=1.15413236618042, loss=2.6575958728790283
I0302 15:09:21.208504 140239850956544 logging_writer.py:48] [27300] global_step=27300, grad_norm=1.1587013006210327, loss=2.7382259368896484
I0302 15:10:06.478737 140239842563840 logging_writer.py:48] [27400] global_step=27400, grad_norm=1.1714937686920166, loss=2.6132023334503174
I0302 15:10:07.505805 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:10:17.526467 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:10:36.792086 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:10:38.424301 140437341357888 submission_runner.py:411] Time since start: 13079.98s, 	Step: 27404, 	{'train/accuracy': 0.6065429449081421, 'train/loss': 1.6465208530426025, 'validation/accuracy': 0.5616399645805359, 'validation/loss': 1.8516168594360352, 'validation/num_examples': 50000, 'test/accuracy': 0.4491000175476074, 'test/loss': 2.521052837371826, 'test/num_examples': 10000, 'score': 12225.197360038757, 'total_duration': 13079.97579050064, 'accumulated_submission_time': 12225.197360038757, 'accumulated_eval_time': 851.1198291778564, 'accumulated_logging_time': 2.133695363998413}
I0302 15:10:38.447341 140239850956544 logging_writer.py:48] [27404] accumulated_eval_time=851.119829, accumulated_logging_time=2.133695, accumulated_submission_time=12225.197360, global_step=27404, preemption_count=0, score=12225.197360, test/accuracy=0.449100, test/loss=2.521053, test/num_examples=10000, total_duration=13079.975791, train/accuracy=0.606543, train/loss=1.646521, validation/accuracy=0.561640, validation/loss=1.851617, validation/num_examples=50000
I0302 15:11:18.714226 140239842563840 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.9477047920227051, loss=4.666382789611816
I0302 15:12:04.268369 140239850956544 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.8499542474746704, loss=4.246584892272949
I0302 15:12:49.536930 140239842563840 logging_writer.py:48] [27700] global_step=27700, grad_norm=1.1710001230239868, loss=2.645007610321045
I0302 15:13:34.619261 140239850956544 logging_writer.py:48] [27800] global_step=27800, grad_norm=1.2120583057403564, loss=2.799588680267334
I0302 15:14:19.839128 140239842563840 logging_writer.py:48] [27900] global_step=27900, grad_norm=1.1407010555267334, loss=2.6766936779022217
I0302 15:15:04.958343 140239850956544 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.136244297027588, loss=2.662482261657715
I0302 15:15:49.956685 140239842563840 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.9619181752204895, loss=4.697600364685059
I0302 15:16:35.255813 140239850956544 logging_writer.py:48] [28200] global_step=28200, grad_norm=1.2218270301818848, loss=2.5069472789764404
I0302 15:17:20.578036 140239842563840 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.9406916499137878, loss=4.756241321563721
I0302 15:17:38.674542 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:17:48.939378 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:18:08.555748 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:18:10.175471 140437341357888 submission_runner.py:411] Time since start: 13531.73s, 	Step: 28342, 	{'train/accuracy': 0.6184960603713989, 'train/loss': 1.6287354230880737, 'validation/accuracy': 0.570580005645752, 'validation/loss': 1.852982759475708, 'validation/num_examples': 50000, 'test/accuracy': 0.4531000256538391, 'test/loss': 2.515817880630493, 'test/num_examples': 10000, 'score': 12645.363277673721, 'total_duration': 13531.726953268051, 'accumulated_submission_time': 12645.363277673721, 'accumulated_eval_time': 882.6207411289215, 'accumulated_logging_time': 2.1664159297943115}
I0302 15:18:10.199204 140239850956544 logging_writer.py:48] [28342] accumulated_eval_time=882.620741, accumulated_logging_time=2.166416, accumulated_submission_time=12645.363278, global_step=28342, preemption_count=0, score=12645.363278, test/accuracy=0.453100, test/loss=2.515818, test/num_examples=10000, total_duration=13531.726953, train/accuracy=0.618496, train/loss=1.628735, validation/accuracy=0.570580, validation/loss=1.852983, validation/num_examples=50000
I0302 15:18:33.646935 140239842563840 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.8952307105064392, loss=5.002823352813721
I0302 15:19:17.842136 140239850956544 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.1626343727111816, loss=2.6468448638916016
I0302 15:20:02.610322 140239842563840 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.8671450614929199, loss=4.542757987976074
I0302 15:20:47.622182 140239850956544 logging_writer.py:48] [28700] global_step=28700, grad_norm=1.1892404556274414, loss=2.618037223815918
I0302 15:21:33.157525 140239842563840 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.9631302356719971, loss=5.249551773071289
I0302 15:22:18.394887 140239850956544 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.9490781426429749, loss=5.275528430938721
I0302 15:23:03.673494 140239842563840 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.0013108253479004, loss=3.7135372161865234
I0302 15:23:48.751041 140239850956544 logging_writer.py:48] [29100] global_step=29100, grad_norm=1.0446090698242188, loss=3.439260482788086
I0302 15:24:34.094944 140239842563840 logging_writer.py:48] [29200] global_step=29200, grad_norm=1.107011318206787, loss=2.883532762527466
I0302 15:25:10.376081 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:25:20.228868 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:25:40.390221 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:25:42.018669 140437341357888 submission_runner.py:411] Time since start: 13983.57s, 	Step: 29282, 	{'train/accuracy': 0.6328710913658142, 'train/loss': 1.5523300170898438, 'validation/accuracy': 0.5777599811553955, 'validation/loss': 1.8129938840866089, 'validation/num_examples': 50000, 'test/accuracy': 0.4621000289916992, 'test/loss': 2.471017837524414, 'test/num_examples': 10000, 'score': 13065.477472305298, 'total_duration': 13983.570016145706, 'accumulated_submission_time': 13065.477472305298, 'accumulated_eval_time': 914.2631750106812, 'accumulated_logging_time': 2.201692819595337}
I0302 15:25:42.044128 140239850956544 logging_writer.py:48] [29282] accumulated_eval_time=914.263175, accumulated_logging_time=2.201693, accumulated_submission_time=13065.477472, global_step=29282, preemption_count=0, score=13065.477472, test/accuracy=0.462100, test/loss=2.471018, test/num_examples=10000, total_duration=13983.570016, train/accuracy=0.632871, train/loss=1.552330, validation/accuracy=0.577760, validation/loss=1.812994, validation/num_examples=50000
I0302 15:25:49.591784 140239842563840 logging_writer.py:48] [29300] global_step=29300, grad_norm=1.066640853881836, loss=2.881776809692383
I0302 15:26:31.554303 140239850956544 logging_writer.py:48] [29400] global_step=29400, grad_norm=1.0254937410354614, loss=2.60627818107605
I0302 15:27:16.849948 140239842563840 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.0095981359481812, loss=5.109978199005127
I0302 15:28:01.754958 140239850956544 logging_writer.py:48] [29600] global_step=29600, grad_norm=1.081327199935913, loss=2.563964605331421
I0302 15:28:47.058748 140239842563840 logging_writer.py:48] [29700] global_step=29700, grad_norm=1.10232412815094, loss=2.7643916606903076
I0302 15:29:31.970483 140239850956544 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.9574522972106934, loss=5.170029640197754
I0302 15:30:17.000656 140239842563840 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.9373944401741028, loss=4.3148016929626465
I0302 15:31:02.122807 140239850956544 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.222137689590454, loss=2.362239122390747
I0302 15:31:47.518284 140239842563840 logging_writer.py:48] [30100] global_step=30100, grad_norm=1.1049238443374634, loss=4.189970016479492
I0302 15:32:32.714513 140239850956544 logging_writer.py:48] [30200] global_step=30200, grad_norm=1.316367268562317, loss=2.6365671157836914
I0302 15:32:42.370818 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:32:52.286564 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:33:11.805412 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:33:13.434437 140437341357888 submission_runner.py:411] Time since start: 14434.99s, 	Step: 30223, 	{'train/accuracy': 0.6181054711341858, 'train/loss': 1.5981839895248413, 'validation/accuracy': 0.5783399939537048, 'validation/loss': 1.7888963222503662, 'validation/num_examples': 50000, 'test/accuracy': 0.46150001883506775, 'test/loss': 2.451876163482666, 'test/num_examples': 10000, 'score': 13485.7399559021, 'total_duration': 14434.98591184616, 'accumulated_submission_time': 13485.7399559021, 'accumulated_eval_time': 945.3267643451691, 'accumulated_logging_time': 2.239365339279175}
I0302 15:33:13.458840 140239842563840 logging_writer.py:48] [30223] accumulated_eval_time=945.326764, accumulated_logging_time=2.239365, accumulated_submission_time=13485.739956, global_step=30223, preemption_count=0, score=13485.739956, test/accuracy=0.461500, test/loss=2.451876, test/num_examples=10000, total_duration=14434.985912, train/accuracy=0.618105, train/loss=1.598184, validation/accuracy=0.578340, validation/loss=1.788896, validation/num_examples=50000
I0302 15:33:44.390852 140239850956544 logging_writer.py:48] [30300] global_step=30300, grad_norm=1.0881783962249756, loss=5.207426071166992
I0302 15:34:29.373292 140239842563840 logging_writer.py:48] [30400] global_step=30400, grad_norm=1.2296853065490723, loss=2.6873703002929688
I0302 15:35:14.634905 140239850956544 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.100882887840271, loss=2.72638201713562
I0302 15:35:59.548414 140239842563840 logging_writer.py:48] [30600] global_step=30600, grad_norm=1.1559609174728394, loss=2.7878005504608154
I0302 15:36:44.671954 140239850956544 logging_writer.py:48] [30700] global_step=30700, grad_norm=1.0826810598373413, loss=2.646456718444824
I0302 15:37:29.887427 140239842563840 logging_writer.py:48] [30800] global_step=30800, grad_norm=1.2187132835388184, loss=2.831563949584961
I0302 15:38:15.075531 140239850956544 logging_writer.py:48] [30900] global_step=30900, grad_norm=1.1783943176269531, loss=2.6084823608398438
I0302 15:38:59.773560 140239842563840 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.124489188194275, loss=2.6756744384765625
I0302 15:39:44.642699 140239850956544 logging_writer.py:48] [31100] global_step=31100, grad_norm=1.1409066915512085, loss=4.9195451736450195
I0302 15:40:13.793825 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:40:23.667555 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:40:43.661229 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:40:45.282121 140437341357888 submission_runner.py:411] Time since start: 14886.83s, 	Step: 31166, 	{'train/accuracy': 0.6274218559265137, 'train/loss': 1.5659538507461548, 'validation/accuracy': 0.5806399583816528, 'validation/loss': 1.7789556980133057, 'validation/num_examples': 50000, 'test/accuracy': 0.4650000333786011, 'test/loss': 2.4483392238616943, 'test/num_examples': 10000, 'score': 13906.012647390366, 'total_duration': 14886.833595275879, 'accumulated_submission_time': 13906.012647390366, 'accumulated_eval_time': 976.8150374889374, 'accumulated_logging_time': 2.2749788761138916}
I0302 15:40:45.305813 140239842563840 logging_writer.py:48] [31166] accumulated_eval_time=976.815037, accumulated_logging_time=2.274979, accumulated_submission_time=13906.012647, global_step=31166, preemption_count=0, score=13906.012647, test/accuracy=0.465000, test/loss=2.448339, test/num_examples=10000, total_duration=14886.833595, train/accuracy=0.627422, train/loss=1.565954, validation/accuracy=0.580640, validation/loss=1.778956, validation/num_examples=50000
I0302 15:40:59.202577 140239850956544 logging_writer.py:48] [31200] global_step=31200, grad_norm=1.1182620525360107, loss=2.613276481628418
I0302 15:41:41.843753 140239842563840 logging_writer.py:48] [31300] global_step=31300, grad_norm=1.1603590250015259, loss=2.679255485534668
I0302 15:42:27.357348 140239850956544 logging_writer.py:48] [31400] global_step=31400, grad_norm=1.0414338111877441, loss=2.5488972663879395
I0302 15:43:12.420656 140239842563840 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.0798861980438232, loss=2.457066059112549
I0302 15:43:57.399105 140239850956544 logging_writer.py:48] [31600] global_step=31600, grad_norm=1.1139154434204102, loss=2.5651416778564453
I0302 15:44:42.795017 140239842563840 logging_writer.py:48] [31700] global_step=31700, grad_norm=1.0603443384170532, loss=2.7387804985046387
I0302 15:45:27.543093 140239850956544 logging_writer.py:48] [31800] global_step=31800, grad_norm=1.0977365970611572, loss=2.627817153930664
I0302 15:46:12.652062 140239842563840 logging_writer.py:48] [31900] global_step=31900, grad_norm=1.0545653104782104, loss=2.51179838180542
I0302 15:46:57.775338 140239850956544 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.1918290853500366, loss=2.7817628383636475
I0302 15:47:43.017681 140239842563840 logging_writer.py:48] [32100] global_step=32100, grad_norm=1.1470648050308228, loss=2.574885845184326
I0302 15:47:45.385526 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:47:55.355340 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:48:14.589646 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:48:16.205818 140437341357888 submission_runner.py:411] Time since start: 15337.76s, 	Step: 32107, 	{'train/accuracy': 0.635058581829071, 'train/loss': 1.529654622077942, 'validation/accuracy': 0.5848599672317505, 'validation/loss': 1.7706170082092285, 'validation/num_examples': 50000, 'test/accuracy': 0.4610000252723694, 'test/loss': 2.439715623855591, 'test/num_examples': 10000, 'score': 14326.030616283417, 'total_duration': 15337.757307052612, 'accumulated_submission_time': 14326.030616283417, 'accumulated_eval_time': 1007.635326385498, 'accumulated_logging_time': 2.308807134628296}
I0302 15:48:16.229974 140239850956544 logging_writer.py:48] [32107] accumulated_eval_time=1007.635326, accumulated_logging_time=2.308807, accumulated_submission_time=14326.030616, global_step=32107, preemption_count=0, score=14326.030616, test/accuracy=0.461000, test/loss=2.439716, test/num_examples=10000, total_duration=15337.757307, train/accuracy=0.635059, train/loss=1.529655, validation/accuracy=0.584860, validation/loss=1.770617, validation/num_examples=50000
I0302 15:48:54.285684 140239842563840 logging_writer.py:48] [32200] global_step=32200, grad_norm=1.1016924381256104, loss=4.466598033905029
I0302 15:49:39.190516 140239850956544 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.9923450350761414, loss=5.209224224090576
I0302 15:50:24.153308 140239842563840 logging_writer.py:48] [32400] global_step=32400, grad_norm=1.172567367553711, loss=2.5571885108947754
I0302 15:51:09.292196 140239850956544 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.0825810432434082, loss=2.7320454120635986
I0302 15:51:54.889442 140239842563840 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.9487117528915405, loss=3.8128461837768555
I0302 15:52:40.100658 140239850956544 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.9294931292533875, loss=3.5560660362243652
I0302 15:53:25.474329 140239842563840 logging_writer.py:48] [32800] global_step=32800, grad_norm=1.0097659826278687, loss=3.335050582885742
I0302 15:54:10.760414 140239850956544 logging_writer.py:48] [32900] global_step=32900, grad_norm=1.078520655632019, loss=4.993234634399414
I0302 15:54:55.777556 140239842563840 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.1055059432983398, loss=2.454970121383667
I0302 15:55:16.399130 140437341357888 spec.py:321] Evaluating on the training split.
I0302 15:55:26.530608 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 15:55:46.412741 140437341357888 spec.py:349] Evaluating on the test split.
I0302 15:55:48.044153 140437341357888 submission_runner.py:411] Time since start: 15789.60s, 	Step: 33047, 	{'train/accuracy': 0.64013671875, 'train/loss': 1.4978110790252686, 'validation/accuracy': 0.5824599862098694, 'validation/loss': 1.7634974718093872, 'validation/num_examples': 50000, 'test/accuracy': 0.46710002422332764, 'test/loss': 2.421347141265869, 'test/num_examples': 10000, 'score': 14746.13856124878, 'total_duration': 15789.595637083054, 'accumulated_submission_time': 14746.13856124878, 'accumulated_eval_time': 1039.280338525772, 'accumulated_logging_time': 2.342710018157959}
I0302 15:55:48.070567 140239850956544 logging_writer.py:48] [33047] accumulated_eval_time=1039.280339, accumulated_logging_time=2.342710, accumulated_submission_time=14746.138561, global_step=33047, preemption_count=0, score=14746.138561, test/accuracy=0.467100, test/loss=2.421347, test/num_examples=10000, total_duration=15789.595637, train/accuracy=0.640137, train/loss=1.497811, validation/accuracy=0.582460, validation/loss=1.763497, validation/num_examples=50000
I0302 15:56:09.509129 140239842563840 logging_writer.py:48] [33100] global_step=33100, grad_norm=1.0474176406860352, loss=3.331284761428833
I0302 15:56:53.087442 140239850956544 logging_writer.py:48] [33200] global_step=33200, grad_norm=1.100709319114685, loss=4.388920307159424
I0302 15:57:38.130830 140239842563840 logging_writer.py:48] [33300] global_step=33300, grad_norm=1.0715471506118774, loss=3.9217782020568848
I0302 15:58:23.073617 140239850956544 logging_writer.py:48] [33400] global_step=33400, grad_norm=1.2193126678466797, loss=2.7152934074401855
I0302 15:59:08.135719 140239842563840 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.0960865020751953, loss=2.978712797164917
I0302 15:59:53.084940 140239850956544 logging_writer.py:48] [33600] global_step=33600, grad_norm=1.269235610961914, loss=2.6812760829925537
I0302 16:00:38.192121 140239842563840 logging_writer.py:48] [33700] global_step=33700, grad_norm=1.2251057624816895, loss=2.5377044677734375
I0302 16:01:23.644944 140239850956544 logging_writer.py:48] [33800] global_step=33800, grad_norm=1.2261372804641724, loss=2.733696699142456
I0302 16:02:08.560766 140239842563840 logging_writer.py:48] [33900] global_step=33900, grad_norm=1.0934765338897705, loss=3.2538297176361084
I0302 16:02:48.180066 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:02:58.057944 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:03:16.906906 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:03:18.536233 140437341357888 submission_runner.py:411] Time since start: 16240.09s, 	Step: 33990, 	{'train/accuracy': 0.6319726705551147, 'train/loss': 1.5471922159194946, 'validation/accuracy': 0.5868399739265442, 'validation/loss': 1.755309820175171, 'validation/num_examples': 50000, 'test/accuracy': 0.46880000829696655, 'test/loss': 2.423509120941162, 'test/num_examples': 10000, 'score': 15166.186804294586, 'total_duration': 16240.087676048279, 'accumulated_submission_time': 15166.186804294586, 'accumulated_eval_time': 1069.6364603042603, 'accumulated_logging_time': 2.3791699409484863}
I0302 16:03:18.561530 140239850956544 logging_writer.py:48] [33990] accumulated_eval_time=1069.636460, accumulated_logging_time=2.379170, accumulated_submission_time=15166.186804, global_step=33990, preemption_count=0, score=15166.186804, test/accuracy=0.468800, test/loss=2.423509, test/num_examples=10000, total_duration=16240.087676, train/accuracy=0.631973, train/loss=1.547192, validation/accuracy=0.586840, validation/loss=1.755310, validation/num_examples=50000
I0302 16:03:22.941893 140239842563840 logging_writer.py:48] [34000] global_step=34000, grad_norm=1.2099709510803223, loss=2.584916353225708
I0302 16:04:04.502228 140239842563840 logging_writer.py:48] [34100] global_step=34100, grad_norm=1.3891881704330444, loss=2.5886995792388916
I0302 16:04:49.790410 140239850956544 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.9244019985198975, loss=4.159256458282471
I0302 16:05:34.978784 140239842563840 logging_writer.py:48] [34300] global_step=34300, grad_norm=1.136711597442627, loss=4.614588737487793
I0302 16:06:20.192149 140239850956544 logging_writer.py:48] [34400] global_step=34400, grad_norm=1.2024633884429932, loss=2.53035044670105
I0302 16:07:05.700612 140239842563840 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.1901869773864746, loss=4.957353591918945
I0302 16:07:50.830139 140239850956544 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.995688796043396, loss=4.115070819854736
I0302 16:08:35.973673 140239842563840 logging_writer.py:48] [34700] global_step=34700, grad_norm=1.1907716989517212, loss=2.8914172649383545
I0302 16:09:21.173837 140239850956544 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.989051103591919, loss=4.9778971672058105
I0302 16:10:06.285719 140239842563840 logging_writer.py:48] [34900] global_step=34900, grad_norm=1.1600642204284668, loss=2.6285479068756104
I0302 16:10:18.663286 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:10:28.796918 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:10:46.792448 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:10:48.423080 140437341357888 submission_runner.py:411] Time since start: 16689.97s, 	Step: 34929, 	{'train/accuracy': 0.641406238079071, 'train/loss': 1.4608179330825806, 'validation/accuracy': 0.5906999707221985, 'validation/loss': 1.7022159099578857, 'validation/num_examples': 50000, 'test/accuracy': 0.4708000123500824, 'test/loss': 2.3756675720214844, 'test/num_examples': 10000, 'score': 15586.226889133453, 'total_duration': 16689.974547863007, 'accumulated_submission_time': 15586.226889133453, 'accumulated_eval_time': 1099.3962256908417, 'accumulated_logging_time': 2.414524793624878}
I0302 16:10:48.452386 140239850956544 logging_writer.py:48] [34929] accumulated_eval_time=1099.396226, accumulated_logging_time=2.414525, accumulated_submission_time=15586.226889, global_step=34929, preemption_count=0, score=15586.226889, test/accuracy=0.470800, test/loss=2.375668, test/num_examples=10000, total_duration=16689.974548, train/accuracy=0.641406, train/loss=1.460818, validation/accuracy=0.590700, validation/loss=1.702216, validation/num_examples=50000
I0302 16:11:17.053790 140239842563840 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.1414028406143188, loss=2.4747166633605957
I0302 16:12:02.142388 140239850956544 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.9549746513366699, loss=5.048038482666016
I0302 16:12:47.385430 140239842563840 logging_writer.py:48] [35200] global_step=35200, grad_norm=1.11782705783844, loss=2.489670515060425
I0302 16:13:32.463507 140239850956544 logging_writer.py:48] [35300] global_step=35300, grad_norm=1.0653761625289917, loss=3.8300623893737793
I0302 16:14:17.683237 140239842563840 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.9236282706260681, loss=3.6911497116088867
I0302 16:15:02.935424 140239850956544 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.2268422842025757, loss=2.7763051986694336
I0302 16:15:48.242121 140239842563840 logging_writer.py:48] [35600] global_step=35600, grad_norm=1.1218161582946777, loss=2.526449203491211
I0302 16:16:33.567561 140239850956544 logging_writer.py:48] [35700] global_step=35700, grad_norm=1.11599600315094, loss=2.87338924407959
I0302 16:17:18.927517 140239842563840 logging_writer.py:48] [35800] global_step=35800, grad_norm=1.1939811706542969, loss=2.365281343460083
I0302 16:17:48.693646 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:17:58.699333 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:18:19.790629 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:18:21.423795 140437341357888 submission_runner.py:411] Time since start: 17142.98s, 	Step: 35868, 	{'train/accuracy': 0.6634570360183716, 'train/loss': 1.371727705001831, 'validation/accuracy': 0.5966399908065796, 'validation/loss': 1.6743971109390259, 'validation/num_examples': 50000, 'test/accuracy': 0.47370001673698425, 'test/loss': 2.3683242797851562, 'test/num_examples': 10000, 'score': 16006.404333353043, 'total_duration': 17142.975281000137, 'accumulated_submission_time': 16006.404333353043, 'accumulated_eval_time': 1132.126388311386, 'accumulated_logging_time': 2.4569034576416016}
I0302 16:18:21.449045 140239850956544 logging_writer.py:48] [35868] accumulated_eval_time=1132.126388, accumulated_logging_time=2.456903, accumulated_submission_time=16006.404333, global_step=35868, preemption_count=0, score=16006.404333, test/accuracy=0.473700, test/loss=2.368324, test/num_examples=10000, total_duration=17142.975281, train/accuracy=0.663457, train/loss=1.371728, validation/accuracy=0.596640, validation/loss=1.674397, validation/num_examples=50000
I0302 16:18:34.552032 140239842563840 logging_writer.py:48] [35900] global_step=35900, grad_norm=1.1937296390533447, loss=2.620570182800293
I0302 16:19:16.369471 140239850956544 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.2399308681488037, loss=2.6027603149414062
I0302 16:20:00.788141 140239842563840 logging_writer.py:48] [36100] global_step=36100, grad_norm=1.0847381353378296, loss=2.9248733520507812
I0302 16:20:46.250116 140239850956544 logging_writer.py:48] [36200] global_step=36200, grad_norm=1.0816718339920044, loss=2.4868240356445312
I0302 16:21:31.591178 140239842563840 logging_writer.py:48] [36300] global_step=36300, grad_norm=1.0299204587936401, loss=3.5606935024261475
I0302 16:22:16.957897 140239850956544 logging_writer.py:48] [36400] global_step=36400, grad_norm=0.9882290959358215, loss=2.995828628540039
I0302 16:23:01.933238 140239842563840 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.1370360851287842, loss=2.56319260597229
I0302 16:23:47.026556 140239850956544 logging_writer.py:48] [36600] global_step=36600, grad_norm=1.1200895309448242, loss=3.544158458709717
I0302 16:24:32.316188 140239842563840 logging_writer.py:48] [36700] global_step=36700, grad_norm=0.9228633642196655, loss=4.685475826263428
I0302 16:25:17.505108 140239850956544 logging_writer.py:48] [36800] global_step=36800, grad_norm=1.3152806758880615, loss=2.4341623783111572
I0302 16:25:21.667100 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:25:31.556683 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:25:51.561199 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:25:53.182554 140437341357888 submission_runner.py:411] Time since start: 17594.73s, 	Step: 36811, 	{'train/accuracy': 0.6385351419448853, 'train/loss': 1.4934431314468384, 'validation/accuracy': 0.5940399765968323, 'validation/loss': 1.706323266029358, 'validation/num_examples': 50000, 'test/accuracy': 0.4733000099658966, 'test/loss': 2.3658699989318848, 'test/num_examples': 10000, 'score': 16426.55730485916, 'total_duration': 17594.734039783478, 'accumulated_submission_time': 16426.55730485916, 'accumulated_eval_time': 1163.6418359279633, 'accumulated_logging_time': 2.4960789680480957}
I0302 16:25:53.207756 140239842563840 logging_writer.py:48] [36811] accumulated_eval_time=1163.641836, accumulated_logging_time=2.496079, accumulated_submission_time=16426.557305, global_step=36811, preemption_count=0, score=16426.557305, test/accuracy=0.473300, test/loss=2.365870, test/num_examples=10000, total_duration=17594.734040, train/accuracy=0.638535, train/loss=1.493443, validation/accuracy=0.594040, validation/loss=1.706323, validation/num_examples=50000
I0302 16:26:29.530436 140239850956544 logging_writer.py:48] [36900] global_step=36900, grad_norm=1.049863338470459, loss=2.7843565940856934
I0302 16:27:14.986877 140239842563840 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.1812336444854736, loss=2.5294277667999268
I0302 16:28:00.132543 140239850956544 logging_writer.py:48] [37100] global_step=37100, grad_norm=1.1091004610061646, loss=3.7778193950653076
I0302 16:28:45.703364 140239842563840 logging_writer.py:48] [37200] global_step=37200, grad_norm=0.9215076565742493, loss=5.046782493591309
I0302 16:29:31.081965 140239850956544 logging_writer.py:48] [37300] global_step=37300, grad_norm=1.1302666664123535, loss=2.7510313987731934
I0302 16:30:16.343275 140239842563840 logging_writer.py:48] [37400] global_step=37400, grad_norm=0.9913106560707092, loss=5.041555404663086
I0302 16:31:01.627800 140239850956544 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.0059477090835571, loss=4.63667631149292
I0302 16:31:47.057210 140239842563840 logging_writer.py:48] [37600] global_step=37600, grad_norm=1.2465298175811768, loss=2.4605984687805176
I0302 16:32:32.302693 140239850956544 logging_writer.py:48] [37700] global_step=37700, grad_norm=1.1791115999221802, loss=2.490394353866577
I0302 16:32:53.307818 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:33:03.509624 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:33:21.540949 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:33:23.171459 140437341357888 submission_runner.py:411] Time since start: 18044.72s, 	Step: 37748, 	{'train/accuracy': 0.641796886920929, 'train/loss': 1.4904508590698242, 'validation/accuracy': 0.5951799750328064, 'validation/loss': 1.7146835327148438, 'validation/num_examples': 50000, 'test/accuracy': 0.4742000102996826, 'test/loss': 2.3896632194519043, 'test/num_examples': 10000, 'score': 16846.59597182274, 'total_duration': 18044.722935914993, 'accumulated_submission_time': 16846.59597182274, 'accumulated_eval_time': 1193.5054569244385, 'accumulated_logging_time': 2.531633138656616}
I0302 16:33:23.201107 140239842563840 logging_writer.py:48] [37748] accumulated_eval_time=1193.505457, accumulated_logging_time=2.531633, accumulated_submission_time=16846.595972, global_step=37748, preemption_count=0, score=16846.595972, test/accuracy=0.474200, test/loss=2.389663, test/num_examples=10000, total_duration=18044.722936, train/accuracy=0.641797, train/loss=1.490451, validation/accuracy=0.595180, validation/loss=1.714684, validation/num_examples=50000
I0302 16:33:44.245818 140239850956544 logging_writer.py:48] [37800] global_step=37800, grad_norm=1.2473728656768799, loss=2.4847912788391113
I0302 16:34:28.444654 140239842563840 logging_writer.py:48] [37900] global_step=37900, grad_norm=1.0126779079437256, loss=3.265129566192627
I0302 16:35:13.800301 140239850956544 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.0467628240585327, loss=3.918238639831543
I0302 16:35:58.557755 140239842563840 logging_writer.py:48] [38100] global_step=38100, grad_norm=1.3120867013931274, loss=2.6312315464019775
I0302 16:36:43.820327 140239850956544 logging_writer.py:48] [38200] global_step=38200, grad_norm=1.1164500713348389, loss=4.975299835205078
I0302 16:37:28.735228 140239842563840 logging_writer.py:48] [38300] global_step=38300, grad_norm=1.0148411989212036, loss=4.734575271606445
I0302 16:38:14.140593 140239850956544 logging_writer.py:48] [38400] global_step=38400, grad_norm=1.1862537860870361, loss=2.4878714084625244
I0302 16:38:59.117485 140239842563840 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.170250415802002, loss=2.5962307453155518
I0302 16:39:44.364501 140239850956544 logging_writer.py:48] [38600] global_step=38600, grad_norm=1.0161265134811401, loss=3.8853940963745117
I0302 16:40:23.311414 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:40:33.278669 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:40:51.728869 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:40:53.353846 140437341357888 submission_runner.py:411] Time since start: 18494.91s, 	Step: 38688, 	{'train/accuracy': 0.6561914086341858, 'train/loss': 1.4135422706604004, 'validation/accuracy': 0.5982199907302856, 'validation/loss': 1.678788661956787, 'validation/num_examples': 50000, 'test/accuracy': 0.4707000255584717, 'test/loss': 2.3531055450439453, 'test/num_examples': 10000, 'score': 17266.64454650879, 'total_duration': 18494.905309677124, 'accumulated_submission_time': 17266.64454650879, 'accumulated_eval_time': 1223.5478613376617, 'accumulated_logging_time': 2.571526288986206}
I0302 16:40:53.384701 140239842563840 logging_writer.py:48] [38688] accumulated_eval_time=1223.547861, accumulated_logging_time=2.571526, accumulated_submission_time=17266.644547, global_step=38688, preemption_count=0, score=17266.644547, test/accuracy=0.470700, test/loss=2.353106, test/num_examples=10000, total_duration=18494.905310, train/accuracy=0.656191, train/loss=1.413542, validation/accuracy=0.598220, validation/loss=1.678789, validation/num_examples=50000
I0302 16:40:58.554944 140239850956544 logging_writer.py:48] [38700] global_step=38700, grad_norm=1.1369383335113525, loss=2.4397799968719482
I0302 16:41:40.444913 140239842563840 logging_writer.py:48] [38800] global_step=38800, grad_norm=1.0246694087982178, loss=3.1580018997192383
I0302 16:42:25.667916 140239850956544 logging_writer.py:48] [38900] global_step=38900, grad_norm=1.053343415260315, loss=2.838670015335083
I0302 16:43:10.709283 140239842563840 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.2802109718322754, loss=2.6247756481170654
I0302 16:43:55.704196 140239850956544 logging_writer.py:48] [39100] global_step=39100, grad_norm=1.0746681690216064, loss=3.484442710876465
I0302 16:44:40.871168 140239842563840 logging_writer.py:48] [39200] global_step=39200, grad_norm=1.317276954650879, loss=2.463784694671631
I0302 16:45:26.236784 140239850956544 logging_writer.py:48] [39300] global_step=39300, grad_norm=1.215761661529541, loss=2.495246171951294
I0302 16:46:11.406545 140239842563840 logging_writer.py:48] [39400] global_step=39400, grad_norm=1.1753066778182983, loss=5.068548679351807
I0302 16:46:56.805489 140239850956544 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.0656921863555908, loss=2.399190664291382
I0302 16:47:41.978863 140239842563840 logging_writer.py:48] [39600] global_step=39600, grad_norm=1.1953842639923096, loss=4.409199237823486
I0302 16:47:53.377084 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:48:03.389523 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:48:21.534116 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:48:23.153331 140437341357888 submission_runner.py:411] Time since start: 18944.70s, 	Step: 39627, 	{'train/accuracy': 0.6489648222923279, 'train/loss': 1.4219398498535156, 'validation/accuracy': 0.6005799770355225, 'validation/loss': 1.6512315273284912, 'validation/num_examples': 50000, 'test/accuracy': 0.4796000123023987, 'test/loss': 2.343630075454712, 'test/num_examples': 10000, 'score': 17686.574685573578, 'total_duration': 18944.70481967926, 'accumulated_submission_time': 17686.574685573578, 'accumulated_eval_time': 1253.3240871429443, 'accumulated_logging_time': 2.613891363143921}
I0302 16:48:23.178630 140239850956544 logging_writer.py:48] [39627] accumulated_eval_time=1253.324087, accumulated_logging_time=2.613891, accumulated_submission_time=17686.574686, global_step=39627, preemption_count=0, score=17686.574686, test/accuracy=0.479600, test/loss=2.343630, test/num_examples=10000, total_duration=18944.704820, train/accuracy=0.648965, train/loss=1.421940, validation/accuracy=0.600580, validation/loss=1.651232, validation/num_examples=50000
I0302 16:48:52.803745 140239842563840 logging_writer.py:48] [39700] global_step=39700, grad_norm=1.2175335884094238, loss=2.5287601947784424
I0302 16:49:37.005926 140239850956544 logging_writer.py:48] [39800] global_step=39800, grad_norm=1.1551827192306519, loss=2.492676258087158
I0302 16:50:21.851006 140239842563840 logging_writer.py:48] [39900] global_step=39900, grad_norm=1.3392053842544556, loss=2.48905873298645
I0302 16:51:07.060282 140239850956544 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.9997940063476562, loss=4.639233112335205
I0302 16:51:52.607645 140239842563840 logging_writer.py:48] [40100] global_step=40100, grad_norm=1.095116376876831, loss=3.2446398735046387
I0302 16:52:38.315095 140239850956544 logging_writer.py:48] [40200] global_step=40200, grad_norm=1.1948139667510986, loss=2.443903684616089
I0302 16:53:23.725367 140239842563840 logging_writer.py:48] [40300] global_step=40300, grad_norm=1.2444294691085815, loss=2.812554121017456
I0302 16:54:09.104274 140239850956544 logging_writer.py:48] [40400] global_step=40400, grad_norm=0.9122810959815979, loss=4.974767208099365
I0302 16:54:54.463188 140239842563840 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.9925979375839233, loss=4.113358020782471
I0302 16:55:23.534040 140437341357888 spec.py:321] Evaluating on the training split.
I0302 16:55:33.480262 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 16:55:52.613840 140437341357888 spec.py:349] Evaluating on the test split.
I0302 16:55:54.257330 140437341357888 submission_runner.py:411] Time since start: 19395.81s, 	Step: 40566, 	{'train/accuracy': 0.6485155820846558, 'train/loss': 1.4499775171279907, 'validation/accuracy': 0.6007800102233887, 'validation/loss': 1.6757594347000122, 'validation/num_examples': 50000, 'test/accuracy': 0.4792000353336334, 'test/loss': 2.341360569000244, 'test/num_examples': 10000, 'score': 18106.868000030518, 'total_duration': 19395.80882000923, 'accumulated_submission_time': 18106.868000030518, 'accumulated_eval_time': 1284.0473837852478, 'accumulated_logging_time': 2.6498749256134033}
I0302 16:55:54.282564 140239850956544 logging_writer.py:48] [40566] accumulated_eval_time=1284.047384, accumulated_logging_time=2.649875, accumulated_submission_time=18106.868000, global_step=40566, preemption_count=0, score=18106.868000, test/accuracy=0.479200, test/loss=2.341361, test/num_examples=10000, total_duration=19395.808820, train/accuracy=0.648516, train/loss=1.449978, validation/accuracy=0.600780, validation/loss=1.675759, validation/num_examples=50000
I0302 16:56:08.191066 140239842563840 logging_writer.py:48] [40600] global_step=40600, grad_norm=1.1735479831695557, loss=2.453516721725464
I0302 16:56:50.964355 140239850956544 logging_writer.py:48] [40700] global_step=40700, grad_norm=0.9325690269470215, loss=4.490421295166016
I0302 16:57:36.119829 140239842563840 logging_writer.py:48] [40800] global_step=40800, grad_norm=1.1314480304718018, loss=2.5734753608703613
I0302 16:58:21.125552 140239850956544 logging_writer.py:48] [40900] global_step=40900, grad_norm=1.1103466749191284, loss=2.962466239929199
I0302 16:59:06.493722 140239842563840 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.1992073059082031, loss=2.4767770767211914
I0302 16:59:51.841863 140239850956544 logging_writer.py:48] [41100] global_step=41100, grad_norm=1.1001315116882324, loss=5.012142181396484
I0302 17:00:36.984270 140239842563840 logging_writer.py:48] [41200] global_step=41200, grad_norm=1.2590581178665161, loss=2.507242202758789
I0302 17:01:22.715134 140239850956544 logging_writer.py:48] [41300] global_step=41300, grad_norm=1.2071669101715088, loss=2.525416612625122
I0302 17:02:08.605252 140239842563840 logging_writer.py:48] [41400] global_step=41400, grad_norm=1.1852052211761475, loss=2.562739849090576
I0302 17:02:54.064183 140239850956544 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.238438367843628, loss=5.043007850646973
I0302 17:02:54.650360 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:03:04.864259 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:03:22.487242 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:03:24.121961 140437341357888 submission_runner.py:411] Time since start: 19845.67s, 	Step: 41503, 	{'train/accuracy': 0.646484375, 'train/loss': 1.5099809169769287, 'validation/accuracy': 0.6010199785232544, 'validation/loss': 1.7225019931793213, 'validation/num_examples': 50000, 'test/accuracy': 0.4783000349998474, 'test/loss': 2.380979061126709, 'test/num_examples': 10000, 'score': 18527.173591852188, 'total_duration': 19845.67344045639, 'accumulated_submission_time': 18527.173591852188, 'accumulated_eval_time': 1313.5189683437347, 'accumulated_logging_time': 2.6855294704437256}
I0302 17:03:24.147051 140239842563840 logging_writer.py:48] [41503] accumulated_eval_time=1313.518968, accumulated_logging_time=2.685529, accumulated_submission_time=18527.173592, global_step=41503, preemption_count=0, score=18527.173592, test/accuracy=0.478300, test/loss=2.380979, test/num_examples=10000, total_duration=19845.673440, train/accuracy=0.646484, train/loss=1.509981, validation/accuracy=0.601020, validation/loss=1.722502, validation/num_examples=50000
I0302 17:04:04.133661 140239850956544 logging_writer.py:48] [41600] global_step=41600, grad_norm=1.1965723037719727, loss=2.562783718109131
I0302 17:04:49.543088 140239842563840 logging_writer.py:48] [41700] global_step=41700, grad_norm=1.1215935945510864, loss=4.044692516326904
I0302 17:05:34.503351 140239850956544 logging_writer.py:48] [41800] global_step=41800, grad_norm=1.0184086561203003, loss=3.270570755004883
I0302 17:06:19.794557 140239842563840 logging_writer.py:48] [41900] global_step=41900, grad_norm=1.0333094596862793, loss=3.1377780437469482
I0302 17:07:05.087685 140239850956544 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.0627926588058472, loss=4.2728271484375
I0302 17:07:50.133530 140239842563840 logging_writer.py:48] [42100] global_step=42100, grad_norm=1.1296576261520386, loss=2.522258996963501
I0302 17:08:35.389924 140239850956544 logging_writer.py:48] [42200] global_step=42200, grad_norm=1.1585094928741455, loss=2.410428285598755
I0302 17:09:20.498585 140239842563840 logging_writer.py:48] [42300] global_step=42300, grad_norm=1.233841061592102, loss=2.522019386291504
I0302 17:10:05.618792 140239850956544 logging_writer.py:48] [42400] global_step=42400, grad_norm=1.2648190259933472, loss=2.5918240547180176
I0302 17:10:24.521176 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:10:34.334586 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:10:53.708351 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:10:55.335139 140437341357888 submission_runner.py:411] Time since start: 20296.89s, 	Step: 42444, 	{'train/accuracy': 0.6727929711341858, 'train/loss': 1.3531529903411865, 'validation/accuracy': 0.6094599962234497, 'validation/loss': 1.6596788167953491, 'validation/num_examples': 50000, 'test/accuracy': 0.4881000220775604, 'test/loss': 2.3156774044036865, 'test/num_examples': 10000, 'score': 18947.48678970337, 'total_duration': 20296.886627674103, 'accumulated_submission_time': 18947.48678970337, 'accumulated_eval_time': 1344.332921743393, 'accumulated_logging_time': 2.720686674118042}
I0302 17:10:55.361524 140239842563840 logging_writer.py:48] [42444] accumulated_eval_time=1344.332922, accumulated_logging_time=2.720687, accumulated_submission_time=18947.486790, global_step=42444, preemption_count=0, score=18947.486790, test/accuracy=0.488100, test/loss=2.315677, test/num_examples=10000, total_duration=20296.886628, train/accuracy=0.672793, train/loss=1.353153, validation/accuracy=0.609460, validation/loss=1.659679, validation/num_examples=50000
I0302 17:11:17.958543 140239850956544 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.2263681888580322, loss=2.460171937942505
I0302 17:12:02.042369 140239842563840 logging_writer.py:48] [42600] global_step=42600, grad_norm=1.329856038093567, loss=2.488908290863037
I0302 17:12:47.505960 140239850956544 logging_writer.py:48] [42700] global_step=42700, grad_norm=1.0429843664169312, loss=4.22714900970459
I0302 17:13:32.208908 140239842563840 logging_writer.py:48] [42800] global_step=42800, grad_norm=1.161048173904419, loss=2.7007107734680176
I0302 17:14:17.268630 140239850956544 logging_writer.py:48] [42900] global_step=42900, grad_norm=0.9658665657043457, loss=3.950592517852783
I0302 17:15:02.474029 140239842563840 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.2222782373428345, loss=2.535421371459961
I0302 17:15:47.592566 140239850956544 logging_writer.py:48] [43100] global_step=43100, grad_norm=1.3173896074295044, loss=2.502476215362549
I0302 17:16:32.666293 140239842563840 logging_writer.py:48] [43200] global_step=43200, grad_norm=1.0899935960769653, loss=5.00452184677124
I0302 17:17:18.012599 140239850956544 logging_writer.py:48] [43300] global_step=43300, grad_norm=1.173743486404419, loss=2.5011706352233887
I0302 17:17:55.403449 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:18:05.218147 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:18:24.774073 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:18:26.390613 140437341357888 submission_runner.py:411] Time since start: 20747.94s, 	Step: 43385, 	{'train/accuracy': 0.6493554711341858, 'train/loss': 1.4348890781402588, 'validation/accuracy': 0.6075999736785889, 'validation/loss': 1.6461001634597778, 'validation/num_examples': 50000, 'test/accuracy': 0.48000001907348633, 'test/loss': 2.3596129417419434, 'test/num_examples': 10000, 'score': 19367.46821308136, 'total_duration': 20747.942059278488, 'accumulated_submission_time': 19367.46821308136, 'accumulated_eval_time': 1375.3200373649597, 'accumulated_logging_time': 2.756638288497925}
I0302 17:18:26.421631 140239842563840 logging_writer.py:48] [43385] accumulated_eval_time=1375.320037, accumulated_logging_time=2.756638, accumulated_submission_time=19367.468213, global_step=43385, preemption_count=0, score=19367.468213, test/accuracy=0.480000, test/loss=2.359613, test/num_examples=10000, total_duration=20747.942059, train/accuracy=0.649355, train/loss=1.434889, validation/accuracy=0.607600, validation/loss=1.646100, validation/num_examples=50000
I0302 17:18:32.784137 140239850956544 logging_writer.py:48] [43400] global_step=43400, grad_norm=0.9189087748527527, loss=4.269519329071045
I0302 17:19:14.286036 140239842563840 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.9696956872940063, loss=3.4991366863250732
I0302 17:19:58.919038 140239850956544 logging_writer.py:48] [43600] global_step=43600, grad_norm=1.2077760696411133, loss=2.4160685539245605
I0302 17:20:44.116496 140239842563840 logging_writer.py:48] [43700] global_step=43700, grad_norm=1.244949460029602, loss=2.4974365234375
I0302 17:21:29.832689 140239850956544 logging_writer.py:48] [43800] global_step=43800, grad_norm=1.126456618309021, loss=4.011493682861328
I0302 17:22:14.874533 140239842563840 logging_writer.py:48] [43900] global_step=43900, grad_norm=1.011731743812561, loss=4.991689682006836
I0302 17:22:59.749189 140239850956544 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.9840953350067139, loss=4.908737659454346
I0302 17:23:44.903022 140239842563840 logging_writer.py:48] [44100] global_step=44100, grad_norm=1.0471243858337402, loss=3.7597551345825195
I0302 17:24:29.864398 140239850956544 logging_writer.py:48] [44200] global_step=44200, grad_norm=1.03180992603302, loss=3.8314692974090576
I0302 17:25:14.975019 140239842563840 logging_writer.py:48] [44300] global_step=44300, grad_norm=1.154530644416809, loss=2.342932939529419
I0302 17:25:26.413639 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:25:36.296871 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:25:55.461310 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:25:57.091281 140437341357888 submission_runner.py:411] Time since start: 21198.64s, 	Step: 44327, 	{'train/accuracy': 0.6592382788658142, 'train/loss': 1.38425874710083, 'validation/accuracy': 0.609499990940094, 'validation/loss': 1.627719759941101, 'validation/num_examples': 50000, 'test/accuracy': 0.48510003089904785, 'test/loss': 2.3165159225463867, 'test/num_examples': 10000, 'score': 19787.398421525955, 'total_duration': 21198.64275765419, 'accumulated_submission_time': 19787.398421525955, 'accumulated_eval_time': 1405.9976406097412, 'accumulated_logging_time': 2.7973742485046387}
I0302 17:25:57.121039 140239850956544 logging_writer.py:48] [44327] accumulated_eval_time=1405.997641, accumulated_logging_time=2.797374, accumulated_submission_time=19787.398422, global_step=44327, preemption_count=0, score=19787.398422, test/accuracy=0.485100, test/loss=2.316516, test/num_examples=10000, total_duration=21198.642758, train/accuracy=0.659238, train/loss=1.384259, validation/accuracy=0.609500, validation/loss=1.627720, validation/num_examples=50000
I0302 17:26:26.466821 140239842563840 logging_writer.py:48] [44400] global_step=44400, grad_norm=1.1325862407684326, loss=2.6377344131469727
I0302 17:27:11.887444 140239850956544 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.2636178731918335, loss=2.34031081199646
I0302 17:27:57.093735 140239842563840 logging_writer.py:48] [44600] global_step=44600, grad_norm=1.1760197877883911, loss=2.350977659225464
I0302 17:28:42.441258 140239850956544 logging_writer.py:48] [44700] global_step=44700, grad_norm=1.2522655725479126, loss=2.4390957355499268
I0302 17:29:27.305157 140239842563840 logging_writer.py:48] [44800] global_step=44800, grad_norm=1.1940785646438599, loss=2.4302971363067627
I0302 17:30:12.619184 140239850956544 logging_writer.py:48] [44900] global_step=44900, grad_norm=1.1579563617706299, loss=2.3889660835266113
I0302 17:30:57.733978 140239842563840 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.082677960395813, loss=2.3883934020996094
I0302 17:31:43.213076 140239850956544 logging_writer.py:48] [45100] global_step=45100, grad_norm=1.2478291988372803, loss=2.5816614627838135
I0302 17:32:28.516438 140239842563840 logging_writer.py:48] [45200] global_step=45200, grad_norm=1.305770754814148, loss=2.4998083114624023
I0302 17:32:57.230863 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:33:07.177928 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:33:25.977444 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:33:27.606140 140437341357888 submission_runner.py:411] Time since start: 21649.16s, 	Step: 45265, 	{'train/accuracy': 0.6744531393051147, 'train/loss': 1.3124046325683594, 'validation/accuracy': 0.6171199679374695, 'validation/loss': 1.5861340761184692, 'validation/num_examples': 50000, 'test/accuracy': 0.492000013589859, 'test/loss': 2.267448663711548, 'test/num_examples': 10000, 'score': 20207.447094917297, 'total_duration': 21649.15763068199, 'accumulated_submission_time': 20207.447094917297, 'accumulated_eval_time': 1436.3729367256165, 'accumulated_logging_time': 2.8370449542999268}
I0302 17:33:27.633779 140239850956544 logging_writer.py:48] [45265] accumulated_eval_time=1436.372937, accumulated_logging_time=2.837045, accumulated_submission_time=20207.447095, global_step=45265, preemption_count=0, score=20207.447095, test/accuracy=0.492000, test/loss=2.267449, test/num_examples=10000, total_duration=21649.157631, train/accuracy=0.674453, train/loss=1.312405, validation/accuracy=0.617120, validation/loss=1.586134, validation/num_examples=50000
I0302 17:33:41.926812 140239842563840 logging_writer.py:48] [45300] global_step=45300, grad_norm=0.9588214159011841, loss=4.783758163452148
I0302 17:34:24.909381 140239850956544 logging_writer.py:48] [45400] global_step=45400, grad_norm=1.288649320602417, loss=2.3951547145843506
I0302 17:35:10.102174 140239842563840 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.2417058944702148, loss=2.39135479927063
I0302 17:35:55.517096 140239850956544 logging_writer.py:48] [45600] global_step=45600, grad_norm=1.1912171840667725, loss=2.316818952560425
I0302 17:36:41.036854 140239842563840 logging_writer.py:48] [45700] global_step=45700, grad_norm=1.1907984018325806, loss=2.562666893005371
I0302 17:37:26.511202 140239850956544 logging_writer.py:48] [45800] global_step=45800, grad_norm=0.9583566188812256, loss=5.065546989440918
I0302 17:38:11.815860 140239842563840 logging_writer.py:48] [45900] global_step=45900, grad_norm=1.1435418128967285, loss=2.8406600952148438
I0302 17:38:56.924937 140239850956544 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.184911847114563, loss=4.995774269104004
I0302 17:39:42.225457 140239842563840 logging_writer.py:48] [46100] global_step=46100, grad_norm=0.9324544668197632, loss=3.4534058570861816
I0302 17:40:27.445377 140239850956544 logging_writer.py:48] [46200] global_step=46200, grad_norm=1.2423588037490845, loss=2.4287314414978027
I0302 17:40:28.003262 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:40:37.845292 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:40:55.573373 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:40:57.195540 140437341357888 submission_runner.py:411] Time since start: 22098.75s, 	Step: 46203, 	{'train/accuracy': 0.66162109375, 'train/loss': 1.3712722063064575, 'validation/accuracy': 0.6122599840164185, 'validation/loss': 1.6086606979370117, 'validation/num_examples': 50000, 'test/accuracy': 0.48820000886917114, 'test/loss': 2.291762351989746, 'test/num_examples': 10000, 'score': 20627.749936580658, 'total_duration': 22098.74702978134, 'accumulated_submission_time': 20627.749936580658, 'accumulated_eval_time': 1465.5651831626892, 'accumulated_logging_time': 2.880309820175171}
I0302 17:40:57.229841 140239842563840 logging_writer.py:48] [46203] accumulated_eval_time=1465.565183, accumulated_logging_time=2.880310, accumulated_submission_time=20627.749937, global_step=46203, preemption_count=0, score=20627.749937, test/accuracy=0.488200, test/loss=2.291762, test/num_examples=10000, total_duration=22098.747030, train/accuracy=0.661621, train/loss=1.371272, validation/accuracy=0.612260, validation/loss=1.608661, validation/num_examples=50000
I0302 17:41:37.581454 140239850956544 logging_writer.py:48] [46300] global_step=46300, grad_norm=1.1984766721725464, loss=2.498539447784424
I0302 17:42:22.752529 140239842563840 logging_writer.py:48] [46400] global_step=46400, grad_norm=1.2385932207107544, loss=2.516017198562622
I0302 17:43:07.849407 140239850956544 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.3388736248016357, loss=2.451493978500366
I0302 17:43:52.829413 140239842563840 logging_writer.py:48] [46600] global_step=46600, grad_norm=1.0822960138320923, loss=4.976283550262451
I0302 17:44:38.037474 140239850956544 logging_writer.py:48] [46700] global_step=46700, grad_norm=1.3942517042160034, loss=2.3685827255249023
I0302 17:45:23.232846 140239842563840 logging_writer.py:48] [46800] global_step=46800, grad_norm=1.2976477146148682, loss=2.4494457244873047
I0302 17:46:08.296961 140239850956544 logging_writer.py:48] [46900] global_step=46900, grad_norm=1.1502163410186768, loss=2.488504648208618
I0302 17:46:53.571662 140239842563840 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.1686745882034302, loss=2.424609422683716
I0302 17:47:38.875998 140239850956544 logging_writer.py:48] [47100] global_step=47100, grad_norm=1.1831450462341309, loss=2.3666927814483643
I0302 17:47:57.418142 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:48:07.371198 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:48:28.128129 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:48:29.757192 140437341357888 submission_runner.py:411] Time since start: 22551.31s, 	Step: 47143, 	{'train/accuracy': 0.6664453148841858, 'train/loss': 1.3697527647018433, 'validation/accuracy': 0.616599977016449, 'validation/loss': 1.6000088453292847, 'validation/num_examples': 50000, 'test/accuracy': 0.49010002613067627, 'test/loss': 2.2621548175811768, 'test/num_examples': 10000, 'score': 21047.87811112404, 'total_duration': 22551.3086810112, 'accumulated_submission_time': 21047.87811112404, 'accumulated_eval_time': 1497.9042127132416, 'accumulated_logging_time': 2.924238920211792}
I0302 17:48:29.784824 140239842563840 logging_writer.py:48] [47143] accumulated_eval_time=1497.904213, accumulated_logging_time=2.924239, accumulated_submission_time=21047.878111, global_step=47143, preemption_count=0, score=21047.878111, test/accuracy=0.490100, test/loss=2.262155, test/num_examples=10000, total_duration=22551.308681, train/accuracy=0.666445, train/loss=1.369753, validation/accuracy=0.616600, validation/loss=1.600009, validation/num_examples=50000
I0302 17:48:52.779366 140239850956544 logging_writer.py:48] [47200] global_step=47200, grad_norm=1.140654444694519, loss=3.726485013961792
I0302 17:49:35.023931 140239842563840 logging_writer.py:48] [47300] global_step=47300, grad_norm=0.970480740070343, loss=3.5486321449279785
I0302 17:50:19.922295 140239850956544 logging_writer.py:48] [47400] global_step=47400, grad_norm=1.1887917518615723, loss=2.4191133975982666
I0302 17:51:05.069195 140239842563840 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.021071195602417, loss=4.935713768005371
I0302 17:51:50.391010 140239850956544 logging_writer.py:48] [47600] global_step=47600, grad_norm=1.0514627695083618, loss=3.123218536376953
I0302 17:52:35.501760 140239842563840 logging_writer.py:48] [47700] global_step=47700, grad_norm=1.1144224405288696, loss=4.9819655418396
I0302 17:53:20.377968 140239850956544 logging_writer.py:48] [47800] global_step=47800, grad_norm=1.04403555393219, loss=4.256169319152832
I0302 17:54:05.451993 140239842563840 logging_writer.py:48] [47900] global_step=47900, grad_norm=1.0306721925735474, loss=4.920461654663086
I0302 17:54:50.491444 140239850956544 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.1554186344146729, loss=2.493482828140259
I0302 17:55:29.846843 140437341357888 spec.py:321] Evaluating on the training split.
I0302 17:55:39.545742 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 17:55:58.239200 140437341357888 spec.py:349] Evaluating on the test split.
I0302 17:55:59.873937 140437341357888 submission_runner.py:411] Time since start: 23001.43s, 	Step: 48088, 	{'train/accuracy': 0.66943359375, 'train/loss': 1.3299815654754639, 'validation/accuracy': 0.6164000034332275, 'validation/loss': 1.5844672918319702, 'validation/num_examples': 50000, 'test/accuracy': 0.49560001492500305, 'test/loss': 2.2268576622009277, 'test/num_examples': 10000, 'score': 21467.8795838356, 'total_duration': 23001.425425052643, 'accumulated_submission_time': 21467.8795838356, 'accumulated_eval_time': 1527.9312839508057, 'accumulated_logging_time': 2.9619107246398926}
I0302 17:55:59.901427 140239842563840 logging_writer.py:48] [48088] accumulated_eval_time=1527.931284, accumulated_logging_time=2.961911, accumulated_submission_time=21467.879584, global_step=48088, preemption_count=0, score=21467.879584, test/accuracy=0.495600, test/loss=2.226858, test/num_examples=10000, total_duration=23001.425425, train/accuracy=0.669434, train/loss=1.329982, validation/accuracy=0.616400, validation/loss=1.584467, validation/num_examples=50000
I0302 17:56:05.072524 140239850956544 logging_writer.py:48] [48100] global_step=48100, grad_norm=1.2657231092453003, loss=2.5807998180389404
I0302 17:56:47.098181 140239842563840 logging_writer.py:48] [48200] global_step=48200, grad_norm=1.1667084693908691, loss=2.4220235347747803
I0302 17:57:32.475219 140239850956544 logging_writer.py:48] [48300] global_step=48300, grad_norm=1.227820873260498, loss=2.460508108139038
I0302 17:58:17.667990 140239842563840 logging_writer.py:48] [48400] global_step=48400, grad_norm=1.2293730974197388, loss=2.686741828918457
I0302 17:59:02.830902 140239850956544 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.2219847440719604, loss=2.466700315475464
I0302 17:59:47.757883 140239842563840 logging_writer.py:48] [48600] global_step=48600, grad_norm=1.0076254606246948, loss=3.81899094581604
I0302 18:00:33.053168 140239850956544 logging_writer.py:48] [48700] global_step=48700, grad_norm=1.1782523393630981, loss=2.5202980041503906
I0302 18:01:18.413162 140239842563840 logging_writer.py:48] [48800] global_step=48800, grad_norm=1.0947203636169434, loss=4.813710689544678
I0302 18:02:03.742563 140239850956544 logging_writer.py:48] [48900] global_step=48900, grad_norm=1.1986620426177979, loss=2.4577386379241943
I0302 18:02:48.810441 140239842563840 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.1241189241409302, loss=2.5652053356170654
I0302 18:03:00.175952 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:03:10.412332 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:03:29.484889 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:03:31.110868 140437341357888 submission_runner.py:411] Time since start: 23452.66s, 	Step: 49027, 	{'train/accuracy': 0.6886523365974426, 'train/loss': 1.2827799320220947, 'validation/accuracy': 0.617680013179779, 'validation/loss': 1.6056610345840454, 'validation/num_examples': 50000, 'test/accuracy': 0.49550002813339233, 'test/loss': 2.2766523361206055, 'test/num_examples': 10000, 'score': 21888.09333539009, 'total_duration': 23452.662343978882, 'accumulated_submission_time': 21888.09333539009, 'accumulated_eval_time': 1558.8661715984344, 'accumulated_logging_time': 2.999751567840576}
I0302 18:03:31.137146 140239850956544 logging_writer.py:48] [49027] accumulated_eval_time=1558.866172, accumulated_logging_time=2.999752, accumulated_submission_time=21888.093335, global_step=49027, preemption_count=0, score=21888.093335, test/accuracy=0.495500, test/loss=2.276652, test/num_examples=10000, total_duration=23452.662344, train/accuracy=0.688652, train/loss=1.282780, validation/accuracy=0.617680, validation/loss=1.605661, validation/num_examples=50000
I0302 18:04:00.508265 140239842563840 logging_writer.py:48] [49100] global_step=49100, grad_norm=1.240031123161316, loss=2.4041385650634766
I0302 18:04:45.214397 140239850956544 logging_writer.py:48] [49200] global_step=49200, grad_norm=1.1283202171325684, loss=3.354093313217163
I0302 18:05:30.346980 140239842563840 logging_writer.py:48] [49300] global_step=49300, grad_norm=1.160704493522644, loss=2.5551352500915527
I0302 18:06:15.229558 140239850956544 logging_writer.py:48] [49400] global_step=49400, grad_norm=1.1971096992492676, loss=2.800814628601074
I0302 18:07:00.426687 140239842563840 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.0313093662261963, loss=3.109666347503662
I0302 18:07:45.582063 140239850956544 logging_writer.py:48] [49600] global_step=49600, grad_norm=0.9475342035293579, loss=4.319727420806885
I0302 18:08:30.428387 140239842563840 logging_writer.py:48] [49700] global_step=49700, grad_norm=1.3635718822479248, loss=2.3764333724975586
I0302 18:09:15.475028 140239850956544 logging_writer.py:48] [49800] global_step=49800, grad_norm=1.320532202720642, loss=2.357576370239258
I0302 18:10:00.529140 140239842563840 logging_writer.py:48] [49900] global_step=49900, grad_norm=1.160855770111084, loss=2.79284405708313
I0302 18:10:31.361718 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:10:41.379934 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:11:00.101045 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:11:01.723465 140437341357888 submission_runner.py:411] Time since start: 23903.27s, 	Step: 49970, 	{'train/accuracy': 0.6638867259025574, 'train/loss': 1.3901808261871338, 'validation/accuracy': 0.6227799654006958, 'validation/loss': 1.5859307050704956, 'validation/num_examples': 50000, 'test/accuracy': 0.49800002574920654, 'test/loss': 2.2585461139678955, 'test/num_examples': 10000, 'score': 22308.256228208542, 'total_duration': 23903.274853229523, 'accumulated_submission_time': 22308.256228208542, 'accumulated_eval_time': 1589.2278089523315, 'accumulated_logging_time': 3.0361344814300537}
I0302 18:11:01.765542 140239850956544 logging_writer.py:48] [49970] accumulated_eval_time=1589.227809, accumulated_logging_time=3.036134, accumulated_submission_time=22308.256228, global_step=49970, preemption_count=0, score=22308.256228, test/accuracy=0.498000, test/loss=2.258546, test/num_examples=10000, total_duration=23903.274853, train/accuracy=0.663887, train/loss=1.390181, validation/accuracy=0.622780, validation/loss=1.585931, validation/num_examples=50000
I0302 18:11:14.078419 140239842563840 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.4544938802719116, loss=2.332923650741577
I0302 18:11:56.857535 140239850956544 logging_writer.py:48] [50100] global_step=50100, grad_norm=1.26666259765625, loss=2.4067344665527344
I0302 18:12:42.138482 140239842563840 logging_writer.py:48] [50200] global_step=50200, grad_norm=1.2268184423446655, loss=2.378631353378296
I0302 18:13:27.277886 140239850956544 logging_writer.py:48] [50300] global_step=50300, grad_norm=1.2462058067321777, loss=2.478059768676758
I0302 18:14:12.412723 140239842563840 logging_writer.py:48] [50400] global_step=50400, grad_norm=1.1204510927200317, loss=4.955420970916748
I0302 18:14:57.668885 140239850956544 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.1114486455917358, loss=2.417372703552246
I0302 18:15:42.638858 140239842563840 logging_writer.py:48] [50600] global_step=50600, grad_norm=1.1115739345550537, loss=4.352762699127197
I0302 18:16:27.722088 140239850956544 logging_writer.py:48] [50700] global_step=50700, grad_norm=1.0489304065704346, loss=3.2294957637786865
I0302 18:17:12.946874 140239842563840 logging_writer.py:48] [50800] global_step=50800, grad_norm=1.164598822593689, loss=2.4283287525177
I0302 18:17:57.962895 140239850956544 logging_writer.py:48] [50900] global_step=50900, grad_norm=1.269773006439209, loss=2.3471269607543945
I0302 18:18:01.734976 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:18:11.726736 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:18:30.811756 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:18:32.451168 140437341357888 submission_runner.py:411] Time since start: 24354.00s, 	Step: 50910, 	{'train/accuracy': 0.6714843511581421, 'train/loss': 1.3220560550689697, 'validation/accuracy': 0.6208400130271912, 'validation/loss': 1.5570722818374634, 'validation/num_examples': 50000, 'test/accuracy': 0.49560001492500305, 'test/loss': 2.232228994369507, 'test/num_examples': 10000, 'score': 22728.157720565796, 'total_duration': 24354.002652168274, 'accumulated_submission_time': 22728.157720565796, 'accumulated_eval_time': 1619.9439854621887, 'accumulated_logging_time': 3.0944161415100098}
I0302 18:18:32.481166 140239842563840 logging_writer.py:48] [50910] accumulated_eval_time=1619.943985, accumulated_logging_time=3.094416, accumulated_submission_time=22728.157721, global_step=50910, preemption_count=0, score=22728.157721, test/accuracy=0.495600, test/loss=2.232229, test/num_examples=10000, total_duration=24354.002652, train/accuracy=0.671484, train/loss=1.322056, validation/accuracy=0.620840, validation/loss=1.557072, validation/num_examples=50000
I0302 18:19:09.401764 140239850956544 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.2714208364486694, loss=2.3525917530059814
I0302 18:19:54.122321 140239842563840 logging_writer.py:48] [51100] global_step=51100, grad_norm=1.2841147184371948, loss=4.831749439239502
I0302 18:20:39.359563 140239850956544 logging_writer.py:48] [51200] global_step=51200, grad_norm=1.1140942573547363, loss=4.851346492767334
I0302 18:21:25.079100 140239842563840 logging_writer.py:48] [51300] global_step=51300, grad_norm=1.0822336673736572, loss=2.6665589809417725
I0302 18:22:10.464051 140239850956544 logging_writer.py:48] [51400] global_step=51400, grad_norm=1.217471718788147, loss=2.926689386367798
I0302 18:22:55.776915 140239842563840 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.1968241930007935, loss=2.3702104091644287
I0302 18:23:40.956296 140239850956544 logging_writer.py:48] [51600] global_step=51600, grad_norm=1.2376090288162231, loss=2.3899269104003906
I0302 18:24:26.278210 140239842563840 logging_writer.py:48] [51700] global_step=51700, grad_norm=1.3606725931167603, loss=2.336033821105957
I0302 18:25:11.525137 140239850956544 logging_writer.py:48] [51800] global_step=51800, grad_norm=1.203330159187317, loss=2.349825859069824
I0302 18:25:32.763190 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:25:42.707257 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:26:04.380342 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:26:06.024552 140437341357888 submission_runner.py:411] Time since start: 24807.58s, 	Step: 51849, 	{'train/accuracy': 0.6763281226158142, 'train/loss': 1.3460313081741333, 'validation/accuracy': 0.6196799874305725, 'validation/loss': 1.6015217304229736, 'validation/num_examples': 50000, 'test/accuracy': 0.4967000186443329, 'test/loss': 2.263665199279785, 'test/num_examples': 10000, 'score': 23148.37905406952, 'total_duration': 24807.57603955269, 'accumulated_submission_time': 23148.37905406952, 'accumulated_eval_time': 1653.205320596695, 'accumulated_logging_time': 3.13411545753479}
I0302 18:26:06.050005 140239842563840 logging_writer.py:48] [51849] accumulated_eval_time=1653.205321, accumulated_logging_time=3.134115, accumulated_submission_time=23148.379054, global_step=51849, preemption_count=0, score=23148.379054, test/accuracy=0.496700, test/loss=2.263665, test/num_examples=10000, total_duration=24807.576040, train/accuracy=0.676328, train/loss=1.346031, validation/accuracy=0.619680, validation/loss=1.601522, validation/num_examples=50000
I0302 18:26:26.684194 140239850956544 logging_writer.py:48] [51900] global_step=51900, grad_norm=1.3512791395187378, loss=2.369889497756958
I0302 18:27:08.722064 140239842563840 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.040978193283081, loss=4.028372287750244
I0302 18:27:54.198366 140239850956544 logging_writer.py:48] [52100] global_step=52100, grad_norm=1.2764239311218262, loss=2.2635374069213867
I0302 18:28:39.442774 140239842563840 logging_writer.py:48] [52200] global_step=52200, grad_norm=1.0921719074249268, loss=2.6485464572906494
I0302 18:29:24.656820 140239850956544 logging_writer.py:48] [52300] global_step=52300, grad_norm=1.3239195346832275, loss=2.2864346504211426
I0302 18:30:09.684459 140239842563840 logging_writer.py:48] [52400] global_step=52400, grad_norm=1.1199833154678345, loss=4.44861364364624
I0302 18:30:54.545277 140239850956544 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.12782621383667, loss=3.473702907562256
I0302 18:31:40.086483 140239842563840 logging_writer.py:48] [52600] global_step=52600, grad_norm=1.218393325805664, loss=3.084109306335449
I0302 18:32:25.314582 140239850956544 logging_writer.py:48] [52700] global_step=52700, grad_norm=1.0981510877609253, loss=2.53247332572937
I0302 18:33:06.322376 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:33:16.255514 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:33:37.806051 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:33:39.435689 140437341357888 submission_runner.py:411] Time since start: 25260.99s, 	Step: 52792, 	{'train/accuracy': 0.6678906083106995, 'train/loss': 1.386376976966858, 'validation/accuracy': 0.6201199889183044, 'validation/loss': 1.6033985614776611, 'validation/num_examples': 50000, 'test/accuracy': 0.4921000301837921, 'test/loss': 2.28542423248291, 'test/num_examples': 10000, 'score': 23568.588448762894, 'total_duration': 25260.98716020584, 'accumulated_submission_time': 23568.588448762894, 'accumulated_eval_time': 1686.3185930252075, 'accumulated_logging_time': 3.1716651916503906}
I0302 18:33:39.468967 140239842563840 logging_writer.py:48] [52792] accumulated_eval_time=1686.318593, accumulated_logging_time=3.171665, accumulated_submission_time=23568.588449, global_step=52792, preemption_count=0, score=23568.588449, test/accuracy=0.492100, test/loss=2.285424, test/num_examples=10000, total_duration=25260.987160, train/accuracy=0.667891, train/loss=1.386377, validation/accuracy=0.620120, validation/loss=1.603399, validation/num_examples=50000
I0302 18:33:43.071074 140239850956544 logging_writer.py:48] [52800] global_step=52800, grad_norm=0.9725832939147949, loss=3.867358446121216
I0302 18:34:24.038944 140239842563840 logging_writer.py:48] [52900] global_step=52900, grad_norm=1.0460965633392334, loss=3.800408363342285
I0302 18:35:09.155261 140239850956544 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.1683369874954224, loss=3.4504036903381348
I0302 18:35:54.222520 140239842563840 logging_writer.py:48] [53100] global_step=53100, grad_norm=1.2243459224700928, loss=2.3821256160736084
I0302 18:36:39.495420 140239850956544 logging_writer.py:48] [53200] global_step=53200, grad_norm=1.0923503637313843, loss=3.2073395252227783
I0302 18:37:24.739880 140239842563840 logging_writer.py:48] [53300] global_step=53300, grad_norm=1.0311496257781982, loss=4.750216960906982
I0302 18:38:09.936800 140239850956544 logging_writer.py:48] [53400] global_step=53400, grad_norm=1.1461116075515747, loss=2.9830284118652344
I0302 18:38:54.870831 140239842563840 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.2026488780975342, loss=2.4515678882598877
I0302 18:39:39.832013 140239850956544 logging_writer.py:48] [53600] global_step=53600, grad_norm=1.0106709003448486, loss=4.287797927856445
I0302 18:40:24.798094 140239842563840 logging_writer.py:48] [53700] global_step=53700, grad_norm=1.0798240900039673, loss=3.07881760597229
I0302 18:40:39.521816 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:40:49.938376 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:41:10.329834 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:41:11.955737 140437341357888 submission_runner.py:411] Time since start: 25713.51s, 	Step: 53734, 	{'train/accuracy': 0.674609363079071, 'train/loss': 1.3201045989990234, 'validation/accuracy': 0.625, 'validation/loss': 1.555474042892456, 'validation/num_examples': 50000, 'test/accuracy': 0.4958000183105469, 'test/loss': 2.2348878383636475, 'test/num_examples': 10000, 'score': 23988.578372478485, 'total_duration': 25713.507219314575, 'accumulated_submission_time': 23988.578372478485, 'accumulated_eval_time': 1718.752513408661, 'accumulated_logging_time': 3.2167985439300537}
I0302 18:41:11.988531 140239850956544 logging_writer.py:48] [53734] accumulated_eval_time=1718.752513, accumulated_logging_time=3.216799, accumulated_submission_time=23988.578372, global_step=53734, preemption_count=0, score=23988.578372, test/accuracy=0.495800, test/loss=2.234888, test/num_examples=10000, total_duration=25713.507219, train/accuracy=0.674609, train/loss=1.320105, validation/accuracy=0.625000, validation/loss=1.555474, validation/num_examples=50000
I0302 18:41:38.580185 140239842563840 logging_writer.py:48] [53800] global_step=53800, grad_norm=1.2921903133392334, loss=2.417717933654785
I0302 18:42:23.407920 140239850956544 logging_writer.py:48] [53900] global_step=53900, grad_norm=1.1634254455566406, loss=2.723925828933716
I0302 18:43:08.841033 140239842563840 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.0831162929534912, loss=4.3832597732543945
I0302 18:43:53.798586 140239850956544 logging_writer.py:48] [54100] global_step=54100, grad_norm=1.2304537296295166, loss=2.307835102081299
I0302 18:44:39.186998 140239842563840 logging_writer.py:48] [54200] global_step=54200, grad_norm=1.1783421039581299, loss=3.657762050628662
I0302 18:45:24.347352 140239850956544 logging_writer.py:48] [54300] global_step=54300, grad_norm=1.1388359069824219, loss=2.8264474868774414
I0302 18:46:09.511601 140239842563840 logging_writer.py:48] [54400] global_step=54400, grad_norm=1.0444116592407227, loss=4.576562881469727
I0302 18:46:54.901468 140239850956544 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.268359661102295, loss=2.312908887863159
I0302 18:47:40.088980 140239842563840 logging_writer.py:48] [54600] global_step=54600, grad_norm=1.1896343231201172, loss=2.3516039848327637
I0302 18:48:12.444829 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:48:22.566668 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:48:43.809054 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:48:45.430747 140437341357888 submission_runner.py:411] Time since start: 26166.98s, 	Step: 54673, 	{'train/accuracy': 0.6805273294448853, 'train/loss': 1.3037056922912598, 'validation/accuracy': 0.6293399930000305, 'validation/loss': 1.5446206331253052, 'validation/num_examples': 50000, 'test/accuracy': 0.508400022983551, 'test/loss': 2.209318161010742, 'test/num_examples': 10000, 'score': 24408.97371816635, 'total_duration': 26166.982230901718, 'accumulated_submission_time': 24408.97371816635, 'accumulated_eval_time': 1751.7384040355682, 'accumulated_logging_time': 3.2596917152404785}
I0302 18:48:45.459723 140239850956544 logging_writer.py:48] [54673] accumulated_eval_time=1751.738404, accumulated_logging_time=3.259692, accumulated_submission_time=24408.973718, global_step=54673, preemption_count=0, score=24408.973718, test/accuracy=0.508400, test/loss=2.209318, test/num_examples=10000, total_duration=26166.982231, train/accuracy=0.680527, train/loss=1.303706, validation/accuracy=0.629340, validation/loss=1.544621, validation/num_examples=50000
I0302 18:48:56.580791 140239842563840 logging_writer.py:48] [54700] global_step=54700, grad_norm=1.3173329830169678, loss=2.3345370292663574
I0302 18:49:38.605513 140239850956544 logging_writer.py:48] [54800] global_step=54800, grad_norm=1.2989661693572998, loss=2.3151321411132812
I0302 18:50:23.490966 140239842563840 logging_writer.py:48] [54900] global_step=54900, grad_norm=1.4831100702285767, loss=3.007506847381592
I0302 18:51:08.894011 140239850956544 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.2948189973831177, loss=2.4427013397216797
I0302 18:51:54.390555 140239842563840 logging_writer.py:48] [55100] global_step=55100, grad_norm=1.1991686820983887, loss=2.393416404724121
I0302 18:52:39.583519 140239850956544 logging_writer.py:48] [55200] global_step=55200, grad_norm=1.2118794918060303, loss=2.342416286468506
I0302 18:53:24.852371 140239842563840 logging_writer.py:48] [55300] global_step=55300, grad_norm=1.2145516872406006, loss=2.774045705795288
I0302 18:54:10.045511 140239850956544 logging_writer.py:48] [55400] global_step=55400, grad_norm=1.284103512763977, loss=2.331098794937134
I0302 18:54:55.181817 140239842563840 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.2756233215332031, loss=2.3118703365325928
I0302 18:55:40.575879 140239850956544 logging_writer.py:48] [55600] global_step=55600, grad_norm=1.0199276208877563, loss=3.377370834350586
I0302 18:55:45.683563 140437341357888 spec.py:321] Evaluating on the training split.
I0302 18:55:55.649304 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 18:56:20.229273 140437341357888 spec.py:349] Evaluating on the test split.
I0302 18:56:21.850477 140437341357888 submission_runner.py:411] Time since start: 26623.40s, 	Step: 55613, 	{'train/accuracy': 0.7066406011581421, 'train/loss': 1.207590937614441, 'validation/accuracy': 0.630079984664917, 'validation/loss': 1.5488102436065674, 'validation/num_examples': 50000, 'test/accuracy': 0.5047000050544739, 'test/loss': 2.2150003910064697, 'test/num_examples': 10000, 'score': 24829.13514328003, 'total_duration': 26623.4019677639, 'accumulated_submission_time': 24829.13514328003, 'accumulated_eval_time': 1787.9053149223328, 'accumulated_logging_time': 3.299623966217041}
I0302 18:56:21.878872 140239842563840 logging_writer.py:48] [55613] accumulated_eval_time=1787.905315, accumulated_logging_time=3.299624, accumulated_submission_time=24829.135143, global_step=55613, preemption_count=0, score=24829.135143, test/accuracy=0.504700, test/loss=2.215000, test/num_examples=10000, total_duration=26623.401968, train/accuracy=0.706641, train/loss=1.207591, validation/accuracy=0.630080, validation/loss=1.548810, validation/num_examples=50000
I0302 18:56:56.758565 140239850956544 logging_writer.py:48] [55700] global_step=55700, grad_norm=1.1903866529464722, loss=2.63616943359375
I0302 18:57:40.307682 140239842563840 logging_writer.py:48] [55800] global_step=55800, grad_norm=1.1677170991897583, loss=2.238093852996826
I0302 18:58:25.454621 140239850956544 logging_writer.py:48] [55900] global_step=55900, grad_norm=1.0723093748092651, loss=3.339939594268799
I0302 18:59:10.655088 140239842563840 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.0162198543548584, loss=4.125741004943848
I0302 18:59:55.568110 140239850956544 logging_writer.py:48] [56100] global_step=56100, grad_norm=1.2187042236328125, loss=2.690403938293457
I0302 19:00:40.629445 140239842563840 logging_writer.py:48] [56200] global_step=56200, grad_norm=1.3402893543243408, loss=2.22643780708313
I0302 19:01:26.019370 140239850956544 logging_writer.py:48] [56300] global_step=56300, grad_norm=1.2531448602676392, loss=2.946475028991699
I0302 19:02:11.457805 140239842563840 logging_writer.py:48] [56400] global_step=56400, grad_norm=1.0781652927398682, loss=4.8931050300598145
I0302 19:02:56.376810 140239850956544 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.3191730976104736, loss=2.3338091373443604
I0302 19:03:22.005958 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:03:32.136787 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:03:54.277965 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:03:55.899887 140437341357888 submission_runner.py:411] Time since start: 27077.45s, 	Step: 56558, 	{'train/accuracy': 0.6771875023841858, 'train/loss': 1.3591915369033813, 'validation/accuracy': 0.629040002822876, 'validation/loss': 1.5706725120544434, 'validation/num_examples': 50000, 'test/accuracy': 0.5024999976158142, 'test/loss': 2.2308924198150635, 'test/num_examples': 10000, 'score': 25249.202270269394, 'total_duration': 27077.451370954514, 'accumulated_submission_time': 25249.202270269394, 'accumulated_eval_time': 1821.7992248535156, 'accumulated_logging_time': 3.3368849754333496}
I0302 19:03:55.928991 140239842563840 logging_writer.py:48] [56558] accumulated_eval_time=1821.799225, accumulated_logging_time=3.336885, accumulated_submission_time=25249.202270, global_step=56558, preemption_count=0, score=25249.202270, test/accuracy=0.502500, test/loss=2.230892, test/num_examples=10000, total_duration=27077.451371, train/accuracy=0.677188, train/loss=1.359192, validation/accuracy=0.629040, validation/loss=1.570673, validation/num_examples=50000
I0302 19:04:13.002563 140239850956544 logging_writer.py:48] [56600] global_step=56600, grad_norm=1.2989583015441895, loss=2.388009786605835
I0302 19:04:55.914143 140239842563840 logging_writer.py:48] [56700] global_step=56700, grad_norm=1.132768154144287, loss=4.018946647644043
I0302 19:05:41.200913 140239850956544 logging_writer.py:48] [56800] global_step=56800, grad_norm=1.3388530015945435, loss=2.2822113037109375
I0302 19:06:26.424376 140239842563840 logging_writer.py:48] [56900] global_step=56900, grad_norm=1.3728488683700562, loss=2.2489378452301025
I0302 19:07:11.442838 140239850956544 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.249455451965332, loss=4.596591949462891
I0302 19:07:56.447917 140239842563840 logging_writer.py:48] [57100] global_step=57100, grad_norm=1.4066317081451416, loss=2.2633399963378906
I0302 19:08:41.741651 140239850956544 logging_writer.py:48] [57200] global_step=57200, grad_norm=1.0992985963821411, loss=3.853541612625122
I0302 19:09:26.589907 140239842563840 logging_writer.py:48] [57300] global_step=57300, grad_norm=1.232693076133728, loss=2.6263628005981445
I0302 19:10:11.626730 140239850956544 logging_writer.py:48] [57400] global_step=57400, grad_norm=1.2249592542648315, loss=2.3323183059692383
I0302 19:10:56.703933 140239842563840 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.1135709285736084, loss=3.1940529346466064
I0302 19:10:56.718318 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:11:07.446483 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:11:27.653472 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:11:29.280389 140437341357888 submission_runner.py:411] Time since start: 27530.83s, 	Step: 57501, 	{'train/accuracy': 0.68505859375, 'train/loss': 1.295912742614746, 'validation/accuracy': 0.6319800019264221, 'validation/loss': 1.5335566997528076, 'validation/num_examples': 50000, 'test/accuracy': 0.5076000094413757, 'test/loss': 2.20805025100708, 'test/num_examples': 10000, 'score': 25669.92558169365, 'total_duration': 27530.83186006546, 'accumulated_submission_time': 25669.92558169365, 'accumulated_eval_time': 1854.3612713813782, 'accumulated_logging_time': 3.379136562347412}
I0302 19:11:29.308998 140239850956544 logging_writer.py:48] [57501] accumulated_eval_time=1854.361271, accumulated_logging_time=3.379137, accumulated_submission_time=25669.925582, global_step=57501, preemption_count=0, score=25669.925582, test/accuracy=0.507600, test/loss=2.208050, test/num_examples=10000, total_duration=27530.831860, train/accuracy=0.685059, train/loss=1.295913, validation/accuracy=0.631980, validation/loss=1.533557, validation/num_examples=50000
I0302 19:12:10.814661 140239842563840 logging_writer.py:48] [57600] global_step=57600, grad_norm=1.080154299736023, loss=3.6741809844970703
I0302 19:12:55.854037 140239850956544 logging_writer.py:48] [57700] global_step=57700, grad_norm=1.2104923725128174, loss=2.2890005111694336
I0302 19:13:40.966489 140239842563840 logging_writer.py:48] [57800] global_step=57800, grad_norm=1.1219007968902588, loss=2.9985809326171875
I0302 19:14:26.042816 140239850956544 logging_writer.py:48] [57900] global_step=57900, grad_norm=1.243564486503601, loss=2.387744665145874
I0302 19:15:11.066852 140239842563840 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.4199354648590088, loss=2.5038950443267822
I0302 19:15:56.251386 140239850956544 logging_writer.py:48] [58100] global_step=58100, grad_norm=1.2493290901184082, loss=2.466600179672241
I0302 19:16:41.572601 140239842563840 logging_writer.py:48] [58200] global_step=58200, grad_norm=1.3950847387313843, loss=5.0273284912109375
I0302 19:17:27.061230 140239850956544 logging_writer.py:48] [58300] global_step=58300, grad_norm=1.0936305522918701, loss=2.3974859714508057
I0302 19:18:12.321116 140239842563840 logging_writer.py:48] [58400] global_step=58400, grad_norm=1.4104655981063843, loss=2.3646717071533203
I0302 19:18:29.676741 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:18:39.717859 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:18:59.275395 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:19:00.914939 140437341357888 submission_runner.py:411] Time since start: 27982.47s, 	Step: 58440, 	{'train/accuracy': 0.6932421922683716, 'train/loss': 1.2518590688705444, 'validation/accuracy': 0.6332600116729736, 'validation/loss': 1.53603196144104, 'validation/num_examples': 50000, 'test/accuracy': 0.5067000389099121, 'test/loss': 2.2019996643066406, 'test/num_examples': 10000, 'score': 26090.231457710266, 'total_duration': 27982.466410398483, 'accumulated_submission_time': 26090.231457710266, 'accumulated_eval_time': 1885.599454164505, 'accumulated_logging_time': 3.4180257320404053}
I0302 19:19:00.944968 140239850956544 logging_writer.py:48] [58440] accumulated_eval_time=1885.599454, accumulated_logging_time=3.418026, accumulated_submission_time=26090.231458, global_step=58440, preemption_count=0, score=26090.231458, test/accuracy=0.506700, test/loss=2.202000, test/num_examples=10000, total_duration=27982.466410, train/accuracy=0.693242, train/loss=1.251859, validation/accuracy=0.633260, validation/loss=1.536032, validation/num_examples=50000
I0302 19:19:25.155966 140239842563840 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.2094275951385498, loss=2.3385276794433594
I0302 19:20:09.489151 140239850956544 logging_writer.py:48] [58600] global_step=58600, grad_norm=1.17244291305542, loss=2.306349039077759
I0302 19:20:54.719422 140239842563840 logging_writer.py:48] [58700] global_step=58700, grad_norm=1.1527831554412842, loss=4.466196060180664
I0302 19:21:40.491162 140239850956544 logging_writer.py:48] [58800] global_step=58800, grad_norm=1.327723503112793, loss=2.3777194023132324
I0302 19:22:25.656675 140239842563840 logging_writer.py:48] [58900] global_step=58900, grad_norm=1.2556854486465454, loss=2.353520154953003
I0302 19:23:11.042968 140239850956544 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.0884689092636108, loss=4.196599006652832
I0302 19:23:56.122689 140239842563840 logging_writer.py:48] [59100] global_step=59100, grad_norm=1.1907850503921509, loss=2.3313214778900146
I0302 19:24:41.426363 140239850956544 logging_writer.py:48] [59200] global_step=59200, grad_norm=1.2247411012649536, loss=2.6019468307495117
I0302 19:25:26.750570 140239842563840 logging_writer.py:48] [59300] global_step=59300, grad_norm=1.1949207782745361, loss=2.808303117752075
I0302 19:26:01.303051 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:26:11.288314 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:26:37.036880 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:26:38.650138 140437341357888 submission_runner.py:411] Time since start: 28440.20s, 	Step: 59378, 	{'train/accuracy': 0.6830077767372131, 'train/loss': 1.290729284286499, 'validation/accuracy': 0.6337800025939941, 'validation/loss': 1.5220874547958374, 'validation/num_examples': 50000, 'test/accuracy': 0.5088000297546387, 'test/loss': 2.1774446964263916, 'test/num_examples': 10000, 'score': 26510.5277197361, 'total_duration': 28440.20163846016, 'accumulated_submission_time': 26510.5277197361, 'accumulated_eval_time': 1922.9465517997742, 'accumulated_logging_time': 3.4586949348449707}
I0302 19:26:38.679409 140239850956544 logging_writer.py:48] [59378] accumulated_eval_time=1922.946552, accumulated_logging_time=3.458695, accumulated_submission_time=26510.527720, global_step=59378, preemption_count=0, score=26510.527720, test/accuracy=0.508800, test/loss=2.177445, test/num_examples=10000, total_duration=28440.201638, train/accuracy=0.683008, train/loss=1.290729, validation/accuracy=0.633780, validation/loss=1.522087, validation/num_examples=50000
I0302 19:26:47.812789 140239842563840 logging_writer.py:48] [59400] global_step=59400, grad_norm=1.2840988636016846, loss=2.2339744567871094
I0302 19:27:28.101588 140239850956544 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.259446620941162, loss=2.331301689147949
I0302 19:28:13.626111 140239842563840 logging_writer.py:48] [59600] global_step=59600, grad_norm=1.269228219985962, loss=2.3284077644348145
I0302 19:28:58.807075 140239850956544 logging_writer.py:48] [59700] global_step=59700, grad_norm=1.192786455154419, loss=4.596383094787598
I0302 19:29:43.916491 140239842563840 logging_writer.py:48] [59800] global_step=59800, grad_norm=1.070224404335022, loss=3.8004701137542725
I0302 19:30:29.105672 140239850956544 logging_writer.py:48] [59900] global_step=59900, grad_norm=1.052295207977295, loss=4.081514835357666
I0302 19:31:14.164502 140239842563840 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.1403049230575562, loss=3.0443813800811768
I0302 19:31:59.564606 140239850956544 logging_writer.py:48] [60100] global_step=60100, grad_norm=1.154736042022705, loss=3.1254849433898926
I0302 19:32:44.583877 140239842563840 logging_writer.py:48] [60200] global_step=60200, grad_norm=1.255341649055481, loss=2.411958694458008
I0302 19:33:29.546615 140239850956544 logging_writer.py:48] [60300] global_step=60300, grad_norm=1.1420164108276367, loss=3.9058680534362793
I0302 19:33:39.076357 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:33:49.117655 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:34:09.869472 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:34:11.497859 140437341357888 submission_runner.py:411] Time since start: 28893.05s, 	Step: 60323, 	{'train/accuracy': 0.6819140315055847, 'train/loss': 1.2942769527435303, 'validation/accuracy': 0.6343799829483032, 'validation/loss': 1.5181857347488403, 'validation/num_examples': 50000, 'test/accuracy': 0.5124000310897827, 'test/loss': 2.1659436225891113, 'test/num_examples': 10000, 'score': 26930.862913370132, 'total_duration': 28893.049347400665, 'accumulated_submission_time': 26930.862913370132, 'accumulated_eval_time': 1955.368063211441, 'accumulated_logging_time': 3.498325824737549}
I0302 19:34:11.527987 140239842563840 logging_writer.py:48] [60323] accumulated_eval_time=1955.368063, accumulated_logging_time=3.498326, accumulated_submission_time=26930.862913, global_step=60323, preemption_count=0, score=26930.862913, test/accuracy=0.512400, test/loss=2.165944, test/num_examples=10000, total_duration=28893.049347, train/accuracy=0.681914, train/loss=1.294277, validation/accuracy=0.634380, validation/loss=1.518186, validation/num_examples=50000
I0302 19:34:42.747492 140239850956544 logging_writer.py:48] [60400] global_step=60400, grad_norm=1.1712552309036255, loss=4.660238265991211
I0302 19:35:27.724072 140239842563840 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.1843796968460083, loss=4.546875476837158
I0302 19:36:12.882026 140239850956544 logging_writer.py:48] [60600] global_step=60600, grad_norm=1.2197216749191284, loss=2.742447853088379
I0302 19:36:57.943251 140239842563840 logging_writer.py:48] [60700] global_step=60700, grad_norm=1.2683922052383423, loss=2.2180285453796387
I0302 19:37:42.998950 140239850956544 logging_writer.py:48] [60800] global_step=60800, grad_norm=1.194732666015625, loss=4.030742168426514
I0302 19:38:28.010671 140239842563840 logging_writer.py:48] [60900] global_step=60900, grad_norm=1.368809461593628, loss=2.281160354614258
I0302 19:39:13.273905 140239850956544 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.3778890371322632, loss=2.341193675994873
I0302 19:39:58.085909 140239842563840 logging_writer.py:48] [61100] global_step=61100, grad_norm=1.0215119123458862, loss=3.9526283740997314
I0302 19:40:43.223173 140239850956544 logging_writer.py:48] [61200] global_step=61200, grad_norm=1.2879743576049805, loss=2.3541786670684814
I0302 19:41:11.736086 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:41:22.155686 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:41:41.671938 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:41:43.307890 140437341357888 submission_runner.py:411] Time since start: 29344.86s, 	Step: 61265, 	{'train/accuracy': 0.6977343559265137, 'train/loss': 1.215801477432251, 'validation/accuracy': 0.640500009059906, 'validation/loss': 1.4811792373657227, 'validation/num_examples': 50000, 'test/accuracy': 0.5146000385284424, 'test/loss': 2.1561248302459717, 'test/num_examples': 10000, 'score': 27351.005984783173, 'total_duration': 29344.859375476837, 'accumulated_submission_time': 27351.005984783173, 'accumulated_eval_time': 1986.939861536026, 'accumulated_logging_time': 3.541537284851074}
I0302 19:41:43.337839 140239842563840 logging_writer.py:48] [61265] accumulated_eval_time=1986.939862, accumulated_logging_time=3.541537, accumulated_submission_time=27351.005985, global_step=61265, preemption_count=0, score=27351.005985, test/accuracy=0.514600, test/loss=2.156125, test/num_examples=10000, total_duration=29344.859375, train/accuracy=0.697734, train/loss=1.215801, validation/accuracy=0.640500, validation/loss=1.481179, validation/num_examples=50000
I0302 19:41:57.835886 140239850956544 logging_writer.py:48] [61300] global_step=61300, grad_norm=1.272168755531311, loss=2.2701330184936523
I0302 19:42:40.502408 140239842563840 logging_writer.py:48] [61400] global_step=61400, grad_norm=1.5030516386032104, loss=2.3551363945007324
I0302 19:43:25.613602 140239850956544 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.2930299043655396, loss=2.07039213180542
I0302 19:44:10.825911 140239842563840 logging_writer.py:48] [61600] global_step=61600, grad_norm=1.2369154691696167, loss=4.886230945587158
I0302 19:44:55.553031 140239850956544 logging_writer.py:48] [61700] global_step=61700, grad_norm=1.126888632774353, loss=3.2842016220092773
I0302 19:45:40.515210 140239842563840 logging_writer.py:48] [61800] global_step=61800, grad_norm=1.3195799589157104, loss=2.405395984649658
I0302 19:46:25.515448 140239850956544 logging_writer.py:48] [61900] global_step=61900, grad_norm=1.3416874408721924, loss=2.429448127746582
I0302 19:47:10.801095 140239842563840 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.201082468032837, loss=2.931253671646118
I0302 19:47:55.873491 140239850956544 logging_writer.py:48] [62100] global_step=62100, grad_norm=1.1989928483963013, loss=4.39128303527832
I0302 19:48:40.777400 140239842563840 logging_writer.py:48] [62200] global_step=62200, grad_norm=1.3049647808074951, loss=2.397642135620117
I0302 19:48:43.723706 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:48:53.878619 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:49:13.397348 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:49:15.037190 140437341357888 submission_runner.py:411] Time since start: 29796.59s, 	Step: 62208, 	{'train/accuracy': 0.7203710675239563, 'train/loss': 1.1145329475402832, 'validation/accuracy': 0.6396999955177307, 'validation/loss': 1.4701439142227173, 'validation/num_examples': 50000, 'test/accuracy': 0.5141000151634216, 'test/loss': 2.1523773670196533, 'test/num_examples': 10000, 'score': 27771.32909488678, 'total_duration': 29796.588678121567, 'accumulated_submission_time': 27771.32909488678, 'accumulated_eval_time': 2018.25333237648, 'accumulated_logging_time': 3.5821726322174072}
I0302 19:49:15.067344 140239850956544 logging_writer.py:48] [62208] accumulated_eval_time=2018.253332, accumulated_logging_time=3.582173, accumulated_submission_time=27771.329095, global_step=62208, preemption_count=0, score=27771.329095, test/accuracy=0.514100, test/loss=2.152377, test/num_examples=10000, total_duration=29796.588678, train/accuracy=0.720371, train/loss=1.114533, validation/accuracy=0.639700, validation/loss=1.470144, validation/num_examples=50000
I0302 19:49:52.890092 140239842563840 logging_writer.py:48] [62300] global_step=62300, grad_norm=1.0913009643554688, loss=4.140425682067871
I0302 19:50:37.633440 140239850956544 logging_writer.py:48] [62400] global_step=62400, grad_norm=1.2419466972351074, loss=2.2618775367736816
I0302 19:51:22.747005 140239842563840 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.2955000400543213, loss=2.320038318634033
I0302 19:52:08.161988 140239850956544 logging_writer.py:48] [62600] global_step=62600, grad_norm=1.2880207300186157, loss=2.231632709503174
I0302 19:52:52.982537 140239842563840 logging_writer.py:48] [62700] global_step=62700, grad_norm=1.1735199689865112, loss=4.333497524261475
I0302 19:53:38.290495 140239850956544 logging_writer.py:48] [62800] global_step=62800, grad_norm=1.218601942062378, loss=2.4315953254699707
I0302 19:54:23.384896 140239842563840 logging_writer.py:48] [62900] global_step=62900, grad_norm=1.2488179206848145, loss=2.385859966278076
I0302 19:55:08.540362 140239850956544 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.3436676263809204, loss=2.16209077835083
I0302 19:55:53.603637 140239842563840 logging_writer.py:48] [63100] global_step=63100, grad_norm=1.196498990058899, loss=3.7868382930755615
I0302 19:56:15.340194 140437341357888 spec.py:321] Evaluating on the training split.
I0302 19:56:25.380352 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 19:56:47.455858 140437341357888 spec.py:349] Evaluating on the test split.
I0302 19:56:49.080721 140437341357888 submission_runner.py:411] Time since start: 30250.63s, 	Step: 63150, 	{'train/accuracy': 0.68994140625, 'train/loss': 1.255996823310852, 'validation/accuracy': 0.6400200128555298, 'validation/loss': 1.4859697818756104, 'validation/num_examples': 50000, 'test/accuracy': 0.5139000415802002, 'test/loss': 2.1568527221679688, 'test/num_examples': 10000, 'score': 28191.540812969208, 'total_duration': 30250.63220858574, 'accumulated_submission_time': 28191.540812969208, 'accumulated_eval_time': 2051.9938457012177, 'accumulated_logging_time': 3.6222991943359375}
I0302 19:56:49.114323 140239850956544 logging_writer.py:48] [63150] accumulated_eval_time=2051.993846, accumulated_logging_time=3.622299, accumulated_submission_time=28191.540813, global_step=63150, preemption_count=0, score=28191.540813, test/accuracy=0.513900, test/loss=2.156853, test/num_examples=10000, total_duration=30250.632209, train/accuracy=0.689941, train/loss=1.255997, validation/accuracy=0.640020, validation/loss=1.485970, validation/num_examples=50000
I0302 19:57:09.351104 140239842563840 logging_writer.py:48] [63200] global_step=63200, grad_norm=1.328460454940796, loss=2.4077069759368896
I0302 19:57:52.003211 140239850956544 logging_writer.py:48] [63300] global_step=63300, grad_norm=1.2763042449951172, loss=2.528660774230957
I0302 19:58:37.527505 140239842563840 logging_writer.py:48] [63400] global_step=63400, grad_norm=1.327298879623413, loss=2.3520355224609375
I0302 19:59:22.609743 140239850956544 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.2505888938903809, loss=2.270263671875
I0302 20:00:07.645689 140239842563840 logging_writer.py:48] [63600] global_step=63600, grad_norm=1.2340809106826782, loss=2.2710559368133545
I0302 20:00:52.773621 140239850956544 logging_writer.py:48] [63700] global_step=63700, grad_norm=1.4804290533065796, loss=4.581958293914795
I0302 20:01:38.097511 140239842563840 logging_writer.py:48] [63800] global_step=63800, grad_norm=1.3337856531143188, loss=2.176370859146118
I0302 20:02:23.063559 140239850956544 logging_writer.py:48] [63900] global_step=63900, grad_norm=1.2285125255584717, loss=2.1173830032348633
I0302 20:03:07.847139 140239842563840 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.2881258726119995, loss=2.1378228664398193
I0302 20:03:49.319620 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:03:59.270390 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:04:20.897656 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:04:22.518348 140437341357888 submission_runner.py:411] Time since start: 30704.07s, 	Step: 64094, 	{'train/accuracy': 0.6942577958106995, 'train/loss': 1.2345657348632812, 'validation/accuracy': 0.6388799548149109, 'validation/loss': 1.49025559425354, 'validation/num_examples': 50000, 'test/accuracy': 0.5193000435829163, 'test/loss': 2.129345655441284, 'test/num_examples': 10000, 'score': 28611.683968544006, 'total_duration': 30704.06983423233, 'accumulated_submission_time': 28611.683968544006, 'accumulated_eval_time': 2085.1925711631775, 'accumulated_logging_time': 3.666409969329834}
I0302 20:04:22.552144 140239850956544 logging_writer.py:48] [64094] accumulated_eval_time=2085.192571, accumulated_logging_time=3.666410, accumulated_submission_time=28611.683969, global_step=64094, preemption_count=0, score=28611.683969, test/accuracy=0.519300, test/loss=2.129346, test/num_examples=10000, total_duration=30704.069834, train/accuracy=0.694258, train/loss=1.234566, validation/accuracy=0.638880, validation/loss=1.490256, validation/num_examples=50000
I0302 20:04:25.367702 140239842563840 logging_writer.py:48] [64100] global_step=64100, grad_norm=1.2923341989517212, loss=2.173733711242676
I0302 20:05:05.590143 140239842563840 logging_writer.py:48] [64200] global_step=64200, grad_norm=1.2742496728897095, loss=2.3966212272644043
I0302 20:05:50.680527 140239850956544 logging_writer.py:48] [64300] global_step=64300, grad_norm=1.231977105140686, loss=2.278578281402588
I0302 20:06:35.648263 140239842563840 logging_writer.py:48] [64400] global_step=64400, grad_norm=1.2342416048049927, loss=2.9716508388519287
I0302 20:07:20.497737 140239850956544 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.2220531702041626, loss=2.6356167793273926
I0302 20:08:05.528987 140239842563840 logging_writer.py:48] [64600] global_step=64600, grad_norm=1.1876397132873535, loss=2.6214706897735596
I0302 20:08:50.445867 140239850956544 logging_writer.py:48] [64700] global_step=64700, grad_norm=1.3068357706069946, loss=2.2584166526794434
I0302 20:09:35.272878 140239842563840 logging_writer.py:48] [64800] global_step=64800, grad_norm=1.388071894645691, loss=2.3878602981567383
I0302 20:10:20.075467 140239850956544 logging_writer.py:48] [64900] global_step=64900, grad_norm=1.344975471496582, loss=2.1422595977783203
I0302 20:11:05.285890 140239842563840 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.2177371978759766, loss=4.15327787399292
I0302 20:11:22.850271 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:11:32.713227 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:11:53.364822 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:11:54.990223 140437341357888 submission_runner.py:411] Time since start: 31156.54s, 	Step: 65041, 	{'train/accuracy': 0.7075585722923279, 'train/loss': 1.1857621669769287, 'validation/accuracy': 0.6427599787712097, 'validation/loss': 1.4769474267959595, 'validation/num_examples': 50000, 'test/accuracy': 0.5171000361442566, 'test/loss': 2.1382808685302734, 'test/num_examples': 10000, 'score': 29031.91866993904, 'total_duration': 31156.541711330414, 'accumulated_submission_time': 29031.91866993904, 'accumulated_eval_time': 2117.3324999809265, 'accumulated_logging_time': 3.71160888671875}
I0302 20:11:55.028988 140239850956544 logging_writer.py:48] [65041] accumulated_eval_time=2117.332500, accumulated_logging_time=3.711609, accumulated_submission_time=29031.918670, global_step=65041, preemption_count=0, score=29031.918670, test/accuracy=0.517100, test/loss=2.138281, test/num_examples=10000, total_duration=31156.541711, train/accuracy=0.707559, train/loss=1.185762, validation/accuracy=0.642760, validation/loss=1.476947, validation/num_examples=50000
I0302 20:12:18.879957 140239842563840 logging_writer.py:48] [65100] global_step=65100, grad_norm=1.2278072834014893, loss=3.6877405643463135
I0302 20:13:02.908440 140239850956544 logging_writer.py:48] [65200] global_step=65200, grad_norm=1.290676474571228, loss=2.1899232864379883
I0302 20:13:48.076968 140239842563840 logging_writer.py:48] [65300] global_step=65300, grad_norm=1.353165864944458, loss=2.252108573913574
I0302 20:14:33.217053 140239850956544 logging_writer.py:48] [65400] global_step=65400, grad_norm=1.3219259977340698, loss=2.2198596000671387
I0302 20:15:18.224602 140239842563840 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.0972808599472046, loss=3.2544655799865723
I0302 20:16:03.343017 140239850956544 logging_writer.py:48] [65600] global_step=65600, grad_norm=1.3382829427719116, loss=2.216796875
I0302 20:16:48.221805 140239842563840 logging_writer.py:48] [65700] global_step=65700, grad_norm=1.2469485998153687, loss=2.2147858142852783
I0302 20:17:33.316493 140239850956544 logging_writer.py:48] [65800] global_step=65800, grad_norm=1.185368537902832, loss=4.852542400360107
I0302 20:18:18.193235 140239842563840 logging_writer.py:48] [65900] global_step=65900, grad_norm=1.2591710090637207, loss=2.104201316833496
I0302 20:18:55.168251 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:19:05.512448 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:19:24.755859 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:19:26.394115 140437341357888 submission_runner.py:411] Time since start: 31607.95s, 	Step: 65984, 	{'train/accuracy': 0.69580078125, 'train/loss': 1.236257791519165, 'validation/accuracy': 0.645799994468689, 'validation/loss': 1.4627673625946045, 'validation/num_examples': 50000, 'test/accuracy': 0.5164999961853027, 'test/loss': 2.1316630840301514, 'test/num_examples': 10000, 'score': 29451.99482369423, 'total_duration': 31607.945594787598, 'accumulated_submission_time': 29451.99482369423, 'accumulated_eval_time': 2148.5583407878876, 'accumulated_logging_time': 3.76130747795105}
I0302 20:19:26.424926 140239850956544 logging_writer.py:48] [65984] accumulated_eval_time=2148.558341, accumulated_logging_time=3.761307, accumulated_submission_time=29451.994824, global_step=65984, preemption_count=0, score=29451.994824, test/accuracy=0.516500, test/loss=2.131663, test/num_examples=10000, total_duration=31607.945595, train/accuracy=0.695801, train/loss=1.236258, validation/accuracy=0.645800, validation/loss=1.462767, validation/num_examples=50000
I0302 20:19:33.191537 140239842563840 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.2502732276916504, loss=3.015791177749634
I0302 20:20:15.077305 140239850956544 logging_writer.py:48] [66100] global_step=66100, grad_norm=1.369232416152954, loss=2.1922576427459717
I0302 20:20:59.897411 140239842563840 logging_writer.py:48] [66200] global_step=66200, grad_norm=1.7143900394439697, loss=2.388270616531372
I0302 20:21:45.437787 140239850956544 logging_writer.py:48] [66300] global_step=66300, grad_norm=1.1123472452163696, loss=4.363405227661133
I0302 20:22:30.487123 140239842563840 logging_writer.py:48] [66400] global_step=66400, grad_norm=1.3684130907058716, loss=2.5168216228485107
I0302 20:23:15.739572 140239850956544 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.1905405521392822, loss=4.8706817626953125
I0302 20:24:00.577836 140239842563840 logging_writer.py:48] [66600] global_step=66600, grad_norm=1.166912317276001, loss=2.7964634895324707
I0302 20:24:45.761170 140239850956544 logging_writer.py:48] [66700] global_step=66700, grad_norm=1.3776235580444336, loss=2.3790743350982666
I0302 20:25:30.949455 140239842563840 logging_writer.py:48] [66800] global_step=66800, grad_norm=1.2666094303131104, loss=2.2362451553344727
I0302 20:26:16.296018 140239850956544 logging_writer.py:48] [66900] global_step=66900, grad_norm=1.1601307392120361, loss=2.7437849044799805
I0302 20:26:26.787647 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:26:37.241908 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:26:57.375790 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:26:59.001216 140437341357888 submission_runner.py:411] Time since start: 32060.55s, 	Step: 66925, 	{'train/accuracy': 0.6991015672683716, 'train/loss': 1.2016446590423584, 'validation/accuracy': 0.6476799845695496, 'validation/loss': 1.4438791275024414, 'validation/num_examples': 50000, 'test/accuracy': 0.5211000442504883, 'test/loss': 2.1141974925994873, 'test/num_examples': 10000, 'score': 29872.294987916946, 'total_duration': 32060.55270266533, 'accumulated_submission_time': 29872.294987916946, 'accumulated_eval_time': 2180.7719078063965, 'accumulated_logging_time': 3.802668809890747}
I0302 20:26:59.032719 140239842563840 logging_writer.py:48] [66925] accumulated_eval_time=2180.771908, accumulated_logging_time=3.802669, accumulated_submission_time=29872.294988, global_step=66925, preemption_count=0, score=29872.294988, test/accuracy=0.521100, test/loss=2.114197, test/num_examples=10000, total_duration=32060.552703, train/accuracy=0.699102, train/loss=1.201645, validation/accuracy=0.647680, validation/loss=1.443879, validation/num_examples=50000
I0302 20:27:29.332832 140239850956544 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.3751603364944458, loss=2.1203999519348145
I0302 20:28:14.328411 140239842563840 logging_writer.py:48] [67100] global_step=67100, grad_norm=1.3387494087219238, loss=2.335712194442749
I0302 20:28:59.748084 140239850956544 logging_writer.py:48] [67200] global_step=67200, grad_norm=1.2041919231414795, loss=2.258249521255493
I0302 20:29:44.696796 140239842563840 logging_writer.py:48] [67300] global_step=67300, grad_norm=1.2840967178344727, loss=2.1651158332824707
I0302 20:30:29.552374 140239850956544 logging_writer.py:48] [67400] global_step=67400, grad_norm=1.2820171117782593, loss=2.155698537826538
I0302 20:31:14.501351 140239842563840 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.1908986568450928, loss=2.7854950428009033
I0302 20:31:59.776301 140239850956544 logging_writer.py:48] [67600] global_step=67600, grad_norm=1.310577630996704, loss=2.188403606414795
I0302 20:32:45.039088 140239842563840 logging_writer.py:48] [67700] global_step=67700, grad_norm=1.5607612133026123, loss=2.332451581954956
I0302 20:33:30.260482 140239850956544 logging_writer.py:48] [67800] global_step=67800, grad_norm=1.3066240549087524, loss=2.1619954109191895
I0302 20:33:59.058624 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:34:09.093184 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:34:29.891597 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:34:31.519488 140437341357888 submission_runner.py:411] Time since start: 32513.07s, 	Step: 67866, 	{'train/accuracy': 0.7053515315055847, 'train/loss': 1.1844969987869263, 'validation/accuracy': 0.6496999859809875, 'validation/loss': 1.450947642326355, 'validation/num_examples': 50000, 'test/accuracy': 0.5210000276565552, 'test/loss': 2.1125617027282715, 'test/num_examples': 10000, 'score': 30292.256318330765, 'total_duration': 32513.07097506523, 'accumulated_submission_time': 30292.256318330765, 'accumulated_eval_time': 2213.2327523231506, 'accumulated_logging_time': 3.8478126525878906}
I0302 20:34:31.555923 140239842563840 logging_writer.py:48] [67866] accumulated_eval_time=2213.232752, accumulated_logging_time=3.847813, accumulated_submission_time=30292.256318, global_step=67866, preemption_count=0, score=30292.256318, test/accuracy=0.521000, test/loss=2.112562, test/num_examples=10000, total_duration=32513.070975, train/accuracy=0.705352, train/loss=1.184497, validation/accuracy=0.649700, validation/loss=1.450948, validation/num_examples=50000
I0302 20:34:45.446012 140239850956544 logging_writer.py:48] [67900] global_step=67900, grad_norm=1.1694735288619995, loss=2.8911192417144775
I0302 20:35:27.568585 140239842563840 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.0765275955200195, loss=3.4196462631225586
I0302 20:36:12.625029 140239850956544 logging_writer.py:48] [68100] global_step=68100, grad_norm=1.231544852256775, loss=2.530427932739258
I0302 20:36:57.569418 140239842563840 logging_writer.py:48] [68200] global_step=68200, grad_norm=1.0920077562332153, loss=3.079385995864868
I0302 20:37:42.778891 140239850956544 logging_writer.py:48] [68300] global_step=68300, grad_norm=1.1903132200241089, loss=3.625861883163452
I0302 20:38:27.530133 140239842563840 logging_writer.py:48] [68400] global_step=68400, grad_norm=1.405739188194275, loss=2.2015576362609863
I0302 20:39:12.391890 140239850956544 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.0945611000061035, loss=3.7662665843963623
I0302 20:39:57.101684 140239842563840 logging_writer.py:48] [68600] global_step=68600, grad_norm=1.3325846195220947, loss=4.393311500549316
I0302 20:40:42.409255 140239850956544 logging_writer.py:48] [68700] global_step=68700, grad_norm=1.1826454401016235, loss=2.019561767578125
I0302 20:41:27.738594 140239842563840 logging_writer.py:48] [68800] global_step=68800, grad_norm=1.0750055313110352, loss=2.888603925704956
I0302 20:41:31.931086 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:41:41.900135 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:42:02.075964 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:42:03.725001 140437341357888 submission_runner.py:411] Time since start: 32965.28s, 	Step: 68811, 	{'train/accuracy': 0.7294921875, 'train/loss': 1.0799065828323364, 'validation/accuracy': 0.6500200033187866, 'validation/loss': 1.4359275102615356, 'validation/num_examples': 50000, 'test/accuracy': 0.524399995803833, 'test/loss': 2.091939687728882, 'test/num_examples': 10000, 'score': 30712.568786621094, 'total_duration': 32965.27647805214, 'accumulated_submission_time': 30712.568786621094, 'accumulated_eval_time': 2245.0266540050507, 'accumulated_logging_time': 3.8953559398651123}
I0302 20:42:03.760233 140239850956544 logging_writer.py:48] [68811] accumulated_eval_time=2245.026654, accumulated_logging_time=3.895356, accumulated_submission_time=30712.568787, global_step=68811, preemption_count=0, score=30712.568787, test/accuracy=0.524400, test/loss=2.091940, test/num_examples=10000, total_duration=32965.276478, train/accuracy=0.729492, train/loss=1.079907, validation/accuracy=0.650020, validation/loss=1.435928, validation/num_examples=50000
I0302 20:42:39.640429 140239842563840 logging_writer.py:48] [68900] global_step=68900, grad_norm=1.182929277420044, loss=4.009276866912842
I0302 20:43:24.183063 140239850956544 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.3205281496047974, loss=2.3359901905059814
I0302 20:44:11.084567 140239842563840 logging_writer.py:48] [69100] global_step=69100, grad_norm=1.0747164487838745, loss=3.5801949501037598
I0302 20:44:56.136520 140239850956544 logging_writer.py:48] [69200] global_step=69200, grad_norm=1.440396785736084, loss=2.4673173427581787
I0302 20:45:41.545444 140239842563840 logging_writer.py:48] [69300] global_step=69300, grad_norm=1.117715835571289, loss=4.420896053314209
I0302 20:46:26.806699 140239850956544 logging_writer.py:48] [69400] global_step=69400, grad_norm=1.250051736831665, loss=2.1098344326019287
I0302 20:47:12.212931 140239842563840 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.2629021406173706, loss=2.140204668045044
I0302 20:47:57.570847 140239850956544 logging_writer.py:48] [69600] global_step=69600, grad_norm=1.3736097812652588, loss=2.2361862659454346
I0302 20:48:42.721459 140239842563840 logging_writer.py:48] [69700] global_step=69700, grad_norm=1.0952717065811157, loss=4.412018299102783
I0302 20:49:03.757378 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:49:13.880466 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:49:33.945200 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:49:35.569555 140437341357888 submission_runner.py:411] Time since start: 33417.12s, 	Step: 69748, 	{'train/accuracy': 0.6984961032867432, 'train/loss': 1.211103916168213, 'validation/accuracy': 0.6511600017547607, 'validation/loss': 1.4439362287521362, 'validation/num_examples': 50000, 'test/accuracy': 0.5236000418663025, 'test/loss': 2.12225604057312, 'test/num_examples': 10000, 'score': 31132.49741792679, 'total_duration': 33417.12102437019, 'accumulated_submission_time': 31132.49741792679, 'accumulated_eval_time': 2276.8387970924377, 'accumulated_logging_time': 3.9474518299102783}
I0302 20:49:35.606470 140239850956544 logging_writer.py:48] [69748] accumulated_eval_time=2276.838797, accumulated_logging_time=3.947452, accumulated_submission_time=31132.497418, global_step=69748, preemption_count=0, score=31132.497418, test/accuracy=0.523600, test/loss=2.122256, test/num_examples=10000, total_duration=33417.121024, train/accuracy=0.698496, train/loss=1.211104, validation/accuracy=0.651160, validation/loss=1.443936, validation/num_examples=50000
I0302 20:49:56.618530 140239842563840 logging_writer.py:48] [69800] global_step=69800, grad_norm=1.3005889654159546, loss=2.314328193664551
I0302 20:50:39.889698 140239850956544 logging_writer.py:48] [69900] global_step=69900, grad_norm=1.1982252597808838, loss=4.605134963989258
I0302 20:51:25.277926 140239842563840 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.2444888353347778, loss=2.9612984657287598
I0302 20:52:10.910336 140239850956544 logging_writer.py:48] [70100] global_step=70100, grad_norm=1.3872395753860474, loss=2.1994829177856445
I0302 20:52:55.896445 140239842563840 logging_writer.py:48] [70200] global_step=70200, grad_norm=1.5002636909484863, loss=2.3390772342681885
I0302 20:53:40.969884 140239850956544 logging_writer.py:48] [70300] global_step=70300, grad_norm=1.1573976278305054, loss=3.0185439586639404
I0302 20:54:26.025170 140239842563840 logging_writer.py:48] [70400] global_step=70400, grad_norm=1.2349451780319214, loss=2.3129847049713135
I0302 20:55:11.050167 140239850956544 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.243646264076233, loss=2.1499667167663574
I0302 20:55:56.137665 140239842563840 logging_writer.py:48] [70600] global_step=70600, grad_norm=1.1813712120056152, loss=3.56730055809021
I0302 20:56:35.711910 140437341357888 spec.py:321] Evaluating on the training split.
I0302 20:56:45.903697 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 20:57:05.169380 140437341357888 spec.py:349] Evaluating on the test split.
I0302 20:57:06.847875 140437341357888 submission_runner.py:411] Time since start: 33868.40s, 	Step: 70689, 	{'train/accuracy': 0.7059765458106995, 'train/loss': 1.168419361114502, 'validation/accuracy': 0.6503599882125854, 'validation/loss': 1.4337413311004639, 'validation/num_examples': 50000, 'test/accuracy': 0.5211000442504883, 'test/loss': 2.1125056743621826, 'test/num_examples': 10000, 'score': 31552.53966331482, 'total_duration': 33868.39933013916, 'accumulated_submission_time': 31552.53966331482, 'accumulated_eval_time': 2307.9747524261475, 'accumulated_logging_time': 3.9964959621429443}
I0302 20:57:06.883522 140239850956544 logging_writer.py:48] [70689] accumulated_eval_time=2307.974752, accumulated_logging_time=3.996496, accumulated_submission_time=31552.539663, global_step=70689, preemption_count=0, score=31552.539663, test/accuracy=0.521100, test/loss=2.112506, test/num_examples=10000, total_duration=33868.399330, train/accuracy=0.705977, train/loss=1.168419, validation/accuracy=0.650360, validation/loss=1.433741, validation/num_examples=50000
I0302 20:57:11.669807 140239842563840 logging_writer.py:48] [70700] global_step=70700, grad_norm=1.143261194229126, loss=3.985569477081299
I0302 20:57:51.917400 140239850956544 logging_writer.py:48] [70800] global_step=70800, grad_norm=1.2557415962219238, loss=2.304579973220825
I0302 20:58:37.275034 140239842563840 logging_writer.py:48] [70900] global_step=70900, grad_norm=1.3060904741287231, loss=2.1836671829223633
I0302 20:59:22.659839 140239850956544 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.2554348707199097, loss=2.9272308349609375
I0302 21:00:07.423509 140239842563840 logging_writer.py:48] [71100] global_step=71100, grad_norm=1.2139439582824707, loss=4.1071929931640625
I0302 21:00:52.426830 140239850956544 logging_writer.py:48] [71200] global_step=71200, grad_norm=1.1266063451766968, loss=3.531829833984375
I0302 21:01:38.151868 140239842563840 logging_writer.py:48] [71300] global_step=71300, grad_norm=1.190805435180664, loss=4.6492919921875
I0302 21:02:23.105518 140239850956544 logging_writer.py:48] [71400] global_step=71400, grad_norm=1.3415467739105225, loss=2.256889581680298
I0302 21:03:08.234619 140239842563840 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.4197731018066406, loss=2.057910680770874
I0302 21:03:53.288684 140239850956544 logging_writer.py:48] [71600] global_step=71600, grad_norm=1.2756640911102295, loss=2.220162868499756
I0302 21:04:06.956005 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:04:16.814274 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:04:37.440905 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:04:39.066393 140437341357888 submission_runner.py:411] Time since start: 34320.62s, 	Step: 71632, 	{'train/accuracy': 0.7135937213897705, 'train/loss': 1.1473480463027954, 'validation/accuracy': 0.6534000039100647, 'validation/loss': 1.4237979650497437, 'validation/num_examples': 50000, 'test/accuracy': 0.5218000411987305, 'test/loss': 2.1029539108276367, 'test/num_examples': 10000, 'score': 31972.546494960785, 'total_duration': 34320.61787605286, 'accumulated_submission_time': 31972.546494960785, 'accumulated_eval_time': 2340.085106611252, 'accumulated_logging_time': 4.0459089279174805}
I0302 21:04:39.098461 140239842563840 logging_writer.py:48] [71632] accumulated_eval_time=2340.085107, accumulated_logging_time=4.045909, accumulated_submission_time=31972.546495, global_step=71632, preemption_count=0, score=31972.546495, test/accuracy=0.521800, test/loss=2.102954, test/num_examples=10000, total_duration=34320.617876, train/accuracy=0.713594, train/loss=1.147348, validation/accuracy=0.653400, validation/loss=1.423798, validation/num_examples=50000
I0302 21:05:06.456221 140239850956544 logging_writer.py:48] [71700] global_step=71700, grad_norm=1.300876259803772, loss=4.706442832946777
I0302 21:05:51.151757 140239842563840 logging_writer.py:48] [71800] global_step=71800, grad_norm=1.4476838111877441, loss=2.1694934368133545
I0302 21:06:36.805438 140239850956544 logging_writer.py:48] [71900] global_step=71900, grad_norm=1.3236618041992188, loss=3.649378776550293
I0302 21:07:21.871637 140239842563840 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.347330927848816, loss=2.0613386631011963
I0302 21:08:07.009267 140239850956544 logging_writer.py:48] [72100] global_step=72100, grad_norm=1.31586754322052, loss=2.287057399749756
I0302 21:08:52.073134 140239842563840 logging_writer.py:48] [72200] global_step=72200, grad_norm=1.2498033046722412, loss=2.9696969985961914
I0302 21:09:37.265955 140239850956544 logging_writer.py:48] [72300] global_step=72300, grad_norm=1.1994870901107788, loss=2.3298068046569824
I0302 21:10:22.318148 140239842563840 logging_writer.py:48] [72400] global_step=72400, grad_norm=1.2307168245315552, loss=4.214555740356445
I0302 21:11:07.595457 140239850956544 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.2265453338623047, loss=2.9040606021881104
I0302 21:11:39.310444 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:11:49.619491 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:12:09.668477 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:12:11.296639 140437341357888 submission_runner.py:411] Time since start: 34772.85s, 	Step: 72572, 	{'train/accuracy': 0.6991015672683716, 'train/loss': 1.2266145944595337, 'validation/accuracy': 0.6523399949073792, 'validation/loss': 1.445721983909607, 'validation/num_examples': 50000, 'test/accuracy': 0.5273000001907349, 'test/loss': 2.112567186355591, 'test/num_examples': 10000, 'score': 32392.69544196129, 'total_duration': 34772.84811258316, 'accumulated_submission_time': 32392.69544196129, 'accumulated_eval_time': 2372.071283340454, 'accumulated_logging_time': 4.090409517288208}
I0302 21:12:11.328929 140239842563840 logging_writer.py:48] [72572] accumulated_eval_time=2372.071283, accumulated_logging_time=4.090410, accumulated_submission_time=32392.695442, global_step=72572, preemption_count=0, score=32392.695442, test/accuracy=0.527300, test/loss=2.112567, test/num_examples=10000, total_duration=34772.848113, train/accuracy=0.699102, train/loss=1.226615, validation/accuracy=0.652340, validation/loss=1.445722, validation/num_examples=50000
I0302 21:12:22.852117 140239850956544 logging_writer.py:48] [72600] global_step=72600, grad_norm=1.1844992637634277, loss=4.255527973175049
I0302 21:13:05.614480 140239842563840 logging_writer.py:48] [72700] global_step=72700, grad_norm=1.2267206907272339, loss=2.800977945327759
I0302 21:13:51.077860 140239850956544 logging_writer.py:48] [72800] global_step=72800, grad_norm=1.3030223846435547, loss=2.170630931854248
I0302 21:14:36.186615 140239842563840 logging_writer.py:48] [72900] global_step=72900, grad_norm=1.39617919921875, loss=2.143623113632202
I0302 21:15:21.320173 140239850956544 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.3737252950668335, loss=2.006301164627075
I0302 21:16:06.440155 140239842563840 logging_writer.py:48] [73100] global_step=73100, grad_norm=1.3189109563827515, loss=2.507847785949707
I0302 21:16:51.666054 140239850956544 logging_writer.py:48] [73200] global_step=73200, grad_norm=1.219249963760376, loss=4.75626277923584
I0302 21:17:36.949613 140239842563840 logging_writer.py:48] [73300] global_step=73300, grad_norm=1.4116787910461426, loss=2.2320191860198975
I0302 21:18:22.232128 140239850956544 logging_writer.py:48] [73400] global_step=73400, grad_norm=1.2601041793823242, loss=2.9083468914031982
I0302 21:19:07.741817 140239842563840 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.3056520223617554, loss=2.134216785430908
I0302 21:19:11.531758 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:19:21.540035 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:19:41.504620 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:19:43.126195 140437341357888 submission_runner.py:411] Time since start: 35224.68s, 	Step: 73510, 	{'train/accuracy': 0.7064843773841858, 'train/loss': 1.1597418785095215, 'validation/accuracy': 0.651919960975647, 'validation/loss': 1.4081584215164185, 'validation/num_examples': 50000, 'test/accuracy': 0.5275000333786011, 'test/loss': 2.077162504196167, 'test/num_examples': 10000, 'score': 32812.83591794968, 'total_duration': 35224.67768549919, 'accumulated_submission_time': 32812.83591794968, 'accumulated_eval_time': 2403.665696620941, 'accumulated_logging_time': 4.1330084800720215}
I0302 21:19:43.158688 140239850956544 logging_writer.py:48] [73510] accumulated_eval_time=2403.665697, accumulated_logging_time=4.133008, accumulated_submission_time=32812.835918, global_step=73510, preemption_count=0, score=32812.835918, test/accuracy=0.527500, test/loss=2.077163, test/num_examples=10000, total_duration=35224.677685, train/accuracy=0.706484, train/loss=1.159742, validation/accuracy=0.651920, validation/loss=1.408158, validation/num_examples=50000
I0302 21:20:19.863156 140239842563840 logging_writer.py:48] [73600] global_step=73600, grad_norm=1.1758836507797241, loss=3.1072258949279785
I0302 21:21:04.631570 140239850956544 logging_writer.py:48] [73700] global_step=73700, grad_norm=1.206216812133789, loss=2.638800621032715
I0302 21:21:49.917122 140239842563840 logging_writer.py:48] [73800] global_step=73800, grad_norm=1.220450758934021, loss=3.6795828342437744
I0302 21:22:35.099471 140239850956544 logging_writer.py:48] [73900] global_step=73900, grad_norm=1.354568600654602, loss=4.296753883361816
I0302 21:23:20.237589 140239842563840 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.1042560338974, loss=3.0735225677490234
I0302 21:24:05.516462 140239850956544 logging_writer.py:48] [74100] global_step=74100, grad_norm=1.312025785446167, loss=2.2716214656829834
I0302 21:24:50.592431 140239842563840 logging_writer.py:48] [74200] global_step=74200, grad_norm=1.1956034898757935, loss=4.227185249328613
I0302 21:25:35.675579 140239850956544 logging_writer.py:48] [74300] global_step=74300, grad_norm=1.307681679725647, loss=2.3113815784454346
I0302 21:26:20.887586 140239842563840 logging_writer.py:48] [74400] global_step=74400, grad_norm=1.3583155870437622, loss=2.2815890312194824
I0302 21:26:43.247435 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:26:53.333828 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:27:19.500424 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:27:21.125591 140437341357888 submission_runner.py:411] Time since start: 35682.68s, 	Step: 74451, 	{'train/accuracy': 0.7114648222923279, 'train/loss': 1.1783130168914795, 'validation/accuracy': 0.652899980545044, 'validation/loss': 1.4420287609100342, 'validation/num_examples': 50000, 'test/accuracy': 0.5303000211715698, 'test/loss': 2.1065101623535156, 'test/num_examples': 10000, 'score': 33232.861943244934, 'total_duration': 35682.67705178261, 'accumulated_submission_time': 33232.861943244934, 'accumulated_eval_time': 2441.54381275177, 'accumulated_logging_time': 4.176920413970947}
I0302 21:27:21.157064 140239850956544 logging_writer.py:48] [74451] accumulated_eval_time=2441.543813, accumulated_logging_time=4.176920, accumulated_submission_time=33232.861943, global_step=74451, preemption_count=0, score=33232.861943, test/accuracy=0.530300, test/loss=2.106510, test/num_examples=10000, total_duration=35682.677052, train/accuracy=0.711465, train/loss=1.178313, validation/accuracy=0.652900, validation/loss=1.442029, validation/num_examples=50000
I0302 21:27:40.987032 140239842563840 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.3271491527557373, loss=2.2066702842712402
I0302 21:28:22.551626 140239850956544 logging_writer.py:48] [74600] global_step=74600, grad_norm=1.5676255226135254, loss=2.1072871685028076
I0302 21:29:08.508094 140239842563840 logging_writer.py:48] [74700] global_step=74700, grad_norm=1.2419686317443848, loss=2.9346847534179688
I0302 21:29:53.419920 140239850956544 logging_writer.py:48] [74800] global_step=74800, grad_norm=1.2647360563278198, loss=2.1616194248199463
I0302 21:30:38.130248 140239842563840 logging_writer.py:48] [74900] global_step=74900, grad_norm=1.2778241634368896, loss=2.4773669242858887
I0302 21:31:23.499548 140239850956544 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.2181063890457153, loss=3.159823417663574
I0302 21:32:08.986717 140239842563840 logging_writer.py:48] [75100] global_step=75100, grad_norm=1.358521580696106, loss=2.066460132598877
I0302 21:32:53.814770 140239850956544 logging_writer.py:48] [75200] global_step=75200, grad_norm=1.1225810050964355, loss=3.383692502975464
I0302 21:33:39.178735 140239842563840 logging_writer.py:48] [75300] global_step=75300, grad_norm=1.391989827156067, loss=2.1958906650543213
I0302 21:34:21.526417 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:34:31.376083 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:34:51.780421 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:34:53.407836 140437341357888 submission_runner.py:411] Time since start: 36134.96s, 	Step: 75395, 	{'train/accuracy': 0.7361718416213989, 'train/loss': 1.0584875345230103, 'validation/accuracy': 0.6551799774169922, 'validation/loss': 1.4225327968597412, 'validation/num_examples': 50000, 'test/accuracy': 0.5238000154495239, 'test/loss': 2.119074583053589, 'test/num_examples': 10000, 'score': 33653.16945314407, 'total_duration': 36134.95932555199, 'accumulated_submission_time': 33653.16945314407, 'accumulated_eval_time': 2473.425219774246, 'accumulated_logging_time': 4.219008684158325}
I0302 21:34:53.440010 140239850956544 logging_writer.py:48] [75395] accumulated_eval_time=2473.425220, accumulated_logging_time=4.219009, accumulated_submission_time=33653.169453, global_step=75395, preemption_count=0, score=33653.169453, test/accuracy=0.523800, test/loss=2.119075, test/num_examples=10000, total_duration=36134.959326, train/accuracy=0.736172, train/loss=1.058488, validation/accuracy=0.655180, validation/loss=1.422533, validation/num_examples=50000
I0302 21:34:55.835349 140239842563840 logging_writer.py:48] [75400] global_step=75400, grad_norm=1.3552016019821167, loss=4.434432506561279
I0302 21:35:36.921291 140239842563840 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.228492259979248, loss=3.2314646244049072
I0302 21:36:22.259354 140239850956544 logging_writer.py:48] [75600] global_step=75600, grad_norm=1.1745116710662842, loss=2.985067129135132
I0302 21:37:07.672903 140239842563840 logging_writer.py:48] [75700] global_step=75700, grad_norm=1.1510752439498901, loss=4.038326263427734
I0302 21:37:52.743086 140239850956544 logging_writer.py:48] [75800] global_step=75800, grad_norm=1.239364743232727, loss=2.8983917236328125
I0302 21:38:38.093096 140239842563840 logging_writer.py:48] [75900] global_step=75900, grad_norm=1.390681266784668, loss=2.4709060192108154
I0302 21:39:23.495929 140239850956544 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.3893088102340698, loss=4.647553443908691
I0302 21:40:08.629598 140239842563840 logging_writer.py:48] [76100] global_step=76100, grad_norm=1.312437891960144, loss=2.1306581497192383
I0302 21:40:53.673205 140239850956544 logging_writer.py:48] [76200] global_step=76200, grad_norm=1.1843059062957764, loss=2.9275007247924805
I0302 21:41:39.072298 140239842563840 logging_writer.py:48] [76300] global_step=76300, grad_norm=1.3195265531539917, loss=2.1927199363708496
I0302 21:41:53.838428 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:42:04.399543 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:42:25.035896 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:42:26.663578 140437341357888 submission_runner.py:411] Time since start: 36588.22s, 	Step: 76333, 	{'train/accuracy': 0.7122265696525574, 'train/loss': 1.1508327722549438, 'validation/accuracy': 0.658840000629425, 'validation/loss': 1.3871424198150635, 'validation/num_examples': 50000, 'test/accuracy': 0.5350000262260437, 'test/loss': 2.0444717407226562, 'test/num_examples': 10000, 'score': 34073.50621318817, 'total_duration': 36588.21505665779, 'accumulated_submission_time': 34073.50621318817, 'accumulated_eval_time': 2506.2503504753113, 'accumulated_logging_time': 4.261711597442627}
I0302 21:42:26.699363 140239850956544 logging_writer.py:48] [76333] accumulated_eval_time=2506.250350, accumulated_logging_time=4.261712, accumulated_submission_time=34073.506213, global_step=76333, preemption_count=0, score=34073.506213, test/accuracy=0.535000, test/loss=2.044472, test/num_examples=10000, total_duration=36588.215057, train/accuracy=0.712227, train/loss=1.150833, validation/accuracy=0.658840, validation/loss=1.387142, validation/num_examples=50000
I0302 21:42:53.896016 140239842563840 logging_writer.py:48] [76400] global_step=76400, grad_norm=1.2926841974258423, loss=2.1233553886413574
I0302 21:43:39.058507 140239850956544 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.4365720748901367, loss=2.294689416885376
I0302 21:44:24.007824 140239842563840 logging_writer.py:48] [76600] global_step=76600, grad_norm=1.3787140846252441, loss=2.386465549468994
I0302 21:45:09.371892 140239850956544 logging_writer.py:48] [76700] global_step=76700, grad_norm=1.1757491827011108, loss=2.4795918464660645
I0302 21:45:54.492985 140239842563840 logging_writer.py:48] [76800] global_step=76800, grad_norm=1.4322959184646606, loss=2.1419124603271484
I0302 21:46:39.931435 140239850956544 logging_writer.py:48] [76900] global_step=76900, grad_norm=1.5731563568115234, loss=2.278079032897949
I0302 21:47:25.071010 140239842563840 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.4697144031524658, loss=2.453843593597412
I0302 21:48:10.335281 140239850956544 logging_writer.py:48] [77100] global_step=77100, grad_norm=1.2938809394836426, loss=2.713914155960083
I0302 21:48:55.651645 140239842563840 logging_writer.py:48] [77200] global_step=77200, grad_norm=1.5798969268798828, loss=2.2141947746276855
I0302 21:49:26.780313 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:49:36.834947 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:50:02.589346 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:50:04.222978 140437341357888 submission_runner.py:411] Time since start: 37045.77s, 	Step: 77270, 	{'train/accuracy': 0.7195898294448853, 'train/loss': 1.1208205223083496, 'validation/accuracy': 0.6632800102233887, 'validation/loss': 1.391443133354187, 'validation/num_examples': 50000, 'test/accuracy': 0.5396000146865845, 'test/loss': 2.0465617179870605, 'test/num_examples': 10000, 'score': 34493.52569794655, 'total_duration': 37045.77448058128, 'accumulated_submission_time': 34493.52569794655, 'accumulated_eval_time': 2543.693027973175, 'accumulated_logging_time': 4.307955265045166}
I0302 21:50:04.254066 140239850956544 logging_writer.py:48] [77270] accumulated_eval_time=2543.693028, accumulated_logging_time=4.307955, accumulated_submission_time=34493.525698, global_step=77270, preemption_count=0, score=34493.525698, test/accuracy=0.539600, test/loss=2.046562, test/num_examples=10000, total_duration=37045.774481, train/accuracy=0.719590, train/loss=1.120821, validation/accuracy=0.663280, validation/loss=1.391443, validation/num_examples=50000
I0302 21:50:16.539370 140239842563840 logging_writer.py:48] [77300] global_step=77300, grad_norm=1.3992708921432495, loss=2.3929998874664307
I0302 21:50:57.683033 140239850956544 logging_writer.py:48] [77400] global_step=77400, grad_norm=1.2460559606552124, loss=4.049859046936035
I0302 21:51:42.478638 140239842563840 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.3395073413848877, loss=4.681262969970703
I0302 21:52:27.939104 140239850956544 logging_writer.py:48] [77600] global_step=77600, grad_norm=1.2653676271438599, loss=2.2970962524414062
I0302 21:53:13.181527 140239842563840 logging_writer.py:48] [77700] global_step=77700, grad_norm=1.3381805419921875, loss=2.298034906387329
I0302 21:53:58.140544 140239850956544 logging_writer.py:48] [77800] global_step=77800, grad_norm=1.2316827774047852, loss=4.466701507568359
I0302 21:54:43.246448 140239842563840 logging_writer.py:48] [77900] global_step=77900, grad_norm=1.2585341930389404, loss=2.700815439224243
I0302 21:55:27.986707 140239850956544 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.2246559858322144, loss=3.4543850421905518
I0302 21:56:13.256679 140239842563840 logging_writer.py:48] [78100] global_step=78100, grad_norm=1.45770263671875, loss=2.2087314128875732
I0302 21:56:58.409094 140239850956544 logging_writer.py:48] [78200] global_step=78200, grad_norm=1.2876439094543457, loss=2.477185010910034
I0302 21:57:04.466977 140437341357888 spec.py:321] Evaluating on the training split.
I0302 21:57:14.472070 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 21:57:35.739086 140437341357888 spec.py:349] Evaluating on the test split.
I0302 21:57:37.355660 140437341357888 submission_runner.py:411] Time since start: 37498.91s, 	Step: 78215, 	{'train/accuracy': 0.7258203029632568, 'train/loss': 1.1131298542022705, 'validation/accuracy': 0.6583600044250488, 'validation/loss': 1.4111359119415283, 'validation/num_examples': 50000, 'test/accuracy': 0.5385000109672546, 'test/loss': 2.0573971271514893, 'test/num_examples': 10000, 'score': 34913.678639411926, 'total_duration': 37498.90714406967, 'accumulated_submission_time': 34913.678639411926, 'accumulated_eval_time': 2576.5816905498505, 'accumulated_logging_time': 4.3477983474731445}
I0302 21:57:37.388371 140239842563840 logging_writer.py:48] [78215] accumulated_eval_time=2576.581691, accumulated_logging_time=4.347798, accumulated_submission_time=34913.678639, global_step=78215, preemption_count=0, score=34913.678639, test/accuracy=0.538500, test/loss=2.057397, test/num_examples=10000, total_duration=37498.907144, train/accuracy=0.725820, train/loss=1.113130, validation/accuracy=0.658360, validation/loss=1.411136, validation/num_examples=50000
I0302 21:58:11.685724 140239850956544 logging_writer.py:48] [78300] global_step=78300, grad_norm=1.3838999271392822, loss=2.661396026611328
I0302 21:58:56.586858 140239842563840 logging_writer.py:48] [78400] global_step=78400, grad_norm=1.3003746271133423, loss=2.2796719074249268
I0302 21:59:41.861976 140239850956544 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.1746437549591064, loss=3.0977532863616943
I0302 22:00:27.054064 140239842563840 logging_writer.py:48] [78600] global_step=78600, grad_norm=1.3303866386413574, loss=4.6935906410217285
I0302 22:01:12.052211 140239850956544 logging_writer.py:48] [78700] global_step=78700, grad_norm=1.341422438621521, loss=2.6962575912475586
I0302 22:01:56.972908 140239842563840 logging_writer.py:48] [78800] global_step=78800, grad_norm=1.3440874814987183, loss=2.6120986938476562
I0302 22:02:42.649685 140239850956544 logging_writer.py:48] [78900] global_step=78900, grad_norm=1.3372423648834229, loss=4.59792423248291
I0302 22:03:27.821341 140239842563840 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.4029995203018188, loss=2.494095802307129
I0302 22:04:12.785094 140239850956544 logging_writer.py:48] [79100] global_step=79100, grad_norm=1.3151540756225586, loss=2.0490236282348633
I0302 22:04:37.721160 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:04:48.196449 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:05:11.031281 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:05:12.652012 140437341357888 submission_runner.py:411] Time since start: 37954.20s, 	Step: 79157, 	{'train/accuracy': 0.7126757502555847, 'train/loss': 1.168033480644226, 'validation/accuracy': 0.6606799960136414, 'validation/loss': 1.408635139465332, 'validation/num_examples': 50000, 'test/accuracy': 0.5360000133514404, 'test/loss': 2.062854766845703, 'test/num_examples': 10000, 'score': 35333.94675087929, 'total_duration': 37954.20350050926, 'accumulated_submission_time': 35333.94675087929, 'accumulated_eval_time': 2611.512553215027, 'accumulated_logging_time': 4.392807483673096}
I0302 22:05:12.685170 140239842563840 logging_writer.py:48] [79157] accumulated_eval_time=2611.512553, accumulated_logging_time=4.392807, accumulated_submission_time=35333.946751, global_step=79157, preemption_count=0, score=35333.946751, test/accuracy=0.536000, test/loss=2.062855, test/num_examples=10000, total_duration=37954.203501, train/accuracy=0.712676, train/loss=1.168033, validation/accuracy=0.660680, validation/loss=1.408635, validation/num_examples=50000
I0302 22:05:30.137845 140239850956544 logging_writer.py:48] [79200] global_step=79200, grad_norm=1.1449567079544067, loss=4.240379810333252
I0302 22:06:12.504574 140239842563840 logging_writer.py:48] [79300] global_step=79300, grad_norm=1.1943650245666504, loss=4.163761138916016
I0302 22:06:57.872744 140239850956544 logging_writer.py:48] [79400] global_step=79400, grad_norm=1.182063102722168, loss=3.962655544281006
I0302 22:07:42.951394 140239842563840 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.4428356885910034, loss=2.216301441192627
I0302 22:08:28.198255 140239850956544 logging_writer.py:48] [79600] global_step=79600, grad_norm=1.2077267169952393, loss=4.2127227783203125
I0302 22:09:13.454778 140239842563840 logging_writer.py:48] [79700] global_step=79700, grad_norm=1.3302443027496338, loss=2.1304187774658203
I0302 22:09:58.495748 140239850956544 logging_writer.py:48] [79800] global_step=79800, grad_norm=1.2874393463134766, loss=2.631145477294922
I0302 22:10:43.516410 140239842563840 logging_writer.py:48] [79900] global_step=79900, grad_norm=1.181888222694397, loss=2.622748374938965
I0302 22:11:28.495918 140239850956544 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.1917383670806885, loss=3.133053779602051
I0302 22:12:12.773900 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:12:22.669898 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:12:47.768707 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:12:49.389868 140437341357888 submission_runner.py:411] Time since start: 38410.94s, 	Step: 80099, 	{'train/accuracy': 0.71546870470047, 'train/loss': 1.14302659034729, 'validation/accuracy': 0.6597599983215332, 'validation/loss': 1.3939063549041748, 'validation/num_examples': 50000, 'test/accuracy': 0.5321000218391418, 'test/loss': 2.0679373741149902, 'test/num_examples': 10000, 'score': 35753.97294163704, 'total_duration': 38410.941356658936, 'accumulated_submission_time': 35753.97294163704, 'accumulated_eval_time': 2648.1285173892975, 'accumulated_logging_time': 4.436190128326416}
I0302 22:12:49.417973 140239842563840 logging_writer.py:48] [80099] accumulated_eval_time=2648.128517, accumulated_logging_time=4.436190, accumulated_submission_time=35753.972942, global_step=80099, preemption_count=0, score=35753.972942, test/accuracy=0.532100, test/loss=2.067937, test/num_examples=10000, total_duration=38410.941357, train/accuracy=0.715469, train/loss=1.143027, validation/accuracy=0.659760, validation/loss=1.393906, validation/num_examples=50000
I0302 22:12:50.217141 140239850956544 logging_writer.py:48] [80100] global_step=80100, grad_norm=1.3753914833068848, loss=3.488145589828491
I0302 22:13:30.212074 140239842563840 logging_writer.py:48] [80200] global_step=80200, grad_norm=1.3953862190246582, loss=2.251142740249634
I0302 22:14:15.340080 140239850956544 logging_writer.py:48] [80300] global_step=80300, grad_norm=1.3642818927764893, loss=2.2821526527404785
I0302 22:15:00.351502 140239842563840 logging_writer.py:48] [80400] global_step=80400, grad_norm=1.1736457347869873, loss=3.354788064956665
I0302 22:15:45.636043 140239850956544 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.2763822078704834, loss=2.305593490600586
I0302 22:16:30.909819 140239842563840 logging_writer.py:48] [80600] global_step=80600, grad_norm=1.3369626998901367, loss=2.104849100112915
I0302 22:17:16.149815 140239850956544 logging_writer.py:48] [80700] global_step=80700, grad_norm=1.3526397943496704, loss=2.0387277603149414
I0302 22:18:01.033367 140239842563840 logging_writer.py:48] [80800] global_step=80800, grad_norm=1.3537511825561523, loss=2.6203091144561768
I0302 22:18:46.140946 140239850956544 logging_writer.py:48] [80900] global_step=80900, grad_norm=1.3188188076019287, loss=2.0065672397613525
I0302 22:19:31.154821 140239842563840 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.1444767713546753, loss=3.5728931427001953
I0302 22:19:49.798321 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:20:00.091816 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:20:20.981283 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:20:22.610054 140437341357888 submission_runner.py:411] Time since start: 38864.16s, 	Step: 81043, 	{'train/accuracy': 0.7226366996765137, 'train/loss': 1.1191169023513794, 'validation/accuracy': 0.6619600057601929, 'validation/loss': 1.3967500925064087, 'validation/num_examples': 50000, 'test/accuracy': 0.5390000343322754, 'test/loss': 2.057657480239868, 'test/num_examples': 10000, 'score': 36174.29339551926, 'total_duration': 38864.1615319252, 'accumulated_submission_time': 36174.29339551926, 'accumulated_eval_time': 2680.9402170181274, 'accumulated_logging_time': 4.473475933074951}
I0302 22:20:22.645131 140239850956544 logging_writer.py:48] [81043] accumulated_eval_time=2680.940217, accumulated_logging_time=4.473476, accumulated_submission_time=36174.293396, global_step=81043, preemption_count=0, score=36174.293396, test/accuracy=0.539000, test/loss=2.057657, test/num_examples=10000, total_duration=38864.161532, train/accuracy=0.722637, train/loss=1.119117, validation/accuracy=0.661960, validation/loss=1.396750, validation/num_examples=50000
I0302 22:20:45.619996 140239842563840 logging_writer.py:48] [81100] global_step=81100, grad_norm=1.230281949043274, loss=2.323014497756958
I0302 22:21:30.195562 140239850956544 logging_writer.py:48] [81200] global_step=81200, grad_norm=1.3999252319335938, loss=2.0203893184661865
I0302 22:22:15.170675 140239842563840 logging_writer.py:48] [81300] global_step=81300, grad_norm=1.3942985534667969, loss=2.0656445026397705
I0302 22:23:00.793844 140239850956544 logging_writer.py:48] [81400] global_step=81400, grad_norm=1.1558388471603394, loss=2.5865724086761475
I0302 22:23:45.892493 140239842563840 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.4150059223175049, loss=2.1974222660064697
I0302 22:24:31.067699 140239850956544 logging_writer.py:48] [81600] global_step=81600, grad_norm=1.5289288759231567, loss=2.037646770477295
I0302 22:25:16.305348 140239842563840 logging_writer.py:48] [81700] global_step=81700, grad_norm=1.3040940761566162, loss=2.5215506553649902
I0302 22:26:01.387983 140239850956544 logging_writer.py:48] [81800] global_step=81800, grad_norm=1.262986183166504, loss=2.06374192237854
I0302 22:26:46.681900 140239842563840 logging_writer.py:48] [81900] global_step=81900, grad_norm=1.351035714149475, loss=2.175607442855835
I0302 22:27:22.851345 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:27:33.285335 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:27:54.391789 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:27:56.014341 140437341357888 submission_runner.py:411] Time since start: 39317.57s, 	Step: 81982, 	{'train/accuracy': 0.7477148175239563, 'train/loss': 1.0231945514678955, 'validation/accuracy': 0.6630799770355225, 'validation/loss': 1.392142415046692, 'validation/num_examples': 50000, 'test/accuracy': 0.5347000360488892, 'test/loss': 2.0538101196289062, 'test/num_examples': 10000, 'score': 36594.43833613396, 'total_duration': 39317.565828323364, 'accumulated_submission_time': 36594.43833613396, 'accumulated_eval_time': 2714.103229045868, 'accumulated_logging_time': 4.518529653549194}
I0302 22:27:56.047464 140239850956544 logging_writer.py:48] [81982] accumulated_eval_time=2714.103229, accumulated_logging_time=4.518530, accumulated_submission_time=36594.438336, global_step=81982, preemption_count=0, score=36594.438336, test/accuracy=0.534700, test/loss=2.053810, test/num_examples=10000, total_duration=39317.565828, train/accuracy=0.747715, train/loss=1.023195, validation/accuracy=0.663080, validation/loss=1.392142, validation/num_examples=50000
I0302 22:28:03.594500 140239842563840 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.2658299207687378, loss=4.535965919494629
I0302 22:28:44.892841 140239850956544 logging_writer.py:48] [82100] global_step=82100, grad_norm=1.4115675687789917, loss=2.1305463314056396
I0302 22:29:30.123393 140239842563840 logging_writer.py:48] [82200] global_step=82200, grad_norm=1.250750184059143, loss=2.2505526542663574
I0302 22:30:15.480537 140239850956544 logging_writer.py:48] [82300] global_step=82300, grad_norm=1.3088135719299316, loss=2.245246648788452
I0302 22:30:59.964082 140239842563840 logging_writer.py:48] [82400] global_step=82400, grad_norm=1.2853955030441284, loss=2.3200600147247314
I0302 22:31:44.997258 140239850956544 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.431079626083374, loss=2.057360887527466
I0302 22:32:30.495429 140239842563840 logging_writer.py:48] [82600] global_step=82600, grad_norm=1.3743155002593994, loss=1.9894061088562012
I0302 22:33:15.724514 140239850956544 logging_writer.py:48] [82700] global_step=82700, grad_norm=1.3541011810302734, loss=2.325371503829956
I0302 22:34:00.821539 140239842563840 logging_writer.py:48] [82800] global_step=82800, grad_norm=1.2360421419143677, loss=1.97416353225708
I0302 22:34:45.900681 140239850956544 logging_writer.py:48] [82900] global_step=82900, grad_norm=1.2980797290802002, loss=2.4025723934173584
I0302 22:34:56.109966 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:35:06.328577 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:35:30.207648 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:35:31.827601 140437341357888 submission_runner.py:411] Time since start: 39773.38s, 	Step: 82924, 	{'train/accuracy': 0.7239843606948853, 'train/loss': 1.1104586124420166, 'validation/accuracy': 0.6676200032234192, 'validation/loss': 1.363040804862976, 'validation/num_examples': 50000, 'test/accuracy': 0.5391000509262085, 'test/loss': 2.0352330207824707, 'test/num_examples': 10000, 'score': 37014.43953371048, 'total_duration': 39773.3790769577, 'accumulated_submission_time': 37014.43953371048, 'accumulated_eval_time': 2749.8208360671997, 'accumulated_logging_time': 4.561380863189697}
I0302 22:35:31.864408 140239842563840 logging_writer.py:48] [82924] accumulated_eval_time=2749.820836, accumulated_logging_time=4.561381, accumulated_submission_time=37014.439534, global_step=82924, preemption_count=0, score=37014.439534, test/accuracy=0.539100, test/loss=2.035233, test/num_examples=10000, total_duration=39773.379077, train/accuracy=0.723984, train/loss=1.110459, validation/accuracy=0.667620, validation/loss=1.363041, validation/num_examples=50000
I0302 22:36:02.381906 140239850956544 logging_writer.py:48] [83000] global_step=83000, grad_norm=1.3777574300765991, loss=2.651782274246216
I0302 22:36:47.425380 140239842563840 logging_writer.py:48] [83100] global_step=83100, grad_norm=1.3796418905258179, loss=2.1411852836608887
I0302 22:37:32.738838 140239850956544 logging_writer.py:48] [83200] global_step=83200, grad_norm=1.3736677169799805, loss=2.112201690673828
I0302 22:38:17.763314 140239842563840 logging_writer.py:48] [83300] global_step=83300, grad_norm=1.422985315322876, loss=1.993402123451233
I0302 22:39:02.811250 140239850956544 logging_writer.py:48] [83400] global_step=83400, grad_norm=1.325892686843872, loss=2.0952954292297363
I0302 22:39:47.934644 140239842563840 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.1615750789642334, loss=4.517669677734375
I0302 22:40:33.063603 140239850956544 logging_writer.py:48] [83600] global_step=83600, grad_norm=1.364463448524475, loss=2.4784750938415527
I0302 22:41:18.338245 140239842563840 logging_writer.py:48] [83700] global_step=83700, grad_norm=1.4036552906036377, loss=2.0412116050720215
I0302 22:42:03.453788 140239850956544 logging_writer.py:48] [83800] global_step=83800, grad_norm=1.3236653804779053, loss=3.046154737472534
I0302 22:42:32.222685 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:42:42.406853 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:43:02.712575 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:43:04.381609 140437341357888 submission_runner.py:411] Time since start: 40225.93s, 	Step: 83865, 	{'train/accuracy': 0.7298241853713989, 'train/loss': 1.0960992574691772, 'validation/accuracy': 0.6693199872970581, 'validation/loss': 1.3602654933929443, 'validation/num_examples': 50000, 'test/accuracy': 0.5454000234603882, 'test/loss': 2.023963689804077, 'test/num_examples': 10000, 'score': 37434.735203027725, 'total_duration': 40225.933086156845, 'accumulated_submission_time': 37434.735203027725, 'accumulated_eval_time': 2781.979739665985, 'accumulated_logging_time': 4.608523607254028}
I0302 22:43:04.420580 140239842563840 logging_writer.py:48] [83865] accumulated_eval_time=2781.979740, accumulated_logging_time=4.608524, accumulated_submission_time=37434.735203, global_step=83865, preemption_count=0, score=37434.735203, test/accuracy=0.545400, test/loss=2.023964, test/num_examples=10000, total_duration=40225.933086, train/accuracy=0.729824, train/loss=1.096099, validation/accuracy=0.669320, validation/loss=1.360265, validation/num_examples=50000
I0302 22:43:18.709958 140239850956544 logging_writer.py:48] [83900] global_step=83900, grad_norm=1.3393073081970215, loss=2.144726276397705
I0302 22:44:00.855468 140239842563840 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.4130090475082397, loss=2.3074300289154053
I0302 22:44:45.968720 140239850956544 logging_writer.py:48] [84100] global_step=84100, grad_norm=1.367795467376709, loss=2.0858383178710938
I0302 22:45:31.034603 140239842563840 logging_writer.py:48] [84200] global_step=84200, grad_norm=1.2355879545211792, loss=3.1477200984954834
I0302 22:46:16.383563 140239850956544 logging_writer.py:48] [84300] global_step=84300, grad_norm=1.3471049070358276, loss=2.617487907409668
I0302 22:47:01.743761 140239842563840 logging_writer.py:48] [84400] global_step=84400, grad_norm=1.3903709650039673, loss=1.9697068929672241
I0302 22:47:46.760896 140239850956544 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.2971547842025757, loss=4.033819675445557
I0302 22:48:32.150854 140239842563840 logging_writer.py:48] [84600] global_step=84600, grad_norm=1.405126929283142, loss=2.0873947143554688
I0302 22:49:17.247596 140239850956544 logging_writer.py:48] [84700] global_step=84700, grad_norm=1.401557445526123, loss=3.1670989990234375
I0302 22:50:02.461630 140239842563840 logging_writer.py:48] [84800] global_step=84800, grad_norm=1.472502589225769, loss=2.2433626651763916
I0302 22:50:04.440858 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:50:14.586920 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:50:34.053080 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:50:35.678474 140437341357888 submission_runner.py:411] Time since start: 40677.23s, 	Step: 84806, 	{'train/accuracy': 0.73451167345047, 'train/loss': 1.0335588455200195, 'validation/accuracy': 0.6688599586486816, 'validation/loss': 1.3441568613052368, 'validation/num_examples': 50000, 'test/accuracy': 0.5470000505447388, 'test/loss': 2.004969358444214, 'test/num_examples': 10000, 'score': 37854.68165183067, 'total_duration': 40677.22996091843, 'accumulated_submission_time': 37854.68165183067, 'accumulated_eval_time': 2813.217336177826, 'accumulated_logging_time': 4.663280725479126}
I0302 22:50:35.714813 140239850956544 logging_writer.py:48] [84806] accumulated_eval_time=2813.217336, accumulated_logging_time=4.663281, accumulated_submission_time=37854.681652, global_step=84806, preemption_count=0, score=37854.681652, test/accuracy=0.547000, test/loss=2.004969, test/num_examples=10000, total_duration=40677.229961, train/accuracy=0.734512, train/loss=1.033559, validation/accuracy=0.668860, validation/loss=1.344157, validation/num_examples=50000
I0302 22:51:14.556519 140239842563840 logging_writer.py:48] [84900] global_step=84900, grad_norm=1.4652347564697266, loss=2.214015245437622
I0302 22:51:59.385142 140239850956544 logging_writer.py:48] [85000] global_step=85000, grad_norm=1.2608518600463867, loss=4.120285511016846
I0302 22:52:44.883404 140239842563840 logging_writer.py:48] [85100] global_step=85100, grad_norm=1.1449229717254639, loss=3.6255712509155273
I0302 22:53:29.964364 140239850956544 logging_writer.py:48] [85200] global_step=85200, grad_norm=1.412414789199829, loss=2.116095781326294
I0302 22:54:15.217070 140239842563840 logging_writer.py:48] [85300] global_step=85300, grad_norm=1.209510087966919, loss=2.9431331157684326
I0302 22:55:00.206321 140239850956544 logging_writer.py:48] [85400] global_step=85400, grad_norm=1.3810789585113525, loss=2.0635790824890137
I0302 22:55:45.526860 140239842563840 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.2468968629837036, loss=4.487298965454102
I0302 22:56:30.842288 140239850956544 logging_writer.py:48] [85600] global_step=85600, grad_norm=1.421164870262146, loss=2.141845226287842
I0302 22:57:16.145840 140239842563840 logging_writer.py:48] [85700] global_step=85700, grad_norm=1.3200619220733643, loss=1.9376306533813477
I0302 22:57:36.150565 140437341357888 spec.py:321] Evaluating on the training split.
I0302 22:57:46.286551 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 22:58:07.364838 140437341357888 spec.py:349] Evaluating on the test split.
I0302 22:58:08.995483 140437341357888 submission_runner.py:411] Time since start: 41130.55s, 	Step: 85746, 	{'train/accuracy': 0.7251952886581421, 'train/loss': 1.0878881216049194, 'validation/accuracy': 0.667419970035553, 'validation/loss': 1.332442045211792, 'validation/num_examples': 50000, 'test/accuracy': 0.541700005531311, 'test/loss': 2.016709089279175, 'test/num_examples': 10000, 'score': 38275.05656552315, 'total_duration': 41130.546951532364, 'accumulated_submission_time': 38275.05656552315, 'accumulated_eval_time': 2846.0622234344482, 'accumulated_logging_time': 4.709845066070557}
I0302 22:58:09.031614 140239850956544 logging_writer.py:48] [85746] accumulated_eval_time=2846.062223, accumulated_logging_time=4.709845, accumulated_submission_time=38275.056566, global_step=85746, preemption_count=0, score=38275.056566, test/accuracy=0.541700, test/loss=2.016709, test/num_examples=10000, total_duration=41130.546952, train/accuracy=0.725195, train/loss=1.087888, validation/accuracy=0.667420, validation/loss=1.332442, validation/num_examples=50000
I0302 22:58:30.836401 140239842563840 logging_writer.py:48] [85800] global_step=85800, grad_norm=1.2647333145141602, loss=2.0854532718658447
I0302 22:59:14.846581 140239850956544 logging_writer.py:48] [85900] global_step=85900, grad_norm=1.3071842193603516, loss=2.3845884799957275
I0302 22:59:59.749484 140239842563840 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.499263048171997, loss=4.360537052154541
I0302 23:00:44.691475 140239850956544 logging_writer.py:48] [86100] global_step=86100, grad_norm=1.552541732788086, loss=2.558788776397705
I0302 23:01:29.707062 140239842563840 logging_writer.py:48] [86200] global_step=86200, grad_norm=1.397824764251709, loss=2.032036304473877
I0302 23:02:14.773786 140239850956544 logging_writer.py:48] [86300] global_step=86300, grad_norm=1.4410922527313232, loss=2.5532660484313965
I0302 23:03:00.276580 140239842563840 logging_writer.py:48] [86400] global_step=86400, grad_norm=1.2234759330749512, loss=2.8026132583618164
I0302 23:03:45.420689 140239850956544 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.1217336654663086, loss=3.228853702545166
I0302 23:04:30.540446 140239842563840 logging_writer.py:48] [86600] global_step=86600, grad_norm=1.6217942237854004, loss=2.099832057952881
I0302 23:05:09.386787 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:05:19.422471 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:05:44.958996 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:05:46.576097 140437341357888 submission_runner.py:411] Time since start: 41588.13s, 	Step: 86688, 	{'train/accuracy': 0.7310351133346558, 'train/loss': 1.069846749305725, 'validation/accuracy': 0.6744799613952637, 'validation/loss': 1.320836067199707, 'validation/num_examples': 50000, 'test/accuracy': 0.5494000315666199, 'test/loss': 1.9850354194641113, 'test/num_examples': 10000, 'score': 38695.34867835045, 'total_duration': 41588.12759113312, 'accumulated_submission_time': 38695.34867835045, 'accumulated_eval_time': 2883.2515251636505, 'accumulated_logging_time': 4.756951808929443}
I0302 23:05:46.605508 140239850956544 logging_writer.py:48] [86688] accumulated_eval_time=2883.251525, accumulated_logging_time=4.756952, accumulated_submission_time=38695.348678, global_step=86688, preemption_count=0, score=38695.348678, test/accuracy=0.549400, test/loss=1.985035, test/num_examples=10000, total_duration=41588.127591, train/accuracy=0.731035, train/loss=1.069847, validation/accuracy=0.674480, validation/loss=1.320836, validation/num_examples=50000
I0302 23:05:51.762219 140239842563840 logging_writer.py:48] [86700] global_step=86700, grad_norm=1.3133487701416016, loss=2.5886685848236084
I0302 23:06:31.981761 140239850956544 logging_writer.py:48] [86800] global_step=86800, grad_norm=1.2392631769180298, loss=3.338932514190674
I0302 23:07:17.317160 140239842563840 logging_writer.py:48] [86900] global_step=86900, grad_norm=1.2640495300292969, loss=2.72682523727417
I0302 23:08:02.434781 140239850956544 logging_writer.py:48] [87000] global_step=87000, grad_norm=1.398155689239502, loss=2.013763666152954
I0302 23:08:47.416025 140239842563840 logging_writer.py:48] [87100] global_step=87100, grad_norm=1.4446678161621094, loss=2.1595613956451416
I0302 23:09:32.472687 140239850956544 logging_writer.py:48] [87200] global_step=87200, grad_norm=1.3860352039337158, loss=4.3372602462768555
I0302 23:10:17.594405 140239842563840 logging_writer.py:48] [87300] global_step=87300, grad_norm=1.5711714029312134, loss=2.0421981811523438
I0302 23:11:02.576393 140239850956544 logging_writer.py:48] [87400] global_step=87400, grad_norm=1.1992305517196655, loss=3.550971269607544
I0302 23:11:47.746994 140239842563840 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.3493953943252563, loss=2.0214664936065674
I0302 23:12:32.975886 140239850956544 logging_writer.py:48] [87600] global_step=87600, grad_norm=1.327379822731018, loss=2.190178871154785
I0302 23:12:47.031739 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:12:57.026046 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:13:20.656455 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:13:22.282833 140437341357888 submission_runner.py:411] Time since start: 42043.83s, 	Step: 87633, 	{'train/accuracy': 0.7341992259025574, 'train/loss': 1.0544023513793945, 'validation/accuracy': 0.6748200058937073, 'validation/loss': 1.3344672918319702, 'validation/num_examples': 50000, 'test/accuracy': 0.5503000020980835, 'test/loss': 1.9918979406356812, 'test/num_examples': 10000, 'score': 39115.71409368515, 'total_duration': 42043.83431196213, 'accumulated_submission_time': 39115.71409368515, 'accumulated_eval_time': 2918.502597808838, 'accumulated_logging_time': 4.796014308929443}
I0302 23:13:22.316544 140239842563840 logging_writer.py:48] [87633] accumulated_eval_time=2918.502598, accumulated_logging_time=4.796014, accumulated_submission_time=39115.714094, global_step=87633, preemption_count=0, score=39115.714094, test/accuracy=0.550300, test/loss=1.991898, test/num_examples=10000, total_duration=42043.834312, train/accuracy=0.734199, train/loss=1.054402, validation/accuracy=0.674820, validation/loss=1.334467, validation/num_examples=50000
I0302 23:13:49.251352 140239850956544 logging_writer.py:48] [87700] global_step=87700, grad_norm=1.3613039255142212, loss=3.9194023609161377
I0302 23:14:32.576067 140239842563840 logging_writer.py:48] [87800] global_step=87800, grad_norm=1.500414252281189, loss=2.215630054473877
I0302 23:15:18.051548 140239850956544 logging_writer.py:48] [87900] global_step=87900, grad_norm=1.3389264345169067, loss=2.023136615753174
I0302 23:16:02.967211 140239842563840 logging_writer.py:48] [88000] global_step=88000, grad_norm=1.5162123441696167, loss=4.28071403503418
I0302 23:16:48.136234 140239850956544 logging_writer.py:48] [88100] global_step=88100, grad_norm=1.4310368299484253, loss=2.076007127761841
I0302 23:17:33.465948 140239842563840 logging_writer.py:48] [88200] global_step=88200, grad_norm=1.442389726638794, loss=2.0787675380706787
I0302 23:18:18.895765 140239850956544 logging_writer.py:48] [88300] global_step=88300, grad_norm=1.3837770223617554, loss=2.176408290863037
I0302 23:19:04.332975 140239842563840 logging_writer.py:48] [88400] global_step=88400, grad_norm=1.428563117980957, loss=2.1581242084503174
I0302 23:19:49.342747 140239850956544 logging_writer.py:48] [88500] global_step=88500, grad_norm=1.3216056823730469, loss=3.609003782272339
I0302 23:20:22.563947 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:20:32.749783 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:20:52.114108 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:20:53.749889 140437341357888 submission_runner.py:411] Time since start: 42495.30s, 	Step: 88575, 	{'train/accuracy': 0.7554491758346558, 'train/loss': 0.969889760017395, 'validation/accuracy': 0.6746399998664856, 'validation/loss': 1.3290221691131592, 'validation/num_examples': 50000, 'test/accuracy': 0.5534000396728516, 'test/loss': 1.966261625289917, 'test/num_examples': 10000, 'score': 39535.89856672287, 'total_duration': 42495.30137729645, 'accumulated_submission_time': 39535.89856672287, 'accumulated_eval_time': 2949.6885225772858, 'accumulated_logging_time': 4.841732740402222}
I0302 23:20:53.788675 140239842563840 logging_writer.py:48] [88575] accumulated_eval_time=2949.688523, accumulated_logging_time=4.841733, accumulated_submission_time=39535.898567, global_step=88575, preemption_count=0, score=39535.898567, test/accuracy=0.553400, test/loss=1.966262, test/num_examples=10000, total_duration=42495.301377, train/accuracy=0.755449, train/loss=0.969890, validation/accuracy=0.674640, validation/loss=1.329022, validation/num_examples=50000
I0302 23:21:04.120006 140239850956544 logging_writer.py:48] [88600] global_step=88600, grad_norm=1.4884003400802612, loss=2.2996270656585693
I0302 23:21:46.825666 140239842563840 logging_writer.py:48] [88700] global_step=88700, grad_norm=1.4601967334747314, loss=1.9879932403564453
I0302 23:22:32.022205 140239850956544 logging_writer.py:48] [88800] global_step=88800, grad_norm=1.6020879745483398, loss=4.77198600769043
I0302 23:23:17.791408 140239842563840 logging_writer.py:48] [88900] global_step=88900, grad_norm=1.2738043069839478, loss=2.519059419631958
I0302 23:24:03.457252 140239850956544 logging_writer.py:48] [89000] global_step=89000, grad_norm=1.469673991203308, loss=4.533552646636963
I0302 23:24:48.531647 140239842563840 logging_writer.py:48] [89100] global_step=89100, grad_norm=1.3544635772705078, loss=2.036891460418701
I0302 23:25:33.946571 140239850956544 logging_writer.py:48] [89200] global_step=89200, grad_norm=1.2800953388214111, loss=4.2977824211120605
I0302 23:26:19.467069 140239842563840 logging_writer.py:48] [89300] global_step=89300, grad_norm=1.4551830291748047, loss=2.042158842086792
I0302 23:27:05.218091 140239850956544 logging_writer.py:48] [89400] global_step=89400, grad_norm=1.511799693107605, loss=2.1195123195648193
I0302 23:27:50.854326 140239842563840 logging_writer.py:48] [89500] global_step=89500, grad_norm=1.415953516960144, loss=2.369225263595581
I0302 23:27:54.136396 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:28:04.594743 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:28:24.382196 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:28:26.006003 140437341357888 submission_runner.py:411] Time since start: 42947.56s, 	Step: 89509, 	{'train/accuracy': 0.7327538728713989, 'train/loss': 1.0732535123825073, 'validation/accuracy': 0.676580011844635, 'validation/loss': 1.3220385313034058, 'validation/num_examples': 50000, 'test/accuracy': 0.5515000224113464, 'test/loss': 1.975314736366272, 'test/num_examples': 10000, 'score': 39956.18599700928, 'total_duration': 42947.557476997375, 'accumulated_submission_time': 39956.18599700928, 'accumulated_eval_time': 2981.5580892562866, 'accumulated_logging_time': 4.89051628112793}
I0302 23:28:26.050306 140239850956544 logging_writer.py:48] [89509] accumulated_eval_time=2981.558089, accumulated_logging_time=4.890516, accumulated_submission_time=39956.185997, global_step=89509, preemption_count=0, score=39956.185997, test/accuracy=0.551500, test/loss=1.975315, test/num_examples=10000, total_duration=42947.557477, train/accuracy=0.732754, train/loss=1.073254, validation/accuracy=0.676580, validation/loss=1.322039, validation/num_examples=50000
I0302 23:29:03.961481 140239842563840 logging_writer.py:48] [89600] global_step=89600, grad_norm=1.4048062562942505, loss=2.1598410606384277
I0302 23:29:49.057180 140239850956544 logging_writer.py:48] [89700] global_step=89700, grad_norm=1.4068931341171265, loss=3.780071258544922
I0302 23:30:34.567396 140239842563840 logging_writer.py:48] [89800] global_step=89800, grad_norm=1.391587495803833, loss=2.0601494312286377
I0302 23:31:19.776454 140239850956544 logging_writer.py:48] [89900] global_step=89900, grad_norm=1.4784746170043945, loss=1.9523937702178955
I0302 23:32:05.166739 140239842563840 logging_writer.py:48] [90000] global_step=90000, grad_norm=1.2788258790969849, loss=2.4236135482788086
I0302 23:32:50.617148 140239850956544 logging_writer.py:48] [90100] global_step=90100, grad_norm=1.4558185338974, loss=2.032674551010132
I0302 23:33:35.866325 140239842563840 logging_writer.py:48] [90200] global_step=90200, grad_norm=1.2744282484054565, loss=4.545793533325195
I0302 23:34:21.254763 140239850956544 logging_writer.py:48] [90300] global_step=90300, grad_norm=1.4622858762741089, loss=2.0484306812286377
I0302 23:35:06.304903 140239842563840 logging_writer.py:48] [90400] global_step=90400, grad_norm=1.3106591701507568, loss=4.389321327209473
I0302 23:35:26.467851 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:35:36.592768 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:35:59.030272 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:36:00.648230 140437341357888 submission_runner.py:411] Time since start: 43402.20s, 	Step: 90446, 	{'train/accuracy': 0.7387109398841858, 'train/loss': 1.030994176864624, 'validation/accuracy': 0.6740999817848206, 'validation/loss': 1.3186286687850952, 'validation/num_examples': 50000, 'test/accuracy': 0.5520000457763672, 'test/loss': 1.9684735536575317, 'test/num_examples': 10000, 'score': 40376.54059243202, 'total_duration': 43402.199709415436, 'accumulated_submission_time': 40376.54059243202, 'accumulated_eval_time': 3015.738451242447, 'accumulated_logging_time': 4.947018384933472}
I0302 23:36:00.684279 140239850956544 logging_writer.py:48] [90446] accumulated_eval_time=3015.738451, accumulated_logging_time=4.947018, accumulated_submission_time=40376.540592, global_step=90446, preemption_count=0, score=40376.540592, test/accuracy=0.552000, test/loss=1.968474, test/num_examples=10000, total_duration=43402.199709, train/accuracy=0.738711, train/loss=1.030994, validation/accuracy=0.674100, validation/loss=1.318629, validation/num_examples=50000
I0302 23:36:22.484686 140239842563840 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.4048045873641968, loss=1.9495209455490112
I0302 23:37:05.953727 140239850956544 logging_writer.py:48] [90600] global_step=90600, grad_norm=1.456007480621338, loss=2.17223858833313
I0302 23:37:50.996103 140239842563840 logging_writer.py:48] [90700] global_step=90700, grad_norm=1.3221631050109863, loss=4.165139675140381
I0302 23:38:35.933077 140239850956544 logging_writer.py:48] [90800] global_step=90800, grad_norm=1.2361009120941162, loss=3.4446043968200684
I0302 23:39:21.037594 140239842563840 logging_writer.py:48] [90900] global_step=90900, grad_norm=1.4387986660003662, loss=4.208662033081055
I0302 23:40:06.008461 140239850956544 logging_writer.py:48] [91000] global_step=91000, grad_norm=1.4077056646347046, loss=4.295268535614014
I0302 23:40:51.185590 140239842563840 logging_writer.py:48] [91100] global_step=91100, grad_norm=1.4031586647033691, loss=2.107877731323242
I0302 23:41:36.196960 140239850956544 logging_writer.py:48] [91200] global_step=91200, grad_norm=1.5096789598464966, loss=1.9129366874694824
I0302 23:42:21.281722 140239842563840 logging_writer.py:48] [91300] global_step=91300, grad_norm=1.2517987489700317, loss=2.9788434505462646
I0302 23:43:00.791363 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:43:11.064205 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:43:34.400302 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:43:36.023036 140437341357888 submission_runner.py:411] Time since start: 43857.57s, 	Step: 91389, 	{'train/accuracy': 0.7518945336341858, 'train/loss': 0.9972430467605591, 'validation/accuracy': 0.6795799732208252, 'validation/loss': 1.3187674283981323, 'validation/num_examples': 50000, 'test/accuracy': 0.5552000403404236, 'test/loss': 1.9847722053527832, 'test/num_examples': 10000, 'score': 40796.58492851257, 'total_duration': 43857.57451105118, 'accumulated_submission_time': 40796.58492851257, 'accumulated_eval_time': 3050.9701120853424, 'accumulated_logging_time': 4.993818759918213}
I0302 23:43:36.058673 140239850956544 logging_writer.py:48] [91389] accumulated_eval_time=3050.970112, accumulated_logging_time=4.993819, accumulated_submission_time=40796.584929, global_step=91389, preemption_count=0, score=40796.584929, test/accuracy=0.555200, test/loss=1.984772, test/num_examples=10000, total_duration=43857.574511, train/accuracy=0.751895, train/loss=0.997243, validation/accuracy=0.679580, validation/loss=1.318767, validation/num_examples=50000
I0302 23:43:40.840246 140239842563840 logging_writer.py:48] [91400] global_step=91400, grad_norm=1.396683692932129, loss=2.0609023571014404
I0302 23:44:21.994799 140239850956544 logging_writer.py:48] [91500] global_step=91500, grad_norm=1.3516002893447876, loss=2.1508841514587402
I0302 23:45:07.522011 140239842563840 logging_writer.py:48] [91600] global_step=91600, grad_norm=1.4633573293685913, loss=1.938305139541626
I0302 23:45:52.455220 140239850956544 logging_writer.py:48] [91700] global_step=91700, grad_norm=1.3796777725219727, loss=2.345102310180664
I0302 23:46:37.841352 140239842563840 logging_writer.py:48] [91800] global_step=91800, grad_norm=1.4082977771759033, loss=2.536822557449341
I0302 23:47:23.075037 140239850956544 logging_writer.py:48] [91900] global_step=91900, grad_norm=1.4562920331954956, loss=2.071772575378418
I0302 23:48:08.146981 140239842563840 logging_writer.py:48] [92000] global_step=92000, grad_norm=1.4434254169464111, loss=2.021589756011963
I0302 23:48:53.451646 140239850956544 logging_writer.py:48] [92100] global_step=92100, grad_norm=1.3691825866699219, loss=2.320660352706909
I0302 23:49:38.651975 140239842563840 logging_writer.py:48] [92200] global_step=92200, grad_norm=1.3670239448547363, loss=2.7567527294158936
I0302 23:50:23.949548 140239850956544 logging_writer.py:48] [92300] global_step=92300, grad_norm=1.4512797594070435, loss=2.0359504222869873
I0302 23:50:36.230336 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:50:46.174060 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:51:05.400007 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:51:07.055396 140437341357888 submission_runner.py:411] Time since start: 44308.61s, 	Step: 92329, 	{'train/accuracy': 0.7335546612739563, 'train/loss': 1.0436562299728394, 'validation/accuracy': 0.6787799596786499, 'validation/loss': 1.2994449138641357, 'validation/num_examples': 50000, 'test/accuracy': 0.5539000034332275, 'test/loss': 1.954208254814148, 'test/num_examples': 10000, 'score': 41216.692452430725, 'total_duration': 44308.60667061806, 'accumulated_submission_time': 41216.692452430725, 'accumulated_eval_time': 3081.7949402332306, 'accumulated_logging_time': 5.041177034378052}
I0302 23:51:07.117996 140239842563840 logging_writer.py:48] [92329] accumulated_eval_time=3081.794940, accumulated_logging_time=5.041177, accumulated_submission_time=41216.692452, global_step=92329, preemption_count=0, score=41216.692452, test/accuracy=0.553900, test/loss=1.954208, test/num_examples=10000, total_duration=44308.606671, train/accuracy=0.733555, train/loss=1.043656, validation/accuracy=0.678780, validation/loss=1.299445, validation/num_examples=50000
I0302 23:51:35.659114 140239850956544 logging_writer.py:48] [92400] global_step=92400, grad_norm=1.417809247970581, loss=2.408536195755005
I0302 23:52:19.141429 140239842563840 logging_writer.py:48] [92500] global_step=92500, grad_norm=1.2837271690368652, loss=3.0246453285217285
I0302 23:53:04.586566 140239850956544 logging_writer.py:48] [92600] global_step=92600, grad_norm=1.42961585521698, loss=2.0709447860717773
I0302 23:53:49.364897 140239842563840 logging_writer.py:48] [92700] global_step=92700, grad_norm=1.4392757415771484, loss=4.353937149047852
I0302 23:54:34.498307 140239850956544 logging_writer.py:48] [92800] global_step=92800, grad_norm=1.383768916130066, loss=2.6898727416992188
I0302 23:55:19.721183 140239842563840 logging_writer.py:48] [92900] global_step=92900, grad_norm=1.2627460956573486, loss=3.4683637619018555
I0302 23:56:04.641356 140239850956544 logging_writer.py:48] [93000] global_step=93000, grad_norm=1.592065691947937, loss=2.170473337173462
I0302 23:56:49.864487 140239842563840 logging_writer.py:48] [93100] global_step=93100, grad_norm=1.3678680658340454, loss=2.136629819869995
I0302 23:57:35.033079 140239850956544 logging_writer.py:48] [93200] global_step=93200, grad_norm=1.4570155143737793, loss=2.0533578395843506
I0302 23:58:07.365595 140437341357888 spec.py:321] Evaluating on the training split.
I0302 23:58:17.520253 140437341357888 spec.py:333] Evaluating on the validation split.
I0302 23:58:38.136998 140437341357888 spec.py:349] Evaluating on the test split.
I0302 23:58:39.769355 140437341357888 submission_runner.py:411] Time since start: 44761.32s, 	Step: 93273, 	{'train/accuracy': 0.7421875, 'train/loss': 1.0251456499099731, 'validation/accuracy': 0.6827200055122375, 'validation/loss': 1.2972899675369263, 'validation/num_examples': 50000, 'test/accuracy': 0.5590000152587891, 'test/loss': 1.9417389631271362, 'test/num_examples': 10000, 'score': 41636.87300825119, 'total_duration': 44761.32083892822, 'accumulated_submission_time': 41636.87300825119, 'accumulated_eval_time': 3114.198682308197, 'accumulated_logging_time': 5.118264436721802}
I0302 23:58:39.805921 140239842563840 logging_writer.py:48] [93273] accumulated_eval_time=3114.198682, accumulated_logging_time=5.118264, accumulated_submission_time=41636.873008, global_step=93273, preemption_count=0, score=41636.873008, test/accuracy=0.559000, test/loss=1.941739, test/num_examples=10000, total_duration=44761.320839, train/accuracy=0.742188, train/loss=1.025146, validation/accuracy=0.682720, validation/loss=1.297290, validation/num_examples=50000
I0302 23:58:50.939469 140239850956544 logging_writer.py:48] [93300] global_step=93300, grad_norm=1.2989368438720703, loss=2.510552406311035
I0302 23:59:33.383107 140239842563840 logging_writer.py:48] [93400] global_step=93400, grad_norm=1.5234627723693848, loss=2.2352235317230225
I0303 00:00:18.857253 140239850956544 logging_writer.py:48] [93500] global_step=93500, grad_norm=1.36931574344635, loss=1.8952898979187012
I0303 00:01:03.925792 140239842563840 logging_writer.py:48] [93600] global_step=93600, grad_norm=1.503409743309021, loss=1.9695967435836792
I0303 00:01:48.706199 140239850956544 logging_writer.py:48] [93700] global_step=93700, grad_norm=1.2471051216125488, loss=2.608128547668457
I0303 00:02:33.860192 140239842563840 logging_writer.py:48] [93800] global_step=93800, grad_norm=1.5711290836334229, loss=2.107104778289795
I0303 00:03:19.378599 140239850956544 logging_writer.py:48] [93900] global_step=93900, grad_norm=1.3996002674102783, loss=2.053138256072998
I0303 00:04:04.462933 140239842563840 logging_writer.py:48] [94000] global_step=94000, grad_norm=1.188845157623291, loss=3.727832317352295
I0303 00:04:49.522649 140239850956544 logging_writer.py:48] [94100] global_step=94100, grad_norm=1.3254839181900024, loss=1.9766757488250732
I0303 00:05:34.612931 140239842563840 logging_writer.py:48] [94200] global_step=94200, grad_norm=1.358426809310913, loss=4.4837646484375
I0303 00:05:40.101374 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:05:50.160084 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:06:17.384059 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:06:18.993223 140437341357888 submission_runner.py:411] Time since start: 45220.54s, 	Step: 94214, 	{'train/accuracy': 0.7447265386581421, 'train/loss': 1.0316696166992188, 'validation/accuracy': 0.6801599860191345, 'validation/loss': 1.314698576927185, 'validation/num_examples': 50000, 'test/accuracy': 0.5564000010490417, 'test/loss': 1.9675493240356445, 'test/num_examples': 10000, 'score': 42057.10592675209, 'total_duration': 45220.5447204113, 'accumulated_submission_time': 42057.10592675209, 'accumulated_eval_time': 3153.09051322937, 'accumulated_logging_time': 5.165774345397949}
I0303 00:06:19.026310 140239850956544 logging_writer.py:48] [94214] accumulated_eval_time=3153.090513, accumulated_logging_time=5.165774, accumulated_submission_time=42057.105927, global_step=94214, preemption_count=0, score=42057.105927, test/accuracy=0.556400, test/loss=1.967549, test/num_examples=10000, total_duration=45220.544720, train/accuracy=0.744727, train/loss=1.031670, validation/accuracy=0.680160, validation/loss=1.314699, validation/num_examples=50000
I0303 00:06:53.524230 140239842563840 logging_writer.py:48] [94300] global_step=94300, grad_norm=1.3684000968933105, loss=2.9017865657806396
I0303 00:07:37.389000 140239850956544 logging_writer.py:48] [94400] global_step=94400, grad_norm=1.39858877658844, loss=1.9260339736938477
I0303 00:08:22.571262 140239842563840 logging_writer.py:48] [94500] global_step=94500, grad_norm=1.4968812465667725, loss=2.013298988342285
I0303 00:09:07.454002 140239850956544 logging_writer.py:48] [94600] global_step=94600, grad_norm=1.473678469657898, loss=2.294006824493408
I0303 00:09:52.533932 140239842563840 logging_writer.py:48] [94700] global_step=94700, grad_norm=1.5338290929794312, loss=2.1197071075439453
I0303 00:10:37.509915 140239850956544 logging_writer.py:48] [94800] global_step=94800, grad_norm=1.343587875366211, loss=3.7458345890045166
I0303 00:11:22.305328 140239842563840 logging_writer.py:48] [94900] global_step=94900, grad_norm=1.4366306066513062, loss=1.9616553783416748
I0303 00:12:07.255216 140239850956544 logging_writer.py:48] [95000] global_step=95000, grad_norm=1.2488577365875244, loss=3.3181769847869873
I0303 00:12:52.820859 140239842563840 logging_writer.py:48] [95100] global_step=95100, grad_norm=1.3489952087402344, loss=2.929018020629883
I0303 00:13:19.324949 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:13:29.432711 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:13:50.511416 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:13:52.147844 140437341357888 submission_runner.py:411] Time since start: 45673.70s, 	Step: 95160, 	{'train/accuracy': 0.7561132907867432, 'train/loss': 0.99065762758255, 'validation/accuracy': 0.6864399909973145, 'validation/loss': 1.2994662523269653, 'validation/num_examples': 50000, 'test/accuracy': 0.5582000017166138, 'test/loss': 1.948542833328247, 'test/num_examples': 10000, 'score': 42477.334065675735, 'total_duration': 45673.6993329525, 'accumulated_submission_time': 42477.334065675735, 'accumulated_eval_time': 3185.913388967514, 'accumulated_logging_time': 5.208800315856934}
I0303 00:13:52.189071 140239850956544 logging_writer.py:48] [95160] accumulated_eval_time=3185.913389, accumulated_logging_time=5.208800, accumulated_submission_time=42477.334066, global_step=95160, preemption_count=0, score=42477.334066, test/accuracy=0.558200, test/loss=1.948543, test/num_examples=10000, total_duration=45673.699333, train/accuracy=0.756113, train/loss=0.990658, validation/accuracy=0.686440, validation/loss=1.299466, validation/num_examples=50000
I0303 00:14:08.480543 140239842563840 logging_writer.py:48] [95200] global_step=95200, grad_norm=1.5102314949035645, loss=1.9750746488571167
I0303 00:14:51.549408 140239850956544 logging_writer.py:48] [95300] global_step=95300, grad_norm=1.550343632698059, loss=2.0773916244506836
I0303 00:15:36.810348 140239842563840 logging_writer.py:48] [95400] global_step=95400, grad_norm=1.693163275718689, loss=2.1340813636779785
I0303 00:16:21.997369 140239850956544 logging_writer.py:48] [95500] global_step=95500, grad_norm=1.4279488325119019, loss=3.9711592197418213
I0303 00:17:07.482408 140239842563840 logging_writer.py:48] [95600] global_step=95600, grad_norm=1.3983839750289917, loss=3.8314263820648193
I0303 00:17:52.440753 140239850956544 logging_writer.py:48] [95700] global_step=95700, grad_norm=1.383716344833374, loss=2.026371479034424
I0303 00:18:37.346564 140239842563840 logging_writer.py:48] [95800] global_step=95800, grad_norm=1.4762746095657349, loss=3.9092698097229004
I0303 00:19:22.265140 140239850956544 logging_writer.py:48] [95900] global_step=95900, grad_norm=1.3948283195495605, loss=3.53104305267334
I0303 00:20:07.432049 140239842563840 logging_writer.py:48] [96000] global_step=96000, grad_norm=1.438886046409607, loss=2.097560405731201
I0303 00:20:52.344829 140239850956544 logging_writer.py:48] [96100] global_step=96100, grad_norm=1.4793339967727661, loss=1.9736053943634033
I0303 00:20:52.360539 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:21:02.978018 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:21:21.497012 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:21:23.119027 140437341357888 submission_runner.py:411] Time since start: 46124.67s, 	Step: 96101, 	{'train/accuracy': 0.7415820360183716, 'train/loss': 1.0177706480026245, 'validation/accuracy': 0.6850599646568298, 'validation/loss': 1.2784010171890259, 'validation/num_examples': 50000, 'test/accuracy': 0.5559000372886658, 'test/loss': 1.9323203563690186, 'test/num_examples': 10000, 'score': 42897.442705631256, 'total_duration': 46124.670513153076, 'accumulated_submission_time': 42897.442705631256, 'accumulated_eval_time': 3216.6718633174896, 'accumulated_logging_time': 5.261148452758789}
I0303 00:21:23.155628 140239842563840 logging_writer.py:48] [96101] accumulated_eval_time=3216.671863, accumulated_logging_time=5.261148, accumulated_submission_time=42897.442706, global_step=96101, preemption_count=0, score=42897.442706, test/accuracy=0.555900, test/loss=1.932320, test/num_examples=10000, total_duration=46124.670513, train/accuracy=0.741582, train/loss=1.017771, validation/accuracy=0.685060, validation/loss=1.278401, validation/num_examples=50000
I0303 00:22:04.492825 140239850956544 logging_writer.py:48] [96200] global_step=96200, grad_norm=1.551969289779663, loss=1.853395700454712
I0303 00:22:49.483256 140239842563840 logging_writer.py:48] [96300] global_step=96300, grad_norm=1.514730453491211, loss=2.8090598583221436
I0303 00:23:34.972327 140239850956544 logging_writer.py:48] [96400] global_step=96400, grad_norm=1.327528953552246, loss=3.2970001697540283
I0303 00:24:19.959240 140239842563840 logging_writer.py:48] [96500] global_step=96500, grad_norm=1.5525296926498413, loss=2.0103554725646973
I0303 00:25:05.147745 140239850956544 logging_writer.py:48] [96600] global_step=96600, grad_norm=1.5151515007019043, loss=2.2309439182281494
I0303 00:25:50.250147 140239842563840 logging_writer.py:48] [96700] global_step=96700, grad_norm=1.3630174398422241, loss=3.623899459838867
I0303 00:26:35.726576 140239850956544 logging_writer.py:48] [96800] global_step=96800, grad_norm=1.4257440567016602, loss=2.012812852859497
I0303 00:27:20.871825 140239842563840 logging_writer.py:48] [96900] global_step=96900, grad_norm=1.42692232131958, loss=2.4982717037200928
I0303 00:28:06.073271 140239850956544 logging_writer.py:48] [97000] global_step=97000, grad_norm=1.528053879737854, loss=2.012695074081421
I0303 00:28:23.483228 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:28:33.681256 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:28:54.654822 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:28:56.281279 140437341357888 submission_runner.py:411] Time since start: 46577.83s, 	Step: 97040, 	{'train/accuracy': 0.7523437142372131, 'train/loss': 0.9721384048461914, 'validation/accuracy': 0.6881399750709534, 'validation/loss': 1.2559822797775269, 'validation/num_examples': 50000, 'test/accuracy': 0.5623000264167786, 'test/loss': 1.909122347831726, 'test/num_examples': 10000, 'score': 43317.70691943169, 'total_duration': 46577.83276820183, 'accumulated_submission_time': 43317.70691943169, 'accumulated_eval_time': 3249.469914674759, 'accumulated_logging_time': 5.307514429092407}
I0303 00:28:56.317873 140239842563840 logging_writer.py:48] [97040] accumulated_eval_time=3249.469915, accumulated_logging_time=5.307514, accumulated_submission_time=43317.706919, global_step=97040, preemption_count=0, score=43317.706919, test/accuracy=0.562300, test/loss=1.909122, test/num_examples=10000, total_duration=46577.832768, train/accuracy=0.752344, train/loss=0.972138, validation/accuracy=0.688140, validation/loss=1.255982, validation/num_examples=50000
I0303 00:29:20.515623 140239850956544 logging_writer.py:48] [97100] global_step=97100, grad_norm=1.2997710704803467, loss=3.7776541709899902
I0303 00:30:04.423237 140239842563840 logging_writer.py:48] [97200] global_step=97200, grad_norm=1.6415661573410034, loss=2.045494318008423
I0303 00:30:49.503533 140239850956544 logging_writer.py:48] [97300] global_step=97300, grad_norm=1.5236109495162964, loss=1.9855250120162964
I0303 00:31:34.707535 140239842563840 logging_writer.py:48] [97400] global_step=97400, grad_norm=1.3602416515350342, loss=1.9594694375991821
I0303 00:32:19.869938 140239850956544 logging_writer.py:48] [97500] global_step=97500, grad_norm=1.2843844890594482, loss=2.626305341720581
I0303 00:33:05.595184 140239842563840 logging_writer.py:48] [97600] global_step=97600, grad_norm=1.406736969947815, loss=4.467453956604004
I0303 00:33:50.566203 140239850956544 logging_writer.py:48] [97700] global_step=97700, grad_norm=1.4033704996109009, loss=3.922847032546997
I0303 00:34:35.675768 140239842563840 logging_writer.py:48] [97800] global_step=97800, grad_norm=1.5668500661849976, loss=2.041390895843506
I0303 00:35:20.985635 140239850956544 logging_writer.py:48] [97900] global_step=97900, grad_norm=1.3857789039611816, loss=2.523167133331299
I0303 00:35:56.700594 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:36:06.836833 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:36:29.198275 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:36:30.818045 140437341357888 submission_runner.py:411] Time since start: 47032.37s, 	Step: 97981, 	{'train/accuracy': 0.7609765529632568, 'train/loss': 0.9368932247161865, 'validation/accuracy': 0.6894800066947937, 'validation/loss': 1.2643203735351562, 'validation/num_examples': 50000, 'test/accuracy': 0.5659000277519226, 'test/loss': 1.9028120040893555, 'test/num_examples': 10000, 'score': 43738.027341365814, 'total_duration': 47032.36952018738, 'accumulated_submission_time': 43738.027341365814, 'accumulated_eval_time': 3283.58735871315, 'accumulated_logging_time': 5.355186462402344}
I0303 00:36:30.854946 140239842563840 logging_writer.py:48] [97981] accumulated_eval_time=3283.587359, accumulated_logging_time=5.355186, accumulated_submission_time=43738.027341, global_step=97981, preemption_count=0, score=43738.027341, test/accuracy=0.565900, test/loss=1.902812, test/num_examples=10000, total_duration=47032.369520, train/accuracy=0.760977, train/loss=0.936893, validation/accuracy=0.689480, validation/loss=1.264320, validation/num_examples=50000
I0303 00:36:38.807600 140239850956544 logging_writer.py:48] [98000] global_step=98000, grad_norm=1.378580927848816, loss=3.092414379119873
I0303 00:37:20.633925 140239842563840 logging_writer.py:48] [98100] global_step=98100, grad_norm=1.6878247261047363, loss=1.9717490673065186
I0303 00:38:05.608729 140239850956544 logging_writer.py:48] [98200] global_step=98200, grad_norm=1.3265846967697144, loss=2.832745313644409
I0303 00:38:50.642036 140239842563840 logging_writer.py:48] [98300] global_step=98300, grad_norm=1.437517523765564, loss=2.120312213897705
I0303 00:39:35.681262 140239850956544 logging_writer.py:48] [98400] global_step=98400, grad_norm=1.4115228652954102, loss=2.1640443801879883
I0303 00:40:20.724428 140239842563840 logging_writer.py:48] [98500] global_step=98500, grad_norm=1.4799686670303345, loss=1.9216591119766235
I0303 00:41:05.679136 140239850956544 logging_writer.py:48] [98600] global_step=98600, grad_norm=1.6666862964630127, loss=2.7925620079040527
I0303 00:41:50.561083 140239842563840 logging_writer.py:48] [98700] global_step=98700, grad_norm=1.4297231435775757, loss=2.9944796562194824
I0303 00:42:35.569946 140239850956544 logging_writer.py:48] [98800] global_step=98800, grad_norm=1.5442222356796265, loss=1.9775598049163818
I0303 00:43:21.260998 140239842563840 logging_writer.py:48] [98900] global_step=98900, grad_norm=1.3665305376052856, loss=1.7916393280029297
I0303 00:43:31.072146 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:43:41.135955 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:44:01.931112 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:44:03.589468 140437341357888 submission_runner.py:411] Time since start: 47485.14s, 	Step: 98923, 	{'train/accuracy': 0.7438867092132568, 'train/loss': 0.993510365486145, 'validation/accuracy': 0.6860799789428711, 'validation/loss': 1.261129379272461, 'validation/num_examples': 50000, 'test/accuracy': 0.5624000430107117, 'test/loss': 1.9388071298599243, 'test/num_examples': 10000, 'score': 44158.18087887764, 'total_duration': 47485.14091467857, 'accumulated_submission_time': 44158.18087887764, 'accumulated_eval_time': 3316.1046471595764, 'accumulated_logging_time': 5.404359579086304}
I0303 00:44:03.648708 140239850956544 logging_writer.py:48] [98923] accumulated_eval_time=3316.104647, accumulated_logging_time=5.404360, accumulated_submission_time=44158.180879, global_step=98923, preemption_count=0, score=44158.180879, test/accuracy=0.562400, test/loss=1.938807, test/num_examples=10000, total_duration=47485.140915, train/accuracy=0.743887, train/loss=0.993510, validation/accuracy=0.686080, validation/loss=1.261129, validation/num_examples=50000
I0303 00:44:34.627794 140239842563840 logging_writer.py:48] [99000] global_step=99000, grad_norm=1.6001944541931152, loss=2.05405592918396
I0303 00:45:18.634154 140239850956544 logging_writer.py:48] [99100] global_step=99100, grad_norm=1.4071605205535889, loss=2.8814857006073
I0303 00:46:04.173700 140239842563840 logging_writer.py:48] [99200] global_step=99200, grad_norm=1.6385834217071533, loss=1.8849773406982422
I0303 00:46:49.203840 140239850956544 logging_writer.py:48] [99300] global_step=99300, grad_norm=1.4684066772460938, loss=2.0075039863586426
I0303 00:47:34.242940 140239842563840 logging_writer.py:48] [99400] global_step=99400, grad_norm=1.5365358591079712, loss=2.005152940750122
I0303 00:48:19.116276 140239850956544 logging_writer.py:48] [99500] global_step=99500, grad_norm=1.4656099081039429, loss=1.9585140943527222
I0303 00:49:04.107959 140239842563840 logging_writer.py:48] [99600] global_step=99600, grad_norm=1.368333101272583, loss=2.169570207595825
I0303 00:49:49.041828 140239850956544 logging_writer.py:48] [99700] global_step=99700, grad_norm=1.3437385559082031, loss=3.2057089805603027
I0303 00:50:34.027665 140239842563840 logging_writer.py:48] [99800] global_step=99800, grad_norm=1.3157206773757935, loss=2.065088987350464
I0303 00:51:03.644464 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:51:13.715359 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:51:34.849565 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:51:36.463736 140437341357888 submission_runner.py:411] Time since start: 47938.02s, 	Step: 99867, 	{'train/accuracy': 0.7521874904632568, 'train/loss': 0.9745285511016846, 'validation/accuracy': 0.6863200068473816, 'validation/loss': 1.2652863264083862, 'validation/num_examples': 50000, 'test/accuracy': 0.5617000460624695, 'test/loss': 1.9162745475769043, 'test/num_examples': 10000, 'score': 44578.10844540596, 'total_duration': 47938.01518249512, 'accumulated_submission_time': 44578.10844540596, 'accumulated_eval_time': 3348.923852443695, 'accumulated_logging_time': 5.479732513427734}
I0303 00:51:36.504873 140239850956544 logging_writer.py:48] [99867] accumulated_eval_time=3348.923852, accumulated_logging_time=5.479733, accumulated_submission_time=44578.108445, global_step=99867, preemption_count=0, score=44578.108445, test/accuracy=0.561700, test/loss=1.916275, test/num_examples=10000, total_duration=47938.015182, train/accuracy=0.752187, train/loss=0.974529, validation/accuracy=0.686320, validation/loss=1.265286, validation/num_examples=50000
I0303 00:51:49.980377 140239842563840 logging_writer.py:48] [99900] global_step=99900, grad_norm=1.537851095199585, loss=1.9532090425491333
I0303 00:52:32.255637 140239850956544 logging_writer.py:48] [100000] global_step=100000, grad_norm=1.476609468460083, loss=1.8285659551620483
I0303 00:53:17.603038 140239842563840 logging_writer.py:48] [100100] global_step=100100, grad_norm=1.3128517866134644, loss=2.9208884239196777
I0303 00:54:02.837744 140239850956544 logging_writer.py:48] [100200] global_step=100200, grad_norm=1.5048786401748657, loss=4.3658223152160645
I0303 00:54:47.646791 140239842563840 logging_writer.py:48] [100300] global_step=100300, grad_norm=1.4044818878173828, loss=4.078359603881836
I0303 00:55:32.884220 140239850956544 logging_writer.py:48] [100400] global_step=100400, grad_norm=1.3298394680023193, loss=2.743727207183838
I0303 00:56:17.817584 140239842563840 logging_writer.py:48] [100500] global_step=100500, grad_norm=1.5204368829727173, loss=1.932440996170044
I0303 00:57:03.139846 140239850956544 logging_writer.py:48] [100600] global_step=100600, grad_norm=1.460193157196045, loss=1.9899078607559204
I0303 00:57:48.115186 140239842563840 logging_writer.py:48] [100700] global_step=100700, grad_norm=1.2517619132995605, loss=3.228086471557617
I0303 00:58:33.265429 140239850956544 logging_writer.py:48] [100800] global_step=100800, grad_norm=1.5550932884216309, loss=1.9550023078918457
I0303 00:58:36.541649 140437341357888 spec.py:321] Evaluating on the training split.
I0303 00:58:46.970087 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 00:59:07.498830 140437341357888 spec.py:349] Evaluating on the test split.
I0303 00:59:09.168912 140437341357888 submission_runner.py:411] Time since start: 48390.72s, 	Step: 100809, 	{'train/accuracy': 0.7562499642372131, 'train/loss': 0.9649302363395691, 'validation/accuracy': 0.6868999600410461, 'validation/loss': 1.2645305395126343, 'validation/num_examples': 50000, 'test/accuracy': 0.5648000240325928, 'test/loss': 1.908398151397705, 'test/num_examples': 10000, 'score': 44998.0839908123, 'total_duration': 48390.72035264969, 'accumulated_submission_time': 44998.0839908123, 'accumulated_eval_time': 3381.551055908203, 'accumulated_logging_time': 5.530679225921631}
I0303 00:59:09.226949 140239842563840 logging_writer.py:48] [100809] accumulated_eval_time=3381.551056, accumulated_logging_time=5.530679, accumulated_submission_time=44998.083991, global_step=100809, preemption_count=0, score=44998.083991, test/accuracy=0.564800, test/loss=1.908398, test/num_examples=10000, total_duration=48390.720353, train/accuracy=0.756250, train/loss=0.964930, validation/accuracy=0.686900, validation/loss=1.264531, validation/num_examples=50000
I0303 00:59:45.685579 140239850956544 logging_writer.py:48] [100900] global_step=100900, grad_norm=1.7123732566833496, loss=4.442922592163086
I0303 01:00:29.932616 140239842563840 logging_writer.py:48] [101000] global_step=101000, grad_norm=1.3758662939071655, loss=3.219933032989502
I0303 01:01:15.236673 140239850956544 logging_writer.py:48] [101100] global_step=101100, grad_norm=1.4427062273025513, loss=2.0110368728637695
I0303 01:02:00.324162 140239842563840 logging_writer.py:48] [101200] global_step=101200, grad_norm=1.4526934623718262, loss=2.7510557174682617
I0303 01:02:45.167546 140239850956544 logging_writer.py:48] [101300] global_step=101300, grad_norm=1.5386452674865723, loss=1.7982558012008667
I0303 01:03:30.631535 140239842563840 logging_writer.py:48] [101400] global_step=101400, grad_norm=1.540176272392273, loss=1.8968346118927002
I0303 01:04:15.654715 140239850956544 logging_writer.py:48] [101500] global_step=101500, grad_norm=1.4008493423461914, loss=1.909886360168457
I0303 01:05:00.581023 140239842563840 logging_writer.py:48] [101600] global_step=101600, grad_norm=1.5076814889907837, loss=2.9503350257873535
I0303 01:05:45.572723 140239850956544 logging_writer.py:48] [101700] global_step=101700, grad_norm=1.4639382362365723, loss=4.0472540855407715
I0303 01:06:09.362147 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:06:19.563361 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:06:40.968062 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:06:42.590162 140437341357888 submission_runner.py:411] Time since start: 48844.14s, 	Step: 101754, 	{'train/accuracy': 0.75830078125, 'train/loss': 0.965836763381958, 'validation/accuracy': 0.6916399598121643, 'validation/loss': 1.2648234367370605, 'validation/num_examples': 50000, 'test/accuracy': 0.5596000552177429, 'test/loss': 1.9227352142333984, 'test/num_examples': 10000, 'score': 45418.158311128616, 'total_duration': 48844.14165306091, 'accumulated_submission_time': 45418.158311128616, 'accumulated_eval_time': 3414.7790591716766, 'accumulated_logging_time': 5.598333120346069}
I0303 01:06:42.626473 140239842563840 logging_writer.py:48] [101754] accumulated_eval_time=3414.779059, accumulated_logging_time=5.598333, accumulated_submission_time=45418.158311, global_step=101754, preemption_count=0, score=45418.158311, test/accuracy=0.559600, test/loss=1.922735, test/num_examples=10000, total_duration=48844.141653, train/accuracy=0.758301, train/loss=0.965837, validation/accuracy=0.691640, validation/loss=1.264823, validation/num_examples=50000
I0303 01:07:01.272283 140239850956544 logging_writer.py:48] [101800] global_step=101800, grad_norm=1.5230287313461304, loss=1.901186227798462
I0303 01:07:44.695824 140239842563840 logging_writer.py:48] [101900] global_step=101900, grad_norm=1.338935136795044, loss=1.9509594440460205
I0303 01:08:29.892574 140239850956544 logging_writer.py:48] [102000] global_step=102000, grad_norm=1.56826913356781, loss=3.8399949073791504
I0303 01:09:14.970797 140239842563840 logging_writer.py:48] [102100] global_step=102100, grad_norm=1.8016424179077148, loss=1.8802292346954346
I0303 01:10:00.065654 140239850956544 logging_writer.py:48] [102200] global_step=102200, grad_norm=1.5074331760406494, loss=1.9469504356384277
I0303 01:10:45.280077 140239842563840 logging_writer.py:48] [102300] global_step=102300, grad_norm=1.5175089836120605, loss=2.1738007068634033
I0303 01:11:30.075128 140239850956544 logging_writer.py:48] [102400] global_step=102400, grad_norm=1.5449641942977905, loss=1.900444507598877
I0303 01:12:15.018708 140239842563840 logging_writer.py:48] [102500] global_step=102500, grad_norm=1.4520045518875122, loss=1.9056955575942993
I0303 01:13:00.390587 140239850956544 logging_writer.py:48] [102600] global_step=102600, grad_norm=1.5058916807174683, loss=1.890689492225647
I0303 01:13:42.876878 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:13:53.123813 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:14:19.579692 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:14:21.204849 140437341357888 submission_runner.py:411] Time since start: 49302.76s, 	Step: 102695, 	{'train/accuracy': 0.7544921636581421, 'train/loss': 0.9744990468025208, 'validation/accuracy': 0.6915799975395203, 'validation/loss': 1.252241611480713, 'validation/num_examples': 50000, 'test/accuracy': 0.5699000358581543, 'test/loss': 1.8935141563415527, 'test/num_examples': 10000, 'score': 45838.346932172775, 'total_duration': 49302.756335020065, 'accumulated_submission_time': 45838.346932172775, 'accumulated_eval_time': 3453.1070244312286, 'accumulated_logging_time': 5.645540475845337}
I0303 01:14:21.243164 140239842563840 logging_writer.py:48] [102695] accumulated_eval_time=3453.107024, accumulated_logging_time=5.645540, accumulated_submission_time=45838.346932, global_step=102695, preemption_count=0, score=45838.346932, test/accuracy=0.569900, test/loss=1.893514, test/num_examples=10000, total_duration=49302.756335, train/accuracy=0.754492, train/loss=0.974499, validation/accuracy=0.691580, validation/loss=1.252242, validation/num_examples=50000
I0303 01:14:23.617208 140239850956544 logging_writer.py:48] [102700] global_step=102700, grad_norm=1.4526227712631226, loss=1.9199978113174438
I0303 01:15:03.840404 140239842563840 logging_writer.py:48] [102800] global_step=102800, grad_norm=1.434959053993225, loss=2.8753366470336914
I0303 01:15:48.656910 140239850956544 logging_writer.py:48] [102900] global_step=102900, grad_norm=1.5656964778900146, loss=1.8933780193328857
I0303 01:16:33.807315 140239842563840 logging_writer.py:48] [103000] global_step=103000, grad_norm=1.7393088340759277, loss=2.351905584335327
I0303 01:17:18.797840 140239850956544 logging_writer.py:48] [103100] global_step=103100, grad_norm=1.4283473491668701, loss=2.0005581378936768
I0303 01:18:03.956049 140239842563840 logging_writer.py:48] [103200] global_step=103200, grad_norm=1.3818907737731934, loss=4.247336387634277
I0303 01:18:48.879041 140239850956544 logging_writer.py:48] [103300] global_step=103300, grad_norm=1.3736556768417358, loss=2.652599573135376
I0303 01:19:33.771570 140239842563840 logging_writer.py:48] [103400] global_step=103400, grad_norm=1.454553484916687, loss=3.3880085945129395
I0303 01:20:18.861292 140239850956544 logging_writer.py:48] [103500] global_step=103500, grad_norm=1.3118494749069214, loss=3.2052059173583984
I0303 01:21:03.691348 140239842563840 logging_writer.py:48] [103600] global_step=103600, grad_norm=1.475429892539978, loss=1.8682215213775635
I0303 01:21:21.436680 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:21:31.424602 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:21:51.901900 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:21:53.532528 140437341357888 submission_runner.py:411] Time since start: 49755.08s, 	Step: 103641, 	{'train/accuracy': 0.76039057970047, 'train/loss': 0.9307794570922852, 'validation/accuracy': 0.6939799785614014, 'validation/loss': 1.2324928045272827, 'validation/num_examples': 50000, 'test/accuracy': 0.5738000273704529, 'test/loss': 1.8720823526382446, 'test/num_examples': 10000, 'score': 46258.4792034626, 'total_duration': 49755.083996772766, 'accumulated_submission_time': 46258.4792034626, 'accumulated_eval_time': 3485.2028307914734, 'accumulated_logging_time': 5.693195819854736}
I0303 01:21:53.570473 140239850956544 logging_writer.py:48] [103641] accumulated_eval_time=3485.202831, accumulated_logging_time=5.693196, accumulated_submission_time=46258.479203, global_step=103641, preemption_count=0, score=46258.479203, test/accuracy=0.573800, test/loss=1.872082, test/num_examples=10000, total_duration=49755.083997, train/accuracy=0.760391, train/loss=0.930779, validation/accuracy=0.693980, validation/loss=1.232493, validation/num_examples=50000
I0303 01:22:17.364756 140239842563840 logging_writer.py:48] [103700] global_step=103700, grad_norm=1.5332283973693848, loss=4.481029510498047
I0303 01:23:01.530408 140239850956544 logging_writer.py:48] [103800] global_step=103800, grad_norm=1.5952856540679932, loss=1.9339354038238525
I0303 01:23:46.854128 140239842563840 logging_writer.py:48] [103900] global_step=103900, grad_norm=1.4590095281600952, loss=2.176938772201538
I0303 01:24:31.690079 140239850956544 logging_writer.py:48] [104000] global_step=104000, grad_norm=1.4888240098953247, loss=3.157393455505371
I0303 01:25:16.632824 140239842563840 logging_writer.py:48] [104100] global_step=104100, grad_norm=1.6079474687576294, loss=1.9425336122512817
I0303 01:26:01.754178 140239850956544 logging_writer.py:48] [104200] global_step=104200, grad_norm=1.5968480110168457, loss=1.8645920753479004
I0303 01:26:47.101463 140239842563840 logging_writer.py:48] [104300] global_step=104300, grad_norm=1.6658477783203125, loss=1.8216633796691895
I0303 01:27:32.383103 140239850956544 logging_writer.py:48] [104400] global_step=104400, grad_norm=1.5560657978057861, loss=1.9326989650726318
I0303 01:28:17.870506 140239842563840 logging_writer.py:48] [104500] global_step=104500, grad_norm=1.5472757816314697, loss=4.225276947021484
I0303 01:28:53.574263 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:29:04.110448 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:29:29.109001 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:29:30.729813 140437341357888 submission_runner.py:411] Time since start: 50212.28s, 	Step: 104581, 	{'train/accuracy': 0.7684960961341858, 'train/loss': 0.922848641872406, 'validation/accuracy': 0.6940000057220459, 'validation/loss': 1.2535018920898438, 'validation/num_examples': 50000, 'test/accuracy': 0.5644000172615051, 'test/loss': 1.9141690731048584, 'test/num_examples': 10000, 'score': 46678.42165637016, 'total_duration': 50212.28129172325, 'accumulated_submission_time': 46678.42165637016, 'accumulated_eval_time': 3522.3583607673645, 'accumulated_logging_time': 5.741758108139038}
I0303 01:29:30.769832 140239850956544 logging_writer.py:48] [104581] accumulated_eval_time=3522.358361, accumulated_logging_time=5.741758, accumulated_submission_time=46678.421656, global_step=104581, preemption_count=0, score=46678.421656, test/accuracy=0.564400, test/loss=1.914169, test/num_examples=10000, total_duration=50212.281292, train/accuracy=0.768496, train/loss=0.922849, validation/accuracy=0.694000, validation/loss=1.253502, validation/num_examples=50000
I0303 01:29:38.710248 140239842563840 logging_writer.py:48] [104600] global_step=104600, grad_norm=1.572954535484314, loss=3.956223964691162
I0303 01:30:20.403950 140239850956544 logging_writer.py:48] [104700] global_step=104700, grad_norm=1.4203076362609863, loss=3.6000585556030273
I0303 01:31:05.719250 140239842563840 logging_writer.py:48] [104800] global_step=104800, grad_norm=1.4037725925445557, loss=3.105717420578003
I0303 01:31:50.556006 140239850956544 logging_writer.py:48] [104900] global_step=104900, grad_norm=1.5567773580551147, loss=3.8281688690185547
I0303 01:32:35.685487 140239842563840 logging_writer.py:48] [105000] global_step=105000, grad_norm=1.577924370765686, loss=1.9239121675491333
I0303 01:33:21.193932 140239850956544 logging_writer.py:48] [105100] global_step=105100, grad_norm=1.3966739177703857, loss=3.500854015350342
I0303 01:34:06.545627 140239842563840 logging_writer.py:48] [105200] global_step=105200, grad_norm=1.5857956409454346, loss=1.8894705772399902
I0303 01:34:51.130930 140239850956544 logging_writer.py:48] [105300] global_step=105300, grad_norm=1.5970146656036377, loss=2.0066773891448975
I0303 01:35:36.500029 140239842563840 logging_writer.py:48] [105400] global_step=105400, grad_norm=1.5774928331375122, loss=4.239666938781738
I0303 01:36:21.743930 140239850956544 logging_writer.py:48] [105500] global_step=105500, grad_norm=1.566770076751709, loss=2.0888442993164062
I0303 01:36:30.863219 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:36:40.965249 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:37:00.400009 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:37:02.038473 140437341357888 submission_runner.py:411] Time since start: 50663.59s, 	Step: 105522, 	{'train/accuracy': 0.7603710889816284, 'train/loss': 0.9424856901168823, 'validation/accuracy': 0.6970199942588806, 'validation/loss': 1.2145726680755615, 'validation/num_examples': 50000, 'test/accuracy': 0.5731000304222107, 'test/loss': 1.8652210235595703, 'test/num_examples': 10000, 'score': 47098.453610897064, 'total_duration': 50663.58996009827, 'accumulated_submission_time': 47098.453610897064, 'accumulated_eval_time': 3553.5336005687714, 'accumulated_logging_time': 5.791807174682617}
I0303 01:37:02.081448 140239842563840 logging_writer.py:48] [105522] accumulated_eval_time=3553.533601, accumulated_logging_time=5.791807, accumulated_submission_time=47098.453611, global_step=105522, preemption_count=0, score=47098.453611, test/accuracy=0.573100, test/loss=1.865221, test/num_examples=10000, total_duration=50663.589960, train/accuracy=0.760371, train/loss=0.942486, validation/accuracy=0.697020, validation/loss=1.214573, validation/num_examples=50000
I0303 01:37:34.213453 140239850956544 logging_writer.py:48] [105600] global_step=105600, grad_norm=1.4246870279312134, loss=2.166370153427124
I0303 01:38:19.373786 140239842563840 logging_writer.py:48] [105700] global_step=105700, grad_norm=1.37607741355896, loss=3.464177131652832
I0303 01:39:04.707855 140239850956544 logging_writer.py:48] [105800] global_step=105800, grad_norm=1.4893858432769775, loss=3.3360648155212402
I0303 01:39:49.752977 140239842563840 logging_writer.py:48] [105900] global_step=105900, grad_norm=1.4906585216522217, loss=1.774768352508545
I0303 01:40:35.116655 140239850956544 logging_writer.py:48] [106000] global_step=106000, grad_norm=1.5953563451766968, loss=1.9799327850341797
I0303 01:41:20.548826 140239842563840 logging_writer.py:48] [106100] global_step=106100, grad_norm=1.435916781425476, loss=1.7994519472122192
I0303 01:42:05.600686 140239850956544 logging_writer.py:48] [106200] global_step=106200, grad_norm=1.6608936786651611, loss=1.9079103469848633
I0303 01:42:50.785799 140239842563840 logging_writer.py:48] [106300] global_step=106300, grad_norm=1.5975826978683472, loss=1.9222241640090942
I0303 01:43:36.406504 140239850956544 logging_writer.py:48] [106400] global_step=106400, grad_norm=1.561309814453125, loss=1.9285967350006104
I0303 01:44:02.369149 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:44:12.598691 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:44:34.995727 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:44:36.622132 140437341357888 submission_runner.py:411] Time since start: 51118.17s, 	Step: 106459, 	{'train/accuracy': 0.7631054520606995, 'train/loss': 0.9237319231033325, 'validation/accuracy': 0.6990599632263184, 'validation/loss': 1.2113115787506104, 'validation/num_examples': 50000, 'test/accuracy': 0.5690000057220459, 'test/loss': 1.8761636018753052, 'test/num_examples': 10000, 'score': 47518.67924666405, 'total_duration': 51118.17361497879, 'accumulated_submission_time': 47518.67924666405, 'accumulated_eval_time': 3587.7865631580353, 'accumulated_logging_time': 5.8463099002838135}
I0303 01:44:36.660591 140239842563840 logging_writer.py:48] [106459] accumulated_eval_time=3587.786563, accumulated_logging_time=5.846310, accumulated_submission_time=47518.679247, global_step=106459, preemption_count=0, score=47518.679247, test/accuracy=0.569000, test/loss=1.876164, test/num_examples=10000, total_duration=51118.173615, train/accuracy=0.763105, train/loss=0.923732, validation/accuracy=0.699060, validation/loss=1.211312, validation/num_examples=50000
I0303 01:44:53.325985 140239850956544 logging_writer.py:48] [106500] global_step=106500, grad_norm=1.4003870487213135, loss=2.6847290992736816
I0303 01:45:36.452185 140239842563840 logging_writer.py:48] [106600] global_step=106600, grad_norm=1.5889142751693726, loss=1.867842674255371
I0303 01:46:21.771382 140239850956544 logging_writer.py:48] [106700] global_step=106700, grad_norm=1.6500067710876465, loss=3.9895124435424805
I0303 01:47:06.946164 140239842563840 logging_writer.py:48] [106800] global_step=106800, grad_norm=1.5564264059066772, loss=1.865036964416504
I0303 01:47:52.155929 140239850956544 logging_writer.py:48] [106900] global_step=106900, grad_norm=1.5670161247253418, loss=1.8745677471160889
I0303 01:48:37.237459 140239842563840 logging_writer.py:48] [107000] global_step=107000, grad_norm=1.5333102941513062, loss=1.8470323085784912
I0303 01:49:22.495100 140239850956544 logging_writer.py:48] [107100] global_step=107100, grad_norm=1.631154179573059, loss=4.220343589782715
I0303 01:50:07.632680 140239842563840 logging_writer.py:48] [107200] global_step=107200, grad_norm=1.3667128086090088, loss=3.7365736961364746
I0303 01:50:52.609867 140239850956544 logging_writer.py:48] [107300] global_step=107300, grad_norm=1.3578842878341675, loss=2.585299491882324
I0303 01:51:36.691013 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:51:46.723731 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:52:08.386514 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:52:10.040161 140437341357888 submission_runner.py:411] Time since start: 51571.59s, 	Step: 107399, 	{'train/accuracy': 0.7676562070846558, 'train/loss': 0.9086039662361145, 'validation/accuracy': 0.6971399784088135, 'validation/loss': 1.2299054861068726, 'validation/num_examples': 50000, 'test/accuracy': 0.5730000138282776, 'test/loss': 1.8663215637207031, 'test/num_examples': 10000, 'score': 47938.64813065529, 'total_duration': 51571.591633319855, 'accumulated_submission_time': 47938.64813065529, 'accumulated_eval_time': 3621.1356875896454, 'accumulated_logging_time': 5.8950090408325195}
I0303 01:52:10.079887 140239842563840 logging_writer.py:48] [107399] accumulated_eval_time=3621.135688, accumulated_logging_time=5.895009, accumulated_submission_time=47938.648131, global_step=107399, preemption_count=0, score=47938.648131, test/accuracy=0.573000, test/loss=1.866322, test/num_examples=10000, total_duration=51571.591633, train/accuracy=0.767656, train/loss=0.908604, validation/accuracy=0.697140, validation/loss=1.229905, validation/num_examples=50000
I0303 01:52:10.873187 140239850956544 logging_writer.py:48] [107400] global_step=107400, grad_norm=1.478845477104187, loss=1.8489545583724976
I0303 01:52:50.492962 140239842563840 logging_writer.py:48] [107500] global_step=107500, grad_norm=1.5251295566558838, loss=1.9296748638153076
I0303 01:53:35.340303 140239850956544 logging_writer.py:48] [107600] global_step=107600, grad_norm=1.484100103378296, loss=1.9268509149551392
I0303 01:54:20.732215 140239842563840 logging_writer.py:48] [107700] global_step=107700, grad_norm=1.575323224067688, loss=2.0168983936309814
I0303 01:55:05.821177 140239850956544 logging_writer.py:48] [107800] global_step=107800, grad_norm=1.5337553024291992, loss=1.9041111469268799
I0303 01:55:50.987556 140239842563840 logging_writer.py:48] [107900] global_step=107900, grad_norm=1.6510368585586548, loss=1.948224425315857
I0303 01:56:36.197584 140239850956544 logging_writer.py:48] [108000] global_step=108000, grad_norm=1.665639877319336, loss=1.998165488243103
I0303 01:57:21.435000 140239842563840 logging_writer.py:48] [108100] global_step=108100, grad_norm=1.6250594854354858, loss=1.931013822555542
I0303 01:58:06.685121 140239850956544 logging_writer.py:48] [108200] global_step=108200, grad_norm=1.5499231815338135, loss=1.8336557149887085
I0303 01:58:51.733509 140239842563840 logging_writer.py:48] [108300] global_step=108300, grad_norm=1.4521551132202148, loss=3.650137186050415
I0303 01:59:10.115536 140437341357888 spec.py:321] Evaluating on the training split.
I0303 01:59:20.147240 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 01:59:40.555209 140437341357888 spec.py:349] Evaluating on the test split.
I0303 01:59:42.183783 140437341357888 submission_runner.py:411] Time since start: 52023.74s, 	Step: 108342, 	{'train/accuracy': 0.7684179544448853, 'train/loss': 0.9172747731208801, 'validation/accuracy': 0.7032999992370605, 'validation/loss': 1.2101258039474487, 'validation/num_examples': 50000, 'test/accuracy': 0.5802000164985657, 'test/loss': 1.8436038494110107, 'test/num_examples': 10000, 'score': 48358.62239551544, 'total_duration': 52023.73527216911, 'accumulated_submission_time': 48358.62239551544, 'accumulated_eval_time': 3653.2039284706116, 'accumulated_logging_time': 5.945183038711548}
I0303 01:59:42.223028 140239850956544 logging_writer.py:48] [108342] accumulated_eval_time=3653.203928, accumulated_logging_time=5.945183, accumulated_submission_time=48358.622396, global_step=108342, preemption_count=0, score=48358.622396, test/accuracy=0.580200, test/loss=1.843604, test/num_examples=10000, total_duration=52023.735272, train/accuracy=0.768418, train/loss=0.917275, validation/accuracy=0.703300, validation/loss=1.210126, validation/num_examples=50000
I0303 02:00:05.592936 140239842563840 logging_writer.py:48] [108400] global_step=108400, grad_norm=1.513549566268921, loss=3.072916269302368
I0303 02:00:49.907655 140239850956544 logging_writer.py:48] [108500] global_step=108500, grad_norm=1.7193400859832764, loss=2.2093865871429443
I0303 02:01:34.906445 140239842563840 logging_writer.py:48] [108600] global_step=108600, grad_norm=1.4062566757202148, loss=2.1799347400665283
I0303 02:02:19.930035 140239850956544 logging_writer.py:48] [108700] global_step=108700, grad_norm=1.5657979249954224, loss=1.8836475610733032
I0303 02:03:04.964437 140239842563840 logging_writer.py:48] [108800] global_step=108800, grad_norm=1.4271272420883179, loss=2.563645362854004
I0303 02:03:50.375602 140239850956544 logging_writer.py:48] [108900] global_step=108900, grad_norm=1.4197092056274414, loss=2.898585319519043
I0303 02:04:35.413364 140239842563840 logging_writer.py:48] [109000] global_step=109000, grad_norm=1.400230884552002, loss=2.959872007369995
I0303 02:05:20.428292 140239850956544 logging_writer.py:48] [109100] global_step=109100, grad_norm=1.588866114616394, loss=1.870942234992981
I0303 02:06:05.703320 140239842563840 logging_writer.py:48] [109200] global_step=109200, grad_norm=1.5411771535873413, loss=4.262465476989746
I0303 02:06:42.390566 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:06:52.686827 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 02:07:14.629573 140437341357888 spec.py:349] Evaluating on the test split.
I0303 02:07:16.256416 140437341357888 submission_runner.py:411] Time since start: 52477.81s, 	Step: 109283, 	{'train/accuracy': 0.7674413919448853, 'train/loss': 0.9051960706710815, 'validation/accuracy': 0.7060799598693848, 'validation/loss': 1.1832246780395508, 'validation/num_examples': 50000, 'test/accuracy': 0.5815000534057617, 'test/loss': 1.822532296180725, 'test/num_examples': 10000, 'score': 48778.72830224037, 'total_duration': 52477.80788874626, 'accumulated_submission_time': 48778.72830224037, 'accumulated_eval_time': 3687.0697605609894, 'accumulated_logging_time': 5.995041608810425}
I0303 02:07:16.293690 140239850956544 logging_writer.py:48] [109283] accumulated_eval_time=3687.069761, accumulated_logging_time=5.995042, accumulated_submission_time=48778.728302, global_step=109283, preemption_count=0, score=48778.728302, test/accuracy=0.581500, test/loss=1.822532, test/num_examples=10000, total_duration=52477.807889, train/accuracy=0.767441, train/loss=0.905196, validation/accuracy=0.706080, validation/loss=1.183225, validation/num_examples=50000
I0303 02:07:23.432258 140239842563840 logging_writer.py:48] [109300] global_step=109300, grad_norm=1.6714155673980713, loss=1.9279910326004028
I0303 02:08:05.470387 140239850956544 logging_writer.py:48] [109400] global_step=109400, grad_norm=1.5621925592422485, loss=3.615508556365967
I0303 02:08:50.624313 140239842563840 logging_writer.py:48] [109500] global_step=109500, grad_norm=1.4108787775039673, loss=2.4327147006988525
I0303 02:09:35.736383 140239850956544 logging_writer.py:48] [109600] global_step=109600, grad_norm=1.6124933958053589, loss=1.8598055839538574
I0303 02:10:20.921516 140239842563840 logging_writer.py:48] [109700] global_step=109700, grad_norm=1.5032390356063843, loss=1.7919435501098633
I0303 02:11:06.037312 140239850956544 logging_writer.py:48] [109800] global_step=109800, grad_norm=1.7573908567428589, loss=1.8357625007629395
I0303 02:11:51.076885 140239842563840 logging_writer.py:48] [109900] global_step=109900, grad_norm=1.783565878868103, loss=2.017867088317871
I0303 02:12:36.182918 140239850956544 logging_writer.py:48] [110000] global_step=110000, grad_norm=1.5023084878921509, loss=3.0244407653808594
I0303 02:13:21.674285 140239842563840 logging_writer.py:48] [110100] global_step=110100, grad_norm=1.5264643430709839, loss=3.793836832046509
I0303 02:14:06.870771 140239850956544 logging_writer.py:48] [110200] global_step=110200, grad_norm=1.68423593044281, loss=2.23225474357605
I0303 02:14:16.474109 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:14:26.358851 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 02:14:47.297245 140437341357888 spec.py:349] Evaluating on the test split.
I0303 02:14:48.928910 140437341357888 submission_runner.py:411] Time since start: 52930.48s, 	Step: 110223, 	{'train/accuracy': 0.77357417345047, 'train/loss': 0.8837026953697205, 'validation/accuracy': 0.7024399638175964, 'validation/loss': 1.1945924758911133, 'validation/num_examples': 50000, 'test/accuracy': 0.5778000354766846, 'test/loss': 1.833355188369751, 'test/num_examples': 10000, 'score': 49198.84672832489, 'total_duration': 52930.480395793915, 'accumulated_submission_time': 49198.84672832489, 'accumulated_eval_time': 3719.5245337486267, 'accumulated_logging_time': 6.0425825119018555}
I0303 02:14:48.971860 140239842563840 logging_writer.py:48] [110223] accumulated_eval_time=3719.524534, accumulated_logging_time=6.042583, accumulated_submission_time=49198.846728, global_step=110223, preemption_count=0, score=49198.846728, test/accuracy=0.577800, test/loss=1.833355, test/num_examples=10000, total_duration=52930.480396, train/accuracy=0.773574, train/loss=0.883703, validation/accuracy=0.702440, validation/loss=1.194592, validation/num_examples=50000
I0303 02:15:19.883871 140239850956544 logging_writer.py:48] [110300] global_step=110300, grad_norm=1.5087765455245972, loss=2.0369014739990234
I0303 02:16:04.799081 140239842563840 logging_writer.py:48] [110400] global_step=110400, grad_norm=1.4470789432525635, loss=3.7544543743133545
I0303 02:16:50.056882 140239850956544 logging_writer.py:48] [110500] global_step=110500, grad_norm=1.5289273262023926, loss=4.0407609939575195
I0303 02:17:35.284554 140239842563840 logging_writer.py:48] [110600] global_step=110600, grad_norm=1.5439826250076294, loss=1.7700289487838745
I0303 02:18:20.567863 140239850956544 logging_writer.py:48] [110700] global_step=110700, grad_norm=1.7664026021957397, loss=4.192934989929199
I0303 02:19:05.593279 140239842563840 logging_writer.py:48] [110800] global_step=110800, grad_norm=1.6181775331497192, loss=1.8702764511108398
I0303 02:19:50.514923 140239842563840 logging_writer.py:48] [110900] global_step=110900, grad_norm=1.681557297706604, loss=4.37009859085083
I0303 02:20:35.963187 140239850956544 logging_writer.py:48] [111000] global_step=111000, grad_norm=1.5523455142974854, loss=4.297401428222656
I0303 02:21:21.174901 140239842563840 logging_writer.py:48] [111100] global_step=111100, grad_norm=1.574052095413208, loss=3.6554038524627686
I0303 02:21:49.288634 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:21:59.281211 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 02:22:22.473018 140437341357888 spec.py:349] Evaluating on the test split.
I0303 02:22:24.096766 140437341357888 submission_runner.py:411] Time since start: 53385.65s, 	Step: 111164, 	{'train/accuracy': 0.7866796851158142, 'train/loss': 0.8273036479949951, 'validation/accuracy': 0.7063199877738953, 'validation/loss': 1.1831731796264648, 'validation/num_examples': 50000, 'test/accuracy': 0.5790000557899475, 'test/loss': 1.8291984796524048, 'test/num_examples': 10000, 'score': 49619.10298538208, 'total_duration': 53385.648253917694, 'accumulated_submission_time': 49619.10298538208, 'accumulated_eval_time': 3754.3326518535614, 'accumulated_logging_time': 6.095505475997925}
I0303 02:22:24.139566 140239850956544 logging_writer.py:48] [111164] accumulated_eval_time=3754.332652, accumulated_logging_time=6.095505, accumulated_submission_time=49619.102985, global_step=111164, preemption_count=0, score=49619.102985, test/accuracy=0.579000, test/loss=1.829198, test/num_examples=10000, total_duration=53385.648254, train/accuracy=0.786680, train/loss=0.827304, validation/accuracy=0.706320, validation/loss=1.183173, validation/num_examples=50000
I0303 02:22:38.805567 140239842563840 logging_writer.py:48] [111200] global_step=111200, grad_norm=1.5797334909439087, loss=4.30705451965332
I0303 02:23:21.274862 140239850956544 logging_writer.py:48] [111300] global_step=111300, grad_norm=1.6994725465774536, loss=1.7585372924804688
I0303 02:24:07.335878 140239842563840 logging_writer.py:48] [111400] global_step=111400, grad_norm=1.6873722076416016, loss=2.0021109580993652
I0303 02:24:52.921762 140239850956544 logging_writer.py:48] [111500] global_step=111500, grad_norm=1.5108728408813477, loss=3.5448904037475586
I0303 02:25:38.461629 140239842563840 logging_writer.py:48] [111600] global_step=111600, grad_norm=1.4437648057937622, loss=2.9406001567840576
I0303 02:26:23.818405 140239850956544 logging_writer.py:48] [111700] global_step=111700, grad_norm=1.6289019584655762, loss=1.9036598205566406
I0303 02:27:09.386890 140239842563840 logging_writer.py:48] [111800] global_step=111800, grad_norm=1.5945261716842651, loss=1.8843587636947632
I0303 02:27:54.614954 140239850956544 logging_writer.py:48] [111900] global_step=111900, grad_norm=1.4189611673355103, loss=2.6545002460479736
I0303 02:28:40.113260 140239842563840 logging_writer.py:48] [112000] global_step=112000, grad_norm=1.540894627571106, loss=3.3887367248535156
I0303 02:29:24.273943 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:29:34.408631 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 02:29:59.775541 140437341357888 spec.py:349] Evaluating on the test split.
I0303 02:30:01.385703 140437341357888 submission_runner.py:411] Time since start: 53842.94s, 	Step: 112098, 	{'train/accuracy': 0.7661523222923279, 'train/loss': 0.9525970816612244, 'validation/accuracy': 0.7068399786949158, 'validation/loss': 1.217895746231079, 'validation/num_examples': 50000, 'test/accuracy': 0.5746000409126282, 'test/loss': 1.8687307834625244, 'test/num_examples': 10000, 'score': 50039.175589084625, 'total_duration': 53842.93714237213, 'accumulated_submission_time': 50039.175589084625, 'accumulated_eval_time': 3791.4443576335907, 'accumulated_logging_time': 6.148894309997559}
I0303 02:30:01.432893 140239850956544 logging_writer.py:48] [112098] accumulated_eval_time=3791.444358, accumulated_logging_time=6.148894, accumulated_submission_time=50039.175589, global_step=112098, preemption_count=0, score=50039.175589, test/accuracy=0.574600, test/loss=1.868731, test/num_examples=10000, total_duration=53842.937142, train/accuracy=0.766152, train/loss=0.952597, validation/accuracy=0.706840, validation/loss=1.217896, validation/num_examples=50000
I0303 02:30:02.628574 140239842563840 logging_writer.py:48] [112100] global_step=112100, grad_norm=1.5433567762374878, loss=4.137821197509766
I0303 02:30:42.282683 140239850956544 logging_writer.py:48] [112200] global_step=112200, grad_norm=1.7875525951385498, loss=1.7751024961471558
I0303 02:31:26.749569 140239842563840 logging_writer.py:48] [112300] global_step=112300, grad_norm=1.69922935962677, loss=4.169225215911865
I0303 02:32:11.967032 140239850956544 logging_writer.py:48] [112400] global_step=112400, grad_norm=1.7485990524291992, loss=1.843530535697937
I0303 02:32:57.196323 140239842563840 logging_writer.py:48] [112500] global_step=112500, grad_norm=1.7016862630844116, loss=1.7625612020492554
I0303 02:33:42.680668 140239850956544 logging_writer.py:48] [112600] global_step=112600, grad_norm=1.6934846639633179, loss=1.7723495960235596
I0303 02:34:28.871181 140239842563840 logging_writer.py:48] [112700] global_step=112700, grad_norm=1.649020791053772, loss=1.8975696563720703
I0303 02:35:13.792950 140239850956544 logging_writer.py:48] [112800] global_step=112800, grad_norm=1.4610435962677002, loss=2.9959943294525146
I0303 02:35:58.855321 140239842563840 logging_writer.py:48] [112900] global_step=112900, grad_norm=1.5843394994735718, loss=1.7602741718292236
I0303 02:36:44.190765 140239850956544 logging_writer.py:48] [113000] global_step=113000, grad_norm=1.4142659902572632, loss=2.86942720413208
I0303 02:37:01.770487 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:37:11.760217 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 02:37:33.217729 140437341357888 spec.py:349] Evaluating on the test split.
I0303 02:37:34.843463 140437341357888 submission_runner.py:411] Time since start: 54296.39s, 	Step: 113041, 	{'train/accuracy': 0.77685546875, 'train/loss': 0.892575740814209, 'validation/accuracy': 0.708139955997467, 'validation/loss': 1.1836878061294556, 'validation/num_examples': 50000, 'test/accuracy': 0.5866000056266785, 'test/loss': 1.8236979246139526, 'test/num_examples': 10000, 'score': 50459.45133137703, 'total_duration': 54296.39494585991, 'accumulated_submission_time': 50459.45133137703, 'accumulated_eval_time': 3824.517323732376, 'accumulated_logging_time': 6.20680570602417}
I0303 02:37:34.886597 140239842563840 logging_writer.py:48] [113041] accumulated_eval_time=3824.517324, accumulated_logging_time=6.206806, accumulated_submission_time=50459.451331, global_step=113041, preemption_count=0, score=50459.451331, test/accuracy=0.586600, test/loss=1.823698, test/num_examples=10000, total_duration=54296.394946, train/accuracy=0.776855, train/loss=0.892576, validation/accuracy=0.708140, validation/loss=1.183688, validation/num_examples=50000
I0303 02:37:58.795736 140239850956544 logging_writer.py:48] [113100] global_step=113100, grad_norm=1.5401605367660522, loss=3.8019471168518066
I0303 02:38:43.027233 140239842563840 logging_writer.py:48] [113200] global_step=113200, grad_norm=1.5068012475967407, loss=3.744302749633789
I0303 02:39:28.325768 140239850956544 logging_writer.py:48] [113300] global_step=113300, grad_norm=1.5983893871307373, loss=1.7393872737884521
I0303 02:40:13.288585 140239842563840 logging_writer.py:48] [113400] global_step=113400, grad_norm=1.557205080986023, loss=3.457296133041382
I0303 02:40:58.256364 140239850956544 logging_writer.py:48] [113500] global_step=113500, grad_norm=1.7290204763412476, loss=1.8329710960388184
I0303 02:41:43.349978 140239842563840 logging_writer.py:48] [113600] global_step=113600, grad_norm=1.4621155261993408, loss=2.36867356300354
I0303 02:42:28.209488 140239850956544 logging_writer.py:48] [113700] global_step=113700, grad_norm=1.5235400199890137, loss=2.349928855895996
I0303 02:43:13.139110 140239842563840 logging_writer.py:48] [113800] global_step=113800, grad_norm=1.6904009580612183, loss=4.185704231262207
I0303 02:43:58.804466 140239850956544 logging_writer.py:48] [113900] global_step=113900, grad_norm=1.6731173992156982, loss=4.298831939697266
I0303 02:44:35.156726 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:44:45.507750 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 02:45:12.104403 140437341357888 spec.py:349] Evaluating on the test split.
I0303 02:45:13.756506 140437341357888 submission_runner.py:411] Time since start: 54755.31s, 	Step: 113982, 	{'train/accuracy': 0.78724604845047, 'train/loss': 0.8162120580673218, 'validation/accuracy': 0.7078999876976013, 'validation/loss': 1.162050485610962, 'validation/num_examples': 50000, 'test/accuracy': 0.5873000025749207, 'test/loss': 1.8146487474441528, 'test/num_examples': 10000, 'score': 50879.65846824646, 'total_duration': 54755.30799412727, 'accumulated_submission_time': 50879.65846824646, 'accumulated_eval_time': 3863.1170892715454, 'accumulated_logging_time': 6.262190341949463}
I0303 02:45:13.791229 140239842563840 logging_writer.py:48] [113982] accumulated_eval_time=3863.117089, accumulated_logging_time=6.262190, accumulated_submission_time=50879.658468, global_step=113982, preemption_count=0, score=50879.658468, test/accuracy=0.587300, test/loss=1.814649, test/num_examples=10000, total_duration=54755.307994, train/accuracy=0.787246, train/loss=0.816212, validation/accuracy=0.707900, validation/loss=1.162050, validation/num_examples=50000
I0303 02:45:21.313193 140239850956544 logging_writer.py:48] [114000] global_step=114000, grad_norm=1.5860010385513306, loss=2.417607307434082
I0303 02:46:02.179906 140239842563840 logging_writer.py:48] [114100] global_step=114100, grad_norm=1.6336954832077026, loss=1.712404727935791
I0303 02:46:47.487349 140239850956544 logging_writer.py:48] [114200] global_step=114200, grad_norm=1.50221848487854, loss=2.1513776779174805
I0303 02:47:32.873490 140239842563840 logging_writer.py:48] [114300] global_step=114300, grad_norm=1.7258670330047607, loss=1.7763794660568237
I0303 02:48:18.080955 140239850956544 logging_writer.py:48] [114400] global_step=114400, grad_norm=1.6709967851638794, loss=1.9494373798370361
I0303 02:49:03.216446 140239842563840 logging_writer.py:48] [114500] global_step=114500, grad_norm=1.5325161218643188, loss=3.182940721511841
I0303 02:49:48.547167 140239850956544 logging_writer.py:48] [114600] global_step=114600, grad_norm=1.738264799118042, loss=1.8854132890701294
I0303 02:50:33.752870 140239842563840 logging_writer.py:48] [114700] global_step=114700, grad_norm=1.7638075351715088, loss=1.7201249599456787
I0303 02:51:18.987414 140239850956544 logging_writer.py:48] [114800] global_step=114800, grad_norm=1.6259710788726807, loss=1.659574031829834
I0303 02:52:03.950578 140239842563840 logging_writer.py:48] [114900] global_step=114900, grad_norm=1.6581753492355347, loss=4.068538665771484
I0303 02:52:14.087024 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:52:24.094773 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 02:52:46.566418 140437341357888 spec.py:349] Evaluating on the test split.
I0303 02:52:48.191044 140437341357888 submission_runner.py:411] Time since start: 55209.74s, 	Step: 114924, 	{'train/accuracy': 0.7758007645606995, 'train/loss': 0.8787176609039307, 'validation/accuracy': 0.7107399702072144, 'validation/loss': 1.1633338928222656, 'validation/num_examples': 50000, 'test/accuracy': 0.5843999981880188, 'test/loss': 1.8155479431152344, 'test/num_examples': 10000, 'score': 51299.89177918434, 'total_duration': 55209.74253320694, 'accumulated_submission_time': 51299.89177918434, 'accumulated_eval_time': 3897.221100330353, 'accumulated_logging_time': 6.308267831802368}
I0303 02:52:48.235079 140239850956544 logging_writer.py:48] [114924] accumulated_eval_time=3897.221100, accumulated_logging_time=6.308268, accumulated_submission_time=51299.891779, global_step=114924, preemption_count=0, score=51299.891779, test/accuracy=0.584400, test/loss=1.815548, test/num_examples=10000, total_duration=55209.742533, train/accuracy=0.775801, train/loss=0.878718, validation/accuracy=0.710740, validation/loss=1.163334, validation/num_examples=50000
I0303 02:53:18.753149 140239842563840 logging_writer.py:48] [115000] global_step=115000, grad_norm=1.7826043367385864, loss=1.9003283977508545
I0303 02:54:03.845486 140239850956544 logging_writer.py:48] [115100] global_step=115100, grad_norm=1.7331782579421997, loss=1.8027369976043701
I0303 02:54:48.927934 140239842563840 logging_writer.py:48] [115200] global_step=115200, grad_norm=1.4917527437210083, loss=3.216092586517334
I0303 02:55:33.965338 140239850956544 logging_writer.py:48] [115300] global_step=115300, grad_norm=1.585610032081604, loss=3.670325994491577
I0303 02:56:19.386757 140239842563840 logging_writer.py:48] [115400] global_step=115400, grad_norm=1.6962624788284302, loss=1.794790506362915
I0303 02:57:04.748999 140239850956544 logging_writer.py:48] [115500] global_step=115500, grad_norm=1.8629549741744995, loss=4.239930152893066
I0303 02:57:49.945777 140239842563840 logging_writer.py:48] [115600] global_step=115600, grad_norm=1.4495025873184204, loss=3.2679131031036377
I0303 02:58:35.361259 140239850956544 logging_writer.py:48] [115700] global_step=115700, grad_norm=1.7095295190811157, loss=2.3590316772460938
I0303 02:59:20.587827 140239842563840 logging_writer.py:48] [115800] global_step=115800, grad_norm=1.5324546098709106, loss=3.0931692123413086
I0303 02:59:48.672509 140437341357888 spec.py:321] Evaluating on the training split.
I0303 02:59:59.136895 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:00:19.303644 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:00:20.922789 140437341357888 submission_runner.py:411] Time since start: 55662.47s, 	Step: 115864, 	{'train/accuracy': 0.7816015481948853, 'train/loss': 0.8619747757911682, 'validation/accuracy': 0.7142999768257141, 'validation/loss': 1.1624583005905151, 'validation/num_examples': 50000, 'test/accuracy': 0.5877000093460083, 'test/loss': 1.806920051574707, 'test/num_examples': 10000, 'score': 51720.268078804016, 'total_duration': 55662.474279880524, 'accumulated_submission_time': 51720.268078804016, 'accumulated_eval_time': 3929.4713776111603, 'accumulated_logging_time': 6.3619771003723145}
I0303 03:00:20.965407 140239850956544 logging_writer.py:48] [115864] accumulated_eval_time=3929.471378, accumulated_logging_time=6.361977, accumulated_submission_time=51720.268079, global_step=115864, preemption_count=0, score=51720.268079, test/accuracy=0.587700, test/loss=1.806920, test/num_examples=10000, total_duration=55662.474280, train/accuracy=0.781602, train/loss=0.861975, validation/accuracy=0.714300, validation/loss=1.162458, validation/num_examples=50000
I0303 03:00:35.636541 140239842563840 logging_writer.py:48] [115900] global_step=115900, grad_norm=1.7894389629364014, loss=1.7880067825317383
I0303 03:01:18.915438 140239850956544 logging_writer.py:48] [116000] global_step=116000, grad_norm=1.7043800354003906, loss=1.8690911531448364
I0303 03:02:04.168714 140239842563840 logging_writer.py:48] [116100] global_step=116100, grad_norm=1.6390430927276611, loss=2.3751132488250732
I0303 03:02:49.322148 140239850956544 logging_writer.py:48] [116200] global_step=116200, grad_norm=1.6088128089904785, loss=3.7393994331359863
I0303 03:03:34.451810 140239842563840 logging_writer.py:48] [116300] global_step=116300, grad_norm=1.6982276439666748, loss=1.900076150894165
I0303 03:04:19.701745 140239850956544 logging_writer.py:48] [116400] global_step=116400, grad_norm=1.7225531339645386, loss=3.672396183013916
I0303 03:05:05.135725 140239842563840 logging_writer.py:48] [116500] global_step=116500, grad_norm=1.6112709045410156, loss=2.256132125854492
I0303 03:05:50.118724 140239850956544 logging_writer.py:48] [116600] global_step=116600, grad_norm=1.66756272315979, loss=1.7950564622879028
I0303 03:06:35.459222 140239842563840 logging_writer.py:48] [116700] global_step=116700, grad_norm=1.438242793083191, loss=2.2697229385375977
I0303 03:07:20.630076 140239850956544 logging_writer.py:48] [116800] global_step=116800, grad_norm=1.7064260244369507, loss=1.7113916873931885
I0303 03:07:21.228255 140437341357888 spec.py:321] Evaluating on the training split.
I0303 03:07:31.482341 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:07:55.019793 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:07:56.634400 140437341357888 submission_runner.py:411] Time since start: 56118.19s, 	Step: 116803, 	{'train/accuracy': 0.7881640195846558, 'train/loss': 0.8116686940193176, 'validation/accuracy': 0.7134599685668945, 'validation/loss': 1.1392488479614258, 'validation/num_examples': 50000, 'test/accuracy': 0.5905000567436218, 'test/loss': 1.7739776372909546, 'test/num_examples': 10000, 'score': 52140.46926808357, 'total_duration': 56118.18588399887, 'accumulated_submission_time': 52140.46926808357, 'accumulated_eval_time': 3964.8775465488434, 'accumulated_logging_time': 6.414790630340576}
I0303 03:07:56.675315 140239842563840 logging_writer.py:48] [116803] accumulated_eval_time=3964.877547, accumulated_logging_time=6.414791, accumulated_submission_time=52140.469268, global_step=116803, preemption_count=0, score=52140.469268, test/accuracy=0.590500, test/loss=1.773978, test/num_examples=10000, total_duration=56118.185884, train/accuracy=0.788164, train/loss=0.811669, validation/accuracy=0.713460, validation/loss=1.139249, validation/num_examples=50000
I0303 03:08:36.670500 140239850956544 logging_writer.py:48] [116900] global_step=116900, grad_norm=1.6922643184661865, loss=4.2079010009765625
I0303 03:09:21.821978 140239842563840 logging_writer.py:48] [117000] global_step=117000, grad_norm=1.587011456489563, loss=1.7247107028961182
I0303 03:10:06.908398 140239850956544 logging_writer.py:48] [117100] global_step=117100, grad_norm=1.5393650531768799, loss=2.0294220447540283
I0303 03:10:51.921750 140239842563840 logging_writer.py:48] [117200] global_step=117200, grad_norm=1.6937904357910156, loss=3.982151746749878
I0303 03:11:37.131946 140239850956544 logging_writer.py:48] [117300] global_step=117300, grad_norm=1.5607340335845947, loss=2.49104380607605
I0303 03:12:21.960021 140239842563840 logging_writer.py:48] [117400] global_step=117400, grad_norm=1.6209396123886108, loss=1.93199622631073
I0303 03:13:07.073866 140239850956544 logging_writer.py:48] [117500] global_step=117500, grad_norm=1.6961458921432495, loss=1.757054328918457
I0303 03:13:52.510597 140239842563840 logging_writer.py:48] [117600] global_step=117600, grad_norm=1.551202654838562, loss=2.060140371322632
I0303 03:14:38.210125 140239850956544 logging_writer.py:48] [117700] global_step=117700, grad_norm=1.652306318283081, loss=4.067122459411621
I0303 03:14:57.014880 140437341357888 spec.py:321] Evaluating on the training split.
I0303 03:15:06.736436 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:15:28.292282 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:15:29.921397 140437341357888 submission_runner.py:411] Time since start: 56571.47s, 	Step: 117743, 	{'train/accuracy': 0.7998046875, 'train/loss': 0.7883418202400208, 'validation/accuracy': 0.7152000069618225, 'validation/loss': 1.1490259170532227, 'validation/num_examples': 50000, 'test/accuracy': 0.5903000235557556, 'test/loss': 1.7920637130737305, 'test/num_examples': 10000, 'score': 52560.747259140015, 'total_duration': 56571.47288775444, 'accumulated_submission_time': 52560.747259140015, 'accumulated_eval_time': 3997.784056663513, 'accumulated_logging_time': 6.465289831161499}
I0303 03:15:29.965167 140239842563840 logging_writer.py:48] [117743] accumulated_eval_time=3997.784057, accumulated_logging_time=6.465290, accumulated_submission_time=52560.747259, global_step=117743, preemption_count=0, score=52560.747259, test/accuracy=0.590300, test/loss=1.792064, test/num_examples=10000, total_duration=56571.472888, train/accuracy=0.799805, train/loss=0.788342, validation/accuracy=0.715200, validation/loss=1.149026, validation/num_examples=50000
I0303 03:15:52.939444 140239850956544 logging_writer.py:48] [117800] global_step=117800, grad_norm=1.5571452379226685, loss=2.140838861465454
I0303 03:16:37.378151 140239842563840 logging_writer.py:48] [117900] global_step=117900, grad_norm=1.6055235862731934, loss=1.6903237104415894
I0303 03:17:23.127070 140239850956544 logging_writer.py:48] [118000] global_step=118000, grad_norm=1.5662403106689453, loss=2.520475149154663
I0303 03:18:08.501834 140239842563840 logging_writer.py:48] [118100] global_step=118100, grad_norm=1.706200361251831, loss=1.742232084274292
I0303 03:18:53.999342 140239850956544 logging_writer.py:48] [118200] global_step=118200, grad_norm=1.733755111694336, loss=1.788184404373169
I0303 03:19:39.212506 140239842563840 logging_writer.py:48] [118300] global_step=118300, grad_norm=1.648202896118164, loss=1.7016042470932007
I0303 03:20:24.539809 140239850956544 logging_writer.py:48] [118400] global_step=118400, grad_norm=1.5657764673233032, loss=2.7698917388916016
I0303 03:21:09.851360 140239842563840 logging_writer.py:48] [118500] global_step=118500, grad_norm=1.6183334589004517, loss=2.0186238288879395
I0303 03:21:55.150489 140239850956544 logging_writer.py:48] [118600] global_step=118600, grad_norm=1.7088038921356201, loss=1.726294994354248
I0303 03:22:30.036421 140437341357888 spec.py:321] Evaluating on the training split.
I0303 03:22:40.114625 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:23:00.490462 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:23:02.114452 140437341357888 submission_runner.py:411] Time since start: 57023.67s, 	Step: 118679, 	{'train/accuracy': 0.7859179377555847, 'train/loss': 0.825340986251831, 'validation/accuracy': 0.7155599594116211, 'validation/loss': 1.1319674253463745, 'validation/num_examples': 50000, 'test/accuracy': 0.5915000438690186, 'test/loss': 1.7688794136047363, 'test/num_examples': 10000, 'score': 52980.7577688694, 'total_duration': 57023.665910959244, 'accumulated_submission_time': 52980.7577688694, 'accumulated_eval_time': 4029.862047433853, 'accumulated_logging_time': 6.51940655708313}
I0303 03:23:02.168807 140239842563840 logging_writer.py:48] [118679] accumulated_eval_time=4029.862047, accumulated_logging_time=6.519407, accumulated_submission_time=52980.757769, global_step=118679, preemption_count=0, score=52980.757769, test/accuracy=0.591500, test/loss=1.768879, test/num_examples=10000, total_duration=57023.665911, train/accuracy=0.785918, train/loss=0.825341, validation/accuracy=0.715560, validation/loss=1.131967, validation/num_examples=50000
I0303 03:23:10.971642 140239850956544 logging_writer.py:48] [118700] global_step=118700, grad_norm=1.903291940689087, loss=1.7581491470336914
I0303 03:23:53.215353 140239842563840 logging_writer.py:48] [118800] global_step=118800, grad_norm=1.6510608196258545, loss=1.992105484008789
I0303 03:24:38.657937 140239850956544 logging_writer.py:48] [118900] global_step=118900, grad_norm=1.4537841081619263, loss=2.547945261001587
I0303 03:25:23.632497 140239842563840 logging_writer.py:48] [119000] global_step=119000, grad_norm=1.784990668296814, loss=1.6505892276763916
I0303 03:26:08.942587 140239850956544 logging_writer.py:48] [119100] global_step=119100, grad_norm=1.5395221710205078, loss=2.1731114387512207
I0303 03:26:53.918375 140239842563840 logging_writer.py:48] [119200] global_step=119200, grad_norm=1.64154052734375, loss=2.6105566024780273
I0303 03:27:38.963327 140239850956544 logging_writer.py:48] [119300] global_step=119300, grad_norm=1.6737747192382812, loss=1.7835149765014648
I0303 03:28:24.051133 140239842563840 logging_writer.py:48] [119400] global_step=119400, grad_norm=1.7688040733337402, loss=1.7825199365615845
I0303 03:29:09.366147 140239850956544 logging_writer.py:48] [119500] global_step=119500, grad_norm=1.6274044513702393, loss=3.9525158405303955
I0303 03:29:54.705563 140239842563840 logging_writer.py:48] [119600] global_step=119600, grad_norm=1.6371185779571533, loss=1.9305812120437622
I0303 03:30:02.520242 140437341357888 spec.py:321] Evaluating on the training split.
I0303 03:30:12.472210 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:30:34.532852 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:30:36.151217 140437341357888 submission_runner.py:411] Time since start: 57477.70s, 	Step: 119619, 	{'train/accuracy': 0.7870898246765137, 'train/loss': 0.8163532614707947, 'validation/accuracy': 0.7176799774169922, 'validation/loss': 1.1236371994018555, 'validation/num_examples': 50000, 'test/accuracy': 0.5887000560760498, 'test/loss': 1.7725476026535034, 'test/num_examples': 10000, 'score': 53401.04287528992, 'total_duration': 57477.70270061493, 'accumulated_submission_time': 53401.04287528992, 'accumulated_eval_time': 4063.4930033683777, 'accumulated_logging_time': 6.587791919708252}
I0303 03:30:36.198030 140239850956544 logging_writer.py:48] [119619] accumulated_eval_time=4063.493003, accumulated_logging_time=6.587792, accumulated_submission_time=53401.042875, global_step=119619, preemption_count=0, score=53401.042875, test/accuracy=0.588700, test/loss=1.772548, test/num_examples=10000, total_duration=57477.702701, train/accuracy=0.787090, train/loss=0.816353, validation/accuracy=0.717680, validation/loss=1.123637, validation/num_examples=50000
I0303 03:31:08.951844 140239842563840 logging_writer.py:48] [119700] global_step=119700, grad_norm=1.7236392498016357, loss=2.1776375770568848
I0303 03:31:53.853458 140239850956544 logging_writer.py:48] [119800] global_step=119800, grad_norm=1.509310007095337, loss=2.3727385997772217
I0303 03:32:38.869923 140239842563840 logging_writer.py:48] [119900] global_step=119900, grad_norm=1.7278491258621216, loss=1.901710867881775
I0303 03:33:23.988723 140239850956544 logging_writer.py:48] [120000] global_step=120000, grad_norm=1.655341625213623, loss=3.5611488819122314
I0303 03:34:09.166699 140239842563840 logging_writer.py:48] [120100] global_step=120100, grad_norm=1.7148914337158203, loss=1.784745454788208
I0303 03:34:54.544035 140239850956544 logging_writer.py:48] [120200] global_step=120200, grad_norm=1.7658004760742188, loss=1.7213282585144043
I0303 03:35:39.807067 140239842563840 logging_writer.py:48] [120300] global_step=120300, grad_norm=1.8116151094436646, loss=1.790664792060852
I0303 03:36:25.172107 140239850956544 logging_writer.py:48] [120400] global_step=120400, grad_norm=1.7343294620513916, loss=2.041703939437866
I0303 03:37:10.828197 140239842563840 logging_writer.py:48] [120500] global_step=120500, grad_norm=1.9120954275131226, loss=1.7531418800354004
I0303 03:37:36.174343 140437341357888 spec.py:321] Evaluating on the training split.
I0303 03:37:46.208121 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:38:14.493939 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:38:16.145067 140437341357888 submission_runner.py:411] Time since start: 57937.70s, 	Step: 120558, 	{'train/accuracy': 0.7944140434265137, 'train/loss': 0.8256067633628845, 'validation/accuracy': 0.7125999927520752, 'validation/loss': 1.1662746667861938, 'validation/num_examples': 50000, 'test/accuracy': 0.5924000144004822, 'test/loss': 1.7938237190246582, 'test/num_examples': 10000, 'score': 53820.95779657364, 'total_duration': 57937.69656896591, 'accumulated_submission_time': 53820.95779657364, 'accumulated_eval_time': 4103.4637269973755, 'accumulated_logging_time': 6.644713640213013}
I0303 03:38:16.183273 140239850956544 logging_writer.py:48] [120558] accumulated_eval_time=4103.463727, accumulated_logging_time=6.644714, accumulated_submission_time=53820.957797, global_step=120558, preemption_count=0, score=53820.957797, test/accuracy=0.592400, test/loss=1.793824, test/num_examples=10000, total_duration=57937.696569, train/accuracy=0.794414, train/loss=0.825607, validation/accuracy=0.712600, validation/loss=1.166275, validation/num_examples=50000
I0303 03:38:33.212948 140239842563840 logging_writer.py:48] [120600] global_step=120600, grad_norm=1.7350316047668457, loss=2.418550491333008
I0303 03:39:14.814107 140239850956544 logging_writer.py:48] [120700] global_step=120700, grad_norm=1.724498987197876, loss=1.789857029914856
I0303 03:39:59.847086 140239842563840 logging_writer.py:48] [120800] global_step=120800, grad_norm=1.583977460861206, loss=2.9139468669891357
I0303 03:40:44.814030 140239850956544 logging_writer.py:48] [120900] global_step=120900, grad_norm=1.6808511018753052, loss=1.6541105508804321
I0303 03:41:30.006099 140239842563840 logging_writer.py:48] [121000] global_step=121000, grad_norm=1.8052438497543335, loss=1.978247880935669
I0303 03:42:14.895421 140239850956544 logging_writer.py:48] [121100] global_step=121100, grad_norm=1.7009328603744507, loss=1.7000157833099365
I0303 03:42:59.538629 140239842563840 logging_writer.py:48] [121200] global_step=121200, grad_norm=1.9053536653518677, loss=1.829580545425415
I0303 03:43:44.609591 140239850956544 logging_writer.py:48] [121300] global_step=121300, grad_norm=1.777022123336792, loss=1.837671160697937
I0303 03:44:29.932547 140239842563840 logging_writer.py:48] [121400] global_step=121400, grad_norm=1.6594592332839966, loss=1.6443661451339722
I0303 03:45:15.149847 140239850956544 logging_writer.py:48] [121500] global_step=121500, grad_norm=1.849316954612732, loss=1.7783267498016357
I0303 03:45:16.219494 140437341357888 spec.py:321] Evaluating on the training split.
I0303 03:45:26.043298 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:45:48.720759 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:45:50.349086 140437341357888 submission_runner.py:411] Time since start: 58391.90s, 	Step: 121504, 	{'train/accuracy': 0.78466796875, 'train/loss': 0.866515576839447, 'validation/accuracy': 0.7185399532318115, 'validation/loss': 1.1521672010421753, 'validation/num_examples': 50000, 'test/accuracy': 0.5913000106811523, 'test/loss': 1.7923246622085571, 'test/num_examples': 10000, 'score': 54240.93333983421, 'total_duration': 58391.900562524796, 'accumulated_submission_time': 54240.93333983421, 'accumulated_eval_time': 4137.593298435211, 'accumulated_logging_time': 6.69199538230896}
I0303 03:45:50.388659 140239842563840 logging_writer.py:48] [121504] accumulated_eval_time=4137.593298, accumulated_logging_time=6.691995, accumulated_submission_time=54240.933340, global_step=121504, preemption_count=0, score=54240.933340, test/accuracy=0.591300, test/loss=1.792325, test/num_examples=10000, total_duration=58391.900563, train/accuracy=0.784668, train/loss=0.866516, validation/accuracy=0.718540, validation/loss=1.152167, validation/num_examples=50000
I0303 03:46:29.896963 140239850956544 logging_writer.py:48] [121600] global_step=121600, grad_norm=1.7063041925430298, loss=3.8777594566345215
I0303 03:47:15.138147 140239842563840 logging_writer.py:48] [121700] global_step=121700, grad_norm=1.636200189590454, loss=3.7986252307891846
I0303 03:48:00.372024 140239850956544 logging_writer.py:48] [121800] global_step=121800, grad_norm=1.9294525384902954, loss=4.039220809936523
I0303 03:48:45.645617 140239842563840 logging_writer.py:48] [121900] global_step=121900, grad_norm=1.5772029161453247, loss=2.5761489868164062
I0303 03:49:30.974192 140239850956544 logging_writer.py:48] [122000] global_step=122000, grad_norm=1.8961365222930908, loss=4.0209503173828125
I0303 03:50:16.244373 140239842563840 logging_writer.py:48] [122100] global_step=122100, grad_norm=1.6772189140319824, loss=1.6976960897445679
I0303 03:51:01.539782 140239850956544 logging_writer.py:48] [122200] global_step=122200, grad_norm=1.7264436483383179, loss=1.7295820713043213
I0303 03:51:46.941853 140239842563840 logging_writer.py:48] [122300] global_step=122300, grad_norm=1.6397656202316284, loss=2.7587804794311523
I0303 03:52:32.013368 140239850956544 logging_writer.py:48] [122400] global_step=122400, grad_norm=1.7409592866897583, loss=1.7250640392303467
I0303 03:52:50.432911 140437341357888 spec.py:321] Evaluating on the training split.
I0303 03:53:00.846040 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 03:53:21.604947 140437341357888 spec.py:349] Evaluating on the test split.
I0303 03:53:23.224845 140437341357888 submission_runner.py:411] Time since start: 58844.78s, 	Step: 122443, 	{'train/accuracy': 0.7889843583106995, 'train/loss': 0.8201755285263062, 'validation/accuracy': 0.7201600074768066, 'validation/loss': 1.1214879751205444, 'validation/num_examples': 50000, 'test/accuracy': 0.5937000513076782, 'test/loss': 1.7646859884262085, 'test/num_examples': 10000, 'score': 54660.913823604584, 'total_duration': 58844.77633571625, 'accumulated_submission_time': 54660.913823604584, 'accumulated_eval_time': 4170.385221481323, 'accumulated_logging_time': 6.743417024612427}
I0303 03:53:23.269471 140239842563840 logging_writer.py:48] [122443] accumulated_eval_time=4170.385221, accumulated_logging_time=6.743417, accumulated_submission_time=54660.913824, global_step=122443, preemption_count=0, score=54660.913824, test/accuracy=0.593700, test/loss=1.764686, test/num_examples=10000, total_duration=58844.776336, train/accuracy=0.788984, train/loss=0.820176, validation/accuracy=0.720160, validation/loss=1.121488, validation/num_examples=50000
I0303 03:53:46.253351 140239850956544 logging_writer.py:48] [122500] global_step=122500, grad_norm=1.8169511556625366, loss=1.896050214767456
I0303 03:54:30.765751 140239842563840 logging_writer.py:48] [122600] global_step=122600, grad_norm=1.7185509204864502, loss=1.9523218870162964
I0303 03:55:16.321164 140239850956544 logging_writer.py:48] [122700] global_step=122700, grad_norm=1.6453133821487427, loss=2.3623716831207275
I0303 03:56:01.207906 140239842563840 logging_writer.py:48] [122800] global_step=122800, grad_norm=1.7307387590408325, loss=1.7352899312973022
I0303 03:56:46.774544 140239850956544 logging_writer.py:48] [122900] global_step=122900, grad_norm=1.6860145330429077, loss=1.6347378492355347
I0303 03:57:32.037447 140239842563840 logging_writer.py:48] [123000] global_step=123000, grad_norm=1.784298062324524, loss=1.8321975469589233
I0303 03:58:17.330996 140239850956544 logging_writer.py:48] [123100] global_step=123100, grad_norm=1.7064117193222046, loss=3.3320882320404053
I0303 03:59:02.704159 140239842563840 logging_writer.py:48] [123200] global_step=123200, grad_norm=1.8396027088165283, loss=1.6625691652297974
I0303 03:59:47.674482 140239850956544 logging_writer.py:48] [123300] global_step=123300, grad_norm=1.6973097324371338, loss=2.5135178565979004
I0303 04:00:23.634435 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:00:33.686454 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:00:56.467738 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:00:58.091948 140437341357888 submission_runner.py:411] Time since start: 59299.64s, 	Step: 123381, 	{'train/accuracy': 0.8001562356948853, 'train/loss': 0.7793758511543274, 'validation/accuracy': 0.7241399884223938, 'validation/loss': 1.10870361328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5998000502586365, 'test/loss': 1.7507137060165405, 'test/num_examples': 10000, 'score': 55081.21804690361, 'total_duration': 59299.64342093468, 'accumulated_submission_time': 55081.21804690361, 'accumulated_eval_time': 4204.8427193164825, 'accumulated_logging_time': 6.7984137535095215}
I0303 04:00:58.137735 140239842563840 logging_writer.py:48] [123381] accumulated_eval_time=4204.842719, accumulated_logging_time=6.798414, accumulated_submission_time=55081.218047, global_step=123381, preemption_count=0, score=55081.218047, test/accuracy=0.599800, test/loss=1.750714, test/num_examples=10000, total_duration=59299.643421, train/accuracy=0.800156, train/loss=0.779376, validation/accuracy=0.724140, validation/loss=1.108704, validation/num_examples=50000
I0303 04:01:06.067445 140239850956544 logging_writer.py:48] [123400] global_step=123400, grad_norm=1.8069435358047485, loss=1.514124870300293
I0303 04:01:47.433536 140239842563840 logging_writer.py:48] [123500] global_step=123500, grad_norm=1.479209303855896, loss=2.4103260040283203
I0303 04:02:32.825769 140239850956544 logging_writer.py:48] [123600] global_step=123600, grad_norm=1.7433700561523438, loss=3.0919785499572754
I0303 04:03:17.931230 140239842563840 logging_writer.py:48] [123700] global_step=123700, grad_norm=1.5440770387649536, loss=2.4404354095458984
I0303 04:04:03.324790 140239850956544 logging_writer.py:48] [123800] global_step=123800, grad_norm=1.8015172481536865, loss=3.7637057304382324
I0303 04:04:48.681362 140239842563840 logging_writer.py:48] [123900] global_step=123900, grad_norm=1.6969503164291382, loss=2.2801740169525146
I0303 04:05:33.797827 140239850956544 logging_writer.py:48] [124000] global_step=124000, grad_norm=1.8388787508010864, loss=2.498608350753784
I0303 04:06:19.260729 140239842563840 logging_writer.py:48] [124100] global_step=124100, grad_norm=1.8121017217636108, loss=3.1351442337036133
I0303 04:07:04.464049 140239850956544 logging_writer.py:48] [124200] global_step=124200, grad_norm=1.896794319152832, loss=1.5505099296569824
I0303 04:07:49.865651 140239842563840 logging_writer.py:48] [124300] global_step=124300, grad_norm=1.835044503211975, loss=1.8896734714508057
I0303 04:07:58.209849 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:08:08.390652 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:08:39.859220 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:08:41.485722 140437341357888 submission_runner.py:411] Time since start: 59763.04s, 	Step: 124320, 	{'train/accuracy': 0.8098242282867432, 'train/loss': 0.7531871795654297, 'validation/accuracy': 0.720579981803894, 'validation/loss': 1.1280159950256348, 'validation/num_examples': 50000, 'test/accuracy': 0.5972000360488892, 'test/loss': 1.7637840509414673, 'test/num_examples': 10000, 'score': 55501.22751235962, 'total_duration': 59763.037217378616, 'accumulated_submission_time': 55501.22751235962, 'accumulated_eval_time': 4248.118583202362, 'accumulated_logging_time': 6.8555824756622314}
I0303 04:08:41.519664 140239850956544 logging_writer.py:48] [124320] accumulated_eval_time=4248.118583, accumulated_logging_time=6.855582, accumulated_submission_time=55501.227512, global_step=124320, preemption_count=0, score=55501.227512, test/accuracy=0.597200, test/loss=1.763784, test/num_examples=10000, total_duration=59763.037217, train/accuracy=0.809824, train/loss=0.753187, validation/accuracy=0.720580, validation/loss=1.128016, validation/num_examples=50000
I0303 04:09:13.577623 140239842563840 logging_writer.py:48] [124400] global_step=124400, grad_norm=1.6486990451812744, loss=2.9243693351745605
I0303 04:09:57.033614 140239850956544 logging_writer.py:48] [124500] global_step=124500, grad_norm=1.8767883777618408, loss=3.9982564449310303
I0303 04:10:42.344263 140239842563840 logging_writer.py:48] [124600] global_step=124600, grad_norm=1.7851505279541016, loss=3.278252601623535
I0303 04:11:27.578525 140239850956544 logging_writer.py:48] [124700] global_step=124700, grad_norm=1.7240180969238281, loss=3.051865339279175
I0303 04:12:13.175629 140239842563840 logging_writer.py:48] [124800] global_step=124800, grad_norm=1.882914423942566, loss=2.8794522285461426
I0303 04:12:57.891129 140239850956544 logging_writer.py:48] [124900] global_step=124900, grad_norm=1.7089757919311523, loss=1.888338565826416
I0303 04:13:42.832561 140239842563840 logging_writer.py:48] [125000] global_step=125000, grad_norm=1.836279034614563, loss=2.029829740524292
I0303 04:14:28.367941 140239850956544 logging_writer.py:48] [125100] global_step=125100, grad_norm=1.6276493072509766, loss=2.2161455154418945
I0303 04:15:13.784835 140239842563840 logging_writer.py:48] [125200] global_step=125200, grad_norm=1.817002534866333, loss=3.285377025604248
I0303 04:15:41.613086 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:15:51.715172 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:16:12.315056 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:16:13.941270 140437341357888 submission_runner.py:411] Time since start: 60215.49s, 	Step: 125263, 	{'train/accuracy': 0.7971484065055847, 'train/loss': 0.7829906344413757, 'validation/accuracy': 0.7261599898338318, 'validation/loss': 1.0861806869506836, 'validation/num_examples': 50000, 'test/accuracy': 0.5982000231742859, 'test/loss': 1.7279510498046875, 'test/num_examples': 10000, 'score': 55921.260788440704, 'total_duration': 60215.49275445938, 'accumulated_submission_time': 55921.260788440704, 'accumulated_eval_time': 4280.447121620178, 'accumulated_logging_time': 6.898099422454834}
I0303 04:16:13.992084 140239850956544 logging_writer.py:48] [125263] accumulated_eval_time=4280.447122, accumulated_logging_time=6.898099, accumulated_submission_time=55921.260788, global_step=125263, preemption_count=0, score=55921.260788, test/accuracy=0.598200, test/loss=1.727951, test/num_examples=10000, total_duration=60215.492754, train/accuracy=0.797148, train/loss=0.782991, validation/accuracy=0.726160, validation/loss=1.086181, validation/num_examples=50000
I0303 04:16:29.045816 140239842563840 logging_writer.py:48] [125300] global_step=125300, grad_norm=1.6223688125610352, loss=2.5961685180664062
I0303 04:17:12.661359 140239850956544 logging_writer.py:48] [125400] global_step=125400, grad_norm=1.776041030883789, loss=1.5932921171188354
I0303 04:17:58.233150 140239842563840 logging_writer.py:48] [125500] global_step=125500, grad_norm=1.912488579750061, loss=1.7774608135223389
I0303 04:18:43.486306 140239850956544 logging_writer.py:48] [125600] global_step=125600, grad_norm=1.9408538341522217, loss=3.784792184829712
I0303 04:19:28.873063 140239842563840 logging_writer.py:48] [125700] global_step=125700, grad_norm=1.6849477291107178, loss=1.6966371536254883
I0303 04:20:14.017882 140239850956544 logging_writer.py:48] [125800] global_step=125800, grad_norm=1.9927129745483398, loss=1.613175630569458
I0303 04:20:58.990037 140239842563840 logging_writer.py:48] [125900] global_step=125900, grad_norm=1.623663306236267, loss=2.715479612350464
I0303 04:21:44.641794 140239850956544 logging_writer.py:48] [126000] global_step=126000, grad_norm=1.8012585639953613, loss=1.8021479845046997
I0303 04:22:30.023756 140239842563840 logging_writer.py:48] [126100] global_step=126100, grad_norm=1.7929991483688354, loss=1.5972212553024292
I0303 04:23:14.060961 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:23:24.552447 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:23:45.031244 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:23:46.653098 140437341357888 submission_runner.py:411] Time since start: 60668.20s, 	Step: 126199, 	{'train/accuracy': 0.802539050579071, 'train/loss': 0.7490731477737427, 'validation/accuracy': 0.7263999581336975, 'validation/loss': 1.0830198526382446, 'validation/num_examples': 50000, 'test/accuracy': 0.6076000332832336, 'test/loss': 1.6989731788635254, 'test/num_examples': 10000, 'score': 56341.26990056038, 'total_duration': 60668.204579114914, 'accumulated_submission_time': 56341.26990056038, 'accumulated_eval_time': 4313.0392434597015, 'accumulated_logging_time': 6.958737850189209}
I0303 04:23:46.695672 140239850956544 logging_writer.py:48] [126199] accumulated_eval_time=4313.039243, accumulated_logging_time=6.958738, accumulated_submission_time=56341.269901, global_step=126199, preemption_count=0, score=56341.269901, test/accuracy=0.607600, test/loss=1.698973, test/num_examples=10000, total_duration=60668.204579, train/accuracy=0.802539, train/loss=0.749073, validation/accuracy=0.726400, validation/loss=1.083020, validation/num_examples=50000
I0303 04:23:47.499719 140239842563840 logging_writer.py:48] [126200] global_step=126200, grad_norm=1.9356067180633545, loss=3.8871867656707764
I0303 04:24:29.005486 140239850956544 logging_writer.py:48] [126300] global_step=126300, grad_norm=1.8833009004592896, loss=1.7498927116394043
I0303 04:25:14.374559 140239842563840 logging_writer.py:48] [126400] global_step=126400, grad_norm=1.7543988227844238, loss=2.9998791217803955
I0303 04:25:59.732178 140239850956544 logging_writer.py:48] [126500] global_step=126500, grad_norm=1.784324049949646, loss=1.656553864479065
I0303 04:26:45.074812 140239842563840 logging_writer.py:48] [126600] global_step=126600, grad_norm=1.7826050519943237, loss=1.8723825216293335
I0303 04:27:30.542330 140239850956544 logging_writer.py:48] [126700] global_step=126700, grad_norm=1.7285593748092651, loss=2.8346519470214844
I0303 04:28:15.936198 140239842563840 logging_writer.py:48] [126800] global_step=126800, grad_norm=1.8124916553497314, loss=1.4952442646026611
I0303 04:29:00.966454 140239850956544 logging_writer.py:48] [126900] global_step=126900, grad_norm=1.7705163955688477, loss=1.6467468738555908
I0303 04:29:46.035900 140239842563840 logging_writer.py:48] [127000] global_step=127000, grad_norm=1.7247285842895508, loss=2.027940034866333
I0303 04:30:31.250189 140239850956544 logging_writer.py:48] [127100] global_step=127100, grad_norm=1.7608329057693481, loss=2.9913382530212402
I0303 04:30:47.022693 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:30:56.938619 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:31:22.411357 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:31:24.037607 140437341357888 submission_runner.py:411] Time since start: 61125.59s, 	Step: 127137, 	{'train/accuracy': 0.8118359446525574, 'train/loss': 0.7276731133460999, 'validation/accuracy': 0.7282399535179138, 'validation/loss': 1.0818513631820679, 'validation/num_examples': 50000, 'test/accuracy': 0.6055999994277954, 'test/loss': 1.7176285982131958, 'test/num_examples': 10000, 'score': 56761.53534936905, 'total_duration': 61125.58907032013, 'accumulated_submission_time': 56761.53534936905, 'accumulated_eval_time': 4350.054116725922, 'accumulated_logging_time': 7.012200832366943}
I0303 04:31:24.080790 140239842563840 logging_writer.py:48] [127137] accumulated_eval_time=4350.054117, accumulated_logging_time=7.012201, accumulated_submission_time=56761.535349, global_step=127137, preemption_count=0, score=56761.535349, test/accuracy=0.605600, test/loss=1.717629, test/num_examples=10000, total_duration=61125.589070, train/accuracy=0.811836, train/loss=0.727673, validation/accuracy=0.728240, validation/loss=1.081851, validation/num_examples=50000
I0303 04:31:49.455466 140239850956544 logging_writer.py:48] [127200] global_step=127200, grad_norm=1.9031651020050049, loss=1.5585557222366333
I0303 04:32:33.373199 140239842563840 logging_writer.py:48] [127300] global_step=127300, grad_norm=1.6969585418701172, loss=2.2242183685302734
I0303 04:33:18.512447 140239850956544 logging_writer.py:48] [127400] global_step=127400, grad_norm=1.8847335577011108, loss=3.075007915496826
I0303 04:34:03.893812 140239842563840 logging_writer.py:48] [127500] global_step=127500, grad_norm=1.7494556903839111, loss=1.7811870574951172
I0303 04:34:49.020560 140239850956544 logging_writer.py:48] [127600] global_step=127600, grad_norm=1.6617498397827148, loss=3.2986297607421875
I0303 04:35:34.441717 140239842563840 logging_writer.py:48] [127700] global_step=127700, grad_norm=1.7162467241287231, loss=3.483567714691162
I0303 04:36:19.742999 140239850956544 logging_writer.py:48] [127800] global_step=127800, grad_norm=1.9219048023223877, loss=1.6335917711257935
I0303 04:37:05.053840 140239842563840 logging_writer.py:48] [127900] global_step=127900, grad_norm=1.921498417854309, loss=1.6496249437332153
I0303 04:37:50.535770 140239850956544 logging_writer.py:48] [128000] global_step=128000, grad_norm=1.9565722942352295, loss=2.6973350048065186
I0303 04:38:24.238279 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:38:34.243531 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:38:54.836837 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:38:56.472064 140437341357888 submission_runner.py:411] Time since start: 61578.02s, 	Step: 128076, 	{'train/accuracy': 0.7968358993530273, 'train/loss': 0.7937740087509155, 'validation/accuracy': 0.7278199791908264, 'validation/loss': 1.0928000211715698, 'validation/num_examples': 50000, 'test/accuracy': 0.603600025177002, 'test/loss': 1.7354732751846313, 'test/num_examples': 10000, 'score': 57181.63070321083, 'total_duration': 61578.02355456352, 'accumulated_submission_time': 57181.63070321083, 'accumulated_eval_time': 4382.287897109985, 'accumulated_logging_time': 7.066992282867432}
I0303 04:38:56.515956 140239842563840 logging_writer.py:48] [128076] accumulated_eval_time=4382.287897, accumulated_logging_time=7.066992, accumulated_submission_time=57181.630703, global_step=128076, preemption_count=0, score=57181.630703, test/accuracy=0.603600, test/loss=1.735473, test/num_examples=10000, total_duration=61578.023555, train/accuracy=0.796836, train/loss=0.793774, validation/accuracy=0.727820, validation/loss=1.092800, validation/num_examples=50000
I0303 04:39:06.461593 140239850956544 logging_writer.py:48] [128100] global_step=128100, grad_norm=2.0671393871307373, loss=2.456066370010376
I0303 04:39:48.725950 140239842563840 logging_writer.py:48] [128200] global_step=128200, grad_norm=1.694673776626587, loss=3.2308342456817627
I0303 04:40:33.929653 140239850956544 logging_writer.py:48] [128300] global_step=128300, grad_norm=1.8825759887695312, loss=1.626515507698059
I0303 04:41:19.143665 140239842563840 logging_writer.py:48] [128400] global_step=128400, grad_norm=2.2133636474609375, loss=3.1526663303375244
I0303 04:42:04.388893 140239850956544 logging_writer.py:48] [128500] global_step=128500, grad_norm=1.937070608139038, loss=1.5583117008209229
I0303 04:42:49.382317 140239842563840 logging_writer.py:48] [128600] global_step=128600, grad_norm=1.8973252773284912, loss=1.5475186109542847
I0303 04:43:34.214342 140239850956544 logging_writer.py:48] [128700] global_step=128700, grad_norm=2.1720499992370605, loss=1.6452795267105103
I0303 04:44:19.452069 140239842563840 logging_writer.py:48] [128800] global_step=128800, grad_norm=1.8700156211853027, loss=1.861767053604126
I0303 04:45:05.287702 140239850956544 logging_writer.py:48] [128900] global_step=128900, grad_norm=1.8530352115631104, loss=1.5665373802185059
I0303 04:45:50.842713 140239842563840 logging_writer.py:48] [129000] global_step=129000, grad_norm=1.9074844121932983, loss=2.962782859802246
I0303 04:45:56.851654 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:46:07.256031 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:46:29.857131 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:46:31.499199 140437341357888 submission_runner.py:411] Time since start: 62033.05s, 	Step: 129015, 	{'train/accuracy': 0.8051171898841858, 'train/loss': 0.7775402665138245, 'validation/accuracy': 0.7311999797821045, 'validation/loss': 1.1002105474472046, 'validation/num_examples': 50000, 'test/accuracy': 0.6086000204086304, 'test/loss': 1.7183754444122314, 'test/num_examples': 10000, 'score': 57601.90099310875, 'total_duration': 62033.050671339035, 'accumulated_submission_time': 57601.90099310875, 'accumulated_eval_time': 4416.935405731201, 'accumulated_logging_time': 7.12395167350769}
I0303 04:46:31.543827 140239850956544 logging_writer.py:48] [129015] accumulated_eval_time=4416.935406, accumulated_logging_time=7.123952, accumulated_submission_time=57601.900993, global_step=129015, preemption_count=0, score=57601.900993, test/accuracy=0.608600, test/loss=1.718375, test/num_examples=10000, total_duration=62033.050671, train/accuracy=0.805117, train/loss=0.777540, validation/accuracy=0.731200, validation/loss=1.100211, validation/num_examples=50000
I0303 04:47:06.033325 140239842563840 logging_writer.py:48] [129100] global_step=129100, grad_norm=1.6119699478149414, loss=2.3959174156188965
I0303 04:47:51.023870 140239850956544 logging_writer.py:48] [129200] global_step=129200, grad_norm=1.8759706020355225, loss=3.17277455329895
I0303 04:48:36.403471 140239842563840 logging_writer.py:48] [129300] global_step=129300, grad_norm=1.932759165763855, loss=3.043121576309204
I0303 04:49:21.627376 140239850956544 logging_writer.py:48] [129400] global_step=129400, grad_norm=2.1208837032318115, loss=3.9761626720428467
I0303 04:50:07.047126 140239842563840 logging_writer.py:48] [129500] global_step=129500, grad_norm=1.9967857599258423, loss=3.7619028091430664
I0303 04:50:52.179532 140239850956544 logging_writer.py:48] [129600] global_step=129600, grad_norm=1.7972451448440552, loss=3.4298064708709717
I0303 04:51:37.254340 140239842563840 logging_writer.py:48] [129700] global_step=129700, grad_norm=1.960015892982483, loss=1.62419593334198
I0303 04:52:22.262297 140239850956544 logging_writer.py:48] [129800] global_step=129800, grad_norm=1.8068431615829468, loss=3.457697629928589
I0303 04:53:07.457828 140239842563840 logging_writer.py:48] [129900] global_step=129900, grad_norm=1.819989562034607, loss=3.503944158554077
I0303 04:53:31.891964 140437341357888 spec.py:321] Evaluating on the training split.
I0303 04:53:41.996902 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 04:54:03.902878 140437341357888 spec.py:349] Evaluating on the test split.
I0303 04:54:05.556724 140437341357888 submission_runner.py:411] Time since start: 62487.11s, 	Step: 129956, 	{'train/accuracy': 0.8118359446525574, 'train/loss': 0.7209511995315552, 'validation/accuracy': 0.7298399806022644, 'validation/loss': 1.0690104961395264, 'validation/num_examples': 50000, 'test/accuracy': 0.6084000468254089, 'test/loss': 1.6949561834335327, 'test/num_examples': 10000, 'score': 58022.18709683418, 'total_duration': 62487.10815668106, 'accumulated_submission_time': 58022.18709683418, 'accumulated_eval_time': 4450.6000871658325, 'accumulated_logging_time': 7.179595232009888}
I0303 04:54:05.627532 140239850956544 logging_writer.py:48] [129956] accumulated_eval_time=4450.600087, accumulated_logging_time=7.179595, accumulated_submission_time=58022.187097, global_step=129956, preemption_count=0, score=58022.187097, test/accuracy=0.608400, test/loss=1.694956, test/num_examples=10000, total_duration=62487.108157, train/accuracy=0.811836, train/loss=0.720951, validation/accuracy=0.729840, validation/loss=1.069010, validation/num_examples=50000
I0303 04:54:23.500228 140239842563840 logging_writer.py:48] [130000] global_step=130000, grad_norm=1.798879861831665, loss=3.3785400390625
I0303 04:55:05.545046 140239850956544 logging_writer.py:48] [130100] global_step=130100, grad_norm=1.736336350440979, loss=1.9183210134506226
I0303 04:55:51.304455 140239842563840 logging_writer.py:48] [130200] global_step=130200, grad_norm=1.7408713102340698, loss=2.6948697566986084
I0303 04:56:36.602010 140239850956544 logging_writer.py:48] [130300] global_step=130300, grad_norm=1.7391470670700073, loss=2.2634801864624023
I0303 04:57:21.859551 140239842563840 logging_writer.py:48] [130400] global_step=130400, grad_norm=1.8265182971954346, loss=1.611790418624878
I0303 04:58:06.999045 140239850956544 logging_writer.py:48] [130500] global_step=130500, grad_norm=1.7453866004943848, loss=1.8682727813720703
I0303 04:58:51.853169 140239842563840 logging_writer.py:48] [130600] global_step=130600, grad_norm=2.055431604385376, loss=1.7604658603668213
I0303 04:59:36.913392 140239850956544 logging_writer.py:48] [130700] global_step=130700, grad_norm=1.9974017143249512, loss=1.645226240158081
I0303 05:00:21.919417 140239842563840 logging_writer.py:48] [130800] global_step=130800, grad_norm=1.9631444215774536, loss=1.7279069423675537
I0303 05:01:05.921287 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:01:16.006738 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:01:36.558319 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:01:38.189688 140437341357888 submission_runner.py:411] Time since start: 62939.74s, 	Step: 130898, 	{'train/accuracy': 0.8252343535423279, 'train/loss': 0.6869196891784668, 'validation/accuracy': 0.7318999767303467, 'validation/loss': 1.0726889371871948, 'validation/num_examples': 50000, 'test/accuracy': 0.6083000302314758, 'test/loss': 1.7007026672363281, 'test/num_examples': 10000, 'score': 58442.412564754486, 'total_duration': 62939.74114704132, 'accumulated_submission_time': 58442.412564754486, 'accumulated_eval_time': 4482.868451356888, 'accumulated_logging_time': 7.265031337738037}
I0303 05:01:38.233977 140239850956544 logging_writer.py:48] [130898] accumulated_eval_time=4482.868451, accumulated_logging_time=7.265031, accumulated_submission_time=58442.412565, global_step=130898, preemption_count=0, score=58442.412565, test/accuracy=0.608300, test/loss=1.700703, test/num_examples=10000, total_duration=62939.741147, train/accuracy=0.825234, train/loss=0.686920, validation/accuracy=0.731900, validation/loss=1.072689, validation/num_examples=50000
I0303 05:01:39.439605 140239842563840 logging_writer.py:48] [130900] global_step=130900, grad_norm=1.7966967821121216, loss=2.9494407176971436
I0303 05:02:20.646782 140239850956544 logging_writer.py:48] [131000] global_step=131000, grad_norm=1.820030689239502, loss=1.6840983629226685
I0303 05:03:06.110903 140239842563840 logging_writer.py:48] [131100] global_step=131100, grad_norm=1.887640118598938, loss=2.5041122436523438
I0303 05:03:51.260498 140239850956544 logging_writer.py:48] [131200] global_step=131200, grad_norm=1.988939881324768, loss=1.6696736812591553
I0303 05:04:36.435021 140239842563840 logging_writer.py:48] [131300] global_step=131300, grad_norm=2.088794469833374, loss=3.7841343879699707
I0303 05:05:22.106785 140239850956544 logging_writer.py:48] [131400] global_step=131400, grad_norm=1.8514071702957153, loss=1.633085012435913
I0303 05:06:07.387734 140239842563840 logging_writer.py:48] [131500] global_step=131500, grad_norm=1.87147057056427, loss=1.7483816146850586
I0303 05:06:52.799869 140239850956544 logging_writer.py:48] [131600] global_step=131600, grad_norm=1.9973037242889404, loss=3.4955060482025146
I0303 05:07:37.892598 140239842563840 logging_writer.py:48] [131700] global_step=131700, grad_norm=2.0382251739501953, loss=1.6500502824783325
I0303 05:08:23.243329 140239850956544 logging_writer.py:48] [131800] global_step=131800, grad_norm=1.851821780204773, loss=1.5997564792633057
I0303 05:08:38.261216 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:08:48.580561 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:09:09.464192 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:09:11.086782 140437341357888 submission_runner.py:411] Time since start: 63392.64s, 	Step: 131835, 	{'train/accuracy': 0.8069726228713989, 'train/loss': 0.7426121234893799, 'validation/accuracy': 0.7356399893760681, 'validation/loss': 1.0555675029754639, 'validation/num_examples': 50000, 'test/accuracy': 0.6165000200271606, 'test/loss': 1.6794337034225464, 'test/num_examples': 10000, 'score': 58862.37831878662, 'total_duration': 63392.63826608658, 'accumulated_submission_time': 58862.37831878662, 'accumulated_eval_time': 4515.693987369537, 'accumulated_logging_time': 7.319501161575317}
I0303 05:09:11.131067 140239842563840 logging_writer.py:48] [131835] accumulated_eval_time=4515.693987, accumulated_logging_time=7.319501, accumulated_submission_time=58862.378319, global_step=131835, preemption_count=0, score=58862.378319, test/accuracy=0.616500, test/loss=1.679434, test/num_examples=10000, total_duration=63392.638266, train/accuracy=0.806973, train/loss=0.742612, validation/accuracy=0.735640, validation/loss=1.055568, validation/num_examples=50000
I0303 05:09:37.274027 140239850956544 logging_writer.py:48] [131900] global_step=131900, grad_norm=1.9269628524780273, loss=1.620572805404663
I0303 05:10:22.153179 140239842563840 logging_writer.py:48] [132000] global_step=132000, grad_norm=1.9955909252166748, loss=1.6561288833618164
I0303 05:11:07.386502 140239850956544 logging_writer.py:48] [132100] global_step=132100, grad_norm=1.9218114614486694, loss=1.6143933534622192
I0303 05:11:52.670689 140239842563840 logging_writer.py:48] [132200] global_step=132200, grad_norm=2.0541772842407227, loss=3.2615134716033936
I0303 05:12:38.009574 140239850956544 logging_writer.py:48] [132300] global_step=132300, grad_norm=1.8162062168121338, loss=1.7487082481384277
I0303 05:13:23.078766 140239842563840 logging_writer.py:48] [132400] global_step=132400, grad_norm=1.7207635641098022, loss=2.815491199493408
I0303 05:14:08.394966 140239850956544 logging_writer.py:48] [132500] global_step=132500, grad_norm=1.9362326860427856, loss=1.613197684288025
I0303 05:14:53.776141 140239842563840 logging_writer.py:48] [132600] global_step=132600, grad_norm=1.8679111003875732, loss=2.0104620456695557
I0303 05:15:39.804137 140239850956544 logging_writer.py:48] [132700] global_step=132700, grad_norm=2.0561587810516357, loss=1.6003843545913696
I0303 05:16:11.522022 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:16:21.599150 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:16:47.180323 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:16:48.805534 140437341357888 submission_runner.py:411] Time since start: 63850.36s, 	Step: 132771, 	{'train/accuracy': 0.8157616853713989, 'train/loss': 0.7002706527709961, 'validation/accuracy': 0.7349199652671814, 'validation/loss': 1.0541627407073975, 'validation/num_examples': 50000, 'test/accuracy': 0.6173000335693359, 'test/loss': 1.6698813438415527, 'test/num_examples': 10000, 'score': 59282.7042388916, 'total_duration': 63850.35701370239, 'accumulated_submission_time': 59282.7042388916, 'accumulated_eval_time': 4552.977478265762, 'accumulated_logging_time': 7.37714958190918}
I0303 05:16:48.851809 140239842563840 logging_writer.py:48] [132771] accumulated_eval_time=4552.977478, accumulated_logging_time=7.377150, accumulated_submission_time=59282.704239, global_step=132771, preemption_count=0, score=59282.704239, test/accuracy=0.617300, test/loss=1.669881, test/num_examples=10000, total_duration=63850.357014, train/accuracy=0.815762, train/loss=0.700271, validation/accuracy=0.734920, validation/loss=1.054163, validation/num_examples=50000
I0303 05:17:00.748963 140239850956544 logging_writer.py:48] [132800] global_step=132800, grad_norm=1.9396183490753174, loss=1.5572383403778076
I0303 05:17:42.543049 140239842563840 logging_writer.py:48] [132900] global_step=132900, grad_norm=1.703924536705017, loss=1.861069679260254
I0303 05:18:27.742943 140239850956544 logging_writer.py:48] [133000] global_step=133000, grad_norm=1.649316668510437, loss=2.3456804752349854
I0303 05:19:12.888122 140239842563840 logging_writer.py:48] [133100] global_step=133100, grad_norm=2.054145097732544, loss=1.472163438796997
I0303 05:19:57.946343 140239850956544 logging_writer.py:48] [133200] global_step=133200, grad_norm=1.947466492652893, loss=1.5437885522842407
I0303 05:20:43.124677 140239842563840 logging_writer.py:48] [133300] global_step=133300, grad_norm=1.9817330837249756, loss=1.702784538269043
I0303 05:21:28.348576 140239850956544 logging_writer.py:48] [133400] global_step=133400, grad_norm=2.017299175262451, loss=1.5790231227874756
I0303 05:22:13.705986 140239842563840 logging_writer.py:48] [133500] global_step=133500, grad_norm=1.8289787769317627, loss=2.8022727966308594
I0303 05:22:58.650066 140239850956544 logging_writer.py:48] [133600] global_step=133600, grad_norm=1.827736258506775, loss=1.622686505317688
I0303 05:23:43.446556 140239842563840 logging_writer.py:48] [133700] global_step=133700, grad_norm=1.9273533821105957, loss=2.5964555740356445
I0303 05:23:49.045795 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:23:59.158418 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:24:26.337231 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:24:27.968390 140437341357888 submission_runner.py:411] Time since start: 64309.52s, 	Step: 133714, 	{'train/accuracy': 0.8212499618530273, 'train/loss': 0.6917605996131897, 'validation/accuracy': 0.7364400029182434, 'validation/loss': 1.0647858381271362, 'validation/num_examples': 50000, 'test/accuracy': 0.6152000427246094, 'test/loss': 1.6732351779937744, 'test/num_examples': 10000, 'score': 59702.83695149422, 'total_duration': 64309.51987743378, 'accumulated_submission_time': 59702.83695149422, 'accumulated_eval_time': 4591.900043010712, 'accumulated_logging_time': 7.433608055114746}
I0303 05:24:28.010607 140239850956544 logging_writer.py:48] [133714] accumulated_eval_time=4591.900043, accumulated_logging_time=7.433608, accumulated_submission_time=59702.836951, global_step=133714, preemption_count=0, score=59702.836951, test/accuracy=0.615200, test/loss=1.673235, test/num_examples=10000, total_duration=64309.519877, train/accuracy=0.821250, train/loss=0.691761, validation/accuracy=0.736440, validation/loss=1.064786, validation/num_examples=50000
I0303 05:25:02.480897 140239842563840 logging_writer.py:48] [133800] global_step=133800, grad_norm=2.020055055618286, loss=1.6152966022491455
I0303 05:25:47.471879 140239850956544 logging_writer.py:48] [133900] global_step=133900, grad_norm=1.9999459981918335, loss=1.9039791822433472
I0303 05:26:32.989630 140239842563840 logging_writer.py:48] [134000] global_step=134000, grad_norm=1.8790287971496582, loss=3.346527099609375
I0303 05:27:17.958182 140239850956544 logging_writer.py:48] [134100] global_step=134100, grad_norm=1.7702432870864868, loss=2.2705039978027344
I0303 05:28:02.913439 140239842563840 logging_writer.py:48] [134200] global_step=134200, grad_norm=1.9522302150726318, loss=1.535361409187317
I0303 05:28:47.788658 140239850956544 logging_writer.py:48] [134300] global_step=134300, grad_norm=1.9090429544448853, loss=1.6119763851165771
I0303 05:29:33.073535 140239842563840 logging_writer.py:48] [134400] global_step=134400, grad_norm=2.2197799682617188, loss=1.5955768823623657
I0303 05:30:18.243098 140239850956544 logging_writer.py:48] [134500] global_step=134500, grad_norm=1.974725365638733, loss=1.4946620464324951
I0303 05:31:03.334022 140239842563840 logging_writer.py:48] [134600] global_step=134600, grad_norm=1.90416419506073, loss=1.5579890012741089
I0303 05:31:28.157150 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:31:38.137114 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:31:56.641312 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:31:58.262891 140437341357888 submission_runner.py:411] Time since start: 64759.81s, 	Step: 134657, 	{'train/accuracy': 0.8107812404632568, 'train/loss': 0.7149853110313416, 'validation/accuracy': 0.7350999712944031, 'validation/loss': 1.0497262477874756, 'validation/num_examples': 50000, 'test/accuracy': 0.6171000003814697, 'test/loss': 1.657669186592102, 'test/num_examples': 10000, 'score': 60122.92111968994, 'total_duration': 64759.81437373161, 'accumulated_submission_time': 60122.92111968994, 'accumulated_eval_time': 4622.005768299103, 'accumulated_logging_time': 7.486406564712524}
I0303 05:31:58.309322 140239850956544 logging_writer.py:48] [134657] accumulated_eval_time=4622.005768, accumulated_logging_time=7.486407, accumulated_submission_time=60122.921120, global_step=134657, preemption_count=0, score=60122.921120, test/accuracy=0.617100, test/loss=1.657669, test/num_examples=10000, total_duration=64759.814374, train/accuracy=0.810781, train/loss=0.714985, validation/accuracy=0.735100, validation/loss=1.049726, validation/num_examples=50000
I0303 05:32:16.046267 140239842563840 logging_writer.py:48] [134700] global_step=134700, grad_norm=2.0176615715026855, loss=1.8083832263946533
I0303 05:32:59.844824 140239850956544 logging_writer.py:48] [134800] global_step=134800, grad_norm=1.8903509378433228, loss=1.661570429801941
I0303 05:33:45.160948 140239842563840 logging_writer.py:48] [134900] global_step=134900, grad_norm=2.162548303604126, loss=4.028392791748047
I0303 05:34:30.636842 140239850956544 logging_writer.py:48] [135000] global_step=135000, grad_norm=1.951254963874817, loss=1.5857436656951904
I0303 05:35:16.011238 140239842563840 logging_writer.py:48] [135100] global_step=135100, grad_norm=2.0393078327178955, loss=1.502983570098877
I0303 05:36:01.076989 140239850956544 logging_writer.py:48] [135200] global_step=135200, grad_norm=1.891845703125, loss=1.6127086877822876
I0303 05:36:46.617712 140239842563840 logging_writer.py:48] [135300] global_step=135300, grad_norm=1.899483323097229, loss=2.576543092727661
I0303 05:37:31.718555 140239850956544 logging_writer.py:48] [135400] global_step=135400, grad_norm=2.0448458194732666, loss=1.5852701663970947
I0303 05:38:16.929026 140239842563840 logging_writer.py:48] [135500] global_step=135500, grad_norm=1.7711323499679565, loss=2.864032030105591
I0303 05:38:58.434487 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:39:09.028713 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:39:30.922100 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:39:32.535379 140437341357888 submission_runner.py:411] Time since start: 65214.09s, 	Step: 135594, 	{'train/accuracy': 0.8163085579872131, 'train/loss': 0.6858136653900146, 'validation/accuracy': 0.7380599975585938, 'validation/loss': 1.0333293676376343, 'validation/num_examples': 50000, 'test/accuracy': 0.6195000410079956, 'test/loss': 1.6498830318450928, 'test/num_examples': 10000, 'score': 60542.98550081253, 'total_duration': 65214.08685183525, 'accumulated_submission_time': 60542.98550081253, 'accumulated_eval_time': 4656.106626033783, 'accumulated_logging_time': 7.542491436004639}
I0303 05:39:32.582055 140239850956544 logging_writer.py:48] [135594] accumulated_eval_time=4656.106626, accumulated_logging_time=7.542491, accumulated_submission_time=60542.985501, global_step=135594, preemption_count=0, score=60542.985501, test/accuracy=0.619500, test/loss=1.649883, test/num_examples=10000, total_duration=65214.086852, train/accuracy=0.816309, train/loss=0.685814, validation/accuracy=0.738060, validation/loss=1.033329, validation/num_examples=50000
I0303 05:39:35.384578 140239842563840 logging_writer.py:48] [135600] global_step=135600, grad_norm=1.9498330354690552, loss=1.42875337600708
I0303 05:40:16.871826 140239842563840 logging_writer.py:48] [135700] global_step=135700, grad_norm=2.153740882873535, loss=2.242119550704956
I0303 05:41:01.862737 140239850956544 logging_writer.py:48] [135800] global_step=135800, grad_norm=1.9669662714004517, loss=2.655330181121826
I0303 05:41:46.860804 140239842563840 logging_writer.py:48] [135900] global_step=135900, grad_norm=2.0441839694976807, loss=1.5851908922195435
I0303 05:42:32.071427 140239850956544 logging_writer.py:48] [136000] global_step=136000, grad_norm=1.9221330881118774, loss=2.444932460784912
I0303 05:43:17.171888 140239842563840 logging_writer.py:48] [136100] global_step=136100, grad_norm=2.1171770095825195, loss=3.9381802082061768
I0303 05:44:02.203824 140239850956544 logging_writer.py:48] [136200] global_step=136200, grad_norm=2.0233993530273438, loss=1.4076557159423828
I0303 05:44:47.206139 140239842563840 logging_writer.py:48] [136300] global_step=136300, grad_norm=2.046786069869995, loss=1.5963900089263916
I0303 05:45:32.868497 140239850956544 logging_writer.py:48] [136400] global_step=136400, grad_norm=1.9516921043395996, loss=1.5840061902999878
I0303 05:46:18.319804 140239842563840 logging_writer.py:48] [136500] global_step=136500, grad_norm=2.029581308364868, loss=1.5008894205093384
I0303 05:46:32.944936 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:46:43.050814 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:47:03.334809 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:47:05.002358 140437341357888 submission_runner.py:411] Time since start: 65666.55s, 	Step: 136534, 	{'train/accuracy': 0.8235937356948853, 'train/loss': 0.691146969795227, 'validation/accuracy': 0.7392999529838562, 'validation/loss': 1.0445665121078491, 'validation/num_examples': 50000, 'test/accuracy': 0.6193000078201294, 'test/loss': 1.6543912887573242, 'test/num_examples': 10000, 'score': 60963.28740334511, 'total_duration': 65666.55383682251, 'accumulated_submission_time': 60963.28740334511, 'accumulated_eval_time': 4688.164028644562, 'accumulated_logging_time': 7.599376678466797}
I0303 05:47:05.062352 140239850956544 logging_writer.py:48] [136534] accumulated_eval_time=4688.164029, accumulated_logging_time=7.599377, accumulated_submission_time=60963.287403, global_step=136534, preemption_count=0, score=60963.287403, test/accuracy=0.619300, test/loss=1.654391, test/num_examples=10000, total_duration=65666.553837, train/accuracy=0.823594, train/loss=0.691147, validation/accuracy=0.739300, validation/loss=1.044567, validation/num_examples=50000
I0303 05:47:31.624955 140239842563840 logging_writer.py:48] [136600] global_step=136600, grad_norm=1.9394155740737915, loss=1.450554609298706
I0303 05:48:14.956481 140239850956544 logging_writer.py:48] [136700] global_step=136700, grad_norm=2.140204906463623, loss=1.5580930709838867
I0303 05:49:00.255653 140239842563840 logging_writer.py:48] [136800] global_step=136800, grad_norm=2.2897133827209473, loss=3.604984998703003
I0303 05:49:45.339152 140239850956544 logging_writer.py:48] [136900] global_step=136900, grad_norm=1.8400509357452393, loss=2.0864295959472656
I0303 05:50:30.235005 140239842563840 logging_writer.py:48] [137000] global_step=137000, grad_norm=1.8949456214904785, loss=1.9509460926055908
I0303 05:51:15.458517 140239850956544 logging_writer.py:48] [137100] global_step=137100, grad_norm=2.0914175510406494, loss=1.5741338729858398
I0303 05:52:00.436635 140239842563840 logging_writer.py:48] [137200] global_step=137200, grad_norm=1.9704928398132324, loss=1.596113681793213
I0303 05:52:45.516287 140239850956544 logging_writer.py:48] [137300] global_step=137300, grad_norm=2.166309356689453, loss=3.3567447662353516
I0303 05:53:30.791278 140239842563840 logging_writer.py:48] [137400] global_step=137400, grad_norm=1.9091169834136963, loss=1.6616967916488647
I0303 05:54:05.288362 140437341357888 spec.py:321] Evaluating on the training split.
I0303 05:54:15.217586 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 05:54:42.379674 140437341357888 spec.py:349] Evaluating on the test split.
I0303 05:54:43.991717 140437341357888 submission_runner.py:411] Time since start: 66125.54s, 	Step: 137478, 	{'train/accuracy': 0.8358203172683716, 'train/loss': 0.6423953771591187, 'validation/accuracy': 0.7375800013542175, 'validation/loss': 1.0486226081848145, 'validation/num_examples': 50000, 'test/accuracy': 0.6115000247955322, 'test/loss': 1.687080979347229, 'test/num_examples': 10000, 'score': 61383.44880151749, 'total_duration': 66125.54321527481, 'accumulated_submission_time': 61383.44880151749, 'accumulated_eval_time': 4726.867444038391, 'accumulated_logging_time': 7.671452760696411}
I0303 05:54:44.032593 140239850956544 logging_writer.py:48] [137478] accumulated_eval_time=4726.867444, accumulated_logging_time=7.671453, accumulated_submission_time=61383.448802, global_step=137478, preemption_count=0, score=61383.448802, test/accuracy=0.611500, test/loss=1.687081, test/num_examples=10000, total_duration=66125.543215, train/accuracy=0.835820, train/loss=0.642395, validation/accuracy=0.737580, validation/loss=1.048623, validation/num_examples=50000
I0303 05:54:53.157251 140239842563840 logging_writer.py:48] [137500] global_step=137500, grad_norm=2.065990924835205, loss=1.5132884979248047
I0303 05:55:33.358222 140239850956544 logging_writer.py:48] [137600] global_step=137600, grad_norm=2.2121593952178955, loss=3.445202350616455
I0303 05:56:18.909258 140239842563840 logging_writer.py:48] [137700] global_step=137700, grad_norm=1.979387640953064, loss=2.192173957824707
I0303 05:57:04.316320 140239850956544 logging_writer.py:48] [137800] global_step=137800, grad_norm=1.8363544940948486, loss=3.1425719261169434
I0303 05:57:49.420107 140239842563840 logging_writer.py:48] [137900] global_step=137900, grad_norm=1.9683061838150024, loss=1.5829488039016724
I0303 05:58:34.637430 140239850956544 logging_writer.py:48] [138000] global_step=138000, grad_norm=1.8076419830322266, loss=3.0455594062805176
I0303 05:59:19.923503 140239842563840 logging_writer.py:48] [138100] global_step=138100, grad_norm=2.0185387134552, loss=3.2120625972747803
I0303 06:00:05.427816 140239850956544 logging_writer.py:48] [138200] global_step=138200, grad_norm=1.9671707153320312, loss=1.537717342376709
I0303 06:00:50.482868 140239842563840 logging_writer.py:48] [138300] global_step=138300, grad_norm=2.211481809616089, loss=1.5358390808105469
I0303 06:01:35.560616 140239850956544 logging_writer.py:48] [138400] global_step=138400, grad_norm=2.0124480724334717, loss=1.5529781579971313
I0303 06:01:44.202202 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:01:54.561839 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:02:19.211942 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:02:20.820863 140437341357888 submission_runner.py:411] Time since start: 66582.37s, 	Step: 138421, 	{'train/accuracy': 0.8221484422683716, 'train/loss': 0.6727483868598938, 'validation/accuracy': 0.7418599724769592, 'validation/loss': 1.0180381536483765, 'validation/num_examples': 50000, 'test/accuracy': 0.6202000379562378, 'test/loss': 1.641932487487793, 'test/num_examples': 10000, 'score': 61803.555621385574, 'total_duration': 66582.37235975266, 'accumulated_submission_time': 61803.555621385574, 'accumulated_eval_time': 4763.486090421677, 'accumulated_logging_time': 7.724071741104126}
I0303 06:02:20.863493 140239842563840 logging_writer.py:48] [138421] accumulated_eval_time=4763.486090, accumulated_logging_time=7.724072, accumulated_submission_time=61803.555621, global_step=138421, preemption_count=0, score=61803.555621, test/accuracy=0.620200, test/loss=1.641932, test/num_examples=10000, total_duration=66582.372360, train/accuracy=0.822148, train/loss=0.672748, validation/accuracy=0.741860, validation/loss=1.018038, validation/num_examples=50000
I0303 06:02:52.586686 140239850956544 logging_writer.py:48] [138500] global_step=138500, grad_norm=2.1186625957489014, loss=1.8660110235214233
I0303 06:03:36.499729 140239842563840 logging_writer.py:48] [138600] global_step=138600, grad_norm=2.0523252487182617, loss=1.7660222053527832
I0303 06:04:21.570183 140239850956544 logging_writer.py:48] [138700] global_step=138700, grad_norm=2.39054536819458, loss=3.4329919815063477
I0303 06:05:07.430746 140239842563840 logging_writer.py:48] [138800] global_step=138800, grad_norm=1.9240036010742188, loss=2.2172152996063232
I0303 06:05:52.430533 140239850956544 logging_writer.py:48] [138900] global_step=138900, grad_norm=2.1530189514160156, loss=1.58169424533844
I0303 06:06:38.008869 140239842563840 logging_writer.py:48] [139000] global_step=139000, grad_norm=2.2085657119750977, loss=3.6227402687072754
I0303 06:07:22.793145 140239850956544 logging_writer.py:48] [139100] global_step=139100, grad_norm=2.000631332397461, loss=1.6218295097351074
I0303 06:08:07.861467 140239842563840 logging_writer.py:48] [139200] global_step=139200, grad_norm=2.062995672225952, loss=2.9362337589263916
I0303 06:08:52.919540 140239850956544 logging_writer.py:48] [139300] global_step=139300, grad_norm=1.9613113403320312, loss=3.440613269805908
I0303 06:09:21.101979 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:09:31.809772 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:09:52.363010 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:09:53.976551 140437341357888 submission_runner.py:411] Time since start: 67035.53s, 	Step: 139364, 	{'train/accuracy': 0.8287304639816284, 'train/loss': 0.6483760476112366, 'validation/accuracy': 0.7456600069999695, 'validation/loss': 1.0039118528366089, 'validation/num_examples': 50000, 'test/accuracy': 0.6260000467300415, 'test/loss': 1.6316074132919312, 'test/num_examples': 10000, 'score': 62223.732880592346, 'total_duration': 67035.52803492546, 'accumulated_submission_time': 62223.732880592346, 'accumulated_eval_time': 4796.3606498241425, 'accumulated_logging_time': 7.7763237953186035}
I0303 06:09:54.021489 140239842563840 logging_writer.py:48] [139364] accumulated_eval_time=4796.360650, accumulated_logging_time=7.776324, accumulated_submission_time=62223.732881, global_step=139364, preemption_count=0, score=62223.732881, test/accuracy=0.626000, test/loss=1.631607, test/num_examples=10000, total_duration=67035.528035, train/accuracy=0.828730, train/loss=0.648376, validation/accuracy=0.745660, validation/loss=1.003912, validation/num_examples=50000
I0303 06:10:08.696868 140239850956544 logging_writer.py:48] [139400] global_step=139400, grad_norm=2.0397214889526367, loss=1.4861196279525757
I0303 06:10:52.632550 140239842563840 logging_writer.py:48] [139500] global_step=139500, grad_norm=2.0855727195739746, loss=1.6230579614639282
I0303 06:11:38.064630 140239850956544 logging_writer.py:48] [139600] global_step=139600, grad_norm=2.0925023555755615, loss=1.5798022747039795
I0303 06:12:23.347001 140239842563840 logging_writer.py:48] [139700] global_step=139700, grad_norm=2.1662392616271973, loss=1.8627012968063354
I0303 06:13:08.320613 140239850956544 logging_writer.py:48] [139800] global_step=139800, grad_norm=2.152270793914795, loss=1.6410577297210693
I0303 06:13:53.744652 140239842563840 logging_writer.py:48] [139900] global_step=139900, grad_norm=1.873429536819458, loss=2.2748003005981445
I0303 06:14:39.020162 140239850956544 logging_writer.py:48] [140000] global_step=140000, grad_norm=2.032832384109497, loss=1.4387720823287964
I0303 06:15:24.352594 140239842563840 logging_writer.py:48] [140100] global_step=140100, grad_norm=2.2394392490386963, loss=1.503585934638977
I0303 06:16:09.955147 140239850956544 logging_writer.py:48] [140200] global_step=140200, grad_norm=1.916969895362854, loss=2.0800669193267822
I0303 06:16:54.332368 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:17:05.240392 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:17:30.910366 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:17:32.533318 140437341357888 submission_runner.py:411] Time since start: 67494.08s, 	Step: 140299, 	{'train/accuracy': 0.8375195264816284, 'train/loss': 0.6271106004714966, 'validation/accuracy': 0.7462999820709229, 'validation/loss': 1.0144020318984985, 'validation/num_examples': 50000, 'test/accuracy': 0.6199000477790833, 'test/loss': 1.6409794092178345, 'test/num_examples': 10000, 'score': 62643.9823744297, 'total_duration': 67494.0847992897, 'accumulated_submission_time': 62643.9823744297, 'accumulated_eval_time': 4834.561587095261, 'accumulated_logging_time': 7.831675052642822}
I0303 06:17:32.578894 140239842563840 logging_writer.py:48] [140299] accumulated_eval_time=4834.561587, accumulated_logging_time=7.831675, accumulated_submission_time=62643.982374, global_step=140299, preemption_count=0, score=62643.982374, test/accuracy=0.619900, test/loss=1.640979, test/num_examples=10000, total_duration=67494.084799, train/accuracy=0.837520, train/loss=0.627111, validation/accuracy=0.746300, validation/loss=1.014402, validation/num_examples=50000
I0303 06:17:33.398680 140239850956544 logging_writer.py:48] [140300] global_step=140300, grad_norm=2.01033616065979, loss=1.5884003639221191
I0303 06:18:14.786462 140239842563840 logging_writer.py:48] [140400] global_step=140400, grad_norm=2.3369884490966797, loss=3.934785842895508
I0303 06:18:59.737989 140239850956544 logging_writer.py:48] [140500] global_step=140500, grad_norm=1.8073714971542358, loss=2.1503243446350098
I0303 06:19:45.181383 140239842563840 logging_writer.py:48] [140600] global_step=140600, grad_norm=2.18363356590271, loss=1.467536449432373
I0303 06:20:30.176095 140239850956544 logging_writer.py:48] [140700] global_step=140700, grad_norm=1.9078524112701416, loss=2.0042643547058105
I0303 06:21:15.283312 140239842563840 logging_writer.py:48] [140800] global_step=140800, grad_norm=2.198772668838501, loss=3.6111509799957275
I0303 06:22:00.634638 140239850956544 logging_writer.py:48] [140900] global_step=140900, grad_norm=2.102647542953491, loss=1.5071032047271729
I0303 06:22:45.825309 140239842563840 logging_writer.py:48] [141000] global_step=141000, grad_norm=2.2237539291381836, loss=1.7817497253417969
I0303 06:23:30.640465 140239850956544 logging_writer.py:48] [141100] global_step=141100, grad_norm=2.0933361053466797, loss=3.3449864387512207
I0303 06:24:15.828003 140239842563840 logging_writer.py:48] [141200] global_step=141200, grad_norm=2.1559336185455322, loss=1.5141286849975586
I0303 06:24:32.617997 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:24:42.697078 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:25:11.594107 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:25:13.243999 140437341357888 submission_runner.py:411] Time since start: 67954.80s, 	Step: 141239, 	{'train/accuracy': 0.8244726657867432, 'train/loss': 0.6539803743362427, 'validation/accuracy': 0.7459200024604797, 'validation/loss': 1.0001908540725708, 'validation/num_examples': 50000, 'test/accuracy': 0.6206000447273254, 'test/loss': 1.6216108798980713, 'test/num_examples': 10000, 'score': 63063.95926761627, 'total_duration': 67954.7954685688, 'accumulated_submission_time': 63063.95926761627, 'accumulated_eval_time': 4875.187557458878, 'accumulated_logging_time': 7.8880674839019775}
I0303 06:25:13.280418 140239850956544 logging_writer.py:48] [141239] accumulated_eval_time=4875.187557, accumulated_logging_time=7.888067, accumulated_submission_time=63063.959268, global_step=141239, preemption_count=0, score=63063.959268, test/accuracy=0.620600, test/loss=1.621611, test/num_examples=10000, total_duration=67954.795469, train/accuracy=0.824473, train/loss=0.653980, validation/accuracy=0.745920, validation/loss=1.000191, validation/num_examples=50000
I0303 06:25:37.839994 140239842563840 logging_writer.py:48] [141300] global_step=141300, grad_norm=2.003178596496582, loss=1.522517204284668
I0303 06:26:20.865182 140239850956544 logging_writer.py:48] [141400] global_step=141400, grad_norm=1.9266854524612427, loss=1.5305980443954468
I0303 06:27:06.645833 140239842563840 logging_writer.py:48] [141500] global_step=141500, grad_norm=2.2786381244659424, loss=1.465118169784546
I0303 06:27:51.466378 140239850956544 logging_writer.py:48] [141600] global_step=141600, grad_norm=1.9693297147750854, loss=2.3777618408203125
I0303 06:28:36.798788 140239842563840 logging_writer.py:48] [141700] global_step=141700, grad_norm=2.2628424167633057, loss=1.5736875534057617
I0303 06:29:21.876813 140239850956544 logging_writer.py:48] [141800] global_step=141800, grad_norm=1.87961745262146, loss=2.921187400817871
I0303 06:30:07.127516 140239842563840 logging_writer.py:48] [141900] global_step=141900, grad_norm=2.1782989501953125, loss=3.441807746887207
I0303 06:30:52.151992 140239850956544 logging_writer.py:48] [142000] global_step=142000, grad_norm=2.3824100494384766, loss=3.6228630542755127
I0303 06:31:37.271526 140239842563840 logging_writer.py:48] [142100] global_step=142100, grad_norm=2.0680696964263916, loss=1.3871946334838867
I0303 06:32:13.412994 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:32:23.708733 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:32:47.863192 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:32:49.483252 140437341357888 submission_runner.py:411] Time since start: 68411.03s, 	Step: 142181, 	{'train/accuracy': 0.83216792345047, 'train/loss': 0.6442916989326477, 'validation/accuracy': 0.7468400001525879, 'validation/loss': 1.000510334968567, 'validation/num_examples': 50000, 'test/accuracy': 0.6249000430107117, 'test/loss': 1.6253139972686768, 'test/num_examples': 10000, 'score': 63484.03082895279, 'total_duration': 68411.03473544121, 'accumulated_submission_time': 63484.03082895279, 'accumulated_eval_time': 4911.257856369019, 'accumulated_logging_time': 7.93324613571167}
I0303 06:32:49.529578 140239850956544 logging_writer.py:48] [142181] accumulated_eval_time=4911.257856, accumulated_logging_time=7.933246, accumulated_submission_time=63484.030829, global_step=142181, preemption_count=0, score=63484.030829, test/accuracy=0.624900, test/loss=1.625314, test/num_examples=10000, total_duration=68411.034735, train/accuracy=0.832168, train/loss=0.644292, validation/accuracy=0.746840, validation/loss=1.000510, validation/num_examples=50000
I0303 06:32:57.469691 140239842563840 logging_writer.py:48] [142200] global_step=142200, grad_norm=2.2704594135284424, loss=1.591480016708374
I0303 06:33:38.908458 140239850956544 logging_writer.py:48] [142300] global_step=142300, grad_norm=1.9790571928024292, loss=1.3235650062561035
I0303 06:34:24.051850 140239842563840 logging_writer.py:48] [142400] global_step=142400, grad_norm=1.7903389930725098, loss=2.7470133304595947
I0303 06:35:09.295716 140239850956544 logging_writer.py:48] [142500] global_step=142500, grad_norm=2.0938451290130615, loss=1.4311376810073853
I0303 06:35:54.468448 140239842563840 logging_writer.py:48] [142600] global_step=142600, grad_norm=2.01353120803833, loss=2.3856894969940186
I0303 06:36:40.568732 140239850956544 logging_writer.py:48] [142700] global_step=142700, grad_norm=2.5695910453796387, loss=3.7815444469451904
I0303 06:37:25.788341 140239842563840 logging_writer.py:48] [142800] global_step=142800, grad_norm=2.3410229682922363, loss=1.4275257587432861
I0303 06:38:11.321129 140239850956544 logging_writer.py:48] [142900] global_step=142900, grad_norm=2.0691654682159424, loss=1.39158034324646
I0303 06:38:56.288132 140239842563840 logging_writer.py:48] [143000] global_step=143000, grad_norm=1.9723224639892578, loss=1.8380147218704224
I0303 06:39:41.736697 140239850956544 logging_writer.py:48] [143100] global_step=143100, grad_norm=2.154001235961914, loss=2.0979034900665283
I0303 06:39:49.771979 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:40:00.278299 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:40:25.648208 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:40:27.269646 140437341357888 submission_runner.py:411] Time since start: 68868.82s, 	Step: 143119, 	{'train/accuracy': 0.8355468511581421, 'train/loss': 0.6156179904937744, 'validation/accuracy': 0.7492799758911133, 'validation/loss': 0.9899269938468933, 'validation/num_examples': 50000, 'test/accuracy': 0.6276000142097473, 'test/loss': 1.612836480140686, 'test/num_examples': 10000, 'score': 63904.20986747742, 'total_duration': 68868.8211402893, 'accumulated_submission_time': 63904.20986747742, 'accumulated_eval_time': 4948.755502462387, 'accumulated_logging_time': 7.992448329925537}
I0303 06:40:27.307768 140239842563840 logging_writer.py:48] [143119] accumulated_eval_time=4948.755502, accumulated_logging_time=7.992448, accumulated_submission_time=63904.209867, global_step=143119, preemption_count=0, score=63904.209867, test/accuracy=0.627600, test/loss=1.612836, test/num_examples=10000, total_duration=68868.821140, train/accuracy=0.835547, train/loss=0.615618, validation/accuracy=0.749280, validation/loss=0.989927, validation/num_examples=50000
I0303 06:40:59.782276 140239850956544 logging_writer.py:48] [143200] global_step=143200, grad_norm=2.5379087924957275, loss=3.4398069381713867
I0303 06:41:44.226747 140239842563840 logging_writer.py:48] [143300] global_step=143300, grad_norm=2.8397939205169678, loss=3.71586537361145
I0303 06:42:29.599223 140239850956544 logging_writer.py:48] [143400] global_step=143400, grad_norm=2.0849852561950684, loss=3.168769359588623
I0303 06:43:15.003565 140239842563840 logging_writer.py:48] [143500] global_step=143500, grad_norm=2.0888452529907227, loss=1.5425294637680054
I0303 06:44:00.190807 140239850956544 logging_writer.py:48] [143600] global_step=143600, grad_norm=2.1360483169555664, loss=1.462951898574829
I0303 06:44:45.535702 140239842563840 logging_writer.py:48] [143700] global_step=143700, grad_norm=2.207595109939575, loss=1.4053587913513184
I0303 06:45:30.503281 140239850956544 logging_writer.py:48] [143800] global_step=143800, grad_norm=2.174262285232544, loss=1.6104974746704102
I0303 06:46:16.041405 140239842563840 logging_writer.py:48] [143900] global_step=143900, grad_norm=2.276949405670166, loss=2.818586826324463
I0303 06:47:00.974725 140239850956544 logging_writer.py:48] [144000] global_step=144000, grad_norm=2.375103712081909, loss=3.5546512603759766
I0303 06:47:27.568158 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:47:37.990335 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:47:59.129144 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:48:00.766665 140437341357888 submission_runner.py:411] Time since start: 69322.32s, 	Step: 144060, 	{'train/accuracy': 0.8414062261581421, 'train/loss': 0.6124166250228882, 'validation/accuracy': 0.7498999834060669, 'validation/loss': 0.9950244426727295, 'validation/num_examples': 50000, 'test/accuracy': 0.6288000345230103, 'test/loss': 1.6108155250549316, 'test/num_examples': 10000, 'score': 64324.40742135048, 'total_duration': 69322.31814837456, 'accumulated_submission_time': 64324.40742135048, 'accumulated_eval_time': 4981.9539959430695, 'accumulated_logging_time': 8.04038405418396}
I0303 06:48:00.817007 140239842563840 logging_writer.py:48] [144060] accumulated_eval_time=4981.953996, accumulated_logging_time=8.040384, accumulated_submission_time=64324.407421, global_step=144060, preemption_count=0, score=64324.407421, test/accuracy=0.628800, test/loss=1.610816, test/num_examples=10000, total_duration=69322.318148, train/accuracy=0.841406, train/loss=0.612417, validation/accuracy=0.749900, validation/loss=0.995024, validation/num_examples=50000
I0303 06:48:17.078956 140239850956544 logging_writer.py:48] [144100] global_step=144100, grad_norm=2.1440553665161133, loss=1.444972276687622
I0303 06:49:01.359223 140239842563840 logging_writer.py:48] [144200] global_step=144200, grad_norm=2.106940984725952, loss=2.978489875793457
I0303 06:49:46.809731 140239850956544 logging_writer.py:48] [144300] global_step=144300, grad_norm=2.1510932445526123, loss=2.1398673057556152
I0303 06:50:32.186129 140239842563840 logging_writer.py:48] [144400] global_step=144400, grad_norm=2.2062313556671143, loss=3.4545512199401855
I0303 06:51:17.517034 140239850956544 logging_writer.py:48] [144500] global_step=144500, grad_norm=2.2891647815704346, loss=3.1604931354522705
I0303 06:52:03.017795 140239842563840 logging_writer.py:48] [144600] global_step=144600, grad_norm=2.272716999053955, loss=1.4926731586456299
I0303 06:52:48.286651 140239850956544 logging_writer.py:48] [144700] global_step=144700, grad_norm=2.145557165145874, loss=1.3686535358428955
I0303 06:53:33.624077 140239842563840 logging_writer.py:48] [144800] global_step=144800, grad_norm=2.2382471561431885, loss=3.500305652618408
I0303 06:54:19.095128 140239850956544 logging_writer.py:48] [144900] global_step=144900, grad_norm=2.088996648788452, loss=1.4183768033981323
I0303 06:55:00.824702 140437341357888 spec.py:321] Evaluating on the training split.
I0303 06:55:11.403924 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 06:55:36.586057 140437341357888 spec.py:349] Evaluating on the test split.
I0303 06:55:38.217456 140437341357888 submission_runner.py:411] Time since start: 69779.77s, 	Step: 144994, 	{'train/accuracy': 0.8344921469688416, 'train/loss': 0.6352013945579529, 'validation/accuracy': 0.7530800104141235, 'validation/loss': 0.9881432056427002, 'validation/num_examples': 50000, 'test/accuracy': 0.6317000389099121, 'test/loss': 1.5940308570861816, 'test/num_examples': 10000, 'score': 64744.354521751404, 'total_duration': 69779.76891851425, 'accumulated_submission_time': 64744.354521751404, 'accumulated_eval_time': 5019.346714496613, 'accumulated_logging_time': 8.100827932357788}
I0303 06:55:38.270276 140239842563840 logging_writer.py:48] [144994] accumulated_eval_time=5019.346714, accumulated_logging_time=8.100828, accumulated_submission_time=64744.354522, global_step=144994, preemption_count=0, score=64744.354522, test/accuracy=0.631700, test/loss=1.594031, test/num_examples=10000, total_duration=69779.768919, train/accuracy=0.834492, train/loss=0.635201, validation/accuracy=0.753080, validation/loss=0.988143, validation/num_examples=50000
I0303 06:55:41.053556 140239850956544 logging_writer.py:48] [145000] global_step=145000, grad_norm=2.1194450855255127, loss=1.426521897315979
I0303 06:56:22.718863 140239850956544 logging_writer.py:48] [145100] global_step=145100, grad_norm=2.492371082305908, loss=3.752934694290161
I0303 06:57:09.174440 140239842563840 logging_writer.py:48] [145200] global_step=145200, grad_norm=2.2943356037139893, loss=3.031606912612915
I0303 06:57:54.986798 140239850956544 logging_writer.py:48] [145300] global_step=145300, grad_norm=2.5228447914123535, loss=3.6568665504455566
I0303 06:58:40.544548 140239842563840 logging_writer.py:48] [145400] global_step=145400, grad_norm=2.1123135089874268, loss=1.4639790058135986
I0303 06:59:26.255102 140239850956544 logging_writer.py:48] [145500] global_step=145500, grad_norm=2.275937080383301, loss=1.422912836074829
I0303 07:00:11.808192 140239842563840 logging_writer.py:48] [145600] global_step=145600, grad_norm=2.1101720333099365, loss=2.4899234771728516
I0303 07:00:57.300557 140239850956544 logging_writer.py:48] [145700] global_step=145700, grad_norm=1.9736829996109009, loss=1.4509326219558716
I0303 07:01:42.936366 140239842563840 logging_writer.py:48] [145800] global_step=145800, grad_norm=2.0513644218444824, loss=1.4606952667236328
I0303 07:02:28.369995 140239850956544 logging_writer.py:48] [145900] global_step=145900, grad_norm=2.304400682449341, loss=2.6462044715881348
I0303 07:02:38.511418 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:02:48.752708 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:03:10.167852 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:03:11.789332 140437341357888 submission_runner.py:411] Time since start: 70233.34s, 	Step: 145924, 	{'train/accuracy': 0.8385546803474426, 'train/loss': 0.615352988243103, 'validation/accuracy': 0.7503199577331543, 'validation/loss': 0.9843414425849915, 'validation/num_examples': 50000, 'test/accuracy': 0.6289000511169434, 'test/loss': 1.6003049612045288, 'test/num_examples': 10000, 'score': 65164.53370523453, 'total_duration': 70233.34082078934, 'accumulated_submission_time': 65164.53370523453, 'accumulated_eval_time': 5052.624608039856, 'accumulated_logging_time': 8.164747714996338}
I0303 07:03:11.841313 140239842563840 logging_writer.py:48] [145924] accumulated_eval_time=5052.624608, accumulated_logging_time=8.164748, accumulated_submission_time=65164.533705, global_step=145924, preemption_count=0, score=65164.533705, test/accuracy=0.628900, test/loss=1.600305, test/num_examples=10000, total_duration=70233.340821, train/accuracy=0.838555, train/loss=0.615353, validation/accuracy=0.750320, validation/loss=0.984341, validation/num_examples=50000
I0303 07:03:42.559111 140239850956544 logging_writer.py:48] [146000] global_step=146000, grad_norm=2.1553802490234375, loss=1.3717525005340576
I0303 07:04:27.632784 140239842563840 logging_writer.py:48] [146100] global_step=146100, grad_norm=2.452232837677002, loss=3.4428586959838867
I0303 07:05:12.994267 140239850956544 logging_writer.py:48] [146200] global_step=146200, grad_norm=2.5545454025268555, loss=1.3782353401184082
I0303 07:05:58.111575 140239842563840 logging_writer.py:48] [146300] global_step=146300, grad_norm=2.3518967628479004, loss=1.4927029609680176
I0303 07:06:43.778266 140239850956544 logging_writer.py:48] [146400] global_step=146400, grad_norm=2.3110644817352295, loss=1.8957642316818237
I0303 07:07:29.189720 140239842563840 logging_writer.py:48] [146500] global_step=146500, grad_norm=2.3215017318725586, loss=1.5425440073013306
I0303 07:08:14.862501 140239850956544 logging_writer.py:48] [146600] global_step=146600, grad_norm=2.23244571685791, loss=1.380167841911316
I0303 07:09:00.268644 140239842563840 logging_writer.py:48] [146700] global_step=146700, grad_norm=2.3505210876464844, loss=1.5086987018585205
I0303 07:09:45.670412 140239850956544 logging_writer.py:48] [146800] global_step=146800, grad_norm=2.563646078109741, loss=1.4111278057098389
I0303 07:10:12.130910 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:10:22.285876 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:10:45.610288 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:10:47.235688 140437341357888 submission_runner.py:411] Time since start: 70688.79s, 	Step: 146860, 	{'train/accuracy': 0.8499999642372131, 'train/loss': 0.5691419243812561, 'validation/accuracy': 0.7542200088500977, 'validation/loss': 0.9688873291015625, 'validation/num_examples': 50000, 'test/accuracy': 0.6330000162124634, 'test/loss': 1.5802263021469116, 'test/num_examples': 10000, 'score': 65584.762103796, 'total_duration': 70688.78717851639, 'accumulated_submission_time': 65584.762103796, 'accumulated_eval_time': 5087.729380130768, 'accumulated_logging_time': 8.226694107055664}
I0303 07:10:47.281768 140239842563840 logging_writer.py:48] [146860] accumulated_eval_time=5087.729380, accumulated_logging_time=8.226694, accumulated_submission_time=65584.762104, global_step=146860, preemption_count=0, score=65584.762104, test/accuracy=0.633000, test/loss=1.580226, test/num_examples=10000, total_duration=70688.787179, train/accuracy=0.850000, train/loss=0.569142, validation/accuracy=0.754220, validation/loss=0.968887, validation/num_examples=50000
I0303 07:11:03.538875 140239850956544 logging_writer.py:48] [146900] global_step=146900, grad_norm=2.242185115814209, loss=1.4641306400299072
I0303 07:11:46.649611 140239842563840 logging_writer.py:48] [147000] global_step=147000, grad_norm=2.234745502471924, loss=1.4192192554473877
I0303 07:12:31.890842 140239850956544 logging_writer.py:48] [147100] global_step=147100, grad_norm=2.53920578956604, loss=1.4373619556427002
I0303 07:13:16.943812 140239842563840 logging_writer.py:48] [147200] global_step=147200, grad_norm=2.062835454940796, loss=1.9636187553405762
I0303 07:14:02.197104 140239850956544 logging_writer.py:48] [147300] global_step=147300, grad_norm=2.103583812713623, loss=1.3331153392791748
I0303 07:14:47.136877 140239842563840 logging_writer.py:48] [147400] global_step=147400, grad_norm=2.1306023597717285, loss=2.777866840362549
I0303 07:15:32.072025 140239850956544 logging_writer.py:48] [147500] global_step=147500, grad_norm=2.4652161598205566, loss=1.4544599056243896
I0303 07:16:17.170630 140239842563840 logging_writer.py:48] [147600] global_step=147600, grad_norm=2.280755043029785, loss=1.3931121826171875
I0303 07:17:02.758900 140239850956544 logging_writer.py:48] [147700] global_step=147700, grad_norm=2.234718084335327, loss=2.4698591232299805
I0303 07:17:47.850394 140239842563840 logging_writer.py:48] [147800] global_step=147800, grad_norm=2.7749855518341064, loss=3.5154006481170654
I0303 07:17:47.864550 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:17:57.835774 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:18:27.385124 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:18:29.007892 140437341357888 submission_runner.py:411] Time since start: 71150.56s, 	Step: 147801, 	{'train/accuracy': 0.841113269329071, 'train/loss': 0.5822334289550781, 'validation/accuracy': 0.7569400072097778, 'validation/loss': 0.9509395956993103, 'validation/num_examples': 50000, 'test/accuracy': 0.6347000598907471, 'test/loss': 1.5633114576339722, 'test/num_examples': 10000, 'score': 66005.28381443024, 'total_duration': 71150.55936717987, 'accumulated_submission_time': 66005.28381443024, 'accumulated_eval_time': 5128.872689962387, 'accumulated_logging_time': 8.282914638519287}
I0303 07:18:29.060215 140239850956544 logging_writer.py:48] [147801] accumulated_eval_time=5128.872690, accumulated_logging_time=8.282915, accumulated_submission_time=66005.283814, global_step=147801, preemption_count=0, score=66005.283814, test/accuracy=0.634700, test/loss=1.563311, test/num_examples=10000, total_duration=71150.559367, train/accuracy=0.841113, train/loss=0.582233, validation/accuracy=0.756940, validation/loss=0.950940, validation/num_examples=50000
I0303 07:19:09.427668 140239842563840 logging_writer.py:48] [147900] global_step=147900, grad_norm=2.0857725143432617, loss=2.274205207824707
I0303 07:19:54.543026 140239850956544 logging_writer.py:48] [148000] global_step=148000, grad_norm=2.1728360652923584, loss=1.3986046314239502
I0303 07:20:39.572034 140239842563840 logging_writer.py:48] [148100] global_step=148100, grad_norm=2.116328716278076, loss=1.400507926940918
I0303 07:21:24.738996 140239850956544 logging_writer.py:48] [148200] global_step=148200, grad_norm=2.693171739578247, loss=1.3175967931747437
I0303 07:22:09.758739 140239842563840 logging_writer.py:48] [148300] global_step=148300, grad_norm=2.1312663555145264, loss=1.3938672542572021
I0303 07:22:54.499879 140239850956544 logging_writer.py:48] [148400] global_step=148400, grad_norm=2.4118704795837402, loss=3.1531825065612793
I0303 07:23:39.555562 140239842563840 logging_writer.py:48] [148500] global_step=148500, grad_norm=2.1275830268859863, loss=1.5107754468917847
I0303 07:24:24.866667 140239850956544 logging_writer.py:48] [148600] global_step=148600, grad_norm=2.0307767391204834, loss=1.371040940284729
I0303 07:25:09.874680 140239842563840 logging_writer.py:48] [148700] global_step=148700, grad_norm=2.3476650714874268, loss=3.367302179336548
I0303 07:25:29.426623 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:25:39.687828 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:25:58.029196 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:25:59.652596 140437341357888 submission_runner.py:411] Time since start: 71601.20s, 	Step: 148745, 	{'train/accuracy': 0.8462304472923279, 'train/loss': 0.5925246477127075, 'validation/accuracy': 0.7569599747657776, 'validation/loss': 0.9620269536972046, 'validation/num_examples': 50000, 'test/accuracy': 0.6318000555038452, 'test/loss': 1.5700883865356445, 'test/num_examples': 10000, 'score': 66425.58796477318, 'total_duration': 71601.20407652855, 'accumulated_submission_time': 66425.58796477318, 'accumulated_eval_time': 5159.098656654358, 'accumulated_logging_time': 8.345009803771973}
I0303 07:25:59.702319 140239850956544 logging_writer.py:48] [148745] accumulated_eval_time=5159.098657, accumulated_logging_time=8.345010, accumulated_submission_time=66425.587965, global_step=148745, preemption_count=0, score=66425.587965, test/accuracy=0.631800, test/loss=1.570088, test/num_examples=10000, total_duration=71601.204077, train/accuracy=0.846230, train/loss=0.592525, validation/accuracy=0.756960, validation/loss=0.962027, validation/num_examples=50000
I0303 07:26:21.903917 140239842563840 logging_writer.py:48] [148800] global_step=148800, grad_norm=2.329965114593506, loss=1.3954521417617798
I0303 07:27:07.294686 140239850956544 logging_writer.py:48] [148900] global_step=148900, grad_norm=2.229849338531494, loss=1.2432140111923218
I0303 07:27:52.971604 140239842563840 logging_writer.py:48] [149000] global_step=149000, grad_norm=2.3314740657806396, loss=1.4667925834655762
I0303 07:28:38.218694 140239850956544 logging_writer.py:48] [149100] global_step=149100, grad_norm=2.3141579627990723, loss=1.7117947340011597
I0303 07:29:23.786406 140239842563840 logging_writer.py:48] [149200] global_step=149200, grad_norm=2.1397294998168945, loss=1.9922513961791992
I0303 07:30:09.204439 140239850956544 logging_writer.py:48] [149300] global_step=149300, grad_norm=2.3787667751312256, loss=3.2824249267578125
I0303 07:30:54.297358 140239842563840 logging_writer.py:48] [149400] global_step=149400, grad_norm=2.387819766998291, loss=2.2645480632781982
I0303 07:31:39.659463 140239850956544 logging_writer.py:48] [149500] global_step=149500, grad_norm=2.3562734127044678, loss=1.435376763343811
I0303 07:32:24.840911 140239842563840 logging_writer.py:48] [149600] global_step=149600, grad_norm=2.5229337215423584, loss=1.5411955118179321
I0303 07:33:00.031844 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:33:10.385384 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:33:39.554022 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:33:41.167586 140437341357888 submission_runner.py:411] Time since start: 72062.72s, 	Step: 149680, 	{'train/accuracy': 0.8490039110183716, 'train/loss': 0.5663567185401917, 'validation/accuracy': 0.7562800049781799, 'validation/loss': 0.9526709914207458, 'validation/num_examples': 50000, 'test/accuracy': 0.6348000168800354, 'test/loss': 1.5691616535186768, 'test/num_examples': 10000, 'score': 66845.85511136055, 'total_duration': 72062.71906900406, 'accumulated_submission_time': 66845.85511136055, 'accumulated_eval_time': 5200.234387397766, 'accumulated_logging_time': 8.406283617019653}
I0303 07:33:41.218364 140239850956544 logging_writer.py:48] [149680] accumulated_eval_time=5200.234387, accumulated_logging_time=8.406284, accumulated_submission_time=66845.855111, global_step=149680, preemption_count=0, score=66845.855111, test/accuracy=0.634800, test/loss=1.569162, test/num_examples=10000, total_duration=72062.719069, train/accuracy=0.849004, train/loss=0.566357, validation/accuracy=0.756280, validation/loss=0.952671, validation/num_examples=50000
I0303 07:33:49.549994 140239842563840 logging_writer.py:48] [149700] global_step=149700, grad_norm=2.5562233924865723, loss=3.4928507804870605
I0303 07:34:30.374310 140239850956544 logging_writer.py:48] [149800] global_step=149800, grad_norm=2.2389073371887207, loss=1.3622205257415771
I0303 07:35:15.364822 140239842563840 logging_writer.py:48] [149900] global_step=149900, grad_norm=2.5586607456207275, loss=3.4821994304656982
I0303 07:36:00.416651 140239850956544 logging_writer.py:48] [150000] global_step=150000, grad_norm=2.3999059200286865, loss=3.4233648777008057
I0303 07:36:45.711185 140239842563840 logging_writer.py:48] [150100] global_step=150100, grad_norm=2.438124895095825, loss=3.4428069591522217
I0303 07:37:31.298735 140239850956544 logging_writer.py:48] [150200] global_step=150200, grad_norm=2.7004165649414062, loss=3.684079170227051
I0303 07:38:16.473891 140239842563840 logging_writer.py:48] [150300] global_step=150300, grad_norm=2.2580718994140625, loss=1.5547242164611816
I0303 07:39:01.537198 140239850956544 logging_writer.py:48] [150400] global_step=150400, grad_norm=2.3058364391326904, loss=1.4425489902496338
I0303 07:39:46.800287 140239842563840 logging_writer.py:48] [150500] global_step=150500, grad_norm=2.2319045066833496, loss=1.3834459781646729
I0303 07:40:32.155388 140239850956544 logging_writer.py:48] [150600] global_step=150600, grad_norm=2.3627922534942627, loss=1.361602544784546
I0303 07:40:41.322695 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:40:51.258299 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:41:16.559779 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:41:18.181956 140437341357888 submission_runner.py:411] Time since start: 72519.73s, 	Step: 150622, 	{'train/accuracy': 0.8469530940055847, 'train/loss': 0.5782976150512695, 'validation/accuracy': 0.7572999596595764, 'validation/loss': 0.9563175439834595, 'validation/num_examples': 50000, 'test/accuracy': 0.6383000016212463, 'test/loss': 1.5757783651351929, 'test/num_examples': 10000, 'score': 67265.89777302742, 'total_duration': 72519.73343348503, 'accumulated_submission_time': 67265.89777302742, 'accumulated_eval_time': 5237.093623876572, 'accumulated_logging_time': 8.467820644378662}
I0303 07:41:18.230795 140239842563840 logging_writer.py:48] [150622] accumulated_eval_time=5237.093624, accumulated_logging_time=8.467821, accumulated_submission_time=67265.897773, global_step=150622, preemption_count=0, score=67265.897773, test/accuracy=0.638300, test/loss=1.575778, test/num_examples=10000, total_duration=72519.733433, train/accuracy=0.846953, train/loss=0.578298, validation/accuracy=0.757300, validation/loss=0.956318, validation/num_examples=50000
I0303 07:41:49.544537 140239850956544 logging_writer.py:48] [150700] global_step=150700, grad_norm=2.224296808242798, loss=2.1985251903533936
I0303 07:42:34.250574 140239842563840 logging_writer.py:48] [150800] global_step=150800, grad_norm=2.1308963298797607, loss=1.6946592330932617
I0303 07:43:19.654027 140239850956544 logging_writer.py:48] [150900] global_step=150900, grad_norm=2.4022905826568604, loss=2.9791247844696045
I0303 07:44:04.850135 140239842563840 logging_writer.py:48] [151000] global_step=151000, grad_norm=2.323108196258545, loss=1.4909402132034302
I0303 07:44:50.065089 140239850956544 logging_writer.py:48] [151100] global_step=151100, grad_norm=2.4672601222991943, loss=1.296088695526123
I0303 07:45:35.261107 140239842563840 logging_writer.py:48] [151200] global_step=151200, grad_norm=2.3365728855133057, loss=1.4013683795928955
I0303 07:46:20.516383 140239850956544 logging_writer.py:48] [151300] global_step=151300, grad_norm=2.197249412536621, loss=1.9725368022918701
I0303 07:47:06.212689 140239842563840 logging_writer.py:48] [151400] global_step=151400, grad_norm=2.138805866241455, loss=2.7095301151275635
I0303 07:47:51.241609 140239850956544 logging_writer.py:48] [151500] global_step=151500, grad_norm=2.1756999492645264, loss=1.4724478721618652
I0303 07:48:18.388934 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:48:28.694574 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:48:51.998755 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:48:53.629537 140437341357888 submission_runner.py:411] Time since start: 72975.18s, 	Step: 151562, 	{'train/accuracy': 0.8485546708106995, 'train/loss': 0.580278217792511, 'validation/accuracy': 0.7583000063896179, 'validation/loss': 0.9555332660675049, 'validation/num_examples': 50000, 'test/accuracy': 0.6325000524520874, 'test/loss': 1.5823768377304077, 'test/num_examples': 10000, 'score': 67685.99413371086, 'total_duration': 72975.18101358414, 'accumulated_submission_time': 67685.99413371086, 'accumulated_eval_time': 5272.33419585228, 'accumulated_logging_time': 8.526651859283447}
I0303 07:48:53.682198 140239842563840 logging_writer.py:48] [151562] accumulated_eval_time=5272.334196, accumulated_logging_time=8.526652, accumulated_submission_time=67685.994134, global_step=151562, preemption_count=0, score=67685.994134, test/accuracy=0.632500, test/loss=1.582377, test/num_examples=10000, total_duration=72975.181014, train/accuracy=0.848555, train/loss=0.580278, validation/accuracy=0.758300, validation/loss=0.955533, validation/num_examples=50000
I0303 07:49:09.163654 140239850956544 logging_writer.py:48] [151600] global_step=151600, grad_norm=2.6437339782714844, loss=1.4694463014602661
I0303 07:49:53.038346 140239842563840 logging_writer.py:48] [151700] global_step=151700, grad_norm=2.3457980155944824, loss=2.9071273803710938
I0303 07:50:38.345085 140239850956544 logging_writer.py:48] [151800] global_step=151800, grad_norm=2.4895732402801514, loss=1.373058795928955
I0303 07:51:23.621941 140239842563840 logging_writer.py:48] [151900] global_step=151900, grad_norm=2.4539241790771484, loss=2.161299705505371
I0303 07:52:08.753588 140239850956544 logging_writer.py:48] [152000] global_step=152000, grad_norm=2.3698604106903076, loss=2.538703680038452
I0303 07:52:53.918526 140239842563840 logging_writer.py:48] [152100] global_step=152100, grad_norm=2.6103854179382324, loss=2.860029697418213
I0303 07:53:39.263465 140239850956544 logging_writer.py:48] [152200] global_step=152200, grad_norm=2.8213255405426025, loss=3.641880512237549
I0303 07:54:24.428144 140239842563840 logging_writer.py:48] [152300] global_step=152300, grad_norm=2.3982763290405273, loss=1.2803007364273071
I0303 07:55:10.026585 140239850956544 logging_writer.py:48] [152400] global_step=152400, grad_norm=2.4159493446350098, loss=1.6667027473449707
I0303 07:55:53.836654 140437341357888 spec.py:321] Evaluating on the training split.
I0303 07:56:04.405937 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 07:56:39.472917 140437341357888 spec.py:349] Evaluating on the test split.
I0303 07:56:41.087018 140437341357888 submission_runner.py:411] Time since start: 73442.64s, 	Step: 152498, 	{'train/accuracy': 0.8522460460662842, 'train/loss': 0.5873256325721741, 'validation/accuracy': 0.7579799890518188, 'validation/loss': 0.9749816656112671, 'validation/num_examples': 50000, 'test/accuracy': 0.6325000524520874, 'test/loss': 1.597623586654663, 'test/num_examples': 10000, 'score': 68106.0849275589, 'total_duration': 73442.63851284981, 'accumulated_submission_time': 68106.0849275589, 'accumulated_eval_time': 5319.5845646858215, 'accumulated_logging_time': 8.591355562210083}
I0303 07:56:41.130413 140239842563840 logging_writer.py:48] [152498] accumulated_eval_time=5319.584565, accumulated_logging_time=8.591356, accumulated_submission_time=68106.084928, global_step=152498, preemption_count=0, score=68106.084928, test/accuracy=0.632500, test/loss=1.597624, test/num_examples=10000, total_duration=73442.638513, train/accuracy=0.852246, train/loss=0.587326, validation/accuracy=0.757980, validation/loss=0.974982, validation/num_examples=50000
I0303 07:56:42.325120 140239850956544 logging_writer.py:48] [152500] global_step=152500, grad_norm=2.829538583755493, loss=1.438124418258667
I0303 07:57:22.163623 140239842563840 logging_writer.py:48] [152600] global_step=152600, grad_norm=2.5899441242218018, loss=3.4997220039367676
I0303 07:58:07.337671 140239850956544 logging_writer.py:48] [152700] global_step=152700, grad_norm=2.51869797706604, loss=1.4962611198425293
I0303 07:58:52.581257 140239842563840 logging_writer.py:48] [152800] global_step=152800, grad_norm=2.41666579246521, loss=1.2759861946105957
I0303 07:59:37.913879 140239850956544 logging_writer.py:48] [152900] global_step=152900, grad_norm=2.3998918533325195, loss=1.4432597160339355
I0303 08:00:23.315709 140239842563840 logging_writer.py:48] [153000] global_step=153000, grad_norm=2.486020803451538, loss=1.505407452583313
I0303 08:01:08.386125 140239850956544 logging_writer.py:48] [153100] global_step=153100, grad_norm=2.3952503204345703, loss=1.473865032196045
I0303 08:01:53.293541 140239842563840 logging_writer.py:48] [153200] global_step=153200, grad_norm=2.2632150650024414, loss=1.3504496812820435
I0303 08:02:38.310923 140239850956544 logging_writer.py:48] [153300] global_step=153300, grad_norm=2.416363477706909, loss=1.288117527961731
I0303 08:03:23.393714 140239842563840 logging_writer.py:48] [153400] global_step=153400, grad_norm=2.3443262577056885, loss=1.405608892440796
I0303 08:03:41.489285 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:03:51.726156 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:04:13.878666 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:04:15.515012 140437341357888 submission_runner.py:411] Time since start: 73897.07s, 	Step: 153442, 	{'train/accuracy': 0.8603124618530273, 'train/loss': 0.5331978797912598, 'validation/accuracy': 0.7604599595069885, 'validation/loss': 0.9412803649902344, 'validation/num_examples': 50000, 'test/accuracy': 0.6397000551223755, 'test/loss': 1.5488471984863281, 'test/num_examples': 10000, 'score': 68526.38285326958, 'total_duration': 73897.06649947166, 'accumulated_submission_time': 68526.38285326958, 'accumulated_eval_time': 5353.610310792923, 'accumulated_logging_time': 8.64404821395874}
I0303 08:04:15.562036 140239850956544 logging_writer.py:48] [153442] accumulated_eval_time=5353.610311, accumulated_logging_time=8.644048, accumulated_submission_time=68526.382853, global_step=153442, preemption_count=0, score=68526.382853, test/accuracy=0.639700, test/loss=1.548847, test/num_examples=10000, total_duration=73897.066499, train/accuracy=0.860312, train/loss=0.533198, validation/accuracy=0.760460, validation/loss=0.941280, validation/num_examples=50000
I0303 08:04:38.957430 140239842563840 logging_writer.py:48] [153500] global_step=153500, grad_norm=2.5390102863311768, loss=3.041452646255493
I0303 08:05:22.637768 140239850956544 logging_writer.py:48] [153600] global_step=153600, grad_norm=2.295987606048584, loss=2.215317726135254
I0303 08:06:07.600156 140239842563840 logging_writer.py:48] [153700] global_step=153700, grad_norm=2.293703556060791, loss=1.349029779434204
I0303 08:06:52.994200 140239850956544 logging_writer.py:48] [153800] global_step=153800, grad_norm=2.428703546524048, loss=1.3166381120681763
I0303 08:07:38.389684 140239842563840 logging_writer.py:48] [153900] global_step=153900, grad_norm=2.5242180824279785, loss=2.6472840309143066
I0303 08:08:23.940293 140239850956544 logging_writer.py:48] [154000] global_step=154000, grad_norm=2.6975862979888916, loss=1.3062422275543213
I0303 08:09:09.196685 140239842563840 logging_writer.py:48] [154100] global_step=154100, grad_norm=2.5905351638793945, loss=3.2172536849975586
I0303 08:09:54.430397 140239850956544 logging_writer.py:48] [154200] global_step=154200, grad_norm=2.3520121574401855, loss=1.4104970693588257
I0303 08:10:39.686234 140239842563840 logging_writer.py:48] [154300] global_step=154300, grad_norm=2.7815115451812744, loss=1.330544352531433
I0303 08:11:15.695651 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:11:26.071534 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:11:50.282395 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:11:51.905467 140437341357888 submission_runner.py:411] Time since start: 74353.46s, 	Step: 154381, 	{'train/accuracy': 0.8544335961341858, 'train/loss': 0.5505743622779846, 'validation/accuracy': 0.7605400085449219, 'validation/loss': 0.9401016235351562, 'validation/num_examples': 50000, 'test/accuracy': 0.6432000398635864, 'test/loss': 1.552872896194458, 'test/num_examples': 10000, 'score': 68946.4556479454, 'total_duration': 74353.45694947243, 'accumulated_submission_time': 68946.4556479454, 'accumulated_eval_time': 5389.820098400116, 'accumulated_logging_time': 8.700559377670288}
I0303 08:11:51.956643 140239850956544 logging_writer.py:48] [154381] accumulated_eval_time=5389.820098, accumulated_logging_time=8.700559, accumulated_submission_time=68946.455648, global_step=154381, preemption_count=0, score=68946.455648, test/accuracy=0.643200, test/loss=1.552873, test/num_examples=10000, total_duration=74353.456949, train/accuracy=0.854434, train/loss=0.550574, validation/accuracy=0.760540, validation/loss=0.940102, validation/num_examples=50000
I0303 08:11:59.889864 140239842563840 logging_writer.py:48] [154400] global_step=154400, grad_norm=2.8684377670288086, loss=3.4808688163757324
I0303 08:12:41.986197 140239850956544 logging_writer.py:48] [154500] global_step=154500, grad_norm=2.5250697135925293, loss=3.295135021209717
I0303 08:13:26.968503 140239842563840 logging_writer.py:48] [154600] global_step=154600, grad_norm=2.5835211277008057, loss=1.8558363914489746
I0303 08:14:12.062283 140239850956544 logging_writer.py:48] [154700] global_step=154700, grad_norm=2.559835433959961, loss=2.7902731895446777
I0303 08:14:56.881595 140239842563840 logging_writer.py:48] [154800] global_step=154800, grad_norm=2.414933919906616, loss=1.248948097229004
I0303 08:15:41.823622 140239850956544 logging_writer.py:48] [154900] global_step=154900, grad_norm=2.801694869995117, loss=2.902350425720215
I0303 08:16:27.008186 140239842563840 logging_writer.py:48] [155000] global_step=155000, grad_norm=3.006763458251953, loss=3.6695923805236816
I0303 08:17:12.762216 140239850956544 logging_writer.py:48] [155100] global_step=155100, grad_norm=2.356051445007324, loss=1.342859148979187
I0303 08:17:58.312006 140239842563840 logging_writer.py:48] [155200] global_step=155200, grad_norm=2.4530413150787354, loss=2.85357666015625
I0303 08:18:43.549738 140239850956544 logging_writer.py:48] [155300] global_step=155300, grad_norm=2.1820921897888184, loss=2.0287702083587646
I0303 08:18:52.330605 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:19:02.782700 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:19:23.393270 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:19:25.014703 140437341357888 submission_runner.py:411] Time since start: 74806.57s, 	Step: 155321, 	{'train/accuracy': 0.8555663824081421, 'train/loss': 0.5521935224533081, 'validation/accuracy': 0.7650399804115295, 'validation/loss': 0.9392313957214355, 'validation/num_examples': 50000, 'test/accuracy': 0.6396000385284424, 'test/loss': 1.5510258674621582, 'test/num_examples': 10000, 'score': 69366.76836133003, 'total_duration': 74806.56618714333, 'accumulated_submission_time': 69366.76836133003, 'accumulated_eval_time': 5422.504199266434, 'accumulated_logging_time': 8.762062788009644}
I0303 08:19:25.065207 140239842563840 logging_writer.py:48] [155321] accumulated_eval_time=5422.504199, accumulated_logging_time=8.762063, accumulated_submission_time=69366.768361, global_step=155321, preemption_count=0, score=69366.768361, test/accuracy=0.639600, test/loss=1.551026, test/num_examples=10000, total_duration=74806.566187, train/accuracy=0.855566, train/loss=0.552194, validation/accuracy=0.765040, validation/loss=0.939231, validation/num_examples=50000
I0303 08:19:57.289602 140239850956544 logging_writer.py:48] [155400] global_step=155400, grad_norm=2.496124029159546, loss=1.2725834846496582
I0303 08:20:42.649780 140239842563840 logging_writer.py:48] [155500] global_step=155500, grad_norm=2.426522731781006, loss=1.4703576564788818
I0303 08:21:27.822097 140239850956544 logging_writer.py:48] [155600] global_step=155600, grad_norm=3.198377847671509, loss=3.6238436698913574
I0303 08:22:13.007987 140239842563840 logging_writer.py:48] [155700] global_step=155700, grad_norm=2.4454739093780518, loss=1.333512544631958
I0303 08:22:57.994598 140239850956544 logging_writer.py:48] [155800] global_step=155800, grad_norm=2.5911009311676025, loss=1.3599311113357544
I0303 08:23:43.130311 140239842563840 logging_writer.py:48] [155900] global_step=155900, grad_norm=2.7337589263916016, loss=3.1218340396881104
I0303 08:24:28.213605 140239850956544 logging_writer.py:48] [156000] global_step=156000, grad_norm=2.363482713699341, loss=1.896446704864502
I0303 08:25:13.330664 140239842563840 logging_writer.py:48] [156100] global_step=156100, grad_norm=2.61761736869812, loss=1.906376838684082
I0303 08:25:58.129079 140239850956544 logging_writer.py:48] [156200] global_step=156200, grad_norm=2.42104172706604, loss=1.6391029357910156
I0303 08:26:25.021319 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:26:35.397866 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:26:58.291542 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:26:59.910953 140437341357888 submission_runner.py:411] Time since start: 75261.46s, 	Step: 156261, 	{'train/accuracy': 0.8625780940055847, 'train/loss': 0.516830325126648, 'validation/accuracy': 0.7641800045967102, 'validation/loss': 0.9275818467140198, 'validation/num_examples': 50000, 'test/accuracy': 0.6413000226020813, 'test/loss': 1.5416245460510254, 'test/num_examples': 10000, 'score': 69786.66360473633, 'total_duration': 75261.46242833138, 'accumulated_submission_time': 69786.66360473633, 'accumulated_eval_time': 5457.393801450729, 'accumulated_logging_time': 8.822291851043701}
I0303 08:26:59.959240 140239842563840 logging_writer.py:48] [156261] accumulated_eval_time=5457.393801, accumulated_logging_time=8.822292, accumulated_submission_time=69786.663605, global_step=156261, preemption_count=0, score=69786.663605, test/accuracy=0.641300, test/loss=1.541625, test/num_examples=10000, total_duration=75261.462428, train/accuracy=0.862578, train/loss=0.516830, validation/accuracy=0.764180, validation/loss=0.927582, validation/num_examples=50000
I0303 08:27:16.759716 140239850956544 logging_writer.py:48] [156300] global_step=156300, grad_norm=3.011817216873169, loss=3.6001152992248535
I0303 08:28:00.149140 140239842563840 logging_writer.py:48] [156400] global_step=156400, grad_norm=2.530930280685425, loss=1.2920876741409302
I0303 08:28:45.590207 140239850956544 logging_writer.py:48] [156500] global_step=156500, grad_norm=2.505098819732666, loss=1.3222765922546387
I0303 08:29:31.114084 140239842563840 logging_writer.py:48] [156600] global_step=156600, grad_norm=2.4481091499328613, loss=2.637603282928467
I0303 08:30:16.436156 140239850956544 logging_writer.py:48] [156700] global_step=156700, grad_norm=2.6199069023132324, loss=1.385059118270874
I0303 08:31:01.811788 140239842563840 logging_writer.py:48] [156800] global_step=156800, grad_norm=2.5049490928649902, loss=1.333096981048584
I0303 08:31:47.216808 140239850956544 logging_writer.py:48] [156900] global_step=156900, grad_norm=2.3342435359954834, loss=1.1791882514953613
I0303 08:32:32.693542 140239842563840 logging_writer.py:48] [157000] global_step=157000, grad_norm=3.0326201915740967, loss=3.345938205718994
I0303 08:33:18.220454 140239850956544 logging_writer.py:48] [157100] global_step=157100, grad_norm=2.4894633293151855, loss=1.2087091207504272
I0303 08:34:00.275955 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:34:10.746536 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:34:35.129292 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:34:36.756412 140437341357888 submission_runner.py:411] Time since start: 75718.31s, 	Step: 157195, 	{'train/accuracy': 0.8593164086341858, 'train/loss': 0.522832989692688, 'validation/accuracy': 0.7650799751281738, 'validation/loss': 0.9194480776786804, 'validation/num_examples': 50000, 'test/accuracy': 0.6414000391960144, 'test/loss': 1.5349903106689453, 'test/num_examples': 10000, 'score': 70206.14763140678, 'total_duration': 75718.30789279938, 'accumulated_submission_time': 70206.14763140678, 'accumulated_eval_time': 5493.874259471893, 'accumulated_logging_time': 9.651360750198364}
I0303 08:34:36.805172 140239842563840 logging_writer.py:48] [157195] accumulated_eval_time=5493.874259, accumulated_logging_time=9.651361, accumulated_submission_time=70206.147631, global_step=157195, preemption_count=0, score=70206.147631, test/accuracy=0.641400, test/loss=1.534990, test/num_examples=10000, total_duration=75718.307893, train/accuracy=0.859316, train/loss=0.522833, validation/accuracy=0.765080, validation/loss=0.919448, validation/num_examples=50000
I0303 08:34:39.192949 140239850956544 logging_writer.py:48] [157200] global_step=157200, grad_norm=2.702340602874756, loss=3.239485502243042
I0303 08:35:20.434893 140239842563840 logging_writer.py:48] [157300] global_step=157300, grad_norm=2.565319061279297, loss=1.3792893886566162
I0303 08:36:05.512591 140239850956544 logging_writer.py:48] [157400] global_step=157400, grad_norm=2.4452109336853027, loss=1.3097889423370361
I0303 08:36:50.696274 140239842563840 logging_writer.py:48] [157500] global_step=157500, grad_norm=2.520634174346924, loss=1.3289369344711304
I0303 08:37:35.870346 140239850956544 logging_writer.py:48] [157600] global_step=157600, grad_norm=2.553158760070801, loss=1.4591436386108398
I0303 08:38:21.455966 140239842563840 logging_writer.py:48] [157700] global_step=157700, grad_norm=2.702458381652832, loss=3.290537118911743
I0303 08:39:06.610614 140239850956544 logging_writer.py:48] [157800] global_step=157800, grad_norm=4.086410045623779, loss=2.0697460174560547
I0303 08:39:51.693172 140239842563840 logging_writer.py:48] [157900] global_step=157900, grad_norm=2.636082172393799, loss=1.3900829553604126
I0303 08:40:36.870403 140239850956544 logging_writer.py:48] [158000] global_step=158000, grad_norm=2.7519497871398926, loss=2.043280601501465
I0303 08:41:21.904408 140239842563840 logging_writer.py:48] [158100] global_step=158100, grad_norm=2.5519769191741943, loss=2.182889938354492
I0303 08:41:37.023848 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:41:47.081324 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:42:11.161573 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:42:12.809832 140437341357888 submission_runner.py:411] Time since start: 76174.36s, 	Step: 158135, 	{'train/accuracy': 0.8620507717132568, 'train/loss': 0.5150201916694641, 'validation/accuracy': 0.7664799690246582, 'validation/loss': 0.9146672487258911, 'validation/num_examples': 50000, 'test/accuracy': 0.6493000388145447, 'test/loss': 1.521514892578125, 'test/num_examples': 10000, 'score': 70626.3047413826, 'total_duration': 76174.36131358147, 'accumulated_submission_time': 70626.3047413826, 'accumulated_eval_time': 5529.660228967667, 'accumulated_logging_time': 9.710200309753418}
I0303 08:42:12.852875 140239850956544 logging_writer.py:48] [158135] accumulated_eval_time=5529.660229, accumulated_logging_time=9.710200, accumulated_submission_time=70626.304741, global_step=158135, preemption_count=0, score=70626.304741, test/accuracy=0.649300, test/loss=1.521515, test/num_examples=10000, total_duration=76174.361314, train/accuracy=0.862051, train/loss=0.515020, validation/accuracy=0.766480, validation/loss=0.914667, validation/num_examples=50000
I0303 08:42:38.983956 140239842563840 logging_writer.py:48] [158200] global_step=158200, grad_norm=2.432375192642212, loss=2.471499443054199
I0303 08:43:21.996335 140239850956544 logging_writer.py:48] [158300] global_step=158300, grad_norm=2.734750986099243, loss=2.7720603942871094
I0303 08:44:07.300791 140239842563840 logging_writer.py:48] [158400] global_step=158400, grad_norm=2.6875076293945312, loss=1.352454423904419
I0303 08:44:52.217442 140239850956544 logging_writer.py:48] [158500] global_step=158500, grad_norm=2.484119415283203, loss=1.1659173965454102
I0303 08:45:37.179806 140239842563840 logging_writer.py:48] [158600] global_step=158600, grad_norm=2.581012487411499, loss=2.2912745475769043
I0303 08:46:22.362943 140239850956544 logging_writer.py:48] [158700] global_step=158700, grad_norm=2.543686628341675, loss=1.204152226448059
I0303 08:47:07.628445 140239842563840 logging_writer.py:48] [158800] global_step=158800, grad_norm=2.6042799949645996, loss=2.8833136558532715
I0303 08:47:53.021502 140239850956544 logging_writer.py:48] [158900] global_step=158900, grad_norm=2.57295560836792, loss=1.3247581720352173
I0303 08:48:38.239530 140239842563840 logging_writer.py:48] [159000] global_step=159000, grad_norm=2.9263854026794434, loss=1.4095510244369507
I0303 08:49:13.120692 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:49:23.335993 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:49:45.406031 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:49:47.026334 140437341357888 submission_runner.py:411] Time since start: 76628.58s, 	Step: 159079, 	{'train/accuracy': 0.8653515577316284, 'train/loss': 0.5030461549758911, 'validation/accuracy': 0.7672199606895447, 'validation/loss': 0.9076811671257019, 'validation/num_examples': 50000, 'test/accuracy': 0.6468000411987305, 'test/loss': 1.5106713771820068, 'test/num_examples': 10000, 'score': 71046.5109963417, 'total_duration': 76628.57782149315, 'accumulated_submission_time': 71046.5109963417, 'accumulated_eval_time': 5563.565862417221, 'accumulated_logging_time': 9.763209104537964}
I0303 08:49:47.077540 140239850956544 logging_writer.py:48] [159079] accumulated_eval_time=5563.565862, accumulated_logging_time=9.763209, accumulated_submission_time=71046.510996, global_step=159079, preemption_count=0, score=71046.510996, test/accuracy=0.646800, test/loss=1.510671, test/num_examples=10000, total_duration=76628.577821, train/accuracy=0.865352, train/loss=0.503046, validation/accuracy=0.767220, validation/loss=0.907681, validation/num_examples=50000
I0303 08:49:55.809221 140239842563840 logging_writer.py:48] [159100] global_step=159100, grad_norm=2.524294853210449, loss=1.564845323562622
I0303 08:50:38.042975 140239850956544 logging_writer.py:48] [159200] global_step=159200, grad_norm=2.6455888748168945, loss=1.3535104990005493
I0303 08:51:23.371558 140239842563840 logging_writer.py:48] [159300] global_step=159300, grad_norm=2.555148124694824, loss=1.4058042764663696
I0303 08:52:08.529891 140239850956544 logging_writer.py:48] [159400] global_step=159400, grad_norm=2.9892425537109375, loss=3.276062250137329
I0303 08:52:53.885294 140239842563840 logging_writer.py:48] [159500] global_step=159500, grad_norm=2.3709967136383057, loss=1.1794607639312744
I0303 08:53:39.259244 140239850956544 logging_writer.py:48] [159600] global_step=159600, grad_norm=2.5940332412719727, loss=1.2490147352218628
I0303 08:54:24.239562 140239842563840 logging_writer.py:48] [159700] global_step=159700, grad_norm=3.1864399909973145, loss=3.300363302230835
I0303 08:55:09.352694 140239850956544 logging_writer.py:48] [159800] global_step=159800, grad_norm=2.5511527061462402, loss=1.1940512657165527
I0303 08:55:54.432362 140239842563840 logging_writer.py:48] [159900] global_step=159900, grad_norm=2.696582078933716, loss=1.2277729511260986
I0303 08:56:39.799206 140239850956544 logging_writer.py:48] [160000] global_step=160000, grad_norm=3.3536527156829834, loss=3.511441230773926
I0303 08:56:47.214716 140437341357888 spec.py:321] Evaluating on the training split.
I0303 08:56:57.661572 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 08:57:24.517407 140437341357888 spec.py:349] Evaluating on the test split.
I0303 08:57:26.140487 140437341357888 submission_runner.py:411] Time since start: 77087.69s, 	Step: 160018, 	{'train/accuracy': 0.8733007907867432, 'train/loss': 0.4837360680103302, 'validation/accuracy': 0.7673999667167664, 'validation/loss': 0.9166808128356934, 'validation/num_examples': 50000, 'test/accuracy': 0.6488000154495239, 'test/loss': 1.520171046257019, 'test/num_examples': 10000, 'score': 71466.58711266518, 'total_duration': 77087.69198036194, 'accumulated_submission_time': 71466.58711266518, 'accumulated_eval_time': 5602.491634130478, 'accumulated_logging_time': 9.824456453323364}
I0303 08:57:26.193292 140239842563840 logging_writer.py:48] [160018] accumulated_eval_time=5602.491634, accumulated_logging_time=9.824456, accumulated_submission_time=71466.587113, global_step=160018, preemption_count=0, score=71466.587113, test/accuracy=0.648800, test/loss=1.520171, test/num_examples=10000, total_duration=77087.691980, train/accuracy=0.873301, train/loss=0.483736, validation/accuracy=0.767400, validation/loss=0.916681, validation/num_examples=50000
I0303 08:57:59.278913 140239850956544 logging_writer.py:48] [160100] global_step=160100, grad_norm=2.6038753986358643, loss=2.7542126178741455
I0303 08:58:44.892811 140239842563840 logging_writer.py:48] [160200] global_step=160200, grad_norm=2.6496033668518066, loss=1.148223876953125
I0303 08:59:30.423810 140239850956544 logging_writer.py:48] [160300] global_step=160300, grad_norm=2.5052096843719482, loss=1.2338815927505493
I0303 09:00:15.600315 140239842563840 logging_writer.py:48] [160400] global_step=160400, grad_norm=2.8201024532318115, loss=2.2320759296417236
I0303 09:01:00.998816 140239850956544 logging_writer.py:48] [160500] global_step=160500, grad_norm=2.558375358581543, loss=1.2695800065994263
I0303 09:01:46.407836 140239842563840 logging_writer.py:48] [160600] global_step=160600, grad_norm=2.561004400253296, loss=1.5089170932769775
I0303 09:02:31.523258 140239850956544 logging_writer.py:48] [160700] global_step=160700, grad_norm=2.6631033420562744, loss=2.2500081062316895
I0303 09:03:16.668923 140239842563840 logging_writer.py:48] [160800] global_step=160800, grad_norm=2.61358380317688, loss=1.1635574102401733
I0303 09:04:01.629504 140239850956544 logging_writer.py:48] [160900] global_step=160900, grad_norm=2.5623977184295654, loss=1.2743642330169678
I0303 09:04:26.254686 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:04:36.462947 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:05:03.012806 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:05:04.668504 140437341357888 submission_runner.py:411] Time since start: 77546.22s, 	Step: 160956, 	{'train/accuracy': 0.8666601181030273, 'train/loss': 0.5009443759918213, 'validation/accuracy': 0.7683999538421631, 'validation/loss': 0.9037065505981445, 'validation/num_examples': 50000, 'test/accuracy': 0.6488000154495239, 'test/loss': 1.511286735534668, 'test/num_examples': 10000, 'score': 71886.58734107018, 'total_duration': 77546.2199819088, 'accumulated_submission_time': 71886.58734107018, 'accumulated_eval_time': 5640.905419826508, 'accumulated_logging_time': 9.887304306030273}
I0303 09:05:04.727928 140239842563840 logging_writer.py:48] [160956] accumulated_eval_time=5640.905420, accumulated_logging_time=9.887304, accumulated_submission_time=71886.587341, global_step=160956, preemption_count=0, score=71886.587341, test/accuracy=0.648800, test/loss=1.511287, test/num_examples=10000, total_duration=77546.219982, train/accuracy=0.866660, train/loss=0.500944, validation/accuracy=0.768400, validation/loss=0.903707, validation/num_examples=50000
I0303 09:05:22.552903 140239850956544 logging_writer.py:48] [161000] global_step=161000, grad_norm=3.2084474563598633, loss=3.515733242034912
I0303 09:06:04.606574 140239842563840 logging_writer.py:48] [161100] global_step=161100, grad_norm=2.9724390506744385, loss=3.5000133514404297
I0303 09:06:49.408116 140239850956544 logging_writer.py:48] [161200] global_step=161200, grad_norm=2.6024277210235596, loss=1.7176697254180908
I0303 09:07:34.591116 140239842563840 logging_writer.py:48] [161300] global_step=161300, grad_norm=2.659108877182007, loss=1.2376703023910522
I0303 09:08:19.905730 140239850956544 logging_writer.py:48] [161400] global_step=161400, grad_norm=2.6349024772644043, loss=2.0719897747039795
I0303 09:09:05.099707 140239842563840 logging_writer.py:48] [161500] global_step=161500, grad_norm=2.8688294887542725, loss=1.2316936254501343
I0303 09:09:50.175460 140239850956544 logging_writer.py:48] [161600] global_step=161600, grad_norm=2.9122796058654785, loss=3.202793836593628
I0303 09:10:35.480462 140239842563840 logging_writer.py:48] [161700] global_step=161700, grad_norm=3.344578504562378, loss=3.630310535430908
I0303 09:11:20.551257 140239850956544 logging_writer.py:48] [161800] global_step=161800, grad_norm=2.6723999977111816, loss=1.2743021249771118
I0303 09:12:04.727799 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:12:14.910220 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:12:45.662102 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:12:47.283086 140437341357888 submission_runner.py:411] Time since start: 78008.83s, 	Step: 161899, 	{'train/accuracy': 0.8688476085662842, 'train/loss': 0.490939736366272, 'validation/accuracy': 0.7700600028038025, 'validation/loss': 0.8974904417991638, 'validation/num_examples': 50000, 'test/accuracy': 0.6458000540733337, 'test/loss': 1.5094892978668213, 'test/num_examples': 10000, 'score': 72306.52605938911, 'total_duration': 78008.83457326889, 'accumulated_submission_time': 72306.52605938911, 'accumulated_eval_time': 5683.460703372955, 'accumulated_logging_time': 9.955764532089233}
I0303 09:12:47.336924 140239842563840 logging_writer.py:48] [161899] accumulated_eval_time=5683.460703, accumulated_logging_time=9.955765, accumulated_submission_time=72306.526059, global_step=161899, preemption_count=0, score=72306.526059, test/accuracy=0.645800, test/loss=1.509489, test/num_examples=10000, total_duration=78008.834573, train/accuracy=0.868848, train/loss=0.490940, validation/accuracy=0.770060, validation/loss=0.897490, validation/num_examples=50000
I0303 09:12:48.143600 140239850956544 logging_writer.py:48] [161900] global_step=161900, grad_norm=2.440001964569092, loss=1.1694477796554565
I0303 09:13:28.438734 140239842563840 logging_writer.py:48] [162000] global_step=162000, grad_norm=2.816624879837036, loss=1.320456624031067
I0303 09:14:13.238714 140239850956544 logging_writer.py:48] [162100] global_step=162100, grad_norm=2.7702784538269043, loss=1.2348521947860718
I0303 09:14:58.438470 140239842563840 logging_writer.py:48] [162200] global_step=162200, grad_norm=3.0185298919677734, loss=3.288801670074463
I0303 09:15:43.641100 140239850956544 logging_writer.py:48] [162300] global_step=162300, grad_norm=3.5996713638305664, loss=2.9083080291748047
I0303 09:16:28.772203 140239842563840 logging_writer.py:48] [162400] global_step=162400, grad_norm=3.244320869445801, loss=3.4522721767425537
I0303 09:17:13.753115 140239850956544 logging_writer.py:48] [162500] global_step=162500, grad_norm=2.495215892791748, loss=1.8219621181488037
I0303 09:17:58.735672 140239842563840 logging_writer.py:48] [162600] global_step=162600, grad_norm=2.6197690963745117, loss=1.2441797256469727
I0303 09:18:44.230665 140239850956544 logging_writer.py:48] [162700] global_step=162700, grad_norm=2.807016611099243, loss=1.3437187671661377
I0303 09:19:29.348772 140239842563840 logging_writer.py:48] [162800] global_step=162800, grad_norm=2.565462350845337, loss=2.0387871265411377
I0303 09:19:47.528520 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:19:57.861361 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:20:19.468601 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:20:21.089613 140437341357888 submission_runner.py:411] Time since start: 78462.64s, 	Step: 162842, 	{'train/accuracy': 0.87611323595047, 'train/loss': 0.4695218503475189, 'validation/accuracy': 0.7698599696159363, 'validation/loss': 0.8996132016181946, 'validation/num_examples': 50000, 'test/accuracy': 0.6525000333786011, 'test/loss': 1.496620774269104, 'test/num_examples': 10000, 'score': 72726.65507078171, 'total_duration': 78462.64110207558, 'accumulated_submission_time': 72726.65507078171, 'accumulated_eval_time': 5717.021797180176, 'accumulated_logging_time': 10.020394086837769}
I0303 09:20:21.142659 140239850956544 logging_writer.py:48] [162842] accumulated_eval_time=5717.021797, accumulated_logging_time=10.020394, accumulated_submission_time=72726.655071, global_step=162842, preemption_count=0, score=72726.655071, test/accuracy=0.652500, test/loss=1.496621, test/num_examples=10000, total_duration=78462.641102, train/accuracy=0.876113, train/loss=0.469522, validation/accuracy=0.769860, validation/loss=0.899613, validation/num_examples=50000
I0303 09:20:44.525735 140239842563840 logging_writer.py:48] [162900] global_step=162900, grad_norm=2.8524909019470215, loss=1.978621482849121
I0303 09:21:29.948150 140239850956544 logging_writer.py:48] [163000] global_step=163000, grad_norm=2.676713228225708, loss=1.1605699062347412
I0303 09:22:15.349172 140239842563840 logging_writer.py:48] [163100] global_step=163100, grad_norm=2.71468448638916, loss=2.947114944458008
I0303 09:23:00.879720 140239850956544 logging_writer.py:48] [163200] global_step=163200, grad_norm=2.648529052734375, loss=1.7359037399291992
I0303 09:23:46.368298 140239842563840 logging_writer.py:48] [163300] global_step=163300, grad_norm=2.625710964202881, loss=1.1991548538208008
I0303 09:24:31.885042 140239850956544 logging_writer.py:48] [163400] global_step=163400, grad_norm=2.6283669471740723, loss=1.2206015586853027
I0303 09:25:17.224213 140239842563840 logging_writer.py:48] [163500] global_step=163500, grad_norm=2.8025095462799072, loss=2.761746883392334
I0303 09:26:02.434353 140239850956544 logging_writer.py:48] [163600] global_step=163600, grad_norm=2.802579402923584, loss=1.3938859701156616
I0303 09:26:47.756073 140239842563840 logging_writer.py:48] [163700] global_step=163700, grad_norm=2.996541738510132, loss=3.329390048980713
I0303 09:27:21.480147 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:27:31.901962 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:27:55.352892 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:27:56.977712 140437341357888 submission_runner.py:411] Time since start: 78918.53s, 	Step: 163776, 	{'train/accuracy': 0.86865234375, 'train/loss': 0.4866144359111786, 'validation/accuracy': 0.7710599899291992, 'validation/loss': 0.8960846662521362, 'validation/num_examples': 50000, 'test/accuracy': 0.6538000106811523, 'test/loss': 1.4957234859466553, 'test/num_examples': 10000, 'score': 73146.93170976639, 'total_duration': 78918.5292005539, 'accumulated_submission_time': 73146.93170976639, 'accumulated_eval_time': 5752.519358158112, 'accumulated_logging_time': 10.0841383934021}
I0303 09:27:57.028184 140239850956544 logging_writer.py:48] [163776] accumulated_eval_time=5752.519358, accumulated_logging_time=10.084138, accumulated_submission_time=73146.931710, global_step=163776, preemption_count=0, score=73146.931710, test/accuracy=0.653800, test/loss=1.495723, test/num_examples=10000, total_duration=78918.529201, train/accuracy=0.868652, train/loss=0.486614, validation/accuracy=0.771060, validation/loss=0.896085, validation/num_examples=50000
I0303 09:28:06.960614 140239842563840 logging_writer.py:48] [163800] global_step=163800, grad_norm=2.5775673389434814, loss=1.3801565170288086
I0303 09:28:50.240076 140239850956544 logging_writer.py:48] [163900] global_step=163900, grad_norm=2.6017496585845947, loss=1.6718440055847168
I0303 09:29:35.553330 140239842563840 logging_writer.py:48] [164000] global_step=164000, grad_norm=2.753678798675537, loss=1.3209480047225952
I0303 09:30:20.779821 140239850956544 logging_writer.py:48] [164100] global_step=164100, grad_norm=2.48075532913208, loss=1.5934206247329712
I0303 09:31:06.059403 140239842563840 logging_writer.py:48] [164200] global_step=164200, grad_norm=3.00775408744812, loss=2.481095314025879
I0303 09:31:51.268314 140239850956544 logging_writer.py:48] [164300] global_step=164300, grad_norm=2.631296396255493, loss=1.1948316097259521
I0303 09:32:36.534076 140239842563840 logging_writer.py:48] [164400] global_step=164400, grad_norm=2.6591744422912598, loss=1.8049448728561401
I0303 09:33:21.740041 140239850956544 logging_writer.py:48] [164500] global_step=164500, grad_norm=2.9619669914245605, loss=1.3348736763000488
I0303 09:34:07.129289 140239842563840 logging_writer.py:48] [164600] global_step=164600, grad_norm=2.4933409690856934, loss=2.243189573287964
I0303 09:34:52.199618 140239850956544 logging_writer.py:48] [164700] global_step=164700, grad_norm=2.853931188583374, loss=1.1458253860473633
I0303 09:34:57.004353 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:35:07.273161 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:35:46.146692 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:35:47.754118 140437341357888 submission_runner.py:411] Time since start: 79389.31s, 	Step: 164712, 	{'train/accuracy': 0.87123042345047, 'train/loss': 0.48354196548461914, 'validation/accuracy': 0.7716599702835083, 'validation/loss': 0.892865002155304, 'validation/num_examples': 50000, 'test/accuracy': 0.65010005235672, 'test/loss': 1.4990768432617188, 'test/num_examples': 10000, 'score': 73566.84558701515, 'total_duration': 79389.30561876297, 'accumulated_submission_time': 73566.84558701515, 'accumulated_eval_time': 5803.269119262695, 'accumulated_logging_time': 10.14598798751831}
I0303 09:35:47.798567 140239842563840 logging_writer.py:48] [164712] accumulated_eval_time=5803.269119, accumulated_logging_time=10.145988, accumulated_submission_time=73566.845587, global_step=164712, preemption_count=0, score=73566.845587, test/accuracy=0.650100, test/loss=1.499077, test/num_examples=10000, total_duration=79389.305619, train/accuracy=0.871230, train/loss=0.483542, validation/accuracy=0.771660, validation/loss=0.892865, validation/num_examples=50000
I0303 09:36:23.028549 140239850956544 logging_writer.py:48] [164800] global_step=164800, grad_norm=2.8966386318206787, loss=1.8039370775222778
I0303 09:37:07.310590 140239842563840 logging_writer.py:48] [164900] global_step=164900, grad_norm=2.789442777633667, loss=1.416007399559021
I0303 09:37:52.109642 140239850956544 logging_writer.py:48] [165000] global_step=165000, grad_norm=2.880242347717285, loss=1.330902338027954
I0303 09:38:37.453436 140239842563840 logging_writer.py:48] [165100] global_step=165100, grad_norm=2.8730905055999756, loss=1.1728402376174927
I0303 09:39:23.044970 140239850956544 logging_writer.py:48] [165200] global_step=165200, grad_norm=2.8755335807800293, loss=1.1595953702926636
I0303 09:40:08.282342 140239842563840 logging_writer.py:48] [165300] global_step=165300, grad_norm=2.9701316356658936, loss=3.295039653778076
I0303 09:40:53.245716 140239850956544 logging_writer.py:48] [165400] global_step=165400, grad_norm=2.822023391723633, loss=1.159388542175293
I0303 09:41:38.363929 140239842563840 logging_writer.py:48] [165500] global_step=165500, grad_norm=2.994457244873047, loss=3.189342975616455
I0303 09:42:23.651371 140239850956544 logging_writer.py:48] [165600] global_step=165600, grad_norm=2.729419231414795, loss=1.4518638849258423
I0303 09:42:47.818443 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:42:58.029942 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:43:21.093117 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:43:22.711412 140437341357888 submission_runner.py:411] Time since start: 79844.26s, 	Step: 165655, 	{'train/accuracy': 0.8752539157867432, 'train/loss': 0.46730539202690125, 'validation/accuracy': 0.7740199565887451, 'validation/loss': 0.8827558159828186, 'validation/num_examples': 50000, 'test/accuracy': 0.6559000015258789, 'test/loss': 1.486812710762024, 'test/num_examples': 10000, 'score': 73986.8037891388, 'total_duration': 79844.26286292076, 'accumulated_submission_time': 73986.8037891388, 'accumulated_eval_time': 5838.162070274353, 'accumulated_logging_time': 10.200010299682617}
I0303 09:43:22.766157 140239842563840 logging_writer.py:48] [165655] accumulated_eval_time=5838.162070, accumulated_logging_time=10.200010, accumulated_submission_time=73986.803789, global_step=165655, preemption_count=0, score=73986.803789, test/accuracy=0.655900, test/loss=1.486813, test/num_examples=10000, total_duration=79844.262863, train/accuracy=0.875254, train/loss=0.467305, validation/accuracy=0.774020, validation/loss=0.882756, validation/num_examples=50000
I0303 09:43:41.019507 140239850956544 logging_writer.py:48] [165700] global_step=165700, grad_norm=3.136962652206421, loss=3.282773971557617
I0303 09:44:24.561066 140239842563840 logging_writer.py:48] [165800] global_step=165800, grad_norm=2.983276844024658, loss=1.273626446723938
I0303 09:45:09.976874 140239850956544 logging_writer.py:48] [165900] global_step=165900, grad_norm=2.877359390258789, loss=3.0090413093566895
I0303 09:45:55.269405 140239842563840 logging_writer.py:48] [166000] global_step=166000, grad_norm=2.8549697399139404, loss=2.4573235511779785
I0303 09:46:40.359567 140239850956544 logging_writer.py:48] [166100] global_step=166100, grad_norm=2.488020896911621, loss=2.4602320194244385
I0303 09:47:25.461840 140239842563840 logging_writer.py:48] [166200] global_step=166200, grad_norm=2.6402080059051514, loss=1.1152398586273193
I0303 09:48:10.869104 140239850956544 logging_writer.py:48] [166300] global_step=166300, grad_norm=2.7141218185424805, loss=1.1840649843215942
I0303 09:48:56.232390 140239842563840 logging_writer.py:48] [166400] global_step=166400, grad_norm=2.746729850769043, loss=1.337066888809204
I0303 09:49:41.329635 140239850956544 logging_writer.py:48] [166500] global_step=166500, grad_norm=2.570895195007324, loss=1.3857033252716064
I0303 09:50:23.027421 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:50:33.570939 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:50:56.544095 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:50:58.170612 140437341357888 submission_runner.py:411] Time since start: 80299.72s, 	Step: 166594, 	{'train/accuracy': 0.8815820217132568, 'train/loss': 0.4435708522796631, 'validation/accuracy': 0.7743200063705444, 'validation/loss': 0.8817341923713684, 'validation/num_examples': 50000, 'test/accuracy': 0.657200038433075, 'test/loss': 1.481296181678772, 'test/num_examples': 10000, 'score': 74406.99995279312, 'total_duration': 80299.7220902443, 'accumulated_submission_time': 74406.99995279312, 'accumulated_eval_time': 5873.305253982544, 'accumulated_logging_time': 10.267615795135498}
I0303 09:50:58.222081 140239842563840 logging_writer.py:48] [166594] accumulated_eval_time=5873.305254, accumulated_logging_time=10.267616, accumulated_submission_time=74406.999953, global_step=166594, preemption_count=0, score=74406.999953, test/accuracy=0.657200, test/loss=1.481296, test/num_examples=10000, total_duration=80299.722090, train/accuracy=0.881582, train/loss=0.443571, validation/accuracy=0.774320, validation/loss=0.881734, validation/num_examples=50000
I0303 09:51:01.009028 140239850956544 logging_writer.py:48] [166600] global_step=166600, grad_norm=3.2379379272460938, loss=3.364445209503174
I0303 09:51:43.685831 140239842563840 logging_writer.py:48] [166700] global_step=166700, grad_norm=2.7297239303588867, loss=1.489634394645691
I0303 09:52:28.938925 140239850956544 logging_writer.py:48] [166800] global_step=166800, grad_norm=2.9417872428894043, loss=2.4616341590881348
I0303 09:53:14.370298 140239842563840 logging_writer.py:48] [166900] global_step=166900, grad_norm=2.6966042518615723, loss=2.364969491958618
I0303 09:53:59.906111 140239850956544 logging_writer.py:48] [167000] global_step=167000, grad_norm=3.058429479598999, loss=1.387696623802185
I0303 09:54:45.308162 140239842563840 logging_writer.py:48] [167100] global_step=167100, grad_norm=2.746994972229004, loss=2.853943109512329
I0303 09:55:30.742743 140239850956544 logging_writer.py:48] [167200] global_step=167200, grad_norm=2.8511526584625244, loss=1.2719708681106567
I0303 09:56:16.198953 140239842563840 logging_writer.py:48] [167300] global_step=167300, grad_norm=2.7580854892730713, loss=1.6882598400115967
I0303 09:57:01.465498 140239850956544 logging_writer.py:48] [167400] global_step=167400, grad_norm=2.7977280616760254, loss=1.9866750240325928
I0303 09:57:47.014967 140239842563840 logging_writer.py:48] [167500] global_step=167500, grad_norm=2.7792911529541016, loss=1.226250410079956
I0303 09:57:58.533262 140437341357888 spec.py:321] Evaluating on the training split.
I0303 09:58:08.905521 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 09:58:35.312368 140437341357888 spec.py:349] Evaluating on the test split.
I0303 09:58:36.937416 140437341357888 submission_runner.py:411] Time since start: 80758.49s, 	Step: 167527, 	{'train/accuracy': 0.8744335770606995, 'train/loss': 0.4724225103855133, 'validation/accuracy': 0.774179995059967, 'validation/loss': 0.8804149627685547, 'validation/num_examples': 50000, 'test/accuracy': 0.6550000309944153, 'test/loss': 1.4792810678482056, 'test/num_examples': 10000, 'score': 74827.24753332138, 'total_duration': 80758.48889684677, 'accumulated_submission_time': 74827.24753332138, 'accumulated_eval_time': 5911.709374427795, 'accumulated_logging_time': 10.32997465133667}
I0303 09:58:36.991412 140239850956544 logging_writer.py:48] [167527] accumulated_eval_time=5911.709374, accumulated_logging_time=10.329975, accumulated_submission_time=74827.247533, global_step=167527, preemption_count=0, score=74827.247533, test/accuracy=0.655000, test/loss=1.479281, test/num_examples=10000, total_duration=80758.488897, train/accuracy=0.874434, train/loss=0.472423, validation/accuracy=0.774180, validation/loss=0.880415, validation/num_examples=50000
I0303 09:59:06.323507 140239842563840 logging_writer.py:48] [167600] global_step=167600, grad_norm=2.7935850620269775, loss=1.17348313331604
I0303 09:59:51.878932 140239850956544 logging_writer.py:48] [167700] global_step=167700, grad_norm=2.880336284637451, loss=1.2958515882492065
I0303 10:00:37.404578 140239842563840 logging_writer.py:48] [167800] global_step=167800, grad_norm=2.837115526199341, loss=1.1673671007156372
I0303 10:01:22.622361 140239850956544 logging_writer.py:48] [167900] global_step=167900, grad_norm=2.753384590148926, loss=1.2397174835205078
I0303 10:02:08.114193 140239842563840 logging_writer.py:48] [168000] global_step=168000, grad_norm=2.716994524002075, loss=1.2590183019638062
I0303 10:02:53.356507 140239850956544 logging_writer.py:48] [168100] global_step=168100, grad_norm=2.747105836868286, loss=2.075016975402832
I0303 10:03:38.456452 140239842563840 logging_writer.py:48] [168200] global_step=168200, grad_norm=2.7060413360595703, loss=1.2016587257385254
I0303 10:04:23.803617 140239850956544 logging_writer.py:48] [168300] global_step=168300, grad_norm=2.6977171897888184, loss=1.5364658832550049
I0303 10:05:09.173563 140239842563840 logging_writer.py:48] [168400] global_step=168400, grad_norm=3.940873861312866, loss=3.3959245681762695
I0303 10:05:37.307396 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:05:47.485213 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:06:23.069743 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:06:24.689068 140437341357888 submission_runner.py:411] Time since start: 81226.24s, 	Step: 168464, 	{'train/accuracy': 0.8765429258346558, 'train/loss': 0.4508543014526367, 'validation/accuracy': 0.774899959564209, 'validation/loss': 0.8729352951049805, 'validation/num_examples': 50000, 'test/accuracy': 0.6531000137329102, 'test/loss': 1.4713881015777588, 'test/num_examples': 10000, 'score': 75247.50064873695, 'total_duration': 81226.24056196213, 'accumulated_submission_time': 75247.50064873695, 'accumulated_eval_time': 5959.091042995453, 'accumulated_logging_time': 10.396169185638428}
I0303 10:06:24.734969 140239850956544 logging_writer.py:48] [168464] accumulated_eval_time=5959.091043, accumulated_logging_time=10.396169, accumulated_submission_time=75247.500649, global_step=168464, preemption_count=0, score=75247.500649, test/accuracy=0.653100, test/loss=1.471388, test/num_examples=10000, total_duration=81226.240562, train/accuracy=0.876543, train/loss=0.450854, validation/accuracy=0.774900, validation/loss=0.872935, validation/num_examples=50000
I0303 10:06:39.399850 140239842563840 logging_writer.py:48] [168500] global_step=168500, grad_norm=3.537428855895996, loss=3.3474326133728027
I0303 10:07:21.080758 140239850956544 logging_writer.py:48] [168600] global_step=168600, grad_norm=2.6127657890319824, loss=1.4290419816970825
I0303 10:08:06.162453 140239842563840 logging_writer.py:48] [168700] global_step=168700, grad_norm=2.681971549987793, loss=1.4204413890838623
I0303 10:08:51.283437 140239850956544 logging_writer.py:48] [168800] global_step=168800, grad_norm=2.719754695892334, loss=1.6842947006225586
I0303 10:09:36.586076 140239842563840 logging_writer.py:48] [168900] global_step=168900, grad_norm=2.743602991104126, loss=2.0729804039001465
I0303 10:10:21.614371 140239850956544 logging_writer.py:48] [169000] global_step=169000, grad_norm=2.8340609073638916, loss=1.1652885675430298
I0303 10:11:06.690291 140239842563840 logging_writer.py:48] [169100] global_step=169100, grad_norm=2.7869956493377686, loss=2.6470842361450195
I0303 10:11:51.658330 140239850956544 logging_writer.py:48] [169200] global_step=169200, grad_norm=2.796931028366089, loss=1.3220722675323486
I0303 10:12:36.895109 140239842563840 logging_writer.py:48] [169300] global_step=169300, grad_norm=3.1963107585906982, loss=1.7621442079544067
I0303 10:13:21.961355 140239850956544 logging_writer.py:48] [169400] global_step=169400, grad_norm=2.6792991161346436, loss=1.200214147567749
I0303 10:13:24.741615 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:13:34.849565 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:13:58.938480 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:14:00.566431 140437341357888 submission_runner.py:411] Time since start: 81682.12s, 	Step: 169408, 	{'train/accuracy': 0.8811718821525574, 'train/loss': 0.44714686274528503, 'validation/accuracy': 0.7753999829292297, 'validation/loss': 0.8756856918334961, 'validation/num_examples': 50000, 'test/accuracy': 0.6557000279426575, 'test/loss': 1.4676754474639893, 'test/num_examples': 10000, 'score': 75667.44517111778, 'total_duration': 81682.11791706085, 'accumulated_submission_time': 75667.44517111778, 'accumulated_eval_time': 5994.915839672089, 'accumulated_logging_time': 10.452755689620972}
I0303 10:14:00.623202 140239842563840 logging_writer.py:48] [169408] accumulated_eval_time=5994.915840, accumulated_logging_time=10.452756, accumulated_submission_time=75667.445171, global_step=169408, preemption_count=0, score=75667.445171, test/accuracy=0.655700, test/loss=1.467675, test/num_examples=10000, total_duration=81682.117917, train/accuracy=0.881172, train/loss=0.447147, validation/accuracy=0.775400, validation/loss=0.875686, validation/num_examples=50000
I0303 10:14:39.116162 140239850956544 logging_writer.py:48] [169500] global_step=169500, grad_norm=2.610079765319824, loss=1.1462433338165283
I0303 10:15:24.194974 140239842563840 logging_writer.py:48] [169600] global_step=169600, grad_norm=2.612506628036499, loss=2.085301160812378
I0303 10:16:09.519420 140239850956544 logging_writer.py:48] [169700] global_step=169700, grad_norm=2.8459246158599854, loss=2.3738906383514404
I0303 10:16:54.532723 140239842563840 logging_writer.py:48] [169800] global_step=169800, grad_norm=2.660936117172241, loss=2.146862745285034
I0303 10:17:39.563398 140239850956544 logging_writer.py:48] [169900] global_step=169900, grad_norm=2.79365611076355, loss=2.4587888717651367
I0303 10:18:24.634716 140239842563840 logging_writer.py:48] [170000] global_step=170000, grad_norm=2.9154579639434814, loss=1.330625057220459
I0303 10:19:09.796151 140239850956544 logging_writer.py:48] [170100] global_step=170100, grad_norm=3.345808506011963, loss=1.1019909381866455
I0303 10:19:55.019489 140239842563840 logging_writer.py:48] [170200] global_step=170200, grad_norm=2.8162388801574707, loss=1.9674770832061768
I0303 10:20:40.317152 140239850956544 logging_writer.py:48] [170300] global_step=170300, grad_norm=3.751861095428467, loss=3.1680290699005127
I0303 10:21:00.652453 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:21:11.258686 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:21:36.853331 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:21:38.480763 140437341357888 submission_runner.py:411] Time since start: 82140.03s, 	Step: 170347, 	{'train/accuracy': 0.8786327838897705, 'train/loss': 0.45409679412841797, 'validation/accuracy': 0.7759400010108948, 'validation/loss': 0.8734537363052368, 'validation/num_examples': 50000, 'test/accuracy': 0.6539000272750854, 'test/loss': 1.4720929861068726, 'test/num_examples': 10000, 'score': 76087.41112089157, 'total_duration': 82140.03224730492, 'accumulated_submission_time': 76087.41112089157, 'accumulated_eval_time': 6032.74413061142, 'accumulated_logging_time': 10.521770477294922}
I0303 10:21:38.530944 140239842563840 logging_writer.py:48] [170347] accumulated_eval_time=6032.744131, accumulated_logging_time=10.521770, accumulated_submission_time=76087.411121, global_step=170347, preemption_count=0, score=76087.411121, test/accuracy=0.653900, test/loss=1.472093, test/num_examples=10000, total_duration=82140.032247, train/accuracy=0.878633, train/loss=0.454097, validation/accuracy=0.775940, validation/loss=0.873454, validation/num_examples=50000
I0303 10:21:59.918478 140239850956544 logging_writer.py:48] [170400] global_step=170400, grad_norm=3.0611250400543213, loss=1.2607874870300293
I0303 10:22:44.250788 140239842563840 logging_writer.py:48] [170500] global_step=170500, grad_norm=2.9056859016418457, loss=1.682430624961853
I0303 10:23:29.641238 140239850956544 logging_writer.py:48] [170600] global_step=170600, grad_norm=3.207247018814087, loss=1.193641185760498
I0303 10:24:15.026458 140239842563840 logging_writer.py:48] [170700] global_step=170700, grad_norm=2.7815210819244385, loss=1.1689541339874268
I0303 10:25:00.123107 140239850956544 logging_writer.py:48] [170800] global_step=170800, grad_norm=3.1748368740081787, loss=1.2095390558242798
I0303 10:25:45.624988 140239842563840 logging_writer.py:48] [170900] global_step=170900, grad_norm=2.8917553424835205, loss=1.1687959432601929
I0303 10:26:30.674579 140239850956544 logging_writer.py:48] [171000] global_step=171000, grad_norm=2.8332388401031494, loss=1.9337992668151855
I0303 10:27:16.055424 140239842563840 logging_writer.py:48] [171100] global_step=171100, grad_norm=2.9706172943115234, loss=1.2471041679382324
I0303 10:28:01.003543 140239850956544 logging_writer.py:48] [171200] global_step=171200, grad_norm=3.3358078002929688, loss=1.9976508617401123
I0303 10:28:38.686486 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:28:48.865189 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:29:20.504739 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:29:22.111220 140437341357888 submission_runner.py:411] Time since start: 82603.66s, 	Step: 171285, 	{'train/accuracy': 0.8799608945846558, 'train/loss': 0.4463948607444763, 'validation/accuracy': 0.7760399580001831, 'validation/loss': 0.8722897171974182, 'validation/num_examples': 50000, 'test/accuracy': 0.6573000550270081, 'test/loss': 1.4642900228500366, 'test/num_examples': 10000, 'score': 76507.5048623085, 'total_duration': 82603.66271305084, 'accumulated_submission_time': 76507.5048623085, 'accumulated_eval_time': 6076.168865442276, 'accumulated_logging_time': 10.582777738571167}
I0303 10:29:22.153537 140239842563840 logging_writer.py:48] [171285] accumulated_eval_time=6076.168865, accumulated_logging_time=10.582778, accumulated_submission_time=76507.504862, global_step=171285, preemption_count=0, score=76507.504862, test/accuracy=0.657300, test/loss=1.464290, test/num_examples=10000, total_duration=82603.662713, train/accuracy=0.879961, train/loss=0.446395, validation/accuracy=0.776040, validation/loss=0.872290, validation/num_examples=50000
I0303 10:29:28.483316 140239850956544 logging_writer.py:48] [171300] global_step=171300, grad_norm=2.7767679691314697, loss=2.4298441410064697
I0303 10:30:09.524597 140239842563840 logging_writer.py:48] [171400] global_step=171400, grad_norm=2.8101627826690674, loss=1.5876514911651611
I0303 10:30:54.135549 140239850956544 logging_writer.py:48] [171500] global_step=171500, grad_norm=3.1645848751068115, loss=3.092750072479248
I0303 10:31:39.384896 140239842563840 logging_writer.py:48] [171600] global_step=171600, grad_norm=3.421382188796997, loss=3.188337564468384
I0303 10:32:24.556930 140239850956544 logging_writer.py:48] [171700] global_step=171700, grad_norm=4.417182445526123, loss=2.9966769218444824
I0303 10:33:09.684733 140239842563840 logging_writer.py:48] [171800] global_step=171800, grad_norm=2.8510518074035645, loss=1.5686085224151611
I0303 10:33:54.945472 140239850956544 logging_writer.py:48] [171900] global_step=171900, grad_norm=3.0039453506469727, loss=3.0973050594329834
I0303 10:34:40.061744 140239842563840 logging_writer.py:48] [172000] global_step=172000, grad_norm=2.9398984909057617, loss=1.1564228534698486
I0303 10:35:25.306842 140239850956544 logging_writer.py:48] [172100] global_step=172100, grad_norm=3.443185329437256, loss=1.1742432117462158
I0303 10:36:10.424419 140239842563840 logging_writer.py:48] [172200] global_step=172200, grad_norm=3.0637004375457764, loss=2.792757272720337
I0303 10:36:22.366109 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:36:32.771407 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:36:57.039841 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:36:58.663089 140437341357888 submission_runner.py:411] Time since start: 83060.21s, 	Step: 172228, 	{'train/accuracy': 0.8814257383346558, 'train/loss': 0.44328436255455017, 'validation/accuracy': 0.7773799896240234, 'validation/loss': 0.8704707026481628, 'validation/num_examples': 50000, 'test/accuracy': 0.6579000353813171, 'test/loss': 1.4670575857162476, 'test/num_examples': 10000, 'score': 76927.65636372566, 'total_duration': 83060.2145652771, 'accumulated_submission_time': 76927.65636372566, 'accumulated_eval_time': 6112.465822458267, 'accumulated_logging_time': 10.634551048278809}
I0303 10:36:58.717989 140239850956544 logging_writer.py:48] [172228] accumulated_eval_time=6112.465822, accumulated_logging_time=10.634551, accumulated_submission_time=76927.656364, global_step=172228, preemption_count=0, score=76927.656364, test/accuracy=0.657900, test/loss=1.467058, test/num_examples=10000, total_duration=83060.214565, train/accuracy=0.881426, train/loss=0.443284, validation/accuracy=0.777380, validation/loss=0.870471, validation/num_examples=50000
I0303 10:37:27.965314 140239842563840 logging_writer.py:48] [172300] global_step=172300, grad_norm=2.916508197784424, loss=2.0371532440185547
I0303 10:38:12.940172 140239850956544 logging_writer.py:48] [172400] global_step=172400, grad_norm=2.8862462043762207, loss=1.1634407043457031
I0303 10:38:57.783612 140239842563840 logging_writer.py:48] [172500] global_step=172500, grad_norm=3.297055244445801, loss=2.4505014419555664
I0303 10:39:43.114160 140239850956544 logging_writer.py:48] [172600] global_step=172600, grad_norm=2.9244003295898438, loss=1.5805259943008423
I0303 10:40:28.381119 140239842563840 logging_writer.py:48] [172700] global_step=172700, grad_norm=4.341540336608887, loss=1.1030158996582031
I0303 10:41:13.520557 140239850956544 logging_writer.py:48] [172800] global_step=172800, grad_norm=2.973080635070801, loss=1.4768238067626953
I0303 10:41:58.354491 140239842563840 logging_writer.py:48] [172900] global_step=172900, grad_norm=2.7816834449768066, loss=1.2625010013580322
I0303 10:42:43.533477 140239850956544 logging_writer.py:48] [173000] global_step=173000, grad_norm=3.1433420181274414, loss=1.3413105010986328
I0303 10:43:28.734122 140239842563840 logging_writer.py:48] [173100] global_step=173100, grad_norm=3.5910775661468506, loss=3.305213689804077
I0303 10:43:58.963174 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:44:09.710138 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:44:38.119929 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:44:39.735361 140437341357888 submission_runner.py:411] Time since start: 83521.29s, 	Step: 173169, 	{'train/accuracy': 0.8839452862739563, 'train/loss': 0.4334542453289032, 'validation/accuracy': 0.7780399918556213, 'validation/loss': 0.8655481934547424, 'validation/num_examples': 50000, 'test/accuracy': 0.6571000218391418, 'test/loss': 1.4592924118041992, 'test/num_examples': 10000, 'score': 77347.83917474747, 'total_duration': 83521.28679227829, 'accumulated_submission_time': 77347.83917474747, 'accumulated_eval_time': 6153.237934350967, 'accumulated_logging_time': 10.700610399246216}
I0303 10:44:39.788186 140239850956544 logging_writer.py:48] [173169] accumulated_eval_time=6153.237934, accumulated_logging_time=10.700610, accumulated_submission_time=77347.839175, global_step=173169, preemption_count=0, score=77347.839175, test/accuracy=0.657100, test/loss=1.459292, test/num_examples=10000, total_duration=83521.286792, train/accuracy=0.883945, train/loss=0.433454, validation/accuracy=0.778040, validation/loss=0.865548, validation/num_examples=50000
I0303 10:44:52.542949 140239842563840 logging_writer.py:48] [173200] global_step=173200, grad_norm=2.818337917327881, loss=1.1513384580612183
I0303 10:45:34.762496 140239850956544 logging_writer.py:48] [173300] global_step=173300, grad_norm=2.7081310749053955, loss=2.1376376152038574
I0303 10:46:20.185014 140239842563840 logging_writer.py:48] [173400] global_step=173400, grad_norm=2.9240224361419678, loss=1.1411770582199097
I0303 10:47:05.602204 140239850956544 logging_writer.py:48] [173500] global_step=173500, grad_norm=3.063039541244507, loss=1.218846321105957
I0303 10:47:50.531588 140239842563840 logging_writer.py:48] [173600] global_step=173600, grad_norm=2.9029102325439453, loss=1.6560336351394653
I0303 10:48:35.403558 140239850956544 logging_writer.py:48] [173700] global_step=173700, grad_norm=2.917513608932495, loss=1.2096401453018188
I0303 10:49:20.520944 140239842563840 logging_writer.py:48] [173800] global_step=173800, grad_norm=2.861672878265381, loss=1.1131625175476074
I0303 10:50:05.678567 140239850956544 logging_writer.py:48] [173900] global_step=173900, grad_norm=3.02144193649292, loss=1.1415936946868896
I0303 10:50:50.613022 140239842563840 logging_writer.py:48] [174000] global_step=174000, grad_norm=2.8638534545898438, loss=1.6518923044204712
I0303 10:51:35.769416 140239850956544 logging_writer.py:48] [174100] global_step=174100, grad_norm=2.924565553665161, loss=1.120630145072937
I0303 10:51:40.080987 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:51:50.388991 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:52:13.047435 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:52:14.682889 140437341357888 submission_runner.py:411] Time since start: 83976.23s, 	Step: 174111, 	{'train/accuracy': 0.8828905820846558, 'train/loss': 0.43228307366371155, 'validation/accuracy': 0.77947998046875, 'validation/loss': 0.8609575033187866, 'validation/num_examples': 50000, 'test/accuracy': 0.6586000323295593, 'test/loss': 1.4545586109161377, 'test/num_examples': 10000, 'score': 77768.06882762909, 'total_duration': 83976.2343738079, 'accumulated_submission_time': 77768.06882762909, 'accumulated_eval_time': 6187.839814186096, 'accumulated_logging_time': 10.765312910079956}
I0303 10:52:14.738488 140239842563840 logging_writer.py:48] [174111] accumulated_eval_time=6187.839814, accumulated_logging_time=10.765313, accumulated_submission_time=77768.068828, global_step=174111, preemption_count=0, score=77768.068828, test/accuracy=0.658600, test/loss=1.454559, test/num_examples=10000, total_duration=83976.234374, train/accuracy=0.882891, train/loss=0.432283, validation/accuracy=0.779480, validation/loss=0.860958, validation/num_examples=50000
I0303 10:52:51.633768 140239850956544 logging_writer.py:48] [174200] global_step=174200, grad_norm=3.1190147399902344, loss=1.158829689025879
I0303 10:53:37.045242 140239842563840 logging_writer.py:48] [174300] global_step=174300, grad_norm=3.1598291397094727, loss=1.3831876516342163
I0303 10:54:22.545915 140239850956544 logging_writer.py:48] [174400] global_step=174400, grad_norm=3.0466203689575195, loss=1.86002516746521
I0303 10:55:07.628814 140239842563840 logging_writer.py:48] [174500] global_step=174500, grad_norm=2.916653871536255, loss=1.1710050106048584
I0303 10:55:52.698338 140239850956544 logging_writer.py:48] [174600] global_step=174600, grad_norm=3.024676561355591, loss=1.0835108757019043
I0303 10:56:38.045928 140239842563840 logging_writer.py:48] [174700] global_step=174700, grad_norm=3.249906063079834, loss=3.1925246715545654
I0303 10:57:23.356440 140239850956544 logging_writer.py:48] [174800] global_step=174800, grad_norm=3.0240306854248047, loss=2.490769863128662
I0303 10:58:08.214546 140239842563840 logging_writer.py:48] [174900] global_step=174900, grad_norm=2.9035019874572754, loss=2.1368939876556396
I0303 10:58:53.068512 140239850956544 logging_writer.py:48] [175000] global_step=175000, grad_norm=3.035921335220337, loss=2.6350061893463135
I0303 10:59:14.691970 140437341357888 spec.py:321] Evaluating on the training split.
I0303 10:59:25.020241 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 10:59:47.412563 140437341357888 spec.py:349] Evaluating on the test split.
I0303 10:59:49.030945 140437341357888 submission_runner.py:411] Time since start: 84430.58s, 	Step: 175049, 	{'train/accuracy': 0.8865429759025574, 'train/loss': 0.4204282760620117, 'validation/accuracy': 0.7789599895477295, 'validation/loss': 0.861438512802124, 'validation/num_examples': 50000, 'test/accuracy': 0.6575000286102295, 'test/loss': 1.4523377418518066, 'test/num_examples': 10000, 'score': 78187.95839118958, 'total_duration': 84430.58243322372, 'accumulated_submission_time': 78187.95839118958, 'accumulated_eval_time': 6222.178782701492, 'accumulated_logging_time': 10.833298206329346}
I0303 10:59:49.084915 140239842563840 logging_writer.py:48] [175049] accumulated_eval_time=6222.178783, accumulated_logging_time=10.833298, accumulated_submission_time=78187.958391, global_step=175049, preemption_count=0, score=78187.958391, test/accuracy=0.657500, test/loss=1.452338, test/num_examples=10000, total_duration=84430.582433, train/accuracy=0.886543, train/loss=0.420428, validation/accuracy=0.778960, validation/loss=0.861439, validation/num_examples=50000
I0303 11:00:09.706081 140239850956544 logging_writer.py:48] [175100] global_step=175100, grad_norm=3.093743324279785, loss=2.5286571979522705
I0303 11:00:53.961798 140239842563840 logging_writer.py:48] [175200] global_step=175200, grad_norm=2.8252620697021484, loss=2.2297773361206055
I0303 11:01:39.562464 140239850956544 logging_writer.py:48] [175300] global_step=175300, grad_norm=2.897789478302002, loss=1.112220287322998
I0303 11:02:24.779840 140239842563840 logging_writer.py:48] [175400] global_step=175400, grad_norm=3.0501372814178467, loss=1.235499620437622
I0303 11:03:10.035544 140239850956544 logging_writer.py:48] [175500] global_step=175500, grad_norm=3.295520782470703, loss=2.9356255531311035
I0303 11:03:55.085094 140239842563840 logging_writer.py:48] [175600] global_step=175600, grad_norm=3.019467830657959, loss=1.1358976364135742
I0303 11:04:40.533797 140239850956544 logging_writer.py:48] [175700] global_step=175700, grad_norm=3.9720561504364014, loss=3.045616388320923
I0303 11:05:25.851017 140239842563840 logging_writer.py:48] [175800] global_step=175800, grad_norm=2.9568073749542236, loss=1.0960928201675415
I0303 11:06:11.144649 140239850956544 logging_writer.py:48] [175900] global_step=175900, grad_norm=3.0916075706481934, loss=1.1008049249649048
I0303 11:06:49.526254 140437341357888 spec.py:321] Evaluating on the training split.
I0303 11:06:59.702576 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 11:07:25.840765 140437341357888 spec.py:349] Evaluating on the test split.
I0303 11:07:27.471070 140437341357888 submission_runner.py:411] Time since start: 84889.02s, 	Step: 175986, 	{'train/accuracy': 0.8853319883346558, 'train/loss': 0.42953523993492126, 'validation/accuracy': 0.7797200083732605, 'validation/loss': 0.859338641166687, 'validation/num_examples': 50000, 'test/accuracy': 0.6561000347137451, 'test/loss': 1.4516371488571167, 'test/num_examples': 10000, 'score': 78608.33759880066, 'total_duration': 84889.0225493908, 'accumulated_submission_time': 78608.33759880066, 'accumulated_eval_time': 6260.123591899872, 'accumulated_logging_time': 10.897441625595093}
I0303 11:07:27.522482 140239842563840 logging_writer.py:48] [175986] accumulated_eval_time=6260.123592, accumulated_logging_time=10.897442, accumulated_submission_time=78608.337599, global_step=175986, preemption_count=0, score=78608.337599, test/accuracy=0.656100, test/loss=1.451637, test/num_examples=10000, total_duration=84889.022549, train/accuracy=0.885332, train/loss=0.429535, validation/accuracy=0.779720, validation/loss=0.859339, validation/num_examples=50000
I0303 11:07:33.470168 140239850956544 logging_writer.py:48] [176000] global_step=176000, grad_norm=3.1490211486816406, loss=1.2649004459381104
I0303 11:08:15.138593 140239842563840 logging_writer.py:48] [176100] global_step=176100, grad_norm=3.410064220428467, loss=3.0777173042297363
I0303 11:09:00.119602 140239850956544 logging_writer.py:48] [176200] global_step=176200, grad_norm=3.350562334060669, loss=1.2334402799606323
I0303 11:09:45.466491 140239842563840 logging_writer.py:48] [176300] global_step=176300, grad_norm=3.5485236644744873, loss=3.2628464698791504
I0303 11:10:30.930739 140239850956544 logging_writer.py:48] [176400] global_step=176400, grad_norm=3.090637683868408, loss=1.2471387386322021
I0303 11:11:16.192286 140239842563840 logging_writer.py:48] [176500] global_step=176500, grad_norm=2.788642406463623, loss=1.7175222635269165
I0303 11:12:01.312140 140239850956544 logging_writer.py:48] [176600] global_step=176600, grad_norm=3.622347593307495, loss=3.0699830055236816
I0303 11:12:46.710950 140239842563840 logging_writer.py:48] [176700] global_step=176700, grad_norm=3.109065055847168, loss=1.0864256620407104
I0303 11:13:31.878051 140239850956544 logging_writer.py:48] [176800] global_step=176800, grad_norm=3.163234233856201, loss=2.6955513954162598
I0303 11:14:17.214212 140239842563840 logging_writer.py:48] [176900] global_step=176900, grad_norm=2.7485408782958984, loss=1.0550373792648315
I0303 11:14:27.704753 140437341357888 spec.py:321] Evaluating on the training split.
I0303 11:14:37.852258 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 11:15:05.044427 140437341357888 spec.py:349] Evaluating on the test split.
I0303 11:15:06.716247 140437341357888 submission_runner.py:411] Time since start: 85348.27s, 	Step: 176925, 	{'train/accuracy': 0.8836327791213989, 'train/loss': 0.42841508984565735, 'validation/accuracy': 0.7784199714660645, 'validation/loss': 0.8580959439277649, 'validation/num_examples': 50000, 'test/accuracy': 0.659000039100647, 'test/loss': 1.450667142868042, 'test/num_examples': 10000, 'score': 79028.45848870277, 'total_duration': 85348.26768136024, 'accumulated_submission_time': 79028.45848870277, 'accumulated_eval_time': 6299.135026216507, 'accumulated_logging_time': 10.9592125415802}
I0303 11:15:06.788975 140239850956544 logging_writer.py:48] [176925] accumulated_eval_time=6299.135026, accumulated_logging_time=10.959213, accumulated_submission_time=79028.458489, global_step=176925, preemption_count=0, score=79028.458489, test/accuracy=0.659000, test/loss=1.450667, test/num_examples=10000, total_duration=85348.267681, train/accuracy=0.883633, train/loss=0.428415, validation/accuracy=0.778420, validation/loss=0.858096, validation/num_examples=50000
I0303 11:15:36.900655 140239842563840 logging_writer.py:48] [177000] global_step=177000, grad_norm=3.362717390060425, loss=1.264074683189392
I0303 11:16:20.521193 140239850956544 logging_writer.py:48] [177100] global_step=177100, grad_norm=3.0604867935180664, loss=1.0992158651351929
I0303 11:17:06.082108 140239842563840 logging_writer.py:48] [177200] global_step=177200, grad_norm=3.3415768146514893, loss=3.0218303203582764
I0303 11:17:51.112933 140239850956544 logging_writer.py:48] [177300] global_step=177300, grad_norm=2.844752073287964, loss=1.4716161489486694
I0303 11:18:36.383135 140239842563840 logging_writer.py:48] [177400] global_step=177400, grad_norm=2.8569159507751465, loss=1.2066506147384644
I0303 11:19:21.766078 140239850956544 logging_writer.py:48] [177500] global_step=177500, grad_norm=3.041332483291626, loss=1.0837762355804443
I0303 11:20:06.782547 140239842563840 logging_writer.py:48] [177600] global_step=177600, grad_norm=2.9692039489746094, loss=1.2330238819122314
I0303 11:20:51.959826 140239850956544 logging_writer.py:48] [177700] global_step=177700, grad_norm=2.793179750442505, loss=1.3324259519577026
I0303 11:21:37.079161 140239842563840 logging_writer.py:48] [177800] global_step=177800, grad_norm=3.6791458129882812, loss=3.244904041290283
I0303 11:22:06.825166 140437341357888 spec.py:321] Evaluating on the training split.
I0303 11:22:17.122052 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 11:22:40.655967 140437341357888 spec.py:349] Evaluating on the test split.
I0303 11:22:42.282941 140437341357888 submission_runner.py:411] Time since start: 85803.83s, 	Step: 177867, 	{'train/accuracy': 0.8875390291213989, 'train/loss': 0.42650339007377625, 'validation/accuracy': 0.7801399827003479, 'validation/loss': 0.8563417792320251, 'validation/num_examples': 50000, 'test/accuracy': 0.6620000600814819, 'test/loss': 1.443135380744934, 'test/num_examples': 10000, 'score': 79448.42927765846, 'total_duration': 85803.83441829681, 'accumulated_submission_time': 79448.42927765846, 'accumulated_eval_time': 6334.59276509285, 'accumulated_logging_time': 11.045661687850952}
I0303 11:22:42.332688 140239850956544 logging_writer.py:48] [177867] accumulated_eval_time=6334.592765, accumulated_logging_time=11.045662, accumulated_submission_time=79448.429278, global_step=177867, preemption_count=0, score=79448.429278, test/accuracy=0.662000, test/loss=1.443135, test/num_examples=10000, total_duration=85803.834418, train/accuracy=0.887539, train/loss=0.426503, validation/accuracy=0.780140, validation/loss=0.856342, validation/num_examples=50000
I0303 11:22:56.110136 140239842563840 logging_writer.py:48] [177900] global_step=177900, grad_norm=3.541189193725586, loss=3.0460762977600098
I0303 11:23:38.732687 140239850956544 logging_writer.py:48] [178000] global_step=178000, grad_norm=3.1621248722076416, loss=2.8076257705688477
I0303 11:24:23.912222 140239842563840 logging_writer.py:48] [178100] global_step=178100, grad_norm=2.967285633087158, loss=1.9009114503860474
I0303 11:25:09.211644 140239850956544 logging_writer.py:48] [178200] global_step=178200, grad_norm=3.1413986682891846, loss=1.088582158088684
I0303 11:25:54.343256 140239842563840 logging_writer.py:48] [178300] global_step=178300, grad_norm=3.064598798751831, loss=1.2244365215301514
I0303 11:26:39.720443 140239850956544 logging_writer.py:48] [178400] global_step=178400, grad_norm=3.1094160079956055, loss=2.4203593730926514
I0303 11:27:25.091834 140239842563840 logging_writer.py:48] [178500] global_step=178500, grad_norm=3.080897092819214, loss=1.2141183614730835
I0303 11:28:10.238600 140239850956544 logging_writer.py:48] [178600] global_step=178600, grad_norm=3.5007712841033936, loss=3.0387539863586426
I0303 11:28:54.811487 140239842563840 logging_writer.py:48] [178700] global_step=178700, grad_norm=2.9679012298583984, loss=1.3786033391952515
I0303 11:29:40.221088 140239850956544 logging_writer.py:48] [178800] global_step=178800, grad_norm=2.869001626968384, loss=1.1541523933410645
I0303 11:29:42.565270 140437341357888 spec.py:321] Evaluating on the training split.
I0303 11:29:52.902168 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 11:30:22.703577 140437341357888 spec.py:349] Evaluating on the test split.
I0303 11:30:24.320276 140437341357888 submission_runner.py:411] Time since start: 86265.87s, 	Step: 178807, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.41582217812538147, 'validation/accuracy': 0.7795199751853943, 'validation/loss': 0.8523306250572205, 'validation/num_examples': 50000, 'test/accuracy': 0.6636000275611877, 'test/loss': 1.4399917125701904, 'test/num_examples': 10000, 'score': 79868.60091280937, 'total_duration': 86265.87176012993, 'accumulated_submission_time': 79868.60091280937, 'accumulated_eval_time': 6376.347739696503, 'accumulated_logging_time': 11.105734825134277}
I0303 11:30:24.370665 140239842563840 logging_writer.py:48] [178807] accumulated_eval_time=6376.347740, accumulated_logging_time=11.105735, accumulated_submission_time=79868.600913, global_step=178807, preemption_count=0, score=79868.600913, test/accuracy=0.663600, test/loss=1.439992, test/num_examples=10000, total_duration=86265.871760, train/accuracy=0.887500, train/loss=0.415822, validation/accuracy=0.779520, validation/loss=0.852331, validation/num_examples=50000
I0303 11:31:02.179933 140239850956544 logging_writer.py:48] [178900] global_step=178900, grad_norm=3.12333083152771, loss=2.8122775554656982
I0303 11:31:47.083380 140239842563840 logging_writer.py:48] [179000] global_step=179000, grad_norm=2.9575936794281006, loss=1.3084301948547363
I0303 11:32:32.513693 140239850956544 logging_writer.py:48] [179100] global_step=179100, grad_norm=3.1626553535461426, loss=2.720709800720215
I0303 11:33:17.789545 140239842563840 logging_writer.py:48] [179200] global_step=179200, grad_norm=3.3755946159362793, loss=2.897165536880493
I0303 11:34:02.998840 140239850956544 logging_writer.py:48] [179300] global_step=179300, grad_norm=3.65252423286438, loss=1.1055222749710083
I0303 11:34:47.958194 140239842563840 logging_writer.py:48] [179400] global_step=179400, grad_norm=2.99768328666687, loss=1.5769028663635254
I0303 11:35:33.175796 140239850956544 logging_writer.py:48] [179500] global_step=179500, grad_norm=3.0443382263183594, loss=1.3336155414581299
I0303 11:36:18.500035 140239842563840 logging_writer.py:48] [179600] global_step=179600, grad_norm=3.004952907562256, loss=1.3487505912780762
I0303 11:37:03.688308 140239850956544 logging_writer.py:48] [179700] global_step=179700, grad_norm=3.001415729522705, loss=1.0892910957336426
I0303 11:37:24.325220 140437341357888 spec.py:321] Evaluating on the training split.
I0303 11:37:34.452165 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 11:38:00.324804 140437341357888 spec.py:349] Evaluating on the test split.
I0303 11:38:01.946346 140437341357888 submission_runner.py:411] Time since start: 86723.50s, 	Step: 179747, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.41893255710601807, 'validation/accuracy': 0.7800399661064148, 'validation/loss': 0.8535423874855042, 'validation/num_examples': 50000, 'test/accuracy': 0.6633000373840332, 'test/loss': 1.4441020488739014, 'test/num_examples': 10000, 'score': 80288.49507188797, 'total_duration': 86723.49782943726, 'accumulated_submission_time': 80288.49507188797, 'accumulated_eval_time': 6413.968862771988, 'accumulated_logging_time': 11.165611028671265}
I0303 11:38:01.999577 140239842563840 logging_writer.py:48] [179747] accumulated_eval_time=6413.968863, accumulated_logging_time=11.165611, accumulated_submission_time=80288.495072, global_step=179747, preemption_count=0, score=80288.495072, test/accuracy=0.663300, test/loss=1.444102, test/num_examples=10000, total_duration=86723.497829, train/accuracy=0.886738, train/loss=0.418933, validation/accuracy=0.780040, validation/loss=0.853542, validation/num_examples=50000
I0303 11:38:23.467150 140239850956544 logging_writer.py:48] [179800] global_step=179800, grad_norm=3.188765287399292, loss=1.127454400062561
I0303 11:39:07.562507 140239842563840 logging_writer.py:48] [179900] global_step=179900, grad_norm=2.958641767501831, loss=2.0700042247772217
I0303 11:39:52.469631 140239850956544 logging_writer.py:48] [180000] global_step=180000, grad_norm=3.0392019748687744, loss=1.1480079889297485
I0303 11:40:37.857153 140239842563840 logging_writer.py:48] [180100] global_step=180100, grad_norm=3.2272229194641113, loss=1.15548837184906
I0303 11:41:23.457278 140239850956544 logging_writer.py:48] [180200] global_step=180200, grad_norm=2.881382942199707, loss=1.1038357019424438
I0303 11:42:09.138527 140239842563840 logging_writer.py:48] [180300] global_step=180300, grad_norm=3.6876044273376465, loss=3.192385673522949
I0303 11:42:54.241690 140239850956544 logging_writer.py:48] [180400] global_step=180400, grad_norm=2.9495108127593994, loss=2.6068294048309326
I0303 11:43:39.533442 140239842563840 logging_writer.py:48] [180500] global_step=180500, grad_norm=3.6913082599639893, loss=3.098755121231079
I0303 11:44:25.004499 140239850956544 logging_writer.py:48] [180600] global_step=180600, grad_norm=3.2536423206329346, loss=1.1877806186676025
I0303 11:45:01.963899 140437341357888 spec.py:321] Evaluating on the training split.
I0303 11:45:12.278331 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 11:45:35.002092 140437341357888 spec.py:349] Evaluating on the test split.
I0303 11:45:36.621781 140437341357888 submission_runner.py:411] Time since start: 87178.17s, 	Step: 180683, 	{'train/accuracy': 0.8873242139816284, 'train/loss': 0.4149569869041443, 'validation/accuracy': 0.7804799675941467, 'validation/loss': 0.8523868322372437, 'validation/num_examples': 50000, 'test/accuracy': 0.6643000245094299, 'test/loss': 1.442840576171875, 'test/num_examples': 10000, 'score': 80708.39556407928, 'total_duration': 87178.17326307297, 'accumulated_submission_time': 80708.39556407928, 'accumulated_eval_time': 6448.626727581024, 'accumulated_logging_time': 11.231953859329224}
I0303 11:45:36.675867 140239842563840 logging_writer.py:48] [180683] accumulated_eval_time=6448.626728, accumulated_logging_time=11.231954, accumulated_submission_time=80708.395564, global_step=180683, preemption_count=0, score=80708.395564, test/accuracy=0.664300, test/loss=1.442841, test/num_examples=10000, total_duration=87178.173263, train/accuracy=0.887324, train/loss=0.414957, validation/accuracy=0.780480, validation/loss=0.852387, validation/num_examples=50000
I0303 11:45:43.808240 140239850956544 logging_writer.py:48] [180700] global_step=180700, grad_norm=3.0375730991363525, loss=1.1999733448028564
I0303 11:46:26.256577 140239842563840 logging_writer.py:48] [180800] global_step=180800, grad_norm=3.40864896774292, loss=2.8162407875061035
I0303 11:47:11.624095 140239850956544 logging_writer.py:48] [180900] global_step=180900, grad_norm=3.0732309818267822, loss=1.0661665201187134
I0303 11:47:57.029208 140239842563840 logging_writer.py:48] [181000] global_step=181000, grad_norm=3.0587058067321777, loss=1.2086045742034912
I0303 11:48:42.351255 140239850956544 logging_writer.py:48] [181100] global_step=181100, grad_norm=3.091038227081299, loss=1.2656519412994385
I0303 11:49:27.580425 140239842563840 logging_writer.py:48] [181200] global_step=181200, grad_norm=2.8275139331817627, loss=1.546895146369934
I0303 11:50:12.701777 140239850956544 logging_writer.py:48] [181300] global_step=181300, grad_norm=3.0234427452087402, loss=1.9608778953552246
I0303 11:50:58.041174 140239842563840 logging_writer.py:48] [181400] global_step=181400, grad_norm=2.778049945831299, loss=1.0980228185653687
I0303 11:51:43.322353 140239850956544 logging_writer.py:48] [181500] global_step=181500, grad_norm=3.1452419757843018, loss=1.236739993095398
I0303 11:52:28.503575 140239842563840 logging_writer.py:48] [181600] global_step=181600, grad_norm=3.0653276443481445, loss=1.5634361505508423
I0303 11:52:36.710331 140437341357888 spec.py:321] Evaluating on the training split.
I0303 11:52:46.998497 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 11:53:15.888547 140437341357888 spec.py:349] Evaluating on the test split.
I0303 11:53:17.510687 140437341357888 submission_runner.py:411] Time since start: 87639.06s, 	Step: 181620, 	{'train/accuracy': 0.8868749737739563, 'train/loss': 0.4176073670387268, 'validation/accuracy': 0.780239999294281, 'validation/loss': 0.8525054454803467, 'validation/num_examples': 50000, 'test/accuracy': 0.6632000207901001, 'test/loss': 1.4451278448104858, 'test/num_examples': 10000, 'score': 81128.36767435074, 'total_duration': 87639.06216335297, 'accumulated_submission_time': 81128.36767435074, 'accumulated_eval_time': 6489.427065849304, 'accumulated_logging_time': 11.297489881515503}
I0303 11:53:17.560848 140239850956544 logging_writer.py:48] [181620] accumulated_eval_time=6489.427066, accumulated_logging_time=11.297490, accumulated_submission_time=81128.367674, global_step=181620, preemption_count=0, score=81128.367674, test/accuracy=0.663200, test/loss=1.445128, test/num_examples=10000, total_duration=87639.062163, train/accuracy=0.886875, train/loss=0.417607, validation/accuracy=0.780240, validation/loss=0.852505, validation/num_examples=50000
I0303 11:53:49.808950 140239842563840 logging_writer.py:48] [181700] global_step=181700, grad_norm=3.4901480674743652, loss=1.1585942506790161
I0303 11:54:34.837858 140239850956544 logging_writer.py:48] [181800] global_step=181800, grad_norm=3.3034608364105225, loss=3.0565829277038574
I0303 11:55:20.132694 140239842563840 logging_writer.py:48] [181900] global_step=181900, grad_norm=3.146094799041748, loss=1.7811720371246338
I0303 11:56:05.352636 140239850956544 logging_writer.py:48] [182000] global_step=182000, grad_norm=3.265625476837158, loss=2.3456101417541504
I0303 11:56:50.695248 140239842563840 logging_writer.py:48] [182100] global_step=182100, grad_norm=3.0534191131591797, loss=1.1901006698608398
I0303 11:57:35.749419 140239850956544 logging_writer.py:48] [182200] global_step=182200, grad_norm=3.965254306793213, loss=3.290727138519287
I0303 11:58:21.113169 140239842563840 logging_writer.py:48] [182300] global_step=182300, grad_norm=2.938957691192627, loss=1.281917691230774
I0303 11:59:06.189363 140239850956544 logging_writer.py:48] [182400] global_step=182400, grad_norm=2.957638740539551, loss=1.0861079692840576
I0303 11:59:50.856295 140239842563840 logging_writer.py:48] [182500] global_step=182500, grad_norm=3.14330792427063, loss=2.62689208984375
I0303 12:00:17.598222 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:00:27.783102 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:01:01.491126 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:01:03.111377 140437341357888 submission_runner.py:411] Time since start: 88104.66s, 	Step: 182561, 	{'train/accuracy': 0.8882421851158142, 'train/loss': 0.4123246967792511, 'validation/accuracy': 0.7803599834442139, 'validation/loss': 0.8496127724647522, 'validation/num_examples': 50000, 'test/accuracy': 0.6635000109672546, 'test/loss': 1.4420886039733887, 'test/num_examples': 10000, 'score': 81548.34212756157, 'total_duration': 88104.66285085678, 'accumulated_submission_time': 81548.34212756157, 'accumulated_eval_time': 6534.940185070038, 'accumulated_logging_time': 11.358872413635254}
I0303 12:01:03.159862 140239850956544 logging_writer.py:48] [182561] accumulated_eval_time=6534.940185, accumulated_logging_time=11.358872, accumulated_submission_time=81548.342128, global_step=182561, preemption_count=0, score=81548.342128, test/accuracy=0.663500, test/loss=1.442089, test/num_examples=10000, total_duration=88104.662851, train/accuracy=0.888242, train/loss=0.412325, validation/accuracy=0.780360, validation/loss=0.849613, validation/num_examples=50000
I0303 12:01:18.993962 140239842563840 logging_writer.py:48] [182600] global_step=182600, grad_norm=3.1115477085113525, loss=2.3207974433898926
I0303 12:02:00.755844 140239850956544 logging_writer.py:48] [182700] global_step=182700, grad_norm=2.9059255123138428, loss=1.3333724737167358
I0303 12:02:45.925116 140239842563840 logging_writer.py:48] [182800] global_step=182800, grad_norm=3.1905999183654785, loss=2.7413036823272705
I0303 12:03:30.851111 140239850956544 logging_writer.py:48] [182900] global_step=182900, grad_norm=3.5294721126556396, loss=3.065091848373413
I0303 12:04:16.134316 140239842563840 logging_writer.py:48] [183000] global_step=183000, grad_norm=2.886955738067627, loss=1.3101537227630615
I0303 12:05:01.220865 140239850956544 logging_writer.py:48] [183100] global_step=183100, grad_norm=3.025033950805664, loss=1.1121844053268433
I0303 12:05:46.573903 140239842563840 logging_writer.py:48] [183200] global_step=183200, grad_norm=3.1616647243499756, loss=1.032226800918579
I0303 12:06:31.640697 140239850956544 logging_writer.py:48] [183300] global_step=183300, grad_norm=3.1810429096221924, loss=1.2318205833435059
I0303 12:07:16.985884 140239842563840 logging_writer.py:48] [183400] global_step=183400, grad_norm=3.0180258750915527, loss=2.131986618041992
I0303 12:08:01.951776 140239850956544 logging_writer.py:48] [183500] global_step=183500, grad_norm=2.893697500228882, loss=2.353203535079956
I0303 12:08:03.509685 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:08:13.741514 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:08:35.720773 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:08:37.341362 140437341357888 submission_runner.py:411] Time since start: 88558.89s, 	Step: 183505, 	{'train/accuracy': 0.8894140720367432, 'train/loss': 0.41239500045776367, 'validation/accuracy': 0.780460000038147, 'validation/loss': 0.8484692573547363, 'validation/num_examples': 50000, 'test/accuracy': 0.6627000570297241, 'test/loss': 1.4406883716583252, 'test/num_examples': 10000, 'score': 81968.63080692291, 'total_duration': 88558.89284658432, 'accumulated_submission_time': 81968.63080692291, 'accumulated_eval_time': 6568.771864891052, 'accumulated_logging_time': 11.416648387908936}
I0303 12:08:37.398270 140239842563840 logging_writer.py:48] [183505] accumulated_eval_time=6568.771865, accumulated_logging_time=11.416648, accumulated_submission_time=81968.630807, global_step=183505, preemption_count=0, score=81968.630807, test/accuracy=0.662700, test/loss=1.440688, test/num_examples=10000, total_duration=88558.892847, train/accuracy=0.889414, train/loss=0.412395, validation/accuracy=0.780460, validation/loss=0.848469, validation/num_examples=50000
I0303 12:09:16.889784 140239850956544 logging_writer.py:48] [183600] global_step=183600, grad_norm=2.944242238998413, loss=2.2898433208465576
I0303 12:10:01.574437 140239842563840 logging_writer.py:48] [183700] global_step=183700, grad_norm=2.9352023601531982, loss=1.043953776359558
I0303 12:10:46.923681 140239850956544 logging_writer.py:48] [183800] global_step=183800, grad_norm=3.121248722076416, loss=1.2265113592147827
I0303 12:11:32.586443 140239842563840 logging_writer.py:48] [183900] global_step=183900, grad_norm=3.1547255516052246, loss=1.1129170656204224
I0303 12:12:17.850573 140239850956544 logging_writer.py:48] [184000] global_step=184000, grad_norm=3.1158249378204346, loss=1.1596876382827759
I0303 12:13:03.149723 140239842563840 logging_writer.py:48] [184100] global_step=184100, grad_norm=3.036907911300659, loss=1.0556918382644653
I0303 12:13:48.306041 140239850956544 logging_writer.py:48] [184200] global_step=184200, grad_norm=3.013152599334717, loss=1.7762891054153442
I0303 12:14:33.364975 140239842563840 logging_writer.py:48] [184300] global_step=184300, grad_norm=3.3211143016815186, loss=1.1141984462738037
I0303 12:15:18.785252 140239850956544 logging_writer.py:48] [184400] global_step=184400, grad_norm=3.234116792678833, loss=2.7416441440582275
I0303 12:15:37.763181 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:15:48.380252 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:16:14.776719 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:16:16.401578 140437341357888 submission_runner.py:411] Time since start: 89017.95s, 	Step: 184444, 	{'train/accuracy': 0.8900390267372131, 'train/loss': 0.41502460837364197, 'validation/accuracy': 0.7807599902153015, 'validation/loss': 0.8500364422798157, 'validation/num_examples': 50000, 'test/accuracy': 0.6625000238418579, 'test/loss': 1.4413601160049438, 'test/num_examples': 10000, 'score': 82388.93534779549, 'total_duration': 89017.95306396484, 'accumulated_submission_time': 82388.93534779549, 'accumulated_eval_time': 6607.41025018692, 'accumulated_logging_time': 11.48314118385315}
I0303 12:16:16.456977 140239842563840 logging_writer.py:48] [184444] accumulated_eval_time=6607.410250, accumulated_logging_time=11.483141, accumulated_submission_time=82388.935348, global_step=184444, preemption_count=0, score=82388.935348, test/accuracy=0.662500, test/loss=1.441360, test/num_examples=10000, total_duration=89017.953064, train/accuracy=0.890039, train/loss=0.415025, validation/accuracy=0.780760, validation/loss=0.850036, validation/num_examples=50000
I0303 12:16:39.062556 140239850956544 logging_writer.py:48] [184500] global_step=184500, grad_norm=2.9618799686431885, loss=1.5245593786239624
I0303 12:17:23.451968 140239842563840 logging_writer.py:48] [184600] global_step=184600, grad_norm=5.735847473144531, loss=1.6666252613067627
I0303 12:18:08.878693 140239850956544 logging_writer.py:48] [184700] global_step=184700, grad_norm=2.9867336750030518, loss=0.9791646599769592
I0303 12:18:53.888731 140239842563840 logging_writer.py:48] [184800] global_step=184800, grad_norm=2.8656582832336426, loss=1.1107256412506104
I0303 12:19:39.125699 140239850956544 logging_writer.py:48] [184900] global_step=184900, grad_norm=3.596949815750122, loss=1.098223328590393
I0303 12:20:24.140830 140239842563840 logging_writer.py:48] [185000] global_step=185000, grad_norm=3.099160671234131, loss=1.197324275970459
I0303 12:21:09.353625 140239850956544 logging_writer.py:48] [185100] global_step=185100, grad_norm=3.0439112186431885, loss=1.2127995491027832
I0303 12:21:54.447854 140239842563840 logging_writer.py:48] [185200] global_step=185200, grad_norm=3.2201602458953857, loss=1.3667256832122803
I0303 12:22:39.576206 140239850956544 logging_writer.py:48] [185300] global_step=185300, grad_norm=2.963531494140625, loss=1.5422816276550293
I0303 12:23:16.631235 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:23:26.771675 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:24:01.046948 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:24:02.669756 140437341357888 submission_runner.py:411] Time since start: 89484.22s, 	Step: 185384, 	{'train/accuracy': 0.8905664086341858, 'train/loss': 0.4088824987411499, 'validation/accuracy': 0.7807799577713013, 'validation/loss': 0.8490588068962097, 'validation/num_examples': 50000, 'test/accuracy': 0.6627000570297241, 'test/loss': 1.4396294355392456, 'test/num_examples': 10000, 'score': 82809.04411435127, 'total_duration': 89484.22124147415, 'accumulated_submission_time': 82809.04411435127, 'accumulated_eval_time': 6653.4487590789795, 'accumulated_logging_time': 11.552966833114624}
I0303 12:24:02.724217 140239842563840 logging_writer.py:48] [185384] accumulated_eval_time=6653.448759, accumulated_logging_time=11.552967, accumulated_submission_time=82809.044114, global_step=185384, preemption_count=0, score=82809.044114, test/accuracy=0.662700, test/loss=1.439629, test/num_examples=10000, total_duration=89484.221241, train/accuracy=0.890566, train/loss=0.408882, validation/accuracy=0.780780, validation/loss=0.849059, validation/num_examples=50000
I0303 12:24:09.471657 140239850956544 logging_writer.py:48] [185400] global_step=185400, grad_norm=2.992575168609619, loss=1.142275094985962
I0303 12:24:49.911431 140239842563840 logging_writer.py:48] [185500] global_step=185500, grad_norm=3.051391124725342, loss=2.8777925968170166
I0303 12:25:35.148104 140239850956544 logging_writer.py:48] [185600] global_step=185600, grad_norm=2.9689133167266846, loss=1.281911849975586
I0303 12:26:20.278203 140239842563840 logging_writer.py:48] [185700] global_step=185700, grad_norm=2.889883518218994, loss=1.1976646184921265
I0303 12:27:05.358897 140239850956544 logging_writer.py:48] [185800] global_step=185800, grad_norm=2.940035820007324, loss=1.1476032733917236
I0303 12:27:50.354930 140239842563840 logging_writer.py:48] [185900] global_step=185900, grad_norm=3.3397531509399414, loss=1.6139827966690063
I0303 12:28:35.426591 140239850956544 logging_writer.py:48] [186000] global_step=186000, grad_norm=3.422074556350708, loss=1.0669838190078735
I0303 12:29:20.434053 140239842563840 logging_writer.py:48] [186100] global_step=186100, grad_norm=2.8789327144622803, loss=1.934091329574585
I0303 12:30:05.473252 140239850956544 logging_writer.py:48] [186200] global_step=186200, grad_norm=3.048922300338745, loss=1.0667425394058228
I0303 12:30:50.338535 140239842563840 logging_writer.py:48] [186300] global_step=186300, grad_norm=3.150714159011841, loss=2.035714864730835
I0303 12:31:02.672550 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:31:12.959719 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:31:40.086169 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:31:41.705776 140437341357888 submission_runner.py:411] Time since start: 89943.26s, 	Step: 186329, 	{'train/accuracy': 0.8901953101158142, 'train/loss': 0.414861798286438, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491452932357788, 'validation/num_examples': 50000, 'test/accuracy': 0.6629000306129456, 'test/loss': 1.4399614334106445, 'test/num_examples': 10000, 'score': 83228.92775535583, 'total_duration': 89943.25726413727, 'accumulated_submission_time': 83228.92775535583, 'accumulated_eval_time': 6692.481970310211, 'accumulated_logging_time': 11.621200561523438}
I0303 12:31:41.763410 140239850956544 logging_writer.py:48] [186329] accumulated_eval_time=6692.481970, accumulated_logging_time=11.621201, accumulated_submission_time=83228.927755, global_step=186329, preemption_count=0, score=83228.927755, test/accuracy=0.662900, test/loss=1.439961, test/num_examples=10000, total_duration=89943.257264, train/accuracy=0.890195, train/loss=0.414862, validation/accuracy=0.780660, validation/loss=0.849145, validation/num_examples=50000
I0303 12:32:10.305108 140239842563840 logging_writer.py:48] [186400] global_step=186400, grad_norm=3.360173225402832, loss=2.922525405883789
I0303 12:32:54.589355 140239850956544 logging_writer.py:48] [186500] global_step=186500, grad_norm=2.849311590194702, loss=1.302146315574646
I0303 12:33:40.126876 140239842563840 logging_writer.py:48] [186600] global_step=186600, grad_norm=2.8915181159973145, loss=1.0850154161453247
I0303 12:34:25.454085 140239850956544 logging_writer.py:48] [186700] global_step=186700, grad_norm=3.0992488861083984, loss=1.1892255544662476
I0303 12:35:10.689630 140239842563840 logging_writer.py:48] [186800] global_step=186800, grad_norm=2.842693328857422, loss=2.4989867210388184
I0303 12:35:55.790364 140239850956544 logging_writer.py:48] [186900] global_step=186900, grad_norm=2.991931200027466, loss=1.5244908332824707
I0303 12:36:41.073635 140239842563840 logging_writer.py:48] [187000] global_step=187000, grad_norm=2.9749481678009033, loss=1.1513710021972656
I0303 12:37:26.230202 140239850956544 logging_writer.py:48] [187100] global_step=187100, grad_norm=3.1677842140197754, loss=1.0621124505996704
I0303 12:38:11.316756 140239842563840 logging_writer.py:48] [187200] global_step=187200, grad_norm=2.987170934677124, loss=1.3924813270568848
I0303 12:38:42.091596 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:38:52.578881 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:39:19.933422 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:39:21.557612 140437341357888 submission_runner.py:411] Time since start: 90403.11s, 	Step: 187270, 	{'train/accuracy': 0.8873632550239563, 'train/loss': 0.4139579236507416, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 83649.1949005127, 'total_duration': 90403.1090900898, 'accumulated_submission_time': 83649.1949005127, 'accumulated_eval_time': 6731.947980880737, 'accumulated_logging_time': 11.689115285873413}
I0303 12:39:21.611253 140239850956544 logging_writer.py:48] [187270] accumulated_eval_time=6731.947981, accumulated_logging_time=11.689115, accumulated_submission_time=83649.194901, global_step=187270, preemption_count=0, score=83649.194901, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=90403.109090, train/accuracy=0.887363, train/loss=0.413958, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 12:39:33.882836 140239842563840 logging_writer.py:48] [187300] global_step=187300, grad_norm=3.5384814739227295, loss=1.135845422744751
I0303 12:40:16.912039 140239850956544 logging_writer.py:48] [187400] global_step=187400, grad_norm=3.3042023181915283, loss=2.9111061096191406
I0303 12:41:01.666899 140239842563840 logging_writer.py:48] [187500] global_step=187500, grad_norm=4.045469760894775, loss=2.9984965324401855
I0303 12:41:47.124052 140239850956544 logging_writer.py:48] [187600] global_step=187600, grad_norm=2.8199098110198975, loss=1.6071399450302124
I0303 12:42:32.617331 140239842563840 logging_writer.py:48] [187700] global_step=187700, grad_norm=3.687363386154175, loss=3.199069023132324
I0303 12:43:17.874895 140239850956544 logging_writer.py:48] [187800] global_step=187800, grad_norm=3.806324005126953, loss=1.1089473962783813
I0303 12:44:03.360506 140239842563840 logging_writer.py:48] [187900] global_step=187900, grad_norm=2.9163596630096436, loss=2.170286178588867
I0303 12:44:48.406398 140239850956544 logging_writer.py:48] [188000] global_step=188000, grad_norm=3.3197996616363525, loss=1.2849996089935303
I0303 12:45:33.647492 140239842563840 logging_writer.py:48] [188100] global_step=188100, grad_norm=2.9427382946014404, loss=1.1093648672103882
I0303 12:46:18.929070 140239850956544 logging_writer.py:48] [188200] global_step=188200, grad_norm=3.463360548019409, loss=2.716050624847412
I0303 12:46:21.741397 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:46:32.398292 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:46:57.274509 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:46:58.896683 140437341357888 submission_runner.py:411] Time since start: 90860.45s, 	Step: 188208, 	{'train/accuracy': 0.8859374523162842, 'train/loss': 0.4201960265636444, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 84069.26384472847, 'total_duration': 90860.44817233086, 'accumulated_submission_time': 84069.26384472847, 'accumulated_eval_time': 6769.103258132935, 'accumulated_logging_time': 11.752736330032349}
I0303 12:46:58.950534 140239842563840 logging_writer.py:48] [188208] accumulated_eval_time=6769.103258, accumulated_logging_time=11.752736, accumulated_submission_time=84069.263845, global_step=188208, preemption_count=0, score=84069.263845, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=90860.448172, train/accuracy=0.885937, train/loss=0.420196, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 12:47:37.229556 140239850956544 logging_writer.py:48] [188300] global_step=188300, grad_norm=3.1610512733459473, loss=1.004750370979309
I0303 12:48:22.245588 140239842563840 logging_writer.py:48] [188400] global_step=188400, grad_norm=3.0756702423095703, loss=1.0585798025131226
I0303 12:49:07.657390 140239850956544 logging_writer.py:48] [188500] global_step=188500, grad_norm=2.8869078159332275, loss=1.8873111009597778
I0303 12:49:52.681683 140239842563840 logging_writer.py:48] [188600] global_step=188600, grad_norm=3.061466693878174, loss=2.4024758338928223
I0303 12:50:37.993560 140239850956544 logging_writer.py:48] [188700] global_step=188700, grad_norm=4.327185153961182, loss=3.237558364868164
I0303 12:51:23.213469 140239842563840 logging_writer.py:48] [188800] global_step=188800, grad_norm=3.2382030487060547, loss=2.805103063583374
I0303 12:52:08.383498 140239850956544 logging_writer.py:48] [188900] global_step=188900, grad_norm=3.076680898666382, loss=1.3291338682174683
I0303 12:52:54.220711 140239842563840 logging_writer.py:48] [189000] global_step=189000, grad_norm=3.3368752002716064, loss=2.3605074882507324
I0303 12:53:39.657266 140239850956544 logging_writer.py:48] [189100] global_step=189100, grad_norm=3.0541257858276367, loss=1.1388843059539795
I0303 12:53:58.957372 140437341357888 spec.py:321] Evaluating on the training split.
I0303 12:54:09.541576 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 12:54:36.041545 140437341357888 spec.py:349] Evaluating on the test split.
I0303 12:54:37.660024 140437341357888 submission_runner.py:411] Time since start: 91319.21s, 	Step: 189144, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.41200846433639526, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 84489.2108707428, 'total_duration': 91319.21151280403, 'accumulated_submission_time': 84489.2108707428, 'accumulated_eval_time': 6807.8059005737305, 'accumulated_logging_time': 11.816109657287598}
I0303 12:54:37.714534 140239842563840 logging_writer.py:48] [189144] accumulated_eval_time=6807.805901, accumulated_logging_time=11.816110, accumulated_submission_time=84489.210871, global_step=189144, preemption_count=0, score=84489.210871, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=91319.211513, train/accuracy=0.888730, train/loss=0.412008, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 12:55:00.332140 140239850956544 logging_writer.py:48] [189200] global_step=189200, grad_norm=2.9820680618286133, loss=2.529961585998535
I0303 12:55:44.772136 140239842563840 logging_writer.py:48] [189300] global_step=189300, grad_norm=3.0881314277648926, loss=1.1395782232284546
I0303 12:56:30.534014 140239850956544 logging_writer.py:48] [189400] global_step=189400, grad_norm=2.932422399520874, loss=1.058648943901062
I0303 12:57:15.818466 140239842563840 logging_writer.py:48] [189500] global_step=189500, grad_norm=3.046738862991333, loss=1.0743026733398438
I0303 12:58:00.842597 140239850956544 logging_writer.py:48] [189600] global_step=189600, grad_norm=3.2431931495666504, loss=2.2594285011291504
I0303 12:58:46.236965 140239842563840 logging_writer.py:48] [189700] global_step=189700, grad_norm=3.0766870975494385, loss=1.8630950450897217
I0303 12:59:31.571206 140239850956544 logging_writer.py:48] [189800] global_step=189800, grad_norm=3.160865306854248, loss=1.1181082725524902
I0303 13:00:16.905513 140239842563840 logging_writer.py:48] [189900] global_step=189900, grad_norm=3.414415121078491, loss=3.0030460357666016
I0303 13:01:02.155835 140239850956544 logging_writer.py:48] [190000] global_step=190000, grad_norm=2.9140429496765137, loss=1.144839882850647
I0303 13:01:38.139405 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:01:48.287758 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:02:14.531866 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:02:16.153492 140437341357888 submission_runner.py:411] Time since start: 91777.70s, 	Step: 190081, 	{'train/accuracy': 0.8896288871765137, 'train/loss': 0.4153327941894531, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 84909.57313537598, 'total_duration': 91777.70495510101, 'accumulated_submission_time': 84909.57313537598, 'accumulated_eval_time': 6845.819953918457, 'accumulated_logging_time': 11.881962776184082}
I0303 13:02:16.206448 140239842563840 logging_writer.py:48] [190081] accumulated_eval_time=6845.819954, accumulated_logging_time=11.881963, accumulated_submission_time=84909.573135, global_step=190081, preemption_count=0, score=84909.573135, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=91777.704955, train/accuracy=0.889629, train/loss=0.415333, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:02:24.160508 140239850956544 logging_writer.py:48] [190100] global_step=190100, grad_norm=2.9071922302246094, loss=1.285145878791809
I0303 13:03:06.544962 140239842563840 logging_writer.py:48] [190200] global_step=190200, grad_norm=2.9714889526367188, loss=1.0154069662094116
I0303 13:03:51.524137 140239850956544 logging_writer.py:48] [190300] global_step=190300, grad_norm=2.932803153991699, loss=2.4954981803894043
I0303 13:04:36.630308 140239842563840 logging_writer.py:48] [190400] global_step=190400, grad_norm=2.9203925132751465, loss=1.5462943315505981
I0303 13:05:21.705917 140239850956544 logging_writer.py:48] [190500] global_step=190500, grad_norm=3.2734200954437256, loss=2.550020217895508
I0303 13:06:06.937171 140239842563840 logging_writer.py:48] [190600] global_step=190600, grad_norm=3.19061541557312, loss=1.4909571409225464
I0303 13:06:51.950230 140239850956544 logging_writer.py:48] [190700] global_step=190700, grad_norm=2.8366200923919678, loss=1.0611307621002197
I0303 13:07:36.991413 140239842563840 logging_writer.py:48] [190800] global_step=190800, grad_norm=3.055811882019043, loss=1.173988699913025
I0303 13:08:22.055614 140239850956544 logging_writer.py:48] [190900] global_step=190900, grad_norm=3.8720896244049072, loss=3.0594120025634766
I0303 13:09:07.312054 140239842563840 logging_writer.py:48] [191000] global_step=191000, grad_norm=3.1468400955200195, loss=1.169796347618103
I0303 13:09:16.390022 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:09:26.560641 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:10:00.881189 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:10:02.505099 140437341357888 submission_runner.py:411] Time since start: 92244.06s, 	Step: 191022, 	{'train/accuracy': 0.8895507454872131, 'train/loss': 0.41602984070777893, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 85329.69141507149, 'total_duration': 92244.0565958023, 'accumulated_submission_time': 85329.69141507149, 'accumulated_eval_time': 6891.935022592545, 'accumulated_logging_time': 11.949048519134521}
I0303 13:10:02.549594 140239850956544 logging_writer.py:48] [191022] accumulated_eval_time=6891.935023, accumulated_logging_time=11.949049, accumulated_submission_time=85329.691415, global_step=191022, preemption_count=0, score=85329.691415, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=92244.056596, train/accuracy=0.889551, train/loss=0.416030, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:10:33.829148 140239842563840 logging_writer.py:48] [191100] global_step=191100, grad_norm=3.805105686187744, loss=3.2972748279571533
I0303 13:11:17.405371 140239850956544 logging_writer.py:48] [191200] global_step=191200, grad_norm=3.4225196838378906, loss=2.451904296875
I0303 13:12:02.086725 140239842563840 logging_writer.py:48] [191300] global_step=191300, grad_norm=3.133455276489258, loss=1.1372535228729248
I0303 13:12:47.417591 140239850956544 logging_writer.py:48] [191400] global_step=191400, grad_norm=2.9331960678100586, loss=1.058345079421997
I0303 13:13:32.611098 140239842563840 logging_writer.py:48] [191500] global_step=191500, grad_norm=3.6692895889282227, loss=3.2422068119049072
I0303 13:14:17.661621 140239850956544 logging_writer.py:48] [191600] global_step=191600, grad_norm=2.9506194591522217, loss=1.7499825954437256
I0303 13:15:02.544547 140239842563840 logging_writer.py:48] [191700] global_step=191700, grad_norm=3.0809166431427, loss=2.5659730434417725
I0303 13:15:47.861245 140239850956544 logging_writer.py:48] [191800] global_step=191800, grad_norm=3.1156365871429443, loss=2.633169174194336
I0303 13:16:33.140207 140239842563840 logging_writer.py:48] [191900] global_step=191900, grad_norm=3.094974994659424, loss=1.0780010223388672
I0303 13:17:02.651465 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:17:12.892944 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:17:40.312801 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:17:41.933138 140437341357888 submission_runner.py:411] Time since start: 92703.48s, 	Step: 191967, 	{'train/accuracy': 0.8859570026397705, 'train/loss': 0.41946274042129517, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 85749.73276805878, 'total_duration': 92703.48462033272, 'accumulated_submission_time': 85749.73276805878, 'accumulated_eval_time': 6931.216662168503, 'accumulated_logging_time': 12.00302505493164}
I0303 13:17:41.997137 140239850956544 logging_writer.py:48] [191967] accumulated_eval_time=6931.216662, accumulated_logging_time=12.003025, accumulated_submission_time=85749.732768, global_step=191967, preemption_count=0, score=85749.732768, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=92703.484620, train/accuracy=0.885957, train/loss=0.419463, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:17:55.490527 140239842563840 logging_writer.py:48] [192000] global_step=192000, grad_norm=3.0843799114227295, loss=1.1496214866638184
I0303 13:18:38.092966 140239850956544 logging_writer.py:48] [192100] global_step=192100, grad_norm=3.3914735317230225, loss=2.8107998371124268
I0303 13:19:23.221389 140239842563840 logging_writer.py:48] [192200] global_step=192200, grad_norm=2.7629823684692383, loss=1.5180208683013916
I0303 13:20:08.507087 140239850956544 logging_writer.py:48] [192300] global_step=192300, grad_norm=3.0801968574523926, loss=1.0526896715164185
I0303 13:20:53.483890 140239842563840 logging_writer.py:48] [192400] global_step=192400, grad_norm=3.0489985942840576, loss=1.5820523500442505
I0303 13:21:38.638651 140239850956544 logging_writer.py:48] [192500] global_step=192500, grad_norm=3.496854543685913, loss=2.871058225631714
I0303 13:22:23.894582 140239842563840 logging_writer.py:48] [192600] global_step=192600, grad_norm=3.055318593978882, loss=1.1492222547531128
I0303 13:23:09.352247 140239850956544 logging_writer.py:48] [192700] global_step=192700, grad_norm=3.010899543762207, loss=1.1402746438980103
I0303 13:23:54.432236 140239842563840 logging_writer.py:48] [192800] global_step=192800, grad_norm=3.122657537460327, loss=2.4409193992614746
I0303 13:24:39.455780 140239850956544 logging_writer.py:48] [192900] global_step=192900, grad_norm=3.089984178543091, loss=1.175538420677185
I0303 13:24:42.320058 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:24:52.949638 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:25:16.404723 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:25:18.025159 140437341357888 submission_runner.py:411] Time since start: 93159.58s, 	Step: 192908, 	{'train/accuracy': 0.8864843845367432, 'train/loss': 0.41634276509284973, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 86169.99474191666, 'total_duration': 93159.57664656639, 'accumulated_submission_time': 86169.99474191666, 'accumulated_eval_time': 6966.921736240387, 'accumulated_logging_time': 12.076726198196411}
I0303 13:25:18.080109 140239842563840 logging_writer.py:48] [192908] accumulated_eval_time=6966.921736, accumulated_logging_time=12.076726, accumulated_submission_time=86169.994742, global_step=192908, preemption_count=0, score=86169.994742, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=93159.576647, train/accuracy=0.886484, train/loss=0.416343, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:25:56.205497 140239850956544 logging_writer.py:48] [193000] global_step=193000, grad_norm=2.875734567642212, loss=1.1606566905975342
I0303 13:26:41.588779 140239842563840 logging_writer.py:48] [193100] global_step=193100, grad_norm=3.001260280609131, loss=1.7098959684371948
I0303 13:27:26.930561 140239850956544 logging_writer.py:48] [193200] global_step=193200, grad_norm=4.025729656219482, loss=3.29355525970459
I0303 13:28:12.217764 140239842563840 logging_writer.py:48] [193300] global_step=193300, grad_norm=3.9004600048065186, loss=3.149087905883789
I0303 13:28:57.373092 140239850956544 logging_writer.py:48] [193400] global_step=193400, grad_norm=3.7584400177001953, loss=3.204418182373047
I0303 13:29:42.396112 140239842563840 logging_writer.py:48] [193500] global_step=193500, grad_norm=3.2754392623901367, loss=2.0556578636169434
I0303 13:30:27.715679 140239850956544 logging_writer.py:48] [193600] global_step=193600, grad_norm=3.1110663414001465, loss=2.56406569480896
I0303 13:31:12.945259 140239842563840 logging_writer.py:48] [193700] global_step=193700, grad_norm=3.381635904312134, loss=1.15321683883667
I0303 13:31:58.252324 140239850956544 logging_writer.py:48] [193800] global_step=193800, grad_norm=3.7389118671417236, loss=3.2670865058898926
I0303 13:32:18.249717 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:32:28.446559 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:32:57.796939 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:32:59.423085 140437341357888 submission_runner.py:411] Time since start: 93620.97s, 	Step: 193846, 	{'train/accuracy': 0.8892577886581421, 'train/loss': 0.41284099221229553, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 86590.10334300995, 'total_duration': 93620.97456073761, 'accumulated_submission_time': 86590.10334300995, 'accumulated_eval_time': 7008.095109939575, 'accumulated_logging_time': 12.14166522026062}
I0303 13:32:59.476848 140239842563840 logging_writer.py:48] [193846] accumulated_eval_time=7008.095110, accumulated_logging_time=12.141665, accumulated_submission_time=86590.103343, global_step=193846, preemption_count=0, score=86590.103343, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=93620.974561, train/accuracy=0.889258, train/loss=0.412841, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:33:21.280479 140239850956544 logging_writer.py:48] [193900] global_step=193900, grad_norm=3.352386713027954, loss=2.6628928184509277
I0303 13:34:05.181369 140239842563840 logging_writer.py:48] [194000] global_step=194000, grad_norm=2.9359333515167236, loss=2.04413104057312
I0303 13:34:50.279859 140239850956544 logging_writer.py:48] [194100] global_step=194100, grad_norm=3.640205144882202, loss=3.196866273880005
I0303 13:35:35.481614 140239842563840 logging_writer.py:48] [194200] global_step=194200, grad_norm=3.2055628299713135, loss=1.1479287147521973
I0303 13:36:20.636443 140239850956544 logging_writer.py:48] [194300] global_step=194300, grad_norm=3.086338758468628, loss=1.0843372344970703
I0303 13:37:06.203398 140239842563840 logging_writer.py:48] [194400] global_step=194400, grad_norm=2.9911134243011475, loss=2.5994467735290527
I0303 13:37:51.246723 140239850956544 logging_writer.py:48] [194500] global_step=194500, grad_norm=3.272700548171997, loss=2.9972095489501953
I0303 13:38:36.562964 140239842563840 logging_writer.py:48] [194600] global_step=194600, grad_norm=3.0834338665008545, loss=1.3247413635253906
I0303 13:39:21.570548 140239850956544 logging_writer.py:48] [194700] global_step=194700, grad_norm=4.02351713180542, loss=2.7534217834472656
I0303 13:39:59.630443 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:40:10.089929 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:40:36.366136 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:40:37.992033 140437341357888 submission_runner.py:411] Time since start: 94079.54s, 	Step: 194786, 	{'train/accuracy': 0.8887109160423279, 'train/loss': 0.4138174057006836, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 87010.18246912956, 'total_duration': 94079.54350543022, 'accumulated_submission_time': 87010.18246912956, 'accumulated_eval_time': 7046.456674575806, 'accumulated_logging_time': 12.20676326751709}
I0303 13:40:38.046597 140239842563840 logging_writer.py:48] [194786] accumulated_eval_time=7046.456675, accumulated_logging_time=12.206763, accumulated_submission_time=87010.182469, global_step=194786, preemption_count=0, score=87010.182469, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=94079.543505, train/accuracy=0.888711, train/loss=0.413817, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:40:44.014468 140239850956544 logging_writer.py:48] [194800] global_step=194800, grad_norm=2.9114675521850586, loss=1.127900242805481
I0303 13:41:25.760607 140239842563840 logging_writer.py:48] [194900] global_step=194900, grad_norm=3.1914868354797363, loss=1.916844129562378
I0303 13:42:10.625436 140239850956544 logging_writer.py:48] [195000] global_step=195000, grad_norm=3.7473268508911133, loss=3.259833812713623
I0303 13:42:55.560953 140239842563840 logging_writer.py:48] [195100] global_step=195100, grad_norm=2.8449673652648926, loss=1.0797663927078247
I0303 13:43:41.105099 140239850956544 logging_writer.py:48] [195200] global_step=195200, grad_norm=3.36569881439209, loss=1.1611852645874023
I0303 13:44:26.317277 140239842563840 logging_writer.py:48] [195300] global_step=195300, grad_norm=3.3311803340911865, loss=2.896005868911743
I0303 13:45:11.535238 140239850956544 logging_writer.py:48] [195400] global_step=195400, grad_norm=3.4478371143341064, loss=1.1889214515686035
I0303 13:45:56.600360 140239842563840 logging_writer.py:48] [195500] global_step=195500, grad_norm=3.8701202869415283, loss=3.220306873321533
I0303 13:46:42.052613 140239850956544 logging_writer.py:48] [195600] global_step=195600, grad_norm=2.97269606590271, loss=2.4341342449188232
I0303 13:47:27.323266 140239842563840 logging_writer.py:48] [195700] global_step=195700, grad_norm=2.988661766052246, loss=2.5568976402282715
I0303 13:47:38.314613 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:47:48.686405 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:48:15.225724 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:48:16.846275 140437341357888 submission_runner.py:411] Time since start: 94538.40s, 	Step: 195726, 	{'train/accuracy': 0.8862695097923279, 'train/loss': 0.42294347286224365, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 87430.38870239258, 'total_duration': 94538.39776062965, 'accumulated_submission_time': 87430.38870239258, 'accumulated_eval_time': 7084.988321781158, 'accumulated_logging_time': 12.271981477737427}
I0303 13:48:16.903187 140239850956544 logging_writer.py:48] [195726] accumulated_eval_time=7084.988322, accumulated_logging_time=12.271981, accumulated_submission_time=87430.388702, global_step=195726, preemption_count=0, score=87430.388702, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=94538.397761, train/accuracy=0.886270, train/loss=0.422943, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:48:46.694882 140239842563840 logging_writer.py:48] [195800] global_step=195800, grad_norm=2.999525785446167, loss=2.0975658893585205
I0303 13:49:31.934991 140239850956544 logging_writer.py:48] [195900] global_step=195900, grad_norm=3.8046603202819824, loss=3.1634159088134766
I0303 13:50:17.273241 140239842563840 logging_writer.py:48] [196000] global_step=196000, grad_norm=2.8152425289154053, loss=1.5875800848007202
I0303 13:51:02.363498 140239850956544 logging_writer.py:48] [196100] global_step=196100, grad_norm=3.207489252090454, loss=1.164891004562378
I0303 13:51:47.507533 140239842563840 logging_writer.py:48] [196200] global_step=196200, grad_norm=4.0131025314331055, loss=3.1864256858825684
I0303 13:52:32.898717 140239850956544 logging_writer.py:48] [196300] global_step=196300, grad_norm=3.137369394302368, loss=1.870333194732666
I0303 13:53:18.182693 140239842563840 logging_writer.py:48] [196400] global_step=196400, grad_norm=3.424028158187866, loss=2.8191208839416504
I0303 13:54:03.863656 140239850956544 logging_writer.py:48] [196500] global_step=196500, grad_norm=3.1183338165283203, loss=1.2431426048278809
I0303 13:54:49.279987 140239842563840 logging_writer.py:48] [196600] global_step=196600, grad_norm=2.908665180206299, loss=1.0673125982284546
I0303 13:55:16.940417 140437341357888 spec.py:321] Evaluating on the training split.
I0303 13:55:27.232122 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 13:55:54.390588 140437341357888 spec.py:349] Evaluating on the test split.
I0303 13:55:56.019247 140437341357888 submission_runner.py:411] Time since start: 94997.57s, 	Step: 196662, 	{'train/accuracy': 0.88929682970047, 'train/loss': 0.4122631251811981, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 87850.36334037781, 'total_duration': 94997.57072806358, 'accumulated_submission_time': 87850.36334037781, 'accumulated_eval_time': 7124.067133426666, 'accumulated_logging_time': 12.340903997421265}
I0303 13:55:56.075364 140239850956544 logging_writer.py:48] [196662] accumulated_eval_time=7124.067133, accumulated_logging_time=12.340904, accumulated_submission_time=87850.363340, global_step=196662, preemption_count=0, score=87850.363340, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=94997.570728, train/accuracy=0.889297, train/loss=0.412263, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 13:56:11.544042 140239842563840 logging_writer.py:48] [196700] global_step=196700, grad_norm=3.2780606746673584, loss=2.695636510848999
I0303 13:56:54.911282 140239850956544 logging_writer.py:48] [196800] global_step=196800, grad_norm=2.5652735233306885, loss=1.4757214784622192
I0303 13:57:40.167326 140239842563840 logging_writer.py:48] [196900] global_step=196900, grad_norm=3.2695116996765137, loss=1.8156206607818604
I0303 13:58:25.328849 140239850956544 logging_writer.py:48] [197000] global_step=197000, grad_norm=3.1401047706604004, loss=1.1373682022094727
I0303 13:59:10.582283 140239842563840 logging_writer.py:48] [197100] global_step=197100, grad_norm=2.8575987815856934, loss=1.427315592765808
I0303 13:59:55.747099 140239850956544 logging_writer.py:48] [197200] global_step=197200, grad_norm=4.1014862060546875, loss=3.1583564281463623
I0303 14:00:40.994318 140239842563840 logging_writer.py:48] [197300] global_step=197300, grad_norm=2.893118381500244, loss=1.1272873878479004
I0303 14:01:26.447767 140239850956544 logging_writer.py:48] [197400] global_step=197400, grad_norm=4.81477689743042, loss=2.688839912414551
I0303 14:02:11.784717 140239842563840 logging_writer.py:48] [197500] global_step=197500, grad_norm=3.141380548477173, loss=1.5412242412567139
I0303 14:02:56.432677 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:03:06.749946 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:03:32.103848 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:03:33.727554 140437341357888 submission_runner.py:411] Time since start: 95455.28s, 	Step: 197600, 	{'train/accuracy': 0.8868359327316284, 'train/loss': 0.4162808060646057, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 88270.65979909897, 'total_duration': 95455.27904057503, 'accumulated_submission_time': 88270.65979909897, 'accumulated_eval_time': 7161.361990451813, 'accumulated_logging_time': 12.406561136245728}
I0303 14:03:33.784231 140239850956544 logging_writer.py:48] [197600] accumulated_eval_time=7161.361990, accumulated_logging_time=12.406561, accumulated_submission_time=88270.659799, global_step=197600, preemption_count=0, score=88270.659799, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=95455.279041, train/accuracy=0.886836, train/loss=0.416281, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:03:34.208349 140239842563840 logging_writer.py:48] [197600] global_step=197600, grad_norm=2.9374468326568604, loss=2.3076508045196533
I0303 14:04:15.463155 140239850956544 logging_writer.py:48] [197700] global_step=197700, grad_norm=3.0523226261138916, loss=2.58432936668396
I0303 14:05:00.656758 140239842563840 logging_writer.py:48] [197800] global_step=197800, grad_norm=3.080047369003296, loss=1.155752182006836
I0303 14:05:45.826518 140239850956544 logging_writer.py:48] [197900] global_step=197900, grad_norm=3.2779040336608887, loss=2.489807605743408
I0303 14:06:31.094544 140239842563840 logging_writer.py:48] [198000] global_step=198000, grad_norm=3.224461793899536, loss=1.2638208866119385
I0303 14:07:16.449592 140239850956544 logging_writer.py:48] [198100] global_step=198100, grad_norm=2.7645034790039062, loss=1.0506268739700317
I0303 14:08:01.633865 140239842563840 logging_writer.py:48] [198200] global_step=198200, grad_norm=2.986168622970581, loss=2.266022205352783
I0303 14:08:46.750983 140239850956544 logging_writer.py:48] [198300] global_step=198300, grad_norm=3.2307329177856445, loss=1.2434982061386108
I0303 14:09:32.125618 140239842563840 logging_writer.py:48] [198400] global_step=198400, grad_norm=3.136781930923462, loss=1.8761860132217407
I0303 14:10:17.450755 140239850956544 logging_writer.py:48] [198500] global_step=198500, grad_norm=2.8168365955352783, loss=1.4403845071792603
I0303 14:10:33.825847 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:10:44.024010 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:11:10.218215 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:11:11.883928 140437341357888 submission_runner.py:411] Time since start: 95913.44s, 	Step: 198538, 	{'train/accuracy': 0.8875390291213989, 'train/loss': 0.413641095161438, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 88690.6394803524, 'total_duration': 95913.43540740013, 'accumulated_submission_time': 88690.6394803524, 'accumulated_eval_time': 7199.420048713684, 'accumulated_logging_time': 12.473467350006104}
I0303 14:11:11.950827 140239842563840 logging_writer.py:48] [198538] accumulated_eval_time=7199.420049, accumulated_logging_time=12.473467, accumulated_submission_time=88690.639480, global_step=198538, preemption_count=0, score=88690.639480, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=95913.435407, train/accuracy=0.887539, train/loss=0.413641, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:11:36.909888 140239850956544 logging_writer.py:48] [198600] global_step=198600, grad_norm=2.8920364379882812, loss=1.1039578914642334
I0303 14:12:19.620214 140239842563840 logging_writer.py:48] [198700] global_step=198700, grad_norm=3.1699912548065186, loss=1.2037720680236816
I0303 14:13:04.794001 140239850956544 logging_writer.py:48] [198800] global_step=198800, grad_norm=3.6474311351776123, loss=3.0149388313293457
I0303 14:13:50.054334 140239842563840 logging_writer.py:48] [198900] global_step=198900, grad_norm=3.3429901599884033, loss=2.710897445678711
I0303 14:14:35.482309 140239850956544 logging_writer.py:48] [199000] global_step=199000, grad_norm=3.0105111598968506, loss=1.6635686159133911
I0303 14:15:20.681209 140239842563840 logging_writer.py:48] [199100] global_step=199100, grad_norm=3.2227113246917725, loss=2.1593503952026367
I0303 14:16:05.844407 140239850956544 logging_writer.py:48] [199200] global_step=199200, grad_norm=2.985811233520508, loss=2.1259024143218994
I0303 14:16:51.201597 140239842563840 logging_writer.py:48] [199300] global_step=199300, grad_norm=3.151515007019043, loss=1.6775676012039185
I0303 14:17:36.297736 140239850956544 logging_writer.py:48] [199400] global_step=199400, grad_norm=3.1852786540985107, loss=1.1594046354293823
I0303 14:18:11.913211 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:18:22.213387 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:18:48.529181 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:18:50.150304 140437341357888 submission_runner.py:411] Time since start: 96371.70s, 	Step: 199480, 	{'train/accuracy': 0.8901171684265137, 'train/loss': 0.41577470302581787, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 89110.54193615913, 'total_duration': 96371.70179224014, 'accumulated_submission_time': 89110.54193615913, 'accumulated_eval_time': 7237.6571300029755, 'accumulated_logging_time': 12.549538135528564}
I0303 14:18:50.206314 140239842563840 logging_writer.py:48] [199480] accumulated_eval_time=7237.657130, accumulated_logging_time=12.549538, accumulated_submission_time=89110.541936, global_step=199480, preemption_count=0, score=89110.541936, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=96371.701792, train/accuracy=0.890117, train/loss=0.415775, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:18:58.704182 140239850956544 logging_writer.py:48] [199500] global_step=199500, grad_norm=2.9637012481689453, loss=2.583550214767456
I0303 14:19:42.265576 140239842563840 logging_writer.py:48] [199600] global_step=199600, grad_norm=3.9362826347351074, loss=3.1575653553009033
I0303 14:20:27.539815 140239850956544 logging_writer.py:48] [199700] global_step=199700, grad_norm=2.976872682571411, loss=1.1390526294708252
I0303 14:21:13.032329 140239842563840 logging_writer.py:48] [199800] global_step=199800, grad_norm=3.052661657333374, loss=1.0454951524734497
I0303 14:21:58.166679 140239850956544 logging_writer.py:48] [199900] global_step=199900, grad_norm=3.190528154373169, loss=2.4606552124023438
I0303 14:22:43.250590 140239842563840 logging_writer.py:48] [200000] global_step=200000, grad_norm=2.870059013366699, loss=1.0049432516098022
I0303 14:23:28.731633 140239850956544 logging_writer.py:48] [200100] global_step=200100, grad_norm=3.126984119415283, loss=2.644537925720215
I0303 14:24:14.116038 140239842563840 logging_writer.py:48] [200200] global_step=200200, grad_norm=2.99871826171875, loss=1.4734771251678467
I0303 14:24:58.846318 140239850956544 logging_writer.py:48] [200300] global_step=200300, grad_norm=3.390803337097168, loss=2.8005530834198
I0303 14:25:44.662698 140239842563840 logging_writer.py:48] [200400] global_step=200400, grad_norm=3.1393203735351562, loss=1.7337878942489624
I0303 14:25:50.234595 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:26:00.749379 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:26:26.172121 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:26:27.797805 140437341357888 submission_runner.py:411] Time since start: 96829.35s, 	Step: 200414, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.41785928606987, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 89530.50885987282, 'total_duration': 96829.34929418564, 'accumulated_submission_time': 89530.50885987282, 'accumulated_eval_time': 7275.220329999924, 'accumulated_logging_time': 12.615999937057495}
I0303 14:26:27.859580 140239850956544 logging_writer.py:48] [200414] accumulated_eval_time=7275.220330, accumulated_logging_time=12.616000, accumulated_submission_time=89530.508860, global_step=200414, preemption_count=0, score=89530.508860, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=96829.349294, train/accuracy=0.887500, train/loss=0.417859, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:27:03.610334 140239842563840 logging_writer.py:48] [200500] global_step=200500, grad_norm=3.2659895420074463, loss=2.005061149597168
I0303 14:27:48.939813 140239850956544 logging_writer.py:48] [200600] global_step=200600, grad_norm=3.364232063293457, loss=2.6997790336608887
I0303 14:28:34.685014 140239842563840 logging_writer.py:48] [200700] global_step=200700, grad_norm=3.23791766166687, loss=1.0067920684814453
I0303 14:29:19.862966 140239850956544 logging_writer.py:48] [200800] global_step=200800, grad_norm=3.1499617099761963, loss=1.072450041770935
I0303 14:30:05.247257 140239842563840 logging_writer.py:48] [200900] global_step=200900, grad_norm=3.199845552444458, loss=1.153264045715332
I0303 14:30:50.372845 140239850956544 logging_writer.py:48] [201000] global_step=201000, grad_norm=3.2168688774108887, loss=1.0681337118148804
I0303 14:31:35.666640 140239842563840 logging_writer.py:48] [201100] global_step=201100, grad_norm=3.078139066696167, loss=2.567028284072876
I0303 14:32:20.872524 140239850956544 logging_writer.py:48] [201200] global_step=201200, grad_norm=3.9565117359161377, loss=1.996274471282959
I0303 14:33:06.262265 140239842563840 logging_writer.py:48] [201300] global_step=201300, grad_norm=3.0065038204193115, loss=1.1755261421203613
I0303 14:33:27.828432 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:33:38.053289 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:34:05.397413 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:34:07.045186 140437341357888 submission_runner.py:411] Time since start: 97288.60s, 	Step: 201349, 	{'train/accuracy': 0.8890624642372131, 'train/loss': 0.41497915983200073, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 89950.4132950306, 'total_duration': 97288.59665942192, 'accumulated_submission_time': 89950.4132950306, 'accumulated_eval_time': 7314.43705201149, 'accumulated_logging_time': 12.690476179122925}
I0303 14:34:07.113014 140239850956544 logging_writer.py:48] [201349] accumulated_eval_time=7314.437052, accumulated_logging_time=12.690476, accumulated_submission_time=89950.413295, global_step=201349, preemption_count=0, score=89950.413295, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=97288.596659, train/accuracy=0.889062, train/loss=0.414979, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:34:27.747040 140239842563840 logging_writer.py:48] [201400] global_step=201400, grad_norm=2.953278064727783, loss=2.1805050373077393
I0303 14:35:10.820633 140239850956544 logging_writer.py:48] [201500] global_step=201500, grad_norm=2.8959243297576904, loss=1.8050761222839355
I0303 14:35:55.977905 140239842563840 logging_writer.py:48] [201600] global_step=201600, grad_norm=3.030970811843872, loss=1.1141424179077148
I0303 14:36:41.203519 140239850956544 logging_writer.py:48] [201700] global_step=201700, grad_norm=3.274437665939331, loss=1.1811730861663818
I0303 14:37:26.275835 140239842563840 logging_writer.py:48] [201800] global_step=201800, grad_norm=3.1049857139587402, loss=1.6594266891479492
I0303 14:38:11.530661 140239850956544 logging_writer.py:48] [201900] global_step=201900, grad_norm=2.9429891109466553, loss=1.1819193363189697
I0303 14:38:56.633971 140239842563840 logging_writer.py:48] [202000] global_step=202000, grad_norm=3.1400232315063477, loss=2.4124794006347656
I0303 14:39:41.687663 140239850956544 logging_writer.py:48] [202100] global_step=202100, grad_norm=4.06962776184082, loss=3.312931537628174
I0303 14:40:26.621403 140239842563840 logging_writer.py:48] [202200] global_step=202200, grad_norm=3.3211052417755127, loss=1.133326530456543
I0303 14:41:07.188813 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:41:17.330194 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:41:44.143424 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:41:45.783884 140437341357888 submission_runner.py:411] Time since start: 97747.34s, 	Step: 202291, 	{'train/accuracy': 0.8885741829872131, 'train/loss': 0.4138651192188263, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 90370.42215585709, 'total_duration': 97747.33528828621, 'accumulated_submission_time': 90370.42215585709, 'accumulated_eval_time': 7353.0320365428925, 'accumulated_logging_time': 12.773582935333252}
I0303 14:41:45.852046 140239850956544 logging_writer.py:48] [202291] accumulated_eval_time=7353.032037, accumulated_logging_time=12.773583, accumulated_submission_time=90370.422156, global_step=202291, preemption_count=0, score=90370.422156, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=97747.335288, train/accuracy=0.888574, train/loss=0.413865, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:41:49.813344 140239842563840 logging_writer.py:48] [202300] global_step=202300, grad_norm=3.179421901702881, loss=1.1627599000930786
I0303 14:42:31.105408 140239850956544 logging_writer.py:48] [202400] global_step=202400, grad_norm=3.0467331409454346, loss=1.1393661499023438
I0303 14:43:15.889221 140239842563840 logging_writer.py:48] [202500] global_step=202500, grad_norm=3.198819637298584, loss=2.508232355117798
I0303 14:44:00.798031 140239850956544 logging_writer.py:48] [202600] global_step=202600, grad_norm=2.9103844165802, loss=1.1398916244506836
I0303 14:44:46.417279 140239842563840 logging_writer.py:48] [202700] global_step=202700, grad_norm=3.614332437515259, loss=3.2635395526885986
I0303 14:45:31.394199 140239850956544 logging_writer.py:48] [202800] global_step=202800, grad_norm=3.074284315109253, loss=1.154943823814392
I0303 14:46:16.651876 140239842563840 logging_writer.py:48] [202900] global_step=202900, grad_norm=3.499366283416748, loss=3.0978317260742188
I0303 14:47:02.139642 140239850956544 logging_writer.py:48] [203000] global_step=203000, grad_norm=3.3713808059692383, loss=1.1324717998504639
I0303 14:47:47.167464 140239842563840 logging_writer.py:48] [203100] global_step=203100, grad_norm=3.0401127338409424, loss=1.072534203529358
I0303 14:48:32.272228 140239850956544 logging_writer.py:48] [203200] global_step=203200, grad_norm=3.4899203777313232, loss=3.08852481842041
I0303 14:48:46.121530 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:48:56.586794 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:49:21.873905 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:49:23.500364 140437341357888 submission_runner.py:411] Time since start: 98205.05s, 	Step: 203232, 	{'train/accuracy': 0.8862109184265137, 'train/loss': 0.4218650758266449, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 90790.63092684746, 'total_duration': 98205.05185079575, 'accumulated_submission_time': 90790.63092684746, 'accumulated_eval_time': 7390.410850524902, 'accumulated_logging_time': 12.851639747619629}
I0303 14:49:23.556890 140239842563840 logging_writer.py:48] [203232] accumulated_eval_time=7390.410851, accumulated_logging_time=12.851640, accumulated_submission_time=90790.630927, global_step=203232, preemption_count=0, score=90790.630927, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=98205.051851, train/accuracy=0.886211, train/loss=0.421865, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:49:50.911511 140239850956544 logging_writer.py:48] [203300] global_step=203300, grad_norm=2.9798665046691895, loss=1.052595853805542
I0303 14:50:35.510428 140239842563840 logging_writer.py:48] [203400] global_step=203400, grad_norm=3.207828998565674, loss=1.9314367771148682
I0303 14:51:20.952693 140239850956544 logging_writer.py:48] [203500] global_step=203500, grad_norm=3.0777134895324707, loss=1.2431226968765259
I0303 14:52:06.059196 140239842563840 logging_writer.py:48] [203600] global_step=203600, grad_norm=3.1251559257507324, loss=1.2217211723327637
I0303 14:52:51.336163 140239850956544 logging_writer.py:48] [203700] global_step=203700, grad_norm=3.211559295654297, loss=1.1729531288146973
I0303 14:53:36.700769 140239842563840 logging_writer.py:48] [203800] global_step=203800, grad_norm=3.106550455093384, loss=1.1935498714447021
I0303 14:54:22.117982 140239850956544 logging_writer.py:48] [203900] global_step=203900, grad_norm=2.9967148303985596, loss=1.0537402629852295
I0303 14:55:08.299380 140239842563840 logging_writer.py:48] [204000] global_step=204000, grad_norm=3.0794835090637207, loss=1.0500730276107788
I0303 14:55:54.222743 140239850956544 logging_writer.py:48] [204100] global_step=204100, grad_norm=3.1933767795562744, loss=1.1922998428344727
I0303 14:56:23.538366 140437341357888 spec.py:321] Evaluating on the training split.
I0303 14:56:34.090670 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 14:56:58.535395 140437341357888 spec.py:349] Evaluating on the test split.
I0303 14:57:00.164797 140437341357888 submission_runner.py:411] Time since start: 98661.72s, 	Step: 204166, 	{'train/accuracy': 0.888964831829071, 'train/loss': 0.4084383249282837, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 91210.55031061172, 'total_duration': 98661.71626615524, 'accumulated_submission_time': 91210.55031061172, 'accumulated_eval_time': 7427.037251472473, 'accumulated_logging_time': 12.919341325759888}
I0303 14:57:00.221080 140239842563840 logging_writer.py:48] [204166] accumulated_eval_time=7427.037251, accumulated_logging_time=12.919341, accumulated_submission_time=91210.550311, global_step=204166, preemption_count=0, score=91210.550311, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=98661.716266, train/accuracy=0.888965, train/loss=0.408438, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 14:57:14.120338 140239850956544 logging_writer.py:48] [204200] global_step=204200, grad_norm=3.601722240447998, loss=2.8856821060180664
I0303 14:57:57.403537 140239842563840 logging_writer.py:48] [204300] global_step=204300, grad_norm=3.53715181350708, loss=1.1305795907974243
I0303 14:58:42.548748 140239850956544 logging_writer.py:48] [204400] global_step=204400, grad_norm=3.040604591369629, loss=1.1903817653656006
I0303 14:59:27.667293 140239842563840 logging_writer.py:48] [204500] global_step=204500, grad_norm=3.473740577697754, loss=2.903759002685547
I0303 15:00:13.036830 140239850956544 logging_writer.py:48] [204600] global_step=204600, grad_norm=3.0000710487365723, loss=1.930844783782959
I0303 15:00:57.860694 140239842563840 logging_writer.py:48] [204700] global_step=204700, grad_norm=3.002171516418457, loss=1.1702393293380737
I0303 15:01:43.141726 140239850956544 logging_writer.py:48] [204800] global_step=204800, grad_norm=2.9913887977600098, loss=2.3160853385925293
I0303 15:02:28.419710 140239842563840 logging_writer.py:48] [204900] global_step=204900, grad_norm=3.2780442237854004, loss=2.311796188354492
I0303 15:03:13.299934 140239850956544 logging_writer.py:48] [205000] global_step=205000, grad_norm=2.748772382736206, loss=1.631723403930664
I0303 15:03:58.436703 140239842563840 logging_writer.py:48] [205100] global_step=205100, grad_norm=2.901461362838745, loss=1.2175322771072388
I0303 15:04:00.358151 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:04:10.567800 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:04:40.561182 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:04:42.186283 140437341357888 submission_runner.py:411] Time since start: 99123.74s, 	Step: 205106, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.41113460063934326, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 91630.6247985363, 'total_duration': 99123.73776745796, 'accumulated_submission_time': 91630.6247985363, 'accumulated_eval_time': 7468.865349769592, 'accumulated_logging_time': 12.98732614517212}
I0303 15:04:42.247128 140239850956544 logging_writer.py:48] [205106] accumulated_eval_time=7468.865350, accumulated_logging_time=12.987326, accumulated_submission_time=91630.624799, global_step=205106, preemption_count=0, score=91630.624799, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=99123.737767, train/accuracy=0.889570, train/loss=0.411135, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:05:20.808834 140239842563840 logging_writer.py:48] [205200] global_step=205200, grad_norm=3.090240716934204, loss=1.3491442203521729
I0303 15:06:05.914218 140239850956544 logging_writer.py:48] [205300] global_step=205300, grad_norm=3.216146469116211, loss=1.1972984075546265
I0303 15:06:51.282247 140239842563840 logging_writer.py:48] [205400] global_step=205400, grad_norm=3.2335946559906006, loss=1.2723512649536133
I0303 15:07:36.450944 140239850956544 logging_writer.py:48] [205500] global_step=205500, grad_norm=3.152451276779175, loss=2.7643847465515137
I0303 15:08:21.677798 140239842563840 logging_writer.py:48] [205600] global_step=205600, grad_norm=2.654815673828125, loss=1.9822986125946045
I0303 15:09:07.149436 140239850956544 logging_writer.py:48] [205700] global_step=205700, grad_norm=3.5994715690612793, loss=3.1361613273620605
I0303 15:09:52.365431 140239842563840 logging_writer.py:48] [205800] global_step=205800, grad_norm=3.054124355316162, loss=1.1585688591003418
I0303 15:10:37.496309 140239850956544 logging_writer.py:48] [205900] global_step=205900, grad_norm=3.059767961502075, loss=1.3490492105484009
I0303 15:11:22.771617 140239842563840 logging_writer.py:48] [206000] global_step=206000, grad_norm=2.9863595962524414, loss=1.0742442607879639
I0303 15:11:42.362486 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:11:52.632099 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:12:17.638198 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:12:19.255989 140437341357888 submission_runner.py:411] Time since start: 99580.81s, 	Step: 206045, 	{'train/accuracy': 0.8857226371765137, 'train/loss': 0.4192066490650177, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 92050.67975926399, 'total_duration': 99580.80747056007, 'accumulated_submission_time': 92050.67975926399, 'accumulated_eval_time': 7505.758831977844, 'accumulated_logging_time': 13.057476282119751}
I0303 15:12:19.312539 140239850956544 logging_writer.py:48] [206045] accumulated_eval_time=7505.758832, accumulated_logging_time=13.057476, accumulated_submission_time=92050.679759, global_step=206045, preemption_count=0, score=92050.679759, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=99580.807471, train/accuracy=0.885723, train/loss=0.419207, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:12:41.514414 140239842563840 logging_writer.py:48] [206100] global_step=206100, grad_norm=3.0368266105651855, loss=2.464329242706299
I0303 15:13:25.614476 140239850956544 logging_writer.py:48] [206200] global_step=206200, grad_norm=3.2046797275543213, loss=2.611903429031372
I0303 15:14:10.576213 140239842563840 logging_writer.py:48] [206300] global_step=206300, grad_norm=3.0469284057617188, loss=2.6470789909362793
I0303 15:14:55.950169 140239850956544 logging_writer.py:48] [206400] global_step=206400, grad_norm=3.210442304611206, loss=1.1485352516174316
I0303 15:15:41.368145 140239842563840 logging_writer.py:48] [206500] global_step=206500, grad_norm=2.816561222076416, loss=1.1240934133529663
I0303 15:16:26.962045 140239850956544 logging_writer.py:48] [206600] global_step=206600, grad_norm=3.7995071411132812, loss=3.064382553100586
I0303 15:17:12.828585 140239842563840 logging_writer.py:48] [206700] global_step=206700, grad_norm=3.1713364124298096, loss=2.576943874359131
I0303 15:17:58.104991 140239850956544 logging_writer.py:48] [206800] global_step=206800, grad_norm=3.2050957679748535, loss=2.9073069095611572
I0303 15:18:43.610084 140239842563840 logging_writer.py:48] [206900] global_step=206900, grad_norm=3.0283756256103516, loss=1.4074236154556274
I0303 15:19:19.348484 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:19:29.673754 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:19:54.135706 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:19:55.768376 140437341357888 submission_runner.py:411] Time since start: 100037.32s, 	Step: 206981, 	{'train/accuracy': 0.8902148008346558, 'train/loss': 0.4150867462158203, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 92470.65465569496, 'total_duration': 100037.31982588768, 'accumulated_submission_time': 92470.65465569496, 'accumulated_eval_time': 7542.178693294525, 'accumulated_logging_time': 13.123713493347168}
I0303 15:19:55.829772 140239850956544 logging_writer.py:48] [206981] accumulated_eval_time=7542.178693, accumulated_logging_time=13.123713, accumulated_submission_time=92470.654656, global_step=206981, preemption_count=0, score=92470.654656, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=100037.319826, train/accuracy=0.890215, train/loss=0.415087, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:20:03.783218 140239842563840 logging_writer.py:48] [207000] global_step=207000, grad_norm=2.9363481998443604, loss=1.145609974861145
I0303 15:20:46.018743 140239850956544 logging_writer.py:48] [207100] global_step=207100, grad_norm=3.5217549800872803, loss=2.8133316040039062
I0303 15:21:31.222487 140239842563840 logging_writer.py:48] [207200] global_step=207200, grad_norm=2.964221954345703, loss=1.2398432493209839
I0303 15:22:16.533658 140239850956544 logging_writer.py:48] [207300] global_step=207300, grad_norm=3.2727015018463135, loss=2.9887688159942627
I0303 15:23:01.624857 140239842563840 logging_writer.py:48] [207400] global_step=207400, grad_norm=3.426964521408081, loss=3.0199170112609863
I0303 15:23:46.804634 140239850956544 logging_writer.py:48] [207500] global_step=207500, grad_norm=3.3587818145751953, loss=3.1591432094573975
I0303 15:24:32.065041 140239842563840 logging_writer.py:48] [207600] global_step=207600, grad_norm=3.3345134258270264, loss=1.1167895793914795
I0303 15:25:17.797333 140239850956544 logging_writer.py:48] [207700] global_step=207700, grad_norm=2.9185686111450195, loss=1.0784249305725098
I0303 15:26:03.054609 140239842563840 logging_writer.py:48] [207800] global_step=207800, grad_norm=3.1057662963867188, loss=1.0564632415771484
I0303 15:26:48.396296 140239850956544 logging_writer.py:48] [207900] global_step=207900, grad_norm=3.0535967350006104, loss=1.108793020248413
I0303 15:26:56.142387 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:27:06.622370 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:27:31.717750 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:27:33.347658 140437341357888 submission_runner.py:411] Time since start: 100494.90s, 	Step: 207919, 	{'train/accuracy': 0.8915429711341858, 'train/loss': 0.4060378968715668, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 92890.90583324432, 'total_duration': 100494.89912700653, 'accumulated_submission_time': 92890.90583324432, 'accumulated_eval_time': 7579.383923530579, 'accumulated_logging_time': 13.19585919380188}
I0303 15:27:33.409415 140239842563840 logging_writer.py:48] [207919] accumulated_eval_time=7579.383924, accumulated_logging_time=13.195859, accumulated_submission_time=92890.905833, global_step=207919, preemption_count=0, score=92890.905833, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=100494.899127, train/accuracy=0.891543, train/loss=0.406038, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:28:06.273232 140239850956544 logging_writer.py:48] [208000] global_step=208000, grad_norm=2.738109588623047, loss=1.5946294069290161
I0303 15:28:50.987779 140239842563840 logging_writer.py:48] [208100] global_step=208100, grad_norm=2.9456422328948975, loss=1.5518524646759033
I0303 15:29:36.585345 140239850956544 logging_writer.py:48] [208200] global_step=208200, grad_norm=3.0398967266082764, loss=2.040818929672241
I0303 15:30:21.696323 140239842563840 logging_writer.py:48] [208300] global_step=208300, grad_norm=2.9399945735931396, loss=1.0838608741760254
I0303 15:31:06.825786 140239850956544 logging_writer.py:48] [208400] global_step=208400, grad_norm=3.181675434112549, loss=1.2153912782669067
I0303 15:31:51.964192 140239842563840 logging_writer.py:48] [208500] global_step=208500, grad_norm=3.2660841941833496, loss=1.157457947731018
I0303 15:32:37.208018 140239850956544 logging_writer.py:48] [208600] global_step=208600, grad_norm=3.308621406555176, loss=1.1828902959823608
I0303 15:33:22.649292 140239842563840 logging_writer.py:48] [208700] global_step=208700, grad_norm=4.535005569458008, loss=3.2114200592041016
I0303 15:34:07.934599 140239850956544 logging_writer.py:48] [208800] global_step=208800, grad_norm=2.962003707885742, loss=1.1471375226974487
I0303 15:34:33.801734 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:34:43.973319 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:35:11.158931 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:35:12.815046 140437341357888 submission_runner.py:411] Time since start: 100954.37s, 	Step: 208859, 	{'train/accuracy': 0.8892382383346558, 'train/loss': 0.41316649317741394, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 93311.23576164246, 'total_duration': 100954.3665342331, 'accumulated_submission_time': 93311.23576164246, 'accumulated_eval_time': 7618.397220611572, 'accumulated_logging_time': 13.267715454101562}
I0303 15:35:12.862931 140239842563840 logging_writer.py:48] [208859] accumulated_eval_time=7618.397221, accumulated_logging_time=13.267715, accumulated_submission_time=93311.235762, global_step=208859, preemption_count=0, score=93311.235762, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=100954.366534, train/accuracy=0.889238, train/loss=0.413166, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:35:29.524883 140239850956544 logging_writer.py:48] [208900] global_step=208900, grad_norm=3.188922166824341, loss=1.3403809070587158
I0303 15:36:11.316882 140239842563840 logging_writer.py:48] [209000] global_step=209000, grad_norm=3.175041675567627, loss=1.1453559398651123
I0303 15:36:56.842513 140239850956544 logging_writer.py:48] [209100] global_step=209100, grad_norm=4.46033239364624, loss=3.2217931747436523
I0303 15:37:42.100301 140239842563840 logging_writer.py:48] [209200] global_step=209200, grad_norm=3.007024049758911, loss=1.4893109798431396
I0303 15:38:27.579062 140239850956544 logging_writer.py:48] [209300] global_step=209300, grad_norm=3.161973714828491, loss=1.1658991575241089
I0303 15:39:12.836213 140239842563840 logging_writer.py:48] [209400] global_step=209400, grad_norm=3.126970052719116, loss=1.16079580783844
I0303 15:39:57.967700 140239850956544 logging_writer.py:48] [209500] global_step=209500, grad_norm=3.5356714725494385, loss=3.171224355697632
I0303 15:40:43.462062 140239842563840 logging_writer.py:48] [209600] global_step=209600, grad_norm=2.9852218627929688, loss=2.4398646354675293
I0303 15:41:28.790955 140239850956544 logging_writer.py:48] [209700] global_step=209700, grad_norm=3.5256481170654297, loss=3.082479953765869
I0303 15:42:13.174422 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:42:23.340838 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:42:48.327072 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:42:49.947163 140437341357888 submission_runner.py:411] Time since start: 101411.50s, 	Step: 209800, 	{'train/accuracy': 0.8897460699081421, 'train/loss': 0.4122765362262726, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 93731.48620271683, 'total_duration': 101411.49864506721, 'accumulated_submission_time': 93731.48620271683, 'accumulated_eval_time': 7655.169943809509, 'accumulated_logging_time': 13.32474970817566}
I0303 15:42:50.005709 140239842563840 logging_writer.py:48] [209800] accumulated_eval_time=7655.169944, accumulated_logging_time=13.324750, accumulated_submission_time=93731.486203, global_step=209800, preemption_count=0, score=93731.486203, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=101411.498645, train/accuracy=0.889746, train/loss=0.412277, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:42:50.411107 140239850956544 logging_writer.py:48] [209800] global_step=209800, grad_norm=2.951056718826294, loss=1.1546084880828857
I0303 15:43:31.536432 140239842563840 logging_writer.py:48] [209900] global_step=209900, grad_norm=3.141606330871582, loss=1.2045884132385254
I0303 15:44:16.142393 140239850956544 logging_writer.py:48] [210000] global_step=210000, grad_norm=3.191856622695923, loss=2.842040777206421
I0303 15:45:01.089958 140239842563840 logging_writer.py:48] [210100] global_step=210100, grad_norm=2.9404544830322266, loss=1.2920680046081543
I0303 15:45:46.438405 140239850956544 logging_writer.py:48] [210200] global_step=210200, grad_norm=3.1417133808135986, loss=1.1153466701507568
I0303 15:46:31.739382 140239842563840 logging_writer.py:48] [210300] global_step=210300, grad_norm=2.940138101577759, loss=1.2066045999526978
I0303 15:47:17.013729 140239850956544 logging_writer.py:48] [210400] global_step=210400, grad_norm=2.9476468563079834, loss=2.3383264541625977
I0303 15:48:02.330903 140239842563840 logging_writer.py:48] [210500] global_step=210500, grad_norm=3.2042746543884277, loss=1.8820757865905762
I0303 15:48:47.338752 140239850956544 logging_writer.py:48] [210600] global_step=210600, grad_norm=3.1025357246398926, loss=1.0632331371307373
I0303 15:49:32.628193 140239842563840 logging_writer.py:48] [210700] global_step=210700, grad_norm=3.450098752975464, loss=1.2018320560455322
I0303 15:49:49.947780 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:50:00.479188 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:50:35.433792 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:50:37.053768 140437341357888 submission_runner.py:411] Time since start: 101878.61s, 	Step: 210740, 	{'train/accuracy': 0.8892187476158142, 'train/loss': 0.4108535349369049, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 94151.36676955223, 'total_duration': 101878.605271101, 'accumulated_submission_time': 94151.36676955223, 'accumulated_eval_time': 7702.275942802429, 'accumulated_logging_time': 13.394086122512817}
I0303 15:50:37.100821 140239850956544 logging_writer.py:48] [210740] accumulated_eval_time=7702.275943, accumulated_logging_time=13.394086, accumulated_submission_time=94151.366770, global_step=210740, preemption_count=0, score=94151.366770, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=101878.605271, train/accuracy=0.889219, train/loss=0.410854, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:51:01.279893 140239842563840 logging_writer.py:48] [210800] global_step=210800, grad_norm=3.578420877456665, loss=3.1433005332946777
I0303 15:51:44.405576 140239850956544 logging_writer.py:48] [210900] global_step=210900, grad_norm=3.5716440677642822, loss=3.079794406890869
I0303 15:52:29.729880 140239842563840 logging_writer.py:48] [211000] global_step=211000, grad_norm=3.2556216716766357, loss=1.163376808166504
I0303 15:53:14.884471 140239850956544 logging_writer.py:48] [211100] global_step=211100, grad_norm=3.198720693588257, loss=2.257232189178467
I0303 15:53:59.903152 140239842563840 logging_writer.py:48] [211200] global_step=211200, grad_norm=2.820451259613037, loss=1.1974074840545654
I0303 15:54:45.170250 140239850956544 logging_writer.py:48] [211300] global_step=211300, grad_norm=3.030236005783081, loss=1.276894450187683
I0303 15:55:30.193275 140239842563840 logging_writer.py:48] [211400] global_step=211400, grad_norm=2.8491644859313965, loss=1.8976361751556396
I0303 15:56:15.682233 140239850956544 logging_writer.py:48] [211500] global_step=211500, grad_norm=3.5618114471435547, loss=2.980112075805664
I0303 15:57:00.800790 140239842563840 logging_writer.py:48] [211600] global_step=211600, grad_norm=2.964555025100708, loss=2.1238555908203125
I0303 15:57:37.126304 140437341357888 spec.py:321] Evaluating on the training split.
I0303 15:57:47.453712 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 15:58:08.842044 140437341357888 spec.py:349] Evaluating on the test split.
I0303 15:58:10.461796 140437341357888 submission_runner.py:411] Time since start: 102332.01s, 	Step: 211682, 	{'train/accuracy': 0.8870898485183716, 'train/loss': 0.41992664337158203, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 94571.33133649826, 'total_duration': 102332.013286829, 'accumulated_submission_time': 94571.33133649826, 'accumulated_eval_time': 7735.611426591873, 'accumulated_logging_time': 13.45100212097168}
I0303 15:58:10.521298 140239850956544 logging_writer.py:48] [211682] accumulated_eval_time=7735.611427, accumulated_logging_time=13.451002, accumulated_submission_time=94571.331336, global_step=211682, preemption_count=0, score=94571.331336, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=102332.013287, train/accuracy=0.887090, train/loss=0.419927, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 15:58:18.078569 140239842563840 logging_writer.py:48] [211700] global_step=211700, grad_norm=2.9961488246917725, loss=1.1587692499160767
I0303 15:59:00.275168 140239850956544 logging_writer.py:48] [211800] global_step=211800, grad_norm=3.2308242321014404, loss=1.0571238994598389
I0303 15:59:45.219141 140239842563840 logging_writer.py:48] [211900] global_step=211900, grad_norm=3.568098306655884, loss=3.2462143898010254
I0303 16:00:30.742534 140239850956544 logging_writer.py:48] [212000] global_step=212000, grad_norm=3.242250680923462, loss=1.1908745765686035
I0303 16:01:16.000469 140239842563840 logging_writer.py:48] [212100] global_step=212100, grad_norm=3.2543153762817383, loss=1.691541314125061
I0303 16:02:00.962889 140239850956544 logging_writer.py:48] [212200] global_step=212200, grad_norm=3.0295779705047607, loss=1.132062315940857
I0303 16:02:46.141932 140239842563840 logging_writer.py:48] [212300] global_step=212300, grad_norm=3.7122769355773926, loss=2.5587868690490723
I0303 16:03:31.315351 140239850956544 logging_writer.py:48] [212400] global_step=212400, grad_norm=3.325389862060547, loss=2.221804618835449
I0303 16:04:16.294445 140239842563840 logging_writer.py:48] [212500] global_step=212500, grad_norm=3.0092623233795166, loss=1.065253734588623
I0303 16:05:01.112811 140239850956544 logging_writer.py:48] [212600] global_step=212600, grad_norm=3.14011812210083, loss=1.1967647075653076
I0303 16:05:10.853453 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:05:21.476003 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:05:46.207240 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:05:47.837205 140437341357888 submission_runner.py:411] Time since start: 102789.39s, 	Step: 212623, 	{'train/accuracy': 0.8870312571525574, 'train/loss': 0.416995108127594, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 94991.60111403465, 'total_duration': 102789.38869023323, 'accumulated_submission_time': 94991.60111403465, 'accumulated_eval_time': 7772.595160007477, 'accumulated_logging_time': 13.521557331085205}
I0303 16:05:47.896549 140239842563840 logging_writer.py:48] [212623] accumulated_eval_time=7772.595160, accumulated_logging_time=13.521557, accumulated_submission_time=94991.601114, global_step=212623, preemption_count=0, score=94991.601114, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=102789.388690, train/accuracy=0.887031, train/loss=0.416995, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:06:19.562796 140239850956544 logging_writer.py:48] [212700] global_step=212700, grad_norm=2.9754981994628906, loss=1.0731102228164673
I0303 16:07:04.776471 140239842563840 logging_writer.py:48] [212800] global_step=212800, grad_norm=3.084256649017334, loss=1.1291701793670654
I0303 16:07:49.822199 140239850956544 logging_writer.py:48] [212900] global_step=212900, grad_norm=3.2688069343566895, loss=1.1512800455093384
I0303 16:08:34.812918 140239842563840 logging_writer.py:48] [213000] global_step=213000, grad_norm=2.954007863998413, loss=1.4352350234985352
I0303 16:09:20.065980 140239850956544 logging_writer.py:48] [213100] global_step=213100, grad_norm=2.924818992614746, loss=1.2709378004074097
I0303 16:10:05.343574 140239842563840 logging_writer.py:48] [213200] global_step=213200, grad_norm=2.9937236309051514, loss=2.257786512374878
I0303 16:10:50.370648 140239850956544 logging_writer.py:48] [213300] global_step=213300, grad_norm=2.863144874572754, loss=1.9468103647232056
I0303 16:11:35.680938 140239842563840 logging_writer.py:48] [213400] global_step=213400, grad_norm=3.006143808364868, loss=1.0582057237625122
I0303 16:12:20.931596 140239850956544 logging_writer.py:48] [213500] global_step=213500, grad_norm=3.737921714782715, loss=3.20324969291687
I0303 16:12:48.124892 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:12:58.123584 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:13:26.741397 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:13:28.372527 140437341357888 submission_runner.py:411] Time since start: 103249.92s, 	Step: 213562, 	{'train/accuracy': 0.8886132836341858, 'train/loss': 0.4166717827320099, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 95411.76716446877, 'total_duration': 103249.92401885986, 'accumulated_submission_time': 95411.76716446877, 'accumulated_eval_time': 7812.842822313309, 'accumulated_logging_time': 13.592507123947144}
I0303 16:13:28.431915 140239842563840 logging_writer.py:48] [213562] accumulated_eval_time=7812.842822, accumulated_logging_time=13.592507, accumulated_submission_time=95411.767164, global_step=213562, preemption_count=0, score=95411.767164, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=103249.924019, train/accuracy=0.888613, train/loss=0.416672, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:13:43.903258 140239850956544 logging_writer.py:48] [213600] global_step=213600, grad_norm=3.1974828243255615, loss=2.3059797286987305
I0303 16:14:26.558329 140239842563840 logging_writer.py:48] [213700] global_step=213700, grad_norm=3.2508370876312256, loss=2.1663057804107666
I0303 16:15:11.589204 140239850956544 logging_writer.py:48] [213800] global_step=213800, grad_norm=3.042665719985962, loss=1.0689935684204102
I0303 16:15:56.719069 140239842563840 logging_writer.py:48] [213900] global_step=213900, grad_norm=3.6398658752441406, loss=3.262146234512329
I0303 16:16:42.221729 140239850956544 logging_writer.py:48] [214000] global_step=214000, grad_norm=3.0632612705230713, loss=2.549649238586426
I0303 16:17:27.719838 140239842563840 logging_writer.py:48] [214100] global_step=214100, grad_norm=3.263827323913574, loss=1.184880256652832
I0303 16:18:12.872919 140239850956544 logging_writer.py:48] [214200] global_step=214200, grad_norm=4.50703763961792, loss=3.2561373710632324
I0303 16:18:58.012444 140239842563840 logging_writer.py:48] [214300] global_step=214300, grad_norm=3.269468307495117, loss=1.1404305696487427
I0303 16:19:43.168582 140239850956544 logging_writer.py:48] [214400] global_step=214400, grad_norm=3.464066505432129, loss=3.1417434215545654
I0303 16:20:28.474926 140239842563840 logging_writer.py:48] [214500] global_step=214500, grad_norm=3.0626351833343506, loss=2.4541501998901367
I0303 16:20:28.488682 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:20:38.825502 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:21:04.670015 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:21:06.325139 140437341357888 submission_runner.py:411] Time since start: 103707.88s, 	Step: 214501, 	{'train/accuracy': 0.888964831829071, 'train/loss': 0.411579966545105, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 95831.76033210754, 'total_duration': 103707.87656855583, 'accumulated_submission_time': 95831.76033210754, 'accumulated_eval_time': 7850.67919921875, 'accumulated_logging_time': 13.663443326950073}
I0303 16:21:06.420130 140239850956544 logging_writer.py:48] [214501] accumulated_eval_time=7850.679199, accumulated_logging_time=13.663443, accumulated_submission_time=95831.760332, global_step=214501, preemption_count=0, score=95831.760332, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=103707.876569, train/accuracy=0.888965, train/loss=0.411580, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:21:46.519516 140239842563840 logging_writer.py:48] [214600] global_step=214600, grad_norm=3.491044521331787, loss=3.1932694911956787
I0303 16:22:31.368979 140239850956544 logging_writer.py:48] [214700] global_step=214700, grad_norm=3.8625576496124268, loss=3.2466204166412354
I0303 16:23:16.624580 140239842563840 logging_writer.py:48] [214800] global_step=214800, grad_norm=3.6275486946105957, loss=3.185739278793335
I0303 16:24:01.691216 140239850956544 logging_writer.py:48] [214900] global_step=214900, grad_norm=3.090773344039917, loss=1.4152144193649292
I0303 16:24:46.593485 140239842563840 logging_writer.py:48] [215000] global_step=215000, grad_norm=2.9512341022491455, loss=1.0719140768051147
I0303 16:25:31.888638 140239850956544 logging_writer.py:48] [215100] global_step=215100, grad_norm=3.3903613090515137, loss=2.857490062713623
I0303 16:26:17.425941 140239842563840 logging_writer.py:48] [215200] global_step=215200, grad_norm=2.9275219440460205, loss=2.3478949069976807
I0303 16:27:02.939993 140239850956544 logging_writer.py:48] [215300] global_step=215300, grad_norm=3.083664655685425, loss=1.466839075088501
I0303 16:27:48.039631 140239842563840 logging_writer.py:48] [215400] global_step=215400, grad_norm=3.115027904510498, loss=1.0493850708007812
I0303 16:28:06.424343 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:28:16.674920 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:28:48.013900 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:28:49.626998 140437341357888 submission_runner.py:411] Time since start: 104171.18s, 	Step: 215442, 	{'train/accuracy': 0.8849804401397705, 'train/loss': 0.4249436855316162, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 96251.69516730309, 'total_duration': 104171.17848610878, 'accumulated_submission_time': 96251.69516730309, 'accumulated_eval_time': 7893.881835460663, 'accumulated_logging_time': 13.775733470916748}
I0303 16:28:49.690133 140239850956544 logging_writer.py:48] [215442] accumulated_eval_time=7893.881835, accumulated_logging_time=13.775733, accumulated_submission_time=96251.695167, global_step=215442, preemption_count=0, score=96251.695167, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=104171.178486, train/accuracy=0.884980, train/loss=0.424944, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:29:13.052593 140239842563840 logging_writer.py:48] [215500] global_step=215500, grad_norm=3.208390235900879, loss=1.1815717220306396
I0303 16:29:57.019694 140239850956544 logging_writer.py:48] [215600] global_step=215600, grad_norm=3.0844602584838867, loss=2.4274535179138184
I0303 16:30:42.523429 140239842563840 logging_writer.py:48] [215700] global_step=215700, grad_norm=3.9938933849334717, loss=1.085368037223816
I0303 16:31:27.698637 140239850956544 logging_writer.py:48] [215800] global_step=215800, grad_norm=3.0772969722747803, loss=1.5749542713165283
I0303 16:32:12.881525 140239842563840 logging_writer.py:48] [215900] global_step=215900, grad_norm=2.931697368621826, loss=2.030571699142456
I0303 16:32:57.974533 140239850956544 logging_writer.py:48] [216000] global_step=216000, grad_norm=3.2309513092041016, loss=1.1182830333709717
I0303 16:33:43.648935 140239842563840 logging_writer.py:48] [216100] global_step=216100, grad_norm=3.2914493083953857, loss=1.2659376859664917
I0303 16:34:29.038677 140239850956544 logging_writer.py:48] [216200] global_step=216200, grad_norm=3.1928412914276123, loss=2.7837202548980713
I0303 16:35:14.468036 140239842563840 logging_writer.py:48] [216300] global_step=216300, grad_norm=3.0994954109191895, loss=1.102786660194397
I0303 16:35:49.844235 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:36:00.272254 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:36:28.966442 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:36:30.585366 140437341357888 submission_runner.py:411] Time since start: 104632.14s, 	Step: 216380, 	{'train/accuracy': 0.8871093392372131, 'train/loss': 0.41798800230026245, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 96671.78650546074, 'total_duration': 104632.13685011864, 'accumulated_submission_time': 96671.78650546074, 'accumulated_eval_time': 7934.622961759567, 'accumulated_logging_time': 13.850823163986206}
I0303 16:36:30.645941 140239850956544 logging_writer.py:48] [216380] accumulated_eval_time=7934.622962, accumulated_logging_time=13.850823, accumulated_submission_time=96671.786505, global_step=216380, preemption_count=0, score=96671.786505, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=104632.136850, train/accuracy=0.887109, train/loss=0.417988, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:36:39.001412 140239842563840 logging_writer.py:48] [216400] global_step=216400, grad_norm=2.9021048545837402, loss=1.0578691959381104
I0303 16:37:21.304949 140239850956544 logging_writer.py:48] [216500] global_step=216500, grad_norm=2.9828546047210693, loss=1.1912673711776733
I0303 16:38:06.774762 140239842563840 logging_writer.py:48] [216600] global_step=216600, grad_norm=2.8320059776306152, loss=1.0323621034622192
I0303 16:38:51.950348 140239850956544 logging_writer.py:48] [216700] global_step=216700, grad_norm=3.3735878467559814, loss=2.8550243377685547
I0303 16:39:37.177286 140239842563840 logging_writer.py:48] [216800] global_step=216800, grad_norm=2.935046672821045, loss=1.207968831062317
I0303 16:40:22.399035 140239850956544 logging_writer.py:48] [216900] global_step=216900, grad_norm=2.971043348312378, loss=1.0706264972686768
I0303 16:41:07.693279 140239842563840 logging_writer.py:48] [217000] global_step=217000, grad_norm=3.1667563915252686, loss=1.071130633354187
I0303 16:41:53.257240 140239850956544 logging_writer.py:48] [217100] global_step=217100, grad_norm=3.1783993244171143, loss=2.7118520736694336
I0303 16:42:38.654339 140239842563840 logging_writer.py:48] [217200] global_step=217200, grad_norm=2.9793782234191895, loss=1.4475719928741455
I0303 16:43:24.051869 140239850956544 logging_writer.py:48] [217300] global_step=217300, grad_norm=3.0711793899536133, loss=1.0866518020629883
I0303 16:43:31.019035 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:43:41.376274 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:44:11.348835 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:44:12.984334 140437341357888 submission_runner.py:411] Time since start: 105094.54s, 	Step: 217317, 	{'train/accuracy': 0.8890234231948853, 'train/loss': 0.4122736155986786, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 97092.09571146965, 'total_duration': 105094.53578543663, 'accumulated_submission_time': 97092.09571146965, 'accumulated_eval_time': 7976.588205337524, 'accumulated_logging_time': 13.924319505691528}
I0303 16:44:13.039338 140239842563840 logging_writer.py:48] [217317] accumulated_eval_time=7976.588205, accumulated_logging_time=13.924320, accumulated_submission_time=97092.095711, global_step=217317, preemption_count=0, score=97092.095711, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=105094.535785, train/accuracy=0.889023, train/loss=0.412274, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:44:46.286853 140239850956544 logging_writer.py:48] [217400] global_step=217400, grad_norm=3.2875003814697266, loss=2.31168532371521
I0303 16:45:30.869472 140239842563840 logging_writer.py:48] [217500] global_step=217500, grad_norm=2.9560561180114746, loss=1.2627172470092773
I0303 16:46:16.077369 140239850956544 logging_writer.py:48] [217600] global_step=217600, grad_norm=3.2746739387512207, loss=2.3934764862060547
I0303 16:47:01.595567 140239842563840 logging_writer.py:48] [217700] global_step=217700, grad_norm=3.3359127044677734, loss=1.2043769359588623
I0303 16:47:46.683148 140239850956544 logging_writer.py:48] [217800] global_step=217800, grad_norm=2.926297903060913, loss=1.1337424516677856
I0303 16:48:32.013616 140239842563840 logging_writer.py:48] [217900] global_step=217900, grad_norm=3.1782150268554688, loss=1.1379752159118652
I0303 16:49:17.122705 140239850956544 logging_writer.py:48] [218000] global_step=218000, grad_norm=2.985410451889038, loss=1.1938318014144897
I0303 16:50:02.577069 140239842563840 logging_writer.py:48] [218100] global_step=218100, grad_norm=3.246417760848999, loss=1.2469096183776855
I0303 16:50:47.667274 140239850956544 logging_writer.py:48] [218200] global_step=218200, grad_norm=3.4613654613494873, loss=2.875314712524414
I0303 16:51:13.157277 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:51:23.406555 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:51:45.724249 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:51:47.337810 140437341357888 submission_runner.py:411] Time since start: 105548.89s, 	Step: 218258, 	{'train/accuracy': 0.8883007764816284, 'train/loss': 0.412197470664978, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 97512.15190458298, 'total_duration': 105548.88929748535, 'accumulated_submission_time': 97512.15190458298, 'accumulated_eval_time': 8010.768728733063, 'accumulated_logging_time': 13.989553689956665}
I0303 16:51:47.398401 140239842563840 logging_writer.py:48] [218258] accumulated_eval_time=8010.768729, accumulated_logging_time=13.989554, accumulated_submission_time=97512.151905, global_step=218258, preemption_count=0, score=97512.151905, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=105548.889297, train/accuracy=0.888301, train/loss=0.412197, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:52:04.458002 140239850956544 logging_writer.py:48] [218300] global_step=218300, grad_norm=3.144564628601074, loss=1.2353729009628296
I0303 16:52:48.165700 140239842563840 logging_writer.py:48] [218400] global_step=218400, grad_norm=2.831559896469116, loss=1.1695442199707031
I0303 16:53:33.816230 140239850956544 logging_writer.py:48] [218500] global_step=218500, grad_norm=3.1279077529907227, loss=1.1652703285217285
I0303 16:54:18.921478 140239842563840 logging_writer.py:48] [218600] global_step=218600, grad_norm=3.175711154937744, loss=1.1719551086425781
I0303 16:55:04.126642 140239850956544 logging_writer.py:48] [218700] global_step=218700, grad_norm=2.7925949096679688, loss=1.4722316265106201
I0303 16:55:49.196047 140239842563840 logging_writer.py:48] [218800] global_step=218800, grad_norm=3.0713939666748047, loss=1.9577237367630005
I0303 16:56:34.713939 140239850956544 logging_writer.py:48] [218900] global_step=218900, grad_norm=4.116573333740234, loss=3.2364094257354736
I0303 16:57:20.323272 140239842563840 logging_writer.py:48] [219000] global_step=219000, grad_norm=3.2519161701202393, loss=1.1362130641937256
I0303 16:58:05.604624 140239850956544 logging_writer.py:48] [219100] global_step=219100, grad_norm=3.1881802082061768, loss=1.740518569946289
I0303 16:58:47.508922 140437341357888 spec.py:321] Evaluating on the training split.
I0303 16:58:58.054879 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 16:59:25.018798 140437341357888 spec.py:349] Evaluating on the test split.
I0303 16:59:26.646833 140437341357888 submission_runner.py:411] Time since start: 106008.20s, 	Step: 219194, 	{'train/accuracy': 0.8895312547683716, 'train/loss': 0.41379064321517944, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 97932.20115685463, 'total_duration': 106008.19831943512, 'accumulated_submission_time': 97932.20115685463, 'accumulated_eval_time': 8049.906625032425, 'accumulated_logging_time': 14.060953378677368}
I0303 16:59:26.708696 140239842563840 logging_writer.py:48] [219194] accumulated_eval_time=8049.906625, accumulated_logging_time=14.060953, accumulated_submission_time=97932.201157, global_step=219194, preemption_count=0, score=97932.201157, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=106008.198319, train/accuracy=0.889531, train/loss=0.413791, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 16:59:29.492036 140239850956544 logging_writer.py:48] [219200] global_step=219200, grad_norm=3.197150468826294, loss=1.1703168153762817
I0303 17:00:11.058839 140239842563840 logging_writer.py:48] [219300] global_step=219300, grad_norm=3.107516288757324, loss=1.265373706817627
I0303 17:00:56.174325 140239850956544 logging_writer.py:48] [219400] global_step=219400, grad_norm=3.7684428691864014, loss=2.045503616333008
I0303 17:01:41.569838 140239842563840 logging_writer.py:48] [219500] global_step=219500, grad_norm=4.005983352661133, loss=3.1485092639923096
I0303 17:02:27.088511 140239850956544 logging_writer.py:48] [219600] global_step=219600, grad_norm=3.7817435264587402, loss=3.1696557998657227
I0303 17:03:12.496588 140239842563840 logging_writer.py:48] [219700] global_step=219700, grad_norm=3.6668591499328613, loss=3.2432498931884766
I0303 17:03:57.769362 140239850956544 logging_writer.py:48] [219800] global_step=219800, grad_norm=3.9811973571777344, loss=2.905733823776245
I0303 17:04:42.835955 140239842563840 logging_writer.py:48] [219900] global_step=219900, grad_norm=3.010047674179077, loss=1.123475193977356
I0303 17:05:28.158185 140239850956544 logging_writer.py:48] [220000] global_step=220000, grad_norm=3.2576231956481934, loss=2.63560152053833
I0303 17:06:13.518188 140239842563840 logging_writer.py:48] [220100] global_step=220100, grad_norm=5.6613335609436035, loss=1.1328999996185303
I0303 17:06:26.830119 140437341357888 spec.py:321] Evaluating on the training split.
I0303 17:06:37.188874 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 17:07:02.675136 140437341357888 spec.py:349] Evaluating on the test split.
I0303 17:07:04.311246 140437341357888 submission_runner.py:411] Time since start: 106465.86s, 	Step: 220131, 	{'train/accuracy': 0.8866210579872131, 'train/loss': 0.41901880502700806, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 98352.26095962524, 'total_duration': 106465.86269831657, 'accumulated_submission_time': 98352.26095962524, 'accumulated_eval_time': 8087.387703418732, 'accumulated_logging_time': 14.133442878723145}
I0303 17:07:04.411790 140239850956544 logging_writer.py:48] [220131] accumulated_eval_time=8087.387703, accumulated_logging_time=14.133443, accumulated_submission_time=98352.260960, global_step=220131, preemption_count=0, score=98352.260960, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=106465.862698, train/accuracy=0.886621, train/loss=0.419019, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 17:07:32.153742 140239842563840 logging_writer.py:48] [220200] global_step=220200, grad_norm=3.2500171661376953, loss=1.1500585079193115
I0303 17:08:16.921930 140239850956544 logging_writer.py:48] [220300] global_step=220300, grad_norm=5.748498439788818, loss=1.0352885723114014
I0303 17:09:02.329607 140239850956544 logging_writer.py:48] [220400] global_step=220400, grad_norm=3.039830446243286, loss=1.1184425354003906
I0303 17:09:47.498583 140239842563840 logging_writer.py:48] [220500] global_step=220500, grad_norm=3.291538715362549, loss=2.511833429336548
I0303 17:10:32.957205 140239850956544 logging_writer.py:48] [220600] global_step=220600, grad_norm=2.832968235015869, loss=1.7470767498016357
I0303 17:11:18.082431 140239842563840 logging_writer.py:48] [220700] global_step=220700, grad_norm=3.0100038051605225, loss=1.1845347881317139
I0303 17:12:03.350862 140239850956544 logging_writer.py:48] [220800] global_step=220800, grad_norm=3.0435028076171875, loss=1.1261082887649536
I0303 17:12:48.423187 140239842563840 logging_writer.py:48] [220900] global_step=220900, grad_norm=3.1432130336761475, loss=1.2132827043533325
I0303 17:13:33.592675 140239850956544 logging_writer.py:48] [221000] global_step=221000, grad_norm=2.9964139461517334, loss=1.5901858806610107
I0303 17:14:04.556653 140437341357888 spec.py:321] Evaluating on the training split.
I0303 17:14:14.786600 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 17:14:42.033065 140437341357888 spec.py:349] Evaluating on the test split.
I0303 17:14:43.654178 140437341357888 submission_runner.py:411] Time since start: 106925.21s, 	Step: 221070, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.41746851801872253, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 98772.34060120583, 'total_duration': 106925.20564007759, 'accumulated_submission_time': 98772.34060120583, 'accumulated_eval_time': 8126.485192060471, 'accumulated_logging_time': 14.248473167419434}
I0303 17:14:43.717767 140239842563840 logging_writer.py:48] [221070] accumulated_eval_time=8126.485192, accumulated_logging_time=14.248473, accumulated_submission_time=98772.340601, global_step=221070, preemption_count=0, score=98772.340601, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=106925.205640, train/accuracy=0.887383, train/loss=0.417469, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 17:14:56.207641 140239850956544 logging_writer.py:48] [221100] global_step=221100, grad_norm=3.9547359943389893, loss=3.1678755283355713
I0303 17:15:38.719859 140239842563840 logging_writer.py:48] [221200] global_step=221200, grad_norm=3.0350663661956787, loss=1.1143344640731812
I0303 17:16:23.520697 140239850956544 logging_writer.py:48] [221300] global_step=221300, grad_norm=2.8180348873138428, loss=1.2141849994659424
I0303 17:17:08.979946 140239842563840 logging_writer.py:48] [221400] global_step=221400, grad_norm=3.017557382583618, loss=2.3136367797851562
I0303 17:17:54.454266 140239850956544 logging_writer.py:48] [221500] global_step=221500, grad_norm=3.0046517848968506, loss=1.600064754486084
I0303 17:18:39.604681 140239842563840 logging_writer.py:48] [221600] global_step=221600, grad_norm=2.9847419261932373, loss=1.1372380256652832
I0303 17:19:24.893396 140239850956544 logging_writer.py:48] [221700] global_step=221700, grad_norm=3.436310052871704, loss=2.673097610473633
I0303 17:20:10.147847 140239842563840 logging_writer.py:48] [221800] global_step=221800, grad_norm=2.9094388484954834, loss=1.0629411935806274
I0303 17:20:55.289923 140239850956544 logging_writer.py:48] [221900] global_step=221900, grad_norm=3.1827709674835205, loss=1.1595499515533447
I0303 17:21:40.319499 140239842563840 logging_writer.py:48] [222000] global_step=222000, grad_norm=4.536318302154541, loss=3.1640946865081787
I0303 17:21:43.748480 140437341357888 spec.py:321] Evaluating on the training split.
I0303 17:21:53.986421 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 17:22:28.787235 140437341357888 spec.py:349] Evaluating on the test split.
I0303 17:22:30.401164 140437341357888 submission_runner.py:411] Time since start: 107391.95s, 	Step: 222009, 	{'train/accuracy': 0.8881054520606995, 'train/loss': 0.41790708899497986, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 99192.3106303215, 'total_duration': 107391.95266342163, 'accumulated_submission_time': 99192.3106303215, 'accumulated_eval_time': 8173.137872457504, 'accumulated_logging_time': 14.322559595108032}
I0303 17:22:30.453253 140239850956544 logging_writer.py:48] [222009] accumulated_eval_time=8173.137872, accumulated_logging_time=14.322560, accumulated_submission_time=99192.310630, global_step=222009, preemption_count=0, score=99192.310630, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=107391.952663, train/accuracy=0.888105, train/loss=0.417907, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 17:23:06.881768 140239842563840 logging_writer.py:48] [222100] global_step=222100, grad_norm=3.0701253414154053, loss=1.8486028909683228
I0303 17:23:51.751658 140239850956544 logging_writer.py:48] [222200] global_step=222200, grad_norm=3.1825263500213623, loss=1.1128411293029785
I0303 17:24:37.184907 140239842563840 logging_writer.py:48] [222300] global_step=222300, grad_norm=3.342489242553711, loss=1.1947020292282104
I0303 17:25:22.235129 140239850956544 logging_writer.py:48] [222400] global_step=222400, grad_norm=3.64322566986084, loss=3.1626341342926025
I0303 17:26:07.919308 140239842563840 logging_writer.py:48] [222500] global_step=222500, grad_norm=2.925699234008789, loss=1.1287732124328613
I0303 17:26:53.336464 140239850956544 logging_writer.py:48] [222600] global_step=222600, grad_norm=3.24743390083313, loss=1.321420669555664
I0303 17:27:38.879682 140239842563840 logging_writer.py:48] [222700] global_step=222700, grad_norm=2.7935214042663574, loss=1.0564652681350708
I0303 17:28:25.289996 140239850956544 logging_writer.py:48] [222800] global_step=222800, grad_norm=3.0452098846435547, loss=1.1155580282211304
I0303 17:29:11.040892 140239842563840 logging_writer.py:48] [222900] global_step=222900, grad_norm=3.2089924812316895, loss=1.2186799049377441
I0303 17:29:30.431850 140437341357888 spec.py:321] Evaluating on the training split.
I0303 17:29:40.635731 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 17:30:06.806681 140437341357888 spec.py:349] Evaluating on the test split.
I0303 17:30:08.456170 140437341357888 submission_runner.py:411] Time since start: 107850.01s, 	Step: 222944, 	{'train/accuracy': 0.8896679282188416, 'train/loss': 0.4159463346004486, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 99612.22961091995, 'total_duration': 107850.00766944885, 'accumulated_submission_time': 99612.22961091995, 'accumulated_eval_time': 8211.162187337875, 'accumulated_logging_time': 14.383384227752686}
I0303 17:30:08.509876 140239850956544 logging_writer.py:48] [222944] accumulated_eval_time=8211.162187, accumulated_logging_time=14.383384, accumulated_submission_time=99612.229611, global_step=222944, preemption_count=0, score=99612.229611, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=107850.007669, train/accuracy=0.889668, train/loss=0.415946, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 17:30:31.069000 140239842563840 logging_writer.py:48] [223000] global_step=223000, grad_norm=3.5738730430603027, loss=3.067034959793091
I0303 17:31:14.092158 140239850956544 logging_writer.py:48] [223100] global_step=223100, grad_norm=2.9816322326660156, loss=1.2269994020462036
I0303 17:31:59.574974 140239842563840 logging_writer.py:48] [223200] global_step=223200, grad_norm=2.944455623626709, loss=1.8091200590133667
I0303 17:32:44.824562 140239850956544 logging_writer.py:48] [223300] global_step=223300, grad_norm=2.9313392639160156, loss=1.1159794330596924
I0303 17:33:30.018249 140239842563840 logging_writer.py:48] [223400] global_step=223400, grad_norm=3.1003098487854004, loss=1.9479539394378662
I0303 17:34:15.201657 140239850956544 logging_writer.py:48] [223500] global_step=223500, grad_norm=2.750737190246582, loss=1.8508632183074951
I0303 17:35:00.451234 140239842563840 logging_writer.py:48] [223600] global_step=223600, grad_norm=3.9126229286193848, loss=3.22273850440979
I0303 17:35:45.686990 140239850956544 logging_writer.py:48] [223700] global_step=223700, grad_norm=3.1247522830963135, loss=1.297851800918579
I0303 17:36:31.161125 140239842563840 logging_writer.py:48] [223800] global_step=223800, grad_norm=3.095181465148926, loss=1.4763288497924805
I0303 17:37:08.510616 140437341357888 spec.py:321] Evaluating on the training split.
I0303 17:37:19.366374 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 17:37:46.685070 140437341357888 spec.py:349] Evaluating on the test split.
I0303 17:37:48.303042 140437341357888 submission_runner.py:411] Time since start: 108309.85s, 	Step: 223884, 	{'train/accuracy': 0.8884570002555847, 'train/loss': 0.4101370871067047, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 100032.17080593109, 'total_duration': 108309.85451054573, 'accumulated_submission_time': 100032.17080593109, 'accumulated_eval_time': 8250.954582214355, 'accumulated_logging_time': 14.445920705795288}
I0303 17:37:48.374470 140239850956544 logging_writer.py:48] [223884] accumulated_eval_time=8250.954582, accumulated_logging_time=14.445921, accumulated_submission_time=100032.170806, global_step=223884, preemption_count=0, score=100032.170806, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=108309.854511, train/accuracy=0.888457, train/loss=0.410137, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 17:37:55.142540 140239842563840 logging_writer.py:48] [223900] global_step=223900, grad_norm=3.5822343826293945, loss=3.305664300918579
I0303 17:38:36.951911 140239850956544 logging_writer.py:48] [224000] global_step=224000, grad_norm=3.296782970428467, loss=1.1149210929870605
I0303 17:39:21.993954 140239842563840 logging_writer.py:48] [224100] global_step=224100, grad_norm=3.392915964126587, loss=2.90412974357605
I0303 17:40:07.641179 140239850956544 logging_writer.py:48] [224200] global_step=224200, grad_norm=2.9132442474365234, loss=1.1657646894454956
I0303 17:40:52.740964 140239842563840 logging_writer.py:48] [224300] global_step=224300, grad_norm=3.1366045475006104, loss=1.0710880756378174
I0303 17:41:38.181344 140239850956544 logging_writer.py:48] [224400] global_step=224400, grad_norm=3.869364023208618, loss=3.1772799491882324
I0303 17:42:23.395363 140239842563840 logging_writer.py:48] [224500] global_step=224500, grad_norm=3.2110259532928467, loss=1.098696231842041
I0303 17:43:08.619355 140239850956544 logging_writer.py:48] [224600] global_step=224600, grad_norm=3.245706081390381, loss=1.1606717109680176
I0303 17:43:53.883378 140239842563840 logging_writer.py:48] [224700] global_step=224700, grad_norm=3.088843584060669, loss=2.303436040878296
I0303 17:44:38.939434 140239850956544 logging_writer.py:48] [224800] global_step=224800, grad_norm=3.792734384536743, loss=3.301060199737549
I0303 17:44:48.470467 140437341357888 spec.py:321] Evaluating on the training split.
I0303 17:44:58.992738 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 17:45:29.345492 140437341357888 spec.py:349] Evaluating on the test split.
I0303 17:45:30.963189 140437341357888 submission_runner.py:411] Time since start: 108772.51s, 	Step: 224823, 	{'train/accuracy': 0.88734370470047, 'train/loss': 0.4182247519493103, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 100452.20421767235, 'total_duration': 108772.51467132568, 'accumulated_submission_time': 100452.20421767235, 'accumulated_eval_time': 8293.447283029556, 'accumulated_logging_time': 14.529171466827393}
I0303 17:45:31.023818 140239842563840 logging_writer.py:48] [224823] accumulated_eval_time=8293.447283, accumulated_logging_time=14.529171, accumulated_submission_time=100452.204218, global_step=224823, preemption_count=0, score=100452.204218, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=108772.514671, train/accuracy=0.887344, train/loss=0.418225, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 17:46:01.923883 140239850956544 logging_writer.py:48] [224900] global_step=224900, grad_norm=3.7464101314544678, loss=3.1834325790405273
I0303 17:46:46.940116 140239842563840 logging_writer.py:48] [225000] global_step=225000, grad_norm=3.4932079315185547, loss=3.0613954067230225
I0303 17:47:31.961483 140239850956544 logging_writer.py:48] [225100] global_step=225100, grad_norm=3.7076966762542725, loss=2.8527297973632812
I0303 17:48:17.650842 140239842563840 logging_writer.py:48] [225200] global_step=225200, grad_norm=2.8084025382995605, loss=1.9796385765075684
I0303 17:49:02.746630 140239850956544 logging_writer.py:48] [225300] global_step=225300, grad_norm=2.9564895629882812, loss=1.6982003450393677
I0303 17:49:47.869307 140239842563840 logging_writer.py:48] [225400] global_step=225400, grad_norm=2.900416612625122, loss=1.3980162143707275
I0303 17:50:33.063979 140239850956544 logging_writer.py:48] [225500] global_step=225500, grad_norm=3.5964574813842773, loss=1.1585159301757812
I0303 17:51:18.185865 140239842563840 logging_writer.py:48] [225600] global_step=225600, grad_norm=2.9145913124084473, loss=2.3954596519470215
I0303 17:52:03.098688 140239850956544 logging_writer.py:48] [225700] global_step=225700, grad_norm=2.868242025375366, loss=1.0215009450912476
I0303 17:52:31.363957 140437341357888 spec.py:321] Evaluating on the training split.
I0303 17:52:41.643854 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 17:53:13.004118 140437341357888 spec.py:349] Evaluating on the test split.
I0303 17:53:14.619894 140437341357888 submission_runner.py:411] Time since start: 109236.17s, 	Step: 225764, 	{'train/accuracy': 0.8885741829872131, 'train/loss': 0.41569995880126953, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 100872.4828350544, 'total_duration': 109236.17139697075, 'accumulated_submission_time': 100872.4828350544, 'accumulated_eval_time': 8336.703224897385, 'accumulated_logging_time': 14.600011348724365}
I0303 17:53:14.672131 140239842563840 logging_writer.py:48] [225764] accumulated_eval_time=8336.703225, accumulated_logging_time=14.600011, accumulated_submission_time=100872.482835, global_step=225764, preemption_count=0, score=100872.482835, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=109236.171397, train/accuracy=0.888574, train/loss=0.415700, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 17:53:29.332739 140239850956544 logging_writer.py:48] [225800] global_step=225800, grad_norm=3.0654361248016357, loss=1.0623735189437866
I0303 17:54:11.575064 140239842563840 logging_writer.py:48] [225900] global_step=225900, grad_norm=3.152092218399048, loss=1.351469874382019
I0303 17:54:56.642934 140239850956544 logging_writer.py:48] [226000] global_step=226000, grad_norm=2.8548316955566406, loss=1.66683030128479
I0303 17:55:42.112046 140239842563840 logging_writer.py:48] [226100] global_step=226100, grad_norm=3.5365841388702393, loss=3.105379104614258
I0303 17:56:27.252777 140239850956544 logging_writer.py:48] [226200] global_step=226200, grad_norm=3.0486838817596436, loss=1.109952688217163
I0303 17:57:12.750470 140239842563840 logging_writer.py:48] [226300] global_step=226300, grad_norm=3.5713603496551514, loss=1.155220627784729
I0303 17:57:57.742124 140239850956544 logging_writer.py:48] [226400] global_step=226400, grad_norm=3.784667730331421, loss=3.2312018871307373
I0303 17:58:43.259415 140239842563840 logging_writer.py:48] [226500] global_step=226500, grad_norm=3.2550745010375977, loss=2.848282814025879
I0303 17:59:28.415078 140239850956544 logging_writer.py:48] [226600] global_step=226600, grad_norm=2.9744555950164795, loss=1.188714623451233
I0303 18:00:13.597565 140239842563840 logging_writer.py:48] [226700] global_step=226700, grad_norm=3.1237940788269043, loss=2.7477006912231445
I0303 18:00:14.680773 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:00:25.428071 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:00:51.856045 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:00:53.483895 140437341357888 submission_runner.py:411] Time since start: 109695.04s, 	Step: 226704, 	{'train/accuracy': 0.88880854845047, 'train/loss': 0.41335996985435486, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 101292.43042826653, 'total_duration': 109695.03538489342, 'accumulated_submission_time': 101292.43042826653, 'accumulated_eval_time': 8375.506333589554, 'accumulated_logging_time': 14.662203788757324}
I0303 18:00:53.547539 140239850956544 logging_writer.py:48] [226704] accumulated_eval_time=8375.506334, accumulated_logging_time=14.662204, accumulated_submission_time=101292.430428, global_step=226704, preemption_count=0, score=101292.430428, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=109695.035385, train/accuracy=0.888809, train/loss=0.413360, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:01:33.591453 140239842563840 logging_writer.py:48] [226800] global_step=226800, grad_norm=3.0246243476867676, loss=2.502861261367798
I0303 18:02:18.789357 140239850956544 logging_writer.py:48] [226900] global_step=226900, grad_norm=4.157565116882324, loss=3.2737021446228027
I0303 18:03:04.057051 140239842563840 logging_writer.py:48] [227000] global_step=227000, grad_norm=3.0370428562164307, loss=1.1233274936676025
I0303 18:03:49.017632 140239850956544 logging_writer.py:48] [227100] global_step=227100, grad_norm=3.1268043518066406, loss=1.158608078956604
I0303 18:04:34.209571 140239842563840 logging_writer.py:48] [227200] global_step=227200, grad_norm=3.0948712825775146, loss=1.0993669033050537
I0303 18:05:19.469869 140239850956544 logging_writer.py:48] [227300] global_step=227300, grad_norm=2.8775522708892822, loss=1.01605224609375
I0303 18:06:04.742167 140239842563840 logging_writer.py:48] [227400] global_step=227400, grad_norm=2.9106502532958984, loss=2.1748416423797607
I0303 18:06:50.029134 140239850956544 logging_writer.py:48] [227500] global_step=227500, grad_norm=2.8800129890441895, loss=1.2580205202102661
I0303 18:07:35.111655 140239842563840 logging_writer.py:48] [227600] global_step=227600, grad_norm=3.0448930263519287, loss=1.1128993034362793
I0303 18:07:53.760005 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:08:04.663608 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:08:38.801166 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:08:40.427405 140437341357888 submission_runner.py:411] Time since start: 110161.98s, 	Step: 227643, 	{'train/accuracy': 0.8872656226158142, 'train/loss': 0.41604503989219666, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 101712.58194470406, 'total_duration': 110161.97889208794, 'accumulated_submission_time': 101712.58194470406, 'accumulated_eval_time': 8422.173720359802, 'accumulated_logging_time': 14.73522162437439}
I0303 18:08:40.500258 140239850956544 logging_writer.py:48] [227643] accumulated_eval_time=8422.173720, accumulated_logging_time=14.735222, accumulated_submission_time=101712.581945, global_step=227643, preemption_count=0, score=101712.581945, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=110161.978892, train/accuracy=0.887266, train/loss=0.416045, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:09:03.486978 140239842563840 logging_writer.py:48] [227700] global_step=227700, grad_norm=3.4433445930480957, loss=1.1282004117965698
I0303 18:09:47.237998 140239850956544 logging_writer.py:48] [227800] global_step=227800, grad_norm=3.0729410648345947, loss=1.1860812902450562
I0303 18:10:32.706624 140239842563840 logging_writer.py:48] [227900] global_step=227900, grad_norm=2.9608421325683594, loss=1.0032958984375
I0303 18:11:18.190370 140239850956544 logging_writer.py:48] [228000] global_step=228000, grad_norm=4.822113990783691, loss=2.9098591804504395
I0303 18:12:03.341292 140239842563840 logging_writer.py:48] [228100] global_step=228100, grad_norm=3.245546817779541, loss=2.382138729095459
I0303 18:12:48.285949 140239850956544 logging_writer.py:48] [228200] global_step=228200, grad_norm=3.3009252548217773, loss=2.846937656402588
I0303 18:13:33.641586 140239842563840 logging_writer.py:48] [228300] global_step=228300, grad_norm=3.0240159034729004, loss=1.1569432020187378
I0303 18:14:18.842159 140239850956544 logging_writer.py:48] [228400] global_step=228400, grad_norm=3.3387961387634277, loss=1.4350342750549316
I0303 18:15:04.185538 140239842563840 logging_writer.py:48] [228500] global_step=228500, grad_norm=3.065603017807007, loss=1.162974238395691
I0303 18:15:40.528528 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:15:50.977284 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:16:24.250033 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:16:25.870030 140437341357888 submission_runner.py:411] Time since start: 110627.42s, 	Step: 228582, 	{'train/accuracy': 0.8897070288658142, 'train/loss': 0.4089111089706421, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 102132.54553413391, 'total_duration': 110627.42151880264, 'accumulated_submission_time': 102132.54553413391, 'accumulated_eval_time': 8467.515223264694, 'accumulated_logging_time': 14.817797183990479}
I0303 18:16:25.926117 140239850956544 logging_writer.py:48] [228582] accumulated_eval_time=8467.515223, accumulated_logging_time=14.817797, accumulated_submission_time=102132.545534, global_step=228582, preemption_count=0, score=102132.545534, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=110627.421519, train/accuracy=0.889707, train/loss=0.408911, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:16:33.453263 140239842563840 logging_writer.py:48] [228600] global_step=228600, grad_norm=2.989112377166748, loss=1.086918830871582
I0303 18:17:14.868774 140239850956544 logging_writer.py:48] [228700] global_step=228700, grad_norm=3.0477547645568848, loss=2.168069839477539
I0303 18:17:59.504760 140239842563840 logging_writer.py:48] [228800] global_step=228800, grad_norm=2.880950450897217, loss=1.2519828081130981
I0303 18:18:44.797493 140239850956544 logging_writer.py:48] [228900] global_step=228900, grad_norm=3.1594650745391846, loss=2.581233024597168
I0303 18:19:30.654704 140239842563840 logging_writer.py:48] [229000] global_step=229000, grad_norm=3.089277982711792, loss=1.1454423666000366
I0303 18:20:15.745306 140239850956544 logging_writer.py:48] [229100] global_step=229100, grad_norm=2.8631064891815186, loss=1.1562180519104004
I0303 18:21:01.056684 140239842563840 logging_writer.py:48] [229200] global_step=229200, grad_norm=3.2242767810821533, loss=1.1663695573806763
I0303 18:21:46.327758 140239850956544 logging_writer.py:48] [229300] global_step=229300, grad_norm=3.0971779823303223, loss=2.3998584747314453
I0303 18:22:31.869173 140239842563840 logging_writer.py:48] [229400] global_step=229400, grad_norm=3.30726957321167, loss=1.3064473867416382
I0303 18:23:17.375600 140239850956544 logging_writer.py:48] [229500] global_step=229500, grad_norm=3.29007887840271, loss=1.4520231485366821
I0303 18:23:26.105040 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:23:36.642231 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:24:03.645373 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:24:05.290483 140437341357888 submission_runner.py:411] Time since start: 111086.84s, 	Step: 229521, 	{'train/accuracy': 0.8869531154632568, 'train/loss': 0.41677793860435486, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 102552.66275954247, 'total_duration': 111086.84193229675, 'accumulated_submission_time': 102552.66275954247, 'accumulated_eval_time': 8506.700605392456, 'accumulated_logging_time': 14.884428977966309}
I0303 18:24:05.381391 140239842563840 logging_writer.py:48] [229521] accumulated_eval_time=8506.700605, accumulated_logging_time=14.884429, accumulated_submission_time=102552.662760, global_step=229521, preemption_count=0, score=102552.662760, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=111086.841932, train/accuracy=0.886953, train/loss=0.416778, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:24:37.681312 140239850956544 logging_writer.py:48] [229600] global_step=229600, grad_norm=3.761657476425171, loss=3.225978374481201
I0303 18:25:22.441216 140239842563840 logging_writer.py:48] [229700] global_step=229700, grad_norm=3.2989649772644043, loss=1.4127310514450073
I0303 18:26:07.863319 140239850956544 logging_writer.py:48] [229800] global_step=229800, grad_norm=3.1202266216278076, loss=1.0714409351348877
I0303 18:26:53.243333 140239842563840 logging_writer.py:48] [229900] global_step=229900, grad_norm=3.0865068435668945, loss=1.142165184020996
I0303 18:27:38.269437 140239850956544 logging_writer.py:48] [230000] global_step=230000, grad_norm=3.039215564727783, loss=1.1225804090499878
I0303 18:28:23.536896 140239842563840 logging_writer.py:48] [230100] global_step=230100, grad_norm=3.211534023284912, loss=2.203638792037964
I0303 18:29:08.953441 140239850956544 logging_writer.py:48] [230200] global_step=230200, grad_norm=3.432793140411377, loss=3.0662617683410645
I0303 18:29:54.136371 140239842563840 logging_writer.py:48] [230300] global_step=230300, grad_norm=3.3354403972625732, loss=1.711382269859314
I0303 18:30:39.529271 140239850956544 logging_writer.py:48] [230400] global_step=230400, grad_norm=3.9450650215148926, loss=1.41688072681427
I0303 18:31:05.512673 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:31:16.407799 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:31:41.831258 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:31:43.473381 140437341357888 submission_runner.py:411] Time since start: 111545.02s, 	Step: 230459, 	{'train/accuracy': 0.8913085460662842, 'train/loss': 0.40918081998825073, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 102972.72747325897, 'total_duration': 111545.02485179901, 'accumulated_submission_time': 102972.72747325897, 'accumulated_eval_time': 8544.661287546158, 'accumulated_logging_time': 14.990256071090698}
I0303 18:31:43.531192 140239842563840 logging_writer.py:48] [230459] accumulated_eval_time=8544.661288, accumulated_logging_time=14.990256, accumulated_submission_time=102972.727473, global_step=230459, preemption_count=0, score=102972.727473, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=111545.024852, train/accuracy=0.891309, train/loss=0.409181, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:32:00.187220 140239850956544 logging_writer.py:48] [230500] global_step=230500, grad_norm=3.331139087677002, loss=2.778987169265747
I0303 18:32:44.868147 140239842563840 logging_writer.py:48] [230600] global_step=230600, grad_norm=2.8733999729156494, loss=1.2883875370025635
I0303 18:33:30.501455 140239850956544 logging_writer.py:48] [230700] global_step=230700, grad_norm=3.2031619548797607, loss=1.7832696437835693
I0303 18:34:16.270314 140239842563840 logging_writer.py:48] [230800] global_step=230800, grad_norm=3.1211633682250977, loss=1.2402766942977905
I0303 18:35:01.836613 140239850956544 logging_writer.py:48] [230900] global_step=230900, grad_norm=2.860790491104126, loss=1.6569907665252686
I0303 18:35:47.705654 140239842563840 logging_writer.py:48] [231000] global_step=231000, grad_norm=2.9910223484039307, loss=1.02418851852417
I0303 18:36:33.553172 140239850956544 logging_writer.py:48] [231100] global_step=231100, grad_norm=3.1736385822296143, loss=1.2134647369384766
I0303 18:37:19.289650 140239842563840 logging_writer.py:48] [231200] global_step=231200, grad_norm=3.203026533126831, loss=2.5276098251342773
I0303 18:38:05.023850 140239850956544 logging_writer.py:48] [231300] global_step=231300, grad_norm=3.137537956237793, loss=1.1088894605636597
I0303 18:38:43.592568 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:38:54.067426 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:39:23.652530 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:39:25.276063 140437341357888 submission_runner.py:411] Time since start: 112006.83s, 	Step: 231386, 	{'train/accuracy': 0.8886132836341858, 'train/loss': 0.41818568110466003, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 103392.72380638123, 'total_duration': 112006.82755184174, 'accumulated_submission_time': 103392.72380638123, 'accumulated_eval_time': 8586.344784021378, 'accumulated_logging_time': 15.06243109703064}
I0303 18:39:25.339869 140239842563840 logging_writer.py:48] [231386] accumulated_eval_time=8586.344784, accumulated_logging_time=15.062431, accumulated_submission_time=103392.723806, global_step=231386, preemption_count=0, score=103392.723806, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=112006.827552, train/accuracy=0.888613, train/loss=0.418186, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:39:31.282084 140239850956544 logging_writer.py:48] [231400] global_step=231400, grad_norm=3.9146499633789062, loss=3.2473461627960205
I0303 18:40:13.366247 140239842563840 logging_writer.py:48] [231500] global_step=231500, grad_norm=3.114408493041992, loss=1.1068307161331177
I0303 18:40:58.541399 140239850956544 logging_writer.py:48] [231600] global_step=231600, grad_norm=3.2714500427246094, loss=2.912980079650879
I0303 18:41:44.050545 140239842563840 logging_writer.py:48] [231700] global_step=231700, grad_norm=3.710618019104004, loss=2.577857732772827
I0303 18:42:29.562263 140239850956544 logging_writer.py:48] [231800] global_step=231800, grad_norm=3.348564624786377, loss=1.9344887733459473
I0303 18:43:14.787367 140239842563840 logging_writer.py:48] [231900] global_step=231900, grad_norm=3.6829562187194824, loss=3.2360992431640625
I0303 18:44:00.046995 140239850956544 logging_writer.py:48] [232000] global_step=232000, grad_norm=3.2060017585754395, loss=1.2139463424682617
I0303 18:44:45.405216 140239842563840 logging_writer.py:48] [232100] global_step=232100, grad_norm=2.9517810344696045, loss=1.0867582559585571
I0303 18:45:30.880848 140239850956544 logging_writer.py:48] [232200] global_step=232200, grad_norm=3.1231958866119385, loss=1.3622772693634033
I0303 18:46:15.988974 140239842563840 logging_writer.py:48] [232300] global_step=232300, grad_norm=2.996320962905884, loss=1.9106734991073608
I0303 18:46:25.661999 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:46:36.108821 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:47:04.635600 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:47:06.298659 140437341357888 submission_runner.py:411] Time since start: 112467.85s, 	Step: 232323, 	{'train/accuracy': 0.8895898461341858, 'train/loss': 0.41014838218688965, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 103812.9854183197, 'total_duration': 112467.85011029243, 'accumulated_submission_time': 103812.9854183197, 'accumulated_eval_time': 8626.981405496597, 'accumulated_logging_time': 15.136332988739014}
I0303 18:47:06.376332 140239850956544 logging_writer.py:48] [232323] accumulated_eval_time=8626.981405, accumulated_logging_time=15.136333, accumulated_submission_time=103812.985418, global_step=232323, preemption_count=0, score=103812.985418, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=112467.850110, train/accuracy=0.889590, train/loss=0.410148, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:47:37.273602 140239842563840 logging_writer.py:48] [232400] global_step=232400, grad_norm=2.7630774974823, loss=1.6223212480545044
I0303 18:48:21.694202 140239850956544 logging_writer.py:48] [232500] global_step=232500, grad_norm=3.1140308380126953, loss=1.1270461082458496
I0303 18:49:06.496732 140239842563840 logging_writer.py:48] [232600] global_step=232600, grad_norm=2.927264451980591, loss=2.5516653060913086
I0303 18:49:52.164509 140239850956544 logging_writer.py:48] [232700] global_step=232700, grad_norm=2.9496214389801025, loss=1.1486763954162598
I0303 18:50:37.321072 140239842563840 logging_writer.py:48] [232800] global_step=232800, grad_norm=3.9377171993255615, loss=3.2185325622558594
I0303 18:51:22.247491 140239850956544 logging_writer.py:48] [232900] global_step=232900, grad_norm=2.826991319656372, loss=1.4405949115753174
I0303 18:52:07.582289 140239842563840 logging_writer.py:48] [233000] global_step=233000, grad_norm=3.13936185836792, loss=1.1517657041549683
I0303 18:52:52.684040 140239850956544 logging_writer.py:48] [233100] global_step=233100, grad_norm=3.221379518508911, loss=1.122613787651062
I0303 18:53:38.250663 140239842563840 logging_writer.py:48] [233200] global_step=233200, grad_norm=2.9039857387542725, loss=1.9998868703842163
I0303 18:54:06.506560 140437341357888 spec.py:321] Evaluating on the training split.
I0303 18:54:16.873939 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 18:54:41.659661 140437341357888 spec.py:349] Evaluating on the test split.
I0303 18:54:43.280112 140437341357888 submission_runner.py:411] Time since start: 112924.83s, 	Step: 233264, 	{'train/accuracy': 0.8911718726158142, 'train/loss': 0.40896210074424744, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 104233.0490720272, 'total_duration': 112924.8316013813, 'accumulated_submission_time': 104233.0490720272, 'accumulated_eval_time': 8663.754947662354, 'accumulated_logging_time': 15.229785442352295}
I0303 18:54:43.344054 140239850956544 logging_writer.py:48] [233264] accumulated_eval_time=8663.754948, accumulated_logging_time=15.229785, accumulated_submission_time=104233.049072, global_step=233264, preemption_count=0, score=104233.049072, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=112924.831601, train/accuracy=0.891172, train/loss=0.408962, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 18:54:58.033516 140239842563840 logging_writer.py:48] [233300] global_step=233300, grad_norm=3.187147855758667, loss=1.077579379081726
I0303 18:55:41.133396 140239850956544 logging_writer.py:48] [233400] global_step=233400, grad_norm=2.8911032676696777, loss=1.5965272188186646
I0303 18:56:26.346036 140239842563840 logging_writer.py:48] [233500] global_step=233500, grad_norm=3.1681876182556152, loss=2.2457637786865234
I0303 18:57:11.761877 140239850956544 logging_writer.py:48] [233600] global_step=233600, grad_norm=3.208249568939209, loss=2.903433084487915
I0303 18:57:56.882507 140239842563840 logging_writer.py:48] [233700] global_step=233700, grad_norm=3.3859081268310547, loss=1.2189397811889648
I0303 18:58:41.888490 140239850956544 logging_writer.py:48] [233800] global_step=233800, grad_norm=2.9460175037384033, loss=1.2206047773361206
I0303 18:59:27.163564 140239842563840 logging_writer.py:48] [233900] global_step=233900, grad_norm=3.0660176277160645, loss=1.1200523376464844
I0303 19:00:12.632303 140239850956544 logging_writer.py:48] [234000] global_step=234000, grad_norm=3.1766629219055176, loss=1.9803396463394165
I0303 19:00:57.789121 140239842563840 logging_writer.py:48] [234100] global_step=234100, grad_norm=3.0520899295806885, loss=1.060736060142517
I0303 19:01:43.189890 140239850956544 logging_writer.py:48] [234200] global_step=234200, grad_norm=3.8156654834747314, loss=3.201122522354126
I0303 19:01:43.353882 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:01:53.842458 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:02:21.636854 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:02:23.267317 140437341357888 submission_runner.py:411] Time since start: 113384.82s, 	Step: 234202, 	{'train/accuracy': 0.8874609470367432, 'train/loss': 0.4192294180393219, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 104652.99808740616, 'total_duration': 113384.81877231598, 'accumulated_submission_time': 104652.99808740616, 'accumulated_eval_time': 8703.668316602707, 'accumulated_logging_time': 15.304007768630981}
I0303 19:02:23.327602 140239842563840 logging_writer.py:48] [234202] accumulated_eval_time=8703.668317, accumulated_logging_time=15.304008, accumulated_submission_time=104652.998087, global_step=234202, preemption_count=0, score=104652.998087, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=113384.818772, train/accuracy=0.887461, train/loss=0.419229, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:03:04.338313 140239850956544 logging_writer.py:48] [234300] global_step=234300, grad_norm=3.2114431858062744, loss=1.1048052310943604
I0303 19:03:49.566979 140239842563840 logging_writer.py:48] [234400] global_step=234400, grad_norm=3.074612617492676, loss=1.1430652141571045
I0303 19:04:34.962909 140239850956544 logging_writer.py:48] [234500] global_step=234500, grad_norm=2.828770875930786, loss=2.3422369956970215
I0303 19:05:20.216550 140239842563840 logging_writer.py:48] [234600] global_step=234600, grad_norm=2.9124443531036377, loss=1.4688758850097656
I0303 19:06:05.887168 140239850956544 logging_writer.py:48] [234700] global_step=234700, grad_norm=3.6236824989318848, loss=3.2622287273406982
I0303 19:06:51.472366 140239842563840 logging_writer.py:48] [234800] global_step=234800, grad_norm=2.9810550212860107, loss=1.5740551948547363
I0303 19:07:36.736406 140239850956544 logging_writer.py:48] [234900] global_step=234900, grad_norm=3.142106056213379, loss=1.029119849205017
I0303 19:08:22.092752 140239842563840 logging_writer.py:48] [235000] global_step=235000, grad_norm=3.098982095718384, loss=2.7175683975219727
I0303 19:09:07.321630 140239850956544 logging_writer.py:48] [235100] global_step=235100, grad_norm=3.6454076766967773, loss=3.2151646614074707
I0303 19:09:23.381301 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:09:34.137027 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:10:00.218602 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:10:01.843467 140437341357888 submission_runner.py:411] Time since start: 113843.39s, 	Step: 235137, 	{'train/accuracy': 0.8865624666213989, 'train/loss': 0.41757380962371826, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 105072.99116683006, 'total_duration': 113843.39495277405, 'accumulated_submission_time': 105072.99116683006, 'accumulated_eval_time': 8742.130467414856, 'accumulated_logging_time': 15.374670505523682}
I0303 19:10:01.908723 140239842563840 logging_writer.py:48] [235137] accumulated_eval_time=8742.130467, accumulated_logging_time=15.374671, accumulated_submission_time=105072.991167, global_step=235137, preemption_count=0, score=105072.991167, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=113843.394953, train/accuracy=0.886562, train/loss=0.417574, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:10:27.562852 140239850956544 logging_writer.py:48] [235200] global_step=235200, grad_norm=3.1614434719085693, loss=1.8442949056625366
I0303 19:11:12.467920 140239842563840 logging_writer.py:48] [235300] global_step=235300, grad_norm=3.024923086166382, loss=2.7620537281036377
I0303 19:11:57.722585 140239850956544 logging_writer.py:48] [235400] global_step=235400, grad_norm=3.066190481185913, loss=1.1557857990264893
I0303 19:12:42.985338 140239842563840 logging_writer.py:48] [235500] global_step=235500, grad_norm=2.869619607925415, loss=1.8978819847106934
I0303 19:13:28.586490 140239850956544 logging_writer.py:48] [235600] global_step=235600, grad_norm=2.932680130004883, loss=1.3636170625686646
I0303 19:14:13.848789 140239842563840 logging_writer.py:48] [235700] global_step=235700, grad_norm=3.807034730911255, loss=3.0582194328308105
I0303 19:14:59.135352 140239850956544 logging_writer.py:48] [235800] global_step=235800, grad_norm=2.952505111694336, loss=1.0808935165405273
I0303 19:15:44.632059 140239842563840 logging_writer.py:48] [235900] global_step=235900, grad_norm=3.1137712001800537, loss=2.5134432315826416
I0303 19:16:29.913077 140239850956544 logging_writer.py:48] [236000] global_step=236000, grad_norm=3.197486400604248, loss=1.0868914127349854
I0303 19:17:02.257701 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:17:12.446662 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:17:40.710589 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:17:42.334491 140437341357888 submission_runner.py:411] Time since start: 114303.89s, 	Step: 236073, 	{'train/accuracy': 0.8865820169448853, 'train/loss': 0.418828547000885, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 105493.27949905396, 'total_duration': 114303.88598370552, 'accumulated_submission_time': 105493.27949905396, 'accumulated_eval_time': 8782.207236289978, 'accumulated_logging_time': 15.449368953704834}
I0303 19:17:42.401117 140239842563840 logging_writer.py:48] [236073] accumulated_eval_time=8782.207236, accumulated_logging_time=15.449369, accumulated_submission_time=105493.279499, global_step=236073, preemption_count=0, score=105493.279499, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=114303.885984, train/accuracy=0.886582, train/loss=0.418829, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:17:53.514459 140239850956544 logging_writer.py:48] [236100] global_step=236100, grad_norm=3.0109663009643555, loss=1.179999828338623
I0303 19:18:36.264297 140239842563840 logging_writer.py:48] [236200] global_step=236200, grad_norm=2.945552349090576, loss=1.101951003074646
I0303 19:19:21.329170 140239850956544 logging_writer.py:48] [236300] global_step=236300, grad_norm=4.411566734313965, loss=1.2339950799942017
I0303 19:20:06.467534 140239842563840 logging_writer.py:48] [236400] global_step=236400, grad_norm=3.1333186626434326, loss=2.297250509262085
I0303 19:20:51.844574 140239850956544 logging_writer.py:48] [236500] global_step=236500, grad_norm=3.2068543434143066, loss=2.9127652645111084
I0303 19:21:37.046974 140239842563840 logging_writer.py:48] [236600] global_step=236600, grad_norm=3.3506524562835693, loss=3.0082125663757324
I0303 19:22:22.297013 140239850956544 logging_writer.py:48] [236700] global_step=236700, grad_norm=3.5061793327331543, loss=1.1470272541046143
I0303 19:23:07.681762 140239842563840 logging_writer.py:48] [236800] global_step=236800, grad_norm=3.1044681072235107, loss=2.640097141265869
I0303 19:23:52.871967 140239850956544 logging_writer.py:48] [236900] global_step=236900, grad_norm=3.299482583999634, loss=1.2921406030654907
I0303 19:24:38.077443 140239842563840 logging_writer.py:48] [237000] global_step=237000, grad_norm=3.234064817428589, loss=1.4066755771636963
I0303 19:24:42.724717 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:24:52.816725 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:25:19.586227 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:25:21.210771 140437341357888 submission_runner.py:411] Time since start: 114762.76s, 	Step: 237012, 	{'train/accuracy': 0.8889843821525574, 'train/loss': 0.4155234694480896, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 105913.54170560837, 'total_duration': 114762.76225996017, 'accumulated_submission_time': 105913.54170560837, 'accumulated_eval_time': 8820.693273544312, 'accumulated_logging_time': 15.526480674743652}
I0303 19:25:21.280448 140239850956544 logging_writer.py:48] [237012] accumulated_eval_time=8820.693274, accumulated_logging_time=15.526481, accumulated_submission_time=105913.541706, global_step=237012, preemption_count=0, score=105913.541706, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=114762.762260, train/accuracy=0.888984, train/loss=0.415523, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:25:57.272219 140239842563840 logging_writer.py:48] [237100] global_step=237100, grad_norm=2.8870911598205566, loss=1.8229340314865112
I0303 19:26:42.741415 140239850956544 logging_writer.py:48] [237200] global_step=237200, grad_norm=2.984325647354126, loss=1.837172269821167
I0303 19:27:28.073708 140239842563840 logging_writer.py:48] [237300] global_step=237300, grad_norm=4.740239143371582, loss=3.2386813163757324
I0303 19:28:13.559227 140239850956544 logging_writer.py:48] [237400] global_step=237400, grad_norm=3.3135149478912354, loss=2.9093515872955322
I0303 19:28:58.740697 140239842563840 logging_writer.py:48] [237500] global_step=237500, grad_norm=3.062425374984741, loss=1.7055577039718628
I0303 19:29:44.070982 140239850956544 logging_writer.py:48] [237600] global_step=237600, grad_norm=3.013582229614258, loss=2.6191983222961426
I0303 19:30:29.824897 140239842563840 logging_writer.py:48] [237700] global_step=237700, grad_norm=3.2543041706085205, loss=1.2726868391036987
I0303 19:31:15.341787 140239850956544 logging_writer.py:48] [237800] global_step=237800, grad_norm=3.0995707511901855, loss=1.1169744729995728
I0303 19:32:00.556094 140239842563840 logging_writer.py:48] [237900] global_step=237900, grad_norm=2.9104795455932617, loss=2.351672410964966
I0303 19:32:21.716720 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:32:32.026602 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:33:05.556756 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:33:07.184954 140437341357888 submission_runner.py:411] Time since start: 115228.74s, 	Step: 237948, 	{'train/accuracy': 0.8892773389816284, 'train/loss': 0.4160856008529663, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 106333.91696500778, 'total_duration': 115228.73643136024, 'accumulated_submission_time': 106333.91696500778, 'accumulated_eval_time': 8866.161488056183, 'accumulated_logging_time': 15.605794191360474}
I0303 19:33:07.246740 140239850956544 logging_writer.py:48] [237948] accumulated_eval_time=8866.161488, accumulated_logging_time=15.605794, accumulated_submission_time=106333.916965, global_step=237948, preemption_count=0, score=106333.916965, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=115228.736431, train/accuracy=0.889277, train/loss=0.416086, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:33:28.229610 140239842563840 logging_writer.py:48] [238000] global_step=238000, grad_norm=2.8131039142608643, loss=1.227494239807129
I0303 19:34:10.807186 140239850956544 logging_writer.py:48] [238100] global_step=238100, grad_norm=2.9681951999664307, loss=1.8976349830627441
I0303 19:34:56.259456 140239842563840 logging_writer.py:48] [238200] global_step=238200, grad_norm=2.9352259635925293, loss=1.204513430595398
I0303 19:35:41.493153 140239850956544 logging_writer.py:48] [238300] global_step=238300, grad_norm=3.235372543334961, loss=1.1957519054412842
I0303 19:36:26.951546 140239842563840 logging_writer.py:48] [238400] global_step=238400, grad_norm=3.0516161918640137, loss=1.055945634841919
I0303 19:37:12.524882 140239850956544 logging_writer.py:48] [238500] global_step=238500, grad_norm=3.3152730464935303, loss=1.109750509262085
I0303 19:37:57.570705 140239842563840 logging_writer.py:48] [238600] global_step=238600, grad_norm=3.023892402648926, loss=1.3198374509811401
I0303 19:38:42.803869 140239850956544 logging_writer.py:48] [238700] global_step=238700, grad_norm=3.03818416595459, loss=2.4995298385620117
I0303 19:39:28.176315 140239842563840 logging_writer.py:48] [238800] global_step=238800, grad_norm=3.1008353233337402, loss=1.1423990726470947
I0303 19:40:07.403975 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:40:17.382811 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:40:44.564331 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:40:46.186125 140437341357888 submission_runner.py:411] Time since start: 115687.74s, 	Step: 238888, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.41338518261909485, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 106754.01340723038, 'total_duration': 115687.73761057854, 'accumulated_submission_time': 106754.01340723038, 'accumulated_eval_time': 8904.943639278412, 'accumulated_logging_time': 15.677077531814575}
I0303 19:40:46.250056 140239850956544 logging_writer.py:48] [238888] accumulated_eval_time=8904.943639, accumulated_logging_time=15.677078, accumulated_submission_time=106754.013407, global_step=238888, preemption_count=0, score=106754.013407, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=115687.737611, train/accuracy=0.887227, train/loss=0.413385, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:40:51.420939 140239842563840 logging_writer.py:48] [238900] global_step=238900, grad_norm=3.066192626953125, loss=1.0510061979293823
I0303 19:41:33.316385 140239850956544 logging_writer.py:48] [239000] global_step=239000, grad_norm=2.9143049716949463, loss=1.1070899963378906
I0303 19:42:18.408529 140239842563840 logging_writer.py:48] [239100] global_step=239100, grad_norm=2.7868998050689697, loss=1.0406311750411987
I0303 19:43:03.835180 140239850956544 logging_writer.py:48] [239200] global_step=239200, grad_norm=3.2280561923980713, loss=1.1107983589172363
I0303 19:43:48.885264 140239842563840 logging_writer.py:48] [239300] global_step=239300, grad_norm=3.619951009750366, loss=1.073285460472107
I0303 19:44:33.763027 140239850956544 logging_writer.py:48] [239400] global_step=239400, grad_norm=3.1705498695373535, loss=2.3003969192504883
I0303 19:45:18.896944 140239842563840 logging_writer.py:48] [239500] global_step=239500, grad_norm=3.028313398361206, loss=1.5359015464782715
I0303 19:46:04.195987 140239850956544 logging_writer.py:48] [239600] global_step=239600, grad_norm=3.08927321434021, loss=2.5838918685913086
I0303 19:46:49.264055 140239842563840 logging_writer.py:48] [239700] global_step=239700, grad_norm=2.870683193206787, loss=1.2059791088104248
I0303 19:47:34.390585 140239850956544 logging_writer.py:48] [239800] global_step=239800, grad_norm=3.2395315170288086, loss=1.1652590036392212
I0303 19:47:46.585852 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:47:57.107699 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:48:21.643258 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:48:23.263428 140437341357888 submission_runner.py:411] Time since start: 116144.81s, 	Step: 239829, 	{'train/accuracy': 0.8869531154632568, 'train/loss': 0.42123910784721375, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 107174.28653025627, 'total_duration': 116144.81491804123, 'accumulated_submission_time': 107174.28653025627, 'accumulated_eval_time': 8941.621190309525, 'accumulated_logging_time': 15.752530097961426}
I0303 19:48:23.327402 140239842563840 logging_writer.py:48] [239829] accumulated_eval_time=8941.621190, accumulated_logging_time=15.752530, accumulated_submission_time=107174.286530, global_step=239829, preemption_count=0, score=107174.286530, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=116144.814918, train/accuracy=0.886953, train/loss=0.421239, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:48:52.089749 140239850956544 logging_writer.py:48] [239900] global_step=239900, grad_norm=3.084277868270874, loss=1.025867223739624
I0303 19:49:36.938785 140239842563840 logging_writer.py:48] [240000] global_step=240000, grad_norm=3.239630699157715, loss=2.654327392578125
I0303 19:50:21.979496 140239850956544 logging_writer.py:48] [240100] global_step=240100, grad_norm=3.6823830604553223, loss=3.1399426460266113
I0303 19:51:07.242420 140239842563840 logging_writer.py:48] [240200] global_step=240200, grad_norm=2.966341018676758, loss=2.3014988899230957
I0303 19:51:52.832830 140239850956544 logging_writer.py:48] [240300] global_step=240300, grad_norm=3.0080575942993164, loss=1.1300013065338135
I0303 19:52:37.960760 140239842563840 logging_writer.py:48] [240400] global_step=240400, grad_norm=3.1893904209136963, loss=1.766491413116455
I0303 19:53:23.381837 140239850956544 logging_writer.py:48] [240500] global_step=240500, grad_norm=3.0194365978240967, loss=1.9358389377593994
I0303 19:54:08.807892 140239842563840 logging_writer.py:48] [240600] global_step=240600, grad_norm=3.5988595485687256, loss=3.246176242828369
I0303 19:54:53.955578 140239850956544 logging_writer.py:48] [240700] global_step=240700, grad_norm=3.1691668033599854, loss=1.1948503255844116
I0303 19:55:23.598152 140437341357888 spec.py:321] Evaluating on the training split.
I0303 19:55:34.017542 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 19:55:59.332678 140437341357888 spec.py:349] Evaluating on the test split.
I0303 19:56:00.949999 140437341357888 submission_runner.py:411] Time since start: 116602.50s, 	Step: 240767, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.41033458709716797, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 107594.49706172943, 'total_duration': 116602.501486063, 'accumulated_submission_time': 107594.49706172943, 'accumulated_eval_time': 8978.973022460938, 'accumulated_logging_time': 15.825635433197021}
I0303 19:56:01.015323 140239842563840 logging_writer.py:48] [240767] accumulated_eval_time=8978.973022, accumulated_logging_time=15.825635, accumulated_submission_time=107594.497062, global_step=240767, preemption_count=0, score=107594.497062, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=116602.501486, train/accuracy=0.888906, train/loss=0.410335, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 19:56:14.492296 140239850956544 logging_writer.py:48] [240800] global_step=240800, grad_norm=3.2555055618286133, loss=1.1334359645843506
I0303 19:56:57.851842 140239842563840 logging_writer.py:48] [240900] global_step=240900, grad_norm=3.2330269813537598, loss=1.1995353698730469
I0303 19:57:42.872293 140239850956544 logging_writer.py:48] [241000] global_step=241000, grad_norm=3.022477865219116, loss=1.3266080617904663
I0303 19:58:28.082142 140239842563840 logging_writer.py:48] [241100] global_step=241100, grad_norm=2.8142004013061523, loss=1.222524642944336
I0303 19:59:13.683319 140239850956544 logging_writer.py:48] [241200] global_step=241200, grad_norm=3.6700096130371094, loss=2.8063652515411377
I0303 19:59:58.631622 140239842563840 logging_writer.py:48] [241300] global_step=241300, grad_norm=2.9436709880828857, loss=1.179540753364563
I0303 20:00:44.068012 140239850956544 logging_writer.py:48] [241400] global_step=241400, grad_norm=3.145014524459839, loss=2.569920539855957
I0303 20:01:29.612951 140239842563840 logging_writer.py:48] [241500] global_step=241500, grad_norm=2.993222236633301, loss=1.143865704536438
I0303 20:02:14.689349 140239850956544 logging_writer.py:48] [241600] global_step=241600, grad_norm=4.299043655395508, loss=3.2536139488220215
I0303 20:02:59.892536 140239842563840 logging_writer.py:48] [241700] global_step=241700, grad_norm=3.008643627166748, loss=1.3117517232894897
I0303 20:03:01.381734 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:03:11.810637 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:03:41.728138 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:03:43.359267 140437341357888 submission_runner.py:411] Time since start: 117064.91s, 	Step: 241705, 	{'train/accuracy': 0.8889257907867432, 'train/loss': 0.4125271141529083, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 108014.80342388153, 'total_duration': 117064.91074442863, 'accumulated_submission_time': 108014.80342388153, 'accumulated_eval_time': 9020.95052599907, 'accumulated_logging_time': 15.900647640228271}
I0303 20:03:43.424574 140239850956544 logging_writer.py:48] [241705] accumulated_eval_time=9020.950526, accumulated_logging_time=15.900648, accumulated_submission_time=108014.803424, global_step=241705, preemption_count=0, score=108014.803424, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=117064.910744, train/accuracy=0.888926, train/loss=0.412527, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:04:22.463145 140239842563840 logging_writer.py:48] [241800] global_step=241800, grad_norm=3.1428987979888916, loss=1.2061126232147217
I0303 20:05:07.693797 140239850956544 logging_writer.py:48] [241900] global_step=241900, grad_norm=3.0006320476531982, loss=1.4046355485916138
I0303 20:05:53.133335 140239842563840 logging_writer.py:48] [242000] global_step=242000, grad_norm=3.6207995414733887, loss=3.189014434814453
I0303 20:06:38.398599 140239850956544 logging_writer.py:48] [242100] global_step=242100, grad_norm=2.8835158348083496, loss=2.124589204788208
I0303 20:07:23.788102 140239842563840 logging_writer.py:48] [242200] global_step=242200, grad_norm=2.9614100456237793, loss=1.4004501104354858
I0303 20:08:09.007502 140239850956544 logging_writer.py:48] [242300] global_step=242300, grad_norm=3.261908531188965, loss=1.8249642848968506
I0303 20:08:54.162107 140239842563840 logging_writer.py:48] [242400] global_step=242400, grad_norm=3.156859874725342, loss=1.3525264263153076
I0303 20:09:39.390505 140239850956544 logging_writer.py:48] [242500] global_step=242500, grad_norm=3.042022228240967, loss=1.0822879076004028
I0303 20:10:24.462770 140239842563840 logging_writer.py:48] [242600] global_step=242600, grad_norm=3.2515082359313965, loss=1.8057527542114258
I0303 20:10:43.606141 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:10:53.711373 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:11:20.408867 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:11:22.029793 140437341357888 submission_runner.py:411] Time since start: 117523.58s, 	Step: 242644, 	{'train/accuracy': 0.8873046636581421, 'train/loss': 0.41702428460121155, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 108434.92385172844, 'total_duration': 117523.58127760887, 'accumulated_submission_time': 108434.92385172844, 'accumulated_eval_time': 9059.374162912369, 'accumulated_logging_time': 15.975814819335938}
I0303 20:11:22.097249 140239850956544 logging_writer.py:48] [242644] accumulated_eval_time=9059.374163, accumulated_logging_time=15.975815, accumulated_submission_time=108434.923852, global_step=242644, preemption_count=0, score=108434.923852, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=117523.581278, train/accuracy=0.887305, train/loss=0.417024, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:11:44.682880 140239842563840 logging_writer.py:48] [242700] global_step=242700, grad_norm=2.8472814559936523, loss=1.0913856029510498
I0303 20:12:28.821134 140239850956544 logging_writer.py:48] [242800] global_step=242800, grad_norm=2.89408278465271, loss=1.136438250541687
I0303 20:13:14.154165 140239842563840 logging_writer.py:48] [242900] global_step=242900, grad_norm=3.020343780517578, loss=1.76264226436615
I0303 20:13:59.429378 140239850956544 logging_writer.py:48] [243000] global_step=243000, grad_norm=2.8620502948760986, loss=1.8634443283081055
I0303 20:14:44.901141 140239842563840 logging_writer.py:48] [243100] global_step=243100, grad_norm=3.4387996196746826, loss=2.949308156967163
I0303 20:15:31.691162 140239850956544 logging_writer.py:48] [243200] global_step=243200, grad_norm=3.762693166732788, loss=2.2205634117126465
I0303 20:16:17.186614 140239842563840 logging_writer.py:48] [243300] global_step=243300, grad_norm=3.4810101985931396, loss=2.998185157775879
I0303 20:17:02.503976 140239850956544 logging_writer.py:48] [243400] global_step=243400, grad_norm=3.1715335845947266, loss=1.0691713094711304
I0303 20:17:47.833756 140239842563840 logging_writer.py:48] [243500] global_step=243500, grad_norm=2.9680402278900146, loss=1.3562448024749756
I0303 20:18:22.461821 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:18:32.767250 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:18:58.680939 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:19:00.301796 140437341357888 submission_runner.py:411] Time since start: 117981.85s, 	Step: 243578, 	{'train/accuracy': 0.8865820169448853, 'train/loss': 0.42238470911979675, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 108855.2262763977, 'total_duration': 117981.85328555107, 'accumulated_submission_time': 108855.2262763977, 'accumulated_eval_time': 9097.214118480682, 'accumulated_logging_time': 16.05459976196289}
I0303 20:19:00.370706 140239850956544 logging_writer.py:48] [243578] accumulated_eval_time=9097.214118, accumulated_logging_time=16.054600, accumulated_submission_time=108855.226276, global_step=243578, preemption_count=0, score=108855.226276, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=117981.853286, train/accuracy=0.886582, train/loss=0.422385, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:19:09.506031 140239842563840 logging_writer.py:48] [243600] global_step=243600, grad_norm=3.077596664428711, loss=1.1189733743667603
I0303 20:19:52.088920 140239850956544 logging_writer.py:48] [243700] global_step=243700, grad_norm=2.864762306213379, loss=1.1121234893798828
I0303 20:20:37.119484 140239842563840 logging_writer.py:48] [243800] global_step=243800, grad_norm=3.4331367015838623, loss=3.152423143386841
I0303 20:21:22.576596 140239850956544 logging_writer.py:48] [243900] global_step=243900, grad_norm=3.0620954036712646, loss=1.0830326080322266
I0303 20:22:08.259992 140239842563840 logging_writer.py:48] [244000] global_step=244000, grad_norm=3.6189239025115967, loss=3.233534574508667
I0303 20:22:53.274548 140239850956544 logging_writer.py:48] [244100] global_step=244100, grad_norm=3.1453938484191895, loss=1.264880895614624
I0303 20:23:38.509868 140239842563840 logging_writer.py:48] [244200] global_step=244200, grad_norm=2.9992265701293945, loss=1.121293067932129
I0303 20:24:23.852957 140239850956544 logging_writer.py:48] [244300] global_step=244300, grad_norm=3.231412172317505, loss=1.0877101421356201
I0303 20:25:09.133373 140239842563840 logging_writer.py:48] [244400] global_step=244400, grad_norm=3.3333277702331543, loss=2.827482223510742
I0303 20:25:54.414181 140239850956544 logging_writer.py:48] [244500] global_step=244500, grad_norm=3.124532699584961, loss=1.1245635747909546
I0303 20:26:00.413118 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:26:10.745063 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:26:38.787928 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:26:40.403419 140437341357888 submission_runner.py:411] Time since start: 118441.95s, 	Step: 244515, 	{'train/accuracy': 0.8882226347923279, 'train/loss': 0.41389209032058716, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 109275.20730948448, 'total_duration': 118441.95490217209, 'accumulated_submission_time': 109275.20730948448, 'accumulated_eval_time': 9137.204396724701, 'accumulated_logging_time': 16.133418798446655}
I0303 20:26:40.467207 140239842563840 logging_writer.py:48] [244515] accumulated_eval_time=9137.204397, accumulated_logging_time=16.133419, accumulated_submission_time=109275.207309, global_step=244515, preemption_count=0, score=109275.207309, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=118441.954902, train/accuracy=0.888223, train/loss=0.413892, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:27:14.955932 140239850956544 logging_writer.py:48] [244600] global_step=244600, grad_norm=3.197873592376709, loss=1.134800910949707
I0303 20:28:00.017166 140239842563840 logging_writer.py:48] [244700] global_step=244700, grad_norm=4.329953670501709, loss=2.9737181663513184
I0303 20:28:45.492721 140239850956544 logging_writer.py:48] [244800] global_step=244800, grad_norm=3.3793084621429443, loss=3.180985927581787
I0303 20:29:30.471810 140239842563840 logging_writer.py:48] [244900] global_step=244900, grad_norm=3.0530881881713867, loss=1.8594390153884888
I0303 20:30:15.819767 140239850956544 logging_writer.py:48] [245000] global_step=245000, grad_norm=2.8865177631378174, loss=2.405120372772217
I0303 20:31:01.099380 140239842563840 logging_writer.py:48] [245100] global_step=245100, grad_norm=3.0666909217834473, loss=1.1667699813842773
I0303 20:31:46.261962 140239850956544 logging_writer.py:48] [245200] global_step=245200, grad_norm=3.239053726196289, loss=1.0814443826675415
I0303 20:32:31.633707 140239842563840 logging_writer.py:48] [245300] global_step=245300, grad_norm=2.7458736896514893, loss=1.1512349843978882
I0303 20:33:17.067767 140239850956544 logging_writer.py:48] [245400] global_step=245400, grad_norm=2.924030065536499, loss=1.0783766508102417
I0303 20:33:40.607668 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:33:50.816173 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:34:17.548234 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:34:19.177675 140437341357888 submission_runner.py:411] Time since start: 118900.73s, 	Step: 245454, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.4170665740966797, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 109695.28633069992, 'total_duration': 118900.72915911674, 'accumulated_submission_time': 109695.28633069992, 'accumulated_eval_time': 9175.77440404892, 'accumulated_logging_time': 16.207163333892822}
I0303 20:34:19.244468 140239842563840 logging_writer.py:48] [245454] accumulated_eval_time=9175.774404, accumulated_logging_time=16.207163, accumulated_submission_time=109695.286331, global_step=245454, preemption_count=0, score=109695.286331, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=118900.729159, train/accuracy=0.887500, train/loss=0.417067, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:34:37.868866 140239850956544 logging_writer.py:48] [245500] global_step=245500, grad_norm=2.9717540740966797, loss=1.2126374244689941
I0303 20:35:21.589180 140239842563840 logging_writer.py:48] [245600] global_step=245600, grad_norm=2.9021894931793213, loss=1.1233952045440674
I0303 20:36:06.966778 140239850956544 logging_writer.py:48] [245700] global_step=245700, grad_norm=3.574089765548706, loss=3.1345839500427246
I0303 20:36:52.283668 140239842563840 logging_writer.py:48] [245800] global_step=245800, grad_norm=3.833232879638672, loss=3.3098721504211426
I0303 20:37:37.464227 140239850956544 logging_writer.py:48] [245900] global_step=245900, grad_norm=3.247684955596924, loss=2.3507730960845947
I0303 20:38:22.694996 140239842563840 logging_writer.py:48] [246000] global_step=246000, grad_norm=3.040199041366577, loss=1.1795806884765625
I0303 20:39:07.850258 140239850956544 logging_writer.py:48] [246100] global_step=246100, grad_norm=3.0471482276916504, loss=1.1033215522766113
I0303 20:39:52.986817 140239842563840 logging_writer.py:48] [246200] global_step=246200, grad_norm=2.987013578414917, loss=1.3108916282653809
I0303 20:40:38.268630 140239850956544 logging_writer.py:48] [246300] global_step=246300, grad_norm=3.1881539821624756, loss=1.1641308069229126
I0303 20:41:19.346672 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:41:29.588136 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:41:56.210935 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:41:57.839908 140437341357888 submission_runner.py:411] Time since start: 119359.39s, 	Step: 246392, 	{'train/accuracy': 0.8889257907867432, 'train/loss': 0.41718822717666626, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 110115.32331180573, 'total_duration': 119359.3913846016, 'accumulated_submission_time': 110115.32331180573, 'accumulated_eval_time': 9214.267620325089, 'accumulated_logging_time': 16.286096334457397}
I0303 20:41:57.907500 140239842563840 logging_writer.py:48] [246392] accumulated_eval_time=9214.267620, accumulated_logging_time=16.286096, accumulated_submission_time=110115.323312, global_step=246392, preemption_count=0, score=110115.323312, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=119359.391385, train/accuracy=0.888926, train/loss=0.417188, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:42:01.503894 140239850956544 logging_writer.py:48] [246400] global_step=246400, grad_norm=3.7224371433258057, loss=1.1884872913360596
I0303 20:42:43.289242 140239842563840 logging_writer.py:48] [246500] global_step=246500, grad_norm=2.988302230834961, loss=2.1567745208740234
I0303 20:43:28.564131 140239850956544 logging_writer.py:48] [246600] global_step=246600, grad_norm=3.085742712020874, loss=2.114093065261841
I0303 20:44:13.690742 140239842563840 logging_writer.py:48] [246700] global_step=246700, grad_norm=2.820976734161377, loss=1.9973801374435425
I0303 20:44:58.626155 140239850956544 logging_writer.py:48] [246800] global_step=246800, grad_norm=3.336885452270508, loss=1.0801159143447876
I0303 20:45:43.794828 140239842563840 logging_writer.py:48] [246900] global_step=246900, grad_norm=2.8865652084350586, loss=1.9772497415542603
I0303 20:46:29.123507 140239850956544 logging_writer.py:48] [247000] global_step=247000, grad_norm=4.07040548324585, loss=3.1513164043426514
I0303 20:47:14.372347 140239842563840 logging_writer.py:48] [247100] global_step=247100, grad_norm=3.023073434829712, loss=1.1938635110855103
I0303 20:47:59.547625 140239850956544 logging_writer.py:48] [247200] global_step=247200, grad_norm=3.867812156677246, loss=2.8875582218170166
I0303 20:48:44.660734 140239842563840 logging_writer.py:48] [247300] global_step=247300, grad_norm=3.1353795528411865, loss=1.1469591856002808
I0303 20:48:57.900615 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:49:08.110235 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:49:39.590634 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:49:41.211452 140437341357888 submission_runner.py:411] Time since start: 119822.76s, 	Step: 247331, 	{'train/accuracy': 0.8894921541213989, 'train/loss': 0.4114971458911896, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 110535.2491569519, 'total_duration': 119822.76293802261, 'accumulated_submission_time': 110535.2491569519, 'accumulated_eval_time': 9257.57844209671, 'accumulated_logging_time': 16.369798183441162}
I0303 20:49:41.277766 140239850956544 logging_writer.py:48] [247331] accumulated_eval_time=9257.578442, accumulated_logging_time=16.369798, accumulated_submission_time=110535.249157, global_step=247331, preemption_count=0, score=110535.249157, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=119822.762938, train/accuracy=0.889492, train/loss=0.411497, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:50:09.009594 140239842563840 logging_writer.py:48] [247400] global_step=247400, grad_norm=3.751943349838257, loss=3.277825355529785
I0303 20:50:52.543561 140239850956544 logging_writer.py:48] [247500] global_step=247500, grad_norm=3.4786741733551025, loss=1.1307591199874878
I0303 20:51:37.426562 140239842563840 logging_writer.py:48] [247600] global_step=247600, grad_norm=2.659559726715088, loss=1.5177357196807861
I0303 20:52:22.965100 140239850956544 logging_writer.py:48] [247700] global_step=247700, grad_norm=2.9171149730682373, loss=1.2226154804229736
I0303 20:53:08.498713 140239842563840 logging_writer.py:48] [247800] global_step=247800, grad_norm=3.393627166748047, loss=2.7823047637939453
I0303 20:53:53.643446 140239850956544 logging_writer.py:48] [247900] global_step=247900, grad_norm=3.1855483055114746, loss=1.6175494194030762
I0303 20:54:38.812552 140239842563840 logging_writer.py:48] [248000] global_step=248000, grad_norm=3.2111799716949463, loss=1.1433099508285522
I0303 20:55:23.870632 140239850956544 logging_writer.py:48] [248100] global_step=248100, grad_norm=2.9889276027679443, loss=1.9979267120361328
I0303 20:56:09.227720 140239842563840 logging_writer.py:48] [248200] global_step=248200, grad_norm=2.7934553623199463, loss=1.023144006729126
I0303 20:56:41.459236 140437341357888 spec.py:321] Evaluating on the training split.
I0303 20:56:51.677834 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 20:57:15.564929 140437341357888 spec.py:349] Evaluating on the test split.
I0303 20:57:17.186780 140437341357888 submission_runner.py:411] Time since start: 120278.74s, 	Step: 248273, 	{'train/accuracy': 0.8887109160423279, 'train/loss': 0.4138701260089874, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 110955.36974859238, 'total_duration': 120278.73826503754, 'accumulated_submission_time': 110955.36974859238, 'accumulated_eval_time': 9293.305986881256, 'accumulated_logging_time': 16.446000337600708}
I0303 20:57:17.255876 140239850956544 logging_writer.py:48] [248273] accumulated_eval_time=9293.305987, accumulated_logging_time=16.446000, accumulated_submission_time=110955.369749, global_step=248273, preemption_count=0, score=110955.369749, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=120278.738265, train/accuracy=0.888711, train/loss=0.413870, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 20:57:28.367118 140239842563840 logging_writer.py:48] [248300] global_step=248300, grad_norm=2.9913418292999268, loss=1.0665535926818848
I0303 20:58:11.173528 140239850956544 logging_writer.py:48] [248400] global_step=248400, grad_norm=2.938171863555908, loss=1.9898931980133057
I0303 20:58:56.325085 140239842563840 logging_writer.py:48] [248500] global_step=248500, grad_norm=2.783066987991333, loss=1.5617307424545288
I0303 20:59:41.659524 140239850956544 logging_writer.py:48] [248600] global_step=248600, grad_norm=2.878819465637207, loss=1.6084370613098145
I0303 21:00:26.799339 140239842563840 logging_writer.py:48] [248700] global_step=248700, grad_norm=2.9045331478118896, loss=2.0640597343444824
I0303 21:01:12.067975 140239850956544 logging_writer.py:48] [248800] global_step=248800, grad_norm=3.232088327407837, loss=1.131377935409546
I0303 21:01:57.170056 140239842563840 logging_writer.py:48] [248900] global_step=248900, grad_norm=2.7846455574035645, loss=1.1105551719665527
I0303 21:02:42.946949 140239850956544 logging_writer.py:48] [249000] global_step=249000, grad_norm=3.265939950942993, loss=1.183476209640503
I0303 21:03:28.156936 140239842563840 logging_writer.py:48] [249100] global_step=249100, grad_norm=3.2052838802337646, loss=2.723769187927246
I0303 21:04:13.491983 140239850956544 logging_writer.py:48] [249200] global_step=249200, grad_norm=3.066718578338623, loss=1.283035159111023
I0303 21:04:17.321101 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:04:27.823386 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:04:57.933956 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:04:59.558234 140437341357888 submission_runner.py:411] Time since start: 120741.11s, 	Step: 249210, 	{'train/accuracy': 0.8867577910423279, 'train/loss': 0.42282629013061523, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 111375.37278437614, 'total_duration': 120741.10971736908, 'accumulated_submission_time': 111375.37278437614, 'accumulated_eval_time': 9335.543090820312, 'accumulated_logging_time': 16.526723384857178}
I0303 21:04:59.625757 140239842563840 logging_writer.py:48] [249210] accumulated_eval_time=9335.543091, accumulated_logging_time=16.526723, accumulated_submission_time=111375.372784, global_step=249210, preemption_count=0, score=111375.372784, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=120741.109717, train/accuracy=0.886758, train/loss=0.422826, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:05:35.676792 140239850956544 logging_writer.py:48] [249300] global_step=249300, grad_norm=3.406705141067505, loss=1.279416561126709
I0303 21:06:20.560156 140239842563840 logging_writer.py:48] [249400] global_step=249400, grad_norm=3.501103401184082, loss=1.1548162698745728
I0303 21:07:06.210456 140239850956544 logging_writer.py:48] [249500] global_step=249500, grad_norm=3.1818087100982666, loss=2.846083879470825
I0303 21:07:51.108120 140239842563840 logging_writer.py:48] [249600] global_step=249600, grad_norm=3.1916391849517822, loss=1.2977919578552246
I0303 21:08:36.557374 140239850956544 logging_writer.py:48] [249700] global_step=249700, grad_norm=3.0570218563079834, loss=2.104301929473877
I0303 21:09:21.665580 140239842563840 logging_writer.py:48] [249800] global_step=249800, grad_norm=3.1567366123199463, loss=1.0994532108306885
I0303 21:10:07.008519 140239850956544 logging_writer.py:48] [249900] global_step=249900, grad_norm=2.85597825050354, loss=1.0949211120605469
I0303 21:10:51.907962 140239842563840 logging_writer.py:48] [250000] global_step=250000, grad_norm=2.895697832107544, loss=1.1777235269546509
I0303 21:11:36.962210 140239850956544 logging_writer.py:48] [250100] global_step=250100, grad_norm=3.076627254486084, loss=1.210463047027588
I0303 21:11:59.715223 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:12:10.064783 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:12:32.629225 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:12:34.259478 140437341357888 submission_runner.py:411] Time since start: 121195.81s, 	Step: 250152, 	{'train/accuracy': 0.8893749713897705, 'train/loss': 0.4094995856285095, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 111795.39901304245, 'total_duration': 121195.81096291542, 'accumulated_submission_time': 111795.39901304245, 'accumulated_eval_time': 9370.087344884872, 'accumulated_logging_time': 16.606194257736206}
I0303 21:12:34.331156 140239842563840 logging_writer.py:48] [250152] accumulated_eval_time=9370.087345, accumulated_logging_time=16.606194, accumulated_submission_time=111795.399013, global_step=250152, preemption_count=0, score=111795.399013, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=121195.810963, train/accuracy=0.889375, train/loss=0.409500, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:12:53.767580 140239850956544 logging_writer.py:48] [250200] global_step=250200, grad_norm=4.212172985076904, loss=3.1745049953460693
I0303 21:13:37.761120 140239842563840 logging_writer.py:48] [250300] global_step=250300, grad_norm=3.0623815059661865, loss=1.4304989576339722
I0303 21:14:23.240303 140239850956544 logging_writer.py:48] [250400] global_step=250400, grad_norm=3.1341395378112793, loss=1.0614839792251587
I0303 21:15:08.661732 140239842563840 logging_writer.py:48] [250500] global_step=250500, grad_norm=3.2327451705932617, loss=1.4225984811782837
I0303 21:15:53.910534 140239850956544 logging_writer.py:48] [250600] global_step=250600, grad_norm=2.77445912361145, loss=1.127553939819336
I0303 21:16:39.235681 140239842563840 logging_writer.py:48] [250700] global_step=250700, grad_norm=3.034451484680176, loss=2.423111915588379
I0303 21:17:24.581454 140239850956544 logging_writer.py:48] [250800] global_step=250800, grad_norm=2.9210760593414307, loss=1.0475225448608398
I0303 21:18:09.737430 140239842563840 logging_writer.py:48] [250900] global_step=250900, grad_norm=2.860945224761963, loss=1.3297159671783447
I0303 21:18:54.725007 140239850956544 logging_writer.py:48] [251000] global_step=251000, grad_norm=2.992854595184326, loss=1.3273366689682007
I0303 21:19:34.627095 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:19:45.193914 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:20:17.797904 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:20:19.409050 140437341357888 submission_runner.py:411] Time since start: 121660.96s, 	Step: 251090, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.4091140627861023, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 112215.63183784485, 'total_duration': 121660.96054553986, 'accumulated_submission_time': 112215.63183784485, 'accumulated_eval_time': 9414.86929488182, 'accumulated_logging_time': 16.68982768058777}
I0303 21:20:19.463050 140239842563840 logging_writer.py:48] [251090] accumulated_eval_time=9414.869295, accumulated_logging_time=16.689828, accumulated_submission_time=112215.631838, global_step=251090, preemption_count=0, score=112215.631838, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=121660.960546, train/accuracy=0.888418, train/loss=0.409114, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:20:23.817315 140239850956544 logging_writer.py:48] [251100] global_step=251100, grad_norm=2.840184450149536, loss=1.0814119577407837
I0303 21:21:04.314062 140239842563840 logging_writer.py:48] [251200] global_step=251200, grad_norm=3.197498321533203, loss=2.515634298324585
I0303 21:21:49.033335 140239850956544 logging_writer.py:48] [251300] global_step=251300, grad_norm=3.1176443099975586, loss=1.8414777517318726
I0303 21:22:34.168228 140239842563840 logging_writer.py:48] [251400] global_step=251400, grad_norm=2.9650752544403076, loss=1.0692486763000488
I0303 21:23:19.448589 140239850956544 logging_writer.py:48] [251500] global_step=251500, grad_norm=3.09987735748291, loss=1.1782273054122925
I0303 21:24:04.504456 140239842563840 logging_writer.py:48] [251600] global_step=251600, grad_norm=3.034027099609375, loss=1.1541965007781982
I0303 21:24:49.593108 140239850956544 logging_writer.py:48] [251700] global_step=251700, grad_norm=3.092823028564453, loss=2.347534656524658
I0303 21:25:34.587473 140239842563840 logging_writer.py:48] [251800] global_step=251800, grad_norm=3.010625123977661, loss=1.2177753448486328
I0303 21:26:19.601922 140239850956544 logging_writer.py:48] [251900] global_step=251900, grad_norm=3.1960551738739014, loss=2.508206844329834
I0303 21:27:04.968072 140239842563840 logging_writer.py:48] [252000] global_step=252000, grad_norm=2.9825823307037354, loss=2.157835006713867
I0303 21:27:19.541363 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:27:29.747197 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:28:03.560294 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:28:05.181748 140437341357888 submission_runner.py:411] Time since start: 122126.73s, 	Step: 252034, 	{'train/accuracy': 0.8879687190055847, 'train/loss': 0.4145607650279999, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 112635.64821743965, 'total_duration': 122126.73324251175, 'accumulated_submission_time': 112635.64821743965, 'accumulated_eval_time': 9460.509674549103, 'accumulated_logging_time': 16.75420641899109}
I0303 21:28:05.239816 140239850956544 logging_writer.py:48] [252034] accumulated_eval_time=9460.509675, accumulated_logging_time=16.754206, accumulated_submission_time=112635.648217, global_step=252034, preemption_count=0, score=112635.648217, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=122126.733243, train/accuracy=0.887969, train/loss=0.414561, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:28:31.777346 140239842563840 logging_writer.py:48] [252100] global_step=252100, grad_norm=2.8432018756866455, loss=1.1440924406051636
I0303 21:29:15.038193 140239850956544 logging_writer.py:48] [252200] global_step=252200, grad_norm=3.0720138549804688, loss=1.059102177619934
I0303 21:30:00.387728 140239842563840 logging_writer.py:48] [252300] global_step=252300, grad_norm=2.9125161170959473, loss=1.0519559383392334
I0303 21:30:45.432344 140239850956544 logging_writer.py:48] [252400] global_step=252400, grad_norm=3.1237833499908447, loss=1.7079607248306274
I0303 21:31:30.374094 140239842563840 logging_writer.py:48] [252500] global_step=252500, grad_norm=3.0083255767822266, loss=1.1195708513259888
I0303 21:32:15.454450 140239850956544 logging_writer.py:48] [252600] global_step=252600, grad_norm=3.6493642330169678, loss=3.193019151687622
I0303 21:33:00.447313 140239842563840 logging_writer.py:48] [252700] global_step=252700, grad_norm=3.563279628753662, loss=1.782537817955017
I0303 21:33:45.996871 140239850956544 logging_writer.py:48] [252800] global_step=252800, grad_norm=3.997255325317383, loss=3.029893636703491
I0303 21:34:31.387186 140239842563840 logging_writer.py:48] [252900] global_step=252900, grad_norm=3.2030270099639893, loss=1.0873844623565674
I0303 21:35:05.288493 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:35:15.928683 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:35:47.391125 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:35:49.017854 140437341357888 submission_runner.py:411] Time since start: 122590.57s, 	Step: 252976, 	{'train/accuracy': 0.8885937333106995, 'train/loss': 0.41547492146492004, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 113055.63692212105, 'total_duration': 122590.56933999062, 'accumulated_submission_time': 113055.63692212105, 'accumulated_eval_time': 9504.239057064056, 'accumulated_logging_time': 16.821215629577637}
I0303 21:35:49.084887 140239850956544 logging_writer.py:48] [252976] accumulated_eval_time=9504.239057, accumulated_logging_time=16.821216, accumulated_submission_time=113055.636922, global_step=252976, preemption_count=0, score=113055.636922, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=122590.569340, train/accuracy=0.888594, train/loss=0.415475, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:35:58.984359 140239842563840 logging_writer.py:48] [253000] global_step=253000, grad_norm=3.440140724182129, loss=3.06152606010437
I0303 21:36:40.997266 140239850956544 logging_writer.py:48] [253100] global_step=253100, grad_norm=3.099377155303955, loss=1.0463569164276123
I0303 21:37:26.126474 140239842563840 logging_writer.py:48] [253200] global_step=253200, grad_norm=3.15368390083313, loss=2.8852877616882324
I0303 21:38:11.702759 140239850956544 logging_writer.py:48] [253300] global_step=253300, grad_norm=3.1978392601013184, loss=1.679146409034729
I0303 21:38:56.853159 140239842563840 logging_writer.py:48] [253400] global_step=253400, grad_norm=3.0349533557891846, loss=1.8813056945800781
I0303 21:39:42.121721 140239850956544 logging_writer.py:48] [253500] global_step=253500, grad_norm=4.04917049407959, loss=1.07742440700531
I0303 21:40:27.535446 140239842563840 logging_writer.py:48] [253600] global_step=253600, grad_norm=3.0945258140563965, loss=1.131762146949768
I0303 21:41:12.819925 140239850956544 logging_writer.py:48] [253700] global_step=253700, grad_norm=3.1420092582702637, loss=1.7047340869903564
I0303 21:41:58.033510 140239842563840 logging_writer.py:48] [253800] global_step=253800, grad_norm=3.1718051433563232, loss=1.0891600847244263
I0303 21:42:43.443256 140239850956544 logging_writer.py:48] [253900] global_step=253900, grad_norm=3.9336280822753906, loss=3.2645208835601807
I0303 21:42:49.294208 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:43:00.040203 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:43:25.517955 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:43:27.144927 140437341357888 submission_runner.py:411] Time since start: 123048.70s, 	Step: 253915, 	{'train/accuracy': 0.8883593678474426, 'train/loss': 0.4171532988548279, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 113475.78511810303, 'total_duration': 123048.69641470909, 'accumulated_submission_time': 113475.78511810303, 'accumulated_eval_time': 9542.089750528336, 'accumulated_logging_time': 16.89837408065796}
I0303 21:43:27.214664 140239842563840 logging_writer.py:48] [253915] accumulated_eval_time=9542.089751, accumulated_logging_time=16.898374, accumulated_submission_time=113475.785118, global_step=253915, preemption_count=0, score=113475.785118, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=123048.696415, train/accuracy=0.888359, train/loss=0.417153, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:44:02.874666 140239850956544 logging_writer.py:48] [254000] global_step=254000, grad_norm=3.1118245124816895, loss=1.7995989322662354
I0303 21:44:48.121090 140239842563840 logging_writer.py:48] [254100] global_step=254100, grad_norm=3.061561346054077, loss=1.1255192756652832
I0303 21:45:33.702167 140239850956544 logging_writer.py:48] [254200] global_step=254200, grad_norm=3.0215418338775635, loss=1.0550884008407593
I0303 21:46:19.356553 140239842563840 logging_writer.py:48] [254300] global_step=254300, grad_norm=3.42871356010437, loss=3.022892475128174
I0303 21:47:05.225440 140239850956544 logging_writer.py:48] [254400] global_step=254400, grad_norm=3.175483465194702, loss=1.1329574584960938
I0303 21:47:50.706125 140239842563840 logging_writer.py:48] [254500] global_step=254500, grad_norm=2.9253296852111816, loss=1.1664814949035645
I0303 21:48:36.133684 140239850956544 logging_writer.py:48] [254600] global_step=254600, grad_norm=3.1675350666046143, loss=1.0944514274597168
I0303 21:49:21.591156 140239842563840 logging_writer.py:48] [254700] global_step=254700, grad_norm=3.2496578693389893, loss=2.7172763347625732
I0303 21:50:07.255157 140239850956544 logging_writer.py:48] [254800] global_step=254800, grad_norm=3.264070987701416, loss=1.646826148033142
I0303 21:50:27.274863 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:50:37.925957 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:51:04.990393 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:51:06.639646 140437341357888 submission_runner.py:411] Time since start: 123508.19s, 	Step: 254846, 	{'train/accuracy': 0.8913671970367432, 'train/loss': 0.4085223972797394, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 113895.78473091125, 'total_duration': 123508.19112324715, 'accumulated_submission_time': 113895.78473091125, 'accumulated_eval_time': 9581.454507350922, 'accumulated_logging_time': 16.978004217147827}
I0303 21:51:06.719414 140239842563840 logging_writer.py:48] [254846] accumulated_eval_time=9581.454507, accumulated_logging_time=16.978004, accumulated_submission_time=113895.784731, global_step=254846, preemption_count=0, score=113895.784731, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=123508.191123, train/accuracy=0.891367, train/loss=0.408522, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:51:28.501600 140239850956544 logging_writer.py:48] [254900] global_step=254900, grad_norm=2.9885568618774414, loss=1.171525001525879
I0303 21:52:11.919376 140239842563840 logging_writer.py:48] [255000] global_step=255000, grad_norm=3.0606846809387207, loss=1.1897398233413696
I0303 21:52:56.918107 140239850956544 logging_writer.py:48] [255100] global_step=255100, grad_norm=3.456472635269165, loss=1.1434810161590576
I0303 21:53:42.782771 140239842563840 logging_writer.py:48] [255200] global_step=255200, grad_norm=3.1352295875549316, loss=2.7463552951812744
I0303 21:54:28.414609 140239850956544 logging_writer.py:48] [255300] global_step=255300, grad_norm=2.957892894744873, loss=1.425321102142334
I0303 21:55:13.605446 140239842563840 logging_writer.py:48] [255400] global_step=255400, grad_norm=3.042448043823242, loss=1.1281317472457886
I0303 21:55:58.662924 140239850956544 logging_writer.py:48] [255500] global_step=255500, grad_norm=3.1116695404052734, loss=1.1394232511520386
I0303 21:56:43.944093 140239842563840 logging_writer.py:48] [255600] global_step=255600, grad_norm=3.2080166339874268, loss=1.494891881942749
I0303 21:57:29.242758 140239850956544 logging_writer.py:48] [255700] global_step=255700, grad_norm=2.948496103286743, loss=1.9980242252349854
I0303 21:58:06.991808 140437341357888 spec.py:321] Evaluating on the training split.
I0303 21:58:17.421255 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 21:58:50.239680 140437341357888 spec.py:349] Evaluating on the test split.
I0303 21:58:51.863469 140437341357888 submission_runner.py:411] Time since start: 123973.41s, 	Step: 255785, 	{'train/accuracy': 0.8885351419448853, 'train/loss': 0.41487205028533936, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 114315.99058461189, 'total_duration': 123973.41496372223, 'accumulated_submission_time': 114315.99058461189, 'accumulated_eval_time': 9626.326175928116, 'accumulated_logging_time': 17.073423862457275}
I0303 21:58:51.921569 140239842563840 logging_writer.py:48] [255785] accumulated_eval_time=9626.326176, accumulated_logging_time=17.073424, accumulated_submission_time=114315.990585, global_step=255785, preemption_count=0, score=114315.990585, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=123973.414964, train/accuracy=0.888535, train/loss=0.414872, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 21:58:58.269111 140239850956544 logging_writer.py:48] [255800] global_step=255800, grad_norm=3.019580364227295, loss=1.1422427892684937
I0303 21:59:39.213962 140239842563840 logging_writer.py:48] [255900] global_step=255900, grad_norm=2.874691963195801, loss=1.202216625213623
I0303 22:00:24.029495 140239850956544 logging_writer.py:48] [256000] global_step=256000, grad_norm=3.1736791133880615, loss=1.2212920188903809
I0303 22:01:09.321602 140239842563840 logging_writer.py:48] [256100] global_step=256100, grad_norm=3.2421131134033203, loss=1.274531602859497
I0303 22:01:54.297876 140239850956544 logging_writer.py:48] [256200] global_step=256200, grad_norm=3.480968952178955, loss=2.507357597351074
I0303 22:02:39.344634 140239842563840 logging_writer.py:48] [256300] global_step=256300, grad_norm=2.920389413833618, loss=1.4104883670806885
I0303 22:03:24.545786 140239850956544 logging_writer.py:48] [256400] global_step=256400, grad_norm=2.9985034465789795, loss=1.1386946439743042
I0303 22:04:09.835840 140239842563840 logging_writer.py:48] [256500] global_step=256500, grad_norm=3.3740792274475098, loss=2.960947036743164
I0303 22:04:54.823783 140239850956544 logging_writer.py:48] [256600] global_step=256600, grad_norm=3.207320213317871, loss=2.0726523399353027
I0303 22:05:40.290932 140239842563840 logging_writer.py:48] [256700] global_step=256700, grad_norm=3.156200647354126, loss=1.117785096168518
I0303 22:05:52.184958 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:06:02.778288 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 22:06:23.433888 140437341357888 spec.py:349] Evaluating on the test split.
I0303 22:06:25.060750 140437341357888 submission_runner.py:411] Time since start: 124426.61s, 	Step: 256728, 	{'train/accuracy': 0.8897265195846558, 'train/loss': 0.41374650597572327, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 114736.19265317917, 'total_duration': 124426.61223173141, 'accumulated_submission_time': 114736.19265317917, 'accumulated_eval_time': 9659.201932668686, 'accumulated_logging_time': 17.14213752746582}
I0303 22:06:25.133210 140239850956544 logging_writer.py:48] [256728] accumulated_eval_time=9659.201933, accumulated_logging_time=17.142138, accumulated_submission_time=114736.192653, global_step=256728, preemption_count=0, score=114736.192653, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=124426.612232, train/accuracy=0.889727, train/loss=0.413747, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 22:06:55.026801 140239842563840 logging_writer.py:48] [256800] global_step=256800, grad_norm=3.3091816902160645, loss=2.061378240585327
I0303 22:07:40.663874 140239850956544 logging_writer.py:48] [256900] global_step=256900, grad_norm=3.2655088901519775, loss=1.1780937910079956
I0303 22:08:26.416371 140239842563840 logging_writer.py:48] [257000] global_step=257000, grad_norm=2.884899139404297, loss=1.1743714809417725
I0303 22:09:12.234875 140239850956544 logging_writer.py:48] [257100] global_step=257100, grad_norm=3.2175745964050293, loss=2.1119637489318848
I0303 22:09:57.945662 140239842563840 logging_writer.py:48] [257200] global_step=257200, grad_norm=2.969616174697876, loss=1.4498252868652344
I0303 22:10:43.838932 140239850956544 logging_writer.py:48] [257300] global_step=257300, grad_norm=3.2634849548339844, loss=1.098609447479248
I0303 22:11:29.599371 140239842563840 logging_writer.py:48] [257400] global_step=257400, grad_norm=2.9303598403930664, loss=1.3948074579238892
I0303 22:12:15.335858 140239850956544 logging_writer.py:48] [257500] global_step=257500, grad_norm=3.396693229675293, loss=1.030348539352417
I0303 22:13:00.893594 140239842563840 logging_writer.py:48] [257600] global_step=257600, grad_norm=3.027301549911499, loss=1.3447691202163696
I0303 22:13:25.306085 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:13:36.769119 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 22:14:03.911649 140437341357888 spec.py:349] Evaluating on the test split.
I0303 22:14:05.555083 140437341357888 submission_runner.py:411] Time since start: 124887.11s, 	Step: 257655, 	{'train/accuracy': 0.8881640434265137, 'train/loss': 0.4150804877281189, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 115156.30558776855, 'total_duration': 124887.1065568924, 'accumulated_submission_time': 115156.30558776855, 'accumulated_eval_time': 9699.450918912888, 'accumulated_logging_time': 17.224257707595825}
I0303 22:14:05.629247 140239850956544 logging_writer.py:48] [257655] accumulated_eval_time=9699.450919, accumulated_logging_time=17.224258, accumulated_submission_time=115156.305588, global_step=257655, preemption_count=0, score=115156.305588, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=124887.106557, train/accuracy=0.888164, train/loss=0.415080, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 22:14:23.864125 140239842563840 logging_writer.py:48] [257700] global_step=257700, grad_norm=3.316736936569214, loss=1.2762445211410522
I0303 22:15:07.108663 140239850956544 logging_writer.py:48] [257800] global_step=257800, grad_norm=7.050797462463379, loss=3.0669844150543213
I0303 22:15:52.340545 140239842563840 logging_writer.py:48] [257900] global_step=257900, grad_norm=2.850731134414673, loss=1.6189154386520386
I0303 22:16:38.067637 140239850956544 logging_writer.py:48] [258000] global_step=258000, grad_norm=3.435418128967285, loss=1.170324444770813
I0303 22:17:23.301599 140239842563840 logging_writer.py:48] [258100] global_step=258100, grad_norm=2.814176321029663, loss=1.1013566255569458
I0303 22:18:08.662720 140239850956544 logging_writer.py:48] [258200] global_step=258200, grad_norm=3.016944169998169, loss=1.475667953491211
I0303 22:18:53.995534 140239842563840 logging_writer.py:48] [258300] global_step=258300, grad_norm=2.7310876846313477, loss=1.9708222150802612
I0303 22:19:39.344731 140239850956544 logging_writer.py:48] [258400] global_step=258400, grad_norm=3.0685875415802, loss=1.2878116369247437
I0303 22:20:24.578455 140239842563840 logging_writer.py:48] [258500] global_step=258500, grad_norm=3.060776710510254, loss=1.0794397592544556
I0303 22:21:05.930342 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:21:16.274665 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 22:21:52.786952 140437341357888 spec.py:349] Evaluating on the test split.
I0303 22:21:54.399017 140437341357888 submission_runner.py:411] Time since start: 125355.95s, 	Step: 258593, 	{'train/accuracy': 0.8871288895606995, 'train/loss': 0.4156031608581543, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 115576.53962373734, 'total_duration': 125355.95051217079, 'accumulated_submission_time': 115576.53962373734, 'accumulated_eval_time': 9747.919601917267, 'accumulated_logging_time': 17.31403613090515}
I0303 22:21:54.459622 140239850956544 logging_writer.py:48] [258593] accumulated_eval_time=9747.919602, accumulated_logging_time=17.314036, accumulated_submission_time=115576.539624, global_step=258593, preemption_count=0, score=115576.539624, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=125355.950512, train/accuracy=0.887129, train/loss=0.415603, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 22:21:57.628323 140239842563840 logging_writer.py:48] [258600] global_step=258600, grad_norm=2.952702522277832, loss=1.3245445489883423
I0303 22:22:38.031168 140239850956544 logging_writer.py:48] [258700] global_step=258700, grad_norm=2.8524117469787598, loss=1.5599220991134644
I0303 22:23:22.874615 140239842563840 logging_writer.py:48] [258800] global_step=258800, grad_norm=3.1082820892333984, loss=1.3287338018417358
I0303 22:24:08.258141 140239850956544 logging_writer.py:48] [258900] global_step=258900, grad_norm=2.965026378631592, loss=1.2115753889083862
I0303 22:24:53.552043 140239842563840 logging_writer.py:48] [259000] global_step=259000, grad_norm=3.0632219314575195, loss=1.2020751237869263
I0303 22:25:38.505558 140239850956544 logging_writer.py:48] [259100] global_step=259100, grad_norm=2.886411428451538, loss=1.652367115020752
I0303 22:26:23.991781 140239842563840 logging_writer.py:48] [259200] global_step=259200, grad_norm=3.2013680934906006, loss=1.13918137550354
I0303 22:27:08.970678 140239850956544 logging_writer.py:48] [259300] global_step=259300, grad_norm=3.040088653564453, loss=1.0886435508728027
I0303 22:27:54.190911 140239842563840 logging_writer.py:48] [259400] global_step=259400, grad_norm=3.0907962322235107, loss=1.1792391538619995
I0303 22:28:39.368494 140239850956544 logging_writer.py:48] [259500] global_step=259500, grad_norm=3.089066505432129, loss=1.0745025873184204
I0303 22:28:54.782245 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:29:05.222448 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 22:29:32.892271 140437341357888 spec.py:349] Evaluating on the test split.
I0303 22:29:34.516887 140437341357888 submission_runner.py:411] Time since start: 125816.07s, 	Step: 259536, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.41446414589881897, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 115996.80192518234, 'total_duration': 125816.06837558746, 'accumulated_submission_time': 115996.80192518234, 'accumulated_eval_time': 9787.654287099838, 'accumulated_logging_time': 17.384129524230957}
I0303 22:29:34.587041 140239842563840 logging_writer.py:48] [259536] accumulated_eval_time=9787.654287, accumulated_logging_time=17.384130, accumulated_submission_time=115996.801925, global_step=259536, preemption_count=0, score=115996.801925, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=125816.068376, train/accuracy=0.888379, train/loss=0.414464, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 22:30:00.340483 140239850956544 logging_writer.py:48] [259600] global_step=259600, grad_norm=3.0463969707489014, loss=1.2093682289123535
I0303 22:30:44.917473 140239842563840 logging_writer.py:48] [259700] global_step=259700, grad_norm=2.9697110652923584, loss=1.0443474054336548
I0303 22:31:30.266713 140239850956544 logging_writer.py:48] [259800] global_step=259800, grad_norm=3.1011111736297607, loss=1.1615556478500366
I0303 22:32:15.465057 140239842563840 logging_writer.py:48] [259900] global_step=259900, grad_norm=3.079517126083374, loss=1.1046032905578613
I0303 22:33:00.730986 140239850956544 logging_writer.py:48] [260000] global_step=260000, grad_norm=3.101325035095215, loss=1.3524662256240845
I0303 22:33:45.874924 140239842563840 logging_writer.py:48] [260100] global_step=260100, grad_norm=4.117989540100098, loss=3.232039213180542
I0303 22:34:30.961195 140239850956544 logging_writer.py:48] [260200] global_step=260200, grad_norm=2.9981937408447266, loss=1.131043553352356
I0303 22:35:16.807391 140239842563840 logging_writer.py:48] [260300] global_step=260300, grad_norm=3.524949073791504, loss=3.1224308013916016
I0303 22:36:02.148395 140239850956544 logging_writer.py:48] [260400] global_step=260400, grad_norm=3.2477312088012695, loss=1.631170392036438
I0303 22:36:34.901789 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:36:45.566740 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 22:37:15.483850 140437341357888 spec.py:349] Evaluating on the test split.
I0303 22:37:17.112365 140437341357888 submission_runner.py:411] Time since start: 126278.66s, 	Step: 260473, 	{'train/accuracy': 0.888671875, 'train/loss': 0.41397181153297424, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 116417.05393886566, 'total_duration': 126278.66386461258, 'accumulated_submission_time': 116417.05393886566, 'accumulated_eval_time': 9829.864854097366, 'accumulated_logging_time': 17.466994762420654}
I0303 22:37:17.167284 140239842563840 logging_writer.py:48] [260473] accumulated_eval_time=9829.864854, accumulated_logging_time=17.466995, accumulated_submission_time=116417.053939, global_step=260473, preemption_count=0, score=116417.053939, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=126278.663865, train/accuracy=0.888672, train/loss=0.413972, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 22:37:28.246560 140239850956544 logging_writer.py:48] [260500] global_step=260500, grad_norm=4.257870197296143, loss=3.2642130851745605
I0303 22:38:10.074361 140239842563840 logging_writer.py:48] [260600] global_step=260600, grad_norm=3.0867128372192383, loss=1.1700999736785889
I0303 22:38:55.275897 140239850956544 logging_writer.py:48] [260700] global_step=260700, grad_norm=3.0149178504943848, loss=1.141520380973816
I0303 22:39:40.848026 140239842563840 logging_writer.py:48] [260800] global_step=260800, grad_norm=3.6792657375335693, loss=2.911159038543701
I0303 22:40:26.044475 140239850956544 logging_writer.py:48] [260900] global_step=260900, grad_norm=2.9948363304138184, loss=1.1150388717651367
I0303 22:41:11.231366 140239842563840 logging_writer.py:48] [261000] global_step=261000, grad_norm=3.38137149810791, loss=1.5805792808532715
I0303 22:41:56.490751 140239850956544 logging_writer.py:48] [261100] global_step=261100, grad_norm=3.1277589797973633, loss=2.42002010345459
I0303 22:42:41.554546 140239842563840 logging_writer.py:48] [261200] global_step=261200, grad_norm=2.85343861579895, loss=1.0261918306350708
I0303 22:43:26.847975 140239850956544 logging_writer.py:48] [261300] global_step=261300, grad_norm=3.034806489944458, loss=2.4637868404388428
I0303 22:44:12.166640 140239842563840 logging_writer.py:48] [261400] global_step=261400, grad_norm=3.1665854454040527, loss=1.134347915649414
I0303 22:44:17.195635 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:44:27.587993 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 22:44:50.058508 140437341357888 spec.py:349] Evaluating on the test split.
I0303 22:44:51.679584 140437341357888 submission_runner.py:411] Time since start: 126733.23s, 	Step: 261413, 	{'train/accuracy': 0.8889257907867432, 'train/loss': 0.4145142734050751, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 116837.02300691605, 'total_duration': 126733.23106122017, 'accumulated_submission_time': 116837.02300691605, 'accumulated_eval_time': 9864.348781108856, 'accumulated_logging_time': 17.530568838119507}
I0303 22:44:51.744945 140239850956544 logging_writer.py:48] [261413] accumulated_eval_time=9864.348781, accumulated_logging_time=17.530569, accumulated_submission_time=116837.023007, global_step=261413, preemption_count=0, score=116837.023007, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=126733.231061, train/accuracy=0.888926, train/loss=0.414514, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 22:45:27.939041 140239842563840 logging_writer.py:48] [261500] global_step=261500, grad_norm=3.2550241947174072, loss=2.8179550170898438
I0303 22:46:13.176254 140239850956544 logging_writer.py:48] [261600] global_step=261600, grad_norm=2.9564104080200195, loss=1.1264002323150635
I0303 22:46:58.530488 140239842563840 logging_writer.py:48] [261700] global_step=261700, grad_norm=3.923215627670288, loss=3.3357858657836914
I0303 22:47:43.793020 140239850956544 logging_writer.py:48] [261800] global_step=261800, grad_norm=3.1807258129119873, loss=1.2077031135559082
I0303 22:48:29.054027 140239842563840 logging_writer.py:48] [261900] global_step=261900, grad_norm=2.979753017425537, loss=1.5665581226348877
I0303 22:49:14.416790 140239850956544 logging_writer.py:48] [262000] global_step=262000, grad_norm=3.1199045181274414, loss=1.1593005657196045
I0303 22:49:59.586195 140239842563840 logging_writer.py:48] [262100] global_step=262100, grad_norm=3.0313007831573486, loss=2.0534768104553223
I0303 22:50:44.997512 140239850956544 logging_writer.py:48] [262200] global_step=262200, grad_norm=3.1161513328552246, loss=2.4884183406829834
I0303 22:51:30.227308 140239842563840 logging_writer.py:48] [262300] global_step=262300, grad_norm=3.137773275375366, loss=1.0560222864151
I0303 22:51:52.190974 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:52:02.880688 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 22:52:39.219986 140437341357888 spec.py:349] Evaluating on the test split.
I0303 22:52:40.834784 140437341357888 submission_runner.py:411] Time since start: 127202.39s, 	Step: 262350, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.41644036769866943, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 117257.40816497803, 'total_duration': 127202.38626980782, 'accumulated_submission_time': 117257.40816497803, 'accumulated_eval_time': 9912.99257516861, 'accumulated_logging_time': 17.60601305961609}
I0303 22:52:40.902611 140239850956544 logging_writer.py:48] [262350] accumulated_eval_time=9912.992575, accumulated_logging_time=17.606013, accumulated_submission_time=117257.408165, global_step=262350, preemption_count=0, score=117257.408165, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=127202.386270, train/accuracy=0.888398, train/loss=0.416440, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 22:53:01.104177 140239842563840 logging_writer.py:48] [262400] global_step=262400, grad_norm=3.1494479179382324, loss=1.2194256782531738
I0303 22:53:44.338940 140239850956544 logging_writer.py:48] [262500] global_step=262500, grad_norm=2.9847774505615234, loss=1.059012770652771
I0303 22:54:28.928340 140239842563840 logging_writer.py:48] [262600] global_step=262600, grad_norm=2.676603317260742, loss=1.5067143440246582
I0303 22:55:14.452193 140239850956544 logging_writer.py:48] [262700] global_step=262700, grad_norm=2.901704788208008, loss=1.1194204092025757
I0303 22:55:59.806770 140239842563840 logging_writer.py:48] [262800] global_step=262800, grad_norm=2.892972469329834, loss=1.1358760595321655
I0303 22:56:45.125265 140239850956544 logging_writer.py:48] [262900] global_step=262900, grad_norm=3.053060293197632, loss=1.3272289037704468
I0303 22:57:30.254127 140239842563840 logging_writer.py:48] [263000] global_step=263000, grad_norm=3.1247074604034424, loss=1.0965276956558228
I0303 22:58:15.664390 140239850956544 logging_writer.py:48] [263100] global_step=263100, grad_norm=3.0670900344848633, loss=1.1140270233154297
I0303 22:59:00.624269 140239842563840 logging_writer.py:48] [263200] global_step=263200, grad_norm=3.1502537727355957, loss=2.0789787769317627
I0303 22:59:41.115642 140437341357888 spec.py:321] Evaluating on the training split.
I0303 22:59:51.428541 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:00:18.528912 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:00:20.152849 140437341357888 submission_runner.py:411] Time since start: 127661.70s, 	Step: 263291, 	{'train/accuracy': 0.8852343559265137, 'train/loss': 0.42179808020591736, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 117677.55997300148, 'total_duration': 127661.7043390274, 'accumulated_submission_time': 117677.55997300148, 'accumulated_eval_time': 9952.029757261276, 'accumulated_logging_time': 17.68432903289795}
I0303 23:00:20.223414 140239850956544 logging_writer.py:48] [263291] accumulated_eval_time=9952.029757, accumulated_logging_time=17.684329, accumulated_submission_time=117677.559973, global_step=263291, preemption_count=0, score=117677.559973, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=127661.704339, train/accuracy=0.885234, train/loss=0.421798, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:00:24.199917 140239842563840 logging_writer.py:48] [263300] global_step=263300, grad_norm=3.0023813247680664, loss=1.0997589826583862
I0303 23:01:06.034704 140239850956544 logging_writer.py:48] [263400] global_step=263400, grad_norm=2.7668914794921875, loss=1.4849907159805298
I0303 23:01:51.120032 140239842563840 logging_writer.py:48] [263500] global_step=263500, grad_norm=3.9315268993377686, loss=2.4062395095825195
I0303 23:02:36.439942 140239850956544 logging_writer.py:48] [263600] global_step=263600, grad_norm=3.270972967147827, loss=1.0655471086502075
I0303 23:03:21.685845 140239842563840 logging_writer.py:48] [263700] global_step=263700, grad_norm=2.974430799484253, loss=1.1004737615585327
I0303 23:04:06.992472 140239850956544 logging_writer.py:48] [263800] global_step=263800, grad_norm=3.3289129734039307, loss=1.1380956172943115
I0303 23:04:52.228899 140239842563840 logging_writer.py:48] [263900] global_step=263900, grad_norm=2.9894039630889893, loss=1.1441760063171387
I0303 23:05:37.701781 140239850956544 logging_writer.py:48] [264000] global_step=264000, grad_norm=2.858261823654175, loss=2.141625165939331
I0303 23:06:23.197149 140239842563840 logging_writer.py:48] [264100] global_step=264100, grad_norm=3.0076351165771484, loss=1.1899491548538208
I0303 23:07:08.774035 140239850956544 logging_writer.py:48] [264200] global_step=264200, grad_norm=4.0760626792907715, loss=3.1721882820129395
I0303 23:07:20.262603 140437341357888 spec.py:321] Evaluating on the training split.
I0303 23:07:30.816537 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:08:01.642001 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:08:03.256960 140437341357888 submission_runner.py:411] Time since start: 128124.81s, 	Step: 264227, 	{'train/accuracy': 0.8889843821525574, 'train/loss': 0.4135739505290985, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 118097.5377099514, 'total_duration': 128124.80843949318, 'accumulated_submission_time': 118097.5377099514, 'accumulated_eval_time': 9995.02408361435, 'accumulated_logging_time': 17.765547513961792}
I0303 23:08:03.335285 140239842563840 logging_writer.py:48] [264227] accumulated_eval_time=9995.024084, accumulated_logging_time=17.765548, accumulated_submission_time=118097.537710, global_step=264227, preemption_count=0, score=118097.537710, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=128124.808439, train/accuracy=0.888984, train/loss=0.413574, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:08:32.893198 140239850956544 logging_writer.py:48] [264300] global_step=264300, grad_norm=2.839662790298462, loss=1.504048228263855
I0303 23:09:18.119498 140239842563840 logging_writer.py:48] [264400] global_step=264400, grad_norm=3.4998528957366943, loss=2.035754919052124
I0303 23:10:03.534734 140239850956544 logging_writer.py:48] [264500] global_step=264500, grad_norm=3.5134646892547607, loss=2.947323799133301
I0303 23:10:48.751545 140239842563840 logging_writer.py:48] [264600] global_step=264600, grad_norm=3.279435157775879, loss=1.9345262050628662
I0303 23:11:34.467649 140239850956544 logging_writer.py:48] [264700] global_step=264700, grad_norm=3.0545096397399902, loss=1.1469124555587769
I0303 23:12:19.848830 140239842563840 logging_writer.py:48] [264800] global_step=264800, grad_norm=2.9752299785614014, loss=1.1217304468154907
I0303 23:13:05.290434 140239850956544 logging_writer.py:48] [264900] global_step=264900, grad_norm=2.8321423530578613, loss=1.4655559062957764
I0303 23:13:50.491581 140239842563840 logging_writer.py:48] [265000] global_step=265000, grad_norm=2.9442038536071777, loss=1.1818122863769531
I0303 23:14:35.903050 140239850956544 logging_writer.py:48] [265100] global_step=265100, grad_norm=2.9018445014953613, loss=1.0708074569702148
I0303 23:15:03.382797 140437341357888 spec.py:321] Evaluating on the training split.
I0303 23:15:13.743905 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:15:37.617408 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:15:39.237058 140437341357888 submission_runner.py:411] Time since start: 128580.79s, 	Step: 265162, 	{'train/accuracy': 0.8879492282867432, 'train/loss': 0.4144449830055237, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 118517.52534794807, 'total_duration': 128580.78847575188, 'accumulated_submission_time': 118517.52534794807, 'accumulated_eval_time': 10030.878251314163, 'accumulated_logging_time': 17.853434562683105}
I0303 23:15:39.308971 140239842563840 logging_writer.py:48] [265162] accumulated_eval_time=10030.878251, accumulated_logging_time=17.853435, accumulated_submission_time=118517.525348, global_step=265162, preemption_count=0, score=118517.525348, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=128580.788476, train/accuracy=0.887949, train/loss=0.414445, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:15:54.755638 140239850956544 logging_writer.py:48] [265200] global_step=265200, grad_norm=3.3976235389709473, loss=1.2241404056549072
I0303 23:16:38.606166 140239842563840 logging_writer.py:48] [265300] global_step=265300, grad_norm=3.328178882598877, loss=1.1704736948013306
I0303 23:17:24.014605 140239850956544 logging_writer.py:48] [265400] global_step=265400, grad_norm=2.913158416748047, loss=1.304448127746582
I0303 23:18:09.282972 140239842563840 logging_writer.py:48] [265500] global_step=265500, grad_norm=2.929523229598999, loss=1.6249605417251587
I0303 23:18:54.591986 140239850956544 logging_writer.py:48] [265600] global_step=265600, grad_norm=2.8399500846862793, loss=1.43129301071167
I0303 23:19:40.186985 140239842563840 logging_writer.py:48] [265700] global_step=265700, grad_norm=3.235191583633423, loss=2.79675030708313
I0303 23:20:25.616006 140239850956544 logging_writer.py:48] [265800] global_step=265800, grad_norm=3.055971384048462, loss=1.8680651187896729
I0303 23:21:11.112758 140239842563840 logging_writer.py:48] [265900] global_step=265900, grad_norm=3.1773617267608643, loss=1.0939476490020752
I0303 23:21:56.287865 140239850956544 logging_writer.py:48] [266000] global_step=266000, grad_norm=2.8846020698547363, loss=1.6267067193984985
I0303 23:22:39.413154 140437341357888 spec.py:321] Evaluating on the training split.
I0303 23:22:49.958744 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:23:15.900213 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:23:17.535036 140437341357888 submission_runner.py:411] Time since start: 129039.09s, 	Step: 266097, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.4173905849456787, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 118937.56853723526, 'total_duration': 129039.0865252018, 'accumulated_submission_time': 118937.56853723526, 'accumulated_eval_time': 10069.000126123428, 'accumulated_logging_time': 17.936197996139526}
I0303 23:23:17.613985 140239842563840 logging_writer.py:48] [266097] accumulated_eval_time=10069.000126, accumulated_logging_time=17.936198, accumulated_submission_time=118937.568537, global_step=266097, preemption_count=0, score=118937.568537, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=129039.086525, train/accuracy=0.888418, train/loss=0.417391, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:23:19.241862 140239850956544 logging_writer.py:48] [266100] global_step=266100, grad_norm=3.1169168949127197, loss=2.6168198585510254
I0303 23:24:00.686268 140239842563840 logging_writer.py:48] [266200] global_step=266200, grad_norm=3.1928703784942627, loss=1.8773398399353027
I0303 23:24:45.720964 140239850956544 logging_writer.py:48] [266300] global_step=266300, grad_norm=3.0094501972198486, loss=1.131134033203125
I0303 23:25:30.905419 140239842563840 logging_writer.py:48] [266400] global_step=266400, grad_norm=4.508749485015869, loss=2.465301752090454
I0303 23:26:16.506651 140239850956544 logging_writer.py:48] [266500] global_step=266500, grad_norm=3.1325700283050537, loss=1.089273452758789
I0303 23:27:01.727424 140239842563840 logging_writer.py:48] [266600] global_step=266600, grad_norm=3.078423261642456, loss=1.129918098449707
I0303 23:27:46.845110 140239850956544 logging_writer.py:48] [266700] global_step=266700, grad_norm=3.373792886734009, loss=2.916123867034912
I0303 23:28:31.988367 140239842563840 logging_writer.py:48] [266800] global_step=266800, grad_norm=3.711228609085083, loss=3.105998992919922
I0303 23:29:17.133775 140239850956544 logging_writer.py:48] [266900] global_step=266900, grad_norm=2.8893673419952393, loss=2.2892255783081055
I0303 23:30:02.381673 140239842563840 logging_writer.py:48] [267000] global_step=267000, grad_norm=2.985989809036255, loss=1.088131308555603
I0303 23:30:17.713377 140437341357888 spec.py:321] Evaluating on the training split.
I0303 23:30:27.865943 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:30:59.079384 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:31:00.698985 140437341357888 submission_runner.py:411] Time since start: 129502.25s, 	Step: 267036, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.41570112109184265, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 119357.60832476616, 'total_duration': 129502.25046014786, 'accumulated_submission_time': 119357.60832476616, 'accumulated_eval_time': 10111.985719919205, 'accumulated_logging_time': 18.02430295944214}
I0303 23:31:00.767971 140239850956544 logging_writer.py:48] [267036] accumulated_eval_time=10111.985720, accumulated_logging_time=18.024303, accumulated_submission_time=119357.608325, global_step=267036, preemption_count=0, score=119357.608325, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=129502.250460, train/accuracy=0.887598, train/loss=0.415701, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:31:26.501430 140239842563840 logging_writer.py:48] [267100] global_step=267100, grad_norm=2.846111536026001, loss=1.138712763786316
I0303 23:32:11.118636 140239850956544 logging_writer.py:48] [267200] global_step=267200, grad_norm=3.3778460025787354, loss=1.1672635078430176
I0303 23:32:56.260356 140239842563840 logging_writer.py:48] [267300] global_step=267300, grad_norm=3.0078494548797607, loss=1.3506938219070435
I0303 23:33:41.308652 140239850956544 logging_writer.py:48] [267400] global_step=267400, grad_norm=2.9133408069610596, loss=2.2341349124908447
I0303 23:34:26.419765 140239842563840 logging_writer.py:48] [267500] global_step=267500, grad_norm=2.95575213432312, loss=1.0553226470947266
I0303 23:35:11.781212 140239850956544 logging_writer.py:48] [267600] global_step=267600, grad_norm=3.082272529602051, loss=2.094980478286743
I0303 23:35:56.929721 140239842563840 logging_writer.py:48] [267700] global_step=267700, grad_norm=3.081143379211426, loss=2.187859058380127
I0303 23:36:42.755701 140239850956544 logging_writer.py:48] [267800] global_step=267800, grad_norm=3.135434627532959, loss=1.0691251754760742
I0303 23:37:28.104778 140239842563840 logging_writer.py:48] [267900] global_step=267900, grad_norm=3.372490882873535, loss=1.2899603843688965
I0303 23:38:01.036705 140437341357888 spec.py:321] Evaluating on the training split.
I0303 23:38:11.379569 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:38:37.602858 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:38:39.230741 140437341357888 submission_runner.py:411] Time since start: 129960.78s, 	Step: 267975, 	{'train/accuracy': 0.8877733945846558, 'train/loss': 0.41517898440361023, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 119777.81729054451, 'total_duration': 129960.78221297264, 'accumulated_submission_time': 119777.81729054451, 'accumulated_eval_time': 10150.179717302322, 'accumulated_logging_time': 18.103163957595825}
I0303 23:38:39.298816 140239850956544 logging_writer.py:48] [267975] accumulated_eval_time=10150.179717, accumulated_logging_time=18.103164, accumulated_submission_time=119777.817291, global_step=267975, preemption_count=0, score=119777.817291, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=129960.782213, train/accuracy=0.887773, train/loss=0.415179, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:38:49.613652 140239842563840 logging_writer.py:48] [268000] global_step=268000, grad_norm=3.08581805229187, loss=1.6590173244476318
I0303 23:39:32.224724 140239850956544 logging_writer.py:48] [268100] global_step=268100, grad_norm=2.9894063472747803, loss=1.1122022867202759
I0303 23:40:17.331309 140239842563840 logging_writer.py:48] [268200] global_step=268200, grad_norm=2.8956127166748047, loss=1.232484221458435
I0303 23:41:02.817654 140239850956544 logging_writer.py:48] [268300] global_step=268300, grad_norm=2.9824934005737305, loss=1.0708633661270142
I0303 23:41:48.044047 140239842563840 logging_writer.py:48] [268400] global_step=268400, grad_norm=3.0649428367614746, loss=1.3117603063583374
I0303 23:42:33.450747 140239850956544 logging_writer.py:48] [268500] global_step=268500, grad_norm=3.084932327270508, loss=1.2180215120315552
I0303 23:43:18.737597 140239842563840 logging_writer.py:48] [268600] global_step=268600, grad_norm=3.836822748184204, loss=3.1968657970428467
I0303 23:44:03.960874 140239850956544 logging_writer.py:48] [268700] global_step=268700, grad_norm=3.472716808319092, loss=1.044905424118042
I0303 23:44:49.066910 140239842563840 logging_writer.py:48] [268800] global_step=268800, grad_norm=2.8519668579101562, loss=1.3768872022628784
I0303 23:45:34.407354 140239850956544 logging_writer.py:48] [268900] global_step=268900, grad_norm=3.1096603870391846, loss=1.1282238960266113
I0303 23:45:39.540949 140437341357888 spec.py:321] Evaluating on the training split.
I0303 23:45:49.961097 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:46:18.070611 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:46:19.693630 140437341357888 submission_runner.py:411] Time since start: 130421.25s, 	Step: 268913, 	{'train/accuracy': 0.8890820145606995, 'train/loss': 0.411138653755188, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 120197.99805498123, 'total_duration': 130421.24511313438, 'accumulated_submission_time': 120197.99805498123, 'accumulated_eval_time': 10190.332374095917, 'accumulated_logging_time': 18.181214332580566}
I0303 23:46:19.764720 140239842563840 logging_writer.py:48] [268913] accumulated_eval_time=10190.332374, accumulated_logging_time=18.181214, accumulated_submission_time=120197.998055, global_step=268913, preemption_count=0, score=120197.998055, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=130421.245113, train/accuracy=0.889082, train/loss=0.411139, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:46:55.589318 140239850956544 logging_writer.py:48] [269000] global_step=269000, grad_norm=2.7958779335021973, loss=1.361156702041626
I0303 23:47:40.960556 140239842563840 logging_writer.py:48] [269100] global_step=269100, grad_norm=3.0686683654785156, loss=1.513486623764038
I0303 23:48:26.377026 140239850956544 logging_writer.py:48] [269200] global_step=269200, grad_norm=3.408048152923584, loss=2.8610856533050537
I0303 23:49:11.766770 140239842563840 logging_writer.py:48] [269300] global_step=269300, grad_norm=2.957413673400879, loss=1.1732075214385986
I0303 23:49:56.829706 140239850956544 logging_writer.py:48] [269400] global_step=269400, grad_norm=2.869007110595703, loss=2.396862745285034
I0303 23:50:42.152725 140239842563840 logging_writer.py:48] [269500] global_step=269500, grad_norm=3.4978339672088623, loss=1.2294433116912842
I0303 23:51:27.466482 140239850956544 logging_writer.py:48] [269600] global_step=269600, grad_norm=3.2388811111450195, loss=2.7645061016082764
I0303 23:52:12.784130 140239842563840 logging_writer.py:48] [269700] global_step=269700, grad_norm=2.892143964767456, loss=1.1324174404144287
I0303 23:52:57.950529 140239850956544 logging_writer.py:48] [269800] global_step=269800, grad_norm=2.9201152324676514, loss=1.1289238929748535
I0303 23:53:19.824141 140437341357888 spec.py:321] Evaluating on the training split.
I0303 23:53:30.007922 140437341357888 spec.py:333] Evaluating on the validation split.
I0303 23:53:56.653537 140437341357888 spec.py:349] Evaluating on the test split.
I0303 23:53:58.282552 140437341357888 submission_runner.py:411] Time since start: 130879.83s, 	Step: 269850, 	{'train/accuracy': 0.8871679306030273, 'train/loss': 0.42296358942985535, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 120617.99323821068, 'total_duration': 130879.83401083946, 'accumulated_submission_time': 120617.99323821068, 'accumulated_eval_time': 10228.79074215889, 'accumulated_logging_time': 18.266133069992065}
I0303 23:53:58.348457 140239842563840 logging_writer.py:48] [269850] accumulated_eval_time=10228.790742, accumulated_logging_time=18.266133, accumulated_submission_time=120617.993238, global_step=269850, preemption_count=0, score=120617.993238, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=130879.834011, train/accuracy=0.887168, train/loss=0.422964, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0303 23:54:18.550101 140239850956544 logging_writer.py:48] [269900] global_step=269900, grad_norm=3.092848777770996, loss=1.136734127998352
I0303 23:55:02.080568 140239842563840 logging_writer.py:48] [270000] global_step=270000, grad_norm=3.8037948608398438, loss=3.2789340019226074
I0303 23:55:47.016707 140239850956544 logging_writer.py:48] [270100] global_step=270100, grad_norm=3.287396192550659, loss=1.749335765838623
I0303 23:56:32.423111 140239842563840 logging_writer.py:48] [270200] global_step=270200, grad_norm=2.9269495010375977, loss=2.6109838485717773
I0303 23:57:17.881992 140239850956544 logging_writer.py:48] [270300] global_step=270300, grad_norm=3.07647967338562, loss=1.144655704498291
I0303 23:58:03.195949 140239842563840 logging_writer.py:48] [270400] global_step=270400, grad_norm=2.7695937156677246, loss=1.6477627754211426
I0303 23:58:48.261985 140239850956544 logging_writer.py:48] [270500] global_step=270500, grad_norm=3.1534223556518555, loss=1.4057377576828003
I0303 23:59:33.509845 140239842563840 logging_writer.py:48] [270600] global_step=270600, grad_norm=2.8878519535064697, loss=1.7921593189239502
I0304 00:00:18.717764 140239850956544 logging_writer.py:48] [270700] global_step=270700, grad_norm=3.049638032913208, loss=2.6868252754211426
I0304 00:00:58.414616 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:01:08.779188 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:01:37.555801 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:01:39.181782 140437341357888 submission_runner.py:411] Time since start: 131340.73s, 	Step: 270790, 	{'train/accuracy': 0.88929682970047, 'train/loss': 0.4126971662044525, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 121037.99829053879, 'total_duration': 131340.73326659203, 'accumulated_submission_time': 121037.99829053879, 'accumulated_eval_time': 10269.557882547379, 'accumulated_logging_time': 18.342522621154785}
I0304 00:01:39.250947 140239842563840 logging_writer.py:48] [270790] accumulated_eval_time=10269.557883, accumulated_logging_time=18.342523, accumulated_submission_time=121037.998291, global_step=270790, preemption_count=0, score=121037.998291, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=131340.733267, train/accuracy=0.889297, train/loss=0.412697, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:01:43.839695 140239850956544 logging_writer.py:48] [270800] global_step=270800, grad_norm=2.9372453689575195, loss=1.125178575515747
I0304 00:02:25.290246 140239842563840 logging_writer.py:48] [270900] global_step=270900, grad_norm=4.690652370452881, loss=3.2568247318267822
I0304 00:03:10.435792 140239850956544 logging_writer.py:48] [271000] global_step=271000, grad_norm=3.7752413749694824, loss=3.2797908782958984
I0304 00:03:55.675240 140239842563840 logging_writer.py:48] [271100] global_step=271100, grad_norm=2.595414400100708, loss=2.2344307899475098
I0304 00:04:40.668573 140239850956544 logging_writer.py:48] [271200] global_step=271200, grad_norm=2.9871652126312256, loss=1.9156477451324463
I0304 00:05:25.723642 140239842563840 logging_writer.py:48] [271300] global_step=271300, grad_norm=3.1486623287200928, loss=1.8089946508407593
I0304 00:06:10.876701 140239850956544 logging_writer.py:48] [271400] global_step=271400, grad_norm=3.30670428276062, loss=1.7996457815170288
I0304 00:06:56.444146 140239842563840 logging_writer.py:48] [271500] global_step=271500, grad_norm=3.1239335536956787, loss=2.827198028564453
I0304 00:07:41.541178 140239850956544 logging_writer.py:48] [271600] global_step=271600, grad_norm=3.336064100265503, loss=2.3179733753204346
I0304 00:08:26.589217 140239842563840 logging_writer.py:48] [271700] global_step=271700, grad_norm=3.189152956008911, loss=1.0813531875610352
I0304 00:08:39.289685 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:08:49.624206 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:09:16.596385 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:09:18.220871 140437341357888 submission_runner.py:411] Time since start: 131799.77s, 	Step: 271730, 	{'train/accuracy': 0.8877539038658142, 'train/loss': 0.4173440933227539, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 121457.97619390488, 'total_duration': 131799.77235770226, 'accumulated_submission_time': 121457.97619390488, 'accumulated_eval_time': 10308.489049196243, 'accumulated_logging_time': 18.421640157699585}
I0304 00:09:18.295561 140239850956544 logging_writer.py:48] [271730] accumulated_eval_time=10308.489049, accumulated_logging_time=18.421640, accumulated_submission_time=121457.976194, global_step=271730, preemption_count=0, score=121457.976194, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=131799.772358, train/accuracy=0.887754, train/loss=0.417344, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:09:46.405786 140239842563840 logging_writer.py:48] [271800] global_step=271800, grad_norm=5.778316497802734, loss=3.2553577423095703
I0304 00:10:31.289536 140239850956544 logging_writer.py:48] [271900] global_step=271900, grad_norm=3.6776227951049805, loss=1.198677659034729
I0304 00:11:16.428194 140239842563840 logging_writer.py:48] [272000] global_step=272000, grad_norm=2.9995920658111572, loss=1.765982747077942
I0304 00:12:01.467218 140239850956544 logging_writer.py:48] [272100] global_step=272100, grad_norm=3.582923173904419, loss=3.00459623336792
I0304 00:12:46.874647 140239842563840 logging_writer.py:48] [272200] global_step=272200, grad_norm=3.157592535018921, loss=1.1803878545761108
I0304 00:13:31.953099 140239850956544 logging_writer.py:48] [272300] global_step=272300, grad_norm=2.880671501159668, loss=1.33953857421875
I0304 00:14:16.983082 140239842563840 logging_writer.py:48] [272400] global_step=272400, grad_norm=3.0472567081451416, loss=1.1709970235824585
I0304 00:15:02.143732 140239850956544 logging_writer.py:48] [272500] global_step=272500, grad_norm=3.6263887882232666, loss=3.188453435897827
I0304 00:15:47.403246 140239842563840 logging_writer.py:48] [272600] global_step=272600, grad_norm=2.9426562786102295, loss=1.1762932538986206
I0304 00:16:18.332474 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:16:28.598298 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:16:58.109415 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:16:59.734785 140437341357888 submission_runner.py:411] Time since start: 132261.29s, 	Step: 272670, 	{'train/accuracy': 0.88832026720047, 'train/loss': 0.41564127802848816, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 121877.95221614838, 'total_duration': 132261.28627204895, 'accumulated_submission_time': 121877.95221614838, 'accumulated_eval_time': 10349.891362667084, 'accumulated_logging_time': 18.50593400001526}
I0304 00:16:59.809097 140239850956544 logging_writer.py:48] [272670] accumulated_eval_time=10349.891363, accumulated_logging_time=18.505934, accumulated_submission_time=121877.952216, global_step=272670, preemption_count=0, score=121877.952216, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=132261.286272, train/accuracy=0.888320, train/loss=0.415641, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:17:12.094530 140239842563840 logging_writer.py:48] [272700] global_step=272700, grad_norm=3.2165944576263428, loss=1.670823574066162
I0304 00:17:54.908966 140239850956544 logging_writer.py:48] [272800] global_step=272800, grad_norm=3.3709535598754883, loss=1.2307811975479126
I0304 00:18:40.590503 140239842563840 logging_writer.py:48] [272900] global_step=272900, grad_norm=3.1533424854278564, loss=2.6875627040863037
I0304 00:19:25.924829 140239850956544 logging_writer.py:48] [273000] global_step=273000, grad_norm=2.8404743671417236, loss=1.0101827383041382
I0304 00:20:10.986531 140239842563840 logging_writer.py:48] [273100] global_step=273100, grad_norm=3.596275568008423, loss=3.01823353767395
I0304 00:20:55.948972 140239850956544 logging_writer.py:48] [273200] global_step=273200, grad_norm=3.141603946685791, loss=1.0530956983566284
I0304 00:21:41.158950 140239842563840 logging_writer.py:48] [273300] global_step=273300, grad_norm=2.9234213829040527, loss=1.0402621030807495
I0304 00:22:26.359348 140239850956544 logging_writer.py:48] [273400] global_step=273400, grad_norm=3.0434515476226807, loss=1.6005582809448242
I0304 00:23:11.576352 140239842563840 logging_writer.py:48] [273500] global_step=273500, grad_norm=3.0620391368865967, loss=1.9782187938690186
I0304 00:23:56.625689 140239850956544 logging_writer.py:48] [273600] global_step=273600, grad_norm=3.6330513954162598, loss=3.0708212852478027
I0304 00:23:59.879648 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:24:10.254500 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:24:43.868617 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:24:45.488969 140437341357888 submission_runner.py:411] Time since start: 132727.04s, 	Step: 273609, 	{'train/accuracy': 0.8891796469688416, 'train/loss': 0.4100504517555237, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 122297.96140408516, 'total_duration': 132727.0404522419, 'accumulated_submission_time': 122297.96140408516, 'accumulated_eval_time': 10395.50066781044, 'accumulated_logging_time': 18.59084153175354}
I0304 00:24:45.560978 140239842563840 logging_writer.py:48] [273609] accumulated_eval_time=10395.500668, accumulated_logging_time=18.590842, accumulated_submission_time=122297.961404, global_step=273609, preemption_count=0, score=122297.961404, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=132727.040452, train/accuracy=0.889180, train/loss=0.410050, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:25:22.025688 140239850956544 logging_writer.py:48] [273700] global_step=273700, grad_norm=2.8773274421691895, loss=1.0578876733779907
I0304 00:26:06.433094 140239842563840 logging_writer.py:48] [273800] global_step=273800, grad_norm=3.8969805240631104, loss=3.197514772415161
I0304 00:26:51.658690 140239850956544 logging_writer.py:48] [273900] global_step=273900, grad_norm=2.876211166381836, loss=1.4455405473709106
I0304 00:27:37.514945 140239842563840 logging_writer.py:48] [274000] global_step=274000, grad_norm=3.1709396839141846, loss=1.2052931785583496
I0304 00:28:22.683882 140239850956544 logging_writer.py:48] [274100] global_step=274100, grad_norm=3.3155720233917236, loss=2.9630346298217773
I0304 00:29:08.109105 140239842563840 logging_writer.py:48] [274200] global_step=274200, grad_norm=3.0837209224700928, loss=1.4389870166778564
I0304 00:29:53.138988 140239850956544 logging_writer.py:48] [274300] global_step=274300, grad_norm=3.3088347911834717, loss=1.2061583995819092
I0304 00:30:38.620359 140239842563840 logging_writer.py:48] [274400] global_step=274400, grad_norm=4.2817301750183105, loss=3.2435240745544434
I0304 00:31:23.709296 140239850956544 logging_writer.py:48] [274500] global_step=274500, grad_norm=3.149524450302124, loss=1.2080495357513428
I0304 00:31:45.561043 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:31:55.732961 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:32:19.345396 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:32:20.969839 140437341357888 submission_runner.py:411] Time since start: 133182.52s, 	Step: 274550, 	{'train/accuracy': 0.8878515362739563, 'train/loss': 0.4165761172771454, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 122717.90025830269, 'total_duration': 133182.52132487297, 'accumulated_submission_time': 122717.90025830269, 'accumulated_eval_time': 10430.909448862076, 'accumulated_logging_time': 18.673195123672485}
I0304 00:32:21.040541 140239842563840 logging_writer.py:48] [274550] accumulated_eval_time=10430.909449, accumulated_logging_time=18.673195, accumulated_submission_time=122717.900258, global_step=274550, preemption_count=0, score=122717.900258, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=133182.521325, train/accuracy=0.887852, train/loss=0.416576, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:32:41.276586 140239850956544 logging_writer.py:48] [274600] global_step=274600, grad_norm=3.309183120727539, loss=1.2850213050842285
I0304 00:33:25.489174 140239842563840 logging_writer.py:48] [274700] global_step=274700, grad_norm=3.1230216026306152, loss=1.0691838264465332
I0304 00:34:10.651607 140239850956544 logging_writer.py:48] [274800] global_step=274800, grad_norm=2.99937105178833, loss=0.9910179972648621
I0304 00:34:55.963969 140239842563840 logging_writer.py:48] [274900] global_step=274900, grad_norm=4.22274112701416, loss=1.1869441270828247
I0304 00:35:41.212372 140239850956544 logging_writer.py:48] [275000] global_step=275000, grad_norm=2.868488073348999, loss=1.65910005569458
I0304 00:36:26.161190 140239842563840 logging_writer.py:48] [275100] global_step=275100, grad_norm=3.3450164794921875, loss=2.7171008586883545
I0304 00:37:11.683660 140239850956544 logging_writer.py:48] [275200] global_step=275200, grad_norm=3.2261335849761963, loss=1.3267523050308228
I0304 00:37:56.935825 140239842563840 logging_writer.py:48] [275300] global_step=275300, grad_norm=3.051577568054199, loss=1.4269689321517944
I0304 00:38:42.078857 140239850956544 logging_writer.py:48] [275400] global_step=275400, grad_norm=3.09439754486084, loss=1.1197723150253296
I0304 00:39:21.245729 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:39:31.761711 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:40:00.959980 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:40:02.590674 140437341357888 submission_runner.py:411] Time since start: 133644.14s, 	Step: 275488, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.4122629761695862, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 123138.03974294662, 'total_duration': 133644.14214658737, 'accumulated_submission_time': 123138.03974294662, 'accumulated_eval_time': 10472.254363298416, 'accumulated_logging_time': 18.758079528808594}
I0304 00:40:02.657157 140239842563840 logging_writer.py:48] [275488] accumulated_eval_time=10472.254363, accumulated_logging_time=18.758080, accumulated_submission_time=123138.039743, global_step=275488, preemption_count=0, score=123138.039743, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=133644.142147, train/accuracy=0.888730, train/loss=0.412263, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:40:07.823449 140239850956544 logging_writer.py:48] [275500] global_step=275500, grad_norm=3.58372163772583, loss=2.620800018310547
I0304 00:40:49.844306 140239850956544 logging_writer.py:48] [275600] global_step=275600, grad_norm=3.535151243209839, loss=3.030294418334961
I0304 00:41:34.939747 140239842563840 logging_writer.py:48] [275700] global_step=275700, grad_norm=3.2139499187469482, loss=1.2839239835739136
I0304 00:42:20.060185 140239850956544 logging_writer.py:48] [275800] global_step=275800, grad_norm=3.108280897140503, loss=1.1541863679885864
I0304 00:43:05.254362 140239842563840 logging_writer.py:48] [275900] global_step=275900, grad_norm=3.014826774597168, loss=1.1550509929656982
I0304 00:43:50.520173 140239850956544 logging_writer.py:48] [276000] global_step=276000, grad_norm=3.6506168842315674, loss=3.2268593311309814
I0304 00:44:35.914438 140239842563840 logging_writer.py:48] [276100] global_step=276100, grad_norm=3.117143392562866, loss=1.0488827228546143
I0304 00:45:21.160720 140239850956544 logging_writer.py:48] [276200] global_step=276200, grad_norm=2.979127883911133, loss=2.212827205657959
I0304 00:46:06.282711 140239842563840 logging_writer.py:48] [276300] global_step=276300, grad_norm=3.23075008392334, loss=1.1254328489303589
I0304 00:46:51.643589 140239850956544 logging_writer.py:48] [276400] global_step=276400, grad_norm=3.6890132427215576, loss=3.073026418685913
I0304 00:47:02.850954 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:47:13.206562 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:47:41.614066 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:47:43.230874 140437341357888 submission_runner.py:411] Time since start: 134104.78s, 	Step: 276426, 	{'train/accuracy': 0.8866796493530273, 'train/loss': 0.4174808859825134, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 123558.17305517197, 'total_duration': 134104.78236317635, 'accumulated_submission_time': 123558.17305517197, 'accumulated_eval_time': 10512.6342856884, 'accumulated_logging_time': 18.83539652824402}
I0304 00:47:43.302158 140239842563840 logging_writer.py:48] [276426] accumulated_eval_time=10512.634286, accumulated_logging_time=18.835397, accumulated_submission_time=123558.173055, global_step=276426, preemption_count=0, score=123558.173055, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=134104.782363, train/accuracy=0.886680, train/loss=0.417481, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:48:13.203517 140239850956544 logging_writer.py:48] [276500] global_step=276500, grad_norm=3.29441237449646, loss=2.7863316535949707
I0304 00:48:58.356065 140239842563840 logging_writer.py:48] [276600] global_step=276600, grad_norm=3.1785049438476562, loss=1.163515567779541
I0304 00:49:43.835653 140239850956544 logging_writer.py:48] [276700] global_step=276700, grad_norm=3.295761823654175, loss=1.1059154272079468
I0304 00:50:28.930683 140239842563840 logging_writer.py:48] [276800] global_step=276800, grad_norm=3.262174606323242, loss=1.1509921550750732
I0304 00:51:14.213280 140239850956544 logging_writer.py:48] [276900] global_step=276900, grad_norm=2.770110845565796, loss=1.476434588432312
I0304 00:51:59.266931 140239842563840 logging_writer.py:48] [277000] global_step=277000, grad_norm=2.909085750579834, loss=1.4087377786636353
I0304 00:52:44.601767 140239850956544 logging_writer.py:48] [277100] global_step=277100, grad_norm=3.012566328048706, loss=1.1016756296157837
I0304 00:53:29.873909 140239842563840 logging_writer.py:48] [277200] global_step=277200, grad_norm=3.238792657852173, loss=2.253570556640625
I0304 00:54:15.011670 140239850956544 logging_writer.py:48] [277300] global_step=277300, grad_norm=3.5529675483703613, loss=3.0204429626464844
I0304 00:54:43.538969 140437341357888 spec.py:321] Evaluating on the training split.
I0304 00:54:54.109235 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 00:55:20.696956 140437341357888 spec.py:349] Evaluating on the test split.
I0304 00:55:22.326395 140437341357888 submission_runner.py:411] Time since start: 134563.88s, 	Step: 277365, 	{'train/accuracy': 0.8886132836341858, 'train/loss': 0.4149703085422516, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 123978.34770202637, 'total_duration': 134563.87787127495, 'accumulated_submission_time': 123978.34770202637, 'accumulated_eval_time': 10551.421706914902, 'accumulated_logging_time': 18.918168783187866}
I0304 00:55:22.392440 140239842563840 logging_writer.py:48] [277365] accumulated_eval_time=10551.421707, accumulated_logging_time=18.918169, accumulated_submission_time=123978.347702, global_step=277365, preemption_count=0, score=123978.347702, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=134563.877871, train/accuracy=0.888613, train/loss=0.414970, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 00:55:36.646972 140239850956544 logging_writer.py:48] [277400] global_step=277400, grad_norm=2.8339684009552, loss=1.9277558326721191
I0304 00:56:19.659373 140239842563840 logging_writer.py:48] [277500] global_step=277500, grad_norm=2.839625120162964, loss=1.090298056602478
I0304 00:57:04.779372 140239850956544 logging_writer.py:48] [277600] global_step=277600, grad_norm=2.9390740394592285, loss=1.1347192525863647
I0304 00:57:50.003115 140239842563840 logging_writer.py:48] [277700] global_step=277700, grad_norm=2.936863660812378, loss=1.1183185577392578
I0304 00:58:35.429076 140239850956544 logging_writer.py:48] [277800] global_step=277800, grad_norm=3.0521504878997803, loss=1.0769308805465698
I0304 00:59:20.733794 140239842563840 logging_writer.py:48] [277900] global_step=277900, grad_norm=3.4491240978240967, loss=1.2646148204803467
I0304 01:00:06.287349 140239850956544 logging_writer.py:48] [278000] global_step=278000, grad_norm=3.460522174835205, loss=2.915123224258423
I0304 01:00:51.256288 140239842563840 logging_writer.py:48] [278100] global_step=278100, grad_norm=3.117473840713501, loss=1.9585319757461548
I0304 01:01:36.412954 140239850956544 logging_writer.py:48] [278200] global_step=278200, grad_norm=2.9488577842712402, loss=1.6477432250976562
I0304 01:02:21.598585 140239842563840 logging_writer.py:48] [278300] global_step=278300, grad_norm=3.1794371604919434, loss=1.3655463457107544
I0304 01:02:22.664589 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:02:33.073945 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:02:59.865585 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:03:01.491848 140437341357888 submission_runner.py:411] Time since start: 135023.04s, 	Step: 278304, 	{'train/accuracy': 0.8903124928474426, 'train/loss': 0.4152889549732208, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 124398.55496621132, 'total_duration': 135023.04332780838, 'accumulated_submission_time': 124398.55496621132, 'accumulated_eval_time': 10590.248939752579, 'accumulated_logging_time': 18.998623609542847}
I0304 01:03:01.577520 140239850956544 logging_writer.py:48] [278304] accumulated_eval_time=10590.248940, accumulated_logging_time=18.998624, accumulated_submission_time=124398.554966, global_step=278304, preemption_count=0, score=124398.554966, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=135023.043328, train/accuracy=0.890312, train/loss=0.415289, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:03:41.381175 140239842563840 logging_writer.py:48] [278400] global_step=278400, grad_norm=5.272312641143799, loss=2.87747859954834
I0304 01:04:26.455655 140239850956544 logging_writer.py:48] [278500] global_step=278500, grad_norm=3.2198400497436523, loss=1.4405543804168701
I0304 01:05:11.887846 140239842563840 logging_writer.py:48] [278600] global_step=278600, grad_norm=3.8057754039764404, loss=3.2628931999206543
I0304 01:05:56.843748 140239850956544 logging_writer.py:48] [278700] global_step=278700, grad_norm=2.905858278274536, loss=1.6585988998413086
I0304 01:06:41.924282 140239842563840 logging_writer.py:48] [278800] global_step=278800, grad_norm=3.2041175365448, loss=2.7458081245422363
I0304 01:07:27.069846 140239850956544 logging_writer.py:48] [278900] global_step=278900, grad_norm=3.2396819591522217, loss=1.212860107421875
I0304 01:08:12.604529 140239842563840 logging_writer.py:48] [279000] global_step=279000, grad_norm=3.287442207336426, loss=2.8225200176239014
I0304 01:08:57.954561 140239850956544 logging_writer.py:48] [279100] global_step=279100, grad_norm=3.110931158065796, loss=1.1234487295150757
I0304 01:09:43.208762 140239842563840 logging_writer.py:48] [279200] global_step=279200, grad_norm=3.334275722503662, loss=1.124028205871582
I0304 01:10:01.709827 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:10:11.978862 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:10:38.854636 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:10:40.475323 140437341357888 submission_runner.py:411] Time since start: 135482.03s, 	Step: 279242, 	{'train/accuracy': 0.888671875, 'train/loss': 0.40865954756736755, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 124818.6222038269, 'total_duration': 135482.02679228783, 'accumulated_submission_time': 124818.6222038269, 'accumulated_eval_time': 10629.01440358162, 'accumulated_logging_time': 19.098854541778564}
I0304 01:10:40.548585 140239850956544 logging_writer.py:48] [279242] accumulated_eval_time=10629.014404, accumulated_logging_time=19.098855, accumulated_submission_time=124818.622204, global_step=279242, preemption_count=0, score=124818.622204, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=135482.026792, train/accuracy=0.888672, train/loss=0.408660, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:11:03.932082 140239842563840 logging_writer.py:48] [279300] global_step=279300, grad_norm=3.1022517681121826, loss=2.3686840534210205
I0304 01:11:48.359956 140239850956544 logging_writer.py:48] [279400] global_step=279400, grad_norm=3.628506898880005, loss=3.168971538543701
I0304 01:12:33.713338 140239842563840 logging_writer.py:48] [279500] global_step=279500, grad_norm=3.0946006774902344, loss=1.1587504148483276
I0304 01:13:18.817340 140239850956544 logging_writer.py:48] [279600] global_step=279600, grad_norm=3.323972463607788, loss=2.7237093448638916
I0304 01:14:04.276950 140239842563840 logging_writer.py:48] [279700] global_step=279700, grad_norm=2.738064765930176, loss=1.8089090585708618
I0304 01:14:49.466943 140239850956544 logging_writer.py:48] [279800] global_step=279800, grad_norm=3.8135743141174316, loss=3.3017592430114746
I0304 01:15:34.802186 140239842563840 logging_writer.py:48] [279900] global_step=279900, grad_norm=2.8903744220733643, loss=1.1772544384002686
I0304 01:16:20.150096 140239850956544 logging_writer.py:48] [280000] global_step=280000, grad_norm=3.074521780014038, loss=1.4463658332824707
I0304 01:17:05.889993 140239842563840 logging_writer.py:48] [280100] global_step=280100, grad_norm=3.613940715789795, loss=3.189514636993408
I0304 01:17:40.814824 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:17:51.119727 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:18:19.001768 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:18:20.622043 140437341357888 submission_runner.py:411] Time since start: 135942.17s, 	Step: 280179, 	{'train/accuracy': 0.8921093344688416, 'train/loss': 0.4076516628265381, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 125238.82615542412, 'total_duration': 135942.1735329628, 'accumulated_submission_time': 125238.82615542412, 'accumulated_eval_time': 10668.821629047394, 'accumulated_logging_time': 19.18437695503235}
I0304 01:18:20.693922 140239850956544 logging_writer.py:48] [280179] accumulated_eval_time=10668.821629, accumulated_logging_time=19.184377, accumulated_submission_time=125238.826155, global_step=280179, preemption_count=0, score=125238.826155, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=135942.173533, train/accuracy=0.892109, train/loss=0.407652, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:18:29.419395 140239842563840 logging_writer.py:48] [280200] global_step=280200, grad_norm=3.193824291229248, loss=2.530611515045166
I0304 01:19:11.817540 140239850956544 logging_writer.py:48] [280300] global_step=280300, grad_norm=3.2109196186065674, loss=2.470557689666748
I0304 01:19:56.976271 140239842563840 logging_writer.py:48] [280400] global_step=280400, grad_norm=2.960374355316162, loss=1.4963959455490112
I0304 01:20:42.169938 140239850956544 logging_writer.py:48] [280500] global_step=280500, grad_norm=3.5247995853424072, loss=3.192201852798462
I0304 01:21:27.245178 140239842563840 logging_writer.py:48] [280600] global_step=280600, grad_norm=3.023695230484009, loss=2.013422966003418
I0304 01:22:12.300911 140239850956544 logging_writer.py:48] [280700] global_step=280700, grad_norm=2.985302686691284, loss=1.476043462753296
I0304 01:22:57.362189 140239842563840 logging_writer.py:48] [280800] global_step=280800, grad_norm=3.194798469543457, loss=2.853682518005371
I0304 01:23:42.538171 140239850956544 logging_writer.py:48] [280900] global_step=280900, grad_norm=2.9030981063842773, loss=1.1670358180999756
I0304 01:24:27.915238 140239842563840 logging_writer.py:48] [281000] global_step=281000, grad_norm=2.8418214321136475, loss=1.0331529378890991
I0304 01:25:13.219236 140239850956544 logging_writer.py:48] [281100] global_step=281100, grad_norm=2.9857890605926514, loss=1.127569556236267
I0304 01:25:20.969432 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:25:32.161069 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:25:58.673832 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:26:00.300054 140437341357888 submission_runner.py:411] Time since start: 136401.85s, 	Step: 281119, 	{'train/accuracy': 0.8885937333106995, 'train/loss': 0.414132297039032, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 125659.04063010216, 'total_duration': 136401.85151863098, 'accumulated_submission_time': 125659.04063010216, 'accumulated_eval_time': 10708.152201652527, 'accumulated_logging_time': 19.266141891479492}
I0304 01:26:00.373137 140239842563840 logging_writer.py:48] [281119] accumulated_eval_time=10708.152202, accumulated_logging_time=19.266142, accumulated_submission_time=125659.040630, global_step=281119, preemption_count=0, score=125659.040630, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=136401.851519, train/accuracy=0.888594, train/loss=0.414132, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:26:33.209527 140239850956544 logging_writer.py:48] [281200] global_step=281200, grad_norm=3.0652639865875244, loss=1.1349124908447266
I0304 01:27:18.079468 140239842563840 logging_writer.py:48] [281300] global_step=281300, grad_norm=3.2203543186187744, loss=1.261979341506958
I0304 01:28:02.970977 140239850956544 logging_writer.py:48] [281400] global_step=281400, grad_norm=2.95395565032959, loss=2.2921934127807617
I0304 01:28:48.308418 140239842563840 logging_writer.py:48] [281500] global_step=281500, grad_norm=3.1023709774017334, loss=2.8125061988830566
I0304 01:29:33.622538 140239850956544 logging_writer.py:48] [281600] global_step=281600, grad_norm=3.2326018810272217, loss=1.101877212524414
I0304 01:30:18.993486 140239842563840 logging_writer.py:48] [281700] global_step=281700, grad_norm=3.2200496196746826, loss=1.1018439531326294
I0304 01:31:04.113499 140239850956544 logging_writer.py:48] [281800] global_step=281800, grad_norm=3.8214242458343506, loss=3.1478047370910645
I0304 01:31:49.198402 140239842563840 logging_writer.py:48] [281900] global_step=281900, grad_norm=3.1550543308258057, loss=1.153120994567871
I0304 01:32:34.310885 140239850956544 logging_writer.py:48] [282000] global_step=282000, grad_norm=3.1581852436065674, loss=1.1210139989852905
I0304 01:33:00.542482 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:33:10.992479 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:33:44.455452 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:33:46.080024 140437341357888 submission_runner.py:411] Time since start: 136867.63s, 	Step: 282060, 	{'train/accuracy': 0.8877929449081421, 'train/loss': 0.4160957634449005, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 126079.14900970459, 'total_duration': 136867.63150930405, 'accumulated_submission_time': 126079.14900970459, 'accumulated_eval_time': 10753.6897149086, 'accumulated_logging_time': 19.349141597747803}
I0304 01:33:46.152773 140239842563840 logging_writer.py:48] [282060] accumulated_eval_time=10753.689715, accumulated_logging_time=19.349142, accumulated_submission_time=126079.149010, global_step=282060, preemption_count=0, score=126079.149010, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=136867.631509, train/accuracy=0.887793, train/loss=0.416096, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:34:02.403352 140239850956544 logging_writer.py:48] [282100] global_step=282100, grad_norm=3.6387853622436523, loss=3.312419891357422
I0304 01:34:44.798593 140239842563840 logging_writer.py:48] [282200] global_step=282200, grad_norm=3.298072099685669, loss=1.1853982210159302
I0304 01:35:29.874363 140239850956544 logging_writer.py:48] [282300] global_step=282300, grad_norm=3.1095292568206787, loss=1.502311110496521
I0304 01:36:15.235403 140239842563840 logging_writer.py:48] [282400] global_step=282400, grad_norm=3.318286657333374, loss=2.9576640129089355
I0304 01:37:00.469386 140239850956544 logging_writer.py:48] [282500] global_step=282500, grad_norm=3.157806634902954, loss=1.0493475198745728
I0304 01:37:45.508657 140239842563840 logging_writer.py:48] [282600] global_step=282600, grad_norm=3.2866923809051514, loss=2.85802960395813
I0304 01:38:30.846417 140239850956544 logging_writer.py:48] [282700] global_step=282700, grad_norm=3.033034086227417, loss=1.028666377067566
I0304 01:39:16.743523 140239842563840 logging_writer.py:48] [282800] global_step=282800, grad_norm=3.3185954093933105, loss=2.814425468444824
I0304 01:40:02.081809 140239850956544 logging_writer.py:48] [282900] global_step=282900, grad_norm=3.050109624862671, loss=1.1770535707473755
I0304 01:40:46.394864 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:40:56.694390 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:41:20.535820 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:41:22.154500 140437341357888 submission_runner.py:411] Time since start: 137323.71s, 	Step: 282999, 	{'train/accuracy': 0.8861523270606995, 'train/loss': 0.418018102645874, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 126499.32816338539, 'total_duration': 137323.70598578453, 'accumulated_submission_time': 126499.32816338539, 'accumulated_eval_time': 10789.449345111847, 'accumulated_logging_time': 19.43389129638672}
I0304 01:41:22.229510 140239842563840 logging_writer.py:48] [282999] accumulated_eval_time=10789.449345, accumulated_logging_time=19.433891, accumulated_submission_time=126499.328163, global_step=282999, preemption_count=0, score=126499.328163, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=137323.705986, train/accuracy=0.886152, train/loss=0.418018, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:41:23.027805 140239850956544 logging_writer.py:48] [283000] global_step=283000, grad_norm=3.2472050189971924, loss=1.0583373308181763
I0304 01:42:04.341669 140239842563840 logging_writer.py:48] [283100] global_step=283100, grad_norm=3.0887413024902344, loss=2.545477867126465
I0304 01:42:49.381669 140239850956544 logging_writer.py:48] [283200] global_step=283200, grad_norm=2.8468801975250244, loss=1.271673560142517
I0304 01:43:34.742357 140239842563840 logging_writer.py:48] [283300] global_step=283300, grad_norm=3.24625825881958, loss=2.540867567062378
I0304 01:44:19.806941 140239850956544 logging_writer.py:48] [283400] global_step=283400, grad_norm=3.071098804473877, loss=1.157745361328125
I0304 01:45:05.105653 140239842563840 logging_writer.py:48] [283500] global_step=283500, grad_norm=4.341509819030762, loss=3.2674484252929688
I0304 01:45:50.216851 140239850956544 logging_writer.py:48] [283600] global_step=283600, grad_norm=3.3074443340301514, loss=1.0934956073760986
I0304 01:46:35.514353 140239842563840 logging_writer.py:48] [283700] global_step=283700, grad_norm=3.2572672367095947, loss=2.553488254547119
I0304 01:47:21.132336 140239850956544 logging_writer.py:48] [283800] global_step=283800, grad_norm=2.9526116847991943, loss=1.1242984533309937
I0304 01:48:06.377151 140239842563840 logging_writer.py:48] [283900] global_step=283900, grad_norm=3.1727137565612793, loss=1.134940505027771
I0304 01:48:22.264725 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:48:32.639866 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:49:04.105780 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:49:05.757071 140437341357888 submission_runner.py:411] Time since start: 137787.31s, 	Step: 283937, 	{'train/accuracy': 0.8886132836341858, 'train/loss': 0.4185100197792053, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 126919.30169415474, 'total_duration': 137787.30851221085, 'accumulated_submission_time': 126919.30169415474, 'accumulated_eval_time': 10832.9416513443, 'accumulated_logging_time': 19.519195318222046}
I0304 01:49:05.872524 140239850956544 logging_writer.py:48] [283937] accumulated_eval_time=10832.941651, accumulated_logging_time=19.519195, accumulated_submission_time=126919.301694, global_step=283937, preemption_count=0, score=126919.301694, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=137787.308512, train/accuracy=0.888613, train/loss=0.418510, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:49:31.218490 140239842563840 logging_writer.py:48] [284000] global_step=284000, grad_norm=2.96109676361084, loss=1.1415154933929443
I0304 01:50:15.235329 140239850956544 logging_writer.py:48] [284100] global_step=284100, grad_norm=3.202625036239624, loss=2.7634637355804443
I0304 01:51:00.801777 140239842563840 logging_writer.py:48] [284200] global_step=284200, grad_norm=2.9925363063812256, loss=1.420830488204956
I0304 01:51:46.240454 140239850956544 logging_writer.py:48] [284300] global_step=284300, grad_norm=5.565217971801758, loss=3.184063196182251
I0304 01:52:31.567338 140239842563840 logging_writer.py:48] [284400] global_step=284400, grad_norm=3.238940715789795, loss=1.230163812637329
I0304 01:53:16.751000 140239850956544 logging_writer.py:48] [284500] global_step=284500, grad_norm=3.3358607292175293, loss=1.2939695119857788
I0304 01:54:01.998004 140239842563840 logging_writer.py:48] [284600] global_step=284600, grad_norm=3.235300064086914, loss=1.1897218227386475
I0304 01:54:47.157917 140239850956544 logging_writer.py:48] [284700] global_step=284700, grad_norm=2.808385133743286, loss=1.740289330482483
I0304 01:55:32.448132 140239842563840 logging_writer.py:48] [284800] global_step=284800, grad_norm=3.2363462448120117, loss=1.1277613639831543
I0304 01:56:05.803819 140437341357888 spec.py:321] Evaluating on the training split.
I0304 01:56:16.136486 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 01:56:44.589174 140437341357888 spec.py:349] Evaluating on the test split.
I0304 01:56:46.224496 140437341357888 submission_runner.py:411] Time since start: 138247.78s, 	Step: 284875, 	{'train/accuracy': 0.8898632526397705, 'train/loss': 0.4148930013179779, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 127339.16857624054, 'total_duration': 138247.77598190308, 'accumulated_submission_time': 127339.16857624054, 'accumulated_eval_time': 10873.362308263779, 'accumulated_logging_time': 19.64874291419983}
I0304 01:56:46.296596 140239850956544 logging_writer.py:48] [284875] accumulated_eval_time=10873.362308, accumulated_logging_time=19.648743, accumulated_submission_time=127339.168576, global_step=284875, preemption_count=0, score=127339.168576, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=138247.775982, train/accuracy=0.889863, train/loss=0.414893, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 01:56:56.619901 140239842563840 logging_writer.py:48] [284900] global_step=284900, grad_norm=3.11309814453125, loss=1.0657380819320679
I0304 01:57:38.981840 140239850956544 logging_writer.py:48] [285000] global_step=285000, grad_norm=2.8742470741271973, loss=1.6277382373809814
I0304 01:58:24.002334 140239842563840 logging_writer.py:48] [285100] global_step=285100, grad_norm=3.1100564002990723, loss=2.3223085403442383
I0304 01:59:09.311956 140239850956544 logging_writer.py:48] [285200] global_step=285200, grad_norm=3.0785460472106934, loss=1.1463191509246826
I0304 01:59:54.658030 140239842563840 logging_writer.py:48] [285300] global_step=285300, grad_norm=3.4178943634033203, loss=2.897414445877075
I0304 02:00:40.167913 140239850956544 logging_writer.py:48] [285400] global_step=285400, grad_norm=3.2080678939819336, loss=2.7403390407562256
I0304 02:01:25.402987 140239842563840 logging_writer.py:48] [285500] global_step=285500, grad_norm=3.2399485111236572, loss=1.2064471244812012
I0304 02:02:10.805944 140239850956544 logging_writer.py:48] [285600] global_step=285600, grad_norm=3.2666711807250977, loss=1.442716360092163
I0304 02:02:55.888927 140239842563840 logging_writer.py:48] [285700] global_step=285700, grad_norm=3.0493643283843994, loss=1.330773949623108
I0304 02:03:41.207368 140239850956544 logging_writer.py:48] [285800] global_step=285800, grad_norm=3.057297706604004, loss=2.7237496376037598
I0304 02:03:46.372777 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:03:56.880614 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:04:24.531608 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:04:26.157834 140437341357888 submission_runner.py:411] Time since start: 138707.71s, 	Step: 285813, 	{'train/accuracy': 0.88734370470047, 'train/loss': 0.41409796476364136, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 127759.18264389038, 'total_duration': 138707.7092897892, 'accumulated_submission_time': 127759.18264389038, 'accumulated_eval_time': 10913.14732003212, 'accumulated_logging_time': 19.732011795043945}
I0304 02:04:26.227231 140239842563840 logging_writer.py:48] [285813] accumulated_eval_time=10913.147320, accumulated_logging_time=19.732012, accumulated_submission_time=127759.182644, global_step=285813, preemption_count=0, score=127759.182644, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=138707.709290, train/accuracy=0.887344, train/loss=0.414098, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:05:02.331550 140239850956544 logging_writer.py:48] [285900] global_step=285900, grad_norm=2.946807861328125, loss=1.094617486000061
I0304 02:05:47.463889 140239842563840 logging_writer.py:48] [286000] global_step=286000, grad_norm=3.0894689559936523, loss=1.1749229431152344
I0304 02:06:32.992932 140239850956544 logging_writer.py:48] [286100] global_step=286100, grad_norm=3.283390760421753, loss=1.195514440536499
I0304 02:07:18.380429 140239842563840 logging_writer.py:48] [286200] global_step=286200, grad_norm=3.2976927757263184, loss=2.4872326850891113
I0304 02:08:03.630469 140239850956544 logging_writer.py:48] [286300] global_step=286300, grad_norm=2.837920904159546, loss=1.732323408126831
I0304 02:08:48.660055 140239842563840 logging_writer.py:48] [286400] global_step=286400, grad_norm=2.793931484222412, loss=1.5676369667053223
I0304 02:09:34.296743 140239850956544 logging_writer.py:48] [286500] global_step=286500, grad_norm=3.957172393798828, loss=1.1022882461547852
I0304 02:10:19.772749 140239842563840 logging_writer.py:48] [286600] global_step=286600, grad_norm=3.1344594955444336, loss=1.1373172998428345
I0304 02:11:05.161623 140239850956544 logging_writer.py:48] [286700] global_step=286700, grad_norm=2.998398542404175, loss=2.182443857192993
I0304 02:11:26.224424 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:11:36.621761 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:12:07.935784 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:12:09.595901 140437341357888 submission_runner.py:411] Time since start: 139171.15s, 	Step: 286748, 	{'train/accuracy': 0.8852343559265137, 'train/loss': 0.4228600561618805, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 128179.11961340904, 'total_duration': 139171.1473546028, 'accumulated_submission_time': 128179.11961340904, 'accumulated_eval_time': 10956.518753528595, 'accumulated_logging_time': 19.811482191085815}
I0304 02:12:09.658852 140239842563840 logging_writer.py:48] [286748] accumulated_eval_time=10956.518754, accumulated_logging_time=19.811482, accumulated_submission_time=128179.119613, global_step=286748, preemption_count=0, score=128179.119613, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=139171.147355, train/accuracy=0.885234, train/loss=0.422860, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:12:30.908855 140239850956544 logging_writer.py:48] [286800] global_step=286800, grad_norm=2.80391263961792, loss=1.1019304990768433
I0304 02:13:13.661561 140239842563840 logging_writer.py:48] [286900] global_step=286900, grad_norm=3.1064484119415283, loss=1.1761159896850586
I0304 02:13:58.996127 140239850956544 logging_writer.py:48] [287000] global_step=287000, grad_norm=3.4090499877929688, loss=3.0283260345458984
I0304 02:14:44.418170 140239842563840 logging_writer.py:48] [287100] global_step=287100, grad_norm=3.027627468109131, loss=1.822015643119812
I0304 02:15:29.521309 140239850956544 logging_writer.py:48] [287200] global_step=287200, grad_norm=3.4697976112365723, loss=3.028444766998291
I0304 02:16:15.055555 140239842563840 logging_writer.py:48] [287300] global_step=287300, grad_norm=2.9831972122192383, loss=1.1378579139709473
I0304 02:17:00.154923 140239850956544 logging_writer.py:48] [287400] global_step=287400, grad_norm=3.553727865219116, loss=3.074479818344116
I0304 02:17:45.365166 140239842563840 logging_writer.py:48] [287500] global_step=287500, grad_norm=3.115656614303589, loss=1.1205079555511475
I0304 02:18:30.545138 140239850956544 logging_writer.py:48] [287600] global_step=287600, grad_norm=3.1322739124298096, loss=1.1175029277801514
I0304 02:19:09.676269 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:19:19.953644 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:19:44.750547 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:19:46.381732 140437341357888 submission_runner.py:411] Time since start: 139627.93s, 	Step: 287688, 	{'train/accuracy': 0.8890038728713989, 'train/loss': 0.4117945730686188, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 128598.82387661934, 'total_duration': 139627.9332201481, 'accumulated_submission_time': 128598.82387661934, 'accumulated_eval_time': 10993.224220991135, 'accumulated_logging_time': 20.136163234710693}
I0304 02:19:46.456609 140239842563840 logging_writer.py:48] [287688] accumulated_eval_time=10993.224221, accumulated_logging_time=20.136163, accumulated_submission_time=128598.823877, global_step=287688, preemption_count=0, score=128598.823877, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=139627.933220, train/accuracy=0.889004, train/loss=0.411795, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:19:51.603923 140239850956544 logging_writer.py:48] [287700] global_step=287700, grad_norm=3.0820956230163574, loss=2.049482822418213
I0304 02:20:33.693809 140239842563840 logging_writer.py:48] [287800] global_step=287800, grad_norm=2.769819736480713, loss=1.2320294380187988
I0304 02:21:19.111678 140239850956544 logging_writer.py:48] [287900] global_step=287900, grad_norm=3.0208709239959717, loss=1.3649768829345703
I0304 02:22:04.496978 140239842563840 logging_writer.py:48] [288000] global_step=288000, grad_norm=3.4168660640716553, loss=2.919509172439575
I0304 02:22:49.700338 140239850956544 logging_writer.py:48] [288100] global_step=288100, grad_norm=2.8966476917266846, loss=1.9181019067764282
I0304 02:23:34.882510 140239842563840 logging_writer.py:48] [288200] global_step=288200, grad_norm=3.285297393798828, loss=2.827948570251465
I0304 02:24:20.331454 140239850956544 logging_writer.py:48] [288300] global_step=288300, grad_norm=2.9713873863220215, loss=1.1595357656478882
I0304 02:25:05.466015 140239842563840 logging_writer.py:48] [288400] global_step=288400, grad_norm=2.963576316833496, loss=1.3212043046951294
I0304 02:25:50.860388 140239850956544 logging_writer.py:48] [288500] global_step=288500, grad_norm=3.1678342819213867, loss=2.549501895904541
I0304 02:26:36.272361 140239842563840 logging_writer.py:48] [288600] global_step=288600, grad_norm=3.0726592540740967, loss=1.1495035886764526
I0304 02:26:46.787086 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:26:57.397918 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:27:22.774231 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:27:24.412995 140437341357888 submission_runner.py:411] Time since start: 140085.96s, 	Step: 288625, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.4140118360519409, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 129019.09246134758, 'total_duration': 140085.9644765854, 'accumulated_submission_time': 129019.09246134758, 'accumulated_eval_time': 11030.850098609924, 'accumulated_logging_time': 20.22132968902588}
I0304 02:27:24.487742 140239850956544 logging_writer.py:48] [288625] accumulated_eval_time=11030.850099, accumulated_logging_time=20.221330, accumulated_submission_time=129019.092461, global_step=288625, preemption_count=0, score=129019.092461, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=140085.964477, train/accuracy=0.888398, train/loss=0.414012, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:27:54.998232 140239842563840 logging_writer.py:48] [288700] global_step=288700, grad_norm=3.277106285095215, loss=1.1723188161849976
I0304 02:28:40.037034 140239850956544 logging_writer.py:48] [288800] global_step=288800, grad_norm=3.0779049396514893, loss=1.4951591491699219
I0304 02:29:25.384132 140239842563840 logging_writer.py:48] [288900] global_step=288900, grad_norm=3.329712152481079, loss=2.727128267288208
I0304 02:30:11.144858 140239850956544 logging_writer.py:48] [289000] global_step=289000, grad_norm=3.2627503871917725, loss=1.1057666540145874
I0304 02:30:56.109630 140239842563840 logging_writer.py:48] [289100] global_step=289100, grad_norm=3.604390859603882, loss=3.2525811195373535
I0304 02:31:41.349129 140239850956544 logging_writer.py:48] [289200] global_step=289200, grad_norm=3.006476402282715, loss=1.1498386859893799
I0304 02:32:26.736749 140239842563840 logging_writer.py:48] [289300] global_step=289300, grad_norm=3.3306350708007812, loss=1.2373403310775757
I0304 02:33:12.489747 140239850956544 logging_writer.py:48] [289400] global_step=289400, grad_norm=3.180422306060791, loss=2.3456006050109863
I0304 02:33:57.985842 140239842563840 logging_writer.py:48] [289500] global_step=289500, grad_norm=2.869006633758545, loss=1.6958388090133667
I0304 02:34:24.540660 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:34:34.764733 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:35:01.013058 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:35:02.645048 140437341357888 submission_runner.py:411] Time since start: 140544.20s, 	Step: 289560, 	{'train/accuracy': 0.88880854845047, 'train/loss': 0.41386398673057556, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 129439.08573746681, 'total_duration': 140544.19653391838, 'accumulated_submission_time': 129439.08573746681, 'accumulated_eval_time': 11068.954473495483, 'accumulated_logging_time': 20.305765628814697}
I0304 02:35:02.720133 140239850956544 logging_writer.py:48] [289560] accumulated_eval_time=11068.954473, accumulated_logging_time=20.305766, accumulated_submission_time=129439.085737, global_step=289560, preemption_count=0, score=129439.085737, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=140544.196534, train/accuracy=0.888809, train/loss=0.413864, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:35:18.977176 140239842563840 logging_writer.py:48] [289600] global_step=289600, grad_norm=3.3866288661956787, loss=2.867276668548584
I0304 02:36:02.461272 140239850956544 logging_writer.py:48] [289700] global_step=289700, grad_norm=3.2430808544158936, loss=1.1595245599746704
I0304 02:36:47.828160 140239842563840 logging_writer.py:48] [289800] global_step=289800, grad_norm=3.4291725158691406, loss=2.447227716445923
I0304 02:37:33.051768 140239850956544 logging_writer.py:48] [289900] global_step=289900, grad_norm=2.972750186920166, loss=1.081094741821289
I0304 02:38:18.403032 140239842563840 logging_writer.py:48] [290000] global_step=290000, grad_norm=2.9804253578186035, loss=2.4099676609039307
I0304 02:39:03.581369 140239850956544 logging_writer.py:48] [290100] global_step=290100, grad_norm=3.057441234588623, loss=1.1732478141784668
I0304 02:39:48.575565 140239842563840 logging_writer.py:48] [290200] global_step=290200, grad_norm=3.35713529586792, loss=3.027722120285034
I0304 02:40:34.347981 140239850956544 logging_writer.py:48] [290300] global_step=290300, grad_norm=3.0013837814331055, loss=1.1244226694107056
I0304 02:41:19.912991 140239842563840 logging_writer.py:48] [290400] global_step=290400, grad_norm=3.081132411956787, loss=1.0679563283920288
I0304 02:42:02.875427 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:42:13.217737 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:42:43.509212 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:42:45.148424 140437341357888 submission_runner.py:411] Time since start: 141006.70s, 	Step: 290496, 	{'train/accuracy': 0.8863085508346558, 'train/loss': 0.4227134883403778, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 129859.1750626564, 'total_duration': 141006.6998987198, 'accumulated_submission_time': 129859.1750626564, 'accumulated_eval_time': 11111.227452993393, 'accumulated_logging_time': 20.39596724510193}
I0304 02:42:45.219863 140239850956544 logging_writer.py:48] [290496] accumulated_eval_time=11111.227453, accumulated_logging_time=20.395967, accumulated_submission_time=129859.175063, global_step=290496, preemption_count=0, score=129859.175063, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=141006.699899, train/accuracy=0.886309, train/loss=0.422713, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:42:47.215234 140239842563840 logging_writer.py:48] [290500] global_step=290500, grad_norm=2.951291084289551, loss=1.100677490234375
I0304 02:43:28.154481 140239850956544 logging_writer.py:48] [290600] global_step=290600, grad_norm=2.9261820316314697, loss=1.334424376487732
I0304 02:44:13.732514 140239842563840 logging_writer.py:48] [290700] global_step=290700, grad_norm=3.2263023853302, loss=1.2130552530288696
I0304 02:44:59.043846 140239850956544 logging_writer.py:48] [290800] global_step=290800, grad_norm=3.0298104286193848, loss=1.5508124828338623
I0304 02:45:44.223901 140239842563840 logging_writer.py:48] [290900] global_step=290900, grad_norm=2.8482842445373535, loss=1.138431429862976
I0304 02:46:29.418473 140239850956544 logging_writer.py:48] [291000] global_step=291000, grad_norm=3.2821946144104004, loss=1.065536379814148
I0304 02:47:14.855182 140239842563840 logging_writer.py:48] [291100] global_step=291100, grad_norm=3.130800247192383, loss=2.44119930267334
I0304 02:47:59.791577 140239850956544 logging_writer.py:48] [291200] global_step=291200, grad_norm=2.9399242401123047, loss=1.1781947612762451
I0304 02:48:44.858078 140239842563840 logging_writer.py:48] [291300] global_step=291300, grad_norm=3.4043798446655273, loss=3.0741190910339355
I0304 02:49:30.261336 140239850956544 logging_writer.py:48] [291400] global_step=291400, grad_norm=3.16310453414917, loss=1.0827598571777344
I0304 02:49:45.285484 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:49:55.503897 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:50:19.390398 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:50:21.017985 140437341357888 submission_runner.py:411] Time since start: 141462.57s, 	Step: 291435, 	{'train/accuracy': 0.8886327743530273, 'train/loss': 0.4127470552921295, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 130279.17562508583, 'total_duration': 141462.5694692135, 'accumulated_submission_time': 130279.17562508583, 'accumulated_eval_time': 11146.959941864014, 'accumulated_logging_time': 20.481508493423462}
I0304 02:50:21.098306 140239842563840 logging_writer.py:48] [291435] accumulated_eval_time=11146.959942, accumulated_logging_time=20.481508, accumulated_submission_time=130279.175625, global_step=291435, preemption_count=0, score=130279.175625, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=141462.569469, train/accuracy=0.888633, train/loss=0.412747, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:50:47.255944 140239850956544 logging_writer.py:48] [291500] global_step=291500, grad_norm=3.149257183074951, loss=1.1665806770324707
I0304 02:51:32.640278 140239842563840 logging_writer.py:48] [291600] global_step=291600, grad_norm=3.1628384590148926, loss=1.2280151844024658
I0304 02:52:18.527373 140239850956544 logging_writer.py:48] [291700] global_step=291700, grad_norm=3.084510564804077, loss=1.1698455810546875
I0304 02:53:04.212188 140239842563840 logging_writer.py:48] [291800] global_step=291800, grad_norm=3.391545295715332, loss=1.068138837814331
I0304 02:53:49.830978 140239850956544 logging_writer.py:48] [291900] global_step=291900, grad_norm=3.6913208961486816, loss=3.033076524734497
I0304 02:54:35.465100 140239842563840 logging_writer.py:48] [292000] global_step=292000, grad_norm=2.8563032150268555, loss=1.4288877248764038
I0304 02:55:20.900089 140239850956544 logging_writer.py:48] [292100] global_step=292100, grad_norm=3.1754066944122314, loss=1.1173005104064941
I0304 02:56:06.321278 140239842563840 logging_writer.py:48] [292200] global_step=292200, grad_norm=3.029115676879883, loss=2.387587070465088
I0304 02:56:51.952501 140239850956544 logging_writer.py:48] [292300] global_step=292300, grad_norm=3.96871018409729, loss=1.5943210124969482
I0304 02:57:21.326095 140437341357888 spec.py:321] Evaluating on the training split.
I0304 02:57:31.949113 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 02:57:59.978394 140437341357888 spec.py:349] Evaluating on the test split.
I0304 02:58:01.598637 140437341357888 submission_runner.py:411] Time since start: 141923.15s, 	Step: 292366, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.4100448489189148, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 130699.34307909012, 'total_duration': 141923.1501107216, 'accumulated_submission_time': 130699.34307909012, 'accumulated_eval_time': 11187.23245549202, 'accumulated_logging_time': 20.571951389312744}
I0304 02:58:01.676044 140239842563840 logging_writer.py:48] [292366] accumulated_eval_time=11187.232455, accumulated_logging_time=20.571951, accumulated_submission_time=130699.343079, global_step=292366, preemption_count=0, score=130699.343079, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=141923.150111, train/accuracy=0.889570, train/loss=0.410045, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 02:58:15.749340 140239850956544 logging_writer.py:48] [292400] global_step=292400, grad_norm=4.204887390136719, loss=2.6248738765716553
I0304 02:58:58.629158 140239842563840 logging_writer.py:48] [292500] global_step=292500, grad_norm=3.0437026023864746, loss=1.4150322675704956
I0304 02:59:43.931079 140239850956544 logging_writer.py:48] [292600] global_step=292600, grad_norm=3.1219394207000732, loss=1.1222232580184937
I0304 03:00:29.244580 140239842563840 logging_writer.py:48] [292700] global_step=292700, grad_norm=3.3154470920562744, loss=1.7317787408828735
I0304 03:01:14.580461 140239850956544 logging_writer.py:48] [292800] global_step=292800, grad_norm=3.110952138900757, loss=1.103918433189392
I0304 03:01:59.990563 140239842563840 logging_writer.py:48] [292900] global_step=292900, grad_norm=3.114039897918701, loss=1.401504635810852
I0304 03:02:45.427427 140239850956544 logging_writer.py:48] [293000] global_step=293000, grad_norm=2.962510347366333, loss=0.9942755699157715
I0304 03:03:30.581071 140239842563840 logging_writer.py:48] [293100] global_step=293100, grad_norm=2.9382174015045166, loss=1.037550926208496
I0304 03:04:15.799363 140239850956544 logging_writer.py:48] [293200] global_step=293200, grad_norm=2.846118927001953, loss=1.7124265432357788
I0304 03:05:00.983067 140239842563840 logging_writer.py:48] [293300] global_step=293300, grad_norm=3.6963419914245605, loss=1.2342449426651
I0304 03:05:01.650190 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:05:11.932652 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:05:40.969588 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:05:42.591067 140437341357888 submission_runner.py:411] Time since start: 142384.14s, 	Step: 293303, 	{'train/accuracy': 0.8876562118530273, 'train/loss': 0.42324042320251465, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 131119.25686120987, 'total_duration': 142384.14255547523, 'accumulated_submission_time': 131119.25686120987, 'accumulated_eval_time': 11228.173330783844, 'accumulated_logging_time': 20.65904426574707}
I0304 03:05:42.666269 140239850956544 logging_writer.py:48] [293303] accumulated_eval_time=11228.173331, accumulated_logging_time=20.659044, accumulated_submission_time=131119.256861, global_step=293303, preemption_count=0, score=131119.256861, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=142384.142555, train/accuracy=0.887656, train/loss=0.423240, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:06:22.847190 140239842563840 logging_writer.py:48] [293400] global_step=293400, grad_norm=3.677712917327881, loss=3.171649932861328
I0304 03:07:08.276342 140239850956544 logging_writer.py:48] [293500] global_step=293500, grad_norm=3.0498507022857666, loss=1.5380094051361084
I0304 03:07:53.582779 140239842563840 logging_writer.py:48] [293600] global_step=293600, grad_norm=3.107314109802246, loss=2.0472116470336914
I0304 03:08:38.543364 140239850956544 logging_writer.py:48] [293700] global_step=293700, grad_norm=3.201826333999634, loss=2.8596251010894775
I0304 03:09:23.877495 140239842563840 logging_writer.py:48] [293800] global_step=293800, grad_norm=3.059299945831299, loss=2.875598669052124
I0304 03:10:09.044505 140239850956544 logging_writer.py:48] [293900] global_step=293900, grad_norm=3.2207822799682617, loss=1.1768348217010498
I0304 03:10:54.345247 140239842563840 logging_writer.py:48] [294000] global_step=294000, grad_norm=3.5469655990600586, loss=2.973620653152466
I0304 03:12:01.754411 140239850956544 logging_writer.py:48] [294100] global_step=294100, grad_norm=3.300917863845825, loss=1.1718729734420776
I0304 03:12:42.841280 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:12:53.062157 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:13:18.844781 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:13:20.465059 140437341357888 submission_runner.py:411] Time since start: 142842.02s, 	Step: 294193, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.41392263770103455, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 131539.37345027924, 'total_duration': 142842.01654458046, 'accumulated_submission_time': 131539.37345027924, 'accumulated_eval_time': 11265.79709982872, 'accumulated_logging_time': 20.745182514190674}
I0304 03:13:20.540368 140239842563840 logging_writer.py:48] [294193] accumulated_eval_time=11265.797100, accumulated_logging_time=20.745183, accumulated_submission_time=131539.373450, global_step=294193, preemption_count=0, score=131539.373450, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=142842.016545, train/accuracy=0.888379, train/loss=0.413923, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:13:23.717454 140239850956544 logging_writer.py:48] [294200] global_step=294200, grad_norm=2.8908236026763916, loss=1.1241192817687988
I0304 03:14:05.389058 140239842563840 logging_writer.py:48] [294300] global_step=294300, grad_norm=2.794191837310791, loss=1.405160665512085
I0304 03:14:50.473809 140239850956544 logging_writer.py:48] [294400] global_step=294400, grad_norm=3.716632604598999, loss=3.29010009765625
I0304 03:15:35.721104 140239842563840 logging_writer.py:48] [294500] global_step=294500, grad_norm=3.4570059776306152, loss=1.175973892211914
I0304 03:16:21.134158 140239850956544 logging_writer.py:48] [294600] global_step=294600, grad_norm=3.109312057495117, loss=1.2030006647109985
I0304 03:17:06.724735 140239842563840 logging_writer.py:48] [294700] global_step=294700, grad_norm=3.0060577392578125, loss=1.4858967065811157
I0304 03:17:51.958778 140239850956544 logging_writer.py:48] [294800] global_step=294800, grad_norm=3.1451830863952637, loss=1.8969330787658691
I0304 03:18:37.317964 140239842563840 logging_writer.py:48] [294900] global_step=294900, grad_norm=2.9557087421417236, loss=1.5189121961593628
I0304 03:19:22.581210 140239850956544 logging_writer.py:48] [295000] global_step=295000, grad_norm=3.084582567214966, loss=1.0753194093704224
I0304 03:20:07.705631 140239842563840 logging_writer.py:48] [295100] global_step=295100, grad_norm=2.9747986793518066, loss=2.1158971786499023
I0304 03:20:20.516226 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:20:30.768956 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:20:58.546945 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:21:00.166694 140437341357888 submission_runner.py:411] Time since start: 143301.72s, 	Step: 295130, 	{'train/accuracy': 0.8861523270606995, 'train/loss': 0.41998040676116943, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 131959.2889535427, 'total_duration': 143301.71817946434, 'accumulated_submission_time': 131959.2889535427, 'accumulated_eval_time': 11305.44756770134, 'accumulated_logging_time': 20.830147981643677}
I0304 03:21:00.239484 140239850956544 logging_writer.py:48] [295130] accumulated_eval_time=11305.447568, accumulated_logging_time=20.830148, accumulated_submission_time=131959.288954, global_step=295130, preemption_count=0, score=131959.288954, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=143301.718179, train/accuracy=0.886152, train/loss=0.419980, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:21:28.366455 140239842563840 logging_writer.py:48] [295200] global_step=295200, grad_norm=3.51950740814209, loss=2.978172540664673
I0304 03:22:13.684823 140239850956544 logging_writer.py:48] [295300] global_step=295300, grad_norm=3.0409600734710693, loss=1.08765709400177
I0304 03:22:58.997376 140239842563840 logging_writer.py:48] [295400] global_step=295400, grad_norm=3.231243371963501, loss=1.1837434768676758
I0304 03:23:44.479101 140239850956544 logging_writer.py:48] [295500] global_step=295500, grad_norm=2.9525563716888428, loss=1.8302563428878784
I0304 03:24:29.467858 140239842563840 logging_writer.py:48] [295600] global_step=295600, grad_norm=3.250314474105835, loss=2.667729377746582
I0304 03:25:14.500423 140239850956544 logging_writer.py:48] [295700] global_step=295700, grad_norm=3.041013240814209, loss=1.0933139324188232
I0304 03:25:59.982794 140239842563840 logging_writer.py:48] [295800] global_step=295800, grad_norm=3.309009313583374, loss=1.9454816579818726
I0304 03:26:45.475884 140239850956544 logging_writer.py:48] [295900] global_step=295900, grad_norm=3.285442352294922, loss=2.701559066772461
I0304 03:27:31.048271 140239842563840 logging_writer.py:48] [296000] global_step=296000, grad_norm=3.19077467918396, loss=2.728264808654785
I0304 03:28:00.531754 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:28:10.747054 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:28:34.976590 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:28:36.601346 140437341357888 submission_runner.py:411] Time since start: 143758.15s, 	Step: 296067, 	{'train/accuracy': 0.8904101252555847, 'train/loss': 0.41304418444633484, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 132379.5202343464, 'total_duration': 143758.15282964706, 'accumulated_submission_time': 132379.5202343464, 'accumulated_eval_time': 11341.517132043839, 'accumulated_logging_time': 20.912667512893677}
I0304 03:28:36.677863 140239850956544 logging_writer.py:48] [296067] accumulated_eval_time=11341.517132, accumulated_logging_time=20.912668, accumulated_submission_time=132379.520234, global_step=296067, preemption_count=0, score=132379.520234, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=143758.152830, train/accuracy=0.890410, train/loss=0.413044, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:28:50.145391 140239842563840 logging_writer.py:48] [296100] global_step=296100, grad_norm=3.1540439128875732, loss=1.2824980020523071
I0304 03:29:33.027320 140239850956544 logging_writer.py:48] [296200] global_step=296200, grad_norm=2.939540386199951, loss=1.1323909759521484
I0304 03:30:18.580192 140239842563840 logging_writer.py:48] [296300] global_step=296300, grad_norm=3.1375348567962646, loss=1.1812727451324463
I0304 03:31:03.994470 140239850956544 logging_writer.py:48] [296400] global_step=296400, grad_norm=2.808692216873169, loss=1.1735819578170776
I0304 03:31:49.181937 140239842563840 logging_writer.py:48] [296500] global_step=296500, grad_norm=3.100207567214966, loss=1.4250677824020386
I0304 03:32:34.962820 140239850956544 logging_writer.py:48] [296600] global_step=296600, grad_norm=3.068228244781494, loss=1.084250807762146
I0304 03:33:20.393574 140239842563840 logging_writer.py:48] [296700] global_step=296700, grad_norm=3.4421608448028564, loss=2.9147965908050537
I0304 03:34:06.024867 140239850956544 logging_writer.py:48] [296800] global_step=296800, grad_norm=3.0965962409973145, loss=2.764486789703369
I0304 03:34:51.313156 140239842563840 logging_writer.py:48] [296900] global_step=296900, grad_norm=3.267690896987915, loss=1.1303638219833374
I0304 03:35:36.803231 140239850956544 logging_writer.py:48] [297000] global_step=297000, grad_norm=2.714541435241699, loss=1.1747643947601318
I0304 03:35:36.820068 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:35:47.171905 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:36:22.869934 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:36:24.478908 140437341357888 submission_runner.py:411] Time since start: 144226.03s, 	Step: 297001, 	{'train/accuracy': 0.8873242139816284, 'train/loss': 0.4146493077278137, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 132799.5991435051, 'total_duration': 144226.03037834167, 'accumulated_submission_time': 132799.5991435051, 'accumulated_eval_time': 11389.175944328308, 'accumulated_logging_time': 21.0025532245636}
I0304 03:36:24.554757 140239842563840 logging_writer.py:48] [297001] accumulated_eval_time=11389.175944, accumulated_logging_time=21.002553, accumulated_submission_time=132799.599144, global_step=297001, preemption_count=0, score=132799.599144, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=144226.030378, train/accuracy=0.887324, train/loss=0.414649, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:37:04.156711 140239850956544 logging_writer.py:48] [297100] global_step=297100, grad_norm=3.4716806411743164, loss=2.9647648334503174
I0304 03:37:49.243951 140239842563840 logging_writer.py:48] [297200] global_step=297200, grad_norm=3.7462174892425537, loss=3.2322261333465576
I0304 03:38:34.423965 140239850956544 logging_writer.py:48] [297300] global_step=297300, grad_norm=3.237220048904419, loss=1.2159767150878906
I0304 03:39:19.504791 140239842563840 logging_writer.py:48] [297400] global_step=297400, grad_norm=3.493086099624634, loss=3.1908812522888184
I0304 03:40:04.875614 140239850956544 logging_writer.py:48] [297500] global_step=297500, grad_norm=8.496651649475098, loss=1.1302671432495117
I0304 03:40:50.129544 140239842563840 logging_writer.py:48] [297600] global_step=297600, grad_norm=2.9667091369628906, loss=1.1084872484207153
I0304 03:41:35.376898 140239850956544 logging_writer.py:48] [297700] global_step=297700, grad_norm=2.8969056606292725, loss=1.4790658950805664
I0304 03:42:21.072320 140239842563840 logging_writer.py:48] [297800] global_step=297800, grad_norm=3.032806158065796, loss=1.1242355108261108
I0304 03:43:05.999689 140239850956544 logging_writer.py:48] [297900] global_step=297900, grad_norm=2.951322317123413, loss=2.1186535358428955
I0304 03:43:24.838790 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:43:35.234391 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:44:00.918197 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:44:02.541115 140437341357888 submission_runner.py:411] Time since start: 144684.09s, 	Step: 297943, 	{'train/accuracy': 0.8876367211341858, 'train/loss': 0.41514840722084045, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 133219.8224363327, 'total_duration': 144684.09260296822, 'accumulated_submission_time': 133219.8224363327, 'accumulated_eval_time': 11426.878244876862, 'accumulated_logging_time': 21.088128566741943}
I0304 03:44:02.624577 140239842563840 logging_writer.py:48] [297943] accumulated_eval_time=11426.878245, accumulated_logging_time=21.088129, accumulated_submission_time=133219.822436, global_step=297943, preemption_count=0, score=133219.822436, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=144684.092603, train/accuracy=0.887637, train/loss=0.415148, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:44:25.591654 140239850956544 logging_writer.py:48] [298000] global_step=298000, grad_norm=3.138376474380493, loss=1.256895899772644
I0304 03:45:10.199604 140239842563840 logging_writer.py:48] [298100] global_step=298100, grad_norm=2.998208522796631, loss=1.1316826343536377
I0304 03:45:55.479887 140239850956544 logging_writer.py:48] [298200] global_step=298200, grad_norm=2.959604501724243, loss=1.113175630569458
I0304 03:46:41.022874 140239842563840 logging_writer.py:48] [298300] global_step=298300, grad_norm=2.961021900177002, loss=1.3673089742660522
I0304 03:47:26.339305 140239850956544 logging_writer.py:48] [298400] global_step=298400, grad_norm=3.0417704582214355, loss=1.11691153049469
I0304 03:48:11.642391 140239842563840 logging_writer.py:48] [298500] global_step=298500, grad_norm=2.8217382431030273, loss=1.5243887901306152
I0304 03:48:56.895661 140239850956544 logging_writer.py:48] [298600] global_step=298600, grad_norm=3.0102128982543945, loss=1.1002297401428223
I0304 03:49:42.249410 140239842563840 logging_writer.py:48] [298700] global_step=298700, grad_norm=5.3263373374938965, loss=2.958712100982666
I0304 03:50:27.424430 140239850956544 logging_writer.py:48] [298800] global_step=298800, grad_norm=3.469248056411743, loss=2.852205514907837
I0304 03:51:03.280536 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:51:14.114968 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:51:38.055696 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:51:39.681394 140437341357888 submission_runner.py:411] Time since start: 145141.23s, 	Step: 298880, 	{'train/accuracy': 0.8898437023162842, 'train/loss': 0.4100130796432495, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 133640.4175248146, 'total_duration': 145141.23288106918, 'accumulated_submission_time': 133640.4175248146, 'accumulated_eval_time': 11463.279082298279, 'accumulated_logging_time': 21.181781768798828}
I0304 03:51:39.763992 140239842563840 logging_writer.py:48] [298880] accumulated_eval_time=11463.279082, accumulated_logging_time=21.181782, accumulated_submission_time=133640.417525, global_step=298880, preemption_count=0, score=133640.417525, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=145141.232881, train/accuracy=0.889844, train/loss=0.410013, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:51:48.087750 140239850956544 logging_writer.py:48] [298900] global_step=298900, grad_norm=2.781858205795288, loss=1.031335711479187
I0304 03:52:30.707371 140239842563840 logging_writer.py:48] [299000] global_step=299000, grad_norm=3.624493360519409, loss=3.227142095565796
I0304 03:53:16.348512 140239850956544 logging_writer.py:48] [299100] global_step=299100, grad_norm=3.2907025814056396, loss=2.719141960144043
I0304 03:54:01.653814 140239842563840 logging_writer.py:48] [299200] global_step=299200, grad_norm=3.0286858081817627, loss=1.0342634916305542
I0304 03:54:46.928863 140239850956544 logging_writer.py:48] [299300] global_step=299300, grad_norm=2.878335475921631, loss=1.8978302478790283
I0304 03:55:32.517815 140239842563840 logging_writer.py:48] [299400] global_step=299400, grad_norm=3.059913396835327, loss=2.3848941326141357
I0304 03:56:17.991406 140239850956544 logging_writer.py:48] [299500] global_step=299500, grad_norm=2.981382369995117, loss=2.083718776702881
I0304 03:57:03.713175 140239842563840 logging_writer.py:48] [299600] global_step=299600, grad_norm=3.7654902935028076, loss=3.2749876976013184
I0304 03:57:49.060557 140239850956544 logging_writer.py:48] [299700] global_step=299700, grad_norm=3.0524744987487793, loss=2.519082546234131
I0304 03:58:34.356505 140239842563840 logging_writer.py:48] [299800] global_step=299800, grad_norm=3.5982484817504883, loss=3.2483577728271484
I0304 03:58:39.849217 140437341357888 spec.py:321] Evaluating on the training split.
I0304 03:58:50.160902 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 03:59:19.763367 140437341357888 spec.py:349] Evaluating on the test split.
I0304 03:59:21.387003 140437341357888 submission_runner.py:411] Time since start: 145602.94s, 	Step: 299814, 	{'train/accuracy': 0.8866406083106995, 'train/loss': 0.4186463952064514, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 134060.4425957203, 'total_duration': 145602.93848657608, 'accumulated_submission_time': 134060.4425957203, 'accumulated_eval_time': 11504.816838264465, 'accumulated_logging_time': 21.274759769439697}
I0304 03:59:21.462363 140239850956544 logging_writer.py:48] [299814] accumulated_eval_time=11504.816838, accumulated_logging_time=21.274760, accumulated_submission_time=134060.442596, global_step=299814, preemption_count=0, score=134060.442596, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=145602.938487, train/accuracy=0.886641, train/loss=0.418646, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 03:59:56.622475 140239842563840 logging_writer.py:48] [299900] global_step=299900, grad_norm=2.9540398120880127, loss=1.1460843086242676
I0304 04:00:41.843964 140239850956544 logging_writer.py:48] [300000] global_step=300000, grad_norm=2.976560354232788, loss=1.4408730268478394
I0304 04:01:27.102316 140239842563840 logging_writer.py:48] [300100] global_step=300100, grad_norm=3.8306310176849365, loss=3.114908218383789
I0304 04:02:12.509620 140239850956544 logging_writer.py:48] [300200] global_step=300200, grad_norm=3.1661181449890137, loss=2.583582639694214
I0304 04:02:57.901509 140239842563840 logging_writer.py:48] [300300] global_step=300300, grad_norm=3.3414909839630127, loss=1.1333743333816528
I0304 04:03:43.384406 140239850956544 logging_writer.py:48] [300400] global_step=300400, grad_norm=2.8768231868743896, loss=1.3838465213775635
I0304 04:04:28.491388 140239842563840 logging_writer.py:48] [300500] global_step=300500, grad_norm=2.8208372592926025, loss=1.1490212678909302
I0304 04:05:13.504668 140239850956544 logging_writer.py:48] [300600] global_step=300600, grad_norm=3.673527479171753, loss=2.908714532852173
I0304 04:05:58.532593 140239842563840 logging_writer.py:48] [300700] global_step=300700, grad_norm=4.152588844299316, loss=3.248648166656494
I0304 04:06:21.426107 140437341357888 spec.py:321] Evaluating on the training split.
I0304 04:06:31.901755 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 04:06:58.395636 140437341357888 spec.py:349] Evaluating on the test split.
I0304 04:07:00.027798 140437341357888 submission_runner.py:411] Time since start: 146061.58s, 	Step: 300752, 	{'train/accuracy': 0.88978511095047, 'train/loss': 0.41117531061172485, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 134480.3460702896, 'total_duration': 146061.57924103737, 'accumulated_submission_time': 134480.3460702896, 'accumulated_eval_time': 11543.418461561203, 'accumulated_logging_time': 21.360515594482422}
I0304 04:07:00.105021 140239850956544 logging_writer.py:48] [300752] accumulated_eval_time=11543.418462, accumulated_logging_time=21.360516, accumulated_submission_time=134480.346070, global_step=300752, preemption_count=0, score=134480.346070, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=146061.579241, train/accuracy=0.889785, train/loss=0.411175, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 04:07:19.512919 140239842563840 logging_writer.py:48] [300800] global_step=300800, grad_norm=3.0044052600860596, loss=1.2864034175872803
I0304 04:08:03.121457 140239850956544 logging_writer.py:48] [300900] global_step=300900, grad_norm=3.314324378967285, loss=1.1084526777267456
I0304 04:08:48.422084 140239842563840 logging_writer.py:48] [301000] global_step=301000, grad_norm=3.3093299865722656, loss=1.5564244985580444
I0304 04:09:33.694116 140239850956544 logging_writer.py:48] [301100] global_step=301100, grad_norm=4.101206302642822, loss=1.4618468284606934
I0304 04:10:19.106175 140239842563840 logging_writer.py:48] [301200] global_step=301200, grad_norm=3.896327018737793, loss=3.2896711826324463
I0304 04:11:04.435243 140239850956544 logging_writer.py:48] [301300] global_step=301300, grad_norm=3.0321853160858154, loss=2.056710720062256
I0304 04:11:49.632713 140239842563840 logging_writer.py:48] [301400] global_step=301400, grad_norm=3.071753740310669, loss=1.8170506954193115
I0304 04:12:34.949738 140239850956544 logging_writer.py:48] [301500] global_step=301500, grad_norm=3.0305335521698, loss=0.9997776746749878
I0304 04:13:20.766484 140239842563840 logging_writer.py:48] [301600] global_step=301600, grad_norm=3.150893449783325, loss=1.1516919136047363
I0304 04:14:00.174414 140437341357888 spec.py:321] Evaluating on the training split.
I0304 04:14:10.629517 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 04:14:41.037117 140437341357888 spec.py:349] Evaluating on the test split.
I0304 04:14:42.663058 140437341357888 submission_runner.py:411] Time since start: 146524.21s, 	Step: 301689, 	{'train/accuracy': 0.8907030820846558, 'train/loss': 0.41155123710632324, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 134900.35364151, 'total_duration': 146524.2145433426, 'accumulated_submission_time': 134900.35364151, 'accumulated_eval_time': 11585.907123088837, 'accumulated_logging_time': 21.44925570487976}
I0304 04:14:42.740311 140239850956544 logging_writer.py:48] [301689] accumulated_eval_time=11585.907123, accumulated_logging_time=21.449256, accumulated_submission_time=134900.353642, global_step=301689, preemption_count=0, score=134900.353642, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=146524.214543, train/accuracy=0.890703, train/loss=0.411551, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 04:14:47.509507 140239842563840 logging_writer.py:48] [301700] global_step=301700, grad_norm=3.292797327041626, loss=1.0865144729614258
I0304 04:15:28.225466 140239850956544 logging_writer.py:48] [301800] global_step=301800, grad_norm=2.663454532623291, loss=1.3478178977966309
I0304 04:16:13.457802 140239842563840 logging_writer.py:48] [301900] global_step=301900, grad_norm=3.2627289295196533, loss=1.1563140153884888
I0304 04:16:59.170332 140239850956544 logging_writer.py:48] [302000] global_step=302000, grad_norm=3.1031641960144043, loss=1.0551071166992188
I0304 04:17:44.213991 140239842563840 logging_writer.py:48] [302100] global_step=302100, grad_norm=3.655634641647339, loss=3.1810946464538574
I0304 04:18:29.420421 140239850956544 logging_writer.py:48] [302200] global_step=302200, grad_norm=3.1420159339904785, loss=1.1311695575714111
I0304 04:19:14.732269 140239842563840 logging_writer.py:48] [302300] global_step=302300, grad_norm=3.223029851913452, loss=2.0468599796295166
I0304 04:19:59.787714 140239850956544 logging_writer.py:48] [302400] global_step=302400, grad_norm=2.878809928894043, loss=1.1225014925003052
I0304 04:20:44.931749 140239842563840 logging_writer.py:48] [302500] global_step=302500, grad_norm=3.1429359912872314, loss=1.3606681823730469
I0304 04:21:30.072976 140239850956544 logging_writer.py:48] [302600] global_step=302600, grad_norm=3.461371421813965, loss=2.9954259395599365
I0304 04:21:42.933509 140437341357888 spec.py:321] Evaluating on the training split.
I0304 04:21:53.221995 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 04:22:15.563801 140437341357888 spec.py:349] Evaluating on the test split.
I0304 04:22:17.192092 140437341357888 submission_runner.py:411] Time since start: 146978.74s, 	Step: 302630, 	{'train/accuracy': 0.8902929425239563, 'train/loss': 0.4095830023288727, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 135320.4859445095, 'total_duration': 146978.74358296394, 'accumulated_submission_time': 135320.4859445095, 'accumulated_eval_time': 11620.165687322617, 'accumulated_logging_time': 21.537031173706055}
I0304 04:22:17.270390 140239842563840 logging_writer.py:48] [302630] accumulated_eval_time=11620.165687, accumulated_logging_time=21.537031, accumulated_submission_time=135320.485945, global_step=302630, preemption_count=0, score=135320.485945, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=146978.743583, train/accuracy=0.890293, train/loss=0.409583, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 04:22:45.551526 140239850956544 logging_writer.py:48] [302700] global_step=302700, grad_norm=3.085444688796997, loss=1.1261670589447021
I0304 04:23:30.906825 140239842563840 logging_writer.py:48] [302800] global_step=302800, grad_norm=3.1156556606292725, loss=1.1010675430297852
I0304 04:24:16.061943 140239850956544 logging_writer.py:48] [302900] global_step=302900, grad_norm=3.0791897773742676, loss=2.544781446456909
I0304 04:25:01.385433 140239842563840 logging_writer.py:48] [303000] global_step=303000, grad_norm=3.3609097003936768, loss=1.4923710823059082
I0304 04:25:46.324515 140239850956544 logging_writer.py:48] [303100] global_step=303100, grad_norm=2.834404468536377, loss=1.7195873260498047
I0304 04:26:31.626385 140239842563840 logging_writer.py:48] [303200] global_step=303200, grad_norm=3.067051410675049, loss=2.690124988555908
I0304 04:27:16.911470 140239850956544 logging_writer.py:48] [303300] global_step=303300, grad_norm=3.0819764137268066, loss=2.4662017822265625
I0304 04:28:02.000425 140239842563840 logging_writer.py:48] [303400] global_step=303400, grad_norm=3.0028603076934814, loss=1.2548620700836182
I0304 04:28:47.110177 140239850956544 logging_writer.py:48] [303500] global_step=303500, grad_norm=2.8795104026794434, loss=1.2479023933410645
I0304 04:29:17.573112 140437341357888 spec.py:321] Evaluating on the training split.
I0304 04:29:28.207398 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 04:29:58.934311 140437341357888 spec.py:349] Evaluating on the test split.
I0304 04:30:00.562783 140437341357888 submission_runner.py:411] Time since start: 147442.11s, 	Step: 303569, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.4151207208633423, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 135740.72599720955, 'total_duration': 147442.11426973343, 'accumulated_submission_time': 135740.72599720955, 'accumulated_eval_time': 11663.155353784561, 'accumulated_logging_time': 21.625725030899048}
I0304 04:30:00.639218 140239842563840 logging_writer.py:48] [303569] accumulated_eval_time=11663.155354, accumulated_logging_time=21.625725, accumulated_submission_time=135740.725997, global_step=303569, preemption_count=0, score=135740.725997, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=147442.114270, train/accuracy=0.888477, train/loss=0.415121, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 04:30:13.331032 140239850956544 logging_writer.py:48] [303600] global_step=303600, grad_norm=3.040806531906128, loss=1.1322969198226929
I0304 04:30:55.955762 140239842563840 logging_writer.py:48] [303700] global_step=303700, grad_norm=2.741642951965332, loss=1.8085644245147705
I0304 04:31:40.959365 140239850956544 logging_writer.py:48] [303800] global_step=303800, grad_norm=2.922286033630371, loss=1.157994270324707
I0304 04:32:26.153911 140239842563840 logging_writer.py:48] [303900] global_step=303900, grad_norm=2.8595101833343506, loss=1.2782697677612305
I0304 04:33:11.278622 140239850956544 logging_writer.py:48] [304000] global_step=304000, grad_norm=2.960355281829834, loss=1.5925769805908203
I0304 04:33:56.814653 140239842563840 logging_writer.py:48] [304100] global_step=304100, grad_norm=3.181936264038086, loss=1.2141464948654175
I0304 04:34:42.139737 140239850956544 logging_writer.py:48] [304200] global_step=304200, grad_norm=3.0025017261505127, loss=2.0322587490081787
I0304 04:35:27.338327 140239842563840 logging_writer.py:48] [304300] global_step=304300, grad_norm=2.850374698638916, loss=1.6173558235168457
I0304 04:36:12.833280 140239850956544 logging_writer.py:48] [304400] global_step=304400, grad_norm=2.8163046836853027, loss=1.7224525213241577
I0304 04:36:58.272876 140239842563840 logging_writer.py:48] [304500] global_step=304500, grad_norm=3.365849018096924, loss=1.1494245529174805
I0304 04:37:00.739871 140437341357888 spec.py:321] Evaluating on the training split.
I0304 04:37:12.005337 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 04:37:38.564122 140437341357888 spec.py:349] Evaluating on the test split.
I0304 04:37:40.190850 140437341357888 submission_runner.py:411] Time since start: 147901.74s, 	Step: 304507, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.41398242115974426, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 136160.76442551613, 'total_duration': 147901.74234127998, 'accumulated_submission_time': 136160.76442551613, 'accumulated_eval_time': 11702.606310367584, 'accumulated_logging_time': 21.71380090713501}
I0304 04:37:40.267235 140239850956544 logging_writer.py:48] [304507] accumulated_eval_time=11702.606310, accumulated_logging_time=21.713801, accumulated_submission_time=136160.764426, global_step=304507, preemption_count=0, score=136160.764426, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=147901.742341, train/accuracy=0.887910, train/loss=0.413982, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 04:38:18.149602 140239842563840 logging_writer.py:48] [304600] global_step=304600, grad_norm=2.944791793823242, loss=1.0828282833099365
I0304 04:39:03.420417 140239850956544 logging_writer.py:48] [304700] global_step=304700, grad_norm=3.1110167503356934, loss=1.996726632118225
I0304 04:39:48.554111 140239842563840 logging_writer.py:48] [304800] global_step=304800, grad_norm=2.982196092605591, loss=1.0412946939468384
I0304 04:40:33.715087 140239850956544 logging_writer.py:48] [304900] global_step=304900, grad_norm=3.0170962810516357, loss=2.1907191276550293
I0304 04:41:18.891635 140239842563840 logging_writer.py:48] [305000] global_step=305000, grad_norm=2.915449380874634, loss=1.1715717315673828
I0304 04:42:04.167785 140239850956544 logging_writer.py:48] [305100] global_step=305100, grad_norm=3.4619832038879395, loss=2.3740928173065186
I0304 04:42:49.389157 140239842563840 logging_writer.py:48] [305200] global_step=305200, grad_norm=2.9889817237854004, loss=1.0973321199417114
I0304 04:43:35.015064 140239850956544 logging_writer.py:48] [305300] global_step=305300, grad_norm=2.9973220825195312, loss=1.1661642789840698
I0304 04:44:20.537878 140239842563840 logging_writer.py:48] [305400] global_step=305400, grad_norm=3.11928129196167, loss=1.1277515888214111
I0304 04:44:40.194136 140437341357888 spec.py:321] Evaluating on the training split.
I0304 04:44:50.665977 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 04:45:17.781923 140437341357888 spec.py:349] Evaluating on the test split.
I0304 04:45:19.410373 140437341357888 submission_runner.py:411] Time since start: 148360.96s, 	Step: 305445, 	{'train/accuracy': 0.8877343535423279, 'train/loss': 0.41628625988960266, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 136580.63121008873, 'total_duration': 148360.96184515953, 'accumulated_submission_time': 136580.63121008873, 'accumulated_eval_time': 11741.822509288788, 'accumulated_logging_time': 21.800002574920654}
I0304 04:45:19.499332 140239850956544 logging_writer.py:48] [305445] accumulated_eval_time=11741.822509, accumulated_logging_time=21.800003, accumulated_submission_time=136580.631210, global_step=305445, preemption_count=0, score=136580.631210, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=148360.961845, train/accuracy=0.887734, train/loss=0.416286, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 04:45:41.675236 140239842563840 logging_writer.py:48] [305500] global_step=305500, grad_norm=3.126439094543457, loss=1.8714590072631836
I0304 04:46:25.760201 140239850956544 logging_writer.py:48] [305600] global_step=305600, grad_norm=3.3243095874786377, loss=2.6997158527374268
I0304 04:47:11.241334 140239842563840 logging_writer.py:48] [305700] global_step=305700, grad_norm=3.464857816696167, loss=2.867314338684082
I0304 04:47:56.141878 140239850956544 logging_writer.py:48] [305800] global_step=305800, grad_norm=3.428492307662964, loss=2.905144453048706
I0304 04:48:41.578019 140239842563840 logging_writer.py:48] [305900] global_step=305900, grad_norm=2.853703260421753, loss=2.1395182609558105
I0304 04:49:27.001404 140239850956544 logging_writer.py:48] [306000] global_step=306000, grad_norm=3.193333148956299, loss=2.601459503173828
I0304 04:50:12.115619 140239842563840 logging_writer.py:48] [306100] global_step=306100, grad_norm=3.1417031288146973, loss=1.140945553779602
I0304 04:50:57.147573 140239850956544 logging_writer.py:48] [306200] global_step=306200, grad_norm=3.1305551528930664, loss=1.0403393507003784
I0304 04:51:42.605686 140239842563840 logging_writer.py:48] [306300] global_step=306300, grad_norm=3.2238247394561768, loss=1.227156639099121
I0304 04:52:19.565393 140437341357888 spec.py:321] Evaluating on the training split.
I0304 04:52:29.885527 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 04:53:05.498852 140437341357888 spec.py:349] Evaluating on the test split.
I0304 04:53:07.129912 140437341357888 submission_runner.py:411] Time since start: 148828.68s, 	Step: 306383, 	{'train/accuracy': 0.8881250023841858, 'train/loss': 0.4133361577987671, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 137000.6361260414, 'total_duration': 148828.68139123917, 'accumulated_submission_time': 137000.6361260414, 'accumulated_eval_time': 11789.387017726898, 'accumulated_logging_time': 21.899590492248535}
I0304 04:53:07.204152 140239850956544 logging_writer.py:48] [306383] accumulated_eval_time=11789.387018, accumulated_logging_time=21.899590, accumulated_submission_time=137000.636126, global_step=306383, preemption_count=0, score=137000.636126, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=148828.681391, train/accuracy=0.888125, train/loss=0.413336, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 04:53:14.335856 140239842563840 logging_writer.py:48] [306400] global_step=306400, grad_norm=3.035343647003174, loss=1.1076939105987549
I0304 04:53:55.000041 140239850956544 logging_writer.py:48] [306500] global_step=306500, grad_norm=3.175651788711548, loss=1.138053297996521
I0304 04:54:40.280070 140239842563840 logging_writer.py:48] [306600] global_step=306600, grad_norm=2.9814555644989014, loss=1.2004826068878174
I0304 04:55:25.757177 140239850956544 logging_writer.py:48] [306700] global_step=306700, grad_norm=2.904353380203247, loss=1.7823805809020996
I0304 04:56:11.066270 140239842563840 logging_writer.py:48] [306800] global_step=306800, grad_norm=3.2821807861328125, loss=1.301051139831543
I0304 04:56:56.628003 140239850956544 logging_writer.py:48] [306900] global_step=306900, grad_norm=2.990861654281616, loss=1.0688718557357788
I0304 04:57:41.947660 140239842563840 logging_writer.py:48] [307000] global_step=307000, grad_norm=3.2960543632507324, loss=1.1295857429504395
I0304 04:58:27.202912 140239850956544 logging_writer.py:48] [307100] global_step=307100, grad_norm=3.000636339187622, loss=1.1310443878173828
I0304 04:59:12.560979 140239842563840 logging_writer.py:48] [307200] global_step=307200, grad_norm=2.9968080520629883, loss=1.906247854232788
I0304 04:59:57.544463 140239850956544 logging_writer.py:48] [307300] global_step=307300, grad_norm=2.986417531967163, loss=2.2427167892456055
I0304 05:00:07.163455 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:00:17.419472 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:00:48.520488 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:00:50.144956 140437341357888 submission_runner.py:411] Time since start: 149291.70s, 	Step: 307323, 	{'train/accuracy': 0.8883593678474426, 'train/loss': 0.4201784133911133, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 137420.53449702263, 'total_duration': 149291.6964457035, 'accumulated_submission_time': 137420.53449702263, 'accumulated_eval_time': 11832.368502616882, 'accumulated_logging_time': 21.984339237213135}
I0304 05:00:50.222165 140239842563840 logging_writer.py:48] [307323] accumulated_eval_time=11832.368503, accumulated_logging_time=21.984339, accumulated_submission_time=137420.534497, global_step=307323, preemption_count=0, score=137420.534497, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=149291.696446, train/accuracy=0.888359, train/loss=0.420178, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:01:21.194733 140239850956544 logging_writer.py:48] [307400] global_step=307400, grad_norm=3.719235420227051, loss=3.16369366645813
I0304 05:02:06.027052 140239842563840 logging_writer.py:48] [307500] global_step=307500, grad_norm=3.0814805030822754, loss=1.196481466293335
I0304 05:02:51.182970 140239850956544 logging_writer.py:48] [307600] global_step=307600, grad_norm=3.2233681678771973, loss=1.1171587705612183
I0304 05:03:36.720622 140239842563840 logging_writer.py:48] [307700] global_step=307700, grad_norm=3.937810182571411, loss=3.1685636043548584
I0304 05:04:22.448167 140239850956544 logging_writer.py:48] [307800] global_step=307800, grad_norm=3.495990753173828, loss=3.372767925262451
I0304 05:05:08.100110 140239842563840 logging_writer.py:48] [307900] global_step=307900, grad_norm=4.445774078369141, loss=2.8415961265563965
I0304 05:05:53.412320 140239850956544 logging_writer.py:48] [308000] global_step=308000, grad_norm=3.02716326713562, loss=1.8335504531860352
I0304 05:06:38.858847 140239842563840 logging_writer.py:48] [308100] global_step=308100, grad_norm=2.985621213912964, loss=1.136539340019226
I0304 05:07:24.035598 140239850956544 logging_writer.py:48] [308200] global_step=308200, grad_norm=2.768284559249878, loss=1.1144734621047974
I0304 05:07:50.543625 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:08:01.247456 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:08:26.825493 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:08:28.444103 140437341357888 submission_runner.py:411] Time since start: 149750.00s, 	Step: 308260, 	{'train/accuracy': 0.8879687190055847, 'train/loss': 0.41777849197387695, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 137840.7928082943, 'total_duration': 149749.99558973312, 'accumulated_submission_time': 137840.7928082943, 'accumulated_eval_time': 11870.268971681595, 'accumulated_logging_time': 22.074394941329956}
I0304 05:08:28.521791 140239842563840 logging_writer.py:48] [308260] accumulated_eval_time=11870.268972, accumulated_logging_time=22.074395, accumulated_submission_time=137840.792808, global_step=308260, preemption_count=0, score=137840.792808, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=149749.995590, train/accuracy=0.887969, train/loss=0.417778, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:08:44.760982 140239850956544 logging_writer.py:48] [308300] global_step=308300, grad_norm=3.031769275665283, loss=1.1415693759918213
I0304 05:09:28.499613 140239842563840 logging_writer.py:48] [308400] global_step=308400, grad_norm=3.0501391887664795, loss=1.2615619897842407
I0304 05:10:13.632629 140239850956544 logging_writer.py:48] [308500] global_step=308500, grad_norm=3.080857276916504, loss=1.1366169452667236
I0304 05:10:59.014292 140239842563840 logging_writer.py:48] [308600] global_step=308600, grad_norm=2.900381088256836, loss=1.371470332145691
I0304 05:11:44.009563 140239850956544 logging_writer.py:48] [308700] global_step=308700, grad_norm=3.1520893573760986, loss=1.7863597869873047
I0304 05:12:29.241900 140239842563840 logging_writer.py:48] [308800] global_step=308800, grad_norm=2.901141405105591, loss=1.068155288696289
I0304 05:13:14.589866 140239850956544 logging_writer.py:48] [308900] global_step=308900, grad_norm=3.016045331954956, loss=1.1678311824798584
I0304 05:13:59.736416 140239842563840 logging_writer.py:48] [309000] global_step=309000, grad_norm=2.786435604095459, loss=1.985593318939209
I0304 05:14:45.598631 140239850956544 logging_writer.py:48] [309100] global_step=309100, grad_norm=3.177510976791382, loss=2.6852734088897705
I0304 05:15:28.652892 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:15:39.082572 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:16:03.466200 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:16:05.092231 140437341357888 submission_runner.py:411] Time since start: 150206.64s, 	Step: 309197, 	{'train/accuracy': 0.88916015625, 'train/loss': 0.40918371081352234, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 138260.85964107513, 'total_duration': 150206.64368653297, 'accumulated_submission_time': 138260.85964107513, 'accumulated_eval_time': 11906.708271741867, 'accumulated_logging_time': 22.166040182113647}
I0304 05:16:05.216123 140239842563840 logging_writer.py:48] [309197] accumulated_eval_time=11906.708272, accumulated_logging_time=22.166040, accumulated_submission_time=138260.859641, global_step=309197, preemption_count=0, score=138260.859641, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=150206.643687, train/accuracy=0.889160, train/loss=0.409184, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:16:06.820722 140239850956544 logging_writer.py:48] [309200] global_step=309200, grad_norm=3.247185468673706, loss=2.8577475547790527
I0304 05:16:48.659334 140239842563840 logging_writer.py:48] [309300] global_step=309300, grad_norm=3.0132482051849365, loss=1.6767518520355225
I0304 05:17:33.900257 140239850956544 logging_writer.py:48] [309400] global_step=309400, grad_norm=3.107069969177246, loss=1.382784366607666
I0304 05:18:19.510353 140239842563840 logging_writer.py:48] [309500] global_step=309500, grad_norm=3.1820294857025146, loss=2.725254535675049
I0304 05:19:04.934527 140239850956544 logging_writer.py:48] [309600] global_step=309600, grad_norm=3.091550350189209, loss=1.0658529996871948
I0304 05:19:50.051498 140239842563840 logging_writer.py:48] [309700] global_step=309700, grad_norm=2.855375051498413, loss=0.9918266534805298
I0304 05:20:35.265249 140239850956544 logging_writer.py:48] [309800] global_step=309800, grad_norm=3.077423572540283, loss=1.1958330869674683
I0304 05:21:20.650952 140239842563840 logging_writer.py:48] [309900] global_step=309900, grad_norm=3.6123220920562744, loss=2.969266891479492
I0304 05:22:05.928935 140239850956544 logging_writer.py:48] [310000] global_step=310000, grad_norm=2.994818687438965, loss=1.095212459564209
I0304 05:22:50.985784 140239842563840 logging_writer.py:48] [310100] global_step=310100, grad_norm=2.937964677810669, loss=1.0313632488250732
I0304 05:23:05.210011 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:23:15.428704 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:23:43.983178 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:23:45.640193 140437341357888 submission_runner.py:411] Time since start: 150667.19s, 	Step: 310133, 	{'train/accuracy': 0.8869531154632568, 'train/loss': 0.4185750484466553, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 138680.788346529, 'total_duration': 150667.1916770935, 'accumulated_submission_time': 138680.788346529, 'accumulated_eval_time': 11947.138439178467, 'accumulated_logging_time': 22.304643392562866}
I0304 05:23:45.720697 140239850956544 logging_writer.py:48] [310133] accumulated_eval_time=11947.138439, accumulated_logging_time=22.304643, accumulated_submission_time=138680.788347, global_step=310133, preemption_count=0, score=138680.788347, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=150667.191677, train/accuracy=0.886953, train/loss=0.418575, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:24:12.669427 140239842563840 logging_writer.py:48] [310200] global_step=310200, grad_norm=3.8946328163146973, loss=3.0335559844970703
I0304 05:24:57.489793 140239850956544 logging_writer.py:48] [310300] global_step=310300, grad_norm=3.0327365398406982, loss=2.118638753890991
I0304 05:25:42.923002 140239842563840 logging_writer.py:48] [310400] global_step=310400, grad_norm=3.1653976440429688, loss=1.141348123550415
I0304 05:26:28.122739 140239850956544 logging_writer.py:48] [310500] global_step=310500, grad_norm=3.3371798992156982, loss=2.819214344024658
I0304 05:27:13.679255 140239842563840 logging_writer.py:48] [310600] global_step=310600, grad_norm=3.527540445327759, loss=3.098690986633301
I0304 05:27:58.749643 140239850956544 logging_writer.py:48] [310700] global_step=310700, grad_norm=3.2285733222961426, loss=1.7987008094787598
I0304 05:28:44.166369 140239842563840 logging_writer.py:48] [310800] global_step=310800, grad_norm=2.9333765506744385, loss=1.066572904586792
I0304 05:29:29.454375 140239850956544 logging_writer.py:48] [310900] global_step=310900, grad_norm=3.222079277038574, loss=1.585407018661499
I0304 05:30:14.641556 140239842563840 logging_writer.py:48] [311000] global_step=311000, grad_norm=3.2594425678253174, loss=1.25186288356781
I0304 05:30:45.708093 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:30:55.978790 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:31:23.398900 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:31:25.024552 140437341357888 submission_runner.py:411] Time since start: 151126.58s, 	Step: 311071, 	{'train/accuracy': 0.8867968320846558, 'train/loss': 0.41894423961639404, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 139100.7155430317, 'total_duration': 151126.57604026794, 'accumulated_submission_time': 139100.7155430317, 'accumulated_eval_time': 11986.454893350601, 'accumulated_logging_time': 22.394673824310303}
I0304 05:31:25.105876 140239850956544 logging_writer.py:48] [311071] accumulated_eval_time=11986.454893, accumulated_logging_time=22.394674, accumulated_submission_time=139100.715543, global_step=311071, preemption_count=0, score=139100.715543, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=151126.576040, train/accuracy=0.886797, train/loss=0.418944, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:31:37.001591 140239842563840 logging_writer.py:48] [311100] global_step=311100, grad_norm=2.999375343322754, loss=1.1796040534973145
I0304 05:32:19.457512 140239850956544 logging_writer.py:48] [311200] global_step=311200, grad_norm=3.1036319732666016, loss=1.1659541130065918
I0304 05:33:04.776559 140239842563840 logging_writer.py:48] [311300] global_step=311300, grad_norm=2.9150021076202393, loss=1.2243338823318481
I0304 05:33:50.188568 140239850956544 logging_writer.py:48] [311400] global_step=311400, grad_norm=2.8185012340545654, loss=2.4490251541137695
I0304 05:34:35.444713 140239842563840 logging_writer.py:48] [311500] global_step=311500, grad_norm=3.180682897567749, loss=2.427086114883423
I0304 05:35:20.983968 140239850956544 logging_writer.py:48] [311600] global_step=311600, grad_norm=3.701131582260132, loss=3.1377224922180176
I0304 05:36:06.319085 140239842563840 logging_writer.py:48] [311700] global_step=311700, grad_norm=3.3554582595825195, loss=2.8749775886535645
I0304 05:36:51.665570 140239850956544 logging_writer.py:48] [311800] global_step=311800, grad_norm=2.996204376220703, loss=1.5268902778625488
I0304 05:37:36.970209 140239842563840 logging_writer.py:48] [311900] global_step=311900, grad_norm=2.785240888595581, loss=1.1810085773468018
I0304 05:38:22.240474 140239850956544 logging_writer.py:48] [312000] global_step=312000, grad_norm=3.5716164112091064, loss=3.0280704498291016
I0304 05:38:25.108308 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:38:35.442617 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:39:04.738771 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:39:06.388841 140437341357888 submission_runner.py:411] Time since start: 151587.94s, 	Step: 312008, 	{'train/accuracy': 0.88916015625, 'train/loss': 0.41110506653785706, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 139520.6550180912, 'total_duration': 151587.94029808044, 'accumulated_submission_time': 139520.6550180912, 'accumulated_eval_time': 12027.735392093658, 'accumulated_logging_time': 22.487955570220947}
I0304 05:39:06.489775 140239842563840 logging_writer.py:48] [312008] accumulated_eval_time=12027.735392, accumulated_logging_time=22.487956, accumulated_submission_time=139520.655018, global_step=312008, preemption_count=0, score=139520.655018, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=151587.940298, train/accuracy=0.889160, train/loss=0.411105, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:39:43.550979 140239850956544 logging_writer.py:48] [312100] global_step=312100, grad_norm=3.503211259841919, loss=2.93233060836792
I0304 05:40:28.602960 140239842563840 logging_writer.py:48] [312200] global_step=312200, grad_norm=3.158889055252075, loss=1.2383240461349487
I0304 05:41:13.898829 140239850956544 logging_writer.py:48] [312300] global_step=312300, grad_norm=2.9881508350372314, loss=1.1413829326629639
I0304 05:41:59.123600 140239842563840 logging_writer.py:48] [312400] global_step=312400, grad_norm=3.0484721660614014, loss=2.61669921875
I0304 05:42:44.430590 140239850956544 logging_writer.py:48] [312500] global_step=312500, grad_norm=2.84211802482605, loss=1.7672230005264282
I0304 05:43:29.692994 140239842563840 logging_writer.py:48] [312600] global_step=312600, grad_norm=2.756458044052124, loss=1.0945936441421509
I0304 05:44:15.060321 140239850956544 logging_writer.py:48] [312700] global_step=312700, grad_norm=4.13146448135376, loss=2.40718150138855
I0304 05:45:00.414986 140239842563840 logging_writer.py:48] [312800] global_step=312800, grad_norm=2.9707775115966797, loss=1.1178944110870361
I0304 05:45:45.719877 140239850956544 logging_writer.py:48] [312900] global_step=312900, grad_norm=3.1314914226531982, loss=1.9604902267456055
I0304 05:46:06.683684 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:46:16.847393 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:46:44.616490 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:46:46.238495 140437341357888 submission_runner.py:411] Time since start: 152047.79s, 	Step: 312948, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.4167310893535614, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 139940.78490543365, 'total_duration': 152047.78997969627, 'accumulated_submission_time': 139940.78490543365, 'accumulated_eval_time': 12067.290197372437, 'accumulated_logging_time': 22.602265119552612}
I0304 05:46:46.319833 140239842563840 logging_writer.py:48] [312948] accumulated_eval_time=12067.290197, accumulated_logging_time=22.602265, accumulated_submission_time=139940.784905, global_step=312948, preemption_count=0, score=139940.784905, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=152047.789980, train/accuracy=0.888144, train/loss=0.416731, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:47:07.299786 140239850956544 logging_writer.py:48] [313000] global_step=313000, grad_norm=2.880455732345581, loss=2.270599842071533
I0304 05:47:51.160579 140239842563840 logging_writer.py:48] [313100] global_step=313100, grad_norm=2.897371530532837, loss=1.1728143692016602
I0304 05:48:36.459776 140239850956544 logging_writer.py:48] [313200] global_step=313200, grad_norm=3.0411806106567383, loss=1.1069579124450684
I0304 05:49:21.807789 140239842563840 logging_writer.py:48] [313300] global_step=313300, grad_norm=3.00895094871521, loss=1.0914459228515625
I0304 05:50:06.975268 140239850956544 logging_writer.py:48] [313400] global_step=313400, grad_norm=3.1915650367736816, loss=2.4571619033813477
I0304 05:50:51.997120 140239842563840 logging_writer.py:48] [313500] global_step=313500, grad_norm=2.867833137512207, loss=2.0578389167785645
I0304 05:51:37.320602 140239850956544 logging_writer.py:48] [313600] global_step=313600, grad_norm=3.4172792434692383, loss=3.1079742908477783
I0304 05:52:22.474863 140239842563840 logging_writer.py:48] [313700] global_step=313700, grad_norm=3.0246927738189697, loss=1.2911474704742432
I0304 05:53:07.938737 140239850956544 logging_writer.py:48] [313800] global_step=313800, grad_norm=3.5927319526672363, loss=1.1797730922698975
I0304 05:53:46.446908 140437341357888 spec.py:321] Evaluating on the training split.
I0304 05:53:56.944742 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 05:54:25.818608 140437341357888 spec.py:349] Evaluating on the test split.
I0304 05:54:27.438550 140437341357888 submission_runner.py:411] Time since start: 152508.99s, 	Step: 313887, 	{'train/accuracy': 0.8859961032867432, 'train/loss': 0.42358630895614624, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 140360.85139131546, 'total_duration': 152508.9900314808, 'accumulated_submission_time': 140360.85139131546, 'accumulated_eval_time': 12108.281812429428, 'accumulated_logging_time': 22.693623065948486}
I0304 05:54:27.518934 140239842563840 logging_writer.py:48] [313887] accumulated_eval_time=12108.281812, accumulated_logging_time=22.693623, accumulated_submission_time=140360.851391, global_step=313887, preemption_count=0, score=140360.851391, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=152508.990031, train/accuracy=0.885996, train/loss=0.423586, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 05:54:33.094154 140239850956544 logging_writer.py:48] [313900] global_step=313900, grad_norm=3.1606616973876953, loss=1.0244977474212646
I0304 05:55:14.950585 140239842563840 logging_writer.py:48] [314000] global_step=314000, grad_norm=3.148792028427124, loss=1.1280930042266846
I0304 05:56:00.345987 140239850956544 logging_writer.py:48] [314100] global_step=314100, grad_norm=3.227081060409546, loss=1.1803839206695557
I0304 05:56:45.917295 140239842563840 logging_writer.py:48] [314200] global_step=314200, grad_norm=3.548133373260498, loss=3.089470386505127
I0304 05:57:31.206237 140239850956544 logging_writer.py:48] [314300] global_step=314300, grad_norm=3.2693276405334473, loss=1.3543728590011597
I0304 05:58:16.642826 140239842563840 logging_writer.py:48] [314400] global_step=314400, grad_norm=3.2515101432800293, loss=1.2624129056930542
I0304 05:59:01.889245 140239850956544 logging_writer.py:48] [314500] global_step=314500, grad_norm=3.039968252182007, loss=2.167750835418701
I0304 05:59:47.040833 140239842563840 logging_writer.py:48] [314600] global_step=314600, grad_norm=3.032388687133789, loss=1.8675280809402466
I0304 06:00:32.392425 140239850956544 logging_writer.py:48] [314700] global_step=314700, grad_norm=2.932274580001831, loss=1.2156957387924194
I0304 06:01:17.631833 140239842563840 logging_writer.py:48] [314800] global_step=314800, grad_norm=3.019296884536743, loss=2.630760669708252
I0304 06:01:27.773161 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:01:37.981708 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:02:04.794679 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:02:06.460032 140437341357888 submission_runner.py:411] Time since start: 152968.01s, 	Step: 314824, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.4152339696884155, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 140781.04164910316, 'total_duration': 152968.01148629189, 'accumulated_submission_time': 140781.04164910316, 'accumulated_eval_time': 12146.96865439415, 'accumulated_logging_time': 22.78712558746338}
I0304 06:02:06.585637 140239850956544 logging_writer.py:48] [314824] accumulated_eval_time=12146.968654, accumulated_logging_time=22.787126, accumulated_submission_time=140781.041649, global_step=314824, preemption_count=0, score=140781.041649, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=152968.011486, train/accuracy=0.888340, train/loss=0.415234, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:02:37.085001 140239842563840 logging_writer.py:48] [314900] global_step=314900, grad_norm=2.9820075035095215, loss=1.1431607007980347
I0304 06:03:21.585432 140239850956544 logging_writer.py:48] [315000] global_step=315000, grad_norm=2.911217212677002, loss=1.7377313375473022
I0304 06:04:06.660380 140239842563840 logging_writer.py:48] [315100] global_step=315100, grad_norm=3.2783100605010986, loss=1.142547607421875
I0304 06:04:52.035125 140239850956544 logging_writer.py:48] [315200] global_step=315200, grad_norm=3.1717405319213867, loss=1.1406371593475342
I0304 06:05:37.866656 140239842563840 logging_writer.py:48] [315300] global_step=315300, grad_norm=3.5937178134918213, loss=3.1743595600128174
I0304 06:06:23.405938 140239850956544 logging_writer.py:48] [315400] global_step=315400, grad_norm=2.864089250564575, loss=1.437392234802246
I0304 06:07:08.867091 140239842563840 logging_writer.py:48] [315500] global_step=315500, grad_norm=3.1557021141052246, loss=1.2653172016143799
I0304 06:07:53.916384 140239850956544 logging_writer.py:48] [315600] global_step=315600, grad_norm=3.061077356338501, loss=1.1384061574935913
I0304 06:08:39.355237 140239842563840 logging_writer.py:48] [315700] global_step=315700, grad_norm=3.0516197681427, loss=1.224249243736267
I0304 06:09:06.816073 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:09:17.183468 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:09:41.961222 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:09:43.590795 140437341357888 submission_runner.py:411] Time since start: 153425.14s, 	Step: 315762, 	{'train/accuracy': 0.8909569978713989, 'train/loss': 0.4055262804031372, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 141201.20494127274, 'total_duration': 153425.1422805786, 'accumulated_submission_time': 141201.20494127274, 'accumulated_eval_time': 12183.743371248245, 'accumulated_logging_time': 22.927883863449097}
I0304 06:09:43.671326 140239850956544 logging_writer.py:48] [315762] accumulated_eval_time=12183.743371, accumulated_logging_time=22.927884, accumulated_submission_time=141201.204941, global_step=315762, preemption_count=0, score=141201.204941, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=153425.142281, train/accuracy=0.890957, train/loss=0.405526, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:09:59.134809 140239842563840 logging_writer.py:48] [315800] global_step=315800, grad_norm=3.237092971801758, loss=1.2036710977554321
I0304 06:10:42.489345 140239850956544 logging_writer.py:48] [315900] global_step=315900, grad_norm=3.080418825149536, loss=2.0811872482299805
I0304 06:11:28.129533 140239842563840 logging_writer.py:48] [316000] global_step=316000, grad_norm=3.175377130508423, loss=1.147007942199707
I0304 06:12:13.337104 140239850956544 logging_writer.py:48] [316100] global_step=316100, grad_norm=3.00132417678833, loss=1.104644775390625
I0304 06:12:58.495945 140239842563840 logging_writer.py:48] [316200] global_step=316200, grad_norm=2.8635308742523193, loss=1.260114312171936
I0304 06:13:44.015246 140239850956544 logging_writer.py:48] [316300] global_step=316300, grad_norm=2.857830762863159, loss=1.3532406091690063
I0304 06:14:29.291657 140239842563840 logging_writer.py:48] [316400] global_step=316400, grad_norm=3.0327649116516113, loss=1.237621784210205
I0304 06:15:14.846229 140239850956544 logging_writer.py:48] [316500] global_step=316500, grad_norm=2.9641852378845215, loss=1.1559065580368042
I0304 06:16:00.692599 140239842563840 logging_writer.py:48] [316600] global_step=316600, grad_norm=2.929187059402466, loss=1.0803909301757812
I0304 06:16:43.990962 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:16:54.558574 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:17:19.685842 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:17:21.303449 140437341357888 submission_runner.py:411] Time since start: 153882.85s, 	Step: 316696, 	{'train/accuracy': 0.8879296779632568, 'train/loss': 0.42035382986068726, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 141621.46349978447, 'total_duration': 153882.85493707657, 'accumulated_submission_time': 141621.46349978447, 'accumulated_eval_time': 12221.055872440338, 'accumulated_logging_time': 23.01867938041687}
I0304 06:17:21.383832 140239850956544 logging_writer.py:48] [316696] accumulated_eval_time=12221.055872, accumulated_logging_time=23.018679, accumulated_submission_time=141621.463500, global_step=316696, preemption_count=0, score=141621.463500, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=153882.854937, train/accuracy=0.887930, train/loss=0.420354, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:17:23.390785 140239842563840 logging_writer.py:48] [316700] global_step=316700, grad_norm=3.6728427410125732, loss=3.128497362136841
I0304 06:18:05.093441 140239850956544 logging_writer.py:48] [316800] global_step=316800, grad_norm=3.0046494007110596, loss=1.512553095817566
I0304 06:18:50.276223 140239842563840 logging_writer.py:48] [316900] global_step=316900, grad_norm=3.5705809593200684, loss=2.493713855743408
I0304 06:19:35.580637 140239850956544 logging_writer.py:48] [317000] global_step=317000, grad_norm=3.1290483474731445, loss=2.5154337882995605
I0304 06:20:20.855709 140239842563840 logging_writer.py:48] [317100] global_step=317100, grad_norm=3.790433645248413, loss=2.9892067909240723
I0304 06:21:06.110728 140239850956544 logging_writer.py:48] [317200] global_step=317200, grad_norm=3.2393505573272705, loss=1.1571671962738037
I0304 06:21:51.300775 140239842563840 logging_writer.py:48] [317300] global_step=317300, grad_norm=3.2339227199554443, loss=1.1722522974014282
I0304 06:22:36.597927 140239850956544 logging_writer.py:48] [317400] global_step=317400, grad_norm=3.244847297668457, loss=1.200860857963562
I0304 06:23:21.868949 140239842563840 logging_writer.py:48] [317500] global_step=317500, grad_norm=2.8717615604400635, loss=1.7342721223831177
I0304 06:24:06.843950 140239850956544 logging_writer.py:48] [317600] global_step=317600, grad_norm=3.4233767986297607, loss=1.2445251941680908
I0304 06:24:21.440300 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:24:31.731148 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:25:01.742602 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:25:03.358617 140437341357888 submission_runner.py:411] Time since start: 154344.91s, 	Step: 317634, 	{'train/accuracy': 0.8866406083106995, 'train/loss': 0.4178559482097626, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 142041.4583003521, 'total_duration': 154344.91010689735, 'accumulated_submission_time': 142041.4583003521, 'accumulated_eval_time': 12262.974166870117, 'accumulated_logging_time': 23.10886240005493}
I0304 06:25:03.436823 140239842563840 logging_writer.py:48] [317634] accumulated_eval_time=12262.974167, accumulated_logging_time=23.108862, accumulated_submission_time=142041.458300, global_step=317634, preemption_count=0, score=142041.458300, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=154344.910107, train/accuracy=0.886641, train/loss=0.417856, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:25:29.969099 140239850956544 logging_writer.py:48] [317700] global_step=317700, grad_norm=3.0582714080810547, loss=2.390848159790039
I0304 06:26:14.701488 140239842563840 logging_writer.py:48] [317800] global_step=317800, grad_norm=3.352257251739502, loss=2.75576114654541
I0304 06:27:00.171625 140239850956544 logging_writer.py:48] [317900] global_step=317900, grad_norm=3.7322142124176025, loss=3.2547318935394287
I0304 06:27:45.295058 140239842563840 logging_writer.py:48] [318000] global_step=318000, grad_norm=2.7637925148010254, loss=1.9307178258895874
I0304 06:28:30.605178 140239850956544 logging_writer.py:48] [318100] global_step=318100, grad_norm=3.4695587158203125, loss=2.97161865234375
I0304 06:29:15.785502 140239842563840 logging_writer.py:48] [318200] global_step=318200, grad_norm=2.9253950119018555, loss=2.556872844696045
I0304 06:30:01.133673 140239850956544 logging_writer.py:48] [318300] global_step=318300, grad_norm=2.859606981277466, loss=1.0348886251449585
I0304 06:30:46.555676 140239842563840 logging_writer.py:48] [318400] global_step=318400, grad_norm=2.884479284286499, loss=1.077458381652832
I0304 06:31:31.893760 140239850956544 logging_writer.py:48] [318500] global_step=318500, grad_norm=2.9434866905212402, loss=1.1005438566207886
I0304 06:32:03.599230 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:32:13.753782 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:32:38.453709 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:32:40.072197 140437341357888 submission_runner.py:411] Time since start: 154801.62s, 	Step: 318572, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.41675031185150146, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 142461.56035637856, 'total_duration': 154801.62366724014, 'accumulated_submission_time': 142461.56035637856, 'accumulated_eval_time': 12299.447113752365, 'accumulated_logging_time': 23.19686794281006}
I0304 06:32:40.148922 140239842563840 logging_writer.py:48] [318572] accumulated_eval_time=12299.447114, accumulated_logging_time=23.196868, accumulated_submission_time=142461.560356, global_step=318572, preemption_count=0, score=142461.560356, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=154801.623667, train/accuracy=0.888340, train/loss=0.416750, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:32:51.661867 140239850956544 logging_writer.py:48] [318600] global_step=318600, grad_norm=2.971763849258423, loss=2.3942415714263916
I0304 06:33:34.132714 140239842563840 logging_writer.py:48] [318700] global_step=318700, grad_norm=2.930086135864258, loss=1.811577320098877
I0304 06:34:19.485501 140239850956544 logging_writer.py:48] [318800] global_step=318800, grad_norm=2.994774580001831, loss=1.0071996450424194
I0304 06:35:05.187280 140239842563840 logging_writer.py:48] [318900] global_step=318900, grad_norm=3.64475154876709, loss=3.182530641555786
I0304 06:35:50.429287 140239850956544 logging_writer.py:48] [319000] global_step=319000, grad_norm=3.219468832015991, loss=1.0929017066955566
I0304 06:36:35.967921 140239842563840 logging_writer.py:48] [319100] global_step=319100, grad_norm=3.26334547996521, loss=1.3130253553390503
I0304 06:37:21.010285 140239850956544 logging_writer.py:48] [319200] global_step=319200, grad_norm=2.854797840118408, loss=1.6530381441116333
I0304 06:38:06.184870 140239842563840 logging_writer.py:48] [319300] global_step=319300, grad_norm=3.1656484603881836, loss=1.1804487705230713
I0304 06:38:51.292113 140239850956544 logging_writer.py:48] [319400] global_step=319400, grad_norm=2.7765016555786133, loss=1.0430952310562134
I0304 06:39:36.648969 140239842563840 logging_writer.py:48] [319500] global_step=319500, grad_norm=3.5484116077423096, loss=1.7966701984405518
I0304 06:39:40.424767 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:39:50.721040 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:40:20.141471 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:40:21.764221 140437341357888 submission_runner.py:411] Time since start: 155263.32s, 	Step: 319510, 	{'train/accuracy': 0.88916015625, 'train/loss': 0.4147959053516388, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 142881.77575540543, 'total_duration': 155263.3157105446, 'accumulated_submission_time': 142881.77575540543, 'accumulated_eval_time': 12340.786552906036, 'accumulated_logging_time': 23.28324294090271}
I0304 06:40:21.846272 140239850956544 logging_writer.py:48] [319510] accumulated_eval_time=12340.786553, accumulated_logging_time=23.283243, accumulated_submission_time=142881.775755, global_step=319510, preemption_count=0, score=142881.775755, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=155263.315711, train/accuracy=0.889160, train/loss=0.414796, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:40:58.844346 140239842563840 logging_writer.py:48] [319600] global_step=319600, grad_norm=2.767188310623169, loss=1.03621244430542
I0304 06:41:44.009553 140239850956544 logging_writer.py:48] [319700] global_step=319700, grad_norm=3.1400625705718994, loss=2.6601815223693848
I0304 06:42:29.305359 140239842563840 logging_writer.py:48] [319800] global_step=319800, grad_norm=3.6053643226623535, loss=3.1975831985473633
I0304 06:43:14.491935 140239850956544 logging_writer.py:48] [319900] global_step=319900, grad_norm=2.8754148483276367, loss=1.2039039134979248
I0304 06:43:59.582642 140239842563840 logging_writer.py:48] [320000] global_step=320000, grad_norm=2.9325528144836426, loss=2.179521083831787
I0304 06:44:44.852285 140239850956544 logging_writer.py:48] [320100] global_step=320100, grad_norm=3.146169424057007, loss=1.079132080078125
I0304 06:45:29.931475 140239842563840 logging_writer.py:48] [320200] global_step=320200, grad_norm=3.1792938709259033, loss=2.5536255836486816
I0304 06:46:15.509947 140239850956544 logging_writer.py:48] [320300] global_step=320300, grad_norm=3.2704238891601562, loss=1.696529507637024
I0304 06:47:01.360235 140239842563840 logging_writer.py:48] [320400] global_step=320400, grad_norm=3.1138405799865723, loss=2.4923129081726074
I0304 06:47:22.145019 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:47:32.362819 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:47:59.594225 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:48:01.222072 140437341357888 submission_runner.py:411] Time since start: 155722.77s, 	Step: 320448, 	{'train/accuracy': 0.8883007764816284, 'train/loss': 0.41130781173706055, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 143302.01441574097, 'total_duration': 155722.77356290817, 'accumulated_submission_time': 143302.01441574097, 'accumulated_eval_time': 12379.863595485687, 'accumulated_logging_time': 23.374863862991333}
I0304 06:48:01.306473 140239850956544 logging_writer.py:48] [320448] accumulated_eval_time=12379.863595, accumulated_logging_time=23.374864, accumulated_submission_time=143302.014416, global_step=320448, preemption_count=0, score=143302.014416, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=155722.773563, train/accuracy=0.888301, train/loss=0.411308, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:48:22.454800 140239842563840 logging_writer.py:48] [320500] global_step=320500, grad_norm=3.4365451335906982, loss=1.2269163131713867
I0304 06:49:06.945686 140239850956544 logging_writer.py:48] [320600] global_step=320600, grad_norm=2.9971518516540527, loss=1.5972952842712402
I0304 06:49:52.106414 140239842563840 logging_writer.py:48] [320700] global_step=320700, grad_norm=3.188567638397217, loss=1.2378110885620117
I0304 06:50:37.237592 140239850956544 logging_writer.py:48] [320800] global_step=320800, grad_norm=3.4344911575317383, loss=1.209774136543274
I0304 06:51:22.418454 140239842563840 logging_writer.py:48] [320900] global_step=320900, grad_norm=3.207947015762329, loss=1.1081600189208984
I0304 06:52:07.496314 140239850956544 logging_writer.py:48] [321000] global_step=321000, grad_norm=3.042080879211426, loss=1.1201410293579102
I0304 06:52:52.550175 140239842563840 logging_writer.py:48] [321100] global_step=321100, grad_norm=3.5560503005981445, loss=3.1447346210479736
I0304 06:53:37.777651 140239850956544 logging_writer.py:48] [321200] global_step=321200, grad_norm=2.956674337387085, loss=1.0864640474319458
I0304 06:54:23.031560 140239842563840 logging_writer.py:48] [321300] global_step=321300, grad_norm=2.9375877380371094, loss=1.1656334400177002
I0304 06:55:01.455276 140437341357888 spec.py:321] Evaluating on the training split.
I0304 06:55:11.934296 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 06:55:43.863163 140437341357888 spec.py:349] Evaluating on the test split.
I0304 06:55:45.491102 140437341357888 submission_runner.py:411] Time since start: 156187.04s, 	Step: 321387, 	{'train/accuracy': 0.8866991996765137, 'train/loss': 0.41740545630455017, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 143722.09818434715, 'total_duration': 156187.04256916046, 'accumulated_submission_time': 143722.09818434715, 'accumulated_eval_time': 12423.899383544922, 'accumulated_logging_time': 23.473129272460938}
I0304 06:55:45.576435 140239850956544 logging_writer.py:48] [321387] accumulated_eval_time=12423.899384, accumulated_logging_time=23.473129, accumulated_submission_time=143722.098184, global_step=321387, preemption_count=0, score=143722.098184, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=156187.042569, train/accuracy=0.886699, train/loss=0.417405, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 06:55:51.135432 140239842563840 logging_writer.py:48] [321400] global_step=321400, grad_norm=3.183950185775757, loss=2.7055914402008057
I0304 06:56:32.824325 140239850956544 logging_writer.py:48] [321500] global_step=321500, grad_norm=2.835742473602295, loss=1.145222544670105
I0304 06:57:18.581080 140239842563840 logging_writer.py:48] [321600] global_step=321600, grad_norm=3.2963807582855225, loss=1.1931129693984985
I0304 06:58:04.054000 140239850956544 logging_writer.py:48] [321700] global_step=321700, grad_norm=3.011268138885498, loss=1.19008469581604
I0304 06:58:49.086253 140239842563840 logging_writer.py:48] [321800] global_step=321800, grad_norm=3.2233545780181885, loss=2.3277623653411865
I0304 06:59:34.592798 140239850956544 logging_writer.py:48] [321900] global_step=321900, grad_norm=3.186084032058716, loss=1.252769947052002
I0304 07:00:19.703618 140239842563840 logging_writer.py:48] [322000] global_step=322000, grad_norm=3.156693458557129, loss=1.2178947925567627
I0304 07:01:04.962258 140239850956544 logging_writer.py:48] [322100] global_step=322100, grad_norm=3.0899930000305176, loss=1.1717801094055176
I0304 07:01:50.598235 140239842563840 logging_writer.py:48] [322200] global_step=322200, grad_norm=2.9253597259521484, loss=1.7268568277359009
I0304 07:02:36.187731 140239850956544 logging_writer.py:48] [322300] global_step=322300, grad_norm=3.1022560596466064, loss=2.15922212600708
I0304 07:02:45.875030 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:02:56.073399 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:03:24.401949 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:03:26.036009 140437341357888 submission_runner.py:411] Time since start: 156647.59s, 	Step: 322323, 	{'train/accuracy': 0.8899218440055847, 'train/loss': 0.40962737798690796, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 144142.33653116226, 'total_duration': 156647.58727145195, 'accumulated_submission_time': 144142.33653116226, 'accumulated_eval_time': 12464.060123443604, 'accumulated_logging_time': 23.5680513381958}
I0304 07:03:26.115819 140239842563840 logging_writer.py:48] [322323] accumulated_eval_time=12464.060123, accumulated_logging_time=23.568051, accumulated_submission_time=144142.336531, global_step=322323, preemption_count=0, score=144142.336531, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=156647.587271, train/accuracy=0.889922, train/loss=0.409627, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:03:57.239129 140239850956544 logging_writer.py:48] [322400] global_step=322400, grad_norm=3.0901386737823486, loss=1.183454155921936
I0304 07:04:42.396674 140239842563840 logging_writer.py:48] [322500] global_step=322500, grad_norm=3.0949907302856445, loss=2.557542324066162
I0304 07:05:27.821886 140239850956544 logging_writer.py:48] [322600] global_step=322600, grad_norm=3.1485626697540283, loss=1.2550468444824219
I0304 07:06:13.345179 140239842563840 logging_writer.py:48] [322700] global_step=322700, grad_norm=2.7365500926971436, loss=1.0572673082351685
I0304 07:06:58.757240 140239850956544 logging_writer.py:48] [322800] global_step=322800, grad_norm=3.1245815753936768, loss=1.1924102306365967
I0304 07:07:44.402636 140239842563840 logging_writer.py:48] [322900] global_step=322900, grad_norm=2.8285932540893555, loss=1.537622094154358
I0304 07:08:29.912761 140239850956544 logging_writer.py:48] [323000] global_step=323000, grad_norm=2.843170404434204, loss=1.3289700746536255
I0304 07:09:15.341442 140239842563840 logging_writer.py:48] [323100] global_step=323100, grad_norm=2.887068510055542, loss=1.430617332458496
I0304 07:10:00.706273 140239850956544 logging_writer.py:48] [323200] global_step=323200, grad_norm=2.9101665019989014, loss=1.9242358207702637
I0304 07:10:26.318812 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:10:36.631949 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:11:04.067116 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:11:05.712484 140437341357888 submission_runner.py:411] Time since start: 157107.26s, 	Step: 323258, 	{'train/accuracy': 0.8880468606948853, 'train/loss': 0.41444021463394165, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 144562.4763252735, 'total_duration': 157107.26393318176, 'accumulated_submission_time': 144562.4763252735, 'accumulated_eval_time': 12503.453735589981, 'accumulated_logging_time': 23.660505771636963}
I0304 07:11:05.843397 140239842563840 logging_writer.py:48] [323258] accumulated_eval_time=12503.453736, accumulated_logging_time=23.660506, accumulated_submission_time=144562.476325, global_step=323258, preemption_count=0, score=144562.476325, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=157107.263933, train/accuracy=0.888047, train/loss=0.414440, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:11:22.872996 140239850956544 logging_writer.py:48] [323300] global_step=323300, grad_norm=3.775355815887451, loss=3.040544271469116
I0304 07:12:06.066943 140239842563840 logging_writer.py:48] [323400] global_step=323400, grad_norm=3.438619375228882, loss=2.937159538269043
I0304 07:12:51.259983 140239850956544 logging_writer.py:48] [323500] global_step=323500, grad_norm=3.5714757442474365, loss=3.190225601196289
I0304 07:13:36.893791 140239842563840 logging_writer.py:48] [323600] global_step=323600, grad_norm=2.9550843238830566, loss=1.140374779701233
I0304 07:14:21.996626 140239850956544 logging_writer.py:48] [323700] global_step=323700, grad_norm=3.042736530303955, loss=2.4975943565368652
I0304 07:15:07.469642 140239842563840 logging_writer.py:48] [323800] global_step=323800, grad_norm=3.5666565895080566, loss=1.131743311882019
I0304 07:15:52.597107 140239850956544 logging_writer.py:48] [323900] global_step=323900, grad_norm=3.1693875789642334, loss=1.1667636632919312
I0304 07:16:37.938033 140239842563840 logging_writer.py:48] [324000] global_step=324000, grad_norm=3.156787157058716, loss=2.1916768550872803
I0304 07:17:23.838607 140239850956544 logging_writer.py:48] [324100] global_step=324100, grad_norm=3.188422918319702, loss=1.200666904449463
I0304 07:18:05.791643 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:18:16.102306 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:18:41.709824 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:18:43.339787 140437341357888 submission_runner.py:411] Time since start: 157564.89s, 	Step: 324194, 	{'train/accuracy': 0.8901171684265137, 'train/loss': 0.41190704703330994, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 144982.35832333565, 'total_duration': 157564.89127373695, 'accumulated_submission_time': 144982.35832333565, 'accumulated_eval_time': 12541.001872062683, 'accumulated_logging_time': 23.807493209838867}
I0304 07:18:43.422272 140239842563840 logging_writer.py:48] [324194] accumulated_eval_time=12541.001872, accumulated_logging_time=23.807493, accumulated_submission_time=144982.358323, global_step=324194, preemption_count=0, score=144982.358323, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=157564.891274, train/accuracy=0.890117, train/loss=0.411907, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:18:46.203118 140239850956544 logging_writer.py:48] [324200] global_step=324200, grad_norm=3.39115047454834, loss=2.378032922744751
I0304 07:19:27.737570 140239842563840 logging_writer.py:48] [324300] global_step=324300, grad_norm=2.9427649974823, loss=2.0027835369110107
I0304 07:20:13.009504 140239850956544 logging_writer.py:48] [324400] global_step=324400, grad_norm=3.819200038909912, loss=3.18386173248291
I0304 07:20:58.035482 140239842563840 logging_writer.py:48] [324500] global_step=324500, grad_norm=3.008101224899292, loss=1.308393120765686
I0304 07:21:43.167138 140239850956544 logging_writer.py:48] [324600] global_step=324600, grad_norm=3.032930612564087, loss=1.9700591564178467
I0304 07:22:28.445159 140239842563840 logging_writer.py:48] [324700] global_step=324700, grad_norm=3.499319314956665, loss=3.0561323165893555
I0304 07:23:13.624968 140239850956544 logging_writer.py:48] [324800] global_step=324800, grad_norm=3.166623115539551, loss=1.266444444656372
I0304 07:23:58.898890 140239842563840 logging_writer.py:48] [324900] global_step=324900, grad_norm=3.134742259979248, loss=1.2482786178588867
I0304 07:24:44.114371 140239850956544 logging_writer.py:48] [325000] global_step=325000, grad_norm=2.951117515563965, loss=1.1349507570266724
I0304 07:25:29.364607 140239842563840 logging_writer.py:48] [325100] global_step=325100, grad_norm=3.3274307250976562, loss=1.2249680757522583
I0304 07:25:43.492345 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:25:53.886708 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:26:23.149202 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:26:24.763556 140437341357888 submission_runner.py:411] Time since start: 158026.32s, 	Step: 325133, 	{'train/accuracy': 0.8872851133346558, 'train/loss': 0.41817501187324524, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 145402.36496806145, 'total_duration': 158026.31503486633, 'accumulated_submission_time': 145402.36496806145, 'accumulated_eval_time': 12582.273058652878, 'accumulated_logging_time': 23.902076482772827}
I0304 07:26:24.844272 140239850956544 logging_writer.py:48] [325133] accumulated_eval_time=12582.273059, accumulated_logging_time=23.902076, accumulated_submission_time=145402.364968, global_step=325133, preemption_count=0, score=145402.364968, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=158026.315035, train/accuracy=0.887285, train/loss=0.418175, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:26:51.774348 140239842563840 logging_writer.py:48] [325200] global_step=325200, grad_norm=3.0440449714660645, loss=1.006069302558899
I0304 07:27:36.982624 140239850956544 logging_writer.py:48] [325300] global_step=325300, grad_norm=3.236846685409546, loss=1.1404255628585815
I0304 07:28:22.157813 140239842563840 logging_writer.py:48] [325400] global_step=325400, grad_norm=3.0355591773986816, loss=1.8559675216674805
I0304 07:29:07.307218 140239850956544 logging_writer.py:48] [325500] global_step=325500, grad_norm=2.909519672393799, loss=2.076888084411621
I0304 07:29:52.470829 140239842563840 logging_writer.py:48] [325600] global_step=325600, grad_norm=3.7791593074798584, loss=1.230303406715393
I0304 07:30:37.628751 140239850956544 logging_writer.py:48] [325700] global_step=325700, grad_norm=3.575542688369751, loss=3.291948080062866
I0304 07:31:22.958030 140239842563840 logging_writer.py:48] [325800] global_step=325800, grad_norm=2.7881104946136475, loss=1.7067285776138306
I0304 07:32:08.222497 140239850956544 logging_writer.py:48] [325900] global_step=325900, grad_norm=2.87593674659729, loss=2.094451904296875
I0304 07:32:53.506774 140239842563840 logging_writer.py:48] [326000] global_step=326000, grad_norm=3.055448532104492, loss=1.0782089233398438
I0304 07:33:24.847474 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:33:35.094134 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:34:04.235055 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:34:05.877748 140437341357888 submission_runner.py:411] Time since start: 158487.43s, 	Step: 326071, 	{'train/accuracy': 0.8898437023162842, 'train/loss': 0.4119757115840912, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 145822.30849671364, 'total_duration': 158487.42919802666, 'accumulated_submission_time': 145822.30849671364, 'accumulated_eval_time': 12623.30327129364, 'accumulated_logging_time': 23.99218988418579}
I0304 07:34:06.007311 140239850956544 logging_writer.py:48] [326071] accumulated_eval_time=12623.303271, accumulated_logging_time=23.992190, accumulated_submission_time=145822.308497, global_step=326071, preemption_count=0, score=145822.308497, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=158487.429198, train/accuracy=0.889844, train/loss=0.411976, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:34:17.891458 140239842563840 logging_writer.py:48] [326100] global_step=326100, grad_norm=3.355239152908325, loss=1.2198938131332397
I0304 07:34:59.538464 140239850956544 logging_writer.py:48] [326200] global_step=326200, grad_norm=2.9685885906219482, loss=1.0720608234405518
I0304 07:35:45.010966 140239842563840 logging_writer.py:48] [326300] global_step=326300, grad_norm=2.7525670528411865, loss=1.859788417816162
I0304 07:36:30.575212 140239850956544 logging_writer.py:48] [326400] global_step=326400, grad_norm=2.9881863594055176, loss=1.0702588558197021
I0304 07:37:16.364213 140239842563840 logging_writer.py:48] [326500] global_step=326500, grad_norm=2.9011270999908447, loss=2.4317054748535156
I0304 07:38:01.918384 140239850956544 logging_writer.py:48] [326600] global_step=326600, grad_norm=3.02014422416687, loss=2.031780242919922
I0304 07:38:47.175056 140239842563840 logging_writer.py:48] [326700] global_step=326700, grad_norm=2.9068524837493896, loss=1.3070505857467651
I0304 07:39:32.219048 140239850956544 logging_writer.py:48] [326800] global_step=326800, grad_norm=2.9619414806365967, loss=1.8885239362716675
I0304 07:40:17.615499 140239842563840 logging_writer.py:48] [326900] global_step=326900, grad_norm=3.7171833515167236, loss=3.1704554557800293
I0304 07:41:02.697175 140239850956544 logging_writer.py:48] [327000] global_step=327000, grad_norm=3.070828914642334, loss=1.6006855964660645
I0304 07:41:06.027357 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:41:16.248164 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:41:40.164412 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:41:41.789375 140437341357888 submission_runner.py:411] Time since start: 158943.34s, 	Step: 327009, 	{'train/accuracy': 0.8896679282188416, 'train/loss': 0.41374221444129944, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 146242.26469278336, 'total_duration': 158943.34083485603, 'accumulated_submission_time': 146242.26469278336, 'accumulated_eval_time': 12659.065303087234, 'accumulated_logging_time': 24.135462999343872}
I0304 07:41:41.877775 140239842563840 logging_writer.py:48] [327009] accumulated_eval_time=12659.065303, accumulated_logging_time=24.135463, accumulated_submission_time=146242.264693, global_step=327009, preemption_count=0, score=146242.264693, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=158943.340835, train/accuracy=0.889668, train/loss=0.413742, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:42:19.453657 140239850956544 logging_writer.py:48] [327100] global_step=327100, grad_norm=4.186379909515381, loss=1.9188241958618164
I0304 07:43:04.610553 140239842563840 logging_writer.py:48] [327200] global_step=327200, grad_norm=3.110764741897583, loss=1.6466124057769775
I0304 07:43:49.842812 140239850956544 logging_writer.py:48] [327300] global_step=327300, grad_norm=3.1756365299224854, loss=1.124539852142334
I0304 07:44:35.146745 140239842563840 logging_writer.py:48] [327400] global_step=327400, grad_norm=2.9704301357269287, loss=1.1285247802734375
I0304 07:45:20.620744 140239850956544 logging_writer.py:48] [327500] global_step=327500, grad_norm=2.988457202911377, loss=1.1400960683822632
I0304 07:46:06.095204 140239842563840 logging_writer.py:48] [327600] global_step=327600, grad_norm=2.985651969909668, loss=1.278019905090332
I0304 07:46:51.339603 140239850956544 logging_writer.py:48] [327700] global_step=327700, grad_norm=2.917501449584961, loss=1.0227481126785278
I0304 07:47:36.869296 140239842563840 logging_writer.py:48] [327800] global_step=327800, grad_norm=3.220762014389038, loss=2.4798216819763184
I0304 07:48:22.455663 140239850956544 logging_writer.py:48] [327900] global_step=327900, grad_norm=3.844392776489258, loss=3.2645928859710693
I0304 07:48:41.967064 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:48:53.253906 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:49:18.599817 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:49:20.218054 140437341357888 submission_runner.py:411] Time since start: 159401.77s, 	Step: 327945, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.41160112619400024, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 146662.29273629189, 'total_duration': 159401.76953983307, 'accumulated_submission_time': 146662.29273629189, 'accumulated_eval_time': 12697.31627702713, 'accumulated_logging_time': 24.234971523284912}
I0304 07:49:20.299921 140239842563840 logging_writer.py:48] [327945] accumulated_eval_time=12697.316277, accumulated_logging_time=24.234972, accumulated_submission_time=146662.292736, global_step=327945, preemption_count=0, score=146662.292736, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=159401.769540, train/accuracy=0.889570, train/loss=0.411601, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:49:42.477545 140239850956544 logging_writer.py:48] [328000] global_step=328000, grad_norm=3.041724443435669, loss=1.1134148836135864
I0304 07:50:27.055236 140239842563840 logging_writer.py:48] [328100] global_step=328100, grad_norm=2.7621469497680664, loss=1.396897315979004
I0304 07:51:12.351157 140239850956544 logging_writer.py:48] [328200] global_step=328200, grad_norm=3.6080589294433594, loss=3.091268301010132
I0304 07:51:57.515455 140239842563840 logging_writer.py:48] [328300] global_step=328300, grad_norm=3.183173894882202, loss=1.1984773874282837
I0304 07:52:42.659000 140239850956544 logging_writer.py:48] [328400] global_step=328400, grad_norm=3.178114891052246, loss=3.0422935485839844
I0304 07:53:27.806240 140239842563840 logging_writer.py:48] [328500] global_step=328500, grad_norm=2.9718072414398193, loss=2.040483236312866
I0304 07:54:13.098548 140239850956544 logging_writer.py:48] [328600] global_step=328600, grad_norm=3.0760838985443115, loss=1.2775993347167969
I0304 07:54:58.296720 140239842563840 logging_writer.py:48] [328700] global_step=328700, grad_norm=3.144482135772705, loss=2.715207576751709
I0304 07:55:43.510849 140239850956544 logging_writer.py:48] [328800] global_step=328800, grad_norm=2.9599342346191406, loss=1.1892298460006714
I0304 07:56:20.591336 140437341357888 spec.py:321] Evaluating on the training split.
I0304 07:56:31.145108 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 07:57:00.412391 140437341357888 spec.py:349] Evaluating on the test split.
I0304 07:57:02.050362 140437341357888 submission_runner.py:411] Time since start: 159863.60s, 	Step: 328883, 	{'train/accuracy': 0.8875585794448853, 'train/loss': 0.4162088930606842, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 147082.52355718613, 'total_duration': 159863.60181355476, 'accumulated_submission_time': 147082.52355718613, 'accumulated_eval_time': 12738.77527141571, 'accumulated_logging_time': 24.327179431915283}
I0304 07:57:02.176184 140239842563840 logging_writer.py:48] [328883] accumulated_eval_time=12738.775271, accumulated_logging_time=24.327179, accumulated_submission_time=147082.523557, global_step=328883, preemption_count=0, score=147082.523557, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=159863.601814, train/accuracy=0.887559, train/loss=0.416209, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 07:57:09.317951 140239850956544 logging_writer.py:48] [328900] global_step=328900, grad_norm=2.8575942516326904, loss=1.3822801113128662
I0304 07:57:51.358245 140239842563840 logging_writer.py:48] [329000] global_step=329000, grad_norm=3.070282459259033, loss=1.196139931678772
I0304 07:58:37.140699 140239850956544 logging_writer.py:48] [329100] global_step=329100, grad_norm=2.9362759590148926, loss=1.1085476875305176
I0304 07:59:23.126331 140239842563840 logging_writer.py:48] [329200] global_step=329200, grad_norm=2.940948247909546, loss=1.203555941581726
I0304 08:00:08.314480 140239850956544 logging_writer.py:48] [329300] global_step=329300, grad_norm=2.8930718898773193, loss=1.1011407375335693
I0304 08:00:53.624752 140239842563840 logging_writer.py:48] [329400] global_step=329400, grad_norm=3.1147620677948, loss=1.9135464429855347
I0304 08:01:39.065205 140239850956544 logging_writer.py:48] [329500] global_step=329500, grad_norm=3.1750710010528564, loss=1.2946531772613525
I0304 08:02:24.274167 140239842563840 logging_writer.py:48] [329600] global_step=329600, grad_norm=2.9245359897613525, loss=2.129643678665161
I0304 08:03:09.594686 140239850956544 logging_writer.py:48] [329700] global_step=329700, grad_norm=3.106546640396118, loss=1.1632040739059448
I0304 08:03:54.923246 140239842563840 logging_writer.py:48] [329800] global_step=329800, grad_norm=3.240827798843384, loss=1.2043668031692505
I0304 08:04:02.315243 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:04:12.485010 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:04:39.935565 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:04:41.555098 140437341357888 submission_runner.py:411] Time since start: 160323.11s, 	Step: 329818, 	{'train/accuracy': 0.8869140148162842, 'train/loss': 0.41703638434410095, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 147502.60175275803, 'total_duration': 160323.10658454895, 'accumulated_submission_time': 147502.60175275803, 'accumulated_eval_time': 12778.015112400055, 'accumulated_logging_time': 24.46321201324463}
I0304 08:04:41.648375 140239850956544 logging_writer.py:48] [329818] accumulated_eval_time=12778.015112, accumulated_logging_time=24.463212, accumulated_submission_time=147502.601753, global_step=329818, preemption_count=0, score=147502.601753, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=160323.106585, train/accuracy=0.886914, train/loss=0.417036, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:05:15.113594 140239842563840 logging_writer.py:48] [329900] global_step=329900, grad_norm=3.2283928394317627, loss=1.232412338256836
I0304 08:06:00.375577 140239850956544 logging_writer.py:48] [330000] global_step=330000, grad_norm=3.2649455070495605, loss=2.253056287765503
I0304 08:06:46.479739 140239842563840 logging_writer.py:48] [330100] global_step=330100, grad_norm=3.2869043350219727, loss=2.9188923835754395
I0304 08:07:31.630403 140239850956544 logging_writer.py:48] [330200] global_step=330200, grad_norm=3.0441367626190186, loss=1.7832818031311035
I0304 08:08:17.147522 140239842563840 logging_writer.py:48] [330300] global_step=330300, grad_norm=2.8712265491485596, loss=1.7636371850967407
I0304 08:09:02.293941 140239850956544 logging_writer.py:48] [330400] global_step=330400, grad_norm=2.938432455062866, loss=1.1106722354888916
I0304 08:09:47.560022 140239842563840 logging_writer.py:48] [330500] global_step=330500, grad_norm=3.069658041000366, loss=2.7123517990112305
I0304 08:10:32.960911 140239850956544 logging_writer.py:48] [330600] global_step=330600, grad_norm=3.2851951122283936, loss=1.1035864353179932
I0304 08:11:17.808753 140239842563840 logging_writer.py:48] [330700] global_step=330700, grad_norm=2.89612078666687, loss=2.1909470558166504
I0304 08:11:41.922173 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:11:52.381065 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:12:21.704910 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:12:23.326251 140437341357888 submission_runner.py:411] Time since start: 160784.88s, 	Step: 330755, 	{'train/accuracy': 0.8896679282188416, 'train/loss': 0.4135584831237793, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 147922.8135919571, 'total_duration': 160784.8777372837, 'accumulated_submission_time': 147922.8135919571, 'accumulated_eval_time': 12819.419175863266, 'accumulated_logging_time': 24.56829261779785}
I0304 08:12:23.408606 140239850956544 logging_writer.py:48] [330755] accumulated_eval_time=12819.419176, accumulated_logging_time=24.568293, accumulated_submission_time=147922.813592, global_step=330755, preemption_count=0, score=147922.813592, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=160784.877737, train/accuracy=0.889668, train/loss=0.413558, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:12:41.645042 140239842563840 logging_writer.py:48] [330800] global_step=330800, grad_norm=3.3859004974365234, loss=1.082837462425232
I0304 08:13:24.899589 140239850956544 logging_writer.py:48] [330900] global_step=330900, grad_norm=3.048800468444824, loss=1.3813289403915405
I0304 08:14:10.503081 140239842563840 logging_writer.py:48] [331000] global_step=331000, grad_norm=3.5445868968963623, loss=1.089208722114563
I0304 08:14:55.747621 140239850956544 logging_writer.py:48] [331100] global_step=331100, grad_norm=2.9721574783325195, loss=1.0050238370895386
I0304 08:15:40.876403 140239842563840 logging_writer.py:48] [331200] global_step=331200, grad_norm=3.1594204902648926, loss=1.1873762607574463
I0304 08:16:26.248780 140239850956544 logging_writer.py:48] [331300] global_step=331300, grad_norm=3.182725429534912, loss=1.421499490737915
I0304 08:17:11.644389 140239842563840 logging_writer.py:48] [331400] global_step=331400, grad_norm=3.025186538696289, loss=1.1392314434051514
I0304 08:17:56.751771 140239850956544 logging_writer.py:48] [331500] global_step=331500, grad_norm=3.2536914348602295, loss=2.500758647918701
I0304 08:18:42.129313 140239842563840 logging_writer.py:48] [331600] global_step=331600, grad_norm=3.211317539215088, loss=1.1089502573013306
I0304 08:19:23.757137 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:19:34.040227 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:20:10.126336 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:20:11.752797 140437341357888 submission_runner.py:411] Time since start: 161253.30s, 	Step: 331694, 	{'train/accuracy': 0.8881250023841858, 'train/loss': 0.4180620610713959, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 148343.09826993942, 'total_duration': 161253.30429697037, 'accumulated_submission_time': 148343.09826993942, 'accumulated_eval_time': 12867.414836645126, 'accumulated_logging_time': 24.66355276107788}
I0304 08:20:11.821981 140239850956544 logging_writer.py:48] [331694] accumulated_eval_time=12867.414837, accumulated_logging_time=24.663553, accumulated_submission_time=148343.098270, global_step=331694, preemption_count=0, score=148343.098270, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=161253.304297, train/accuracy=0.888125, train/loss=0.418062, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:20:14.590435 140239842563840 logging_writer.py:48] [331700] global_step=331700, grad_norm=3.106065511703491, loss=1.355895757675171
I0304 08:20:54.606914 140239850956544 logging_writer.py:48] [331800] global_step=331800, grad_norm=3.1873106956481934, loss=1.1924008131027222
I0304 08:21:39.669213 140239842563840 logging_writer.py:48] [331900] global_step=331900, grad_norm=3.1900036334991455, loss=1.0921030044555664
I0304 08:22:25.209684 140239850956544 logging_writer.py:48] [332000] global_step=332000, grad_norm=3.1246604919433594, loss=1.1832010746002197
I0304 08:23:10.308602 140239842563840 logging_writer.py:48] [332100] global_step=332100, grad_norm=3.274648666381836, loss=2.1401662826538086
I0304 08:23:55.518019 140239850956544 logging_writer.py:48] [332200] global_step=332200, grad_norm=3.555645227432251, loss=3.0203423500061035
I0304 08:24:40.624890 140239842563840 logging_writer.py:48] [332300] global_step=332300, grad_norm=3.2259302139282227, loss=1.1426353454589844
I0304 08:25:25.870305 140239850956544 logging_writer.py:48] [332400] global_step=332400, grad_norm=2.802685260772705, loss=1.7811342477798462
I0304 08:26:11.013093 140239842563840 logging_writer.py:48] [332500] global_step=332500, grad_norm=3.0192453861236572, loss=1.032214641571045
I0304 08:26:55.892436 140239850956544 logging_writer.py:48] [332600] global_step=332600, grad_norm=3.0498909950256348, loss=1.4163141250610352
I0304 08:27:11.990816 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:27:22.312192 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:27:50.298011 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:27:51.921920 140437341357888 submission_runner.py:411] Time since start: 161713.47s, 	Step: 332637, 	{'train/accuracy': 0.8884961009025574, 'train/loss': 0.4143311083316803, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 148763.2022268772, 'total_duration': 161713.47340416908, 'accumulated_submission_time': 148763.2022268772, 'accumulated_eval_time': 12907.345923662186, 'accumulated_logging_time': 24.7419536113739}
I0304 08:27:52.004902 140239842563840 logging_writer.py:48] [332637] accumulated_eval_time=12907.345924, accumulated_logging_time=24.741954, accumulated_submission_time=148763.202227, global_step=332637, preemption_count=0, score=148763.202227, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=161713.473404, train/accuracy=0.888496, train/loss=0.414331, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:28:17.356336 140239850956544 logging_writer.py:48] [332700] global_step=332700, grad_norm=3.1580002307891846, loss=1.1324639320373535
I0304 08:29:02.710726 140239842563840 logging_writer.py:48] [332800] global_step=332800, grad_norm=3.6634602546691895, loss=3.264415979385376
I0304 08:29:48.000364 140239850956544 logging_writer.py:48] [332900] global_step=332900, grad_norm=3.835764169692993, loss=3.2738492488861084
I0304 08:30:33.499720 140239842563840 logging_writer.py:48] [333000] global_step=333000, grad_norm=3.2775652408599854, loss=2.6927385330200195
I0304 08:31:18.613359 140239850956544 logging_writer.py:48] [333100] global_step=333100, grad_norm=3.24558424949646, loss=1.5253793001174927
I0304 08:32:04.044758 140239842563840 logging_writer.py:48] [333200] global_step=333200, grad_norm=3.3483688831329346, loss=1.0366092920303345
I0304 08:32:49.407988 140239850956544 logging_writer.py:48] [333300] global_step=333300, grad_norm=3.7943978309631348, loss=1.6746889352798462
I0304 08:33:34.670298 140239842563840 logging_writer.py:48] [333400] global_step=333400, grad_norm=3.1038124561309814, loss=1.0742542743682861
I0304 08:34:19.898232 140239850956544 logging_writer.py:48] [333500] global_step=333500, grad_norm=3.2617855072021484, loss=1.572106957435608
I0304 08:34:52.129521 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:35:02.920290 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:35:33.411056 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:35:35.036605 140437341357888 submission_runner.py:411] Time since start: 162176.59s, 	Step: 333573, 	{'train/accuracy': 0.8854101300239563, 'train/loss': 0.4235457181930542, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 149183.26648783684, 'total_duration': 162176.588023901, 'accumulated_submission_time': 149183.26648783684, 'accumulated_eval_time': 12950.252911806107, 'accumulated_logging_time': 24.83434271812439}
I0304 08:35:35.117806 140239842563840 logging_writer.py:48] [333573] accumulated_eval_time=12950.252912, accumulated_logging_time=24.834343, accumulated_submission_time=149183.266488, global_step=333573, preemption_count=0, score=149183.266488, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=162176.588024, train/accuracy=0.885410, train/loss=0.423546, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:35:46.239191 140239850956544 logging_writer.py:48] [333600] global_step=333600, grad_norm=4.049587726593018, loss=1.649472713470459
I0304 08:36:29.172965 140239842563840 logging_writer.py:48] [333700] global_step=333700, grad_norm=3.2653238773345947, loss=2.61442494392395
I0304 08:37:14.553678 140239850956544 logging_writer.py:48] [333800] global_step=333800, grad_norm=2.891955614089966, loss=1.163910150527954
I0304 08:38:00.057369 140239842563840 logging_writer.py:48] [333900] global_step=333900, grad_norm=3.1532161235809326, loss=1.2375518083572388
I0304 08:38:45.372413 140239850956544 logging_writer.py:48] [334000] global_step=334000, grad_norm=3.005520820617676, loss=1.0922917127609253
I0304 08:39:31.000583 140239842563840 logging_writer.py:48] [334100] global_step=334100, grad_norm=2.827792167663574, loss=1.0978410243988037
I0304 08:40:16.558177 140239850956544 logging_writer.py:48] [334200] global_step=334200, grad_norm=4.015199184417725, loss=3.1102664470672607
I0304 08:41:01.810959 140239842563840 logging_writer.py:48] [334300] global_step=334300, grad_norm=3.067481279373169, loss=1.0678881406784058
I0304 08:41:47.160878 140239850956544 logging_writer.py:48] [334400] global_step=334400, grad_norm=3.456223964691162, loss=2.980797290802002
I0304 08:42:32.620021 140239842563840 logging_writer.py:48] [334500] global_step=334500, grad_norm=3.12668776512146, loss=1.2105172872543335
I0304 08:42:35.403582 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:42:45.727560 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:43:16.320489 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:43:17.956593 140437341357888 submission_runner.py:411] Time since start: 162639.51s, 	Step: 334508, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.4125818610191345, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 149603.49204540253, 'total_duration': 162639.50809574127, 'accumulated_submission_time': 149603.49204540253, 'accumulated_eval_time': 12992.80593752861, 'accumulated_logging_time': 24.925283670425415}
I0304 08:43:18.022102 140239850956544 logging_writer.py:48] [334508] accumulated_eval_time=12992.805938, accumulated_logging_time=24.925284, accumulated_submission_time=149603.492045, global_step=334508, preemption_count=0, score=149603.492045, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=162639.508096, train/accuracy=0.888398, train/loss=0.412582, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:43:55.032575 140239842563840 logging_writer.py:48] [334600] global_step=334600, grad_norm=3.0090091228485107, loss=1.1531031131744385
I0304 08:44:39.780971 140239850956544 logging_writer.py:48] [334700] global_step=334700, grad_norm=3.0163168907165527, loss=1.4224560260772705
I0304 08:45:25.260757 140239842563840 logging_writer.py:48] [334800] global_step=334800, grad_norm=3.180523633956909, loss=1.1875654458999634
I0304 08:46:10.436788 140239850956544 logging_writer.py:48] [334900] global_step=334900, grad_norm=3.104402780532837, loss=1.1534727811813354
I0304 08:46:55.587544 140239842563840 logging_writer.py:48] [335000] global_step=335000, grad_norm=3.5420279502868652, loss=3.0662076473236084
I0304 08:47:40.819005 140239850956544 logging_writer.py:48] [335100] global_step=335100, grad_norm=2.978088140487671, loss=1.1248998641967773
I0304 08:48:25.931481 140239842563840 logging_writer.py:48] [335200] global_step=335200, grad_norm=3.7714831829071045, loss=3.085801601409912
I0304 08:49:11.501160 140239850956544 logging_writer.py:48] [335300] global_step=335300, grad_norm=2.9615938663482666, loss=1.5561007261276245
I0304 08:49:56.673298 140239842563840 logging_writer.py:48] [335400] global_step=335400, grad_norm=3.0594160556793213, loss=1.2698099613189697
I0304 08:50:18.157082 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:50:28.558506 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:50:58.229186 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:50:59.855133 140437341357888 submission_runner.py:411] Time since start: 163101.41s, 	Step: 335449, 	{'train/accuracy': 0.8907030820846558, 'train/loss': 0.40665367245674133, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 150023.56773352623, 'total_duration': 163101.40661740303, 'accumulated_submission_time': 150023.56773352623, 'accumulated_eval_time': 13034.503975629807, 'accumulated_logging_time': 24.99918556213379}
I0304 08:50:59.939014 140239850956544 logging_writer.py:48] [335449] accumulated_eval_time=13034.503976, accumulated_logging_time=24.999186, accumulated_submission_time=150023.567734, global_step=335449, preemption_count=0, score=150023.567734, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=163101.406617, train/accuracy=0.890703, train/loss=0.406654, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:51:20.554053 140239842563840 logging_writer.py:48] [335500] global_step=335500, grad_norm=3.186551094055176, loss=1.252915620803833
I0304 08:52:04.333246 140239850956544 logging_writer.py:48] [335600] global_step=335600, grad_norm=3.040989637374878, loss=1.1539604663848877
I0304 08:52:49.485222 140239842563840 logging_writer.py:48] [335700] global_step=335700, grad_norm=2.872272491455078, loss=1.998542308807373
I0304 08:53:34.983456 140239850956544 logging_writer.py:48] [335800] global_step=335800, grad_norm=3.2348711490631104, loss=1.2382982969284058
I0304 08:54:20.274012 140239842563840 logging_writer.py:48] [335900] global_step=335900, grad_norm=3.2246131896972656, loss=2.9273464679718018
I0304 08:55:05.535176 140239850956544 logging_writer.py:48] [336000] global_step=336000, grad_norm=3.4574429988861084, loss=1.2030346393585205
I0304 08:55:50.640138 140239842563840 logging_writer.py:48] [336100] global_step=336100, grad_norm=2.9798519611358643, loss=1.3009471893310547
I0304 08:56:36.058885 140239850956544 logging_writer.py:48] [336200] global_step=336200, grad_norm=3.7033300399780273, loss=3.268148422241211
I0304 08:57:21.266628 140239842563840 logging_writer.py:48] [336300] global_step=336300, grad_norm=3.126966714859009, loss=2.354531764984131
I0304 08:58:00.239906 140437341357888 spec.py:321] Evaluating on the training split.
I0304 08:58:11.157510 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 08:58:43.397808 140437341357888 spec.py:349] Evaluating on the test split.
I0304 08:58:45.015904 140437341357888 submission_runner.py:411] Time since start: 163566.57s, 	Step: 336388, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.42055708169937134, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 150443.80747699738, 'total_duration': 163566.56737589836, 'accumulated_submission_time': 150443.80747699738, 'accumulated_eval_time': 13079.279954433441, 'accumulated_logging_time': 25.093581438064575}
I0304 08:58:45.101353 140239850956544 logging_writer.py:48] [336388] accumulated_eval_time=13079.279954, accumulated_logging_time=25.093581, accumulated_submission_time=150443.807477, global_step=336388, preemption_count=0, score=150443.807477, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=163566.567376, train/accuracy=0.886738, train/loss=0.420557, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 08:58:50.252629 140239842563840 logging_writer.py:48] [336400] global_step=336400, grad_norm=3.0038435459136963, loss=1.3543249368667603
I0304 08:59:31.838892 140239850956544 logging_writer.py:48] [336500] global_step=336500, grad_norm=2.950495719909668, loss=2.456956386566162
I0304 09:00:17.208029 140239842563840 logging_writer.py:48] [336600] global_step=336600, grad_norm=3.142183780670166, loss=1.175842046737671
I0304 09:01:02.947338 140239850956544 logging_writer.py:48] [336700] global_step=336700, grad_norm=3.334078073501587, loss=1.9771645069122314
I0304 09:01:47.995953 140239842563840 logging_writer.py:48] [336800] global_step=336800, grad_norm=3.3300814628601074, loss=1.1139163970947266
I0304 09:02:33.242627 140239850956544 logging_writer.py:48] [336900] global_step=336900, grad_norm=3.0327908992767334, loss=1.3978997468948364
I0304 09:03:18.591360 140239842563840 logging_writer.py:48] [337000] global_step=337000, grad_norm=3.3138341903686523, loss=1.1105221509933472
I0304 09:04:03.864171 140239850956544 logging_writer.py:48] [337100] global_step=337100, grad_norm=3.133734941482544, loss=1.0792207717895508
I0304 09:04:49.346699 140239842563840 logging_writer.py:48] [337200] global_step=337200, grad_norm=2.8876307010650635, loss=2.0607166290283203
I0304 09:05:34.707819 140239850956544 logging_writer.py:48] [337300] global_step=337300, grad_norm=3.0064949989318848, loss=1.207308292388916
I0304 09:05:45.206871 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:05:55.969366 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 09:06:23.574759 140437341357888 spec.py:349] Evaluating on the test split.
I0304 09:06:25.202806 140437341357888 submission_runner.py:411] Time since start: 164026.75s, 	Step: 337325, 	{'train/accuracy': 0.8875390291213989, 'train/loss': 0.4201224744319916, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 150863.85061359406, 'total_duration': 164026.75428032875, 'accumulated_submission_time': 150863.85061359406, 'accumulated_eval_time': 13119.275871992111, 'accumulated_logging_time': 25.190476655960083}
I0304 09:06:25.286798 140239842563840 logging_writer.py:48] [337325] accumulated_eval_time=13119.275872, accumulated_logging_time=25.190477, accumulated_submission_time=150863.850614, global_step=337325, preemption_count=0, score=150863.850614, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=164026.754280, train/accuracy=0.887539, train/loss=0.420122, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 09:06:56.074512 140239850956544 logging_writer.py:48] [337400] global_step=337400, grad_norm=2.9327828884124756, loss=2.208913803100586
I0304 09:07:41.416604 140239842563840 logging_writer.py:48] [337500] global_step=337500, grad_norm=2.9845223426818848, loss=2.2692995071411133
I0304 09:08:26.718437 140239850956544 logging_writer.py:48] [337600] global_step=337600, grad_norm=3.1630802154541016, loss=2.7795021533966064
I0304 09:09:12.107508 140239842563840 logging_writer.py:48] [337700] global_step=337700, grad_norm=3.5747082233428955, loss=3.1884918212890625
I0304 09:09:57.856237 140239850956544 logging_writer.py:48] [337800] global_step=337800, grad_norm=3.032885789871216, loss=2.242109775543213
I0304 09:10:43.190540 140239842563840 logging_writer.py:48] [337900] global_step=337900, grad_norm=3.0511224269866943, loss=2.4903452396392822
I0304 09:11:28.494516 140239850956544 logging_writer.py:48] [338000] global_step=338000, grad_norm=3.200692892074585, loss=2.6592342853546143
I0304 09:12:14.447465 140239842563840 logging_writer.py:48] [338100] global_step=338100, grad_norm=3.157275676727295, loss=2.988431453704834
I0304 09:12:59.922409 140239850956544 logging_writer.py:48] [338200] global_step=338200, grad_norm=3.0321385860443115, loss=1.7290654182434082
I0304 09:13:25.435790 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:13:35.876225 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 09:14:16.164338 140437341357888 spec.py:349] Evaluating on the test split.
I0304 09:14:17.771934 140437341357888 submission_runner.py:411] Time since start: 164499.32s, 	Step: 338258, 	{'train/accuracy': 0.8876367211341858, 'train/loss': 0.41452014446258545, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 151283.9351758957, 'total_duration': 164499.32343387604, 'accumulated_submission_time': 151283.9351758957, 'accumulated_eval_time': 13171.61202454567, 'accumulated_logging_time': 25.28453826904297}
I0304 09:14:17.841068 140239842563840 logging_writer.py:48] [338258] accumulated_eval_time=13171.612025, accumulated_logging_time=25.284538, accumulated_submission_time=151283.935176, global_step=338258, preemption_count=0, score=151283.935176, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=164499.323434, train/accuracy=0.887637, train/loss=0.414520, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 09:14:34.871462 140239850956544 logging_writer.py:48] [338300] global_step=338300, grad_norm=3.8855926990509033, loss=3.2406506538391113
I0304 09:15:17.026492 140239842563840 logging_writer.py:48] [338400] global_step=338400, grad_norm=2.9844326972961426, loss=1.1700098514556885
I0304 09:16:02.458459 140239850956544 logging_writer.py:48] [338500] global_step=338500, grad_norm=3.0758512020111084, loss=2.185141086578369
I0304 09:16:47.905737 140239842563840 logging_writer.py:48] [338600] global_step=338600, grad_norm=3.3669023513793945, loss=2.719481945037842
I0304 09:17:33.081975 140239850956544 logging_writer.py:48] [338700] global_step=338700, grad_norm=3.1601240634918213, loss=1.1918836832046509
I0304 09:18:18.428053 140239842563840 logging_writer.py:48] [338800] global_step=338800, grad_norm=2.838663101196289, loss=1.1607602834701538
I0304 09:19:03.968413 140239850956544 logging_writer.py:48] [338900] global_step=338900, grad_norm=3.3870902061462402, loss=1.0960757732391357
I0304 09:19:49.121611 140239842563840 logging_writer.py:48] [339000] global_step=339000, grad_norm=2.9812028408050537, loss=1.3722801208496094
I0304 09:20:35.080844 140239850956544 logging_writer.py:48] [339100] global_step=339100, grad_norm=3.400686502456665, loss=3.2082884311676025
I0304 09:21:17.928150 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:21:28.311986 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 09:21:51.004250 140437341357888 spec.py:349] Evaluating on the test split.
I0304 09:21:52.624143 140437341357888 submission_runner.py:411] Time since start: 164954.18s, 	Step: 339196, 	{'train/accuracy': 0.8885351419448853, 'train/loss': 0.4120396077632904, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 151703.95897865295, 'total_duration': 164954.1756284237, 'accumulated_submission_time': 151703.95897865295, 'accumulated_eval_time': 13206.307997703552, 'accumulated_logging_time': 25.36584448814392}
I0304 09:21:52.709541 140239842563840 logging_writer.py:48] [339196] accumulated_eval_time=13206.307998, accumulated_logging_time=25.365844, accumulated_submission_time=151703.958979, global_step=339196, preemption_count=0, score=151703.958979, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=164954.175628, train/accuracy=0.888535, train/loss=0.412040, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 09:21:54.721843 140239850956544 logging_writer.py:48] [339200] global_step=339200, grad_norm=3.133251190185547, loss=1.1143279075622559
I0304 09:22:36.898430 140239842563840 logging_writer.py:48] [339300] global_step=339300, grad_norm=3.4260170459747314, loss=3.0057106018066406
I0304 09:23:22.531414 140239850956544 logging_writer.py:48] [339400] global_step=339400, grad_norm=3.596992015838623, loss=3.271111249923706
I0304 09:24:08.141689 140239842563840 logging_writer.py:48] [339500] global_step=339500, grad_norm=3.3248112201690674, loss=1.1477078199386597
I0304 09:24:53.569290 140239850956544 logging_writer.py:48] [339600] global_step=339600, grad_norm=3.258622884750366, loss=1.263297438621521
I0304 09:25:38.921415 140239842563840 logging_writer.py:48] [339700] global_step=339700, grad_norm=3.142119884490967, loss=1.1137672662734985
I0304 09:26:24.333010 140239850956544 logging_writer.py:48] [339800] global_step=339800, grad_norm=5.133497714996338, loss=3.3313894271850586
I0304 09:27:09.905369 140239842563840 logging_writer.py:48] [339900] global_step=339900, grad_norm=3.16670298576355, loss=2.4212772846221924
I0304 09:27:55.270571 140239850956544 logging_writer.py:48] [340000] global_step=340000, grad_norm=3.2369771003723145, loss=1.1549021005630493
I0304 09:28:40.570626 140239842563840 logging_writer.py:48] [340100] global_step=340100, grad_norm=3.050776958465576, loss=1.1065677404403687
I0304 09:28:52.988842 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:29:04.104845 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 09:29:31.705833 140437341357888 spec.py:349] Evaluating on the test split.
I0304 09:29:33.325484 140437341357888 submission_runner.py:411] Time since start: 165414.88s, 	Step: 340129, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.42021432518959045, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 152124.17705917358, 'total_duration': 165414.87696027756, 'accumulated_submission_time': 152124.17705917358, 'accumulated_eval_time': 13246.64460015297, 'accumulated_logging_time': 25.46287226676941}
I0304 09:29:33.417660 140239850956544 logging_writer.py:48] [340129] accumulated_eval_time=13246.644600, accumulated_logging_time=25.462872, accumulated_submission_time=152124.177059, global_step=340129, preemption_count=0, score=152124.177059, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=165414.876960, train/accuracy=0.887383, train/loss=0.420214, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 09:30:02.362888 140239842563840 logging_writer.py:48] [340200] global_step=340200, grad_norm=3.1479437351226807, loss=2.4184343814849854
I0304 09:30:47.771742 140239850956544 logging_writer.py:48] [340300] global_step=340300, grad_norm=3.256758213043213, loss=1.1989102363586426
I0304 09:31:33.516003 140239842563840 logging_writer.py:48] [340400] global_step=340400, grad_norm=2.7183163166046143, loss=1.0008445978164673
I0304 09:32:19.063273 140239850956544 logging_writer.py:48] [340500] global_step=340500, grad_norm=3.132922887802124, loss=1.1266919374465942
I0304 09:33:04.716551 140239842563840 logging_writer.py:48] [340600] global_step=340600, grad_norm=3.0053772926330566, loss=1.1718839406967163
I0304 09:33:50.101274 140239850956544 logging_writer.py:48] [340700] global_step=340700, grad_norm=3.1880578994750977, loss=1.213579773902893
I0304 09:34:35.545285 140239842563840 logging_writer.py:48] [340800] global_step=340800, grad_norm=3.0507264137268066, loss=2.4691269397735596
I0304 09:35:21.167380 140239850956544 logging_writer.py:48] [340900] global_step=340900, grad_norm=2.7765917778015137, loss=1.2625609636306763
I0304 09:36:06.545648 140239842563840 logging_writer.py:48] [341000] global_step=341000, grad_norm=3.138896942138672, loss=1.6753222942352295
I0304 09:36:33.655664 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:36:44.043000 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 09:37:14.836440 140437341357888 spec.py:349] Evaluating on the test split.
I0304 09:37:16.490473 140437341357888 submission_runner.py:411] Time since start: 165878.04s, 	Step: 341061, 	{'train/accuracy': 0.8905078172683716, 'train/loss': 0.40985074639320374, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 152544.35502910614, 'total_duration': 165878.04197120667, 'accumulated_submission_time': 152544.35502910614, 'accumulated_eval_time': 13289.47941160202, 'accumulated_logging_time': 25.565407514572144}
I0304 09:37:16.558125 140239850956544 logging_writer.py:48] [341061] accumulated_eval_time=13289.479412, accumulated_logging_time=25.565408, accumulated_submission_time=152544.355029, global_step=341061, preemption_count=0, score=152544.355029, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=165878.041971, train/accuracy=0.890508, train/loss=0.409851, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 09:37:32.402901 140239842563840 logging_writer.py:48] [341100] global_step=341100, grad_norm=3.7663662433624268, loss=1.2050561904907227
I0304 09:38:14.608880 140239850956544 logging_writer.py:48] [341200] global_step=341200, grad_norm=2.9654006958007812, loss=1.5742003917694092
I0304 09:38:59.531142 140239842563840 logging_writer.py:48] [341300] global_step=341300, grad_norm=2.897329330444336, loss=1.1097849607467651
I0304 09:39:45.041478 140239850956544 logging_writer.py:48] [341400] global_step=341400, grad_norm=3.3273935317993164, loss=2.835110902786255
I0304 09:40:30.219738 140239842563840 logging_writer.py:48] [341500] global_step=341500, grad_norm=3.210407018661499, loss=1.212761402130127
I0304 09:41:15.881628 140239850956544 logging_writer.py:48] [341600] global_step=341600, grad_norm=3.1080644130706787, loss=1.137010097503662
I0304 09:42:00.983896 140239842563840 logging_writer.py:48] [341700] global_step=341700, grad_norm=3.0315372943878174, loss=1.3640432357788086
I0304 09:42:45.650516 140239850956544 logging_writer.py:48] [341800] global_step=341800, grad_norm=3.6394741535186768, loss=2.902562141418457
I0304 09:43:30.774078 140239842563840 logging_writer.py:48] [341900] global_step=341900, grad_norm=3.2896687984466553, loss=1.069496512413025
I0304 09:44:15.994377 140239850956544 logging_writer.py:48] [342000] global_step=342000, grad_norm=3.109070062637329, loss=1.1330554485321045
I0304 09:44:16.592219 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:44:27.127060 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 09:44:47.830664 140437341357888 spec.py:349] Evaluating on the test split.
I0304 09:44:49.451896 140437341357888 submission_runner.py:411] Time since start: 166331.00s, 	Step: 342003, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.41863876581192017, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 152964.3291182518, 'total_duration': 166331.00338292122, 'accumulated_submission_time': 152964.3291182518, 'accumulated_eval_time': 13322.339082717896, 'accumulated_logging_time': 25.64190411567688}
I0304 09:44:49.535603 140239842563840 logging_writer.py:48] [342003] accumulated_eval_time=13322.339083, accumulated_logging_time=25.641904, accumulated_submission_time=152964.329118, global_step=342003, preemption_count=0, score=152964.329118, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=166331.003383, train/accuracy=0.887227, train/loss=0.418639, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 09:45:29.928524 140239850956544 logging_writer.py:48] [342100] global_step=342100, grad_norm=3.0454041957855225, loss=1.165548324584961
I0304 09:46:15.101737 140239842563840 logging_writer.py:48] [342200] global_step=342200, grad_norm=3.068540573120117, loss=0.9806492924690247
I0304 09:47:00.483454 140239850956544 logging_writer.py:48] [342300] global_step=342300, grad_norm=2.9251270294189453, loss=1.0819519758224487
I0304 09:47:45.754828 140239842563840 logging_writer.py:48] [342400] global_step=342400, grad_norm=3.4346141815185547, loss=2.6091971397399902
I0304 09:48:30.859780 140239850956544 logging_writer.py:48] [342500] global_step=342500, grad_norm=3.247340202331543, loss=1.1446537971496582
I0304 09:49:16.145808 140239842563840 logging_writer.py:48] [342600] global_step=342600, grad_norm=3.44640851020813, loss=2.148885726928711
I0304 09:50:01.448738 140239850956544 logging_writer.py:48] [342700] global_step=342700, grad_norm=3.0735511779785156, loss=2.5538089275360107
I0304 09:50:47.050885 140239842563840 logging_writer.py:48] [342800] global_step=342800, grad_norm=2.8825738430023193, loss=2.2863967418670654
I0304 09:51:32.697512 140239850956544 logging_writer.py:48] [342900] global_step=342900, grad_norm=2.9786953926086426, loss=1.1238282918930054
I0304 09:51:49.600959 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:52:00.089469 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 09:52:27.757281 140437341357888 spec.py:349] Evaluating on the test split.
I0304 09:52:29.374701 140437341357888 submission_runner.py:411] Time since start: 166790.93s, 	Step: 342939, 	{'train/accuracy': 0.8864062428474426, 'train/loss': 0.4191470742225647, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 153384.33371186256, 'total_duration': 166790.92618012428, 'accumulated_submission_time': 153384.33371186256, 'accumulated_eval_time': 13362.112790107727, 'accumulated_logging_time': 25.7352511882782}
I0304 09:52:29.458997 140239842563840 logging_writer.py:48] [342939] accumulated_eval_time=13362.112790, accumulated_logging_time=25.735251, accumulated_submission_time=153384.333712, global_step=342939, preemption_count=0, score=153384.333712, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=166790.926180, train/accuracy=0.886406, train/loss=0.419147, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 09:52:54.028221 140239850956544 logging_writer.py:48] [343000] global_step=343000, grad_norm=3.0409085750579834, loss=2.5001964569091797
I0304 09:53:38.911751 140239842563840 logging_writer.py:48] [343100] global_step=343100, grad_norm=3.149653196334839, loss=2.3375117778778076
I0304 09:54:24.334222 140239850956544 logging_writer.py:48] [343200] global_step=343200, grad_norm=3.5498924255371094, loss=1.1039698123931885
I0304 09:55:09.721506 140239842563840 logging_writer.py:48] [343300] global_step=343300, grad_norm=3.032973289489746, loss=1.16232168674469
I0304 09:55:54.779180 140239850956544 logging_writer.py:48] [343400] global_step=343400, grad_norm=3.1869406700134277, loss=2.809427261352539
I0304 09:56:40.244069 140239842563840 logging_writer.py:48] [343500] global_step=343500, grad_norm=3.0654454231262207, loss=1.116829752922058
I0304 09:57:25.464167 140239850956544 logging_writer.py:48] [343600] global_step=343600, grad_norm=2.727234125137329, loss=1.5484461784362793
I0304 09:58:10.951637 140239842563840 logging_writer.py:48] [343700] global_step=343700, grad_norm=2.923551321029663, loss=1.6235790252685547
I0304 09:58:56.148513 140239850956544 logging_writer.py:48] [343800] global_step=343800, grad_norm=3.113558053970337, loss=1.1118195056915283
I0304 09:59:29.688284 140437341357888 spec.py:321] Evaluating on the training split.
I0304 09:59:40.011914 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:00:18.507410 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:00:20.134437 140437341357888 submission_runner.py:411] Time since start: 167261.69s, 	Step: 343876, 	{'train/accuracy': 0.8897656202316284, 'train/loss': 0.41292402148246765, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 153804.50244569778, 'total_duration': 167261.68593525887, 'accumulated_submission_time': 153804.50244569778, 'accumulated_eval_time': 13412.558959245682, 'accumulated_logging_time': 25.82959008216858}
I0304 10:00:20.203670 140239842563840 logging_writer.py:48] [343876] accumulated_eval_time=13412.558959, accumulated_logging_time=25.829590, accumulated_submission_time=153804.502446, global_step=343876, preemption_count=0, score=153804.502446, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=167261.685935, train/accuracy=0.889766, train/loss=0.412924, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:00:30.101523 140239850956544 logging_writer.py:48] [343900] global_step=343900, grad_norm=2.992662191390991, loss=1.2947229146957397
I0304 10:01:11.028105 140239842563840 logging_writer.py:48] [344000] global_step=344000, grad_norm=3.372079372406006, loss=1.057786464691162
I0304 10:01:56.494317 140239850956544 logging_writer.py:48] [344100] global_step=344100, grad_norm=3.8285510540008545, loss=2.884155035018921
I0304 10:02:42.191144 140239842563840 logging_writer.py:48] [344200] global_step=344200, grad_norm=3.0718038082122803, loss=2.4877052307128906
I0304 10:03:27.276982 140239850956544 logging_writer.py:48] [344300] global_step=344300, grad_norm=3.1352057456970215, loss=1.1357483863830566
I0304 10:04:12.549534 140239842563840 logging_writer.py:48] [344400] global_step=344400, grad_norm=3.1075351238250732, loss=1.0745552778244019
I0304 10:04:57.641107 140239850956544 logging_writer.py:48] [344500] global_step=344500, grad_norm=3.229236125946045, loss=1.105395793914795
I0304 10:05:43.103330 140239842563840 logging_writer.py:48] [344600] global_step=344600, grad_norm=3.0294008255004883, loss=2.6699881553649902
I0304 10:06:28.188493 140239850956544 logging_writer.py:48] [344700] global_step=344700, grad_norm=3.20359206199646, loss=1.0703591108322144
I0304 10:07:13.781849 140239842563840 logging_writer.py:48] [344800] global_step=344800, grad_norm=3.5911028385162354, loss=3.1424062252044678
I0304 10:07:20.176779 140437341357888 spec.py:321] Evaluating on the training split.
I0304 10:07:30.557808 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:07:56.170741 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:07:57.808991 140437341357888 submission_runner.py:411] Time since start: 167719.36s, 	Step: 344816, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.41348201036453247, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 154224.41515517235, 'total_duration': 167719.3604798317, 'accumulated_submission_time': 154224.41515517235, 'accumulated_eval_time': 13450.191165685654, 'accumulated_logging_time': 25.908400774002075}
I0304 10:07:57.894980 140239850956544 logging_writer.py:48] [344816] accumulated_eval_time=13450.191166, accumulated_logging_time=25.908401, accumulated_submission_time=154224.415155, global_step=344816, preemption_count=0, score=154224.415155, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=167719.360480, train/accuracy=0.888066, train/loss=0.413482, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:08:32.593069 140239842563840 logging_writer.py:48] [344900] global_step=344900, grad_norm=3.310443162918091, loss=1.1848626136779785
I0304 10:09:17.643906 140239850956544 logging_writer.py:48] [345000] global_step=345000, grad_norm=3.6079044342041016, loss=3.0694823265075684
I0304 10:10:02.996578 140239842563840 logging_writer.py:48] [345100] global_step=345100, grad_norm=2.9311821460723877, loss=1.4491450786590576
I0304 10:10:48.377748 140239850956544 logging_writer.py:48] [345200] global_step=345200, grad_norm=3.1179168224334717, loss=1.1577988862991333
I0304 10:11:33.783936 140239842563840 logging_writer.py:48] [345300] global_step=345300, grad_norm=4.40308141708374, loss=1.102536678314209
I0304 10:12:18.851970 140239850956544 logging_writer.py:48] [345400] global_step=345400, grad_norm=2.9861526489257812, loss=2.524916648864746
I0304 10:13:04.192706 140239842563840 logging_writer.py:48] [345500] global_step=345500, grad_norm=3.2222330570220947, loss=1.207940697669983
I0304 10:13:49.378347 140239850956544 logging_writer.py:48] [345600] global_step=345600, grad_norm=2.976712703704834, loss=1.010033130645752
I0304 10:14:34.677875 140239842563840 logging_writer.py:48] [345700] global_step=345700, grad_norm=2.78330135345459, loss=1.877362608909607
I0304 10:14:57.830661 140437341357888 spec.py:321] Evaluating on the training split.
I0304 10:15:08.680799 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:15:43.838548 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:15:45.470726 140437341357888 submission_runner.py:411] Time since start: 168187.02s, 	Step: 345753, 	{'train/accuracy': 0.8886132836341858, 'train/loss': 0.4115453362464905, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 154644.2866268158, 'total_duration': 168187.02220201492, 'accumulated_submission_time': 154644.2866268158, 'accumulated_eval_time': 13497.831232309341, 'accumulated_logging_time': 26.00806427001953}
I0304 10:15:45.552646 140239850956544 logging_writer.py:48] [345753] accumulated_eval_time=13497.831232, accumulated_logging_time=26.008064, accumulated_submission_time=154644.286627, global_step=345753, preemption_count=0, score=154644.286627, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=168187.022202, train/accuracy=0.888613, train/loss=0.411545, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:16:04.568904 140239842563840 logging_writer.py:48] [345800] global_step=345800, grad_norm=2.9267590045928955, loss=1.1444578170776367
I0304 10:16:48.420957 140239850956544 logging_writer.py:48] [345900] global_step=345900, grad_norm=2.943185567855835, loss=1.1806505918502808
I0304 10:17:33.958225 140239842563840 logging_writer.py:48] [346000] global_step=346000, grad_norm=3.01749849319458, loss=1.2049391269683838
I0304 10:18:19.305063 140239850956544 logging_writer.py:48] [346100] global_step=346100, grad_norm=3.0049614906311035, loss=1.192943811416626
I0304 10:19:04.630472 140239842563840 logging_writer.py:48] [346200] global_step=346200, grad_norm=2.8594982624053955, loss=1.02647066116333
I0304 10:19:49.996424 140239850956544 logging_writer.py:48] [346300] global_step=346300, grad_norm=3.397908926010132, loss=2.867676019668579
I0304 10:20:35.179246 140239842563840 logging_writer.py:48] [346400] global_step=346400, grad_norm=2.824871778488159, loss=1.8965904712677002
I0304 10:21:20.560034 140239850956544 logging_writer.py:48] [346500] global_step=346500, grad_norm=3.11011004447937, loss=1.130021333694458
I0304 10:22:06.264469 140239842563840 logging_writer.py:48] [346600] global_step=346600, grad_norm=3.7971439361572266, loss=3.199026346206665
I0304 10:22:45.721103 140437341357888 spec.py:321] Evaluating on the training split.
I0304 10:22:56.098561 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:23:21.550365 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:23:23.174462 140437341357888 submission_runner.py:411] Time since start: 168644.73s, 	Step: 346689, 	{'train/accuracy': 0.88720703125, 'train/loss': 0.4173647165298462, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 155064.39183330536, 'total_duration': 168644.72593283653, 'accumulated_submission_time': 155064.39183330536, 'accumulated_eval_time': 13535.284557580948, 'accumulated_logging_time': 26.102439403533936}
I0304 10:23:23.289574 140239850956544 logging_writer.py:48] [346689] accumulated_eval_time=13535.284558, accumulated_logging_time=26.102439, accumulated_submission_time=155064.391833, global_step=346689, preemption_count=0, score=155064.391833, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=168644.725933, train/accuracy=0.887207, train/loss=0.417365, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:23:28.064321 140239842563840 logging_writer.py:48] [346700] global_step=346700, grad_norm=3.067659854888916, loss=1.1489180326461792
I0304 10:24:10.221521 140239850956544 logging_writer.py:48] [346800] global_step=346800, grad_norm=3.324385404586792, loss=1.1936758756637573
I0304 10:24:55.166541 140239842563840 logging_writer.py:48] [346900] global_step=346900, grad_norm=3.059415340423584, loss=1.1906321048736572
I0304 10:25:40.466380 140239850956544 logging_writer.py:48] [347000] global_step=347000, grad_norm=3.462373733520508, loss=3.080989360809326
I0304 10:26:25.728206 140239842563840 logging_writer.py:48] [347100] global_step=347100, grad_norm=3.8159682750701904, loss=3.178631544113159
I0304 10:27:11.146069 140239850956544 logging_writer.py:48] [347200] global_step=347200, grad_norm=3.1101722717285156, loss=1.740291953086853
I0304 10:27:56.174246 140239842563840 logging_writer.py:48] [347300] global_step=347300, grad_norm=2.9511680603027344, loss=1.0542268753051758
I0304 10:28:41.385270 140239850956544 logging_writer.py:48] [347400] global_step=347400, grad_norm=2.877253293991089, loss=1.767608404159546
I0304 10:29:26.542225 140239842563840 logging_writer.py:48] [347500] global_step=347500, grad_norm=2.949821949005127, loss=1.0981311798095703
I0304 10:30:11.777054 140239850956544 logging_writer.py:48] [347600] global_step=347600, grad_norm=2.9983654022216797, loss=1.0736297369003296
I0304 10:30:23.349808 140437341357888 spec.py:321] Evaluating on the training split.
I0304 10:30:33.910702 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:31:05.948433 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:31:07.596721 140437341357888 submission_runner.py:411] Time since start: 169109.15s, 	Step: 347627, 	{'train/accuracy': 0.8901757597923279, 'train/loss': 0.4099457561969757, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 155484.39171671867, 'total_duration': 169109.14815998077, 'accumulated_submission_time': 155484.39171671867, 'accumulated_eval_time': 13579.531408786774, 'accumulated_logging_time': 26.227181434631348}
I0304 10:31:07.731774 140239842563840 logging_writer.py:48] [347627] accumulated_eval_time=13579.531409, accumulated_logging_time=26.227181, accumulated_submission_time=155484.391717, global_step=347627, preemption_count=0, score=155484.391717, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=169109.148160, train/accuracy=0.890176, train/loss=0.409946, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:31:37.060142 140239850956544 logging_writer.py:48] [347700] global_step=347700, grad_norm=3.4380877017974854, loss=2.8873400688171387
I0304 10:32:21.418657 140239842563840 logging_writer.py:48] [347800] global_step=347800, grad_norm=3.908217668533325, loss=3.199155807495117
I0304 10:33:07.739420 140239850956544 logging_writer.py:48] [347900] global_step=347900, grad_norm=3.0735645294189453, loss=1.0988329648971558
I0304 10:33:53.511095 140239842563840 logging_writer.py:48] [348000] global_step=348000, grad_norm=3.0423784255981445, loss=1.243233323097229
I0304 10:34:38.881069 140239850956544 logging_writer.py:48] [348100] global_step=348100, grad_norm=3.856328010559082, loss=3.3160171508789062
I0304 10:35:24.367564 140239842563840 logging_writer.py:48] [348200] global_step=348200, grad_norm=3.010998487472534, loss=1.193304419517517
I0304 10:36:09.937290 140239850956544 logging_writer.py:48] [348300] global_step=348300, grad_norm=3.313183546066284, loss=1.0826319456100464
I0304 10:36:55.427344 140239842563840 logging_writer.py:48] [348400] global_step=348400, grad_norm=3.1592442989349365, loss=1.0684760808944702
I0304 10:37:40.836282 140239850956544 logging_writer.py:48] [348500] global_step=348500, grad_norm=3.1351277828216553, loss=1.1859111785888672
I0304 10:38:07.784560 140437341357888 spec.py:321] Evaluating on the training split.
I0304 10:38:18.039829 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:38:45.708003 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:38:47.324686 140437341357888 submission_runner.py:411] Time since start: 169568.88s, 	Step: 348561, 	{'train/accuracy': 0.8900585770606995, 'train/loss': 0.4157879054546356, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 155904.38059473038, 'total_duration': 169568.8761703968, 'accumulated_submission_time': 155904.38059473038, 'accumulated_eval_time': 13619.071528434753, 'accumulated_logging_time': 26.375840425491333}
I0304 10:38:47.410702 140239842563840 logging_writer.py:48] [348561] accumulated_eval_time=13619.071528, accumulated_logging_time=26.375840, accumulated_submission_time=155904.380595, global_step=348561, preemption_count=0, score=155904.380595, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=169568.876170, train/accuracy=0.890059, train/loss=0.415788, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:39:03.401699 140239850956544 logging_writer.py:48] [348600] global_step=348600, grad_norm=4.037614345550537, loss=1.185173511505127
I0304 10:39:47.154858 140239842563840 logging_writer.py:48] [348700] global_step=348700, grad_norm=3.0523195266723633, loss=1.1216850280761719
I0304 10:40:32.508514 140239850956544 logging_writer.py:48] [348800] global_step=348800, grad_norm=3.0773684978485107, loss=1.1503276824951172
I0304 10:41:17.620688 140239842563840 logging_writer.py:48] [348900] global_step=348900, grad_norm=3.17531418800354, loss=1.161569595336914
I0304 10:42:02.903594 140239850956544 logging_writer.py:48] [349000] global_step=349000, grad_norm=3.0728912353515625, loss=1.5446999073028564
I0304 10:42:48.606426 140239842563840 logging_writer.py:48] [349100] global_step=349100, grad_norm=3.145282745361328, loss=1.7527250051498413
I0304 10:43:34.019387 140239850956544 logging_writer.py:48] [349200] global_step=349200, grad_norm=3.5534112453460693, loss=1.1419408321380615
I0304 10:44:19.241318 140239842563840 logging_writer.py:48] [349300] global_step=349300, grad_norm=2.747373104095459, loss=1.473846435546875
I0304 10:45:05.003891 140239850956544 logging_writer.py:48] [349400] global_step=349400, grad_norm=3.0555694103240967, loss=1.639876365661621
I0304 10:45:47.660415 140437341357888 spec.py:321] Evaluating on the training split.
I0304 10:45:58.349136 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:46:36.691336 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:46:38.304879 140437341357888 submission_runner.py:411] Time since start: 170039.86s, 	Step: 349496, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.4083418846130371, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 156324.56995940208, 'total_duration': 170039.8563761711, 'accumulated_submission_time': 156324.56995940208, 'accumulated_eval_time': 13669.715999364853, 'accumulated_logging_time': 26.47144365310669}
I0304 10:46:38.374934 140239842563840 logging_writer.py:48] [349496] accumulated_eval_time=13669.715999, accumulated_logging_time=26.471444, accumulated_submission_time=156324.569959, global_step=349496, preemption_count=0, score=156324.569959, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=170039.856376, train/accuracy=0.888906, train/loss=0.408342, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:46:40.355370 140239850956544 logging_writer.py:48] [349500] global_step=349500, grad_norm=2.9866251945495605, loss=2.202749252319336
I0304 10:47:20.941380 140239842563840 logging_writer.py:48] [349600] global_step=349600, grad_norm=2.931858539581299, loss=1.119612455368042
I0304 10:48:05.997313 140239850956544 logging_writer.py:48] [349700] global_step=349700, grad_norm=3.3592612743377686, loss=1.1065449714660645
I0304 10:48:51.326198 140239842563840 logging_writer.py:48] [349800] global_step=349800, grad_norm=3.122398853302002, loss=2.798421859741211
I0304 10:49:36.493692 140239850956544 logging_writer.py:48] [349900] global_step=349900, grad_norm=2.9284207820892334, loss=1.7730845212936401
I0304 10:50:21.947196 140239842563840 logging_writer.py:48] [350000] global_step=350000, grad_norm=2.9597394466400146, loss=1.0597940683364868
I0304 10:51:07.042660 140239850956544 logging_writer.py:48] [350100] global_step=350100, grad_norm=2.8027243614196777, loss=1.7729660272598267
I0304 10:51:51.911120 140239842563840 logging_writer.py:48] [350200] global_step=350200, grad_norm=3.2334070205688477, loss=2.9811666011810303
I0304 10:52:37.342501 140239850956544 logging_writer.py:48] [350300] global_step=350300, grad_norm=3.1006243228912354, loss=1.1359816789627075
I0304 10:53:22.776884 140239842563840 logging_writer.py:48] [350400] global_step=350400, grad_norm=3.638913869857788, loss=3.3016855716705322
I0304 10:53:38.309924 140437341357888 spec.py:321] Evaluating on the training split.
I0304 10:53:48.724704 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 10:54:14.441435 140437341357888 spec.py:349] Evaluating on the test split.
I0304 10:54:16.060744 140437341357888 submission_runner.py:411] Time since start: 170497.61s, 	Step: 350436, 	{'train/accuracy': 0.8913476467132568, 'train/loss': 0.41062843799591064, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 156744.44487810135, 'total_duration': 170497.61222934723, 'accumulated_submission_time': 156744.44487810135, 'accumulated_eval_time': 13707.466798067093, 'accumulated_logging_time': 26.550642251968384}
I0304 10:54:16.147698 140239850956544 logging_writer.py:48] [350436] accumulated_eval_time=13707.466798, accumulated_logging_time=26.550642, accumulated_submission_time=156744.444878, global_step=350436, preemption_count=0, score=156744.444878, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=170497.612229, train/accuracy=0.891348, train/loss=0.410628, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 10:54:42.244218 140239842563840 logging_writer.py:48] [350500] global_step=350500, grad_norm=3.5151777267456055, loss=2.9521684646606445
I0304 10:55:27.929380 140239850956544 logging_writer.py:48] [350600] global_step=350600, grad_norm=3.0162723064422607, loss=1.036799430847168
I0304 10:56:13.492429 140239842563840 logging_writer.py:48] [350700] global_step=350700, grad_norm=3.0923821926116943, loss=2.4753003120422363
I0304 10:56:59.513967 140239850956544 logging_writer.py:48] [350800] global_step=350800, grad_norm=3.822986125946045, loss=1.9415255784988403
I0304 10:57:45.175098 140239842563840 logging_writer.py:48] [350900] global_step=350900, grad_norm=3.4485042095184326, loss=2.9846436977386475
I0304 10:58:30.874748 140239850956544 logging_writer.py:48] [351000] global_step=351000, grad_norm=3.4322071075439453, loss=2.0593514442443848
I0304 10:59:16.767519 140239842563840 logging_writer.py:48] [351100] global_step=351100, grad_norm=3.060143232345581, loss=1.2887612581253052
I0304 11:00:02.343978 140239850956544 logging_writer.py:48] [351200] global_step=351200, grad_norm=2.996382236480713, loss=2.053255081176758
I0304 11:00:47.844985 140239842563840 logging_writer.py:48] [351300] global_step=351300, grad_norm=2.9034814834594727, loss=2.203684091567993
I0304 11:01:16.167387 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:01:27.721645 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:01:56.100897 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:01:57.725058 140437341357888 submission_runner.py:411] Time since start: 170959.28s, 	Step: 351364, 	{'train/accuracy': 0.8867577910423279, 'train/loss': 0.41962930560112, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 157164.40446853638, 'total_duration': 170959.27654767036, 'accumulated_submission_time': 157164.40446853638, 'accumulated_eval_time': 13749.024479150772, 'accumulated_logging_time': 26.64775824546814}
I0304 11:01:57.810033 140239850956544 logging_writer.py:48] [351364] accumulated_eval_time=13749.024479, accumulated_logging_time=26.647758, accumulated_submission_time=157164.404469, global_step=351364, preemption_count=0, score=157164.404469, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=170959.276548, train/accuracy=0.886758, train/loss=0.419629, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:02:12.483073 140239842563840 logging_writer.py:48] [351400] global_step=351400, grad_norm=2.874695301055908, loss=1.4838879108428955
I0304 11:02:55.852038 140239850956544 logging_writer.py:48] [351500] global_step=351500, grad_norm=3.8313682079315186, loss=1.5439918041229248
I0304 11:03:41.713849 140239842563840 logging_writer.py:48] [351600] global_step=351600, grad_norm=3.1004719734191895, loss=1.0445600748062134
I0304 11:04:27.431732 140239850956544 logging_writer.py:48] [351700] global_step=351700, grad_norm=3.5149729251861572, loss=3.069945812225342
I0304 11:05:12.865954 140239842563840 logging_writer.py:48] [351800] global_step=351800, grad_norm=2.962362051010132, loss=1.001810073852539
I0304 11:05:58.602019 140239850956544 logging_writer.py:48] [351900] global_step=351900, grad_norm=3.2112460136413574, loss=2.1008434295654297
I0304 11:06:44.108383 140239842563840 logging_writer.py:48] [352000] global_step=352000, grad_norm=3.059600830078125, loss=1.890629768371582
I0304 11:07:29.457303 140239850956544 logging_writer.py:48] [352100] global_step=352100, grad_norm=3.0269510746002197, loss=1.5072715282440186
I0304 11:08:15.024120 140239842563840 logging_writer.py:48] [352200] global_step=352200, grad_norm=3.0055298805236816, loss=1.5204944610595703
I0304 11:08:57.962020 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:09:08.528985 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:09:38.772969 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:09:40.407394 140437341357888 submission_runner.py:411] Time since start: 171421.96s, 	Step: 352296, 	{'train/accuracy': 0.8877148032188416, 'train/loss': 0.4151216149330139, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 157584.49403834343, 'total_duration': 171421.9588572979, 'accumulated_submission_time': 157584.49403834343, 'accumulated_eval_time': 13791.469810724258, 'accumulated_logging_time': 26.74502730369568}
I0304 11:09:40.493682 140239850956544 logging_writer.py:48] [352296] accumulated_eval_time=13791.469811, accumulated_logging_time=26.745027, accumulated_submission_time=157584.494038, global_step=352296, preemption_count=0, score=157584.494038, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=171421.958857, train/accuracy=0.887715, train/loss=0.415122, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:09:42.488621 140239842563840 logging_writer.py:48] [352300] global_step=352300, grad_norm=2.9190196990966797, loss=2.400007724761963
I0304 11:10:24.323557 140239850956544 logging_writer.py:48] [352400] global_step=352400, grad_norm=3.119731903076172, loss=2.701371669769287
I0304 11:11:09.687484 140239842563840 logging_writer.py:48] [352500] global_step=352500, grad_norm=2.818406820297241, loss=2.149724006652832
I0304 11:11:54.904120 140239850956544 logging_writer.py:48] [352600] global_step=352600, grad_norm=2.9490723609924316, loss=1.3455290794372559
I0304 11:12:40.717397 140239842563840 logging_writer.py:48] [352700] global_step=352700, grad_norm=3.1361453533172607, loss=1.199413776397705
I0304 11:13:25.862459 140239850956544 logging_writer.py:48] [352800] global_step=352800, grad_norm=3.7609546184539795, loss=2.8391213417053223
I0304 11:14:11.447822 140239842563840 logging_writer.py:48] [352900] global_step=352900, grad_norm=3.0816330909729004, loss=1.1693378686904907
I0304 11:14:56.533124 140239850956544 logging_writer.py:48] [353000] global_step=353000, grad_norm=3.348583459854126, loss=1.0763102769851685
I0304 11:15:42.099839 140239842563840 logging_writer.py:48] [353100] global_step=353100, grad_norm=2.9350175857543945, loss=1.0691683292388916
I0304 11:16:27.308012 140239850956544 logging_writer.py:48] [353200] global_step=353200, grad_norm=3.4477856159210205, loss=1.1414366960525513
I0304 11:16:40.657405 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:16:51.013074 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:17:16.994345 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:17:18.615413 140437341357888 submission_runner.py:411] Time since start: 171880.17s, 	Step: 353231, 	{'train/accuracy': 0.8877539038658142, 'train/loss': 0.4173828661441803, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 158004.5953962803, 'total_duration': 171880.16689515114, 'accumulated_submission_time': 158004.5953962803, 'accumulated_eval_time': 13829.427808046341, 'accumulated_logging_time': 26.84268879890442}
I0304 11:17:18.702306 140239842563840 logging_writer.py:48] [353231] accumulated_eval_time=13829.427808, accumulated_logging_time=26.842689, accumulated_submission_time=158004.595396, global_step=353231, preemption_count=0, score=158004.595396, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=171880.166895, train/accuracy=0.887754, train/loss=0.417383, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:17:46.572879 140239850956544 logging_writer.py:48] [353300] global_step=353300, grad_norm=3.0429189205169678, loss=1.2796728610992432
I0304 11:18:31.872267 140239842563840 logging_writer.py:48] [353400] global_step=353400, grad_norm=3.0325145721435547, loss=1.1003520488739014
I0304 11:19:17.284637 140239850956544 logging_writer.py:48] [353500] global_step=353500, grad_norm=3.0430166721343994, loss=1.1313327550888062
I0304 11:20:02.565391 140239842563840 logging_writer.py:48] [353600] global_step=353600, grad_norm=2.8889262676239014, loss=1.6657302379608154
I0304 11:20:47.890966 140239850956544 logging_writer.py:48] [353700] global_step=353700, grad_norm=2.9305639266967773, loss=1.1342467069625854
I0304 11:21:33.187793 140239842563840 logging_writer.py:48] [353800] global_step=353800, grad_norm=3.258110523223877, loss=1.1377475261688232
I0304 11:22:18.869193 140239850956544 logging_writer.py:48] [353900] global_step=353900, grad_norm=2.8559563159942627, loss=1.2697275876998901
I0304 11:23:04.336444 140239842563840 logging_writer.py:48] [354000] global_step=354000, grad_norm=4.924133777618408, loss=2.6777329444885254
I0304 11:23:50.005105 140239850956544 logging_writer.py:48] [354100] global_step=354100, grad_norm=3.1380507946014404, loss=1.1091313362121582
I0304 11:24:18.670428 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:24:29.033164 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:24:58.662841 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:25:00.295961 140437341357888 submission_runner.py:411] Time since start: 172341.85s, 	Step: 354164, 	{'train/accuracy': 0.8898046612739563, 'train/loss': 0.4126203954219818, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 158424.50338053703, 'total_duration': 172341.84744262695, 'accumulated_submission_time': 158424.50338053703, 'accumulated_eval_time': 13871.05332994461, 'accumulated_logging_time': 26.939480543136597}
I0304 11:25:00.391492 140239842563840 logging_writer.py:48] [354164] accumulated_eval_time=13871.053330, accumulated_logging_time=26.939481, accumulated_submission_time=158424.503381, global_step=354164, preemption_count=0, score=158424.503381, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=172341.847443, train/accuracy=0.889805, train/loss=0.412620, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:25:15.069945 140239850956544 logging_writer.py:48] [354200] global_step=354200, grad_norm=3.4578166007995605, loss=1.4940402507781982
I0304 11:25:58.226325 140239842563840 logging_writer.py:48] [354300] global_step=354300, grad_norm=3.218993902206421, loss=2.888914108276367
I0304 11:26:43.544642 140239850956544 logging_writer.py:48] [354400] global_step=354400, grad_norm=2.8031060695648193, loss=1.7837830781936646
I0304 11:27:29.021653 140239842563840 logging_writer.py:48] [354500] global_step=354500, grad_norm=3.413179636001587, loss=1.2365691661834717
I0304 11:28:14.184557 140239850956544 logging_writer.py:48] [354600] global_step=354600, grad_norm=3.3729569911956787, loss=3.2009847164154053
I0304 11:28:59.235658 140239842563840 logging_writer.py:48] [354700] global_step=354700, grad_norm=3.7610671520233154, loss=1.1277300119400024
I0304 11:29:44.506768 140239850956544 logging_writer.py:48] [354800] global_step=354800, grad_norm=3.005706310272217, loss=1.7137504816055298
I0304 11:30:29.576084 140239842563840 logging_writer.py:48] [354900] global_step=354900, grad_norm=3.5929486751556396, loss=2.8751626014709473
I0304 11:31:15.009252 140239850956544 logging_writer.py:48] [355000] global_step=355000, grad_norm=3.1584534645080566, loss=1.3889408111572266
I0304 11:31:59.955850 140239842563840 logging_writer.py:48] [355100] global_step=355100, grad_norm=3.1603639125823975, loss=1.1608175039291382
I0304 11:32:00.515675 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:32:10.965063 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:32:37.989675 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:32:39.611884 140437341357888 submission_runner.py:411] Time since start: 172801.16s, 	Step: 355103, 	{'train/accuracy': 0.8887304663658142, 'train/loss': 0.41556066274642944, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 158844.56557393074, 'total_duration': 172801.1633708477, 'accumulated_submission_time': 158844.56557393074, 'accumulated_eval_time': 13910.14951992035, 'accumulated_logging_time': 27.044692754745483}
I0304 11:32:39.707840 140239850956544 logging_writer.py:48] [355103] accumulated_eval_time=13910.149520, accumulated_logging_time=27.044693, accumulated_submission_time=158844.565574, global_step=355103, preemption_count=0, score=158844.565574, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=172801.163371, train/accuracy=0.888730, train/loss=0.415561, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:33:19.910508 140239842563840 logging_writer.py:48] [355200] global_step=355200, grad_norm=2.8773984909057617, loss=1.955744743347168
I0304 11:34:05.040946 140239850956544 logging_writer.py:48] [355300] global_step=355300, grad_norm=3.699129343032837, loss=2.973865032196045
I0304 11:34:50.972643 140239842563840 logging_writer.py:48] [355400] global_step=355400, grad_norm=2.9923272132873535, loss=1.2154927253723145
I0304 11:35:36.299427 140239850956544 logging_writer.py:48] [355500] global_step=355500, grad_norm=3.3083643913269043, loss=2.95837664604187
I0304 11:36:21.705336 140239842563840 logging_writer.py:48] [355600] global_step=355600, grad_norm=3.270383358001709, loss=1.1626291275024414
I0304 11:37:07.397774 140239850956544 logging_writer.py:48] [355700] global_step=355700, grad_norm=3.1695642471313477, loss=1.116098165512085
I0304 11:37:52.569234 140239842563840 logging_writer.py:48] [355800] global_step=355800, grad_norm=2.975395917892456, loss=1.1907811164855957
I0304 11:38:37.596123 140239850956544 logging_writer.py:48] [355900] global_step=355900, grad_norm=3.2422564029693604, loss=2.397976875305176
I0304 11:39:22.686386 140239842563840 logging_writer.py:48] [356000] global_step=356000, grad_norm=2.884160041809082, loss=1.096861720085144
I0304 11:39:40.000119 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:39:50.288204 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:40:21.401522 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:40:23.028245 140437341357888 submission_runner.py:411] Time since start: 173264.58s, 	Step: 356040, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.4178290069103241, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 159264.79722499847, 'total_duration': 173264.57972598076, 'accumulated_submission_time': 159264.79722499847, 'accumulated_eval_time': 13953.177673339844, 'accumulated_logging_time': 27.149667501449585}
I0304 11:40:23.117152 140239850956544 logging_writer.py:48] [356040] accumulated_eval_time=13953.177673, accumulated_logging_time=27.149668, accumulated_submission_time=159264.797225, global_step=356040, preemption_count=0, score=159264.797225, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=173264.579726, train/accuracy=0.887598, train/loss=0.417829, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:40:47.285514 140239842563840 logging_writer.py:48] [356100] global_step=356100, grad_norm=3.021318197250366, loss=1.153489112854004
I0304 11:41:31.313560 140239850956544 logging_writer.py:48] [356200] global_step=356200, grad_norm=3.0924160480499268, loss=2.7303965091705322
I0304 11:42:16.418767 140239842563840 logging_writer.py:48] [356300] global_step=356300, grad_norm=3.049680233001709, loss=1.5462005138397217
I0304 11:43:01.763829 140239850956544 logging_writer.py:48] [356400] global_step=356400, grad_norm=3.3734045028686523, loss=1.0400160551071167
I0304 11:43:46.819118 140239842563840 logging_writer.py:48] [356500] global_step=356500, grad_norm=3.3076987266540527, loss=1.8693536520004272
I0304 11:44:32.368643 140239850956544 logging_writer.py:48] [356600] global_step=356600, grad_norm=2.901913642883301, loss=1.258302092552185
I0304 11:45:17.677709 140239842563840 logging_writer.py:48] [356700] global_step=356700, grad_norm=2.924382448196411, loss=1.5006242990493774
I0304 11:46:02.847033 140239850956544 logging_writer.py:48] [356800] global_step=356800, grad_norm=2.998908758163452, loss=1.0731849670410156
I0304 11:46:48.308667 140239842563840 logging_writer.py:48] [356900] global_step=356900, grad_norm=3.481506824493408, loss=1.1148648262023926
I0304 11:47:23.201346 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:47:33.493409 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:47:59.219544 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:48:00.836812 140437341357888 submission_runner.py:411] Time since start: 173722.39s, 	Step: 356979, 	{'train/accuracy': 0.8841601610183716, 'train/loss': 0.422722190618515, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 159684.81939792633, 'total_duration': 173722.38829994202, 'accumulated_submission_time': 159684.81939792633, 'accumulated_eval_time': 13990.813126564026, 'accumulated_logging_time': 27.24921751022339}
I0304 11:48:00.926263 140239850956544 logging_writer.py:48] [356979] accumulated_eval_time=13990.813127, accumulated_logging_time=27.249218, accumulated_submission_time=159684.819398, global_step=356979, preemption_count=0, score=159684.819398, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=173722.388300, train/accuracy=0.884160, train/loss=0.422722, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:48:09.656971 140239842563840 logging_writer.py:48] [357000] global_step=357000, grad_norm=3.3538661003112793, loss=1.1960022449493408
I0304 11:48:52.189426 140239850956544 logging_writer.py:48] [357100] global_step=357100, grad_norm=3.0560708045959473, loss=2.402461051940918
I0304 11:49:37.640986 140239842563840 logging_writer.py:48] [357200] global_step=357200, grad_norm=3.0460798740386963, loss=1.1642494201660156
I0304 11:50:23.039783 140239850956544 logging_writer.py:48] [357300] global_step=357300, grad_norm=4.7060394287109375, loss=3.1548638343811035
I0304 11:51:08.329899 140239842563840 logging_writer.py:48] [357400] global_step=357400, grad_norm=3.013184070587158, loss=1.1343178749084473
I0304 11:51:53.535933 140239850956544 logging_writer.py:48] [357500] global_step=357500, grad_norm=2.825786590576172, loss=1.8920561075210571
I0304 11:52:38.656158 140239842563840 logging_writer.py:48] [357600] global_step=357600, grad_norm=2.946826219558716, loss=1.1918013095855713
I0304 11:53:23.892729 140239850956544 logging_writer.py:48] [357700] global_step=357700, grad_norm=3.0622620582580566, loss=1.134178638458252
I0304 11:54:09.164185 140239842563840 logging_writer.py:48] [357800] global_step=357800, grad_norm=2.9653897285461426, loss=1.107271432876587
I0304 11:54:54.609240 140239850956544 logging_writer.py:48] [357900] global_step=357900, grad_norm=3.0642478466033936, loss=1.0080316066741943
I0304 11:55:01.123018 140437341357888 spec.py:321] Evaluating on the training split.
I0304 11:55:11.617663 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 11:55:42.103400 140437341357888 spec.py:349] Evaluating on the test split.
I0304 11:55:43.722565 140437341357888 submission_runner.py:411] Time since start: 174185.27s, 	Step: 357916, 	{'train/accuracy': 0.8896288871765137, 'train/loss': 0.4120044708251953, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 160104.9553952217, 'total_duration': 174185.2740430832, 'accumulated_submission_time': 160104.9553952217, 'accumulated_eval_time': 14033.412657022476, 'accumulated_logging_time': 27.349547863006592}
I0304 11:55:43.809680 140239842563840 logging_writer.py:48] [357916] accumulated_eval_time=14033.412657, accumulated_logging_time=27.349548, accumulated_submission_time=160104.955395, global_step=357916, preemption_count=0, score=160104.955395, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=174185.274043, train/accuracy=0.889629, train/loss=0.412004, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 11:56:17.786355 140239850956544 logging_writer.py:48] [358000] global_step=358000, grad_norm=3.5739645957946777, loss=1.175321340560913
I0304 11:57:03.189999 140239842563840 logging_writer.py:48] [358100] global_step=358100, grad_norm=3.075471878051758, loss=1.0685826539993286
I0304 11:57:48.396610 140239850956544 logging_writer.py:48] [358200] global_step=358200, grad_norm=3.955069065093994, loss=3.232241153717041
I0304 11:58:33.624216 140239842563840 logging_writer.py:48] [358300] global_step=358300, grad_norm=3.7591631412506104, loss=3.242271900177002
I0304 11:59:18.859991 140239850956544 logging_writer.py:48] [358400] global_step=358400, grad_norm=3.077442169189453, loss=2.187521457672119
I0304 12:00:03.857420 140239842563840 logging_writer.py:48] [358500] global_step=358500, grad_norm=3.1487865447998047, loss=1.078655481338501
I0304 12:00:48.907066 140239850956544 logging_writer.py:48] [358600] global_step=358600, grad_norm=2.956840991973877, loss=1.0415308475494385
I0304 12:01:34.218908 140239842563840 logging_writer.py:48] [358700] global_step=358700, grad_norm=3.706263542175293, loss=3.1621813774108887
I0304 12:02:19.308693 140239850956544 logging_writer.py:48] [358800] global_step=358800, grad_norm=3.0068600177764893, loss=1.1541316509246826
I0304 12:02:43.772822 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:02:54.072278 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:03:17.825111 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:03:19.451315 140437341357888 submission_runner.py:411] Time since start: 174641.00s, 	Step: 358856, 	{'train/accuracy': 0.8890820145606995, 'train/loss': 0.410955011844635, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 160524.85397338867, 'total_duration': 174641.0027630329, 'accumulated_submission_time': 160524.85397338867, 'accumulated_eval_time': 14069.091092348099, 'accumulated_logging_time': 27.44993758201599}
I0304 12:03:19.539058 140239842563840 logging_writer.py:48] [358856] accumulated_eval_time=14069.091092, accumulated_logging_time=27.449938, accumulated_submission_time=160524.853973, global_step=358856, preemption_count=0, score=160524.853973, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=174641.002763, train/accuracy=0.889082, train/loss=0.410955, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:03:37.416627 140239850956544 logging_writer.py:48] [358900] global_step=358900, grad_norm=2.7188568115234375, loss=1.7086948156356812
I0304 12:04:21.301304 140239842563840 logging_writer.py:48] [359000] global_step=359000, grad_norm=3.3087503910064697, loss=1.2038644552230835
I0304 12:05:07.139578 140239850956544 logging_writer.py:48] [359100] global_step=359100, grad_norm=3.112738609313965, loss=1.0963140726089478
I0304 12:05:52.535760 140239842563840 logging_writer.py:48] [359200] global_step=359200, grad_norm=3.1797051429748535, loss=1.2321447134017944
I0304 12:06:38.146256 140239850956544 logging_writer.py:48] [359300] global_step=359300, grad_norm=3.6668057441711426, loss=2.987028121948242
I0304 12:07:23.547091 140239842563840 logging_writer.py:48] [359400] global_step=359400, grad_norm=3.8656599521636963, loss=3.16739559173584
I0304 12:08:08.961138 140239850956544 logging_writer.py:48] [359500] global_step=359500, grad_norm=3.144498586654663, loss=1.267747163772583
I0304 12:08:54.181615 140239842563840 logging_writer.py:48] [359600] global_step=359600, grad_norm=3.1714677810668945, loss=1.152093768119812
I0304 12:09:39.745340 140239850956544 logging_writer.py:48] [359700] global_step=359700, grad_norm=3.1691701412200928, loss=1.1664860248565674
I0304 12:10:19.712191 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:10:30.117945 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:10:57.686722 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:10:59.305330 140437341357888 submission_runner.py:411] Time since start: 175100.86s, 	Step: 359790, 	{'train/accuracy': 0.8885937333106995, 'train/loss': 0.41691115498542786, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 160944.96697402, 'total_duration': 175100.8567893505, 'accumulated_submission_time': 160944.96697402, 'accumulated_eval_time': 14108.684185504913, 'accumulated_logging_time': 27.54713273048401}
I0304 12:10:59.390432 140239842563840 logging_writer.py:48] [359790] accumulated_eval_time=14108.684186, accumulated_logging_time=27.547133, accumulated_submission_time=160944.966974, global_step=359790, preemption_count=0, score=160944.966974, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=175100.856789, train/accuracy=0.888594, train/loss=0.416911, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:11:03.766318 140239850956544 logging_writer.py:48] [359800] global_step=359800, grad_norm=3.5109593868255615, loss=3.1435132026672363
I0304 12:11:45.438643 140239842563840 logging_writer.py:48] [359900] global_step=359900, grad_norm=3.022338390350342, loss=1.0952903032302856
I0304 12:12:30.916026 140239850956544 logging_writer.py:48] [360000] global_step=360000, grad_norm=3.914031744003296, loss=3.1288809776306152
I0304 12:13:16.273298 140239842563840 logging_writer.py:48] [360100] global_step=360100, grad_norm=3.9941513538360596, loss=3.2647643089294434
I0304 12:14:01.581098 140239850956544 logging_writer.py:48] [360200] global_step=360200, grad_norm=3.0372440814971924, loss=2.659820318222046
I0304 12:14:46.832327 140239842563840 logging_writer.py:48] [360300] global_step=360300, grad_norm=3.6666741371154785, loss=3.2508349418640137
I0304 12:15:32.579870 140239850956544 logging_writer.py:48] [360400] global_step=360400, grad_norm=2.955108404159546, loss=1.073690414428711
I0304 12:16:18.023409 140239842563840 logging_writer.py:48] [360500] global_step=360500, grad_norm=3.906123638153076, loss=2.7426609992980957
I0304 12:17:03.429404 140239850956544 logging_writer.py:48] [360600] global_step=360600, grad_norm=2.8865442276000977, loss=1.8206536769866943
I0304 12:17:48.743279 140239842563840 logging_writer.py:48] [360700] global_step=360700, grad_norm=3.4836461544036865, loss=1.1480334997177124
I0304 12:17:59.328056 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:18:09.638102 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:18:40.347153 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:18:41.967524 140437341357888 submission_runner.py:411] Time since start: 175563.52s, 	Step: 360725, 	{'train/accuracy': 0.8864648342132568, 'train/loss': 0.421193391084671, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 161364.8423793316, 'total_duration': 175563.51901459694, 'accumulated_submission_time': 161364.8423793316, 'accumulated_eval_time': 14151.323654413223, 'accumulated_logging_time': 27.643819570541382}
I0304 12:18:42.054300 140239850956544 logging_writer.py:48] [360725] accumulated_eval_time=14151.323654, accumulated_logging_time=27.643820, accumulated_submission_time=161364.842379, global_step=360725, preemption_count=0, score=161364.842379, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=175563.519015, train/accuracy=0.886465, train/loss=0.421193, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:19:12.151596 140239842563840 logging_writer.py:48] [360800] global_step=360800, grad_norm=3.5512852668762207, loss=3.2914085388183594
I0304 12:19:56.971434 140239850956544 logging_writer.py:48] [360900] global_step=360900, grad_norm=2.7889626026153564, loss=1.7511250972747803
I0304 12:20:42.315975 140239842563840 logging_writer.py:48] [361000] global_step=361000, grad_norm=2.976335048675537, loss=1.3721113204956055
I0304 12:21:27.200922 140239850956544 logging_writer.py:48] [361100] global_step=361100, grad_norm=2.787733554840088, loss=1.749845266342163
I0304 12:22:12.175240 140239842563840 logging_writer.py:48] [361200] global_step=361200, grad_norm=2.9210307598114014, loss=1.0337737798690796
I0304 12:22:57.571242 140239850956544 logging_writer.py:48] [361300] global_step=361300, grad_norm=2.9245641231536865, loss=1.1429991722106934
I0304 12:23:42.732843 140239842563840 logging_writer.py:48] [361400] global_step=361400, grad_norm=3.055861234664917, loss=1.2203558683395386
I0304 12:24:28.068788 140239850956544 logging_writer.py:48] [361500] global_step=361500, grad_norm=3.0590078830718994, loss=2.4415996074676514
I0304 12:25:13.546844 140239842563840 logging_writer.py:48] [361600] global_step=361600, grad_norm=3.506720542907715, loss=3.1822879314422607
I0304 12:25:42.288091 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:25:52.535514 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:26:18.215255 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:26:19.844624 140437341357888 submission_runner.py:411] Time since start: 176021.40s, 	Step: 361665, 	{'train/accuracy': 0.8865820169448853, 'train/loss': 0.4151625633239746, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 161785.01636505127, 'total_duration': 176021.39610123634, 'accumulated_submission_time': 161785.01636505127, 'accumulated_eval_time': 14188.880197048187, 'accumulated_logging_time': 27.73991370201111}
I0304 12:26:19.937095 140239850956544 logging_writer.py:48] [361665] accumulated_eval_time=14188.880197, accumulated_logging_time=27.739914, accumulated_submission_time=161785.016365, global_step=361665, preemption_count=0, score=161785.016365, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=176021.396101, train/accuracy=0.886582, train/loss=0.415163, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:26:34.209672 140239842563840 logging_writer.py:48] [361700] global_step=361700, grad_norm=3.2351155281066895, loss=1.3004132509231567
I0304 12:27:17.386814 140239850956544 logging_writer.py:48] [361800] global_step=361800, grad_norm=3.0861594676971436, loss=1.5037693977355957
I0304 12:28:02.453090 140239842563840 logging_writer.py:48] [361900] global_step=361900, grad_norm=3.1460859775543213, loss=2.757166862487793
I0304 12:28:47.775868 140239850956544 logging_writer.py:48] [362000] global_step=362000, grad_norm=3.046698808670044, loss=2.079226016998291
I0304 12:29:33.189949 140239842563840 logging_writer.py:48] [362100] global_step=362100, grad_norm=2.9082212448120117, loss=1.1061317920684814
I0304 12:30:18.590733 140239850956544 logging_writer.py:48] [362200] global_step=362200, grad_norm=2.8952202796936035, loss=1.1807113885879517
I0304 12:31:03.709699 140239842563840 logging_writer.py:48] [362300] global_step=362300, grad_norm=3.091113328933716, loss=2.1103529930114746
I0304 12:31:49.069528 140239850956544 logging_writer.py:48] [362400] global_step=362400, grad_norm=2.7194273471832275, loss=1.6849089860916138
I0304 12:32:34.263315 140239842563840 logging_writer.py:48] [362500] global_step=362500, grad_norm=3.280911922454834, loss=2.5318918228149414
I0304 12:33:19.424208 140239850956544 logging_writer.py:48] [362600] global_step=362600, grad_norm=2.926459550857544, loss=1.1865551471710205
I0304 12:33:20.009836 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:33:30.559315 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:34:03.678431 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:34:05.293283 140437341357888 submission_runner.py:411] Time since start: 176486.84s, 	Step: 362603, 	{'train/accuracy': 0.8888476490974426, 'train/loss': 0.41118159890174866, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 162205.02902841568, 'total_duration': 176486.84476661682, 'accumulated_submission_time': 162205.02902841568, 'accumulated_eval_time': 14234.16361951828, 'accumulated_logging_time': 27.842221975326538}
I0304 12:34:05.382287 140239842563840 logging_writer.py:48] [362603] accumulated_eval_time=14234.163620, accumulated_logging_time=27.842222, accumulated_submission_time=162205.029028, global_step=362603, preemption_count=0, score=162205.029028, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=176486.844767, train/accuracy=0.888848, train/loss=0.411182, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:34:44.609393 140239850956544 logging_writer.py:48] [362700] global_step=362700, grad_norm=3.4550108909606934, loss=3.17572283744812
I0304 12:35:29.930537 140239842563840 logging_writer.py:48] [362800] global_step=362800, grad_norm=3.171074390411377, loss=1.0511338710784912
I0304 12:36:16.007903 140239850956544 logging_writer.py:48] [362900] global_step=362900, grad_norm=3.3063833713531494, loss=2.434145450592041
I0304 12:37:01.375949 140239842563840 logging_writer.py:48] [363000] global_step=363000, grad_norm=2.897134780883789, loss=1.6797661781311035
I0304 12:37:46.665745 140239850956544 logging_writer.py:48] [363100] global_step=363100, grad_norm=3.2003333568573, loss=1.1157091856002808
I0304 12:38:31.968170 140239842563840 logging_writer.py:48] [363200] global_step=363200, grad_norm=2.888136386871338, loss=2.042189121246338
I0304 12:39:17.019388 140239850956544 logging_writer.py:48] [363300] global_step=363300, grad_norm=2.9584546089172363, loss=1.1324362754821777
I0304 12:40:02.455808 140239842563840 logging_writer.py:48] [363400] global_step=363400, grad_norm=2.8389711380004883, loss=1.303354263305664
I0304 12:40:47.533973 140239850956544 logging_writer.py:48] [363500] global_step=363500, grad_norm=2.7811217308044434, loss=1.3051207065582275
I0304 12:41:05.416363 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:41:15.610053 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:41:45.013238 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:41:46.636013 140437341357888 submission_runner.py:411] Time since start: 176948.19s, 	Step: 363541, 	{'train/accuracy': 0.8886523246765137, 'train/loss': 0.4192703664302826, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 162625.00325775146, 'total_duration': 176948.18750071526, 'accumulated_submission_time': 162625.00325775146, 'accumulated_eval_time': 14275.383254051208, 'accumulated_logging_time': 27.941187858581543}
I0304 12:41:46.724989 140239842563840 logging_writer.py:48] [363541] accumulated_eval_time=14275.383254, accumulated_logging_time=27.941188, accumulated_submission_time=162625.003258, global_step=363541, preemption_count=0, score=162625.003258, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=176948.187501, train/accuracy=0.888652, train/loss=0.419270, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:42:10.496862 140239850956544 logging_writer.py:48] [363600] global_step=363600, grad_norm=3.0064454078674316, loss=2.569056749343872
I0304 12:42:54.679224 140239842563840 logging_writer.py:48] [363700] global_step=363700, grad_norm=2.80507230758667, loss=1.0169373750686646
I0304 12:43:39.919034 140239850956544 logging_writer.py:48] [363800] global_step=363800, grad_norm=2.788433074951172, loss=1.085665225982666
I0304 12:44:25.519631 140239842563840 logging_writer.py:48] [363900] global_step=363900, grad_norm=2.9795491695404053, loss=1.1303596496582031
I0304 12:45:10.764328 140239850956544 logging_writer.py:48] [364000] global_step=364000, grad_norm=3.2037136554718018, loss=1.988537073135376
I0304 12:45:56.370737 140239842563840 logging_writer.py:48] [364100] global_step=364100, grad_norm=2.931330919265747, loss=1.1520501375198364
I0304 12:46:41.679714 140239850956544 logging_writer.py:48] [364200] global_step=364200, grad_norm=3.713426351547241, loss=3.2825589179992676
I0304 12:47:26.809459 140239842563840 logging_writer.py:48] [364300] global_step=364300, grad_norm=4.472601413726807, loss=3.1240601539611816
I0304 12:48:11.966824 140239850956544 logging_writer.py:48] [364400] global_step=364400, grad_norm=3.396277666091919, loss=2.521259307861328
I0304 12:48:46.949277 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:48:57.408412 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:49:21.084435 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:49:22.701558 140437341357888 submission_runner.py:411] Time since start: 177404.25s, 	Step: 364479, 	{'train/accuracy': 0.8897656202316284, 'train/loss': 0.4115915596485138, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 163045.1636610031, 'total_duration': 177404.25304937363, 'accumulated_submission_time': 163045.1636610031, 'accumulated_eval_time': 14311.135527849197, 'accumulated_logging_time': 28.044018983840942}
I0304 12:49:22.789823 140239842563840 logging_writer.py:48] [364479] accumulated_eval_time=14311.135528, accumulated_logging_time=28.044019, accumulated_submission_time=163045.163661, global_step=364479, preemption_count=0, score=163045.163661, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=177404.253049, train/accuracy=0.889766, train/loss=0.411592, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:49:31.514458 140239850956544 logging_writer.py:48] [364500] global_step=364500, grad_norm=3.3308732509613037, loss=2.576425075531006
I0304 12:50:14.281126 140239842563840 logging_writer.py:48] [364600] global_step=364600, grad_norm=3.043238401412964, loss=1.336111068725586
I0304 12:50:59.383473 140239850956544 logging_writer.py:48] [364700] global_step=364700, grad_norm=3.2375106811523438, loss=2.39314866065979
I0304 12:51:44.552107 140239842563840 logging_writer.py:48] [364800] global_step=364800, grad_norm=3.0649940967559814, loss=1.05899977684021
I0304 12:52:29.982994 140239850956544 logging_writer.py:48] [364900] global_step=364900, grad_norm=2.7398881912231445, loss=1.1399532556533813
I0304 12:53:15.282403 140239842563840 logging_writer.py:48] [365000] global_step=365000, grad_norm=3.0238006114959717, loss=1.084313988685608
I0304 12:54:00.535708 140239850956544 logging_writer.py:48] [365100] global_step=365100, grad_norm=3.696348190307617, loss=2.660064697265625
I0304 12:54:45.810030 140239842563840 logging_writer.py:48] [365200] global_step=365200, grad_norm=2.989938259124756, loss=1.3542100191116333
I0304 12:55:31.334208 140239850956544 logging_writer.py:48] [365300] global_step=365300, grad_norm=3.5811262130737305, loss=3.120712995529175
I0304 12:56:17.591393 140239842563840 logging_writer.py:48] [365400] global_step=365400, grad_norm=4.052741050720215, loss=2.9027795791625977
I0304 12:56:22.745205 140437341357888 spec.py:321] Evaluating on the training split.
I0304 12:56:33.217659 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 12:57:06.898915 140437341357888 spec.py:349] Evaluating on the test split.
I0304 12:57:08.517378 140437341357888 submission_runner.py:411] Time since start: 177870.07s, 	Step: 365413, 	{'train/accuracy': 0.8880468606948853, 'train/loss': 0.4186495542526245, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 163465.0584104061, 'total_duration': 177870.06887936592, 'accumulated_submission_time': 163465.0584104061, 'accumulated_eval_time': 14356.90769314766, 'accumulated_logging_time': 28.14191770553589}
I0304 12:57:08.589565 140239850956544 logging_writer.py:48] [365413] accumulated_eval_time=14356.907693, accumulated_logging_time=28.141918, accumulated_submission_time=163465.058410, global_step=365413, preemption_count=0, score=163465.058410, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=177870.068879, train/accuracy=0.888047, train/loss=0.418650, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 12:57:43.441687 140239842563840 logging_writer.py:48] [365500] global_step=365500, grad_norm=2.9734227657318115, loss=1.0762145519256592
I0304 12:58:28.702174 140239850956544 logging_writer.py:48] [365600] global_step=365600, grad_norm=3.964481830596924, loss=3.170557737350464
I0304 12:59:14.473677 140239842563840 logging_writer.py:48] [365700] global_step=365700, grad_norm=2.8571858406066895, loss=1.9009690284729004
I0304 12:59:59.668447 140239850956544 logging_writer.py:48] [365800] global_step=365800, grad_norm=3.363807201385498, loss=2.9959235191345215
I0304 13:00:45.112707 140239842563840 logging_writer.py:48] [365900] global_step=365900, grad_norm=3.0763661861419678, loss=1.119227409362793
I0304 13:01:30.378464 140239850956544 logging_writer.py:48] [366000] global_step=366000, grad_norm=2.8495047092437744, loss=1.4149993658065796
I0304 13:02:15.855117 140239842563840 logging_writer.py:48] [366100] global_step=366100, grad_norm=3.479217529296875, loss=3.277073621749878
I0304 13:03:01.234241 140239850956544 logging_writer.py:48] [366200] global_step=366200, grad_norm=3.651503801345825, loss=3.268794536590576
I0304 13:03:46.653979 140239842563840 logging_writer.py:48] [366300] global_step=366300, grad_norm=6.198978900909424, loss=1.043607473373413
I0304 13:04:08.644898 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:04:18.977072 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:04:41.421154 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:04:43.040780 140437341357888 submission_runner.py:411] Time since start: 178324.59s, 	Step: 366350, 	{'train/accuracy': 0.8872460722923279, 'train/loss': 0.41885775327682495, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 163885.0548875332, 'total_duration': 178324.59226608276, 'accumulated_submission_time': 163885.0548875332, 'accumulated_eval_time': 14391.303559541702, 'accumulated_logging_time': 28.22307014465332}
I0304 13:04:43.129583 140239850956544 logging_writer.py:48] [366350] accumulated_eval_time=14391.303560, accumulated_logging_time=28.223070, accumulated_submission_time=163885.054888, global_step=366350, preemption_count=0, score=163885.054888, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=178324.592266, train/accuracy=0.887246, train/loss=0.418858, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:05:03.345341 140239842563840 logging_writer.py:48] [366400] global_step=366400, grad_norm=2.7920892238616943, loss=1.311086654663086
I0304 13:05:47.398038 140239850956544 logging_writer.py:48] [366500] global_step=366500, grad_norm=3.041574716567993, loss=1.384695053100586
I0304 13:06:33.169065 140239842563840 logging_writer.py:48] [366600] global_step=366600, grad_norm=3.0403547286987305, loss=1.070783019065857
I0304 13:07:18.649713 140239850956544 logging_writer.py:48] [366700] global_step=366700, grad_norm=3.1503539085388184, loss=2.6365232467651367
I0304 13:08:03.807775 140239842563840 logging_writer.py:48] [366800] global_step=366800, grad_norm=2.898514986038208, loss=1.1467198133468628
I0304 13:08:49.334985 140239850956544 logging_writer.py:48] [366900] global_step=366900, grad_norm=2.840668201446533, loss=1.5926988124847412
I0304 13:09:34.626672 140239842563840 logging_writer.py:48] [367000] global_step=367000, grad_norm=3.1193957328796387, loss=2.8622665405273438
I0304 13:10:19.905044 140239850956544 logging_writer.py:48] [367100] global_step=367100, grad_norm=2.9306724071502686, loss=1.1134971380233765
I0304 13:11:05.296321 140239842563840 logging_writer.py:48] [367200] global_step=367200, grad_norm=4.17503023147583, loss=3.058011770248413
I0304 13:11:43.235001 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:11:53.895744 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:12:24.474477 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:12:26.100441 140437341357888 submission_runner.py:411] Time since start: 178787.65s, 	Step: 367286, 	{'train/accuracy': 0.8896288871765137, 'train/loss': 0.4089963436126709, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 164305.09626293182, 'total_duration': 178787.65193104744, 'accumulated_submission_time': 164305.09626293182, 'accumulated_eval_time': 14434.169000864029, 'accumulated_logging_time': 28.325141668319702}
I0304 13:12:26.189838 140239850956544 logging_writer.py:48] [367286] accumulated_eval_time=14434.169001, accumulated_logging_time=28.325142, accumulated_submission_time=164305.096263, global_step=367286, preemption_count=0, score=164305.096263, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=178787.651931, train/accuracy=0.889629, train/loss=0.408996, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:12:32.162181 140239842563840 logging_writer.py:48] [367300] global_step=367300, grad_norm=2.987243175506592, loss=2.2926666736602783
I0304 13:13:13.868402 140239850956544 logging_writer.py:48] [367400] global_step=367400, grad_norm=2.8781964778900146, loss=1.1229678392410278
I0304 13:13:58.925562 140239842563840 logging_writer.py:48] [367500] global_step=367500, grad_norm=3.1744892597198486, loss=2.2448062896728516
I0304 13:14:44.503719 140239850956544 logging_writer.py:48] [367600] global_step=367600, grad_norm=3.167182683944702, loss=1.0939267873764038
I0304 13:15:29.814549 140239842563840 logging_writer.py:48] [367700] global_step=367700, grad_norm=2.9177725315093994, loss=2.3182358741760254
I0304 13:16:15.360949 140239850956544 logging_writer.py:48] [367800] global_step=367800, grad_norm=2.9284417629241943, loss=1.1052887439727783
I0304 13:17:00.880025 140239842563840 logging_writer.py:48] [367900] global_step=367900, grad_norm=3.0308029651641846, loss=1.0715149641036987
I0304 13:17:46.247797 140239850956544 logging_writer.py:48] [368000] global_step=368000, grad_norm=3.004417657852173, loss=1.1089248657226562
I0304 13:18:31.491525 140239842563840 logging_writer.py:48] [368100] global_step=368100, grad_norm=3.1568140983581543, loss=1.046858787536621
I0304 13:19:16.816297 140239850956544 logging_writer.py:48] [368200] global_step=368200, grad_norm=2.9716882705688477, loss=1.8117649555206299
I0304 13:19:26.420320 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:19:36.768380 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:20:05.369408 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:20:07.039055 140437341357888 submission_runner.py:411] Time since start: 179248.59s, 	Step: 368223, 	{'train/accuracy': 0.8872460722923279, 'train/loss': 0.41348394751548767, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 164725.26630687714, 'total_duration': 179248.5905110836, 'accumulated_submission_time': 164725.26630687714, 'accumulated_eval_time': 14474.787692546844, 'accumulated_logging_time': 28.424390077590942}
I0304 13:20:07.184414 140239842563840 logging_writer.py:48] [368223] accumulated_eval_time=14474.787693, accumulated_logging_time=28.424390, accumulated_submission_time=164725.266307, global_step=368223, preemption_count=0, score=164725.266307, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=179248.590511, train/accuracy=0.887246, train/loss=0.413484, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:20:38.083637 140239850956544 logging_writer.py:48] [368300] global_step=368300, grad_norm=2.956491470336914, loss=1.1849602460861206
I0304 13:21:22.944252 140239842563840 logging_writer.py:48] [368400] global_step=368400, grad_norm=3.108718156814575, loss=1.21181058883667
I0304 13:22:08.536568 140239850956544 logging_writer.py:48] [368500] global_step=368500, grad_norm=3.105311870574951, loss=1.2085850238800049
I0304 13:22:53.840996 140239842563840 logging_writer.py:48] [368600] global_step=368600, grad_norm=3.6633217334747314, loss=2.709627866744995
I0304 13:23:39.176284 140239850956544 logging_writer.py:48] [368700] global_step=368700, grad_norm=3.1045875549316406, loss=1.952384352684021
I0304 13:24:24.508505 140239842563840 logging_writer.py:48] [368800] global_step=368800, grad_norm=2.8807859420776367, loss=1.03987717628479
I0304 13:25:09.866307 140239850956544 logging_writer.py:48] [368900] global_step=368900, grad_norm=3.2332565784454346, loss=1.1042587757110596
I0304 13:25:55.082061 140239842563840 logging_writer.py:48] [369000] global_step=369000, grad_norm=9.037909507751465, loss=1.1699658632278442
I0304 13:26:40.889459 140239850956544 logging_writer.py:48] [369100] global_step=369100, grad_norm=3.368360757827759, loss=1.2111382484436035
I0304 13:27:07.165157 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:27:17.696552 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:27:47.372424 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:27:48.988942 140437341357888 submission_runner.py:411] Time since start: 179710.54s, 	Step: 369160, 	{'train/accuracy': 0.8898632526397705, 'train/loss': 0.41051897406578064, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 165145.18168735504, 'total_duration': 179710.54042887688, 'accumulated_submission_time': 165145.18168735504, 'accumulated_eval_time': 14516.611475229263, 'accumulated_logging_time': 28.584221839904785}
I0304 13:27:49.079108 140239842563840 logging_writer.py:48] [369160] accumulated_eval_time=14516.611475, accumulated_logging_time=28.584222, accumulated_submission_time=165145.181687, global_step=369160, preemption_count=0, score=165145.181687, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=179710.540429, train/accuracy=0.889863, train/loss=0.410519, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:28:05.352014 140239850956544 logging_writer.py:48] [369200] global_step=369200, grad_norm=2.972276449203491, loss=2.04962158203125
I0304 13:28:48.542436 140239842563840 logging_writer.py:48] [369300] global_step=369300, grad_norm=3.028501272201538, loss=1.2737351655960083
I0304 13:29:33.797782 140239850956544 logging_writer.py:48] [369400] global_step=369400, grad_norm=4.0407609939575195, loss=1.1526505947113037
I0304 13:30:19.288801 140239842563840 logging_writer.py:48] [369500] global_step=369500, grad_norm=3.8273472785949707, loss=3.2186412811279297
I0304 13:31:04.506139 140239850956544 logging_writer.py:48] [369600] global_step=369600, grad_norm=4.111069679260254, loss=1.1093344688415527
I0304 13:31:49.558822 140239842563840 logging_writer.py:48] [369700] global_step=369700, grad_norm=3.030912160873413, loss=1.6854681968688965
I0304 13:32:35.071541 140239850956544 logging_writer.py:48] [369800] global_step=369800, grad_norm=3.1151225566864014, loss=1.0845333337783813
I0304 13:33:20.238094 140239842563840 logging_writer.py:48] [369900] global_step=369900, grad_norm=2.7137646675109863, loss=1.54634690284729
I0304 13:34:05.696928 140239850956544 logging_writer.py:48] [370000] global_step=370000, grad_norm=7.0252838134765625, loss=2.9386770725250244
I0304 13:34:49.276308 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:35:00.319407 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:35:28.939389 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:35:30.553367 140437341357888 submission_runner.py:411] Time since start: 180172.10s, 	Step: 370098, 	{'train/accuracy': 0.8863281011581421, 'train/loss': 0.41797366738319397, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 165565.3174443245, 'total_duration': 180172.10485219955, 'accumulated_submission_time': 165565.3174443245, 'accumulated_eval_time': 14557.888511419296, 'accumulated_logging_time': 28.685779333114624}
I0304 13:35:30.643472 140239842563840 logging_writer.py:48] [370098] accumulated_eval_time=14557.888511, accumulated_logging_time=28.685779, accumulated_submission_time=165565.317444, global_step=370098, preemption_count=0, score=165565.317444, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=180172.104852, train/accuracy=0.886328, train/loss=0.417974, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:35:31.846640 140239850956544 logging_writer.py:48] [370100] global_step=370100, grad_norm=5.019219398498535, loss=3.2165188789367676
I0304 13:36:13.101645 140239842563840 logging_writer.py:48] [370200] global_step=370200, grad_norm=3.1992053985595703, loss=1.0579216480255127
I0304 13:36:58.329877 140239850956544 logging_writer.py:48] [370300] global_step=370300, grad_norm=2.871870517730713, loss=1.0953271389007568
I0304 13:37:43.950328 140239842563840 logging_writer.py:48] [370400] global_step=370400, grad_norm=3.0164852142333984, loss=1.9910624027252197
I0304 13:38:29.346763 140239850956544 logging_writer.py:48] [370500] global_step=370500, grad_norm=2.9756927490234375, loss=2.3445241451263428
I0304 13:39:14.808891 140239842563840 logging_writer.py:48] [370600] global_step=370600, grad_norm=3.122217893600464, loss=2.200225830078125
I0304 13:39:59.719056 140239850956544 logging_writer.py:48] [370700] global_step=370700, grad_norm=2.93428635597229, loss=1.8994102478027344
I0304 13:40:45.141640 140239842563840 logging_writer.py:48] [370800] global_step=370800, grad_norm=3.8257737159729004, loss=1.300621509552002
I0304 13:41:30.364490 140239850956544 logging_writer.py:48] [370900] global_step=370900, grad_norm=3.0188143253326416, loss=1.0559998750686646
I0304 13:42:15.616667 140239842563840 logging_writer.py:48] [371000] global_step=371000, grad_norm=3.1677615642547607, loss=1.210013508796692
I0304 13:42:30.776877 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:42:41.193630 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:43:07.900968 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:43:09.552382 140437341357888 submission_runner.py:411] Time since start: 180631.10s, 	Step: 371035, 	{'train/accuracy': 0.889453113079071, 'train/loss': 0.41628116369247437, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 165985.38984370232, 'total_duration': 180631.10386180878, 'accumulated_submission_time': 165985.38984370232, 'accumulated_eval_time': 14596.663992404938, 'accumulated_logging_time': 28.78573179244995}
I0304 13:43:09.656768 140239850956544 logging_writer.py:48] [371035] accumulated_eval_time=14596.663992, accumulated_logging_time=28.785732, accumulated_submission_time=165985.389844, global_step=371035, preemption_count=0, score=165985.389844, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=180631.103862, train/accuracy=0.889453, train/loss=0.416281, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:43:35.822293 140239842563840 logging_writer.py:48] [371100] global_step=371100, grad_norm=3.007982015609741, loss=2.3576889038085938
I0304 13:44:19.705775 140239850956544 logging_writer.py:48] [371200] global_step=371200, grad_norm=3.281278371810913, loss=1.9821158647537231
I0304 13:45:05.114756 140239842563840 logging_writer.py:48] [371300] global_step=371300, grad_norm=2.9704818725585938, loss=1.0361942052841187
I0304 13:45:50.608626 140239850956544 logging_writer.py:48] [371400] global_step=371400, grad_norm=3.168654203414917, loss=1.0399589538574219
I0304 13:46:35.923731 140239842563840 logging_writer.py:48] [371500] global_step=371500, grad_norm=3.048649549484253, loss=1.032478928565979
I0304 13:47:21.523469 140239850956544 logging_writer.py:48] [371600] global_step=371600, grad_norm=3.0175817012786865, loss=1.1767319440841675
I0304 13:48:06.672457 140239842563840 logging_writer.py:48] [371700] global_step=371700, grad_norm=3.6166293621063232, loss=3.027167320251465
I0304 13:48:52.008889 140239850956544 logging_writer.py:48] [371800] global_step=371800, grad_norm=3.9468631744384766, loss=2.7571654319763184
I0304 13:49:37.453099 140239842563840 logging_writer.py:48] [371900] global_step=371900, grad_norm=2.9515368938446045, loss=1.1749995946884155
I0304 13:50:09.792560 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:50:20.376845 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:50:48.783394 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:50:50.405014 140437341357888 submission_runner.py:411] Time since start: 181091.96s, 	Step: 371973, 	{'train/accuracy': 0.8895117044448853, 'train/loss': 0.4145427942276001, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 166405.45948576927, 'total_duration': 181091.9565012455, 'accumulated_submission_time': 166405.45948576927, 'accumulated_eval_time': 14637.276457309723, 'accumulated_logging_time': 28.905762434005737}
I0304 13:50:50.496177 140239850956544 logging_writer.py:48] [371973] accumulated_eval_time=14637.276457, accumulated_logging_time=28.905762, accumulated_submission_time=166405.459486, global_step=371973, preemption_count=0, score=166405.459486, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=181091.956501, train/accuracy=0.889512, train/loss=0.414543, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:51:01.598141 140239842563840 logging_writer.py:48] [372000] global_step=372000, grad_norm=3.378754138946533, loss=3.1354546546936035
I0304 13:51:44.125055 140239850956544 logging_writer.py:48] [372100] global_step=372100, grad_norm=3.0305402278900146, loss=1.2932491302490234
I0304 13:52:29.665624 140239842563840 logging_writer.py:48] [372200] global_step=372200, grad_norm=3.3185935020446777, loss=2.6754965782165527
I0304 13:53:15.142821 140239850956544 logging_writer.py:48] [372300] global_step=372300, grad_norm=2.8537049293518066, loss=2.094331741333008
I0304 13:54:00.437366 140239842563840 logging_writer.py:48] [372400] global_step=372400, grad_norm=2.9127233028411865, loss=2.2110211849212646
I0304 13:54:45.695934 140239850956544 logging_writer.py:48] [372500] global_step=372500, grad_norm=2.8078482151031494, loss=0.9853443503379822
I0304 13:55:31.407850 140239842563840 logging_writer.py:48] [372600] global_step=372600, grad_norm=2.9878385066986084, loss=1.8852912187576294
I0304 13:56:16.971092 140239850956544 logging_writer.py:48] [372700] global_step=372700, grad_norm=2.9043328762054443, loss=1.7476963996887207
I0304 13:57:02.301450 140239842563840 logging_writer.py:48] [372800] global_step=372800, grad_norm=3.999378204345703, loss=3.2842888832092285
I0304 13:57:48.039806 140239850956544 logging_writer.py:48] [372900] global_step=372900, grad_norm=2.9040188789367676, loss=1.1109027862548828
I0304 13:57:50.713389 140437341357888 spec.py:321] Evaluating on the training split.
I0304 13:58:01.222564 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 13:58:27.180157 140437341357888 spec.py:349] Evaluating on the test split.
I0304 13:58:28.806261 140437341357888 submission_runner.py:411] Time since start: 181550.36s, 	Step: 372908, 	{'train/accuracy': 0.889941394329071, 'train/loss': 0.40621355175971985, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 166825.61236143112, 'total_duration': 181550.35774874687, 'accumulated_submission_time': 166825.61236143112, 'accumulated_eval_time': 14675.369314670563, 'accumulated_logging_time': 29.011127471923828}
I0304 13:58:28.903006 140239842563840 logging_writer.py:48] [372908] accumulated_eval_time=14675.369315, accumulated_logging_time=29.011127, accumulated_submission_time=166825.612361, global_step=372908, preemption_count=0, score=166825.612361, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=181550.357749, train/accuracy=0.889941, train/loss=0.406214, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 13:59:07.138241 140239850956544 logging_writer.py:48] [373000] global_step=373000, grad_norm=3.5210938453674316, loss=2.894594192504883
I0304 13:59:52.284515 140239842563840 logging_writer.py:48] [373100] global_step=373100, grad_norm=3.1194827556610107, loss=1.4313089847564697
I0304 14:00:37.862934 140239850956544 logging_writer.py:48] [373200] global_step=373200, grad_norm=3.220752477645874, loss=1.1742852926254272
I0304 14:01:23.370776 140239842563840 logging_writer.py:48] [373300] global_step=373300, grad_norm=3.6542701721191406, loss=3.078455924987793
I0304 14:02:08.846930 140239850956544 logging_writer.py:48] [373400] global_step=373400, grad_norm=3.2192444801330566, loss=1.840230107307434
I0304 14:02:54.073758 140239842563840 logging_writer.py:48] [373500] global_step=373500, grad_norm=3.034393787384033, loss=1.2672157287597656
I0304 14:03:39.508624 140239850956544 logging_writer.py:48] [373600] global_step=373600, grad_norm=3.058657646179199, loss=1.2917115688323975
I0304 14:04:25.841754 140239842563840 logging_writer.py:48] [373700] global_step=373700, grad_norm=2.985633611679077, loss=1.1004977226257324
I0304 14:05:11.013008 140239850956544 logging_writer.py:48] [373800] global_step=373800, grad_norm=3.052375316619873, loss=1.1423673629760742
I0304 14:05:29.171848 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:05:39.715776 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:06:06.183580 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:06:07.838209 140437341357888 submission_runner.py:411] Time since start: 182009.39s, 	Step: 373842, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.4190575182437897, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 167245.81822776794, 'total_duration': 182009.38965320587, 'accumulated_submission_time': 167245.81822776794, 'accumulated_eval_time': 14714.035625219345, 'accumulated_logging_time': 29.120630979537964}
I0304 14:06:07.990686 140239842563840 logging_writer.py:48] [373842] accumulated_eval_time=14714.035625, accumulated_logging_time=29.120631, accumulated_submission_time=167245.818228, global_step=373842, preemption_count=0, score=167245.818228, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=182009.389653, train/accuracy=0.888477, train/loss=0.419058, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 14:06:31.366244 140239850956544 logging_writer.py:48] [373900] global_step=373900, grad_norm=2.974672794342041, loss=1.055902123451233
I0304 14:07:14.866614 140239842563840 logging_writer.py:48] [374000] global_step=374000, grad_norm=3.828622579574585, loss=3.0055975914001465
I0304 14:08:00.531471 140239850956544 logging_writer.py:48] [374100] global_step=374100, grad_norm=3.258157253265381, loss=1.1131411790847778
I0304 14:08:46.298522 140239842563840 logging_writer.py:48] [374200] global_step=374200, grad_norm=3.1906991004943848, loss=1.0605648756027222
I0304 14:09:31.399255 140239850956544 logging_writer.py:48] [374300] global_step=374300, grad_norm=2.9012792110443115, loss=1.646217703819275
I0304 14:10:17.154620 140239842563840 logging_writer.py:48] [374400] global_step=374400, grad_norm=2.8751301765441895, loss=1.0892666578292847
I0304 14:11:02.808841 140239850956544 logging_writer.py:48] [374500] global_step=374500, grad_norm=3.0926175117492676, loss=2.502389907836914
I0304 14:11:47.922913 140239842563840 logging_writer.py:48] [374600] global_step=374600, grad_norm=2.9857630729675293, loss=2.1559579372406006
I0304 14:12:33.159966 140239850956544 logging_writer.py:48] [374700] global_step=374700, grad_norm=2.8772215843200684, loss=1.2516225576400757
I0304 14:13:07.877707 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:13:18.949243 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:13:42.776477 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:13:44.401886 140437341357888 submission_runner.py:411] Time since start: 182465.95s, 	Step: 374778, 	{'train/accuracy': 0.88880854845047, 'train/loss': 0.4142800569534302, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 167665.64027285576, 'total_duration': 182465.95337557793, 'accumulated_submission_time': 167665.64027285576, 'accumulated_eval_time': 14750.559784173965, 'accumulated_logging_time': 29.287435293197632}
I0304 14:13:44.491729 140239842563840 logging_writer.py:48] [374778] accumulated_eval_time=14750.559784, accumulated_logging_time=29.287435, accumulated_submission_time=167665.640273, global_step=374778, preemption_count=0, score=167665.640273, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=182465.953376, train/accuracy=0.888809, train/loss=0.414280, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 14:13:53.622766 140239850956544 logging_writer.py:48] [374800] global_step=374800, grad_norm=3.3862993717193604, loss=2.916985511779785
I0304 14:14:36.007161 140239842563840 logging_writer.py:48] [374900] global_step=374900, grad_norm=3.4179575443267822, loss=1.1139779090881348
I0304 14:15:21.348390 140239850956544 logging_writer.py:48] [375000] global_step=375000, grad_norm=3.197596311569214, loss=1.084603190422058
I0304 14:16:06.850792 140239842563840 logging_writer.py:48] [375100] global_step=375100, grad_norm=3.8656110763549805, loss=3.065004587173462
I0304 14:16:52.149757 140239850956544 logging_writer.py:48] [375200] global_step=375200, grad_norm=3.0965659618377686, loss=1.7315473556518555
I0304 14:17:37.316781 140239842563840 logging_writer.py:48] [375300] global_step=375300, grad_norm=3.483816623687744, loss=3.228858232498169
I0304 14:18:22.838754 140239850956544 logging_writer.py:48] [375400] global_step=375400, grad_norm=3.8335649967193604, loss=3.1777329444885254
I0304 14:19:07.938917 140239842563840 logging_writer.py:48] [375500] global_step=375500, grad_norm=3.6113052368164062, loss=3.1593587398529053
I0304 14:19:53.060105 140239850956544 logging_writer.py:48] [375600] global_step=375600, grad_norm=2.8739142417907715, loss=1.969290018081665
I0304 14:20:38.305662 140239842563840 logging_writer.py:48] [375700] global_step=375700, grad_norm=2.8395326137542725, loss=2.2552309036254883
I0304 14:20:44.698335 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:20:55.598361 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:21:25.500122 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:21:27.123193 140437341357888 submission_runner.py:411] Time since start: 182928.67s, 	Step: 375716, 	{'train/accuracy': 0.88720703125, 'train/loss': 0.4153881371021271, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 168085.7812242508, 'total_duration': 182928.67467594147, 'accumulated_submission_time': 168085.7812242508, 'accumulated_eval_time': 14792.984617710114, 'accumulated_logging_time': 29.391901969909668}
I0304 14:21:27.213848 140239850956544 logging_writer.py:48] [375716] accumulated_eval_time=14792.984618, accumulated_logging_time=29.391902, accumulated_submission_time=168085.781224, global_step=375716, preemption_count=0, score=168085.781224, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=182928.674676, train/accuracy=0.887207, train/loss=0.415388, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 14:22:01.391230 140239842563840 logging_writer.py:48] [375800] global_step=375800, grad_norm=3.8349952697753906, loss=3.0969724655151367
I0304 14:22:46.587420 140239850956544 logging_writer.py:48] [375900] global_step=375900, grad_norm=2.980761766433716, loss=2.0690369606018066
I0304 14:23:32.014381 140239842563840 logging_writer.py:48] [376000] global_step=376000, grad_norm=3.3530709743499756, loss=1.9224196672439575
I0304 14:24:17.170469 140239850956544 logging_writer.py:48] [376100] global_step=376100, grad_norm=3.2147936820983887, loss=1.1800203323364258
I0304 14:25:02.361733 140239842563840 logging_writer.py:48] [376200] global_step=376200, grad_norm=2.878978967666626, loss=2.1429600715637207
I0304 14:25:47.524073 140239850956544 logging_writer.py:48] [376300] global_step=376300, grad_norm=3.0596818923950195, loss=1.5956215858459473
I0304 14:26:32.781324 140239842563840 logging_writer.py:48] [376400] global_step=376400, grad_norm=3.4979183673858643, loss=1.1235506534576416
I0304 14:27:18.136363 140239850956544 logging_writer.py:48] [376500] global_step=376500, grad_norm=2.961172103881836, loss=2.205416440963745
I0304 14:28:03.924485 140239842563840 logging_writer.py:48] [376600] global_step=376600, grad_norm=3.2008981704711914, loss=1.5778480768203735
I0304 14:28:27.593930 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:28:37.831209 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:29:03.271359 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:29:04.893933 140437341357888 submission_runner.py:411] Time since start: 183386.45s, 	Step: 376654, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.4154757261276245, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 168506.1006731987, 'total_duration': 183386.4454011917, 'accumulated_submission_time': 168506.1006731987, 'accumulated_eval_time': 14830.284606933594, 'accumulated_logging_time': 29.49255681037903}
I0304 14:29:04.985721 140239850956544 logging_writer.py:48] [376654] accumulated_eval_time=14830.284607, accumulated_logging_time=29.492557, accumulated_submission_time=168506.100673, global_step=376654, preemption_count=0, score=168506.100673, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=183386.445401, train/accuracy=0.888066, train/loss=0.415476, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 14:29:23.792541 140239842563840 logging_writer.py:48] [376700] global_step=376700, grad_norm=3.431082010269165, loss=1.0715548992156982
I0304 14:30:07.829216 140239850956544 logging_writer.py:48] [376800] global_step=376800, grad_norm=3.4693148136138916, loss=2.817863941192627
I0304 14:30:53.125199 140239842563840 logging_writer.py:48] [376900] global_step=376900, grad_norm=3.021029472351074, loss=1.5705358982086182
I0304 14:31:38.370794 140239850956544 logging_writer.py:48] [377000] global_step=377000, grad_norm=3.105144500732422, loss=2.450894355773926
I0304 14:32:23.532167 140239842563840 logging_writer.py:48] [377100] global_step=377100, grad_norm=3.0179266929626465, loss=1.121337890625
I0304 14:33:08.846526 140239850956544 logging_writer.py:48] [377200] global_step=377200, grad_norm=3.2208492755889893, loss=1.0672132968902588
I0304 14:33:53.958441 140239842563840 logging_writer.py:48] [377300] global_step=377300, grad_norm=2.727508068084717, loss=1.3743560314178467
I0304 14:34:39.200383 140239850956544 logging_writer.py:48] [377400] global_step=377400, grad_norm=2.998873233795166, loss=1.1516693830490112
I0304 14:35:24.783517 140239842563840 logging_writer.py:48] [377500] global_step=377500, grad_norm=3.608160972595215, loss=1.197788953781128
I0304 14:36:05.182357 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:36:15.660333 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:36:41.013765 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:36:42.633039 140437341357888 submission_runner.py:411] Time since start: 183844.18s, 	Step: 377591, 	{'train/accuracy': 0.8890624642372131, 'train/loss': 0.4145684838294983, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 168926.2371172905, 'total_duration': 183844.18452715874, 'accumulated_submission_time': 168926.2371172905, 'accumulated_eval_time': 14867.735316514969, 'accumulated_logging_time': 29.594119548797607}
I0304 14:36:42.726266 140239850956544 logging_writer.py:48] [377591] accumulated_eval_time=14867.735317, accumulated_logging_time=29.594120, accumulated_submission_time=168926.237117, global_step=377591, preemption_count=0, score=168926.237117, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=183844.184527, train/accuracy=0.889062, train/loss=0.414568, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 14:36:46.690579 140239842563840 logging_writer.py:48] [377600] global_step=377600, grad_norm=2.7956626415252686, loss=1.2766122817993164
I0304 14:37:28.469005 140239850956544 logging_writer.py:48] [377700] global_step=377700, grad_norm=3.209444284439087, loss=1.0580050945281982
I0304 14:38:13.782846 140239842563840 logging_writer.py:48] [377800] global_step=377800, grad_norm=3.1995649337768555, loss=2.1582770347595215
I0304 14:38:59.291446 140239850956544 logging_writer.py:48] [377900] global_step=377900, grad_norm=2.9828829765319824, loss=2.503732681274414
I0304 14:39:44.265636 140239842563840 logging_writer.py:48] [378000] global_step=378000, grad_norm=4.418544769287109, loss=3.206043004989624
I0304 14:40:29.510331 140239850956544 logging_writer.py:48] [378100] global_step=378100, grad_norm=3.135039806365967, loss=1.129329800605774
I0304 14:41:14.754785 140239842563840 logging_writer.py:48] [378200] global_step=378200, grad_norm=2.884023666381836, loss=1.596388578414917
I0304 14:41:59.973592 140239850956544 logging_writer.py:48] [378300] global_step=378300, grad_norm=2.931830883026123, loss=1.430358648300171
I0304 14:42:45.250778 140239842563840 logging_writer.py:48] [378400] global_step=378400, grad_norm=3.2063045501708984, loss=2.801234006881714
I0304 14:43:30.417406 140239850956544 logging_writer.py:48] [378500] global_step=378500, grad_norm=3.0084893703460693, loss=2.4917871952056885
I0304 14:43:42.682562 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:43:52.947614 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:44:23.085096 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:44:24.707155 140437341357888 submission_runner.py:411] Time since start: 184306.26s, 	Step: 378529, 	{'train/accuracy': 0.8909765481948853, 'train/loss': 0.41091883182525635, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 169346.13319802284, 'total_duration': 184306.2586414814, 'accumulated_submission_time': 169346.13319802284, 'accumulated_eval_time': 14909.759913921356, 'accumulated_logging_time': 29.696993350982666}
I0304 14:44:24.797328 140239842563840 logging_writer.py:48] [378529] accumulated_eval_time=14909.759914, accumulated_logging_time=29.696993, accumulated_submission_time=169346.133198, global_step=378529, preemption_count=0, score=169346.133198, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=184306.258641, train/accuracy=0.890977, train/loss=0.410919, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 14:44:53.336366 140239850956544 logging_writer.py:48] [378600] global_step=378600, grad_norm=3.217273712158203, loss=1.7114665508270264
I0304 14:45:38.077203 140239842563840 logging_writer.py:48] [378700] global_step=378700, grad_norm=3.044041156768799, loss=1.0853164196014404
I0304 14:46:23.134498 140239850956544 logging_writer.py:48] [378800] global_step=378800, grad_norm=2.987935781478882, loss=1.8687578439712524
I0304 14:47:09.003723 140239842563840 logging_writer.py:48] [378900] global_step=378900, grad_norm=3.6312637329101562, loss=3.210515260696411
I0304 14:47:54.110431 140239850956544 logging_writer.py:48] [379000] global_step=379000, grad_norm=2.9473729133605957, loss=1.8838093280792236
I0304 14:48:39.805222 140239842563840 logging_writer.py:48] [379100] global_step=379100, grad_norm=2.977311134338379, loss=1.1385297775268555
I0304 14:49:25.089440 140239850956544 logging_writer.py:48] [379200] global_step=379200, grad_norm=3.465968132019043, loss=1.0929218530654907
I0304 14:50:10.359696 140239842563840 logging_writer.py:48] [379300] global_step=379300, grad_norm=3.023210048675537, loss=1.3903429508209229
I0304 14:50:55.512293 140239850956544 logging_writer.py:48] [379400] global_step=379400, grad_norm=2.944765329360962, loss=1.6488609313964844
I0304 14:51:25.045697 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:51:35.180879 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:52:05.141876 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:52:06.780786 140437341357888 submission_runner.py:411] Time since start: 184768.33s, 	Step: 379467, 	{'train/accuracy': 0.8854491710662842, 'train/loss': 0.42224425077438354, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 169766.32176852226, 'total_duration': 184768.3322675228, 'accumulated_submission_time': 169766.32176852226, 'accumulated_eval_time': 14951.494970560074, 'accumulated_logging_time': 29.796590089797974}
I0304 14:52:06.886938 140239842563840 logging_writer.py:48] [379467] accumulated_eval_time=14951.494971, accumulated_logging_time=29.796590, accumulated_submission_time=169766.321769, global_step=379467, preemption_count=0, score=169766.321769, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=184768.332268, train/accuracy=0.885449, train/loss=0.422244, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 14:52:20.389761 140239850956544 logging_writer.py:48] [379500] global_step=379500, grad_norm=3.049673080444336, loss=1.185678482055664
I0304 14:53:02.545203 140239842563840 logging_writer.py:48] [379600] global_step=379600, grad_norm=3.703773260116577, loss=3.1672751903533936
I0304 14:53:47.592968 140239850956544 logging_writer.py:48] [379700] global_step=379700, grad_norm=3.106123924255371, loss=1.1217396259307861
I0304 14:54:32.874218 140239842563840 logging_writer.py:48] [379800] global_step=379800, grad_norm=2.9645700454711914, loss=1.3946430683135986
I0304 14:55:18.038078 140239850956544 logging_writer.py:48] [379900] global_step=379900, grad_norm=3.4519972801208496, loss=2.889219045639038
I0304 14:56:02.975138 140239842563840 logging_writer.py:48] [380000] global_step=380000, grad_norm=3.4085822105407715, loss=1.1812635660171509
I0304 14:56:47.951896 140239850956544 logging_writer.py:48] [380100] global_step=380100, grad_norm=3.033895492553711, loss=1.2285749912261963
I0304 14:57:33.060051 140239842563840 logging_writer.py:48] [380200] global_step=380200, grad_norm=2.886594295501709, loss=2.4760918617248535
I0304 14:58:18.330334 140239850956544 logging_writer.py:48] [380300] global_step=380300, grad_norm=3.083850622177124, loss=2.0775985717773438
I0304 14:59:03.575933 140239842563840 logging_writer.py:48] [380400] global_step=380400, grad_norm=3.388856887817383, loss=1.1822941303253174
I0304 14:59:06.899789 140437341357888 spec.py:321] Evaluating on the training split.
I0304 14:59:17.148718 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 14:59:42.544024 140437341357888 spec.py:349] Evaluating on the test split.
I0304 14:59:44.169773 140437341357888 submission_runner.py:411] Time since start: 185225.72s, 	Step: 380409, 	{'train/accuracy': 0.8866991996765137, 'train/loss': 0.4186405539512634, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 170186.26800489426, 'total_duration': 185225.72126054764, 'accumulated_submission_time': 170186.26800489426, 'accumulated_eval_time': 14988.764938354492, 'accumulated_logging_time': 29.917121410369873}
I0304 14:59:44.260923 140239850956544 logging_writer.py:48] [380409] accumulated_eval_time=14988.764938, accumulated_logging_time=29.917121, accumulated_submission_time=170186.268005, global_step=380409, preemption_count=0, score=170186.268005, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=185225.721261, train/accuracy=0.886699, train/loss=0.418641, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:00:21.712421 140239842563840 logging_writer.py:48] [380500] global_step=380500, grad_norm=3.3011693954467773, loss=1.1099228858947754
I0304 15:01:06.850483 140239850956544 logging_writer.py:48] [380600] global_step=380600, grad_norm=3.2857260704040527, loss=1.299095630645752
I0304 15:01:52.258626 140239842563840 logging_writer.py:48] [380700] global_step=380700, grad_norm=3.110124349594116, loss=1.129885196685791
I0304 15:02:37.327591 140239850956544 logging_writer.py:48] [380800] global_step=380800, grad_norm=4.098719120025635, loss=2.9801151752471924
I0304 15:03:22.939023 140239842563840 logging_writer.py:48] [380900] global_step=380900, grad_norm=2.959808349609375, loss=1.133508563041687
I0304 15:04:08.268160 140239850956544 logging_writer.py:48] [381000] global_step=381000, grad_norm=3.0352864265441895, loss=2.494584560394287
I0304 15:04:53.258109 140239842563840 logging_writer.py:48] [381100] global_step=381100, grad_norm=3.1354820728302, loss=1.3360192775726318
I0304 15:05:38.479178 140239850956544 logging_writer.py:48] [381200] global_step=381200, grad_norm=3.3395650386810303, loss=1.1147054433822632
I0304 15:06:23.494882 140239842563840 logging_writer.py:48] [381300] global_step=381300, grad_norm=3.1738545894622803, loss=1.0779118537902832
I0304 15:06:44.439107 140437341357888 spec.py:321] Evaluating on the training split.
I0304 15:06:55.010626 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 15:07:20.446220 140437341357888 spec.py:349] Evaluating on the test split.
I0304 15:07:22.065383 140437341357888 submission_runner.py:411] Time since start: 185683.62s, 	Step: 381348, 	{'train/accuracy': 0.8898242115974426, 'train/loss': 0.4092896282672882, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 170606.38489556313, 'total_duration': 185683.61686849594, 'accumulated_submission_time': 170606.38489556313, 'accumulated_eval_time': 15026.391194105148, 'accumulated_logging_time': 30.018149852752686}
I0304 15:07:22.157387 140239850956544 logging_writer.py:48] [381348] accumulated_eval_time=15026.391194, accumulated_logging_time=30.018150, accumulated_submission_time=170606.384896, global_step=381348, preemption_count=0, score=170606.384896, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=185683.616868, train/accuracy=0.889824, train/loss=0.409290, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:07:43.158786 140239842563840 logging_writer.py:48] [381400] global_step=381400, grad_norm=3.8032329082489014, loss=3.324860095977783
I0304 15:08:27.506735 140239850956544 logging_writer.py:48] [381500] global_step=381500, grad_norm=3.0033435821533203, loss=2.42103910446167
I0304 15:09:12.876922 140239842563840 logging_writer.py:48] [381600] global_step=381600, grad_norm=3.3064656257629395, loss=1.1135344505310059
I0304 15:09:57.871603 140239850956544 logging_writer.py:48] [381700] global_step=381700, grad_norm=3.6979784965515137, loss=2.935568332672119
I0304 15:10:43.091388 140239842563840 logging_writer.py:48] [381800] global_step=381800, grad_norm=3.2653961181640625, loss=1.284804344177246
I0304 15:11:28.269262 140239850956544 logging_writer.py:48] [381900] global_step=381900, grad_norm=3.129885673522949, loss=1.253348469734192
I0304 15:12:13.501410 140239842563840 logging_writer.py:48] [382000] global_step=382000, grad_norm=2.949629068374634, loss=1.6781803369522095
I0304 15:12:58.707156 140239850956544 logging_writer.py:48] [382100] global_step=382100, grad_norm=2.8440754413604736, loss=1.4289259910583496
I0304 15:13:43.787917 140239842563840 logging_writer.py:48] [382200] global_step=382200, grad_norm=2.7229840755462646, loss=1.4629452228546143
I0304 15:14:22.474482 140437341357888 spec.py:321] Evaluating on the training split.
I0304 15:14:32.750031 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 15:15:03.020058 140437341357888 spec.py:349] Evaluating on the test split.
I0304 15:15:04.641388 140437341357888 submission_runner.py:411] Time since start: 186146.19s, 	Step: 382287, 	{'train/accuracy': 0.8888476490974426, 'train/loss': 0.4133008122444153, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 171026.64174222946, 'total_duration': 186146.19286894798, 'accumulated_submission_time': 171026.64174222946, 'accumulated_eval_time': 15068.558099269867, 'accumulated_logging_time': 30.119590759277344}
I0304 15:15:04.732554 140239850956544 logging_writer.py:48] [382287] accumulated_eval_time=15068.558099, accumulated_logging_time=30.119591, accumulated_submission_time=171026.641742, global_step=382287, preemption_count=0, score=171026.641742, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=186146.192869, train/accuracy=0.888848, train/loss=0.413301, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:15:10.285279 140239842563840 logging_writer.py:48] [382300] global_step=382300, grad_norm=2.9199318885803223, loss=2.021846055984497
I0304 15:15:51.987325 140239850956544 logging_writer.py:48] [382400] global_step=382400, grad_norm=3.2992331981658936, loss=1.115097165107727
I0304 15:16:37.625268 140239842563840 logging_writer.py:48] [382500] global_step=382500, grad_norm=3.0773963928222656, loss=1.1940275430679321
I0304 15:17:23.245008 140239850956544 logging_writer.py:48] [382600] global_step=382600, grad_norm=3.2782809734344482, loss=1.4004533290863037
I0304 15:18:08.746515 140239842563840 logging_writer.py:48] [382700] global_step=382700, grad_norm=3.3759469985961914, loss=2.935559034347534
I0304 15:18:54.053828 140239850956544 logging_writer.py:48] [382800] global_step=382800, grad_norm=3.7467567920684814, loss=2.76348876953125
I0304 15:19:39.741403 140239842563840 logging_writer.py:48] [382900] global_step=382900, grad_norm=2.9745707511901855, loss=1.5203747749328613
I0304 15:20:24.850773 140239850956544 logging_writer.py:48] [383000] global_step=383000, grad_norm=3.007206678390503, loss=1.465340256690979
I0304 15:21:10.164079 140239842563840 logging_writer.py:48] [383100] global_step=383100, grad_norm=2.992044448852539, loss=2.322141170501709
I0304 15:21:55.151640 140239850956544 logging_writer.py:48] [383200] global_step=383200, grad_norm=3.144421339035034, loss=1.459602952003479
I0304 15:22:04.891517 140437341357888 spec.py:321] Evaluating on the training split.
I0304 15:22:15.226107 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 15:22:43.261521 140437341357888 spec.py:349] Evaluating on the test split.
I0304 15:22:44.883026 140437341357888 submission_runner.py:411] Time since start: 186606.43s, 	Step: 383223, 	{'train/accuracy': 0.8874022960662842, 'train/loss': 0.41682925820350647, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 171446.73694324493, 'total_duration': 186606.4345138073, 'accumulated_submission_time': 171446.73694324493, 'accumulated_eval_time': 15108.549597740173, 'accumulated_logging_time': 30.223318576812744}
I0304 15:22:44.975665 140239842563840 logging_writer.py:48] [383223] accumulated_eval_time=15108.549598, accumulated_logging_time=30.223319, accumulated_submission_time=171446.736943, global_step=383223, preemption_count=0, score=171446.736943, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=186606.434514, train/accuracy=0.887402, train/loss=0.416829, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:23:16.142241 140239850956544 logging_writer.py:48] [383300] global_step=383300, grad_norm=3.1288604736328125, loss=1.3733397722244263
I0304 15:24:01.194332 140239842563840 logging_writer.py:48] [383400] global_step=383400, grad_norm=2.8340609073638916, loss=1.0711536407470703
I0304 15:24:46.376558 140239850956544 logging_writer.py:48] [383500] global_step=383500, grad_norm=2.8763179779052734, loss=1.3041722774505615
I0304 15:25:31.661306 140239842563840 logging_writer.py:48] [383600] global_step=383600, grad_norm=2.6914429664611816, loss=1.651060700416565
I0304 15:26:16.966953 140239850956544 logging_writer.py:48] [383700] global_step=383700, grad_norm=2.890381097793579, loss=1.5095561742782593
I0304 15:27:02.271225 140239842563840 logging_writer.py:48] [383800] global_step=383800, grad_norm=3.147163152694702, loss=2.2570953369140625
I0304 15:27:47.180556 140239850956544 logging_writer.py:48] [383900] global_step=383900, grad_norm=3.200807571411133, loss=1.2968567609786987
I0304 15:28:32.530499 140239842563840 logging_writer.py:48] [384000] global_step=384000, grad_norm=3.105323314666748, loss=1.1359567642211914
I0304 15:29:18.145585 140239850956544 logging_writer.py:48] [384100] global_step=384100, grad_norm=2.9120991230010986, loss=1.2000095844268799
I0304 15:29:44.919809 140437341357888 spec.py:321] Evaluating on the training split.
I0304 15:29:55.201777 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 15:30:25.149693 140437341357888 spec.py:349] Evaluating on the test split.
I0304 15:30:26.762454 140437341357888 submission_runner.py:411] Time since start: 187068.31s, 	Step: 384161, 	{'train/accuracy': 0.8870702981948853, 'train/loss': 0.42220020294189453, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 171866.6207382679, 'total_duration': 187068.31393790245, 'accumulated_submission_time': 171866.6207382679, 'accumulated_eval_time': 15150.392226219177, 'accumulated_logging_time': 30.326022624969482}
I0304 15:30:26.855513 140239842563840 logging_writer.py:48] [384161] accumulated_eval_time=15150.392226, accumulated_logging_time=30.326023, accumulated_submission_time=171866.620738, global_step=384161, preemption_count=0, score=171866.620738, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=187068.313938, train/accuracy=0.887070, train/loss=0.422200, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:30:42.710395 140239850956544 logging_writer.py:48] [384200] global_step=384200, grad_norm=2.88391375541687, loss=2.390209674835205
I0304 15:31:25.926839 140239842563840 logging_writer.py:48] [384300] global_step=384300, grad_norm=3.9282476902008057, loss=3.3406295776367188
I0304 15:32:11.372203 140239850956544 logging_writer.py:48] [384400] global_step=384400, grad_norm=2.960855484008789, loss=2.3105499744415283
I0304 15:32:56.807718 140239842563840 logging_writer.py:48] [384500] global_step=384500, grad_norm=3.150491952896118, loss=1.2195013761520386
I0304 15:33:41.938667 140239850956544 logging_writer.py:48] [384600] global_step=384600, grad_norm=3.6478965282440186, loss=3.2894461154937744
I0304 15:34:27.271557 140239842563840 logging_writer.py:48] [384700] global_step=384700, grad_norm=2.9938623905181885, loss=2.1923325061798096
I0304 15:35:12.382365 140239850956544 logging_writer.py:48] [384800] global_step=384800, grad_norm=2.8699893951416016, loss=1.0559089183807373
I0304 15:35:57.497462 140239842563840 logging_writer.py:48] [384900] global_step=384900, grad_norm=3.835155963897705, loss=3.0277843475341797
I0304 15:36:42.866192 140239850956544 logging_writer.py:48] [385000] global_step=385000, grad_norm=3.233245372772217, loss=1.0794801712036133
I0304 15:37:26.973255 140437341357888 spec.py:321] Evaluating on the training split.
I0304 15:37:37.229121 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 15:38:00.892131 140437341357888 spec.py:349] Evaluating on the test split.
I0304 15:38:02.519080 140437341357888 submission_runner.py:411] Time since start: 187524.07s, 	Step: 385099, 	{'train/accuracy': 0.8860937356948853, 'train/loss': 0.41773977875709534, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 172286.67732286453, 'total_duration': 187524.0705358982, 'accumulated_submission_time': 172286.67732286453, 'accumulated_eval_time': 15185.938012599945, 'accumulated_logging_time': 30.430259704589844}
I0304 15:38:02.609379 140239842563840 logging_writer.py:48] [385099] accumulated_eval_time=15185.938013, accumulated_logging_time=30.430260, accumulated_submission_time=172286.677323, global_step=385099, preemption_count=0, score=172286.677323, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=187524.070536, train/accuracy=0.886094, train/loss=0.417740, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:38:03.426779 140239850956544 logging_writer.py:48] [385100] global_step=385100, grad_norm=2.959336042404175, loss=2.2931509017944336
I0304 15:38:44.789057 140239842563840 logging_writer.py:48] [385200] global_step=385200, grad_norm=3.030278205871582, loss=2.575861692428589
I0304 15:39:30.323906 140239850956544 logging_writer.py:48] [385300] global_step=385300, grad_norm=2.900212049484253, loss=1.4087473154067993
I0304 15:40:15.824929 140239842563840 logging_writer.py:48] [385400] global_step=385400, grad_norm=2.971242904663086, loss=1.3043431043624878
I0304 15:41:00.808851 140239850956544 logging_writer.py:48] [385500] global_step=385500, grad_norm=2.8893866539001465, loss=1.2351698875427246
I0304 15:41:45.976161 140239842563840 logging_writer.py:48] [385600] global_step=385600, grad_norm=2.851018190383911, loss=1.4890538454055786
I0304 15:42:31.348229 140239850956544 logging_writer.py:48] [385700] global_step=385700, grad_norm=3.1227364540100098, loss=1.4142963886260986
I0304 15:43:16.619752 140239842563840 logging_writer.py:48] [385800] global_step=385800, grad_norm=3.846850633621216, loss=1.1530401706695557
I0304 15:44:02.056293 140239850956544 logging_writer.py:48] [385900] global_step=385900, grad_norm=3.1126794815063477, loss=1.1132670640945435
I0304 15:44:47.204826 140239842563840 logging_writer.py:48] [386000] global_step=386000, grad_norm=2.753357172012329, loss=1.618498682975769
I0304 15:45:02.673874 140437341357888 spec.py:321] Evaluating on the training split.
I0304 15:45:13.106764 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 15:45:41.586142 140437341357888 spec.py:349] Evaluating on the test split.
I0304 15:45:43.214927 140437341357888 submission_runner.py:411] Time since start: 187984.77s, 	Step: 386036, 	{'train/accuracy': 0.89013671875, 'train/loss': 0.4076444208621979, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 172706.67554998398, 'total_duration': 187984.76641225815, 'accumulated_submission_time': 172706.67554998398, 'accumulated_eval_time': 15226.47905087471, 'accumulated_logging_time': 30.53153157234192}
I0304 15:45:43.306852 140239850956544 logging_writer.py:48] [386036] accumulated_eval_time=15226.479051, accumulated_logging_time=30.531532, accumulated_submission_time=172706.675550, global_step=386036, preemption_count=0, score=172706.675550, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=187984.766412, train/accuracy=0.890137, train/loss=0.407644, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:46:09.053642 140239842563840 logging_writer.py:48] [386100] global_step=386100, grad_norm=2.9248838424682617, loss=1.7698100805282593
I0304 15:46:53.529795 140239850956544 logging_writer.py:48] [386200] global_step=386200, grad_norm=2.894101619720459, loss=1.050849199295044
I0304 15:47:39.111825 140239842563840 logging_writer.py:48] [386300] global_step=386300, grad_norm=3.023829698562622, loss=1.2135145664215088
I0304 15:48:24.454500 140239850956544 logging_writer.py:48] [386400] global_step=386400, grad_norm=3.250857353210449, loss=2.547393321990967
I0304 15:49:09.540015 140239842563840 logging_writer.py:48] [386500] global_step=386500, grad_norm=2.7169876098632812, loss=1.016928791999817
I0304 15:49:55.097297 140239850956544 logging_writer.py:48] [386600] global_step=386600, grad_norm=3.753281354904175, loss=3.2008228302001953
I0304 15:50:40.090791 140239842563840 logging_writer.py:48] [386700] global_step=386700, grad_norm=3.8279473781585693, loss=3.278918504714966
I0304 15:51:25.405220 140239850956544 logging_writer.py:48] [386800] global_step=386800, grad_norm=3.1807918548583984, loss=1.057641625404358
I0304 15:52:10.771112 140239842563840 logging_writer.py:48] [386900] global_step=386900, grad_norm=3.1403892040252686, loss=1.0968701839447021
I0304 15:52:43.309970 140437341357888 spec.py:321] Evaluating on the training split.
I0304 15:52:53.428933 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 15:53:21.567578 140437341357888 spec.py:349] Evaluating on the test split.
I0304 15:53:23.190822 140437341357888 submission_runner.py:411] Time since start: 188444.74s, 	Step: 386974, 	{'train/accuracy': 0.8879687190055847, 'train/loss': 0.42172208428382874, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 173126.61281085014, 'total_duration': 188444.74231219292, 'accumulated_submission_time': 173126.61281085014, 'accumulated_eval_time': 15266.359908103943, 'accumulated_logging_time': 30.636120319366455}
I0304 15:53:23.286072 140239850956544 logging_writer.py:48] [386974] accumulated_eval_time=15266.359908, accumulated_logging_time=30.636120, accumulated_submission_time=173126.612811, global_step=386974, preemption_count=0, score=173126.612811, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=188444.742312, train/accuracy=0.887969, train/loss=0.421722, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 15:53:34.009299 140239842563840 logging_writer.py:48] [387000] global_step=387000, grad_norm=3.185082197189331, loss=2.192715644836426
I0304 15:54:16.726453 140239850956544 logging_writer.py:48] [387100] global_step=387100, grad_norm=3.3104937076568604, loss=2.5490028858184814
I0304 15:55:02.031015 140239842563840 logging_writer.py:48] [387200] global_step=387200, grad_norm=2.900158166885376, loss=1.2822201251983643
I0304 15:55:47.318227 140239850956544 logging_writer.py:48] [387300] global_step=387300, grad_norm=3.300288200378418, loss=2.6473398208618164
I0304 15:56:32.583428 140239842563840 logging_writer.py:48] [387400] global_step=387400, grad_norm=3.0379531383514404, loss=1.1898083686828613
I0304 15:57:17.871842 140239850956544 logging_writer.py:48] [387500] global_step=387500, grad_norm=3.0387372970581055, loss=1.8697961568832397
I0304 15:58:03.128205 140239842563840 logging_writer.py:48] [387600] global_step=387600, grad_norm=3.2442944049835205, loss=1.1995302438735962
I0304 15:58:48.299047 140239850956544 logging_writer.py:48] [387700] global_step=387700, grad_norm=3.1649389266967773, loss=1.0878746509552002
I0304 15:59:33.643555 140239842563840 logging_writer.py:48] [387800] global_step=387800, grad_norm=3.2127785682678223, loss=2.1712160110473633
I0304 16:00:19.332134 140239850956544 logging_writer.py:48] [387900] global_step=387900, grad_norm=2.859469413757324, loss=2.3408045768737793
I0304 16:00:23.508275 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:00:33.852447 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:01:03.112346 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:01:04.747062 140437341357888 submission_runner.py:411] Time since start: 188906.30s, 	Step: 387911, 	{'train/accuracy': 0.888671875, 'train/loss': 0.41331568360328674, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 173546.7705936432, 'total_duration': 188906.29854869843, 'accumulated_submission_time': 173546.7705936432, 'accumulated_eval_time': 15307.598673582077, 'accumulated_logging_time': 30.744555711746216}
I0304 16:01:04.838276 140239842563840 logging_writer.py:48] [387911] accumulated_eval_time=15307.598674, accumulated_logging_time=30.744556, accumulated_submission_time=173546.770594, global_step=387911, preemption_count=0, score=173546.770594, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=188906.298549, train/accuracy=0.888672, train/loss=0.413316, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:01:41.132920 140239850956544 logging_writer.py:48] [388000] global_step=388000, grad_norm=2.934964656829834, loss=1.3235589265823364
I0304 16:02:26.299032 140239842563840 logging_writer.py:48] [388100] global_step=388100, grad_norm=3.124336004257202, loss=2.587080955505371
I0304 16:03:11.967967 140239850956544 logging_writer.py:48] [388200] global_step=388200, grad_norm=2.8645894527435303, loss=1.7410906553268433
I0304 16:03:57.084292 140239842563840 logging_writer.py:48] [388300] global_step=388300, grad_norm=2.8351151943206787, loss=1.6589144468307495
I0304 16:04:42.602911 140239850956544 logging_writer.py:48] [388400] global_step=388400, grad_norm=3.1237375736236572, loss=1.144679069519043
I0304 16:05:27.954635 140239842563840 logging_writer.py:48] [388500] global_step=388500, grad_norm=3.118257761001587, loss=1.4503424167633057
I0304 16:06:13.371225 140239850956544 logging_writer.py:48] [388600] global_step=388600, grad_norm=3.2052183151245117, loss=1.639864444732666
I0304 16:06:58.820406 140239842563840 logging_writer.py:48] [388700] global_step=388700, grad_norm=2.8206496238708496, loss=1.0572969913482666
I0304 16:07:44.100450 140239850956544 logging_writer.py:48] [388800] global_step=388800, grad_norm=3.2213780879974365, loss=1.9236866235733032
I0304 16:08:05.184031 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:08:15.423151 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:08:40.051006 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:08:41.685085 140437341357888 submission_runner.py:411] Time since start: 189363.24s, 	Step: 388848, 	{'train/accuracy': 0.8880078196525574, 'train/loss': 0.4169968068599701, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 173967.05476927757, 'total_duration': 189363.23657369614, 'accumulated_submission_time': 173967.05476927757, 'accumulated_eval_time': 15344.09970164299, 'accumulated_logging_time': 30.845953226089478}
I0304 16:08:41.779181 140239842563840 logging_writer.py:48] [388848] accumulated_eval_time=15344.099702, accumulated_logging_time=30.845953, accumulated_submission_time=173967.054769, global_step=388848, preemption_count=0, score=173967.054769, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=189363.236574, train/accuracy=0.888008, train/loss=0.416997, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:09:02.850339 140239850956544 logging_writer.py:48] [388900] global_step=388900, grad_norm=2.847285747528076, loss=1.0613317489624023
I0304 16:09:46.630776 140239842563840 logging_writer.py:48] [389000] global_step=389000, grad_norm=2.8422536849975586, loss=2.0130422115325928
I0304 16:10:32.511868 140239850956544 logging_writer.py:48] [389100] global_step=389100, grad_norm=2.9602251052856445, loss=1.5536729097366333
I0304 16:11:17.743273 140239842563840 logging_writer.py:48] [389200] global_step=389200, grad_norm=3.364312171936035, loss=1.1620656251907349
I0304 16:12:02.752171 140239850956544 logging_writer.py:48] [389300] global_step=389300, grad_norm=2.7833192348480225, loss=1.0244897603988647
I0304 16:12:48.119157 140239842563840 logging_writer.py:48] [389400] global_step=389400, grad_norm=3.3291070461273193, loss=1.1763312816619873
I0304 16:13:33.321218 140239850956544 logging_writer.py:48] [389500] global_step=389500, grad_norm=3.005122423171997, loss=1.8371121883392334
I0304 16:14:18.711606 140239842563840 logging_writer.py:48] [389600] global_step=389600, grad_norm=3.092526912689209, loss=2.450443983078003
I0304 16:15:04.004553 140239850956544 logging_writer.py:48] [389700] global_step=389700, grad_norm=3.0022940635681152, loss=2.3708300590515137
I0304 16:15:42.054374 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:15:52.460322 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:16:21.550323 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:16:23.172511 140437341357888 submission_runner.py:411] Time since start: 189824.72s, 	Step: 389786, 	{'train/accuracy': 0.8884570002555847, 'train/loss': 0.4161718785762787, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 174387.26860404015, 'total_duration': 189824.72399759293, 'accumulated_submission_time': 174387.26860404015, 'accumulated_eval_time': 15385.21784043312, 'accumulated_logging_time': 30.950018405914307}
I0304 16:16:23.266406 140239842563840 logging_writer.py:48] [389786] accumulated_eval_time=15385.217840, accumulated_logging_time=30.950018, accumulated_submission_time=174387.268604, global_step=389786, preemption_count=0, score=174387.268604, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=189824.723998, train/accuracy=0.888457, train/loss=0.416172, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:16:29.215158 140239850956544 logging_writer.py:48] [389800] global_step=389800, grad_norm=2.8280699253082275, loss=1.968493103981018
I0304 16:17:11.340460 140239842563840 logging_writer.py:48] [389900] global_step=389900, grad_norm=3.551896095275879, loss=1.2152504920959473
I0304 16:17:56.323717 140239850956544 logging_writer.py:48] [390000] global_step=390000, grad_norm=3.15963077545166, loss=1.4533429145812988
I0304 16:18:41.645187 140239842563840 logging_writer.py:48] [390100] global_step=390100, grad_norm=3.5125696659088135, loss=1.771604061126709
I0304 16:19:26.756855 140239850956544 logging_writer.py:48] [390200] global_step=390200, grad_norm=2.9835071563720703, loss=2.2309763431549072
I0304 16:20:11.898747 140239842563840 logging_writer.py:48] [390300] global_step=390300, grad_norm=3.0992302894592285, loss=1.3931113481521606
I0304 16:20:57.312142 140239850956544 logging_writer.py:48] [390400] global_step=390400, grad_norm=3.0954530239105225, loss=1.1700334548950195
I0304 16:21:42.274052 140239842563840 logging_writer.py:48] [390500] global_step=390500, grad_norm=3.9304261207580566, loss=3.1155290603637695
I0304 16:22:27.365725 140239850956544 logging_writer.py:48] [390600] global_step=390600, grad_norm=3.3743748664855957, loss=2.7366552352905273
I0304 16:23:12.503205 140239842563840 logging_writer.py:48] [390700] global_step=390700, grad_norm=2.9404361248016357, loss=1.1009403467178345
I0304 16:23:23.355496 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:23:33.554775 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:24:05.073075 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:24:06.717873 140437341357888 submission_runner.py:411] Time since start: 190288.27s, 	Step: 390726, 	{'train/accuracy': 0.8868359327316284, 'train/loss': 0.41680166125297546, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 174807.295296669, 'total_duration': 190288.2693283558, 'accumulated_submission_time': 174807.295296669, 'accumulated_eval_time': 15428.580172777176, 'accumulated_logging_time': 31.055320739746094}
I0304 16:24:06.864405 140239850956544 logging_writer.py:48] [390726] accumulated_eval_time=15428.580173, accumulated_logging_time=31.055321, accumulated_submission_time=174807.295297, global_step=390726, preemption_count=0, score=174807.295297, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=190288.269328, train/accuracy=0.886836, train/loss=0.416802, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:24:36.598319 140239842563840 logging_writer.py:48] [390800] global_step=390800, grad_norm=3.273995876312256, loss=1.0440905094146729
I0304 16:25:20.666902 140239850956544 logging_writer.py:48] [390900] global_step=390900, grad_norm=3.7631964683532715, loss=3.217360258102417
I0304 16:26:06.181828 140239842563840 logging_writer.py:48] [391000] global_step=391000, grad_norm=3.9835469722747803, loss=2.484572649002075
I0304 16:26:51.314116 140239850956544 logging_writer.py:48] [391100] global_step=391100, grad_norm=2.9946677684783936, loss=1.2382988929748535
I0304 16:27:36.811526 140239842563840 logging_writer.py:48] [391200] global_step=391200, grad_norm=3.5064594745635986, loss=2.968039035797119
I0304 16:28:22.325496 140239850956544 logging_writer.py:48] [391300] global_step=391300, grad_norm=2.8321197032928467, loss=1.9605827331542969
I0304 16:29:07.380564 140239842563840 logging_writer.py:48] [391400] global_step=391400, grad_norm=3.123626232147217, loss=1.173844814300537
I0304 16:29:52.507104 140239850956544 logging_writer.py:48] [391500] global_step=391500, grad_norm=3.1887712478637695, loss=2.6514079570770264
I0304 16:30:37.959839 140239842563840 logging_writer.py:48] [391600] global_step=391600, grad_norm=3.1649367809295654, loss=1.1757681369781494
I0304 16:31:06.780670 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:31:17.050067 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:31:40.181994 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:31:41.809453 140437341357888 submission_runner.py:411] Time since start: 190743.36s, 	Step: 391665, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.4064289629459381, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 175227.144854784, 'total_duration': 190743.3609380722, 'accumulated_submission_time': 175227.144854784, 'accumulated_eval_time': 15463.608940601349, 'accumulated_logging_time': 31.21803855895996}
I0304 16:31:41.904860 140239850956544 logging_writer.py:48] [391665] accumulated_eval_time=15463.608941, accumulated_logging_time=31.218039, accumulated_submission_time=175227.144855, global_step=391665, preemption_count=0, score=175227.144855, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=190743.360938, train/accuracy=0.888906, train/loss=0.406429, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:31:56.202737 140239842563840 logging_writer.py:48] [391700] global_step=391700, grad_norm=2.9339487552642822, loss=1.1292965412139893
I0304 16:32:39.575611 140239850956544 logging_writer.py:48] [391800] global_step=391800, grad_norm=3.120847225189209, loss=1.1036884784698486
I0304 16:33:25.166549 140239842563840 logging_writer.py:48] [391900] global_step=391900, grad_norm=2.938352346420288, loss=0.9990397095680237
I0304 16:34:10.560562 140239850956544 logging_writer.py:48] [392000] global_step=392000, grad_norm=3.0056371688842773, loss=1.177778720855713
I0304 16:34:55.907915 140239842563840 logging_writer.py:48] [392100] global_step=392100, grad_norm=3.388429641723633, loss=2.9952831268310547
I0304 16:35:41.338769 140239850956544 logging_writer.py:48] [392200] global_step=392200, grad_norm=3.337005138397217, loss=1.0610134601593018
I0304 16:36:26.913741 140239842563840 logging_writer.py:48] [392300] global_step=392300, grad_norm=3.3578574657440186, loss=2.201774835586548
I0304 16:37:12.443887 140239850956544 logging_writer.py:48] [392400] global_step=392400, grad_norm=3.143355369567871, loss=1.2373673915863037
I0304 16:37:57.932694 140239842563840 logging_writer.py:48] [392500] global_step=392500, grad_norm=3.0789201259613037, loss=2.1465706825256348
I0304 16:38:42.046715 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:38:52.482908 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:39:20.878688 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:39:22.504664 140437341357888 submission_runner.py:411] Time since start: 191204.06s, 	Step: 392599, 	{'train/accuracy': 0.8891796469688416, 'train/loss': 0.4163433015346527, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 175647.2268936634, 'total_duration': 191204.05614495277, 'accumulated_submission_time': 175647.2268936634, 'accumulated_eval_time': 15504.066883087158, 'accumulated_logging_time': 31.322965621948242}
I0304 16:39:22.599258 140239850956544 logging_writer.py:48] [392599] accumulated_eval_time=15504.066883, accumulated_logging_time=31.322966, accumulated_submission_time=175647.226894, global_step=392599, preemption_count=0, score=175647.226894, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=191204.056145, train/accuracy=0.889180, train/loss=0.416343, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:39:23.393927 140239842563840 logging_writer.py:48] [392600] global_step=392600, grad_norm=3.386552095413208, loss=1.1202455759048462
I0304 16:40:04.831660 140239850956544 logging_writer.py:48] [392700] global_step=392700, grad_norm=2.894448757171631, loss=1.5418376922607422
I0304 16:40:49.992172 140239842563840 logging_writer.py:48] [392800] global_step=392800, grad_norm=3.124945878982544, loss=1.0894595384597778
I0304 16:41:35.664874 140239850956544 logging_writer.py:48] [392900] global_step=392900, grad_norm=3.293757438659668, loss=2.976789712905884
I0304 16:42:20.998056 140239842563840 logging_writer.py:48] [393000] global_step=393000, grad_norm=3.525413751602173, loss=3.1702473163604736
I0304 16:43:06.443434 140239850956544 logging_writer.py:48] [393100] global_step=393100, grad_norm=3.13649320602417, loss=1.1616076231002808
I0304 16:43:51.663814 140239842563840 logging_writer.py:48] [393200] global_step=393200, grad_norm=3.9841079711914062, loss=3.264014482498169
I0304 16:44:36.878474 140239850956544 logging_writer.py:48] [393300] global_step=393300, grad_norm=2.8555991649627686, loss=1.51443350315094
I0304 16:45:21.979336 140239842563840 logging_writer.py:48] [393400] global_step=393400, grad_norm=3.1159965991973877, loss=1.0186856985092163
I0304 16:46:07.121991 140239850956544 logging_writer.py:48] [393500] global_step=393500, grad_norm=3.33393931388855, loss=1.671247959136963
I0304 16:46:22.626143 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:46:33.080956 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:47:02.417602 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:47:04.036538 140437341357888 submission_runner.py:411] Time since start: 191665.59s, 	Step: 393536, 	{'train/accuracy': 0.8873632550239563, 'train/loss': 0.4174995720386505, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 176067.19288492203, 'total_duration': 191665.5880215168, 'accumulated_submission_time': 176067.19288492203, 'accumulated_eval_time': 15545.477265357971, 'accumulated_logging_time': 31.42723274230957}
I0304 16:47:04.130314 140239842563840 logging_writer.py:48] [393536] accumulated_eval_time=15545.477265, accumulated_logging_time=31.427233, accumulated_submission_time=176067.192885, global_step=393536, preemption_count=0, score=176067.192885, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=191665.588022, train/accuracy=0.887363, train/loss=0.417500, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:47:29.908432 140239850956544 logging_writer.py:48] [393600] global_step=393600, grad_norm=2.9217419624328613, loss=1.4581655263900757
I0304 16:48:14.417047 140239842563840 logging_writer.py:48] [393700] global_step=393700, grad_norm=3.5300872325897217, loss=3.1868515014648438
I0304 16:48:59.602725 140239850956544 logging_writer.py:48] [393800] global_step=393800, grad_norm=4.55837345123291, loss=3.2358591556549072
I0304 16:49:45.188479 140239842563840 logging_writer.py:48] [393900] global_step=393900, grad_norm=3.0777883529663086, loss=1.1620975732803345
I0304 16:50:30.041075 140239850956544 logging_writer.py:48] [394000] global_step=394000, grad_norm=2.9946258068084717, loss=2.268782377243042
I0304 16:51:15.634300 140239842563840 logging_writer.py:48] [394100] global_step=394100, grad_norm=2.9635610580444336, loss=1.0922927856445312
I0304 16:52:01.290993 140239850956544 logging_writer.py:48] [394200] global_step=394200, grad_norm=2.8667943477630615, loss=1.3726686239242554
I0304 16:52:46.812675 140239842563840 logging_writer.py:48] [394300] global_step=394300, grad_norm=2.8784778118133545, loss=2.4532766342163086
I0304 16:53:32.049871 140239850956544 logging_writer.py:48] [394400] global_step=394400, grad_norm=3.6045150756835938, loss=1.1091701984405518
I0304 16:54:04.189545 140437341357888 spec.py:321] Evaluating on the training split.
I0304 16:54:14.406351 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 16:54:42.300264 140437341357888 spec.py:349] Evaluating on the test split.
I0304 16:54:43.921896 140437341357888 submission_runner.py:411] Time since start: 192125.47s, 	Step: 394473, 	{'train/accuracy': 0.8908984065055847, 'train/loss': 0.40837523341178894, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 176487.19069099426, 'total_duration': 192125.47338366508, 'accumulated_submission_time': 176487.19069099426, 'accumulated_eval_time': 15585.209602117538, 'accumulated_logging_time': 31.53172993659973}
I0304 16:54:44.017816 140239842563840 logging_writer.py:48] [394473] accumulated_eval_time=15585.209602, accumulated_logging_time=31.531730, accumulated_submission_time=176487.190691, global_step=394473, preemption_count=0, score=176487.190691, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=192125.473384, train/accuracy=0.890898, train/loss=0.408375, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 16:54:55.119874 140239850956544 logging_writer.py:48] [394500] global_step=394500, grad_norm=3.737854480743408, loss=3.318601608276367
I0304 16:55:37.702286 140239842563840 logging_writer.py:48] [394600] global_step=394600, grad_norm=3.024841785430908, loss=1.340339183807373
I0304 16:56:22.994200 140239850956544 logging_writer.py:48] [394700] global_step=394700, grad_norm=2.823716640472412, loss=1.708945631980896
I0304 16:57:08.672535 140239842563840 logging_writer.py:48] [394800] global_step=394800, grad_norm=3.2130112648010254, loss=1.2118337154388428
I0304 16:57:53.663780 140239850956544 logging_writer.py:48] [394900] global_step=394900, grad_norm=3.237370491027832, loss=1.099054217338562
I0304 16:58:38.972009 140239842563840 logging_writer.py:48] [395000] global_step=395000, grad_norm=3.56707763671875, loss=2.8148746490478516
I0304 16:59:24.035244 140239850956544 logging_writer.py:48] [395100] global_step=395100, grad_norm=3.017772674560547, loss=1.5105024576187134
I0304 17:00:09.224434 140239842563840 logging_writer.py:48] [395200] global_step=395200, grad_norm=2.7204809188842773, loss=1.5875715017318726
I0304 17:00:54.151221 140239850956544 logging_writer.py:48] [395300] global_step=395300, grad_norm=3.774198293685913, loss=3.172189235687256
I0304 17:01:39.576674 140239842563840 logging_writer.py:48] [395400] global_step=395400, grad_norm=3.0091495513916016, loss=1.09601628780365
I0304 17:01:44.222198 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:01:54.822448 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:02:28.314415 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:02:29.939776 140437341357888 submission_runner.py:411] Time since start: 192591.49s, 	Step: 395412, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.41814863681793213, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 176907.33445096016, 'total_duration': 192591.49126529694, 'accumulated_submission_time': 176907.33445096016, 'accumulated_eval_time': 15630.927192687988, 'accumulated_logging_time': 31.637397050857544}
I0304 17:02:30.033817 140239850956544 logging_writer.py:48] [395412] accumulated_eval_time=15630.927193, accumulated_logging_time=31.637397, accumulated_submission_time=176907.334451, global_step=395412, preemption_count=0, score=176907.334451, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=192591.491265, train/accuracy=0.887598, train/loss=0.418149, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:03:05.869227 140239842563840 logging_writer.py:48] [395500] global_step=395500, grad_norm=3.0682485103607178, loss=1.1512967348098755
I0304 17:03:50.758256 140239850956544 logging_writer.py:48] [395600] global_step=395600, grad_norm=3.1900975704193115, loss=1.1905699968338013
I0304 17:04:36.183065 140239842563840 logging_writer.py:48] [395700] global_step=395700, grad_norm=3.0993988513946533, loss=1.067713737487793
I0304 17:05:21.456456 140239850956544 logging_writer.py:48] [395800] global_step=395800, grad_norm=3.1332974433898926, loss=2.206965446472168
I0304 17:06:06.611245 140239842563840 logging_writer.py:48] [395900] global_step=395900, grad_norm=3.2082178592681885, loss=1.995789647102356
I0304 17:06:51.829699 140239850956544 logging_writer.py:48] [396000] global_step=396000, grad_norm=3.217890739440918, loss=1.4627909660339355
I0304 17:07:37.018460 140239842563840 logging_writer.py:48] [396100] global_step=396100, grad_norm=2.940621852874756, loss=1.3590577840805054
I0304 17:08:22.140011 140239850956544 logging_writer.py:48] [396200] global_step=396200, grad_norm=3.2980175018310547, loss=2.776585102081299
I0304 17:09:07.290458 140239842563840 logging_writer.py:48] [396300] global_step=396300, grad_norm=3.7159194946289062, loss=3.114004135131836
I0304 17:09:30.096496 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:09:40.292594 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:10:15.120203 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:10:16.750373 140437341357888 submission_runner.py:411] Time since start: 193058.30s, 	Step: 396352, 	{'train/accuracy': 0.8899609446525574, 'train/loss': 0.4101354479789734, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 177327.337089777, 'total_duration': 193058.3018424511, 'accumulated_submission_time': 177327.337089777, 'accumulated_eval_time': 15677.581050395966, 'accumulated_logging_time': 31.74113130569458}
I0304 17:10:16.835038 140239850956544 logging_writer.py:48] [396352] accumulated_eval_time=15677.581050, accumulated_logging_time=31.741131, accumulated_submission_time=177327.337090, global_step=396352, preemption_count=0, score=177327.337090, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=193058.301842, train/accuracy=0.889961, train/loss=0.410135, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:10:36.243764 140239842563840 logging_writer.py:48] [396400] global_step=396400, grad_norm=3.2807838916778564, loss=2.933023452758789
I0304 17:11:18.735876 140239850956544 logging_writer.py:48] [396500] global_step=396500, grad_norm=3.946899652481079, loss=3.316946029663086
I0304 17:12:04.485574 140239842563840 logging_writer.py:48] [396600] global_step=396600, grad_norm=3.5512070655822754, loss=2.8673861026763916
I0304 17:12:49.680455 140239850956544 logging_writer.py:48] [396700] global_step=396700, grad_norm=3.0984842777252197, loss=1.1386816501617432
I0304 17:13:34.632618 140239842563840 logging_writer.py:48] [396800] global_step=396800, grad_norm=2.968703508377075, loss=1.2093886137008667
I0304 17:14:19.861702 140239850956544 logging_writer.py:48] [396900] global_step=396900, grad_norm=3.0579676628112793, loss=1.03725266456604
I0304 17:15:04.850723 140239842563840 logging_writer.py:48] [397000] global_step=397000, grad_norm=3.498649835586548, loss=1.6138654947280884
I0304 17:15:50.196995 140239850956544 logging_writer.py:48] [397100] global_step=397100, grad_norm=3.553257703781128, loss=3.050374984741211
I0304 17:16:35.504922 140239842563840 logging_writer.py:48] [397200] global_step=397200, grad_norm=3.1861870288848877, loss=1.1093837022781372
I0304 17:17:17.106072 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:17:27.498772 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:17:51.234375 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:17:52.854734 140437341357888 submission_runner.py:411] Time since start: 193514.41s, 	Step: 397294, 	{'train/accuracy': 0.8896484375, 'train/loss': 0.41119706630706787, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 177747.5464015007, 'total_duration': 193514.40622234344, 'accumulated_submission_time': 177747.5464015007, 'accumulated_eval_time': 15713.32974267006, 'accumulated_logging_time': 31.83563208580017}
I0304 17:17:52.948828 140239850956544 logging_writer.py:48] [397294] accumulated_eval_time=15713.329743, accumulated_logging_time=31.835632, accumulated_submission_time=177747.546402, global_step=397294, preemption_count=0, score=177747.546402, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=193514.406222, train/accuracy=0.889648, train/loss=0.411197, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:17:55.728560 140239842563840 logging_writer.py:48] [397300] global_step=397300, grad_norm=3.4049930572509766, loss=3.0298376083374023
I0304 17:18:37.498077 140239850956544 logging_writer.py:48] [397400] global_step=397400, grad_norm=3.7652316093444824, loss=3.227109432220459
I0304 17:19:22.691738 140239842563840 logging_writer.py:48] [397500] global_step=397500, grad_norm=2.950721263885498, loss=1.6072108745574951
I0304 17:20:08.154539 140239850956544 logging_writer.py:48] [397600] global_step=397600, grad_norm=3.3823938369750977, loss=1.1148706674575806
I0304 17:20:53.412579 140239842563840 logging_writer.py:48] [397700] global_step=397700, grad_norm=3.058953285217285, loss=2.6607370376586914
I0304 17:21:38.737886 140239850956544 logging_writer.py:48] [397800] global_step=397800, grad_norm=2.9614222049713135, loss=2.468837022781372
I0304 17:22:24.392290 140239842563840 logging_writer.py:48] [397900] global_step=397900, grad_norm=3.0350420475006104, loss=1.1928000450134277
I0304 17:23:09.778435 140239850956544 logging_writer.py:48] [398000] global_step=398000, grad_norm=3.0308401584625244, loss=1.1428418159484863
I0304 17:23:54.912555 140239842563840 logging_writer.py:48] [398100] global_step=398100, grad_norm=3.104851484298706, loss=1.1417585611343384
I0304 17:24:40.161837 140239850956544 logging_writer.py:48] [398200] global_step=398200, grad_norm=3.280627489089966, loss=2.354224920272827
I0304 17:24:52.952703 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:25:04.326005 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:25:28.900849 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:25:30.530165 140437341357888 submission_runner.py:411] Time since start: 193972.08s, 	Step: 398230, 	{'train/accuracy': 0.8900781273841858, 'train/loss': 0.4136282205581665, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 178167.48953986168, 'total_duration': 193972.08164024353, 'accumulated_submission_time': 178167.48953986168, 'accumulated_eval_time': 15750.907168149948, 'accumulated_logging_time': 31.93990921974182}
I0304 17:25:30.625298 140239842563840 logging_writer.py:48] [398230] accumulated_eval_time=15750.907168, accumulated_logging_time=31.939909, accumulated_submission_time=178167.489540, global_step=398230, preemption_count=0, score=178167.489540, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=193972.081640, train/accuracy=0.890078, train/loss=0.413628, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:25:59.130872 140239850956544 logging_writer.py:48] [398300] global_step=398300, grad_norm=3.2709460258483887, loss=1.0912309885025024
I0304 17:26:44.022116 140239842563840 logging_writer.py:48] [398400] global_step=398400, grad_norm=3.4545605182647705, loss=1.1090303659439087
I0304 17:27:29.563204 140239850956544 logging_writer.py:48] [398500] global_step=398500, grad_norm=3.196730613708496, loss=1.18411386013031
I0304 17:28:14.723831 140239842563840 logging_writer.py:48] [398600] global_step=398600, grad_norm=2.836116075515747, loss=1.3472747802734375
I0304 17:28:59.877927 140239850956544 logging_writer.py:48] [398700] global_step=398700, grad_norm=3.048556327819824, loss=1.858893632888794
I0304 17:29:45.080536 140239842563840 logging_writer.py:48] [398800] global_step=398800, grad_norm=2.961408853530884, loss=2.1805243492126465
I0304 17:30:30.106730 140239850956544 logging_writer.py:48] [398900] global_step=398900, grad_norm=2.9824209213256836, loss=1.2200628519058228
I0304 17:31:15.651765 140239842563840 logging_writer.py:48] [399000] global_step=399000, grad_norm=3.1614937782287598, loss=1.725792407989502
I0304 17:32:00.858257 140239850956544 logging_writer.py:48] [399100] global_step=399100, grad_norm=3.0498361587524414, loss=1.9857778549194336
I0304 17:32:30.872460 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:32:41.203542 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:33:14.333223 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:33:15.995798 140437341357888 submission_runner.py:411] Time since start: 194437.55s, 	Step: 399168, 	{'train/accuracy': 0.8863476514816284, 'train/loss': 0.4190600514411926, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 178587.6754131317, 'total_duration': 194437.5472960472, 'accumulated_submission_time': 178587.6754131317, 'accumulated_eval_time': 15796.030497074127, 'accumulated_logging_time': 32.04532527923584}
I0304 17:33:16.074431 140239842563840 logging_writer.py:48] [399168] accumulated_eval_time=15796.030497, accumulated_logging_time=32.045325, accumulated_submission_time=178587.675413, global_step=399168, preemption_count=0, score=178587.675413, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=194437.547296, train/accuracy=0.886348, train/loss=0.419060, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:33:29.159554 140239850956544 logging_writer.py:48] [399200] global_step=399200, grad_norm=2.9732327461242676, loss=2.37227201461792
I0304 17:34:10.692744 140239842563840 logging_writer.py:48] [399300] global_step=399300, grad_norm=2.9603915214538574, loss=1.0654481649398804
I0304 17:34:55.769596 140239850956544 logging_writer.py:48] [399400] global_step=399400, grad_norm=3.1578357219696045, loss=2.6828134059906006
I0304 17:35:41.390679 140239842563840 logging_writer.py:48] [399500] global_step=399500, grad_norm=3.5042991638183594, loss=1.271796464920044
I0304 17:36:26.712561 140239850956544 logging_writer.py:48] [399600] global_step=399600, grad_norm=3.7815070152282715, loss=3.164322853088379
I0304 17:37:12.176009 140239842563840 logging_writer.py:48] [399700] global_step=399700, grad_norm=2.900069236755371, loss=1.1080116033554077
I0304 17:37:57.201245 140239850956544 logging_writer.py:48] [399800] global_step=399800, grad_norm=3.5119857788085938, loss=2.023625612258911
I0304 17:38:42.472229 140239842563840 logging_writer.py:48] [399900] global_step=399900, grad_norm=3.139920949935913, loss=2.497476577758789
I0304 17:39:27.616340 140239850956544 logging_writer.py:48] [400000] global_step=400000, grad_norm=2.988966941833496, loss=1.104905366897583
I0304 17:40:13.212297 140239842563840 logging_writer.py:48] [400100] global_step=400100, grad_norm=3.1208066940307617, loss=2.6999917030334473
I0304 17:40:16.047233 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:40:26.385372 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:40:47.616218 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:40:49.252618 140437341357888 submission_runner.py:411] Time since start: 194890.80s, 	Step: 400108, 	{'train/accuracy': 0.8864257335662842, 'train/loss': 0.42170605063438416, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 179007.58912825584, 'total_duration': 194890.8040919304, 'accumulated_submission_time': 179007.58912825584, 'accumulated_eval_time': 15829.235847234726, 'accumulated_logging_time': 32.13245725631714}
I0304 17:40:49.342821 140239850956544 logging_writer.py:48] [400108] accumulated_eval_time=15829.235847, accumulated_logging_time=32.132457, accumulated_submission_time=179007.589128, global_step=400108, preemption_count=0, score=179007.589128, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=194890.804092, train/accuracy=0.886426, train/loss=0.421706, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:41:27.624939 140239842563840 logging_writer.py:48] [400200] global_step=400200, grad_norm=3.0532937049865723, loss=2.4644570350646973
I0304 17:42:12.796404 140239850956544 logging_writer.py:48] [400300] global_step=400300, grad_norm=3.7929885387420654, loss=3.015017032623291
I0304 17:42:58.332647 140239842563840 logging_writer.py:48] [400400] global_step=400400, grad_norm=4.059046268463135, loss=3.176316261291504
I0304 17:43:43.608626 140239850956544 logging_writer.py:48] [400500] global_step=400500, grad_norm=3.050766706466675, loss=1.568263292312622
I0304 17:44:28.720652 140239842563840 logging_writer.py:48] [400600] global_step=400600, grad_norm=2.8019165992736816, loss=1.1515357494354248
I0304 17:45:13.997571 140239850956544 logging_writer.py:48] [400700] global_step=400700, grad_norm=3.2565183639526367, loss=2.8407626152038574
I0304 17:45:58.947852 140239842563840 logging_writer.py:48] [400800] global_step=400800, grad_norm=2.9870591163635254, loss=1.0933735370635986
I0304 17:46:44.328194 140239850956544 logging_writer.py:48] [400900] global_step=400900, grad_norm=3.046710252761841, loss=1.1222947835922241
I0304 17:47:29.569742 140239842563840 logging_writer.py:48] [401000] global_step=401000, grad_norm=3.3482539653778076, loss=2.751138925552368
I0304 17:47:49.579982 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:48:00.304911 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:48:34.145962 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:48:35.768032 140437341357888 submission_runner.py:411] Time since start: 195357.32s, 	Step: 401046, 	{'train/accuracy': 0.8907226324081421, 'train/loss': 0.4068452715873718, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 179427.76574611664, 'total_duration': 195357.3195183277, 'accumulated_submission_time': 179427.76574611664, 'accumulated_eval_time': 15875.423902750015, 'accumulated_logging_time': 32.232825756073}
I0304 17:48:35.861613 140239850956544 logging_writer.py:48] [401046] accumulated_eval_time=15875.423903, accumulated_logging_time=32.232826, accumulated_submission_time=179427.765746, global_step=401046, preemption_count=0, score=179427.765746, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=195357.319518, train/accuracy=0.890723, train/loss=0.406845, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:48:57.643808 140239842563840 logging_writer.py:48] [401100] global_step=401100, grad_norm=3.1777658462524414, loss=0.9661281108856201
I0304 17:49:41.004582 140239850956544 logging_writer.py:48] [401200] global_step=401200, grad_norm=3.7591047286987305, loss=2.9402718544006348
I0304 17:50:25.998009 140239842563840 logging_writer.py:48] [401300] global_step=401300, grad_norm=3.9585020542144775, loss=3.0854737758636475
I0304 17:51:11.534153 140239850956544 logging_writer.py:48] [401400] global_step=401400, grad_norm=3.026158094406128, loss=1.208492636680603
I0304 17:51:56.498752 140239842563840 logging_writer.py:48] [401500] global_step=401500, grad_norm=2.767139434814453, loss=1.1000499725341797
I0304 17:52:41.814711 140239850956544 logging_writer.py:48] [401600] global_step=401600, grad_norm=2.6672351360321045, loss=1.9186686277389526
I0304 17:53:27.208588 140239842563840 logging_writer.py:48] [401700] global_step=401700, grad_norm=3.2066986560821533, loss=1.3687947988510132
I0304 17:54:12.457505 140239850956544 logging_writer.py:48] [401800] global_step=401800, grad_norm=2.9692814350128174, loss=1.129782795906067
I0304 17:54:57.818246 140239842563840 logging_writer.py:48] [401900] global_step=401900, grad_norm=3.6705801486968994, loss=3.2636494636535645
I0304 17:55:35.922862 140437341357888 spec.py:321] Evaluating on the training split.
I0304 17:55:46.353634 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 17:56:14.623436 140437341357888 spec.py:349] Evaluating on the test split.
I0304 17:56:16.281601 140437341357888 submission_runner.py:411] Time since start: 195817.83s, 	Step: 401986, 	{'train/accuracy': 0.8880859017372131, 'train/loss': 0.41931840777397156, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 179847.76591467857, 'total_duration': 195817.83309102058, 'accumulated_submission_time': 179847.76591467857, 'accumulated_eval_time': 15915.782636880875, 'accumulated_logging_time': 32.33623695373535}
I0304 17:56:16.360530 140239850956544 logging_writer.py:48] [401986] accumulated_eval_time=15915.782637, accumulated_logging_time=32.336237, accumulated_submission_time=179847.765915, global_step=401986, preemption_count=0, score=179847.765915, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=195817.833091, train/accuracy=0.888086, train/loss=0.419318, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 17:56:22.300360 140239842563840 logging_writer.py:48] [402000] global_step=402000, grad_norm=2.861548900604248, loss=1.580243468284607
I0304 17:57:03.277174 140239850956544 logging_writer.py:48] [402100] global_step=402100, grad_norm=3.150606393814087, loss=1.4509844779968262
I0304 17:57:48.405090 140239842563840 logging_writer.py:48] [402200] global_step=402200, grad_norm=3.5270938873291016, loss=2.86629056930542
I0304 17:58:33.912508 140239850956544 logging_writer.py:48] [402300] global_step=402300, grad_norm=3.09724760055542, loss=1.1570632457733154
I0304 17:59:19.203391 140239842563840 logging_writer.py:48] [402400] global_step=402400, grad_norm=3.6690640449523926, loss=3.144594192504883
I0304 18:00:04.831896 140239850956544 logging_writer.py:48] [402500] global_step=402500, grad_norm=3.189584493637085, loss=2.546567440032959
I0304 18:00:49.977605 140239842563840 logging_writer.py:48] [402600] global_step=402600, grad_norm=3.117948293685913, loss=1.2126245498657227
I0304 18:01:35.128905 140239850956544 logging_writer.py:48] [402700] global_step=402700, grad_norm=3.1341054439544678, loss=1.5639421939849854
I0304 18:02:20.577693 140239842563840 logging_writer.py:48] [402800] global_step=402800, grad_norm=3.0815589427948, loss=2.179213047027588
I0304 18:03:06.087885 140239850956544 logging_writer.py:48] [402900] global_step=402900, grad_norm=3.037141799926758, loss=1.1992284059524536
I0304 18:03:16.528957 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:03:27.102303 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:03:53.418876 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:03:55.037765 140437341357888 submission_runner.py:411] Time since start: 196276.59s, 	Step: 402925, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.4192410707473755, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 180267.8737359047, 'total_duration': 196276.5892522335, 'accumulated_submission_time': 180267.8737359047, 'accumulated_eval_time': 15954.291462898254, 'accumulated_logging_time': 32.424152135849}
I0304 18:03:55.135569 140239842563840 logging_writer.py:48] [402925] accumulated_eval_time=15954.291463, accumulated_logging_time=32.424152, accumulated_submission_time=180267.873736, global_step=402925, preemption_count=0, score=180267.873736, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=196276.589252, train/accuracy=0.887383, train/loss=0.419241, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:04:26.243902 140239850956544 logging_writer.py:48] [403000] global_step=403000, grad_norm=3.2689201831817627, loss=2.919626235961914
I0304 18:05:11.523711 140239842563840 logging_writer.py:48] [403100] global_step=403100, grad_norm=3.8597211837768555, loss=3.1792893409729004
I0304 18:05:56.715491 140239850956544 logging_writer.py:48] [403200] global_step=403200, grad_norm=2.910521984100342, loss=1.136324405670166
I0304 18:06:42.451351 140239842563840 logging_writer.py:48] [403300] global_step=403300, grad_norm=3.0937180519104004, loss=1.1935908794403076
I0304 18:07:27.605247 140239850956544 logging_writer.py:48] [403400] global_step=403400, grad_norm=3.208265781402588, loss=1.615929126739502
I0304 18:08:12.958972 140239842563840 logging_writer.py:48] [403500] global_step=403500, grad_norm=3.084001302719116, loss=2.934180736541748
I0304 18:08:58.250263 140239850956544 logging_writer.py:48] [403600] global_step=403600, grad_norm=3.0251107215881348, loss=1.548796534538269
I0304 18:09:43.497817 140239842563840 logging_writer.py:48] [403700] global_step=403700, grad_norm=2.9909896850585938, loss=1.170596718788147
I0304 18:10:28.784367 140239850956544 logging_writer.py:48] [403800] global_step=403800, grad_norm=3.3417859077453613, loss=2.8184409141540527
I0304 18:10:55.138890 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:11:05.888083 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:11:28.927606 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:11:30.541135 140437341357888 submission_runner.py:411] Time since start: 196732.09s, 	Step: 403860, 	{'train/accuracy': 0.8870312571525574, 'train/loss': 0.4160933196544647, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 180687.81717061996, 'total_duration': 196732.09262561798, 'accumulated_submission_time': 180687.81717061996, 'accumulated_eval_time': 15989.69368314743, 'accumulated_logging_time': 32.5312180519104}
I0304 18:11:30.634544 140239842563840 logging_writer.py:48] [403860] accumulated_eval_time=15989.693683, accumulated_logging_time=32.531218, accumulated_submission_time=180687.817171, global_step=403860, preemption_count=0, score=180687.817171, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=196732.092626, train/accuracy=0.887031, train/loss=0.416093, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:11:46.912287 140239850956544 logging_writer.py:48] [403900] global_step=403900, grad_norm=3.2162368297576904, loss=1.2258027791976929
I0304 18:12:30.667889 140239842563840 logging_writer.py:48] [404000] global_step=404000, grad_norm=3.469329833984375, loss=1.8179733753204346
I0304 18:13:15.940243 140239850956544 logging_writer.py:48] [404100] global_step=404100, grad_norm=3.5307137966156006, loss=1.0846624374389648
I0304 18:14:01.319768 140239842563840 logging_writer.py:48] [404200] global_step=404200, grad_norm=3.028371810913086, loss=1.7194585800170898
I0304 18:14:46.440459 140239850956544 logging_writer.py:48] [404300] global_step=404300, grad_norm=3.169389009475708, loss=1.1533536911010742
I0304 18:15:31.924826 140239842563840 logging_writer.py:48] [404400] global_step=404400, grad_norm=3.6773786544799805, loss=3.3004534244537354
I0304 18:16:17.159007 140239850956544 logging_writer.py:48] [404500] global_step=404500, grad_norm=3.2157013416290283, loss=2.305086612701416
I0304 18:17:02.640313 140239842563840 logging_writer.py:48] [404600] global_step=404600, grad_norm=2.865509033203125, loss=1.1396331787109375
I0304 18:17:47.766663 140239850956544 logging_writer.py:48] [404700] global_step=404700, grad_norm=2.877424955368042, loss=1.0644766092300415
I0304 18:18:30.958878 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:18:41.227334 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:19:14.589415 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:19:16.234594 140437341357888 submission_runner.py:411] Time since start: 197197.79s, 	Step: 404797, 	{'train/accuracy': 0.8872265219688416, 'train/loss': 0.4159035086631775, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 181108.08257174492, 'total_duration': 197197.78607559204, 'accumulated_submission_time': 181108.08257174492, 'accumulated_eval_time': 16034.969373941422, 'accumulated_logging_time': 32.63423204421997}
I0304 18:19:16.315262 140239842563840 logging_writer.py:48] [404797] accumulated_eval_time=16034.969374, accumulated_logging_time=32.634232, accumulated_submission_time=181108.082572, global_step=404797, preemption_count=0, score=181108.082572, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=197197.786076, train/accuracy=0.887227, train/loss=0.415904, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:19:17.899219 140239850956544 logging_writer.py:48] [404800] global_step=404800, grad_norm=2.905700206756592, loss=1.3495219945907593
I0304 18:19:58.004535 140239842563840 logging_writer.py:48] [404900] global_step=404900, grad_norm=3.031473159790039, loss=1.5231423377990723
I0304 18:20:42.947116 140239850956544 logging_writer.py:48] [405000] global_step=405000, grad_norm=2.962890148162842, loss=1.7427476644515991
I0304 18:21:28.438923 140239842563840 logging_writer.py:48] [405100] global_step=405100, grad_norm=3.386862277984619, loss=3.096695899963379
I0304 18:22:13.937517 140239850956544 logging_writer.py:48] [405200] global_step=405200, grad_norm=3.2255911827087402, loss=2.780930757522583
I0304 18:22:58.853535 140239842563840 logging_writer.py:48] [405300] global_step=405300, grad_norm=3.494249105453491, loss=1.290879487991333
I0304 18:23:44.402374 140239850956544 logging_writer.py:48] [405400] global_step=405400, grad_norm=3.207443952560425, loss=2.860203504562378
I0304 18:24:29.320219 140239842563840 logging_writer.py:48] [405500] global_step=405500, grad_norm=3.494823455810547, loss=1.1132440567016602
I0304 18:25:14.590599 140239850956544 logging_writer.py:48] [405600] global_step=405600, grad_norm=3.0882925987243652, loss=1.3244847059249878
I0304 18:25:59.870772 140239842563840 logging_writer.py:48] [405700] global_step=405700, grad_norm=3.011293649673462, loss=1.2990225553512573
I0304 18:26:16.236575 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:26:26.328863 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:26:52.566997 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:26:54.196385 140437341357888 submission_runner.py:411] Time since start: 197655.75s, 	Step: 405738, 	{'train/accuracy': 0.8909765481948853, 'train/loss': 0.40668314695358276, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 181527.94424247742, 'total_duration': 197655.74682331085, 'accumulated_submission_time': 181527.94424247742, 'accumulated_eval_time': 16072.9281270504, 'accumulated_logging_time': 32.72395944595337}
I0304 18:26:54.292735 140239850956544 logging_writer.py:48] [405738] accumulated_eval_time=16072.928127, accumulated_logging_time=32.723959, accumulated_submission_time=181527.944242, global_step=405738, preemption_count=0, score=181527.944242, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=197655.746823, train/accuracy=0.890977, train/loss=0.406683, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:27:19.250804 140239842563840 logging_writer.py:48] [405800] global_step=405800, grad_norm=2.8722643852233887, loss=1.0503900051116943
I0304 18:28:03.914279 140239850956544 logging_writer.py:48] [405900] global_step=405900, grad_norm=2.997084140777588, loss=1.979237675666809
I0304 18:28:48.813255 140239842563840 logging_writer.py:48] [406000] global_step=406000, grad_norm=3.0008389949798584, loss=1.1629033088684082
I0304 18:29:34.036633 140239850956544 logging_writer.py:48] [406100] global_step=406100, grad_norm=3.5025627613067627, loss=1.2324317693710327
I0304 18:30:19.160827 140239842563840 logging_writer.py:48] [406200] global_step=406200, grad_norm=2.8817336559295654, loss=2.207014799118042
I0304 18:31:04.200373 140239850956544 logging_writer.py:48] [406300] global_step=406300, grad_norm=3.2099428176879883, loss=1.1862139701843262
I0304 18:31:49.084676 140239842563840 logging_writer.py:48] [406400] global_step=406400, grad_norm=3.4916977882385254, loss=3.038515090942383
I0304 18:32:34.496973 140239850956544 logging_writer.py:48] [406500] global_step=406500, grad_norm=3.206442356109619, loss=1.1109085083007812
I0304 18:33:19.799573 140239842563840 logging_writer.py:48] [406600] global_step=406600, grad_norm=3.21158766746521, loss=1.023117184638977
I0304 18:33:54.460047 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:34:05.153510 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:34:28.917989 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:34:30.539672 140437341357888 submission_runner.py:411] Time since start: 198112.09s, 	Step: 406678, 	{'train/accuracy': 0.8872851133346558, 'train/loss': 0.41612011194229126, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 181948.04838109016, 'total_duration': 198112.09012413025, 'accumulated_submission_time': 181948.04838109016, 'accumulated_eval_time': 16109.006716966629, 'accumulated_logging_time': 32.83241391181946}
I0304 18:34:30.636109 140239850956544 logging_writer.py:48] [406678] accumulated_eval_time=16109.006717, accumulated_logging_time=32.832414, accumulated_submission_time=181948.048381, global_step=406678, preemption_count=0, score=181948.048381, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=198112.090124, train/accuracy=0.887285, train/loss=0.416120, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:34:39.776372 140239842563840 logging_writer.py:48] [406700] global_step=406700, grad_norm=2.969318389892578, loss=1.5139437913894653
I0304 18:35:22.406518 140239850956544 logging_writer.py:48] [406800] global_step=406800, grad_norm=3.111121416091919, loss=1.181602120399475
I0304 18:36:07.839709 140239842563840 logging_writer.py:48] [406900] global_step=406900, grad_norm=2.9274744987487793, loss=2.1976072788238525
I0304 18:36:53.250671 140239850956544 logging_writer.py:48] [407000] global_step=407000, grad_norm=3.9208414554595947, loss=3.204864740371704
I0304 18:37:38.473051 140239842563840 logging_writer.py:48] [407100] global_step=407100, grad_norm=3.1276938915252686, loss=1.6066426038742065
I0304 18:38:23.883754 140239850956544 logging_writer.py:48] [407200] global_step=407200, grad_norm=2.8657150268554688, loss=2.5411417484283447
I0304 18:39:09.238238 140239842563840 logging_writer.py:48] [407300] global_step=407300, grad_norm=3.305621385574341, loss=2.6141834259033203
I0304 18:39:54.531395 140239850956544 logging_writer.py:48] [407400] global_step=407400, grad_norm=3.751521348953247, loss=3.2380409240722656
I0304 18:40:39.870828 140239842563840 logging_writer.py:48] [407500] global_step=407500, grad_norm=2.9741833209991455, loss=1.5509710311889648
I0304 18:41:25.305592 140239850956544 logging_writer.py:48] [407600] global_step=407600, grad_norm=3.1257410049438477, loss=0.9662832021713257
I0304 18:41:30.949098 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:41:41.271530 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:42:19.150562 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:42:20.771060 140437341357888 submission_runner.py:411] Time since start: 198582.32s, 	Step: 407614, 	{'train/accuracy': 0.8865038752555847, 'train/loss': 0.42033588886260986, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 182368.29708647728, 'total_duration': 198582.32165956497, 'accumulated_submission_time': 182368.29708647728, 'accumulated_eval_time': 16158.827764034271, 'accumulated_logging_time': 32.94143462181091}
I0304 18:42:20.848731 140239842563840 logging_writer.py:48] [407614] accumulated_eval_time=16158.827764, accumulated_logging_time=32.941435, accumulated_submission_time=182368.297086, global_step=407614, preemption_count=0, score=182368.297086, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=198582.321660, train/accuracy=0.886504, train/loss=0.420336, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:42:55.289419 140239850956544 logging_writer.py:48] [407700] global_step=407700, grad_norm=3.091017007827759, loss=2.19974946975708
I0304 18:43:39.593103 140239842563840 logging_writer.py:48] [407800] global_step=407800, grad_norm=2.9616122245788574, loss=1.1235301494598389
I0304 18:44:25.560142 140239850956544 logging_writer.py:48] [407900] global_step=407900, grad_norm=3.1095638275146484, loss=1.523601770401001
I0304 18:45:10.960494 140239842563840 logging_writer.py:48] [408000] global_step=408000, grad_norm=3.0275015830993652, loss=1.6242210865020752
I0304 18:45:56.093672 140239850956544 logging_writer.py:48] [408100] global_step=408100, grad_norm=3.1679136753082275, loss=1.8541033267974854
I0304 18:46:41.517736 140239842563840 logging_writer.py:48] [408200] global_step=408200, grad_norm=2.9569578170776367, loss=1.2671723365783691
I0304 18:47:26.693956 140239850956544 logging_writer.py:48] [408300] global_step=408300, grad_norm=3.154049873352051, loss=1.046626329421997
I0304 18:48:11.960069 140239842563840 logging_writer.py:48] [408400] global_step=408400, grad_norm=2.9754385948181152, loss=2.655923366546631
I0304 18:48:57.122689 140239850956544 logging_writer.py:48] [408500] global_step=408500, grad_norm=2.985269069671631, loss=1.3416924476623535
I0304 18:49:20.947386 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:49:31.427546 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:49:58.971230 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:50:00.597675 140437341357888 submission_runner.py:411] Time since start: 199042.15s, 	Step: 408554, 	{'train/accuracy': 0.8880078196525574, 'train/loss': 0.41498419642448425, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 182788.3319592476, 'total_duration': 199042.14831399918, 'accumulated_submission_time': 182788.3319592476, 'accumulated_eval_time': 16198.477226018906, 'accumulated_logging_time': 33.029731035232544}
I0304 18:50:00.695477 140239842563840 logging_writer.py:48] [408554] accumulated_eval_time=16198.477226, accumulated_logging_time=33.029731, accumulated_submission_time=182788.331959, global_step=408554, preemption_count=0, score=182788.331959, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=199042.148314, train/accuracy=0.888008, train/loss=0.414984, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:50:19.331585 140239850956544 logging_writer.py:48] [408600] global_step=408600, grad_norm=3.0022058486938477, loss=1.7065831422805786
I0304 18:51:02.737735 140239842563840 logging_writer.py:48] [408700] global_step=408700, grad_norm=3.2848899364471436, loss=1.0936328172683716
I0304 18:51:48.088069 140239850956544 logging_writer.py:48] [408800] global_step=408800, grad_norm=3.5333409309387207, loss=2.4629263877868652
I0304 18:52:33.563799 140239842563840 logging_writer.py:48] [408900] global_step=408900, grad_norm=2.9451355934143066, loss=1.1017051935195923
I0304 18:53:19.114396 140239850956544 logging_writer.py:48] [409000] global_step=409000, grad_norm=3.2128043174743652, loss=2.742173194885254
I0304 18:54:04.342492 140239842563840 logging_writer.py:48] [409100] global_step=409100, grad_norm=3.1201062202453613, loss=1.6414518356323242
I0304 18:54:49.869858 140239850956544 logging_writer.py:48] [409200] global_step=409200, grad_norm=3.6619043350219727, loss=3.046065092086792
I0304 18:55:35.261918 140239842563840 logging_writer.py:48] [409300] global_step=409300, grad_norm=2.9147303104400635, loss=1.1263315677642822
I0304 18:56:20.765213 140239850956544 logging_writer.py:48] [409400] global_step=409400, grad_norm=3.0939829349517822, loss=1.5263549089431763
I0304 18:57:00.757750 140437341357888 spec.py:321] Evaluating on the training split.
I0304 18:57:11.616135 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 18:57:34.467436 140437341357888 spec.py:349] Evaluating on the test split.
I0304 18:57:36.095493 140437341357888 submission_runner.py:411] Time since start: 199497.65s, 	Step: 409490, 	{'train/accuracy': 0.8875390291213989, 'train/loss': 0.4196300804615021, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 183208.33271503448, 'total_duration': 199497.64591693878, 'accumulated_submission_time': 183208.33271503448, 'accumulated_eval_time': 16233.813900232315, 'accumulated_logging_time': 33.13789200782776}
I0304 18:57:36.191849 140239842563840 logging_writer.py:48] [409490] accumulated_eval_time=16233.813900, accumulated_logging_time=33.137892, accumulated_submission_time=183208.332715, global_step=409490, preemption_count=0, score=183208.332715, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=199497.645917, train/accuracy=0.887539, train/loss=0.419630, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 18:57:40.562710 140239850956544 logging_writer.py:48] [409500] global_step=409500, grad_norm=3.423800230026245, loss=1.0942821502685547
I0304 18:58:23.227242 140239842563840 logging_writer.py:48] [409600] global_step=409600, grad_norm=4.083327293395996, loss=3.02793550491333
I0304 18:59:08.614756 140239850956544 logging_writer.py:48] [409700] global_step=409700, grad_norm=2.925081968307495, loss=1.3262050151824951
I0304 18:59:53.994972 140239842563840 logging_writer.py:48] [409800] global_step=409800, grad_norm=2.8641610145568848, loss=1.4356234073638916
I0304 19:00:39.346607 140239850956544 logging_writer.py:48] [409900] global_step=409900, grad_norm=3.160418748855591, loss=1.1057804822921753
I0304 19:01:25.030734 140239842563840 logging_writer.py:48] [410000] global_step=410000, grad_norm=2.95430064201355, loss=2.3958005905151367
I0304 19:02:10.450976 140239850956544 logging_writer.py:48] [410100] global_step=410100, grad_norm=3.544292449951172, loss=2.778118133544922
I0304 19:02:55.958434 140239842563840 logging_writer.py:48] [410200] global_step=410200, grad_norm=3.0764408111572266, loss=1.139113426208496
I0304 19:03:41.629983 140239850956544 logging_writer.py:48] [410300] global_step=410300, grad_norm=2.808300018310547, loss=1.0989136695861816
I0304 19:04:27.283490 140239842563840 logging_writer.py:48] [410400] global_step=410400, grad_norm=3.011000871658325, loss=1.2695119380950928
I0304 19:04:36.530753 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:04:46.971622 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:05:21.210227 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:05:22.839125 140437341357888 submission_runner.py:411] Time since start: 199964.39s, 	Step: 410422, 	{'train/accuracy': 0.8884961009025574, 'train/loss': 0.4138842225074768, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 183628.6072833538, 'total_duration': 199964.38940405846, 'accumulated_submission_time': 183628.6072833538, 'accumulated_eval_time': 16280.1210501194, 'accumulated_logging_time': 33.24795961380005}
I0304 19:05:22.932891 140239850956544 logging_writer.py:48] [410422] accumulated_eval_time=16280.121050, accumulated_logging_time=33.247960, accumulated_submission_time=183628.607283, global_step=410422, preemption_count=0, score=183628.607283, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=199964.389404, train/accuracy=0.888496, train/loss=0.413884, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:05:54.203892 140239842563840 logging_writer.py:48] [410500] global_step=410500, grad_norm=5.4747419357299805, loss=3.0469887256622314
I0304 19:06:38.536959 140239850956544 logging_writer.py:48] [410600] global_step=410600, grad_norm=3.2113749980926514, loss=1.0992834568023682
I0304 19:07:23.820637 140239842563840 logging_writer.py:48] [410700] global_step=410700, grad_norm=2.957306146621704, loss=2.0745186805725098
I0304 19:08:09.105624 140239850956544 logging_writer.py:48] [410800] global_step=410800, grad_norm=3.0206661224365234, loss=1.2185947895050049
I0304 19:08:54.373595 140239842563840 logging_writer.py:48] [410900] global_step=410900, grad_norm=3.1076009273529053, loss=1.3665271997451782
I0304 19:09:39.705267 140239850956544 logging_writer.py:48] [411000] global_step=411000, grad_norm=3.081061601638794, loss=1.155695915222168
I0304 19:10:24.715408 140239842563840 logging_writer.py:48] [411100] global_step=411100, grad_norm=3.237339973449707, loss=1.9649304151535034
I0304 19:11:09.917085 140239850956544 logging_writer.py:48] [411200] global_step=411200, grad_norm=2.7532496452331543, loss=1.0600680112838745
I0304 19:11:54.923908 140239842563840 logging_writer.py:48] [411300] global_step=411300, grad_norm=2.8361976146698, loss=1.101531982421875
I0304 19:12:23.180549 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:12:33.414378 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:12:54.255546 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:12:55.880001 140437341357888 submission_runner.py:411] Time since start: 200417.43s, 	Step: 411364, 	{'train/accuracy': 0.8887109160423279, 'train/loss': 0.4179222285747528, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 184048.79243969917, 'total_duration': 200417.43037319183, 'accumulated_submission_time': 184048.79243969917, 'accumulated_eval_time': 16312.81937122345, 'accumulated_logging_time': 33.35289120674133}
I0304 19:12:55.975897 140239850956544 logging_writer.py:48] [411364] accumulated_eval_time=16312.819371, accumulated_logging_time=33.352891, accumulated_submission_time=184048.792440, global_step=411364, preemption_count=0, score=184048.792440, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=200417.430373, train/accuracy=0.888711, train/loss=0.417922, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:13:10.660834 140239842563840 logging_writer.py:48] [411400] global_step=411400, grad_norm=3.1232078075408936, loss=1.1408125162124634
I0304 19:13:53.983186 140239850956544 logging_writer.py:48] [411500] global_step=411500, grad_norm=2.8973827362060547, loss=1.2222135066986084
I0304 19:14:39.139671 140239842563840 logging_writer.py:48] [411600] global_step=411600, grad_norm=3.0520243644714355, loss=1.2383185625076294
I0304 19:15:24.672893 140239850956544 logging_writer.py:48] [411700] global_step=411700, grad_norm=3.3147501945495605, loss=3.0111398696899414
I0304 19:16:09.767404 140239842563840 logging_writer.py:48] [411800] global_step=411800, grad_norm=2.971151828765869, loss=1.092734694480896
I0304 19:16:55.254639 140239850956544 logging_writer.py:48] [411900] global_step=411900, grad_norm=3.0209975242614746, loss=1.8080648183822632
I0304 19:17:40.382258 140239842563840 logging_writer.py:48] [412000] global_step=412000, grad_norm=2.8487114906311035, loss=1.0893700122833252
I0304 19:18:25.479047 140239850956544 logging_writer.py:48] [412100] global_step=412100, grad_norm=3.16679048538208, loss=1.1488319635391235
I0304 19:19:10.820513 140239842563840 logging_writer.py:48] [412200] global_step=412200, grad_norm=2.7966372966766357, loss=1.5206400156021118
I0304 19:19:55.970042 140239850956544 logging_writer.py:48] [412300] global_step=412300, grad_norm=3.6451034545898438, loss=2.901888608932495
I0304 19:19:55.982430 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:20:06.814428 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:20:36.211797 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:20:37.831162 140437341357888 submission_runner.py:411] Time since start: 200879.38s, 	Step: 412301, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.41154855489730835, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 184468.7359404564, 'total_duration': 200879.38162469864, 'accumulated_submission_time': 184468.7359404564, 'accumulated_eval_time': 16354.667058467865, 'accumulated_logging_time': 33.46069145202637}
I0304 19:20:37.926719 140239842563840 logging_writer.py:48] [412301] accumulated_eval_time=16354.667058, accumulated_logging_time=33.460691, accumulated_submission_time=184468.735940, global_step=412301, preemption_count=0, score=184468.735940, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=200879.381625, train/accuracy=0.889570, train/loss=0.411549, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:21:19.302565 140239850956544 logging_writer.py:48] [412400] global_step=412400, grad_norm=3.413198471069336, loss=2.3146767616271973
I0304 19:22:04.541558 140239842563840 logging_writer.py:48] [412500] global_step=412500, grad_norm=2.951434850692749, loss=1.2094385623931885
I0304 19:22:49.981212 140239850956544 logging_writer.py:48] [412600] global_step=412600, grad_norm=3.52734637260437, loss=3.0436532497406006
I0304 19:23:35.797541 140239842563840 logging_writer.py:48] [412700] global_step=412700, grad_norm=3.1307835578918457, loss=1.222022533416748
I0304 19:24:21.260967 140239850956544 logging_writer.py:48] [412800] global_step=412800, grad_norm=2.8701651096343994, loss=1.2431495189666748
I0304 19:25:06.959839 140239842563840 logging_writer.py:48] [412900] global_step=412900, grad_norm=2.9372127056121826, loss=2.1433982849121094
I0304 19:25:52.657219 140239850956544 logging_writer.py:48] [413000] global_step=413000, grad_norm=2.8523855209350586, loss=1.600180745124817
I0304 19:26:38.404989 140239842563840 logging_writer.py:48] [413100] global_step=413100, grad_norm=2.9300081729888916, loss=1.1348624229431152
I0304 19:27:23.777274 140239850956544 logging_writer.py:48] [413200] global_step=413200, grad_norm=2.856067657470703, loss=1.590314507484436
I0304 19:27:38.024672 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:27:48.297256 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:28:23.094938 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:28:24.715966 140437341357888 submission_runner.py:411] Time since start: 201346.26s, 	Step: 413233, 	{'train/accuracy': 0.8875781297683716, 'train/loss': 0.4195011556148529, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 184888.77264356613, 'total_duration': 201346.26455664635, 'accumulated_submission_time': 184888.77264356613, 'accumulated_eval_time': 16401.355442762375, 'accumulated_logging_time': 33.5668420791626}
I0304 19:28:24.794796 140239842563840 logging_writer.py:48] [413233] accumulated_eval_time=16401.355443, accumulated_logging_time=33.566842, accumulated_submission_time=184888.772644, global_step=413233, preemption_count=0, score=184888.772644, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=201346.264557, train/accuracy=0.887578, train/loss=0.419501, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:28:51.712644 140239850956544 logging_writer.py:48] [413300] global_step=413300, grad_norm=3.0384950637817383, loss=1.8244788646697998
I0304 19:29:35.284703 140239842563840 logging_writer.py:48] [413400] global_step=413400, grad_norm=3.0517427921295166, loss=1.163534164428711
I0304 19:30:20.840704 140239850956544 logging_writer.py:48] [413500] global_step=413500, grad_norm=3.0136561393737793, loss=1.17818021774292
I0304 19:31:06.293364 140239842563840 logging_writer.py:48] [413600] global_step=413600, grad_norm=2.9545135498046875, loss=1.2742338180541992
I0304 19:31:51.439896 140239850956544 logging_writer.py:48] [413700] global_step=413700, grad_norm=3.1130030155181885, loss=2.544231414794922
I0304 19:32:36.797616 140239842563840 logging_writer.py:48] [413800] global_step=413800, grad_norm=3.1328976154327393, loss=1.1681159734725952
I0304 19:33:22.140287 140239850956544 logging_writer.py:48] [413900] global_step=413900, grad_norm=3.081623077392578, loss=1.0592384338378906
I0304 19:34:07.526595 140239842563840 logging_writer.py:48] [414000] global_step=414000, grad_norm=3.2719759941101074, loss=2.006277322769165
I0304 19:34:52.912891 140239850956544 logging_writer.py:48] [414100] global_step=414100, grad_norm=3.061434507369995, loss=1.2617638111114502
I0304 19:35:24.755178 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:35:35.114781 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:35:56.241272 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:35:57.870444 140437341357888 submission_runner.py:411] Time since start: 201799.42s, 	Step: 414171, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.4134228527545929, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 185308.6721343994, 'total_duration': 201799.42095828056, 'accumulated_submission_time': 185308.6721343994, 'accumulated_eval_time': 16434.469732284546, 'accumulated_logging_time': 33.65598273277283}
I0304 19:35:57.969210 140239842563840 logging_writer.py:48] [414171] accumulated_eval_time=16434.469732, accumulated_logging_time=33.655983, accumulated_submission_time=185308.672134, global_step=414171, preemption_count=0, score=185308.672134, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=201799.420958, train/accuracy=0.887910, train/loss=0.413423, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:36:09.888219 140239850956544 logging_writer.py:48] [414200] global_step=414200, grad_norm=3.350569486618042, loss=3.0140066146850586
I0304 19:36:52.852210 140239842563840 logging_writer.py:48] [414300] global_step=414300, grad_norm=3.498279333114624, loss=1.573492407798767
I0304 19:37:38.137929 140239850956544 logging_writer.py:48] [414400] global_step=414400, grad_norm=3.636807918548584, loss=3.32656192779541
I0304 19:38:23.443835 140239842563840 logging_writer.py:48] [414500] global_step=414500, grad_norm=2.8124260902404785, loss=1.1129168272018433
I0304 19:39:08.663864 140239850956544 logging_writer.py:48] [414600] global_step=414600, grad_norm=2.882737159729004, loss=1.7214641571044922
I0304 19:39:53.674403 140239842563840 logging_writer.py:48] [414700] global_step=414700, grad_norm=2.8604414463043213, loss=2.5367610454559326
I0304 19:40:38.672824 140239850956544 logging_writer.py:48] [414800] global_step=414800, grad_norm=3.0426888465881348, loss=1.3869929313659668
I0304 19:41:23.920594 140239842563840 logging_writer.py:48] [414900] global_step=414900, grad_norm=3.280796527862549, loss=1.0689661502838135
I0304 19:42:09.229739 140239850956544 logging_writer.py:48] [415000] global_step=415000, grad_norm=2.92268967628479, loss=1.1738603115081787
I0304 19:42:54.099998 140239842563840 logging_writer.py:48] [415100] global_step=415100, grad_norm=3.166555404663086, loss=1.2926708459854126
I0304 19:42:58.293281 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:43:09.005956 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:43:33.282304 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:43:34.905240 140437341357888 submission_runner.py:411] Time since start: 202256.46s, 	Step: 415111, 	{'train/accuracy': 0.8889257907867432, 'train/loss': 0.41159743070602417, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 185728.93351864815, 'total_duration': 202256.4557170868, 'accumulated_submission_time': 185728.93351864815, 'accumulated_eval_time': 16471.08065843582, 'accumulated_logging_time': 33.76547908782959}
I0304 19:43:35.003284 140239850956544 logging_writer.py:48] [415111] accumulated_eval_time=16471.080658, accumulated_logging_time=33.765479, accumulated_submission_time=185728.933519, global_step=415111, preemption_count=0, score=185728.933519, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=202256.455717, train/accuracy=0.888926, train/loss=0.411597, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:44:12.025731 140239842563840 logging_writer.py:48] [415200] global_step=415200, grad_norm=2.967595100402832, loss=1.2038426399230957
I0304 19:44:57.057037 140239850956544 logging_writer.py:48] [415300] global_step=415300, grad_norm=3.6155011653900146, loss=3.2103939056396484
I0304 19:45:42.742881 140239842563840 logging_writer.py:48] [415400] global_step=415400, grad_norm=3.354215383529663, loss=1.1199055910110474
I0304 19:46:28.021365 140239850956544 logging_writer.py:48] [415500] global_step=415500, grad_norm=3.4428958892822266, loss=1.144751787185669
I0304 19:47:13.479478 140239842563840 logging_writer.py:48] [415600] global_step=415600, grad_norm=2.7269365787506104, loss=1.031264305114746
I0304 19:47:58.509748 140239850956544 logging_writer.py:48] [415700] global_step=415700, grad_norm=3.0394139289855957, loss=1.0811482667922974
I0304 19:48:43.627700 140239842563840 logging_writer.py:48] [415800] global_step=415800, grad_norm=2.9116604328155518, loss=1.2402029037475586
I0304 19:49:28.601592 140239850956544 logging_writer.py:48] [415900] global_step=415900, grad_norm=3.1677067279815674, loss=2.7174580097198486
I0304 19:50:13.872835 140239842563840 logging_writer.py:48] [416000] global_step=416000, grad_norm=2.957728624343872, loss=1.4218499660491943
I0304 19:50:35.185755 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:50:45.496517 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:51:24.728197 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:51:26.338980 140437341357888 submission_runner.py:411] Time since start: 202727.89s, 	Step: 416049, 	{'train/accuracy': 0.888671875, 'train/loss': 0.4118475914001465, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 186149.0531988144, 'total_duration': 202727.88941383362, 'accumulated_submission_time': 186149.0531988144, 'accumulated_eval_time': 16522.232833862305, 'accumulated_logging_time': 33.87578749656677}
I0304 19:51:26.417990 140239850956544 logging_writer.py:48] [416049] accumulated_eval_time=16522.232834, accumulated_logging_time=33.875787, accumulated_submission_time=186149.053199, global_step=416049, preemption_count=0, score=186149.053199, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=202727.889414, train/accuracy=0.888672, train/loss=0.411848, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:51:47.009470 140239842563840 logging_writer.py:48] [416100] global_step=416100, grad_norm=2.9593489170074463, loss=1.1346343755722046
I0304 19:52:29.049974 140239850956544 logging_writer.py:48] [416200] global_step=416200, grad_norm=3.2526917457580566, loss=1.3214569091796875
I0304 19:53:14.368997 140239842563840 logging_writer.py:48] [416300] global_step=416300, grad_norm=3.2059671878814697, loss=1.2528347969055176
I0304 19:53:59.371644 140239850956544 logging_writer.py:48] [416400] global_step=416400, grad_norm=2.9381299018859863, loss=1.2887836694717407
I0304 19:54:44.482162 140239842563840 logging_writer.py:48] [416500] global_step=416500, grad_norm=3.113715887069702, loss=1.10928213596344
I0304 19:55:29.680602 140239850956544 logging_writer.py:48] [416600] global_step=416600, grad_norm=3.180817127227783, loss=2.5321645736694336
I0304 19:56:15.262194 140239842563840 logging_writer.py:48] [416700] global_step=416700, grad_norm=2.9309799671173096, loss=1.4613518714904785
I0304 19:57:00.422067 140239850956544 logging_writer.py:48] [416800] global_step=416800, grad_norm=3.0349819660186768, loss=2.1371304988861084
I0304 19:57:45.488011 140239842563840 logging_writer.py:48] [416900] global_step=416900, grad_norm=3.0588185787200928, loss=2.679819107055664
I0304 19:58:26.340643 140437341357888 spec.py:321] Evaluating on the training split.
I0304 19:58:36.656374 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 19:58:59.185761 140437341357888 spec.py:349] Evaluating on the test split.
I0304 19:59:00.821900 140437341357888 submission_runner.py:411] Time since start: 203182.37s, 	Step: 416992, 	{'train/accuracy': 0.8870507478713989, 'train/loss': 0.4178069829940796, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 186568.91537976265, 'total_duration': 203182.3723757267, 'accumulated_submission_time': 186568.91537976265, 'accumulated_eval_time': 16556.713079452515, 'accumulated_logging_time': 33.965121269226074}
I0304 19:59:00.916247 140239850956544 logging_writer.py:48] [416992] accumulated_eval_time=16556.713079, accumulated_logging_time=33.965121, accumulated_submission_time=186568.915380, global_step=416992, preemption_count=0, score=186568.915380, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=203182.372376, train/accuracy=0.887051, train/loss=0.417807, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 19:59:05.405414 140239842563840 logging_writer.py:48] [417000] global_step=417000, grad_norm=3.0449914932250977, loss=2.546987533569336
I0304 19:59:47.078918 140239850956544 logging_writer.py:48] [417100] global_step=417100, grad_norm=2.890389919281006, loss=1.0805808305740356
I0304 20:00:32.406288 140239842563840 logging_writer.py:48] [417200] global_step=417200, grad_norm=3.7148683071136475, loss=3.1949167251586914
I0304 20:01:18.082209 140239850956544 logging_writer.py:48] [417300] global_step=417300, grad_norm=3.0633862018585205, loss=1.0965780019760132
I0304 20:02:03.065060 140239842563840 logging_writer.py:48] [417400] global_step=417400, grad_norm=2.9702906608581543, loss=2.0099453926086426
I0304 20:02:48.135417 140239850956544 logging_writer.py:48] [417500] global_step=417500, grad_norm=3.3151137828826904, loss=1.0518535375595093
I0304 20:03:33.371480 140239842563840 logging_writer.py:48] [417600] global_step=417600, grad_norm=3.3229386806488037, loss=1.0878974199295044
I0304 20:04:18.835704 140239850956544 logging_writer.py:48] [417700] global_step=417700, grad_norm=3.0400006771087646, loss=2.8076999187469482
I0304 20:05:04.186548 140239842563840 logging_writer.py:48] [417800] global_step=417800, grad_norm=2.9027516841888428, loss=1.8563579320907593
I0304 20:05:49.355466 140239850956544 logging_writer.py:48] [417900] global_step=417900, grad_norm=3.0812249183654785, loss=1.455249309539795
I0304 20:06:00.843582 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:06:11.642363 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 20:06:41.956755 140437341357888 spec.py:349] Evaluating on the test split.
I0304 20:06:43.569575 140437341357888 submission_runner.py:411] Time since start: 203645.12s, 	Step: 417927, 	{'train/accuracy': 0.8895117044448853, 'train/loss': 0.4142775535583496, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 186987.86484646797, 'total_duration': 203645.12013983727, 'accumulated_submission_time': 186987.86484646797, 'accumulated_eval_time': 16599.438136577606, 'accumulated_logging_time': 34.98693084716797}
I0304 20:06:43.668142 140239842563840 logging_writer.py:48] [417927] accumulated_eval_time=16599.438137, accumulated_logging_time=34.986931, accumulated_submission_time=186987.864846, global_step=417927, preemption_count=0, score=186987.864846, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=203645.120140, train/accuracy=0.889512, train/loss=0.414278, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 20:07:13.457205 140239850956544 logging_writer.py:48] [418000] global_step=418000, grad_norm=2.849013090133667, loss=1.1068226099014282
I0304 20:07:58.461010 140239842563840 logging_writer.py:48] [418100] global_step=418100, grad_norm=3.313469886779785, loss=1.100330114364624
I0304 20:08:43.866596 140239850956544 logging_writer.py:48] [418200] global_step=418200, grad_norm=3.419466018676758, loss=3.0336647033691406
I0304 20:09:29.238659 140239842563840 logging_writer.py:48] [418300] global_step=418300, grad_norm=3.177877902984619, loss=1.1305702924728394
I0304 20:10:14.597499 140239850956544 logging_writer.py:48] [418400] global_step=418400, grad_norm=3.0744755268096924, loss=1.058879017829895
I0304 20:10:59.660533 140239842563840 logging_writer.py:48] [418500] global_step=418500, grad_norm=2.9959444999694824, loss=1.1250633001327515
I0304 20:11:44.646834 140239850956544 logging_writer.py:48] [418600] global_step=418600, grad_norm=2.9553565979003906, loss=1.2028017044067383
I0304 20:12:29.681864 140239842563840 logging_writer.py:48] [418700] global_step=418700, grad_norm=3.110736131668091, loss=1.053827166557312
I0304 20:13:15.140551 140239850956544 logging_writer.py:48] [418800] global_step=418800, grad_norm=3.127035140991211, loss=1.147920846939087
I0304 20:13:43.793420 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:13:54.066797 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 20:14:21.392875 140437341357888 spec.py:349] Evaluating on the test split.
I0304 20:14:23.019626 140437341357888 submission_runner.py:411] Time since start: 204104.57s, 	Step: 418865, 	{'train/accuracy': 0.8903124928474426, 'train/loss': 0.41410204768180847, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 187407.9261534214, 'total_duration': 204104.56997919083, 'accumulated_submission_time': 187407.9261534214, 'accumulated_eval_time': 16638.66318511963, 'accumulated_logging_time': 35.098740100860596}
I0304 20:14:23.122033 140239842563840 logging_writer.py:48] [418865] accumulated_eval_time=16638.663185, accumulated_logging_time=35.098740, accumulated_submission_time=187407.926153, global_step=418865, preemption_count=0, score=187407.926153, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=204104.569979, train/accuracy=0.890312, train/loss=0.414102, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 20:14:37.385181 140239850956544 logging_writer.py:48] [418900] global_step=418900, grad_norm=3.209528684616089, loss=1.0618268251419067
I0304 20:15:20.332475 140239842563840 logging_writer.py:48] [419000] global_step=419000, grad_norm=2.7444913387298584, loss=1.6913305521011353
I0304 20:16:05.652880 140239850956544 logging_writer.py:48] [419100] global_step=419100, grad_norm=3.130307197570801, loss=1.112099528312683
I0304 20:16:51.345545 140239842563840 logging_writer.py:48] [419200] global_step=419200, grad_norm=3.3951504230499268, loss=1.1668739318847656
I0304 20:17:36.406193 140239850956544 logging_writer.py:48] [419300] global_step=419300, grad_norm=3.0971319675445557, loss=1.0741972923278809
I0304 20:18:21.709993 140239842563840 logging_writer.py:48] [419400] global_step=419400, grad_norm=3.2364501953125, loss=1.1783661842346191
I0304 20:19:06.861785 140239850956544 logging_writer.py:48] [419500] global_step=419500, grad_norm=3.2561607360839844, loss=1.610809326171875
I0304 20:19:51.741209 140239842563840 logging_writer.py:48] [419600] global_step=419600, grad_norm=3.498765707015991, loss=3.2337217330932617
I0304 20:20:36.981281 140239850956544 logging_writer.py:48] [419700] global_step=419700, grad_norm=3.033318519592285, loss=2.2964963912963867
I0304 20:21:22.308474 140239842563840 logging_writer.py:48] [419800] global_step=419800, grad_norm=2.970918893814087, loss=1.1611336469650269
I0304 20:21:23.455127 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:21:33.921658 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 20:22:06.358664 140437341357888 spec.py:349] Evaluating on the test split.
I0304 20:22:08.002943 140437341357888 submission_runner.py:411] Time since start: 204569.55s, 	Step: 419804, 	{'train/accuracy': 0.8893945217132568, 'train/loss': 0.4078099727630615, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 187828.1980266571, 'total_duration': 204569.55319857597, 'accumulated_submission_time': 187828.1980266571, 'accumulated_eval_time': 16683.20975136757, 'accumulated_logging_time': 35.21203064918518}
I0304 20:22:08.093396 140239850956544 logging_writer.py:48] [419804] accumulated_eval_time=16683.209751, accumulated_logging_time=35.212031, accumulated_submission_time=187828.198027, global_step=419804, preemption_count=0, score=187828.198027, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=204569.553199, train/accuracy=0.889395, train/loss=0.407810, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 20:22:46.670133 140239842563840 logging_writer.py:48] [419900] global_step=419900, grad_norm=3.106102228164673, loss=1.0352362394332886
I0304 20:23:31.472014 140239850956544 logging_writer.py:48] [420000] global_step=420000, grad_norm=2.963961601257324, loss=1.0167359113693237
I0304 20:24:17.088272 140239842563840 logging_writer.py:48] [420100] global_step=420100, grad_norm=3.165947914123535, loss=1.203778624534607
I0304 20:25:02.581016 140239850956544 logging_writer.py:48] [420200] global_step=420200, grad_norm=3.3223717212677, loss=1.6500229835510254
I0304 20:25:47.487457 140239842563840 logging_writer.py:48] [420300] global_step=420300, grad_norm=2.845264196395874, loss=1.9548718929290771
I0304 20:26:33.510115 140239850956544 logging_writer.py:48] [420400] global_step=420400, grad_norm=3.4267685413360596, loss=1.1679801940917969
I0304 20:27:18.814776 140239842563840 logging_writer.py:48] [420500] global_step=420500, grad_norm=2.9037773609161377, loss=1.568871021270752
I0304 20:28:04.377394 140239850956544 logging_writer.py:48] [420600] global_step=420600, grad_norm=4.436488628387451, loss=3.2404115200042725
I0304 20:28:49.765070 140239842563840 logging_writer.py:48] [420700] global_step=420700, grad_norm=3.0510547161102295, loss=1.4885412454605103
I0304 20:29:08.063133 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:29:18.646772 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 20:29:45.271635 140437341357888 spec.py:349] Evaluating on the test split.
I0304 20:29:46.894888 140437341357888 submission_runner.py:411] Time since start: 205028.45s, 	Step: 420742, 	{'train/accuracy': 0.8888280987739563, 'train/loss': 0.41579750180244446, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 188248.1066851616, 'total_duration': 205028.44544243813, 'accumulated_submission_time': 188248.1066851616, 'accumulated_eval_time': 16722.040591955185, 'accumulated_logging_time': 35.3136100769043}
I0304 20:29:46.998236 140239850956544 logging_writer.py:48] [420742] accumulated_eval_time=16722.040592, accumulated_logging_time=35.313610, accumulated_submission_time=188248.106685, global_step=420742, preemption_count=0, score=188248.106685, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=205028.445442, train/accuracy=0.888828, train/loss=0.415798, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 20:30:10.358780 140239842563840 logging_writer.py:48] [420800] global_step=420800, grad_norm=2.8739895820617676, loss=1.7488977909088135
I0304 20:30:54.780295 140239850956544 logging_writer.py:48] [420900] global_step=420900, grad_norm=3.2296018600463867, loss=1.0667085647583008
I0304 20:31:40.228533 140239842563840 logging_writer.py:48] [421000] global_step=421000, grad_norm=3.3636226654052734, loss=1.1757206916809082
I0304 20:32:25.606464 140239850956544 logging_writer.py:48] [421100] global_step=421100, grad_norm=4.692303657531738, loss=3.2966580390930176
I0304 20:33:10.714682 140239842563840 logging_writer.py:48] [421200] global_step=421200, grad_norm=3.1975135803222656, loss=1.1588331460952759
I0304 20:33:55.925209 140239850956544 logging_writer.py:48] [421300] global_step=421300, grad_norm=3.2515931129455566, loss=1.1223623752593994
I0304 20:34:41.231925 140239842563840 logging_writer.py:48] [421400] global_step=421400, grad_norm=3.0190300941467285, loss=1.067631483078003
I0304 20:35:26.581380 140239850956544 logging_writer.py:48] [421500] global_step=421500, grad_norm=2.7236990928649902, loss=1.1255698204040527
I0304 20:36:11.863043 140239842563840 logging_writer.py:48] [421600] global_step=421600, grad_norm=2.942920684814453, loss=1.0621610879898071
I0304 20:36:47.316393 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:36:58.803767 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 20:37:23.063036 140437341357888 spec.py:349] Evaluating on the test split.
I0304 20:37:24.685096 140437341357888 submission_runner.py:411] Time since start: 205486.24s, 	Step: 421679, 	{'train/accuracy': 0.8882812261581421, 'train/loss': 0.41607365012168884, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 188668.3634223938, 'total_duration': 205486.2354171276, 'accumulated_submission_time': 188668.3634223938, 'accumulated_eval_time': 16759.408123254776, 'accumulated_logging_time': 35.428178787231445}
I0304 20:37:24.782193 140239850956544 logging_writer.py:48] [421679] accumulated_eval_time=16759.408123, accumulated_logging_time=35.428179, accumulated_submission_time=188668.363422, global_step=421679, preemption_count=0, score=188668.363422, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=205486.235417, train/accuracy=0.888281, train/loss=0.416074, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 20:37:33.521747 140239842563840 logging_writer.py:48] [421700] global_step=421700, grad_norm=2.99165678024292, loss=1.8162275552749634
I0304 20:38:16.268790 140239850956544 logging_writer.py:48] [421800] global_step=421800, grad_norm=3.561702251434326, loss=2.6615843772888184
I0304 20:39:01.406733 140239842563840 logging_writer.py:48] [421900] global_step=421900, grad_norm=2.8934617042541504, loss=1.1057238578796387
I0304 20:39:46.898942 140239850956544 logging_writer.py:48] [422000] global_step=422000, grad_norm=3.090200901031494, loss=1.171488881111145
I0304 20:40:32.200853 140239842563840 logging_writer.py:48] [422100] global_step=422100, grad_norm=3.7558066844940186, loss=2.1155526638031006
I0304 20:41:17.329967 140239850956544 logging_writer.py:48] [422200] global_step=422200, grad_norm=4.961368083953857, loss=3.141650915145874
I0304 20:42:02.656835 140239842563840 logging_writer.py:48] [422300] global_step=422300, grad_norm=2.9482104778289795, loss=1.1089057922363281
I0304 20:42:47.814043 140239850956544 logging_writer.py:48] [422400] global_step=422400, grad_norm=3.172182321548462, loss=1.2013466358184814
I0304 20:43:33.081877 140239842563840 logging_writer.py:48] [422500] global_step=422500, grad_norm=2.966165542602539, loss=1.8338534832000732
I0304 20:44:18.201330 140239850956544 logging_writer.py:48] [422600] global_step=422600, grad_norm=3.146806001663208, loss=2.5131938457489014
I0304 20:44:24.813026 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:44:35.263861 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 20:45:05.868644 140437341357888 spec.py:349] Evaluating on the test split.
I0304 20:45:07.519568 140437341357888 submission_runner.py:411] Time since start: 205949.07s, 	Step: 422616, 	{'train/accuracy': 0.8886913657188416, 'train/loss': 0.41182056069374084, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 189088.33290719986, 'total_duration': 205949.06998586655, 'accumulated_submission_time': 189088.33290719986, 'accumulated_eval_time': 16802.113570451736, 'accumulated_logging_time': 35.536232471466064}
I0304 20:45:07.699690 140239842563840 logging_writer.py:48] [422616] accumulated_eval_time=16802.113570, accumulated_logging_time=35.536232, accumulated_submission_time=189088.332907, global_step=422616, preemption_count=0, score=189088.332907, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=205949.069986, train/accuracy=0.888691, train/loss=0.411821, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 20:45:41.501456 140239850956544 logging_writer.py:48] [422700] global_step=422700, grad_norm=2.7339863777160645, loss=1.9624041318893433
I0304 20:46:26.569847 140239842563840 logging_writer.py:48] [422800] global_step=422800, grad_norm=3.5293257236480713, loss=2.6505887508392334
I0304 20:47:12.298238 140239850956544 logging_writer.py:48] [422900] global_step=422900, grad_norm=4.457302093505859, loss=1.2713643312454224
I0304 20:47:57.761614 140239842563840 logging_writer.py:48] [423000] global_step=423000, grad_norm=3.0396888256073, loss=1.1994235515594482
I0304 20:48:42.904004 140239850956544 logging_writer.py:48] [423100] global_step=423100, grad_norm=3.625450611114502, loss=1.1692150831222534
I0304 20:49:28.322038 140239842563840 logging_writer.py:48] [423200] global_step=423200, grad_norm=2.9260878562927246, loss=1.0691750049591064
I0304 20:50:13.568535 140239850956544 logging_writer.py:48] [423300] global_step=423300, grad_norm=3.5618395805358887, loss=1.1549874544143677
I0304 20:50:58.923079 140239842563840 logging_writer.py:48] [423400] global_step=423400, grad_norm=2.8914945125579834, loss=1.1614089012145996
I0304 20:51:44.053780 140239850956544 logging_writer.py:48] [423500] global_step=423500, grad_norm=3.143000364303589, loss=2.067046880722046
I0304 20:52:07.602499 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:52:17.867532 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 20:52:43.448760 140437341357888 spec.py:349] Evaluating on the test split.
I0304 20:52:45.071281 140437341357888 submission_runner.py:411] Time since start: 206406.62s, 	Step: 423554, 	{'train/accuracy': 0.8875585794448853, 'train/loss': 0.4185675084590912, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 189508.17068457603, 'total_duration': 206406.62183642387, 'accumulated_submission_time': 189508.17068457603, 'accumulated_eval_time': 16839.58140516281, 'accumulated_logging_time': 35.73130702972412}
I0304 20:52:45.170280 140239842563840 logging_writer.py:48] [423554] accumulated_eval_time=16839.581405, accumulated_logging_time=35.731307, accumulated_submission_time=189508.170685, global_step=423554, preemption_count=0, score=189508.170685, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=206406.621836, train/accuracy=0.887559, train/loss=0.418568, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 20:53:03.878861 140239850956544 logging_writer.py:48] [423600] global_step=423600, grad_norm=3.032198190689087, loss=1.1814383268356323
I0304 20:53:47.714572 140239842563840 logging_writer.py:48] [423700] global_step=423700, grad_norm=3.160374164581299, loss=1.6430102586746216
I0304 20:54:32.909079 140239850956544 logging_writer.py:48] [423800] global_step=423800, grad_norm=3.020554542541504, loss=1.3049721717834473
I0304 20:55:18.575936 140239842563840 logging_writer.py:48] [423900] global_step=423900, grad_norm=2.9615378379821777, loss=1.787841558456421
I0304 20:56:03.773735 140239850956544 logging_writer.py:48] [424000] global_step=424000, grad_norm=3.7892298698425293, loss=1.6820523738861084
I0304 20:56:49.292125 140239842563840 logging_writer.py:48] [424100] global_step=424100, grad_norm=3.131737232208252, loss=2.9496572017669678
I0304 20:57:34.830877 140239850956544 logging_writer.py:48] [424200] global_step=424200, grad_norm=2.9581174850463867, loss=1.6676750183105469
I0304 20:58:19.915530 140239842563840 logging_writer.py:48] [424300] global_step=424300, grad_norm=3.1053433418273926, loss=1.114740252494812
I0304 20:59:05.174932 140239850956544 logging_writer.py:48] [424400] global_step=424400, grad_norm=4.0237040519714355, loss=2.9748311042785645
I0304 20:59:45.070789 140437341357888 spec.py:321] Evaluating on the training split.
I0304 20:59:55.525871 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:00:23.247360 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:00:24.885448 140437341357888 submission_runner.py:411] Time since start: 206866.44s, 	Step: 424490, 	{'train/accuracy': 0.8890429735183716, 'train/loss': 0.41326823830604553, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 189928.00553822517, 'total_duration': 206866.43586206436, 'accumulated_submission_time': 189928.00553822517, 'accumulated_eval_time': 16879.394988775253, 'accumulated_logging_time': 35.84501767158508}
I0304 21:00:24.977472 140239842563840 logging_writer.py:48] [424490] accumulated_eval_time=16879.394989, accumulated_logging_time=35.845018, accumulated_submission_time=189928.005538, global_step=424490, preemption_count=0, score=189928.005538, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=206866.435862, train/accuracy=0.889043, train/loss=0.413268, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:00:29.357921 140239850956544 logging_writer.py:48] [424500] global_step=424500, grad_norm=2.9958910942077637, loss=1.0337309837341309
I0304 21:01:11.153715 140239842563840 logging_writer.py:48] [424600] global_step=424600, grad_norm=2.829641819000244, loss=1.5070117712020874
I0304 21:01:56.147440 140239850956544 logging_writer.py:48] [424700] global_step=424700, grad_norm=2.815208911895752, loss=1.15915048122406
I0304 21:02:41.320834 140239842563840 logging_writer.py:48] [424800] global_step=424800, grad_norm=2.9358484745025635, loss=1.1151338815689087
I0304 21:03:26.506586 140239850956544 logging_writer.py:48] [424900] global_step=424900, grad_norm=3.020253896713257, loss=1.2091602087020874
I0304 21:04:11.640439 140239842563840 logging_writer.py:48] [425000] global_step=425000, grad_norm=3.2167437076568604, loss=2.7843384742736816
I0304 21:04:56.567200 140239850956544 logging_writer.py:48] [425100] global_step=425100, grad_norm=3.2653002738952637, loss=1.2763135433197021
I0304 21:05:41.831961 140239842563840 logging_writer.py:48] [425200] global_step=425200, grad_norm=3.262701988220215, loss=1.0541406869888306
I0304 21:06:27.026639 140239850956544 logging_writer.py:48] [425300] global_step=425300, grad_norm=2.8065567016601562, loss=1.2340115308761597
I0304 21:07:12.595121 140239842563840 logging_writer.py:48] [425400] global_step=425400, grad_norm=2.959520101547241, loss=1.0059386491775513
I0304 21:07:25.028127 140437341357888 spec.py:321] Evaluating on the training split.
I0304 21:07:35.348879 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:08:04.055188 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:08:05.673355 140437341357888 submission_runner.py:411] Time since start: 207327.22s, 	Step: 425429, 	{'train/accuracy': 0.88734370470047, 'train/loss': 0.41967085003852844, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 190347.99412417412, 'total_duration': 207327.22372031212, 'accumulated_submission_time': 190347.99412417412, 'accumulated_eval_time': 16920.03908252716, 'accumulated_logging_time': 35.94810652732849}
I0304 21:08:05.771902 140239850956544 logging_writer.py:48] [425429] accumulated_eval_time=16920.039083, accumulated_logging_time=35.948107, accumulated_submission_time=190347.994124, global_step=425429, preemption_count=0, score=190347.994124, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=207327.223720, train/accuracy=0.887344, train/loss=0.419671, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:08:34.284075 140239842563840 logging_writer.py:48] [425500] global_step=425500, grad_norm=3.0398683547973633, loss=1.1553984880447388
I0304 21:09:19.354368 140239850956544 logging_writer.py:48] [425600] global_step=425600, grad_norm=3.082095146179199, loss=1.059975028038025
I0304 21:10:04.710455 140239842563840 logging_writer.py:48] [425700] global_step=425700, grad_norm=2.9994874000549316, loss=1.1759490966796875
I0304 21:10:50.122306 140239850956544 logging_writer.py:48] [425800] global_step=425800, grad_norm=3.2353174686431885, loss=1.0398688316345215
I0304 21:11:35.659054 140239842563840 logging_writer.py:48] [425900] global_step=425900, grad_norm=3.075770616531372, loss=1.0854846239089966
I0304 21:12:20.835871 140239850956544 logging_writer.py:48] [426000] global_step=426000, grad_norm=2.9483556747436523, loss=1.175004482269287
I0304 21:13:06.056853 140239842563840 logging_writer.py:48] [426100] global_step=426100, grad_norm=2.9572744369506836, loss=2.0525076389312744
I0304 21:13:51.252058 140239850956544 logging_writer.py:48] [426200] global_step=426200, grad_norm=2.950796604156494, loss=1.1670010089874268
I0304 21:14:36.424550 140239842563840 logging_writer.py:48] [426300] global_step=426300, grad_norm=2.8937768936157227, loss=1.3663833141326904
I0304 21:15:06.029527 140437341357888 spec.py:321] Evaluating on the training split.
I0304 21:15:16.259750 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:15:45.571827 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:15:47.201865 140437341357888 submission_runner.py:411] Time since start: 207788.75s, 	Step: 426367, 	{'train/accuracy': 0.8880664110183716, 'train/loss': 0.41235724091529846, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 190768.18881583214, 'total_duration': 207788.75227856636, 'accumulated_submission_time': 190768.18881583214, 'accumulated_eval_time': 16961.210329294205, 'accumulated_logging_time': 36.057634353637695}
I0304 21:15:47.308874 140239850956544 logging_writer.py:48] [426367] accumulated_eval_time=16961.210329, accumulated_logging_time=36.057634, accumulated_submission_time=190768.188816, global_step=426367, preemption_count=0, score=190768.188816, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=207788.752279, train/accuracy=0.888066, train/loss=0.412357, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:16:00.786533 140239842563840 logging_writer.py:48] [426400] global_step=426400, grad_norm=2.8617324829101562, loss=1.0852649211883545
I0304 21:16:43.836341 140239850956544 logging_writer.py:48] [426500] global_step=426500, grad_norm=3.062859535217285, loss=1.7043638229370117
I0304 21:17:28.751661 140239842563840 logging_writer.py:48] [426600] global_step=426600, grad_norm=3.441810369491577, loss=1.666715145111084
I0304 21:18:14.481482 140239850956544 logging_writer.py:48] [426700] global_step=426700, grad_norm=2.983668565750122, loss=1.2219138145446777
I0304 21:18:59.349662 140239842563840 logging_writer.py:48] [426800] global_step=426800, grad_norm=2.933422803878784, loss=1.1766233444213867
I0304 21:19:44.357741 140239850956544 logging_writer.py:48] [426900] global_step=426900, grad_norm=3.071942090988159, loss=1.426943063735962
I0304 21:20:29.698761 140239842563840 logging_writer.py:48] [427000] global_step=427000, grad_norm=3.1206297874450684, loss=1.0121709108352661
I0304 21:21:14.922249 140239850956544 logging_writer.py:48] [427100] global_step=427100, grad_norm=2.857595443725586, loss=1.1518800258636475
I0304 21:22:00.055171 140239842563840 logging_writer.py:48] [427200] global_step=427200, grad_norm=3.230207920074463, loss=2.522812843322754
I0304 21:22:45.150898 140239850956544 logging_writer.py:48] [427300] global_step=427300, grad_norm=3.048654079437256, loss=1.093705177307129
I0304 21:22:47.594649 140437341357888 spec.py:321] Evaluating on the training split.
I0304 21:22:58.038807 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:23:27.337394 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:23:28.962193 140437341357888 submission_runner.py:411] Time since start: 208250.51s, 	Step: 427307, 	{'train/accuracy': 0.8867382407188416, 'train/loss': 0.41962718963623047, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 191188.41430687904, 'total_duration': 208250.51259469986, 'accumulated_submission_time': 191188.41430687904, 'accumulated_eval_time': 17002.576770305634, 'accumulated_logging_time': 36.17466354370117}
I0304 21:23:29.063247 140239842563840 logging_writer.py:48] [427307] accumulated_eval_time=17002.576770, accumulated_logging_time=36.174664, accumulated_submission_time=191188.414307, global_step=427307, preemption_count=0, score=191188.414307, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=208250.512595, train/accuracy=0.886738, train/loss=0.419627, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:24:07.495427 140239850956544 logging_writer.py:48] [427400] global_step=427400, grad_norm=2.991525650024414, loss=1.1484966278076172
I0304 21:24:52.635514 140239842563840 logging_writer.py:48] [427500] global_step=427500, grad_norm=3.3655145168304443, loss=1.499356985092163
I0304 21:25:38.074013 140239850956544 logging_writer.py:48] [427600] global_step=427600, grad_norm=2.957815170288086, loss=2.2316629886627197
I0304 21:26:23.205286 140239842563840 logging_writer.py:48] [427700] global_step=427700, grad_norm=2.949739933013916, loss=1.6135363578796387
I0304 21:27:08.762288 140239850956544 logging_writer.py:48] [427800] global_step=427800, grad_norm=3.110464096069336, loss=1.0272399187088013
I0304 21:27:54.044344 140239842563840 logging_writer.py:48] [427900] global_step=427900, grad_norm=2.9806253910064697, loss=1.5259511470794678
I0304 21:28:39.290660 140239850956544 logging_writer.py:48] [428000] global_step=428000, grad_norm=3.0503146648406982, loss=1.1073546409606934
I0304 21:29:24.322331 140239842563840 logging_writer.py:48] [428100] global_step=428100, grad_norm=2.87465238571167, loss=1.1097970008850098
I0304 21:30:09.685789 140239850956544 logging_writer.py:48] [428200] global_step=428200, grad_norm=3.584035634994507, loss=3.2238147258758545
I0304 21:30:29.229683 140437341357888 spec.py:321] Evaluating on the training split.
I0304 21:30:39.443244 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:31:07.573160 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:31:09.216144 140437341357888 submission_runner.py:411] Time since start: 208710.77s, 	Step: 428245, 	{'train/accuracy': 0.8895898461341858, 'train/loss': 0.41299718618392944, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 191608.5195260048, 'total_duration': 208710.7665054798, 'accumulated_submission_time': 191608.5195260048, 'accumulated_eval_time': 17042.562101125717, 'accumulated_logging_time': 36.28608512878418}
I0304 21:31:09.323849 140239842563840 logging_writer.py:48] [428245] accumulated_eval_time=17042.562101, accumulated_logging_time=36.286085, accumulated_submission_time=191608.519526, global_step=428245, preemption_count=0, score=191608.519526, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=208710.766505, train/accuracy=0.889590, train/loss=0.412997, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:31:31.526783 140239850956544 logging_writer.py:48] [428300] global_step=428300, grad_norm=3.0860073566436768, loss=2.172300338745117
I0304 21:32:14.970652 140239842563840 logging_writer.py:48] [428400] global_step=428400, grad_norm=3.1052870750427246, loss=1.1641204357147217
I0304 21:33:00.047081 140239850956544 logging_writer.py:48] [428500] global_step=428500, grad_norm=3.1024928092956543, loss=1.1620804071426392
I0304 21:33:45.542662 140239842563840 logging_writer.py:48] [428600] global_step=428600, grad_norm=3.5827503204345703, loss=2.837736129760742
I0304 21:34:30.492536 140239850956544 logging_writer.py:48] [428700] global_step=428700, grad_norm=3.153806209564209, loss=2.626951217651367
I0304 21:35:15.634140 140239842563840 logging_writer.py:48] [428800] global_step=428800, grad_norm=3.105015277862549, loss=1.1745593547821045
I0304 21:36:00.851583 140239850956544 logging_writer.py:48] [428900] global_step=428900, grad_norm=3.323401689529419, loss=3.1986730098724365
I0304 21:36:46.172189 140239842563840 logging_writer.py:48] [429000] global_step=429000, grad_norm=3.6398301124572754, loss=3.122966766357422
I0304 21:37:31.639877 140239850956544 logging_writer.py:48] [429100] global_step=429100, grad_norm=3.1203248500823975, loss=1.2169122695922852
I0304 21:38:09.620701 140437341357888 spec.py:321] Evaluating on the training split.
I0304 21:38:19.993665 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:38:43.128367 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:38:44.752543 140437341357888 submission_runner.py:411] Time since start: 209166.30s, 	Step: 429185, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.4158594012260437, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 192028.75000452995, 'total_duration': 209166.30269360542, 'accumulated_submission_time': 192028.75000452995, 'accumulated_eval_time': 17077.692586660385, 'accumulated_logging_time': 36.40941309928894}
I0304 21:38:44.854576 140239842563840 logging_writer.py:48] [429185] accumulated_eval_time=17077.692587, accumulated_logging_time=36.409413, accumulated_submission_time=192028.750005, global_step=429185, preemption_count=0, score=192028.750005, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=209166.302694, train/accuracy=0.888438, train/loss=0.415859, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:38:51.201792 140239850956544 logging_writer.py:48] [429200] global_step=429200, grad_norm=2.9071133136749268, loss=1.0951817035675049
I0304 21:39:33.440598 140239842563840 logging_writer.py:48] [429300] global_step=429300, grad_norm=2.8639707565307617, loss=1.7191219329833984
I0304 21:40:18.681754 140239850956544 logging_writer.py:48] [429400] global_step=429400, grad_norm=2.9400250911712646, loss=1.0981152057647705
I0304 21:41:04.065535 140239842563840 logging_writer.py:48] [429500] global_step=429500, grad_norm=3.069039821624756, loss=1.0696923732757568
I0304 21:41:49.074772 140239850956544 logging_writer.py:48] [429600] global_step=429600, grad_norm=3.2116024494171143, loss=2.9350364208221436
I0304 21:42:34.411995 140239842563840 logging_writer.py:48] [429700] global_step=429700, grad_norm=3.1598286628723145, loss=1.1559733152389526
I0304 21:43:19.603620 140239850956544 logging_writer.py:48] [429800] global_step=429800, grad_norm=3.3343255519866943, loss=1.4821020364761353
I0304 21:44:04.896741 140239842563840 logging_writer.py:48] [429900] global_step=429900, grad_norm=2.9000649452209473, loss=1.1930526494979858
I0304 21:44:49.977611 140239850956544 logging_writer.py:48] [430000] global_step=430000, grad_norm=3.6388697624206543, loss=3.050598382949829
I0304 21:45:35.156604 140239842563840 logging_writer.py:48] [430100] global_step=430100, grad_norm=3.2277162075042725, loss=1.1878474950790405
I0304 21:45:45.196521 140437341357888 spec.py:321] Evaluating on the training split.
I0304 21:45:55.629739 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:46:21.685626 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:46:23.314379 140437341357888 submission_runner.py:411] Time since start: 209624.87s, 	Step: 430124, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.4134212136268616, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 192449.02923035622, 'total_duration': 209624.86515569687, 'accumulated_submission_time': 192449.02923035622, 'accumulated_eval_time': 17115.80970931053, 'accumulated_logging_time': 36.52241349220276}
I0304 21:46:23.414635 140239850956544 logging_writer.py:48] [430124] accumulated_eval_time=17115.809709, accumulated_logging_time=36.522413, accumulated_submission_time=192449.029230, global_step=430124, preemption_count=0, score=192449.029230, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=209624.865156, train/accuracy=0.888379, train/loss=0.413421, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:46:54.387929 140239842563840 logging_writer.py:48] [430200] global_step=430200, grad_norm=3.3573968410491943, loss=3.0944221019744873
I0304 21:47:39.438693 140239850956544 logging_writer.py:48] [430300] global_step=430300, grad_norm=3.095858573913574, loss=2.787518262863159
I0304 21:48:25.162189 140239842563840 logging_writer.py:48] [430400] global_step=430400, grad_norm=2.855194091796875, loss=1.0074446201324463
I0304 21:49:10.714156 140239850956544 logging_writer.py:48] [430500] global_step=430500, grad_norm=3.914818286895752, loss=3.1827056407928467
I0304 21:49:55.823869 140239842563840 logging_writer.py:48] [430600] global_step=430600, grad_norm=3.0987708568573, loss=1.6735228300094604
I0304 21:50:40.885443 140239850956544 logging_writer.py:48] [430700] global_step=430700, grad_norm=3.1045844554901123, loss=1.2190362215042114
I0304 21:51:26.084733 140239842563840 logging_writer.py:48] [430800] global_step=430800, grad_norm=3.113114833831787, loss=1.2316454648971558
I0304 21:52:11.473540 140239850956544 logging_writer.py:48] [430900] global_step=430900, grad_norm=4.204877853393555, loss=3.266055107116699
I0304 21:52:56.671008 140239842563840 logging_writer.py:48] [431000] global_step=431000, grad_norm=3.160675048828125, loss=1.901921033859253
I0304 21:53:23.591264 140437341357888 spec.py:321] Evaluating on the training split.
I0304 21:53:33.807612 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 21:54:05.477899 140437341357888 spec.py:349] Evaluating on the test split.
I0304 21:54:07.108637 140437341357888 submission_runner.py:411] Time since start: 210088.66s, 	Step: 431061, 	{'train/accuracy': 0.8847460746765137, 'train/loss': 0.4247710406780243, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 192869.14423632622, 'total_duration': 210088.6588923931, 'accumulated_submission_time': 192869.14423632622, 'accumulated_eval_time': 17159.325850486755, 'accumulated_logging_time': 36.63349270820618}
I0304 21:54:07.219036 140239850956544 logging_writer.py:48] [431061] accumulated_eval_time=17159.325850, accumulated_logging_time=36.633493, accumulated_submission_time=192869.144236, global_step=431061, preemption_count=0, score=192869.144236, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=210088.658892, train/accuracy=0.884746, train/loss=0.424771, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 21:54:23.093604 140239842563840 logging_writer.py:48] [431100] global_step=431100, grad_norm=2.917876720428467, loss=1.5352370738983154
I0304 21:55:05.840370 140239850956544 logging_writer.py:48] [431200] global_step=431200, grad_norm=3.8050737380981445, loss=3.2200655937194824
I0304 21:55:51.247800 140239842563840 logging_writer.py:48] [431300] global_step=431300, grad_norm=3.4839372634887695, loss=2.8133509159088135
I0304 21:56:37.123045 140239850956544 logging_writer.py:48] [431400] global_step=431400, grad_norm=2.919619083404541, loss=1.869257926940918
I0304 21:57:22.663940 140239842563840 logging_writer.py:48] [431500] global_step=431500, grad_norm=3.0311877727508545, loss=1.1380139589309692
I0304 21:58:07.911127 140239850956544 logging_writer.py:48] [431600] global_step=431600, grad_norm=3.0899081230163574, loss=2.1670122146606445
I0304 21:58:53.198133 140239842563840 logging_writer.py:48] [431700] global_step=431700, grad_norm=3.083186626434326, loss=1.0854990482330322
I0304 21:59:38.310373 140239850956544 logging_writer.py:48] [431800] global_step=431800, grad_norm=3.292125940322876, loss=2.1764111518859863
I0304 22:00:23.516706 140239842563840 logging_writer.py:48] [431900] global_step=431900, grad_norm=2.9250402450561523, loss=0.9996412992477417
I0304 22:01:07.129260 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:01:17.308024 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:01:42.746234 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:01:44.367929 140437341357888 submission_runner.py:411] Time since start: 210545.92s, 	Step: 431998, 	{'train/accuracy': 0.8877539038658142, 'train/loss': 0.41517573595046997, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 193288.98817515373, 'total_duration': 210545.91840672493, 'accumulated_submission_time': 193288.98817515373, 'accumulated_eval_time': 17196.563505887985, 'accumulated_logging_time': 36.75905227661133}
I0304 22:01:44.470674 140239850956544 logging_writer.py:48] [431998] accumulated_eval_time=17196.563506, accumulated_logging_time=36.759052, accumulated_submission_time=193288.988175, global_step=431998, preemption_count=0, score=193288.988175, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=210545.918407, train/accuracy=0.887754, train/loss=0.415176, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:01:45.678158 140239842563840 logging_writer.py:48] [432000] global_step=432000, grad_norm=3.2551655769348145, loss=2.760509490966797
I0304 22:02:27.021818 140239842563840 logging_writer.py:48] [432100] global_step=432100, grad_norm=2.962557077407837, loss=1.5678226947784424
I0304 22:03:12.034003 140239850956544 logging_writer.py:48] [432200] global_step=432200, grad_norm=3.468770742416382, loss=3.16308331489563
I0304 22:03:57.320437 140239842563840 logging_writer.py:48] [432300] global_step=432300, grad_norm=3.2383224964141846, loss=1.0898760557174683
I0304 22:04:42.488172 140239850956544 logging_writer.py:48] [432400] global_step=432400, grad_norm=4.030203342437744, loss=3.1870779991149902
I0304 22:05:27.800495 140239842563840 logging_writer.py:48] [432500] global_step=432500, grad_norm=2.9566357135772705, loss=1.0240365266799927
I0304 22:06:13.036319 140239850956544 logging_writer.py:48] [432600] global_step=432600, grad_norm=2.81071400642395, loss=1.597470760345459
I0304 22:06:58.314174 140239842563840 logging_writer.py:48] [432700] global_step=432700, grad_norm=2.9236385822296143, loss=2.4958765506744385
I0304 22:07:43.624078 140239850956544 logging_writer.py:48] [432800] global_step=432800, grad_norm=2.9712531566619873, loss=1.1180510520935059
I0304 22:08:29.212763 140239842563840 logging_writer.py:48] [432900] global_step=432900, grad_norm=3.1419215202331543, loss=1.2265406847000122
I0304 22:08:44.615551 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:08:55.047995 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:09:25.948498 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:09:27.567615 140437341357888 submission_runner.py:411] Time since start: 211009.12s, 	Step: 432936, 	{'train/accuracy': 0.8878124952316284, 'train/loss': 0.4115523099899292, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 193709.06731200218, 'total_duration': 211009.11804699898, 'accumulated_submission_time': 193709.06731200218, 'accumulated_eval_time': 17239.514502763748, 'accumulated_logging_time': 36.87295937538147}
I0304 22:09:27.677893 140239850956544 logging_writer.py:48] [432936] accumulated_eval_time=17239.514503, accumulated_logging_time=36.872959, accumulated_submission_time=193709.067312, global_step=432936, preemption_count=0, score=193709.067312, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=211009.118047, train/accuracy=0.887812, train/loss=0.411552, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:09:53.424649 140239842563840 logging_writer.py:48] [433000] global_step=433000, grad_norm=2.929931640625, loss=1.1535195112228394
I0304 22:10:38.141894 140239850956544 logging_writer.py:48] [433100] global_step=433100, grad_norm=3.6171910762786865, loss=1.1739099025726318
I0304 22:11:23.621240 140239842563840 logging_writer.py:48] [433200] global_step=433200, grad_norm=3.2699458599090576, loss=2.6089205741882324
I0304 22:12:08.941808 140239850956544 logging_writer.py:48] [433300] global_step=433300, grad_norm=4.0054473876953125, loss=3.17826509475708
I0304 22:12:54.246799 140239842563840 logging_writer.py:48] [433400] global_step=433400, grad_norm=2.9339182376861572, loss=1.1285340785980225
I0304 22:13:39.619562 140239850956544 logging_writer.py:48] [433500] global_step=433500, grad_norm=3.779087543487549, loss=3.0759003162384033
I0304 22:14:24.956816 140239842563840 logging_writer.py:48] [433600] global_step=433600, grad_norm=3.357001304626465, loss=2.229569911956787
I0304 22:15:10.364581 140239850956544 logging_writer.py:48] [433700] global_step=433700, grad_norm=3.0039665699005127, loss=1.1046234369277954
I0304 22:15:55.661857 140239842563840 logging_writer.py:48] [433800] global_step=433800, grad_norm=3.1345062255859375, loss=2.2012667655944824
I0304 22:16:27.851988 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:16:38.285440 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:17:05.331350 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:17:06.974755 140437341357888 submission_runner.py:411] Time since start: 211468.53s, 	Step: 433872, 	{'train/accuracy': 0.8901171684265137, 'train/loss': 0.4164775013923645, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 194129.18050289154, 'total_duration': 211468.52519202232, 'accumulated_submission_time': 194129.18050289154, 'accumulated_eval_time': 17278.63621211052, 'accumulated_logging_time': 36.99358677864075}
I0304 22:17:07.102101 140239850956544 logging_writer.py:48] [433872] accumulated_eval_time=17278.636212, accumulated_logging_time=36.993587, accumulated_submission_time=194129.180503, global_step=433872, preemption_count=0, score=194129.180503, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=211468.525192, train/accuracy=0.890117, train/loss=0.416478, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:17:18.639007 140239842563840 logging_writer.py:48] [433900] global_step=433900, grad_norm=3.0834357738494873, loss=1.2361011505126953
I0304 22:18:01.437196 140239850956544 logging_writer.py:48] [434000] global_step=434000, grad_norm=3.0584816932678223, loss=1.6525694131851196
I0304 22:18:46.649066 140239842563840 logging_writer.py:48] [434100] global_step=434100, grad_norm=4.1326704025268555, loss=3.2941231727600098
I0304 22:19:32.260125 140239850956544 logging_writer.py:48] [434200] global_step=434200, grad_norm=3.179931402206421, loss=1.1989938020706177
I0304 22:20:17.433153 140239842563840 logging_writer.py:48] [434300] global_step=434300, grad_norm=3.337966203689575, loss=2.7999253273010254
I0304 22:21:02.552232 140239850956544 logging_writer.py:48] [434400] global_step=434400, grad_norm=3.3780345916748047, loss=2.725847005844116
I0304 22:21:47.655481 140239842563840 logging_writer.py:48] [434500] global_step=434500, grad_norm=4.03062629699707, loss=3.1783456802368164
I0304 22:22:32.820304 140239850956544 logging_writer.py:48] [434600] global_step=434600, grad_norm=2.978302478790283, loss=1.0917439460754395
I0304 22:23:18.128377 140239842563840 logging_writer.py:48] [434700] global_step=434700, grad_norm=2.943173885345459, loss=1.230193018913269
I0304 22:24:03.311938 140239850956544 logging_writer.py:48] [434800] global_step=434800, grad_norm=3.4711127281188965, loss=3.052093982696533
I0304 22:24:07.175374 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:24:17.463255 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:24:46.325063 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:24:47.967370 140437341357888 submission_runner.py:411] Time since start: 211929.52s, 	Step: 434810, 	{'train/accuracy': 0.887988269329071, 'train/loss': 0.41553401947021484, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 194549.187220335, 'total_duration': 211929.5177807808, 'accumulated_submission_time': 194549.187220335, 'accumulated_eval_time': 17319.42714571953, 'accumulated_logging_time': 37.13652777671814}
I0304 22:24:48.070282 140239842563840 logging_writer.py:48] [434810] accumulated_eval_time=17319.427146, accumulated_logging_time=37.136528, accumulated_submission_time=194549.187220, global_step=434810, preemption_count=0, score=194549.187220, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=211929.517781, train/accuracy=0.887988, train/loss=0.415534, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:25:24.789340 140239850956544 logging_writer.py:48] [434900] global_step=434900, grad_norm=2.8958261013031006, loss=1.1745545864105225
I0304 22:26:09.987577 140239842563840 logging_writer.py:48] [435000] global_step=435000, grad_norm=3.085693359375, loss=1.1521648168563843
I0304 22:26:55.435258 140239850956544 logging_writer.py:48] [435100] global_step=435100, grad_norm=3.3876330852508545, loss=1.1687778234481812
I0304 22:27:40.670524 140239842563840 logging_writer.py:48] [435200] global_step=435200, grad_norm=3.775721788406372, loss=3.182683229446411
I0304 22:28:26.018566 140239850956544 logging_writer.py:48] [435300] global_step=435300, grad_norm=3.5886144638061523, loss=3.2448272705078125
I0304 22:29:11.564814 140239842563840 logging_writer.py:48] [435400] global_step=435400, grad_norm=3.088778495788574, loss=1.1853976249694824
I0304 22:29:56.791900 140239850956544 logging_writer.py:48] [435500] global_step=435500, grad_norm=2.843885898590088, loss=1.4641873836517334
I0304 22:30:42.142194 140239842563840 logging_writer.py:48] [435600] global_step=435600, grad_norm=2.7826573848724365, loss=1.7696218490600586
I0304 22:31:27.301162 140239850956544 logging_writer.py:48] [435700] global_step=435700, grad_norm=2.9688210487365723, loss=1.9912171363830566
I0304 22:31:48.226699 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:31:58.557640 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:32:28.374038 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:32:29.990187 140437341357888 submission_runner.py:411] Time since start: 212391.54s, 	Step: 435748, 	{'train/accuracy': 0.8893749713897705, 'train/loss': 0.4128265976905823, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 194969.2794907093, 'total_duration': 212391.54075169563, 'accumulated_submission_time': 194969.2794907093, 'accumulated_eval_time': 17361.18970298767, 'accumulated_logging_time': 37.25248050689697}
I0304 22:32:30.093921 140239842563840 logging_writer.py:48] [435748] accumulated_eval_time=17361.189703, accumulated_logging_time=37.252481, accumulated_submission_time=194969.279491, global_step=435748, preemption_count=0, score=194969.279491, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=212391.540752, train/accuracy=0.889375, train/loss=0.412827, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:32:51.113218 140239850956544 logging_writer.py:48] [435800] global_step=435800, grad_norm=3.1533076763153076, loss=1.5172613859176636
I0304 22:33:35.325930 140239842563840 logging_writer.py:48] [435900] global_step=435900, grad_norm=3.1394190788269043, loss=1.1512866020202637
I0304 22:34:20.601800 140239850956544 logging_writer.py:48] [436000] global_step=436000, grad_norm=2.8903369903564453, loss=1.8105297088623047
I0304 22:35:05.618957 140239842563840 logging_writer.py:48] [436100] global_step=436100, grad_norm=3.0285916328430176, loss=1.1362754106521606
I0304 22:35:50.963964 140239850956544 logging_writer.py:48] [436200] global_step=436200, grad_norm=3.0305607318878174, loss=1.2097077369689941
I0304 22:36:36.625949 140239842563840 logging_writer.py:48] [436300] global_step=436300, grad_norm=3.238194465637207, loss=1.1849966049194336
I0304 22:37:21.873048 140239850956544 logging_writer.py:48] [436400] global_step=436400, grad_norm=3.575622320175171, loss=2.9710917472839355
I0304 22:38:07.044791 140239842563840 logging_writer.py:48] [436500] global_step=436500, grad_norm=2.9756433963775635, loss=1.0789824724197388
I0304 22:38:52.107202 140239850956544 logging_writer.py:48] [436600] global_step=436600, grad_norm=3.167145252227783, loss=2.3798365592956543
I0304 22:39:30.091178 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:39:40.675922 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:40:10.705342 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:40:12.350843 140437341357888 submission_runner.py:411] Time since start: 212853.90s, 	Step: 436685, 	{'train/accuracy': 0.8864257335662842, 'train/loss': 0.4213772416114807, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 195389.2151684761, 'total_duration': 212853.9011592865, 'accumulated_submission_time': 195389.2151684761, 'accumulated_eval_time': 17403.448195934296, 'accumulated_logging_time': 37.366387605667114}
I0304 22:40:12.472508 140239842563840 logging_writer.py:48] [436685] accumulated_eval_time=17403.448196, accumulated_logging_time=37.366388, accumulated_submission_time=195389.215168, global_step=436685, preemption_count=0, score=195389.215168, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=212853.901159, train/accuracy=0.886426, train/loss=0.421377, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:40:18.809192 140239850956544 logging_writer.py:48] [436700] global_step=436700, grad_norm=2.8846094608306885, loss=2.2983596324920654
I0304 22:40:59.457407 140239842563840 logging_writer.py:48] [436800] global_step=436800, grad_norm=2.9804863929748535, loss=1.0733039379119873
I0304 22:41:44.693614 140239850956544 logging_writer.py:48] [436900] global_step=436900, grad_norm=3.213078737258911, loss=1.3332107067108154
I0304 22:42:30.257906 140239842563840 logging_writer.py:48] [437000] global_step=437000, grad_norm=3.099879026412964, loss=3.0531411170959473
I0304 22:43:15.551793 140239850956544 logging_writer.py:48] [437100] global_step=437100, grad_norm=3.0738611221313477, loss=1.3149316310882568
I0304 22:44:00.874786 140239842563840 logging_writer.py:48] [437200] global_step=437200, grad_norm=3.0969090461730957, loss=1.1400694847106934
I0304 22:44:46.450587 140239850956544 logging_writer.py:48] [437300] global_step=437300, grad_norm=2.8950886726379395, loss=1.3845469951629639
I0304 22:45:31.755171 140239842563840 logging_writer.py:48] [437400] global_step=437400, grad_norm=2.9259159564971924, loss=1.066041111946106
I0304 22:46:16.995148 140239850956544 logging_writer.py:48] [437500] global_step=437500, grad_norm=2.8397328853607178, loss=1.025903344154358
I0304 22:47:02.437866 140239842563840 logging_writer.py:48] [437600] global_step=437600, grad_norm=2.988675832748413, loss=2.3750228881835938
I0304 22:47:12.562819 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:47:22.944783 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:47:49.086056 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:47:50.709041 140437341357888 submission_runner.py:411] Time since start: 213312.26s, 	Step: 437624, 	{'train/accuracy': 0.8902343511581421, 'train/loss': 0.40923163294792175, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 195809.24481654167, 'total_duration': 213312.25943803787, 'accumulated_submission_time': 195809.24481654167, 'accumulated_eval_time': 17441.593303203583, 'accumulated_logging_time': 37.49781918525696}
I0304 22:47:50.810362 140239850956544 logging_writer.py:48] [437624] accumulated_eval_time=17441.593303, accumulated_logging_time=37.497819, accumulated_submission_time=195809.244817, global_step=437624, preemption_count=0, score=195809.244817, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=213312.259438, train/accuracy=0.890234, train/loss=0.409232, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:48:21.835451 140239842563840 logging_writer.py:48] [437700] global_step=437700, grad_norm=3.355973482131958, loss=2.941497325897217
I0304 22:49:06.944611 140239850956544 logging_writer.py:48] [437800] global_step=437800, grad_norm=2.8293700218200684, loss=1.096977949142456
I0304 22:49:52.449564 140239842563840 logging_writer.py:48] [437900] global_step=437900, grad_norm=3.151204824447632, loss=1.9121109247207642
I0304 22:50:37.589114 140239850956544 logging_writer.py:48] [438000] global_step=438000, grad_norm=3.0783848762512207, loss=1.438513159751892
I0304 22:51:22.830368 140239842563840 logging_writer.py:48] [438100] global_step=438100, grad_norm=3.5364444255828857, loss=1.486267328262329
I0304 22:52:08.149430 140239850956544 logging_writer.py:48] [438200] global_step=438200, grad_norm=3.0053253173828125, loss=1.205946683883667
I0304 22:52:53.237636 140239842563840 logging_writer.py:48] [438300] global_step=438300, grad_norm=3.0065133571624756, loss=1.025933027267456
I0304 22:53:38.390764 140239850956544 logging_writer.py:48] [438400] global_step=438400, grad_norm=3.299469470977783, loss=1.3187692165374756
I0304 22:54:23.605820 140239842563840 logging_writer.py:48] [438500] global_step=438500, grad_norm=2.9282889366149902, loss=1.1540477275848389
I0304 22:54:51.022405 140437341357888 spec.py:321] Evaluating on the training split.
I0304 22:55:01.542644 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 22:55:31.613211 140437341357888 spec.py:349] Evaluating on the test split.
I0304 22:55:33.239129 140437341357888 submission_runner.py:411] Time since start: 213774.79s, 	Step: 438562, 	{'train/accuracy': 0.8884179592132568, 'train/loss': 0.41259950399398804, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 196229.3932518959, 'total_duration': 213774.78959608078, 'accumulated_submission_time': 196229.3932518959, 'accumulated_eval_time': 17483.80901670456, 'accumulated_logging_time': 37.61236357688904}
I0304 22:55:33.369005 140239850956544 logging_writer.py:48] [438562] accumulated_eval_time=17483.809017, accumulated_logging_time=37.612364, accumulated_submission_time=196229.393252, global_step=438562, preemption_count=0, score=196229.393252, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=213774.789596, train/accuracy=0.888418, train/loss=0.412600, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 22:55:48.834610 140239842563840 logging_writer.py:48] [438600] global_step=438600, grad_norm=2.9476046562194824, loss=1.0317800045013428
I0304 22:56:32.217674 140239850956544 logging_writer.py:48] [438700] global_step=438700, grad_norm=3.1550116539001465, loss=1.0849558115005493
I0304 22:57:17.723054 140239842563840 logging_writer.py:48] [438800] global_step=438800, grad_norm=3.1265459060668945, loss=1.4481548070907593
I0304 22:58:03.160114 140239850956544 logging_writer.py:48] [438900] global_step=438900, grad_norm=3.2301175594329834, loss=2.8396315574645996
I0304 22:58:48.189632 140239842563840 logging_writer.py:48] [439000] global_step=439000, grad_norm=3.032630205154419, loss=1.3023470640182495
I0304 22:59:33.613145 140239850956544 logging_writer.py:48] [439100] global_step=439100, grad_norm=3.3080506324768066, loss=1.5335655212402344
I0304 23:00:19.240611 140239842563840 logging_writer.py:48] [439200] global_step=439200, grad_norm=3.3283190727233887, loss=2.740931510925293
I0304 23:01:04.523402 140239850956544 logging_writer.py:48] [439300] global_step=439300, grad_norm=2.9462358951568604, loss=1.1520357131958008
I0304 23:01:49.643875 140239842563840 logging_writer.py:48] [439400] global_step=439400, grad_norm=2.9162614345550537, loss=1.8363027572631836
I0304 23:02:33.278774 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:02:43.585057 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:03:17.418310 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:03:19.051828 140437341357888 submission_runner.py:411] Time since start: 214240.60s, 	Step: 439498, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.41825178265571594, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 196649.24244713783, 'total_duration': 214240.60220837593, 'accumulated_submission_time': 196649.24244713783, 'accumulated_eval_time': 17529.58095383644, 'accumulated_logging_time': 37.7523980140686}
I0304 23:03:19.136504 140239850956544 logging_writer.py:48] [439498] accumulated_eval_time=17529.580954, accumulated_logging_time=37.752398, accumulated_submission_time=196649.242447, global_step=439498, preemption_count=0, score=196649.242447, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=214240.602208, train/accuracy=0.887910, train/loss=0.418252, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:03:20.328786 140239842563840 logging_writer.py:48] [439500] global_step=439500, grad_norm=2.9371089935302734, loss=2.5225517749786377
I0304 23:04:00.525171 140239850956544 logging_writer.py:48] [439600] global_step=439600, grad_norm=3.766120195388794, loss=2.2663660049438477
I0304 23:04:45.913170 140239842563840 logging_writer.py:48] [439700] global_step=439700, grad_norm=3.1274163722991943, loss=1.1826238632202148
I0304 23:05:31.706005 140239850956544 logging_writer.py:48] [439800] global_step=439800, grad_norm=3.500417947769165, loss=2.6628148555755615
I0304 23:06:16.983863 140239842563840 logging_writer.py:48] [439900] global_step=439900, grad_norm=2.7790510654449463, loss=1.0565003156661987
I0304 23:07:02.396998 140239850956544 logging_writer.py:48] [440000] global_step=440000, grad_norm=3.0143840312957764, loss=1.0239440202713013
I0304 23:07:47.754891 140239842563840 logging_writer.py:48] [440100] global_step=440100, grad_norm=2.7584824562072754, loss=1.031595230102539
I0304 23:08:32.909775 140239850956544 logging_writer.py:48] [440200] global_step=440200, grad_norm=3.7024433612823486, loss=3.3210504055023193
I0304 23:09:18.581128 140239842563840 logging_writer.py:48] [440300] global_step=440300, grad_norm=2.874333381652832, loss=1.1142152547836304
I0304 23:10:04.201994 140239850956544 logging_writer.py:48] [440400] global_step=440400, grad_norm=3.344160318374634, loss=1.1313307285308838
I0304 23:10:19.187083 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:10:29.535502 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:10:58.374255 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:10:59.994627 140437341357888 submission_runner.py:411] Time since start: 214701.55s, 	Step: 440435, 	{'train/accuracy': 0.8888476490974426, 'train/loss': 0.4082626700401306, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 197069.23230481148, 'total_duration': 214701.54510903358, 'accumulated_submission_time': 197069.23230481148, 'accumulated_eval_time': 17570.387481451035, 'accumulated_logging_time': 37.847246170043945}
I0304 23:11:00.092610 140239842563840 logging_writer.py:48] [440435] accumulated_eval_time=17570.387481, accumulated_logging_time=37.847246, accumulated_submission_time=197069.232305, global_step=440435, preemption_count=0, score=197069.232305, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=214701.545109, train/accuracy=0.888848, train/loss=0.408263, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:11:26.320507 140239850956544 logging_writer.py:48] [440500] global_step=440500, grad_norm=2.9869234561920166, loss=1.0930166244506836
I0304 23:12:11.232261 140239842563840 logging_writer.py:48] [440600] global_step=440600, grad_norm=3.0172905921936035, loss=1.0864458084106445
I0304 23:12:56.473168 140239850956544 logging_writer.py:48] [440700] global_step=440700, grad_norm=3.0055179595947266, loss=2.6352035999298096
I0304 23:13:41.642786 140239842563840 logging_writer.py:48] [440800] global_step=440800, grad_norm=3.0153677463531494, loss=1.2798303365707397
I0304 23:14:27.180501 140239850956544 logging_writer.py:48] [440900] global_step=440900, grad_norm=2.9654343128204346, loss=1.6391462087631226
I0304 23:15:12.532503 140239842563840 logging_writer.py:48] [441000] global_step=441000, grad_norm=2.872511386871338, loss=1.1011242866516113
I0304 23:15:57.751793 140239850956544 logging_writer.py:48] [441100] global_step=441100, grad_norm=3.354268789291382, loss=2.4044647216796875
I0304 23:16:43.276799 140239842563840 logging_writer.py:48] [441200] global_step=441200, grad_norm=3.636064291000366, loss=3.158633232116699
I0304 23:17:28.756828 140239850956544 logging_writer.py:48] [441300] global_step=441300, grad_norm=3.3282079696655273, loss=2.9860122203826904
I0304 23:18:00.011990 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:18:10.870553 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:18:39.047134 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:18:40.671111 140437341357888 submission_runner.py:411] Time since start: 215162.22s, 	Step: 441371, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.4172675311565399, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 197489.0875673294, 'total_duration': 215162.22162938118, 'accumulated_submission_time': 197489.0875673294, 'accumulated_eval_time': 17611.045613527298, 'accumulated_logging_time': 37.9582302570343}
I0304 23:18:40.773905 140239842563840 logging_writer.py:48] [441371] accumulated_eval_time=17611.045614, accumulated_logging_time=37.958230, accumulated_submission_time=197489.087567, global_step=441371, preemption_count=0, score=197489.087567, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=215162.221629, train/accuracy=0.887383, train/loss=0.417268, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:18:52.682843 140239850956544 logging_writer.py:48] [441400] global_step=441400, grad_norm=3.289844274520874, loss=1.118364691734314
I0304 23:19:35.562470 140239842563840 logging_writer.py:48] [441500] global_step=441500, grad_norm=2.8113107681274414, loss=1.1256749629974365
I0304 23:20:20.726253 140239850956544 logging_writer.py:48] [441600] global_step=441600, grad_norm=3.8831915855407715, loss=3.245739698410034
I0304 23:21:06.237648 140239842563840 logging_writer.py:48] [441700] global_step=441700, grad_norm=3.8819127082824707, loss=3.256801128387451
I0304 23:21:51.248202 140239850956544 logging_writer.py:48] [441800] global_step=441800, grad_norm=3.4434640407562256, loss=2.9483180046081543
I0304 23:22:36.440471 140239842563840 logging_writer.py:48] [441900] global_step=441900, grad_norm=3.2559797763824463, loss=1.4770714044570923
I0304 23:23:21.940765 140239850956544 logging_writer.py:48] [442000] global_step=442000, grad_norm=3.1615452766418457, loss=2.735896587371826
I0304 23:24:07.130166 140239842563840 logging_writer.py:48] [442100] global_step=442100, grad_norm=3.701115369796753, loss=3.074181079864502
I0304 23:24:52.296702 140239850956544 logging_writer.py:48] [442200] global_step=442200, grad_norm=3.048119068145752, loss=1.102409839630127
I0304 23:25:37.818636 140239842563840 logging_writer.py:48] [442300] global_step=442300, grad_norm=2.9176275730133057, loss=2.1155781745910645
I0304 23:25:41.017217 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:25:51.330320 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:26:20.098857 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:26:21.729345 140437341357888 submission_runner.py:411] Time since start: 215623.28s, 	Step: 442309, 	{'train/accuracy': 0.8910546898841858, 'train/loss': 0.41432660818099976, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 197909.26830005646, 'total_duration': 215623.2797615528, 'accumulated_submission_time': 197909.26830005646, 'accumulated_eval_time': 17651.756640195847, 'accumulated_logging_time': 38.073039293289185}
I0304 23:26:21.831817 140239850956544 logging_writer.py:48] [442309] accumulated_eval_time=17651.756640, accumulated_logging_time=38.073039, accumulated_submission_time=197909.268300, global_step=442309, preemption_count=0, score=197909.268300, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=215623.279762, train/accuracy=0.891055, train/loss=0.414327, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:26:59.471274 140239842563840 logging_writer.py:48] [442400] global_step=442400, grad_norm=3.0765457153320312, loss=1.9407222270965576
I0304 23:27:44.654577 140239850956544 logging_writer.py:48] [442500] global_step=442500, grad_norm=4.428108215332031, loss=3.0234322547912598
I0304 23:28:30.104973 140239842563840 logging_writer.py:48] [442600] global_step=442600, grad_norm=2.887415885925293, loss=1.313141107559204
I0304 23:29:15.156611 140239850956544 logging_writer.py:48] [442700] global_step=442700, grad_norm=2.913921594619751, loss=1.1233593225479126
I0304 23:30:00.133152 140239842563840 logging_writer.py:48] [442800] global_step=442800, grad_norm=2.9455840587615967, loss=1.1782063245773315
I0304 23:30:45.819762 140239850956544 logging_writer.py:48] [442900] global_step=442900, grad_norm=3.3483242988586426, loss=2.9739151000976562
I0304 23:31:31.226802 140239842563840 logging_writer.py:48] [443000] global_step=443000, grad_norm=3.773606061935425, loss=3.040219306945801
I0304 23:32:16.548781 140239850956544 logging_writer.py:48] [443100] global_step=443100, grad_norm=2.8346807956695557, loss=1.5111045837402344
I0304 23:33:02.052322 140239842563840 logging_writer.py:48] [443200] global_step=443200, grad_norm=2.683807611465454, loss=1.8147318363189697
I0304 23:33:21.791099 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:33:32.215015 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:34:05.306777 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:34:06.936901 140437341357888 submission_runner.py:411] Time since start: 216088.49s, 	Step: 443245, 	{'train/accuracy': 0.8901757597923279, 'train/loss': 0.40958476066589355, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 198329.16502404213, 'total_duration': 216088.4873046875, 'accumulated_submission_time': 198329.16502404213, 'accumulated_eval_time': 17696.90135359764, 'accumulated_logging_time': 38.18743085861206}
I0304 23:34:07.055845 140239850956544 logging_writer.py:48] [443245] accumulated_eval_time=17696.901354, accumulated_logging_time=38.187431, accumulated_submission_time=198329.165024, global_step=443245, preemption_count=0, score=198329.165024, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=216088.487305, train/accuracy=0.890176, train/loss=0.409585, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:34:29.278683 140239842563840 logging_writer.py:48] [443300] global_step=443300, grad_norm=3.680311441421509, loss=3.2058157920837402
I0304 23:35:13.032304 140239850956544 logging_writer.py:48] [443400] global_step=443400, grad_norm=2.991640567779541, loss=1.014331579208374
I0304 23:35:58.383944 140239842563840 logging_writer.py:48] [443500] global_step=443500, grad_norm=3.3162429332733154, loss=1.7401471138000488
I0304 23:36:44.007143 140239850956544 logging_writer.py:48] [443600] global_step=443600, grad_norm=2.849008560180664, loss=1.1570346355438232
I0304 23:37:29.158134 140239842563840 logging_writer.py:48] [443700] global_step=443700, grad_norm=2.9521427154541016, loss=1.106149435043335
I0304 23:38:14.425450 140239850956544 logging_writer.py:48] [443800] global_step=443800, grad_norm=3.0176737308502197, loss=1.062796711921692
I0304 23:38:59.728277 140239842563840 logging_writer.py:48] [443900] global_step=443900, grad_norm=3.5007474422454834, loss=1.198732852935791
I0304 23:39:45.070204 140239850956544 logging_writer.py:48] [444000] global_step=444000, grad_norm=3.120737314224243, loss=1.0349962711334229
I0304 23:40:30.507112 140239842563840 logging_writer.py:48] [444100] global_step=444100, grad_norm=2.9338865280151367, loss=1.0604969263076782
I0304 23:41:07.219719 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:41:17.647111 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:41:44.100663 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:41:45.726328 140437341357888 submission_runner.py:411] Time since start: 216547.28s, 	Step: 444182, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.412271648645401, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 198749.26356339455, 'total_duration': 216547.2765877247, 'accumulated_submission_time': 198749.26356339455, 'accumulated_eval_time': 17735.406715393066, 'accumulated_logging_time': 38.32096481323242}
I0304 23:41:45.830218 140239850956544 logging_writer.py:48] [444182] accumulated_eval_time=17735.406715, accumulated_logging_time=38.320965, accumulated_submission_time=198749.263563, global_step=444182, preemption_count=0, score=198749.263563, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=216547.276588, train/accuracy=0.888906, train/loss=0.412272, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:41:53.378662 140239842563840 logging_writer.py:48] [444200] global_step=444200, grad_norm=3.572744607925415, loss=3.067868232727051
I0304 23:42:35.956121 140239850956544 logging_writer.py:48] [444300] global_step=444300, grad_norm=2.777438163757324, loss=1.6131558418273926
I0304 23:43:21.252101 140239842563840 logging_writer.py:48] [444400] global_step=444400, grad_norm=3.563814640045166, loss=3.0796620845794678
I0304 23:44:06.710183 140239850956544 logging_writer.py:48] [444500] global_step=444500, grad_norm=3.678053855895996, loss=3.092151165008545
I0304 23:44:51.818709 140239842563840 logging_writer.py:48] [444600] global_step=444600, grad_norm=3.9282121658325195, loss=3.2801594734191895
I0304 23:45:36.978565 140239850956544 logging_writer.py:48] [444700] global_step=444700, grad_norm=2.8591275215148926, loss=1.2751386165618896
I0304 23:46:22.308579 140239842563840 logging_writer.py:48] [444800] global_step=444800, grad_norm=3.6645195484161377, loss=3.042571544647217
I0304 23:47:07.700491 140239850956544 logging_writer.py:48] [444900] global_step=444900, grad_norm=3.794210910797119, loss=2.8163740634918213
I0304 23:47:53.055178 140239842563840 logging_writer.py:48] [445000] global_step=445000, grad_norm=2.9324254989624023, loss=1.8874157667160034
I0304 23:48:38.260147 140239850956544 logging_writer.py:48] [445100] global_step=445100, grad_norm=3.5189688205718994, loss=2.764832019805908
I0304 23:48:46.008558 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:48:56.949108 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:49:25.038041 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:49:26.657762 140437341357888 submission_runner.py:411] Time since start: 217008.21s, 	Step: 445119, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.4158249497413635, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 199169.37876105309, 'total_duration': 217008.20818781853, 'accumulated_submission_time': 199169.37876105309, 'accumulated_eval_time': 17776.054845571518, 'accumulated_logging_time': 38.437227964401245}
I0304 23:49:26.765503 140239842563840 logging_writer.py:48] [445119] accumulated_eval_time=17776.054846, accumulated_logging_time=38.437228, accumulated_submission_time=199169.378761, global_step=445119, preemption_count=0, score=199169.378761, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=217008.208188, train/accuracy=0.888906, train/loss=0.415825, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:49:59.928336 140239850956544 logging_writer.py:48] [445200] global_step=445200, grad_norm=2.953092575073242, loss=1.9901034832000732
I0304 23:50:45.022742 140239842563840 logging_writer.py:48] [445300] global_step=445300, grad_norm=2.9399142265319824, loss=2.1454553604125977
I0304 23:51:30.732145 140239850956544 logging_writer.py:48] [445400] global_step=445400, grad_norm=2.863553524017334, loss=1.0366880893707275
I0304 23:52:16.507824 140239842563840 logging_writer.py:48] [445500] global_step=445500, grad_norm=3.093082904815674, loss=1.1206492185592651
I0304 23:53:01.949322 140239850956544 logging_writer.py:48] [445600] global_step=445600, grad_norm=2.8946127891540527, loss=1.4177660942077637
I0304 23:53:47.373837 140239842563840 logging_writer.py:48] [445700] global_step=445700, grad_norm=2.885826587677002, loss=1.019519329071045
I0304 23:54:32.893122 140239850956544 logging_writer.py:48] [445800] global_step=445800, grad_norm=2.98452091217041, loss=1.8728282451629639
I0304 23:55:18.298353 140239842563840 logging_writer.py:48] [445900] global_step=445900, grad_norm=2.963871717453003, loss=1.1904046535491943
I0304 23:56:03.814967 140239850956544 logging_writer.py:48] [446000] global_step=446000, grad_norm=3.053722858428955, loss=1.0716378688812256
I0304 23:56:26.659644 140437341357888 spec.py:321] Evaluating on the training split.
I0304 23:56:37.209012 140437341357888 spec.py:333] Evaluating on the validation split.
I0304 23:57:18.229804 140437341357888 spec.py:349] Evaluating on the test split.
I0304 23:57:19.842759 140437341357888 submission_runner.py:411] Time since start: 217481.39s, 	Step: 446052, 	{'train/accuracy': 0.8854687213897705, 'train/loss': 0.42126578092575073, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 199589.21167612076, 'total_duration': 217481.39326262474, 'accumulated_submission_time': 199589.21167612076, 'accumulated_eval_time': 17829.23697257042, 'accumulated_logging_time': 38.55621099472046}
I0304 23:57:19.927183 140239842563840 logging_writer.py:48] [446052] accumulated_eval_time=17829.236973, accumulated_logging_time=38.556211, accumulated_submission_time=199589.211676, global_step=446052, preemption_count=0, score=199589.211676, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=217481.393263, train/accuracy=0.885469, train/loss=0.421266, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0304 23:57:39.344072 140239850956544 logging_writer.py:48] [446100] global_step=446100, grad_norm=3.4345688819885254, loss=1.5745543241500854
I0304 23:58:21.756187 140239842563840 logging_writer.py:48] [446200] global_step=446200, grad_norm=3.2234244346618652, loss=1.1481584310531616
I0304 23:59:06.921721 140239850956544 logging_writer.py:48] [446300] global_step=446300, grad_norm=2.9547250270843506, loss=1.1809635162353516
I0304 23:59:52.772243 140239842563840 logging_writer.py:48] [446400] global_step=446400, grad_norm=3.1119844913482666, loss=1.1316392421722412
I0305 00:00:38.062989 140239850956544 logging_writer.py:48] [446500] global_step=446500, grad_norm=2.9979493618011475, loss=1.1302039623260498
I0305 00:01:23.567055 140239842563840 logging_writer.py:48] [446600] global_step=446600, grad_norm=3.229297399520874, loss=1.199005365371704
I0305 00:02:09.209075 140239850956544 logging_writer.py:48] [446700] global_step=446700, grad_norm=3.42191481590271, loss=1.3674113750457764
I0305 00:02:54.586705 140239842563840 logging_writer.py:48] [446800] global_step=446800, grad_norm=2.9572818279266357, loss=1.441373586654663
I0305 00:03:40.244183 140239850956544 logging_writer.py:48] [446900] global_step=446900, grad_norm=3.69093656539917, loss=3.0775322914123535
I0305 00:04:19.971203 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:04:30.277994 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:04:54.371823 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:04:55.994443 140437341357888 submission_runner.py:411] Time since start: 217937.54s, 	Step: 446989, 	{'train/accuracy': 0.8869921565055847, 'train/loss': 0.41610443592071533, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 200009.1923904419, 'total_duration': 217937.54481863976, 'accumulated_submission_time': 200009.1923904419, 'accumulated_eval_time': 17865.259093284607, 'accumulated_logging_time': 38.65262007713318}
I0305 00:04:56.100093 140239842563840 logging_writer.py:48] [446989] accumulated_eval_time=17865.259093, accumulated_logging_time=38.652620, accumulated_submission_time=200009.192390, global_step=446989, preemption_count=0, score=200009.192390, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=217937.544819, train/accuracy=0.886992, train/loss=0.416104, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:05:00.887834 140239850956544 logging_writer.py:48] [447000] global_step=447000, grad_norm=3.3909854888916016, loss=1.080512523651123
I0305 00:05:42.854608 140239842563840 logging_writer.py:48] [447100] global_step=447100, grad_norm=3.4350528717041016, loss=1.0962616205215454
I0305 00:06:28.202150 140239850956544 logging_writer.py:48] [447200] global_step=447200, grad_norm=2.977174758911133, loss=1.680040955543518
I0305 00:07:14.076011 140239842563840 logging_writer.py:48] [447300] global_step=447300, grad_norm=3.8285701274871826, loss=2.9961235523223877
I0305 00:07:59.273794 140239850956544 logging_writer.py:48] [447400] global_step=447400, grad_norm=2.57416033744812, loss=1.64345121383667
I0305 00:08:44.740326 140239842563840 logging_writer.py:48] [447500] global_step=447500, grad_norm=3.1082117557525635, loss=1.216413974761963
I0305 00:09:30.217128 140239850956544 logging_writer.py:48] [447600] global_step=447600, grad_norm=3.0084660053253174, loss=1.0772485733032227
I0305 00:10:15.704321 140239842563840 logging_writer.py:48] [447700] global_step=447700, grad_norm=3.1313750743865967, loss=1.1242579221725464
I0305 00:11:00.957830 140239850956544 logging_writer.py:48] [447800] global_step=447800, grad_norm=2.9910025596618652, loss=1.0691108703613281
I0305 00:11:46.742663 140239842563840 logging_writer.py:48] [447900] global_step=447900, grad_norm=3.718902349472046, loss=3.1331210136413574
I0305 00:11:56.380148 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:12:07.158914 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:12:37.221771 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:12:38.854102 140437341357888 submission_runner.py:411] Time since start: 218400.40s, 	Step: 447923, 	{'train/accuracy': 0.8915429711341858, 'train/loss': 0.40917032957077026, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 200429.40899014473, 'total_duration': 218400.40449666977, 'accumulated_submission_time': 200429.40899014473, 'accumulated_eval_time': 17907.731934070587, 'accumulated_logging_time': 38.77121067047119}
I0305 00:12:38.960073 140239850956544 logging_writer.py:48] [447923] accumulated_eval_time=17907.731934, accumulated_logging_time=38.771211, accumulated_submission_time=200429.408990, global_step=447923, preemption_count=0, score=200429.408990, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=218400.404497, train/accuracy=0.891543, train/loss=0.409170, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:13:10.496345 140239842563840 logging_writer.py:48] [448000] global_step=448000, grad_norm=3.3409502506256104, loss=1.4967819452285767
I0305 00:13:55.495548 140239850956544 logging_writer.py:48] [448100] global_step=448100, grad_norm=3.124351978302002, loss=1.1160919666290283
I0305 00:14:41.149535 140239842563840 logging_writer.py:48] [448200] global_step=448200, grad_norm=2.849621534347534, loss=1.080187439918518
I0305 00:15:26.494838 140239850956544 logging_writer.py:48] [448300] global_step=448300, grad_norm=3.667494773864746, loss=3.28814959526062
I0305 00:16:11.973565 140239842563840 logging_writer.py:48] [448400] global_step=448400, grad_norm=3.0412185192108154, loss=1.1745660305023193
I0305 00:16:57.446474 140239850956544 logging_writer.py:48] [448500] global_step=448500, grad_norm=3.1255528926849365, loss=1.1298818588256836
I0305 00:17:42.774511 140239842563840 logging_writer.py:48] [448600] global_step=448600, grad_norm=3.147440195083618, loss=1.6418375968933105
I0305 00:18:28.364593 140239850956544 logging_writer.py:48] [448700] global_step=448700, grad_norm=2.890270471572876, loss=2.0391197204589844
I0305 00:19:13.511956 140239842563840 logging_writer.py:48] [448800] global_step=448800, grad_norm=3.368499755859375, loss=1.1060311794281006
I0305 00:19:39.226965 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:19:50.006415 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:20:12.704782 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:20:14.353332 140437341357888 submission_runner.py:411] Time since start: 218855.90s, 	Step: 448858, 	{'train/accuracy': 0.8885351419448853, 'train/loss': 0.41493692994117737, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 200849.61452794075, 'total_duration': 218855.90346169472, 'accumulated_submission_time': 200849.61452794075, 'accumulated_eval_time': 17942.856937885284, 'accumulated_logging_time': 38.887372732162476}
I0305 00:20:14.456092 140239850956544 logging_writer.py:48] [448858] accumulated_eval_time=17942.856938, accumulated_logging_time=38.887373, accumulated_submission_time=200849.614528, global_step=448858, preemption_count=0, score=200849.614528, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=218855.903462, train/accuracy=0.888535, train/loss=0.414937, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:20:31.629858 140239842563840 logging_writer.py:48] [448900] global_step=448900, grad_norm=2.9612364768981934, loss=2.1196460723876953
I0305 00:21:13.992364 140239850956544 logging_writer.py:48] [449000] global_step=449000, grad_norm=3.003570079803467, loss=1.2175673246383667
I0305 00:21:59.144570 140239842563840 logging_writer.py:48] [449100] global_step=449100, grad_norm=2.8745737075805664, loss=1.7854657173156738
I0305 00:22:45.123907 140239850956544 logging_writer.py:48] [449200] global_step=449200, grad_norm=4.950069427490234, loss=2.931778907775879
I0305 00:23:30.405749 140239842563840 logging_writer.py:48] [449300] global_step=449300, grad_norm=3.247342109680176, loss=3.02437424659729
I0305 00:24:15.732659 140239850956544 logging_writer.py:48] [449400] global_step=449400, grad_norm=3.0123589038848877, loss=1.18967604637146
I0305 00:25:00.807257 140239842563840 logging_writer.py:48] [449500] global_step=449500, grad_norm=3.116656541824341, loss=1.0535069704055786
I0305 00:25:45.867025 140239850956544 logging_writer.py:48] [449600] global_step=449600, grad_norm=3.3332910537719727, loss=2.0182077884674072
I0305 00:26:31.135123 140239842563840 logging_writer.py:48] [449700] global_step=449700, grad_norm=2.9031670093536377, loss=1.0619462728500366
I0305 00:27:14.602195 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:27:25.273283 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:27:49.334814 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:27:50.964090 140437341357888 submission_runner.py:411] Time since start: 219312.51s, 	Step: 449797, 	{'train/accuracy': 0.8884961009025574, 'train/loss': 0.4168313145637512, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 201269.6993484497, 'total_duration': 219312.5145866871, 'accumulated_submission_time': 201269.6993484497, 'accumulated_eval_time': 17979.217833518982, 'accumulated_logging_time': 38.999953508377075}
I0305 00:27:51.067775 140239850956544 logging_writer.py:48] [449797] accumulated_eval_time=17979.217834, accumulated_logging_time=38.999954, accumulated_submission_time=201269.699348, global_step=449797, preemption_count=0, score=201269.699348, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=219312.514587, train/accuracy=0.888496, train/loss=0.416831, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:27:52.671444 140239842563840 logging_writer.py:48] [449800] global_step=449800, grad_norm=3.111553430557251, loss=1.4807274341583252
I0305 00:28:34.538737 140239850956544 logging_writer.py:48] [449900] global_step=449900, grad_norm=3.007078170776367, loss=2.1328914165496826
I0305 00:29:19.727608 140239842563840 logging_writer.py:48] [450000] global_step=450000, grad_norm=3.0421319007873535, loss=1.210867166519165
I0305 00:30:05.014979 140239850956544 logging_writer.py:48] [450100] global_step=450100, grad_norm=2.9881999492645264, loss=1.085193157196045
I0305 00:30:50.174058 140239842563840 logging_writer.py:48] [450200] global_step=450200, grad_norm=3.003636360168457, loss=2.0587875843048096
I0305 00:31:35.341736 140239850956544 logging_writer.py:48] [450300] global_step=450300, grad_norm=2.9647340774536133, loss=1.0368682146072388
I0305 00:32:21.273350 140239842563840 logging_writer.py:48] [450400] global_step=450400, grad_norm=2.9397385120391846, loss=2.171786308288574
I0305 00:33:06.491365 140239850956544 logging_writer.py:48] [450500] global_step=450500, grad_norm=3.272071599960327, loss=2.4162328243255615
I0305 00:33:51.427700 140239842563840 logging_writer.py:48] [450600] global_step=450600, grad_norm=2.8513805866241455, loss=2.1701674461364746
I0305 00:34:36.654758 140239850956544 logging_writer.py:48] [450700] global_step=450700, grad_norm=3.0381813049316406, loss=1.3010962009429932
I0305 00:34:51.235738 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:35:01.740031 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:35:36.784762 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:35:38.402931 140437341357888 submission_runner.py:411] Time since start: 219779.95s, 	Step: 450734, 	{'train/accuracy': 0.8858007788658142, 'train/loss': 0.42144712805747986, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 201689.80603957176, 'total_duration': 219779.95336055756, 'accumulated_submission_time': 201689.80603957176, 'accumulated_eval_time': 18026.383950948715, 'accumulated_logging_time': 39.11453557014465}
I0305 00:35:38.508057 140239842563840 logging_writer.py:48] [450734] accumulated_eval_time=18026.383951, accumulated_logging_time=39.114536, accumulated_submission_time=201689.806040, global_step=450734, preemption_count=0, score=201689.806040, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=219779.953361, train/accuracy=0.885801, train/loss=0.421447, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:36:05.077569 140239850956544 logging_writer.py:48] [450800] global_step=450800, grad_norm=3.151484489440918, loss=1.1161456108093262
I0305 00:36:50.056274 140239842563840 logging_writer.py:48] [450900] global_step=450900, grad_norm=2.9180452823638916, loss=1.076393961906433
I0305 00:37:35.318025 140239850956544 logging_writer.py:48] [451000] global_step=451000, grad_norm=3.014820098876953, loss=1.0564486980438232
I0305 00:38:20.340575 140239842563840 logging_writer.py:48] [451100] global_step=451100, grad_norm=2.9429209232330322, loss=1.1231228113174438
I0305 00:39:05.933654 140239850956544 logging_writer.py:48] [451200] global_step=451200, grad_norm=3.2003772258758545, loss=2.481633186340332
I0305 00:39:50.827536 140239842563840 logging_writer.py:48] [451300] global_step=451300, grad_norm=2.8145651817321777, loss=1.0586217641830444
I0305 00:40:36.122531 140239850956544 logging_writer.py:48] [451400] global_step=451400, grad_norm=3.0219881534576416, loss=1.6104141473770142
I0305 00:41:21.268281 140239842563840 logging_writer.py:48] [451500] global_step=451500, grad_norm=3.320248603820801, loss=2.4809885025024414
I0305 00:42:06.524237 140239850956544 logging_writer.py:48] [451600] global_step=451600, grad_norm=3.2419545650482178, loss=2.501492977142334
I0305 00:42:38.534705 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:42:48.745938 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:43:19.757332 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:43:21.386985 140437341357888 submission_runner.py:411] Time since start: 220242.94s, 	Step: 451672, 	{'train/accuracy': 0.8877733945846558, 'train/loss': 0.4172125458717346, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 202109.7711122036, 'total_duration': 220242.93742847443, 'accumulated_submission_time': 202109.7711122036, 'accumulated_eval_time': 18069.235177755356, 'accumulated_logging_time': 39.230353116989136}
I0305 00:43:21.472010 140239842563840 logging_writer.py:48] [451672] accumulated_eval_time=18069.235178, accumulated_logging_time=39.230353, accumulated_submission_time=202109.771112, global_step=451672, preemption_count=0, score=202109.771112, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=220242.937428, train/accuracy=0.887773, train/loss=0.417213, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:43:32.962636 140239850956544 logging_writer.py:48] [451700] global_step=451700, grad_norm=3.2693381309509277, loss=1.104190707206726
I0305 00:44:14.317598 140239842563840 logging_writer.py:48] [451800] global_step=451800, grad_norm=2.9409432411193848, loss=1.3813621997833252
I0305 00:44:59.318048 140239850956544 logging_writer.py:48] [451900] global_step=451900, grad_norm=3.1715497970581055, loss=1.1836471557617188
I0305 00:45:44.840827 140239842563840 logging_writer.py:48] [452000] global_step=452000, grad_norm=3.1513469219207764, loss=1.1709455251693726
I0305 00:46:30.070597 140239850956544 logging_writer.py:48] [452100] global_step=452100, grad_norm=4.064728260040283, loss=3.1660807132720947
I0305 00:47:15.602290 140239842563840 logging_writer.py:48] [452200] global_step=452200, grad_norm=4.043367385864258, loss=3.155795097351074
I0305 00:48:00.700324 140239850956544 logging_writer.py:48] [452300] global_step=452300, grad_norm=3.1944398880004883, loss=2.681155204772949
I0305 00:48:46.138382 140239842563840 logging_writer.py:48] [452400] global_step=452400, grad_norm=2.7565321922302246, loss=1.744962215423584
I0305 00:49:31.332040 140239850956544 logging_writer.py:48] [452500] global_step=452500, grad_norm=3.044027805328369, loss=1.1137158870697021
I0305 00:50:16.434818 140239842563840 logging_writer.py:48] [452600] global_step=452600, grad_norm=2.9806597232818604, loss=1.0149712562561035
I0305 00:50:21.544293 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:50:32.077932 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:50:53.669702 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:50:55.292668 140437341357888 submission_runner.py:411] Time since start: 220696.84s, 	Step: 452613, 	{'train/accuracy': 0.888476550579071, 'train/loss': 0.4082569479942322, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 202529.78248882294, 'total_duration': 220696.84306454659, 'accumulated_submission_time': 202529.78248882294, 'accumulated_eval_time': 18102.982452869415, 'accumulated_logging_time': 39.325342893600464}
I0305 00:50:55.395855 140239850956544 logging_writer.py:48] [452613] accumulated_eval_time=18102.982453, accumulated_logging_time=39.325343, accumulated_submission_time=202529.782489, global_step=452613, preemption_count=0, score=202529.782489, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=220696.843065, train/accuracy=0.888477, train/loss=0.408257, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:51:31.262274 140239842563840 logging_writer.py:48] [452700] global_step=452700, grad_norm=2.930445909500122, loss=2.059187889099121
I0305 00:52:16.451195 140239850956544 logging_writer.py:48] [452800] global_step=452800, grad_norm=2.9088618755340576, loss=1.0665806531906128
I0305 00:53:01.636665 140239842563840 logging_writer.py:48] [452900] global_step=452900, grad_norm=3.277017831802368, loss=1.1789767742156982
I0305 00:53:47.180418 140239850956544 logging_writer.py:48] [453000] global_step=453000, grad_norm=4.568800926208496, loss=3.0240907669067383
I0305 00:54:32.385715 140239842563840 logging_writer.py:48] [453100] global_step=453100, grad_norm=3.1298153400421143, loss=1.3937665224075317
I0305 00:55:17.916392 140239850956544 logging_writer.py:48] [453200] global_step=453200, grad_norm=3.560323715209961, loss=3.185601234436035
I0305 00:56:03.182990 140239842563840 logging_writer.py:48] [453300] global_step=453300, grad_norm=3.772132158279419, loss=3.0989789962768555
I0305 00:56:48.501774 140239850956544 logging_writer.py:48] [453400] global_step=453400, grad_norm=3.1619246006011963, loss=1.1024060249328613
I0305 00:57:33.943674 140239842563840 logging_writer.py:48] [453500] global_step=453500, grad_norm=3.086928606033325, loss=1.0874381065368652
I0305 00:57:55.473555 140437341357888 spec.py:321] Evaluating on the training split.
I0305 00:58:06.371065 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 00:58:33.445726 140437341357888 spec.py:349] Evaluating on the test split.
I0305 00:58:35.070414 140437341357888 submission_runner.py:411] Time since start: 221156.62s, 	Step: 453549, 	{'train/accuracy': 0.8876367211341858, 'train/loss': 0.4193960428237915, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 202949.79995965958, 'total_duration': 221156.62088036537, 'accumulated_submission_time': 202949.79995965958, 'accumulated_eval_time': 18142.578282356262, 'accumulated_logging_time': 39.43860602378845}
I0305 00:58:35.177393 140239850956544 logging_writer.py:48] [453549] accumulated_eval_time=18142.578282, accumulated_logging_time=39.438606, accumulated_submission_time=202949.799960, global_step=453549, preemption_count=0, score=202949.799960, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=221156.620880, train/accuracy=0.887637, train/loss=0.419396, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 00:58:55.788285 140239842563840 logging_writer.py:48] [453600] global_step=453600, grad_norm=3.036283254623413, loss=2.013484477996826
I0305 00:59:40.320970 140239850956544 logging_writer.py:48] [453700] global_step=453700, grad_norm=2.7335712909698486, loss=1.4989625215530396
I0305 01:00:25.742648 140239842563840 logging_writer.py:48] [453800] global_step=453800, grad_norm=3.051426887512207, loss=2.0167596340179443
I0305 01:01:11.058531 140239850956544 logging_writer.py:48] [453900] global_step=453900, grad_norm=3.266068458557129, loss=3.060746192932129
I0305 01:01:56.013816 140239842563840 logging_writer.py:48] [454000] global_step=454000, grad_norm=3.0196895599365234, loss=1.758620262145996
I0305 01:02:41.650979 140239850956544 logging_writer.py:48] [454100] global_step=454100, grad_norm=3.418800115585327, loss=2.736471652984619
I0305 01:03:27.231527 140239842563840 logging_writer.py:48] [454200] global_step=454200, grad_norm=3.4325430393218994, loss=3.2318689823150635
I0305 01:04:12.198530 140239850956544 logging_writer.py:48] [454300] global_step=454300, grad_norm=3.105898380279541, loss=1.226696491241455
I0305 01:04:57.328489 140239842563840 logging_writer.py:48] [454400] global_step=454400, grad_norm=3.221597909927368, loss=2.3332018852233887
I0305 01:05:35.149554 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:05:45.450674 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 01:06:17.769524 140437341357888 spec.py:349] Evaluating on the test split.
I0305 01:06:19.432006 140437341357888 submission_runner.py:411] Time since start: 221620.98s, 	Step: 454485, 	{'train/accuracy': 0.8869335651397705, 'train/loss': 0.4207581579685211, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 203369.71106481552, 'total_duration': 221620.98258256912, 'accumulated_submission_time': 203369.71106481552, 'accumulated_eval_time': 18186.859826803207, 'accumulated_logging_time': 39.55583477020264}
I0305 01:06:19.517224 140239850956544 logging_writer.py:48] [454485] accumulated_eval_time=18186.859827, accumulated_logging_time=39.555835, accumulated_submission_time=203369.711065, global_step=454485, preemption_count=0, score=203369.711065, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=221620.982583, train/accuracy=0.886934, train/loss=0.420758, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 01:06:25.856092 140239842563840 logging_writer.py:48] [454500] global_step=454500, grad_norm=3.1623311042785645, loss=0.9744808673858643
I0305 01:07:06.380712 140239850956544 logging_writer.py:48] [454600] global_step=454600, grad_norm=3.0683388710021973, loss=1.1365771293640137
I0305 01:07:51.532109 140239842563840 logging_writer.py:48] [454700] global_step=454700, grad_norm=3.1808300018310547, loss=1.4743413925170898
I0305 01:08:37.335256 140239850956544 logging_writer.py:48] [454800] global_step=454800, grad_norm=3.024092197418213, loss=1.4616202116012573
I0305 01:09:22.732665 140239842563840 logging_writer.py:48] [454900] global_step=454900, grad_norm=3.080660820007324, loss=1.0783333778381348
I0305 01:10:07.955427 140239850956544 logging_writer.py:48] [455000] global_step=455000, grad_norm=2.866788625717163, loss=1.0116699934005737
I0305 01:10:52.922260 140239842563840 logging_writer.py:48] [455100] global_step=455100, grad_norm=3.205901861190796, loss=2.954768657684326
I0305 01:11:38.055841 140239850956544 logging_writer.py:48] [455200] global_step=455200, grad_norm=2.9277288913726807, loss=1.1395949125289917
I0305 01:12:23.427135 140239842563840 logging_writer.py:48] [455300] global_step=455300, grad_norm=3.3947620391845703, loss=3.098341464996338
I0305 01:13:08.818720 140239850956544 logging_writer.py:48] [455400] global_step=455400, grad_norm=3.0149917602539062, loss=1.2038264274597168
I0305 01:13:19.840044 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:13:30.270335 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 01:13:57.673505 140437341357888 spec.py:349] Evaluating on the test split.
I0305 01:13:59.308578 140437341357888 submission_runner.py:411] Time since start: 222080.86s, 	Step: 455426, 	{'train/accuracy': 0.88818359375, 'train/loss': 0.4161781072616577, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 203789.97352862358, 'total_duration': 222080.85911655426, 'accumulated_submission_time': 203789.97352862358, 'accumulated_eval_time': 18226.327399015427, 'accumulated_logging_time': 39.65032410621643}
I0305 01:13:59.415216 140239842563840 logging_writer.py:48] [455426] accumulated_eval_time=18226.327399, accumulated_logging_time=39.650324, accumulated_submission_time=203789.973529, global_step=455426, preemption_count=0, score=203789.973529, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=222080.859117, train/accuracy=0.888184, train/loss=0.416178, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 01:14:29.102263 140239850956544 logging_writer.py:48] [455500] global_step=455500, grad_norm=2.945423126220703, loss=1.1487298011779785
I0305 01:15:13.897417 140239842563840 logging_writer.py:48] [455600] global_step=455600, grad_norm=3.1391096115112305, loss=1.1984920501708984
I0305 01:15:59.148974 140239850956544 logging_writer.py:48] [455700] global_step=455700, grad_norm=3.2773187160491943, loss=1.3236984014511108
I0305 01:16:44.475264 140239842563840 logging_writer.py:48] [455800] global_step=455800, grad_norm=3.79982852935791, loss=2.766047477722168
I0305 01:17:29.876220 140239850956544 logging_writer.py:48] [455900] global_step=455900, grad_norm=3.1215012073516846, loss=1.1155250072479248
I0305 01:18:15.312011 140239842563840 logging_writer.py:48] [456000] global_step=456000, grad_norm=3.194417715072632, loss=2.040820837020874
I0305 01:19:00.637481 140239850956544 logging_writer.py:48] [456100] global_step=456100, grad_norm=3.2306084632873535, loss=1.1121442317962646
I0305 01:19:46.206280 140239842563840 logging_writer.py:48] [456200] global_step=456200, grad_norm=3.220029830932617, loss=1.091721773147583
I0305 01:20:31.715758 140239850956544 logging_writer.py:48] [456300] global_step=456300, grad_norm=2.997157096862793, loss=1.04840886592865
I0305 01:20:59.684882 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:21:10.487088 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 01:21:32.338893 140437341357888 spec.py:349] Evaluating on the test split.
I0305 01:21:33.958180 140437341357888 submission_runner.py:411] Time since start: 222535.51s, 	Step: 456364, 	{'train/accuracy': 0.8884375095367432, 'train/loss': 0.4117911756038666, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 204210.18108654022, 'total_duration': 222535.50862407684, 'accumulated_submission_time': 204210.18108654022, 'accumulated_eval_time': 18260.59964799881, 'accumulated_logging_time': 39.7682089805603}
I0305 01:21:34.062802 140239842563840 logging_writer.py:48] [456364] accumulated_eval_time=18260.599648, accumulated_logging_time=39.768209, accumulated_submission_time=204210.181087, global_step=456364, preemption_count=0, score=204210.181087, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=222535.508624, train/accuracy=0.888438, train/loss=0.411791, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 01:21:48.737377 140239850956544 logging_writer.py:48] [456400] global_step=456400, grad_norm=2.9875173568725586, loss=1.1159496307373047
I0305 01:22:32.277999 140239842563840 logging_writer.py:48] [456500] global_step=456500, grad_norm=3.089635133743286, loss=1.372410535812378
I0305 01:23:17.592675 140239850956544 logging_writer.py:48] [456600] global_step=456600, grad_norm=3.280081272125244, loss=1.182674527168274
I0305 01:24:03.075885 140239842563840 logging_writer.py:48] [456700] global_step=456700, grad_norm=3.009617328643799, loss=1.2521932125091553
I0305 01:24:48.543056 140239850956544 logging_writer.py:48] [456800] global_step=456800, grad_norm=3.163670539855957, loss=1.1083358526229858
I0305 01:25:33.711155 140239842563840 logging_writer.py:48] [456900] global_step=456900, grad_norm=3.055589437484741, loss=2.262439727783203
I0305 01:26:19.311855 140239850956544 logging_writer.py:48] [457000] global_step=457000, grad_norm=3.0140480995178223, loss=1.202871561050415
I0305 01:27:04.880262 140239842563840 logging_writer.py:48] [457100] global_step=457100, grad_norm=3.7862515449523926, loss=3.087531328201294
I0305 01:27:49.957918 140239850956544 logging_writer.py:48] [457200] global_step=457200, grad_norm=3.621537685394287, loss=3.1840081214904785
I0305 01:28:33.973407 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:28:44.437544 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 01:29:24.450177 140437341357888 spec.py:349] Evaluating on the test split.
I0305 01:29:26.062700 140437341357888 submission_runner.py:411] Time since start: 223007.61s, 	Step: 457298, 	{'train/accuracy': 0.889453113079071, 'train/loss': 0.4147363305091858, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 204630.03143048286, 'total_duration': 223007.61329698563, 'accumulated_submission_time': 204630.03143048286, 'accumulated_eval_time': 18312.688049077988, 'accumulated_logging_time': 39.88325357437134}
I0305 01:29:26.149646 140239842563840 logging_writer.py:48] [457298] accumulated_eval_time=18312.688049, accumulated_logging_time=39.883254, accumulated_submission_time=204630.031430, global_step=457298, preemption_count=0, score=204630.031430, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=223007.613297, train/accuracy=0.889453, train/loss=0.414736, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 01:29:27.338293 140239850956544 logging_writer.py:48] [457300] global_step=457300, grad_norm=3.001926898956299, loss=1.380342960357666
I0305 01:30:07.550337 140239842563840 logging_writer.py:48] [457400] global_step=457400, grad_norm=2.953258752822876, loss=1.1383626461029053
I0305 01:30:52.654193 140239850956544 logging_writer.py:48] [457500] global_step=457500, grad_norm=3.0085437297821045, loss=1.3529553413391113
I0305 01:31:38.081615 140239842563840 logging_writer.py:48] [457600] global_step=457600, grad_norm=2.9367902278900146, loss=1.1895382404327393
I0305 01:32:23.169990 140239850956544 logging_writer.py:48] [457700] global_step=457700, grad_norm=2.955202341079712, loss=1.6456208229064941
I0305 01:33:08.246133 140239842563840 logging_writer.py:48] [457800] global_step=457800, grad_norm=3.704793930053711, loss=3.23610520362854
I0305 01:33:53.892777 140239850956544 logging_writer.py:48] [457900] global_step=457900, grad_norm=3.106598377227783, loss=1.1828176975250244
I0305 01:34:39.227195 140239842563840 logging_writer.py:48] [458000] global_step=458000, grad_norm=3.654038667678833, loss=3.1853280067443848
I0305 01:35:24.599580 140239850956544 logging_writer.py:48] [458100] global_step=458100, grad_norm=4.063094139099121, loss=3.1944055557250977
I0305 01:36:09.700905 140239842563840 logging_writer.py:48] [458200] global_step=458200, grad_norm=3.079133987426758, loss=1.0466444492340088
I0305 01:36:26.303224 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:36:36.540816 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 01:36:59.796051 140437341357888 spec.py:349] Evaluating on the test split.
I0305 01:37:01.420577 140437341357888 submission_runner.py:411] Time since start: 223462.97s, 	Step: 458238, 	{'train/accuracy': 0.8873828053474426, 'train/loss': 0.4160374402999878, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 205050.12309336662, 'total_duration': 223462.97123146057, 'accumulated_submission_time': 205050.12309336662, 'accumulated_eval_time': 18347.804554224014, 'accumulated_logging_time': 39.98117995262146}
I0305 01:37:01.553962 140239850956544 logging_writer.py:48] [458238] accumulated_eval_time=18347.804554, accumulated_logging_time=39.981180, accumulated_submission_time=205050.123093, global_step=458238, preemption_count=0, score=205050.123093, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=223462.971231, train/accuracy=0.887383, train/loss=0.416037, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 01:37:26.532258 140239842563840 logging_writer.py:48] [458300] global_step=458300, grad_norm=3.209954261779785, loss=1.1590441465377808
I0305 01:38:11.453275 140239850956544 logging_writer.py:48] [458400] global_step=458400, grad_norm=3.039133071899414, loss=2.3697333335876465
I0305 01:38:56.762031 140239842563840 logging_writer.py:48] [458500] global_step=458500, grad_norm=2.9823524951934814, loss=1.130589485168457
I0305 01:39:42.544883 140239850956544 logging_writer.py:48] [458600] global_step=458600, grad_norm=3.2469162940979004, loss=2.736565113067627
I0305 01:40:27.872746 140239842563840 logging_writer.py:48] [458700] global_step=458700, grad_norm=3.4840683937072754, loss=1.2154951095581055
I0305 01:41:13.087680 140239850956544 logging_writer.py:48] [458800] global_step=458800, grad_norm=3.032874345779419, loss=1.1665183305740356
I0305 01:41:58.371077 140239842563840 logging_writer.py:48] [458900] global_step=458900, grad_norm=3.717184066772461, loss=3.0814456939697266
I0305 01:42:43.954480 140239850956544 logging_writer.py:48] [459000] global_step=459000, grad_norm=3.600579023361206, loss=1.152390956878662
I0305 01:43:29.528609 140239842563840 logging_writer.py:48] [459100] global_step=459100, grad_norm=2.862623691558838, loss=1.3585178852081299
I0305 01:44:01.464229 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:44:12.334900 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 01:44:45.182657 140437341357888 spec.py:349] Evaluating on the test split.
I0305 01:44:46.803807 140437341357888 submission_runner.py:411] Time since start: 223928.35s, 	Step: 459172, 	{'train/accuracy': 0.8875781297683716, 'train/loss': 0.41674086451530457, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 205469.96904063225, 'total_duration': 223928.35405111313, 'accumulated_submission_time': 205469.96904063225, 'accumulated_eval_time': 18393.14288878441, 'accumulated_logging_time': 40.127110719680786}
I0305 01:44:46.907899 140239850956544 logging_writer.py:48] [459172] accumulated_eval_time=18393.142889, accumulated_logging_time=40.127111, accumulated_submission_time=205469.969041, global_step=459172, preemption_count=0, score=205469.969041, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=223928.354051, train/accuracy=0.887578, train/loss=0.416741, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 01:44:58.397259 140239842563840 logging_writer.py:48] [459200] global_step=459200, grad_norm=3.153308629989624, loss=1.2158210277557373
I0305 01:45:40.998527 140239850956544 logging_writer.py:48] [459300] global_step=459300, grad_norm=3.241055488586426, loss=2.237739086151123
I0305 01:46:26.183628 140239842563840 logging_writer.py:48] [459400] global_step=459400, grad_norm=2.8721137046813965, loss=1.8054790496826172
I0305 01:47:11.614590 140239850956544 logging_writer.py:48] [459500] global_step=459500, grad_norm=3.2731056213378906, loss=2.722015857696533
I0305 01:47:56.515347 140239842563840 logging_writer.py:48] [459600] global_step=459600, grad_norm=3.3278841972351074, loss=1.129848837852478
I0305 01:48:41.859192 140239850956544 logging_writer.py:48] [459700] global_step=459700, grad_norm=2.9941558837890625, loss=1.0922930240631104
I0305 01:49:26.872503 140239842563840 logging_writer.py:48] [459800] global_step=459800, grad_norm=3.0667378902435303, loss=2.621220588684082
I0305 01:50:12.140747 140239850956544 logging_writer.py:48] [459900] global_step=459900, grad_norm=2.900115728378296, loss=1.5630087852478027
I0305 01:50:57.029668 140239842563840 logging_writer.py:48] [460000] global_step=460000, grad_norm=3.058964252471924, loss=1.194414496421814
I0305 01:51:42.250825 140239850956544 logging_writer.py:48] [460100] global_step=460100, grad_norm=2.920346975326538, loss=2.481813907623291
I0305 01:51:46.914429 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:51:57.174614 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 01:52:25.717281 140437341357888 spec.py:349] Evaluating on the test split.
I0305 01:52:27.336403 140437341357888 submission_runner.py:411] Time since start: 224388.89s, 	Step: 460112, 	{'train/accuracy': 0.8892577886581421, 'train/loss': 0.41508975625038147, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 205889.9131486416, 'total_duration': 224388.8865418434, 'accumulated_submission_time': 205889.9131486416, 'accumulated_eval_time': 18433.56349658966, 'accumulated_logging_time': 40.242703437805176}
I0305 01:52:27.452766 140239842563840 logging_writer.py:48] [460112] accumulated_eval_time=18433.563497, accumulated_logging_time=40.242703, accumulated_submission_time=205889.913149, global_step=460112, preemption_count=0, score=205889.913149, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=224388.886542, train/accuracy=0.889258, train/loss=0.415090, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 01:53:03.634996 140239850956544 logging_writer.py:48] [460200] global_step=460200, grad_norm=2.9969322681427, loss=1.116936445236206
I0305 01:53:48.581610 140239842563840 logging_writer.py:48] [460300] global_step=460300, grad_norm=3.6016480922698975, loss=3.085232973098755
I0305 01:54:33.911054 140239850956544 logging_writer.py:48] [460400] global_step=460400, grad_norm=2.9195632934570312, loss=1.0756090879440308
I0305 01:55:19.942228 140239842563840 logging_writer.py:48] [460500] global_step=460500, grad_norm=3.541431188583374, loss=3.0864768028259277
I0305 01:56:06.336534 140239850956544 logging_writer.py:48] [460600] global_step=460600, grad_norm=3.0529658794403076, loss=2.2709758281707764
I0305 01:56:51.660897 140239842563840 logging_writer.py:48] [460700] global_step=460700, grad_norm=3.942836046218872, loss=3.1497225761413574
I0305 01:57:36.756001 140239850956544 logging_writer.py:48] [460800] global_step=460800, grad_norm=3.299386501312256, loss=1.5384695529937744
I0305 01:58:22.099126 140239842563840 logging_writer.py:48] [460900] global_step=460900, grad_norm=3.042074203491211, loss=1.0925233364105225
I0305 01:59:07.933818 140239850956544 logging_writer.py:48] [461000] global_step=461000, grad_norm=2.9551286697387695, loss=1.095619559288025
I0305 01:59:27.360759 140437341357888 spec.py:321] Evaluating on the training split.
I0305 01:59:37.945004 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:00:05.730731 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:00:07.367609 140437341357888 submission_runner.py:411] Time since start: 224848.92s, 	Step: 461045, 	{'train/accuracy': 0.8885155916213989, 'train/loss': 0.4129526913166046, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 206309.76017975807, 'total_duration': 224848.9179956913, 'accumulated_submission_time': 206309.76017975807, 'accumulated_eval_time': 18473.569224596024, 'accumulated_logging_time': 40.369800329208374}
I0305 02:00:07.550639 140239842563840 logging_writer.py:48] [461045] accumulated_eval_time=18473.569225, accumulated_logging_time=40.369800, accumulated_submission_time=206309.760180, global_step=461045, preemption_count=0, score=206309.760180, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=224848.917996, train/accuracy=0.888516, train/loss=0.412953, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:00:29.743500 140239850956544 logging_writer.py:48] [461100] global_step=461100, grad_norm=3.3384201526641846, loss=1.0516008138656616
I0305 02:01:13.728368 140239842563840 logging_writer.py:48] [461200] global_step=461200, grad_norm=3.7443039417266846, loss=1.4559983015060425
I0305 02:01:59.006137 140239850956544 logging_writer.py:48] [461300] global_step=461300, grad_norm=2.8935060501098633, loss=0.9958572387695312
I0305 02:02:44.613556 140239842563840 logging_writer.py:48] [461400] global_step=461400, grad_norm=3.287551164627075, loss=2.907390594482422
I0305 02:03:30.315573 140239850956544 logging_writer.py:48] [461500] global_step=461500, grad_norm=3.3957066535949707, loss=1.1712695360183716
I0305 02:04:15.838395 140239842563840 logging_writer.py:48] [461600] global_step=461600, grad_norm=3.224637508392334, loss=2.937647581100464
I0305 02:05:01.674735 140239850956544 logging_writer.py:48] [461700] global_step=461700, grad_norm=2.940380811691284, loss=1.689504861831665
I0305 02:05:47.523427 140239842563840 logging_writer.py:48] [461800] global_step=461800, grad_norm=3.2700247764587402, loss=2.930513858795166
I0305 02:06:32.893756 140239850956544 logging_writer.py:48] [461900] global_step=461900, grad_norm=2.9011900424957275, loss=1.124700665473938
I0305 02:07:07.399085 140437341357888 spec.py:321] Evaluating on the training split.
I0305 02:07:17.875737 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:07:45.169385 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:07:46.792038 140437341357888 submission_runner.py:411] Time since start: 225308.34s, 	Step: 461977, 	{'train/accuracy': 0.8879492282867432, 'train/loss': 0.4129699170589447, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 206729.54073095322, 'total_duration': 225308.3424794674, 'accumulated_submission_time': 206729.54073095322, 'accumulated_eval_time': 18512.961121320724, 'accumulated_logging_time': 40.57051396369934}
I0305 02:07:46.899136 140239842563840 logging_writer.py:48] [461977] accumulated_eval_time=18512.961121, accumulated_logging_time=40.570514, accumulated_submission_time=206729.540731, global_step=461977, preemption_count=0, score=206729.540731, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=225308.342479, train/accuracy=0.887949, train/loss=0.412970, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:07:56.431233 140239850956544 logging_writer.py:48] [462000] global_step=462000, grad_norm=3.0048718452453613, loss=2.5213656425476074
I0305 02:08:39.308375 140239842563840 logging_writer.py:48] [462100] global_step=462100, grad_norm=3.6105709075927734, loss=3.1894261837005615
I0305 02:09:24.547864 140239850956544 logging_writer.py:48] [462200] global_step=462200, grad_norm=3.2846481800079346, loss=2.149949312210083
I0305 02:10:10.140557 140239842563840 logging_writer.py:48] [462300] global_step=462300, grad_norm=2.8902387619018555, loss=2.3811755180358887
I0305 02:10:55.508971 140239850956544 logging_writer.py:48] [462400] global_step=462400, grad_norm=3.190763473510742, loss=1.4811360836029053
I0305 02:11:40.820921 140239842563840 logging_writer.py:48] [462500] global_step=462500, grad_norm=3.3301830291748047, loss=2.6248350143432617
I0305 02:12:26.225536 140239850956544 logging_writer.py:48] [462600] global_step=462600, grad_norm=2.9449217319488525, loss=1.6890062093734741
I0305 02:13:11.429462 140239842563840 logging_writer.py:48] [462700] global_step=462700, grad_norm=3.5954227447509766, loss=3.1557397842407227
I0305 02:13:56.705311 140239850956544 logging_writer.py:48] [462800] global_step=462800, grad_norm=3.1006014347076416, loss=1.1418492794036865
I0305 02:14:42.077734 140239842563840 logging_writer.py:48] [462900] global_step=462900, grad_norm=2.9789981842041016, loss=1.1152786016464233
I0305 02:14:47.124283 140437341357888 spec.py:321] Evaluating on the training split.
I0305 02:14:57.621407 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:15:26.218040 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:15:27.843001 140437341357888 submission_runner.py:411] Time since start: 225769.39s, 	Step: 462912, 	{'train/accuracy': 0.8885155916213989, 'train/loss': 0.4146435856819153, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 207149.70380544662, 'total_duration': 225769.39330291748, 'accumulated_submission_time': 207149.70380544662, 'accumulated_eval_time': 18553.678634643555, 'accumulated_logging_time': 40.68940997123718}
I0305 02:15:27.950507 140239850956544 logging_writer.py:48] [462912] accumulated_eval_time=18553.678635, accumulated_logging_time=40.689410, accumulated_submission_time=207149.703805, global_step=462912, preemption_count=0, score=207149.703805, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=225769.393303, train/accuracy=0.888516, train/loss=0.414644, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:16:04.463491 140239842563840 logging_writer.py:48] [463000] global_step=463000, grad_norm=2.9417614936828613, loss=1.1947734355926514
I0305 02:16:49.572418 140239850956544 logging_writer.py:48] [463100] global_step=463100, grad_norm=3.0991501808166504, loss=1.7815991640090942
I0305 02:17:35.133516 140239842563840 logging_writer.py:48] [463200] global_step=463200, grad_norm=3.1141533851623535, loss=2.5949740409851074
I0305 02:18:20.346654 140239850956544 logging_writer.py:48] [463300] global_step=463300, grad_norm=3.204028606414795, loss=1.3155663013458252
I0305 02:19:05.589298 140239842563840 logging_writer.py:48] [463400] global_step=463400, grad_norm=3.0699727535247803, loss=1.3171782493591309
I0305 02:19:50.806735 140239850956544 logging_writer.py:48] [463500] global_step=463500, grad_norm=3.088515281677246, loss=1.181204915046692
I0305 02:20:36.185267 140239842563840 logging_writer.py:48] [463600] global_step=463600, grad_norm=3.1959152221679688, loss=1.5356553792953491
I0305 02:21:21.629018 140239850956544 logging_writer.py:48] [463700] global_step=463700, grad_norm=3.3736422061920166, loss=2.8091704845428467
I0305 02:22:06.925263 140239842563840 logging_writer.py:48] [463800] global_step=463800, grad_norm=3.286079168319702, loss=1.2320326566696167
I0305 02:22:27.845337 140437341357888 spec.py:321] Evaluating on the training split.
I0305 02:22:38.229124 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:23:12.498233 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:23:14.143050 140437341357888 submission_runner.py:411] Time since start: 226235.69s, 	Step: 463848, 	{'train/accuracy': 0.8866796493530273, 'train/loss': 0.41630151867866516, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 207569.53734230995, 'total_duration': 226235.69345355034, 'accumulated_submission_time': 207569.53734230995, 'accumulated_eval_time': 18599.975264310837, 'accumulated_logging_time': 40.80809164047241}
I0305 02:23:14.240051 140239850956544 logging_writer.py:48] [463848] accumulated_eval_time=18599.975264, accumulated_logging_time=40.808092, accumulated_submission_time=207569.537342, global_step=463848, preemption_count=0, score=207569.537342, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=226235.693454, train/accuracy=0.886680, train/loss=0.416302, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:23:35.247381 140239842563840 logging_writer.py:48] [463900] global_step=463900, grad_norm=3.21882963180542, loss=1.2354247570037842
I0305 02:24:17.860042 140239850956544 logging_writer.py:48] [464000] global_step=464000, grad_norm=3.8563320636749268, loss=3.3456735610961914
I0305 02:25:03.069257 140239842563840 logging_writer.py:48] [464100] global_step=464100, grad_norm=2.9327731132507324, loss=1.3412022590637207
I0305 02:25:48.706462 140239850956544 logging_writer.py:48] [464200] global_step=464200, grad_norm=3.0258302688598633, loss=2.3327558040618896
I0305 02:26:34.034621 140239842563840 logging_writer.py:48] [464300] global_step=464300, grad_norm=3.023581027984619, loss=1.128739833831787
I0305 02:27:19.129060 140239850956544 logging_writer.py:48] [464400] global_step=464400, grad_norm=2.985460042953491, loss=1.9128600358963013
I0305 02:28:04.329813 140239842563840 logging_writer.py:48] [464500] global_step=464500, grad_norm=3.716266632080078, loss=1.5523436069488525
I0305 02:28:49.303484 140239850956544 logging_writer.py:48] [464600] global_step=464600, grad_norm=2.8670525550842285, loss=1.2693829536437988
I0305 02:29:34.584992 140239842563840 logging_writer.py:48] [464700] global_step=464700, grad_norm=3.1805989742279053, loss=2.197976589202881
I0305 02:30:14.496206 140437341357888 spec.py:321] Evaluating on the training split.
I0305 02:30:24.826673 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:30:49.813758 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:30:51.443546 140437341357888 submission_runner.py:411] Time since start: 226692.99s, 	Step: 464790, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.41648128628730774, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 207989.73219513893, 'total_duration': 226692.9933104515, 'accumulated_submission_time': 207989.73219513893, 'accumulated_eval_time': 18636.920867919922, 'accumulated_logging_time': 40.91565990447998}
I0305 02:30:51.551112 140239850956544 logging_writer.py:48] [464790] accumulated_eval_time=18636.920868, accumulated_logging_time=40.915660, accumulated_submission_time=207989.732195, global_step=464790, preemption_count=0, score=207989.732195, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=226692.993310, train/accuracy=0.888906, train/loss=0.416481, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:30:55.917351 140239842563840 logging_writer.py:48] [464800] global_step=464800, grad_norm=5.52651834487915, loss=2.872920513153076
I0305 02:31:38.083427 140239850956544 logging_writer.py:48] [464900] global_step=464900, grad_norm=3.5660810470581055, loss=1.1357587575912476
I0305 02:32:23.046259 140239842563840 logging_writer.py:48] [465000] global_step=465000, grad_norm=3.0389292240142822, loss=1.197159767150879
I0305 02:33:08.541510 140239850956544 logging_writer.py:48] [465100] global_step=465100, grad_norm=3.5463244915008545, loss=1.6571934223175049
I0305 02:33:53.568457 140239842563840 logging_writer.py:48] [465200] global_step=465200, grad_norm=3.425649642944336, loss=1.4190961122512817
I0305 02:34:38.629229 140239850956544 logging_writer.py:48] [465300] global_step=465300, grad_norm=3.7555601596832275, loss=1.1580218076705933
I0305 02:35:24.017161 140239842563840 logging_writer.py:48] [465400] global_step=465400, grad_norm=2.9049081802368164, loss=0.9875264167785645
I0305 02:36:09.909314 140239850956544 logging_writer.py:48] [465500] global_step=465500, grad_norm=3.3657212257385254, loss=1.5681304931640625
I0305 02:36:55.263647 140239842563840 logging_writer.py:48] [465600] global_step=465600, grad_norm=2.923617124557495, loss=1.0063070058822632
I0305 02:37:40.612964 140239850956544 logging_writer.py:48] [465700] global_step=465700, grad_norm=3.0062968730926514, loss=1.2346179485321045
I0305 02:37:51.541386 140437341357888 spec.py:321] Evaluating on the training split.
I0305 02:38:02.483485 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:38:33.183260 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:38:34.802704 140437341357888 submission_runner.py:411] Time since start: 227156.35s, 	Step: 465726, 	{'train/accuracy': 0.8902929425239563, 'train/loss': 0.41110602021217346, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 208409.66075110435, 'total_duration': 227156.35308504105, 'accumulated_submission_time': 208409.66075110435, 'accumulated_eval_time': 18680.181062698364, 'accumulated_logging_time': 41.034393310546875}
I0305 02:38:34.902243 140239842563840 logging_writer.py:48] [465726] accumulated_eval_time=18680.181063, accumulated_logging_time=41.034393, accumulated_submission_time=208409.660751, global_step=465726, preemption_count=0, score=208409.660751, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=227156.353085, train/accuracy=0.890293, train/loss=0.411106, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:39:05.211179 140239850956544 logging_writer.py:48] [465800] global_step=465800, grad_norm=3.721339464187622, loss=3.263277769088745
I0305 02:39:50.299772 140239842563840 logging_writer.py:48] [465900] global_step=465900, grad_norm=3.781740427017212, loss=3.254673480987549
I0305 02:40:35.676863 140239850956544 logging_writer.py:48] [466000] global_step=466000, grad_norm=3.329653024673462, loss=1.2392241954803467
I0305 02:41:20.945842 140239842563840 logging_writer.py:48] [466100] global_step=466100, grad_norm=2.890089750289917, loss=1.5286891460418701
I0305 02:42:06.305747 140239850956544 logging_writer.py:48] [466200] global_step=466200, grad_norm=3.220273971557617, loss=2.590244770050049
I0305 02:42:51.605691 140239842563840 logging_writer.py:48] [466300] global_step=466300, grad_norm=2.9771416187286377, loss=2.6206421852111816
I0305 02:43:36.986496 140239850956544 logging_writer.py:48] [466400] global_step=466400, grad_norm=3.3927676677703857, loss=1.2491613626480103
I0305 02:44:22.424520 140239842563840 logging_writer.py:48] [466500] global_step=466500, grad_norm=2.9615159034729004, loss=1.1078453063964844
I0305 02:45:07.549664 140239850956544 logging_writer.py:48] [466600] global_step=466600, grad_norm=3.2320802211761475, loss=1.1202702522277832
I0305 02:45:35.184360 140437341357888 spec.py:321] Evaluating on the training split.
I0305 02:45:45.542897 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:46:14.193365 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:46:15.839758 140437341357888 submission_runner.py:411] Time since start: 227617.39s, 	Step: 466662, 	{'train/accuracy': 0.8910546898841858, 'train/loss': 0.40772971510887146, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 208829.88141417503, 'total_duration': 227617.39014077187, 'accumulated_submission_time': 208829.88141417503, 'accumulated_eval_time': 18720.83535385132, 'accumulated_logging_time': 41.144742250442505}
I0305 02:46:15.928137 140239842563840 logging_writer.py:48] [466662] accumulated_eval_time=18720.835354, accumulated_logging_time=41.144742, accumulated_submission_time=208829.881414, global_step=466662, preemption_count=0, score=208829.881414, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=227617.390141, train/accuracy=0.891055, train/loss=0.407730, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:46:31.386414 140239850956544 logging_writer.py:48] [466700] global_step=466700, grad_norm=2.8357322216033936, loss=1.691026210784912
I0305 02:47:13.600319 140239842563840 logging_writer.py:48] [466800] global_step=466800, grad_norm=3.1970927715301514, loss=2.6609487533569336
I0305 02:47:58.639892 140239850956544 logging_writer.py:48] [466900] global_step=466900, grad_norm=3.9500553607940674, loss=3.192011833190918
I0305 02:48:44.416265 140239842563840 logging_writer.py:48] [467000] global_step=467000, grad_norm=3.9718027114868164, loss=3.2679944038391113
I0305 02:49:29.609419 140239850956544 logging_writer.py:48] [467100] global_step=467100, grad_norm=3.212373733520508, loss=1.1855931282043457
I0305 02:50:14.952936 140239842563840 logging_writer.py:48] [467200] global_step=467200, grad_norm=3.166438579559326, loss=1.302207112312317
I0305 02:50:59.964577 140239850956544 logging_writer.py:48] [467300] global_step=467300, grad_norm=2.940535306930542, loss=1.268067479133606
I0305 02:51:45.189605 140239842563840 logging_writer.py:48] [467400] global_step=467400, grad_norm=3.2517905235290527, loss=1.1984779834747314
I0305 02:52:30.323521 140239850956544 logging_writer.py:48] [467500] global_step=467500, grad_norm=3.39377498626709, loss=1.5651113986968994
I0305 02:53:15.459312 140239842563840 logging_writer.py:48] [467600] global_step=467600, grad_norm=2.829009771347046, loss=1.5061161518096924
I0305 02:53:16.046324 140437341357888 spec.py:321] Evaluating on the training split.
I0305 02:53:26.537390 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 02:53:51.132336 140437341357888 spec.py:349] Evaluating on the test split.
I0305 02:53:52.750403 140437341357888 submission_runner.py:411] Time since start: 228074.30s, 	Step: 467603, 	{'train/accuracy': 0.8886913657188416, 'train/loss': 0.41690775752067566, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 209249.93860125542, 'total_duration': 228074.30078601837, 'accumulated_submission_time': 209249.93860125542, 'accumulated_eval_time': 18757.538311719894, 'accumulated_logging_time': 41.24268078804016}
I0305 02:53:52.859207 140239850956544 logging_writer.py:48] [467603] accumulated_eval_time=18757.538312, accumulated_logging_time=41.242681, accumulated_submission_time=209249.938601, global_step=467603, preemption_count=0, score=209249.938601, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=228074.300786, train/accuracy=0.888691, train/loss=0.416908, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 02:54:33.494050 140239842563840 logging_writer.py:48] [467700] global_step=467700, grad_norm=3.6103200912475586, loss=2.52052640914917
I0305 02:55:18.666524 140239850956544 logging_writer.py:48] [467800] global_step=467800, grad_norm=3.2732222080230713, loss=1.7155184745788574
I0305 02:56:03.848836 140239842563840 logging_writer.py:48] [467900] global_step=467900, grad_norm=3.6286585330963135, loss=1.97406005859375
I0305 02:56:49.339940 140239850956544 logging_writer.py:48] [468000] global_step=468000, grad_norm=2.7656407356262207, loss=1.2873563766479492
I0305 02:57:34.555009 140239842563840 logging_writer.py:48] [468100] global_step=468100, grad_norm=3.050225019454956, loss=1.106877326965332
I0305 02:58:19.875295 140239850956544 logging_writer.py:48] [468200] global_step=468200, grad_norm=3.026916742324829, loss=1.0890861749649048
I0305 02:59:05.247309 140239842563840 logging_writer.py:48] [468300] global_step=468300, grad_norm=2.8992903232574463, loss=1.104698896408081
I0305 02:59:50.322968 140239850956544 logging_writer.py:48] [468400] global_step=468400, grad_norm=3.4925198554992676, loss=2.802743911743164
I0305 03:00:35.663128 140239842563840 logging_writer.py:48] [468500] global_step=468500, grad_norm=3.1092636585235596, loss=1.5577105283737183
I0305 03:00:53.020448 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:01:04.350156 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:01:30.772763 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:01:32.406331 140437341357888 submission_runner.py:411] Time since start: 228533.96s, 	Step: 468540, 	{'train/accuracy': 0.8895702958106995, 'train/loss': 0.4094632863998413, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 209670.0353667736, 'total_duration': 228533.95680093765, 'accumulated_submission_time': 209670.0353667736, 'accumulated_eval_time': 18796.923159122467, 'accumulated_logging_time': 41.36542820930481}
I0305 03:01:32.515044 140239850956544 logging_writer.py:48] [468540] accumulated_eval_time=18796.923159, accumulated_logging_time=41.365428, accumulated_submission_time=209670.035367, global_step=468540, preemption_count=0, score=209670.035367, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=228533.956801, train/accuracy=0.889570, train/loss=0.409463, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:01:56.678723 140239842563840 logging_writer.py:48] [468600] global_step=468600, grad_norm=3.7696056365966797, loss=3.1775076389312744
I0305 03:02:41.380455 140239850956544 logging_writer.py:48] [468700] global_step=468700, grad_norm=3.0071020126342773, loss=2.2868404388427734
I0305 03:03:26.701657 140239842563840 logging_writer.py:48] [468800] global_step=468800, grad_norm=3.0094358921051025, loss=2.246976137161255
I0305 03:04:11.986412 140239850956544 logging_writer.py:48] [468900] global_step=468900, grad_norm=2.8444364070892334, loss=1.3589787483215332
I0305 03:04:57.572414 140239842563840 logging_writer.py:48] [469000] global_step=469000, grad_norm=3.1056323051452637, loss=1.0548633337020874
I0305 03:05:43.190779 140239850956544 logging_writer.py:48] [469100] global_step=469100, grad_norm=3.791365623474121, loss=2.697417736053467
I0305 03:06:28.862879 140239842563840 logging_writer.py:48] [469200] global_step=469200, grad_norm=3.616286039352417, loss=3.256303310394287
I0305 03:07:14.441918 140239850956544 logging_writer.py:48] [469300] global_step=469300, grad_norm=3.1679248809814453, loss=1.200834035873413
I0305 03:07:59.890205 140239842563840 logging_writer.py:48] [469400] global_step=469400, grad_norm=2.9503610134124756, loss=1.019707441329956
I0305 03:08:32.652533 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:08:43.197116 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:09:18.692262 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:09:20.329943 140437341357888 submission_runner.py:411] Time since start: 229001.88s, 	Step: 469474, 	{'train/accuracy': 0.8866015672683716, 'train/loss': 0.42165932059288025, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 210090.10920333862, 'total_duration': 229001.88045072556, 'accumulated_submission_time': 210090.10920333862, 'accumulated_eval_time': 18844.599578857422, 'accumulated_logging_time': 41.487314224243164}
I0305 03:09:20.416590 140239850956544 logging_writer.py:48] [469474] accumulated_eval_time=18844.599579, accumulated_logging_time=41.487314, accumulated_submission_time=210090.109203, global_step=469474, preemption_count=0, score=210090.109203, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=229001.880451, train/accuracy=0.886602, train/loss=0.421659, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:09:31.119509 140239842563840 logging_writer.py:48] [469500] global_step=469500, grad_norm=3.0017576217651367, loss=1.2015923261642456
I0305 03:10:12.547184 140239850956544 logging_writer.py:48] [469600] global_step=469600, grad_norm=3.292304277420044, loss=2.8063197135925293
I0305 03:10:57.525666 140239842563840 logging_writer.py:48] [469700] global_step=469700, grad_norm=3.044295072555542, loss=1.473653793334961
I0305 03:11:43.004725 140239850956544 logging_writer.py:48] [469800] global_step=469800, grad_norm=3.3917324542999268, loss=2.6719956398010254
I0305 03:12:28.164766 140239842563840 logging_writer.py:48] [469900] global_step=469900, grad_norm=3.949444532394409, loss=3.22967791557312
I0305 03:13:13.722936 140239850956544 logging_writer.py:48] [470000] global_step=470000, grad_norm=3.661566972732544, loss=2.9251222610473633
I0305 03:13:59.056125 140239842563840 logging_writer.py:48] [470100] global_step=470100, grad_norm=3.026866912841797, loss=2.6495285034179688
I0305 03:14:44.106626 140239850956544 logging_writer.py:48] [470200] global_step=470200, grad_norm=3.0118749141693115, loss=1.1499038934707642
I0305 03:15:29.480247 140239842563840 logging_writer.py:48] [470300] global_step=470300, grad_norm=2.9498422145843506, loss=1.2277013063430786
I0305 03:16:14.730709 140239850956544 logging_writer.py:48] [470400] global_step=470400, grad_norm=3.2985262870788574, loss=1.2168724536895752
I0305 03:16:20.483836 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:16:30.981207 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:16:56.120165 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:16:57.736092 140437341357888 submission_runner.py:411] Time since start: 229459.29s, 	Step: 470414, 	{'train/accuracy': 0.8875976204872131, 'train/loss': 0.415841668844223, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 210510.11679530144, 'total_duration': 229459.28646302223, 'accumulated_submission_time': 210510.11679530144, 'accumulated_eval_time': 18881.850703954697, 'accumulated_logging_time': 41.58333134651184}
I0305 03:16:57.843278 140239842563840 logging_writer.py:48] [470414] accumulated_eval_time=18881.850704, accumulated_logging_time=41.583331, accumulated_submission_time=210510.116795, global_step=470414, preemption_count=0, score=210510.116795, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=229459.286463, train/accuracy=0.887598, train/loss=0.415842, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:17:33.811458 140239850956544 logging_writer.py:48] [470500] global_step=470500, grad_norm=2.9921131134033203, loss=2.2404518127441406
I0305 03:18:19.360468 140239842563840 logging_writer.py:48] [470600] global_step=470600, grad_norm=3.7296230792999268, loss=3.2633767127990723
I0305 03:19:04.821398 140239850956544 logging_writer.py:48] [470700] global_step=470700, grad_norm=3.2186832427978516, loss=1.1270511150360107
I0305 03:19:50.161255 140239842563840 logging_writer.py:48] [470800] global_step=470800, grad_norm=3.55423903465271, loss=3.0724611282348633
I0305 03:20:35.496628 140239850956544 logging_writer.py:48] [470900] global_step=470900, grad_norm=3.028515577316284, loss=2.1887757778167725
I0305 03:21:21.086732 140239842563840 logging_writer.py:48] [471000] global_step=471000, grad_norm=2.818441152572632, loss=1.418583869934082
I0305 03:22:06.422586 140239850956544 logging_writer.py:48] [471100] global_step=471100, grad_norm=3.9260120391845703, loss=2.9034695625305176
I0305 03:22:51.764150 140239842563840 logging_writer.py:48] [471200] global_step=471200, grad_norm=3.183260440826416, loss=1.2712904214859009
I0305 03:23:37.305584 140239850956544 logging_writer.py:48] [471300] global_step=471300, grad_norm=3.038917303085327, loss=1.1429513692855835
I0305 03:23:57.833473 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:24:08.732225 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:24:40.811528 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:24:42.441645 140437341357888 submission_runner.py:411] Time since start: 229923.99s, 	Step: 471347, 	{'train/accuracy': 0.8912695050239563, 'train/loss': 0.40659332275390625, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 210930.04602122307, 'total_duration': 229923.99203276634, 'accumulated_submission_time': 210930.04602122307, 'accumulated_eval_time': 18926.457754135132, 'accumulated_logging_time': 41.70092463493347}
I0305 03:24:42.550010 140239842563840 logging_writer.py:48] [471347] accumulated_eval_time=18926.457754, accumulated_logging_time=41.700925, accumulated_submission_time=210930.046021, global_step=471347, preemption_count=0, score=210930.046021, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=229923.992033, train/accuracy=0.891270, train/loss=0.406593, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:25:03.921154 140239850956544 logging_writer.py:48] [471400] global_step=471400, grad_norm=3.0959458351135254, loss=1.1182658672332764
I0305 03:25:48.651945 140239842563840 logging_writer.py:48] [471500] global_step=471500, grad_norm=2.9148659706115723, loss=1.2901458740234375
I0305 03:26:34.316574 140239850956544 logging_writer.py:48] [471600] global_step=471600, grad_norm=3.6203415393829346, loss=1.3103559017181396
I0305 03:27:20.425045 140239842563840 logging_writer.py:48] [471700] global_step=471700, grad_norm=3.273176670074463, loss=1.442132592201233
I0305 03:28:06.219264 140239850956544 logging_writer.py:48] [471800] global_step=471800, grad_norm=3.0425236225128174, loss=1.3766067028045654
I0305 03:28:51.801334 140239842563840 logging_writer.py:48] [471900] global_step=471900, grad_norm=3.4440290927886963, loss=3.096487522125244
I0305 03:29:37.652120 140239850956544 logging_writer.py:48] [472000] global_step=472000, grad_norm=3.051544427871704, loss=1.1064189672470093
I0305 03:30:23.621707 140239842563840 logging_writer.py:48] [472100] global_step=472100, grad_norm=2.8599612712860107, loss=1.6315436363220215
I0305 03:31:09.510402 140239850956544 logging_writer.py:48] [472200] global_step=472200, grad_norm=3.2424890995025635, loss=1.0853888988494873
I0305 03:31:42.751771 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:31:52.756358 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:32:20.457055 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:32:22.078914 140437341357888 submission_runner.py:411] Time since start: 230383.63s, 	Step: 472275, 	{'train/accuracy': 0.8875390291213989, 'train/loss': 0.4188980460166931, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 211350.18746185303, 'total_duration': 230383.62945699692, 'accumulated_submission_time': 211350.18746185303, 'accumulated_eval_time': 18965.783930778503, 'accumulated_logging_time': 41.82049751281738}
I0305 03:32:22.190427 140239842563840 logging_writer.py:48] [472275] accumulated_eval_time=18965.783931, accumulated_logging_time=41.820498, accumulated_submission_time=211350.187462, global_step=472275, preemption_count=0, score=211350.187462, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=230383.629457, train/accuracy=0.887539, train/loss=0.418898, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:32:32.511209 140239850956544 logging_writer.py:48] [472300] global_step=472300, grad_norm=3.5624208450317383, loss=3.0022385120391846
I0305 03:33:15.265345 140239842563840 logging_writer.py:48] [472400] global_step=472400, grad_norm=3.065232038497925, loss=1.7633097171783447
I0305 03:34:00.697668 140239850956544 logging_writer.py:48] [472500] global_step=472500, grad_norm=2.854433059692383, loss=2.2449898719787598
I0305 03:34:46.155970 140239842563840 logging_writer.py:48] [472600] global_step=472600, grad_norm=3.001307487487793, loss=1.9982117414474487
I0305 03:35:31.359464 140239850956544 logging_writer.py:48] [472700] global_step=472700, grad_norm=3.0361034870147705, loss=1.0765821933746338
I0305 03:36:16.962798 140239842563840 logging_writer.py:48] [472800] global_step=472800, grad_norm=2.9755475521087646, loss=1.0734200477600098
I0305 03:37:02.360521 140239850956544 logging_writer.py:48] [472900] global_step=472900, grad_norm=3.9016311168670654, loss=1.1783406734466553
I0305 03:37:47.740319 140239842563840 logging_writer.py:48] [473000] global_step=473000, grad_norm=3.9961740970611572, loss=3.2164416313171387
I0305 03:38:32.953882 140239850956544 logging_writer.py:48] [473100] global_step=473100, grad_norm=3.314530372619629, loss=1.2041919231414795
I0305 03:39:18.211747 140239842563840 logging_writer.py:48] [473200] global_step=473200, grad_norm=2.863184928894043, loss=1.5548968315124512
I0305 03:39:22.750610 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:39:33.293434 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:40:00.749474 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:40:02.375771 140437341357888 submission_runner.py:411] Time since start: 230843.93s, 	Step: 473211, 	{'train/accuracy': 0.8882226347923279, 'train/loss': 0.41510963439941406, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 211770.68524432182, 'total_duration': 230843.92622327805, 'accumulated_submission_time': 211770.68524432182, 'accumulated_eval_time': 19005.408094406128, 'accumulated_logging_time': 41.944220781326294}
I0305 03:40:02.483582 140239850956544 logging_writer.py:48] [473211] accumulated_eval_time=19005.408094, accumulated_logging_time=41.944221, accumulated_submission_time=211770.685244, global_step=473211, preemption_count=0, score=211770.685244, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=230843.926223, train/accuracy=0.888223, train/loss=0.415110, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:40:39.245041 140239842563840 logging_writer.py:48] [473300] global_step=473300, grad_norm=3.6169509887695312, loss=3.3017468452453613
I0305 03:41:24.445409 140239850956544 logging_writer.py:48] [473400] global_step=473400, grad_norm=3.1456480026245117, loss=1.1983306407928467
I0305 03:42:09.678528 140239842563840 logging_writer.py:48] [473500] global_step=473500, grad_norm=2.8112246990203857, loss=1.2208926677703857
I0305 03:42:54.703647 140239850956544 logging_writer.py:48] [473600] global_step=473600, grad_norm=3.012563943862915, loss=2.7569093704223633
I0305 03:43:39.933283 140239842563840 logging_writer.py:48] [473700] global_step=473700, grad_norm=2.8942503929138184, loss=1.449249267578125
I0305 03:44:25.253245 140239850956544 logging_writer.py:48] [473800] global_step=473800, grad_norm=3.293983221054077, loss=1.0966832637786865
I0305 03:45:10.540216 140239842563840 logging_writer.py:48] [473900] global_step=473900, grad_norm=3.2228987216949463, loss=1.1038808822631836
I0305 03:45:55.789486 140239850956544 logging_writer.py:48] [474000] global_step=474000, grad_norm=3.1266345977783203, loss=1.417076826095581
I0305 03:46:41.101275 140239842563840 logging_writer.py:48] [474100] global_step=474100, grad_norm=3.4449822902679443, loss=1.820404052734375
I0305 03:47:02.454498 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:47:12.678187 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:47:43.006236 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:47:44.639482 140437341357888 submission_runner.py:411] Time since start: 231306.19s, 	Step: 474149, 	{'train/accuracy': 0.886523425579071, 'train/loss': 0.42000043392181396, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 212190.5941722393, 'total_duration': 231306.18983483315, 'accumulated_submission_time': 212190.5941722393, 'accumulated_eval_time': 19047.591923952103, 'accumulated_logging_time': 42.06261587142944}
I0305 03:47:44.739697 140239850956544 logging_writer.py:48] [474149] accumulated_eval_time=19047.591924, accumulated_logging_time=42.062616, accumulated_submission_time=212190.594172, global_step=474149, preemption_count=0, score=212190.594172, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=231306.189835, train/accuracy=0.886523, train/loss=0.420000, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:48:05.343191 140239842563840 logging_writer.py:48] [474200] global_step=474200, grad_norm=3.639211893081665, loss=3.1413826942443848
I0305 03:48:49.166121 140239850956544 logging_writer.py:48] [474300] global_step=474300, grad_norm=2.957853078842163, loss=2.1104345321655273
I0305 03:49:34.285715 140239842563840 logging_writer.py:48] [474400] global_step=474400, grad_norm=3.113581895828247, loss=1.1707152128219604
I0305 03:50:19.374600 140239850956544 logging_writer.py:48] [474500] global_step=474500, grad_norm=2.996495008468628, loss=1.2412837743759155
I0305 03:51:04.406403 140239842563840 logging_writer.py:48] [474600] global_step=474600, grad_norm=3.2943296432495117, loss=3.0899817943573
I0305 03:51:49.647101 140239850956544 logging_writer.py:48] [474700] global_step=474700, grad_norm=3.2130637168884277, loss=1.1333119869232178
I0305 03:52:34.842017 140239842563840 logging_writer.py:48] [474800] global_step=474800, grad_norm=3.3155105113983154, loss=1.2371814250946045
I0305 03:53:20.030534 140239850956544 logging_writer.py:48] [474900] global_step=474900, grad_norm=2.9364640712738037, loss=1.0115325450897217
I0305 03:54:05.397115 140239842563840 logging_writer.py:48] [475000] global_step=475000, grad_norm=2.845182180404663, loss=1.8188854455947876
I0305 03:54:44.872243 140437341357888 spec.py:321] Evaluating on the training split.
I0305 03:54:55.202857 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 03:55:24.105971 140437341357888 spec.py:349] Evaluating on the test split.
I0305 03:55:25.729066 140437341357888 submission_runner.py:411] Time since start: 231767.28s, 	Step: 475089, 	{'train/accuracy': 0.8861913681030273, 'train/loss': 0.42005056142807007, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 212610.66497921944, 'total_duration': 231767.27955651283, 'accumulated_submission_time': 212610.66497921944, 'accumulated_eval_time': 19088.447747945786, 'accumulated_logging_time': 42.17369341850281}
I0305 03:55:25.839126 140239850956544 logging_writer.py:48] [475089] accumulated_eval_time=19088.447748, accumulated_logging_time=42.173693, accumulated_submission_time=212610.664979, global_step=475089, preemption_count=0, score=212610.664979, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=231767.279557, train/accuracy=0.886191, train/loss=0.420051, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 03:55:30.615758 140239842563840 logging_writer.py:48] [475100] global_step=475100, grad_norm=3.3239529132843018, loss=1.5264626741409302
I0305 03:56:12.258988 140239850956544 logging_writer.py:48] [475200] global_step=475200, grad_norm=2.8724305629730225, loss=1.2439204454421997
I0305 03:56:57.418709 140239842563840 logging_writer.py:48] [475300] global_step=475300, grad_norm=3.246321678161621, loss=2.7079145908355713
I0305 03:57:42.906924 140239850956544 logging_writer.py:48] [475400] global_step=475400, grad_norm=3.8268516063690186, loss=3.424649715423584
I0305 03:58:28.601956 140239842563840 logging_writer.py:48] [475500] global_step=475500, grad_norm=2.8548805713653564, loss=1.7310242652893066
I0305 03:59:14.206207 140239850956544 logging_writer.py:48] [475600] global_step=475600, grad_norm=3.029529333114624, loss=1.0982542037963867
I0305 03:59:59.876713 140239842563840 logging_writer.py:48] [475700] global_step=475700, grad_norm=3.2056710720062256, loss=1.1282100677490234
I0305 04:00:45.330457 140239850956544 logging_writer.py:48] [475800] global_step=475800, grad_norm=2.9641449451446533, loss=1.018090009689331
I0305 04:01:30.706489 140239842563840 logging_writer.py:48] [475900] global_step=475900, grad_norm=3.0448286533355713, loss=1.3547542095184326
I0305 04:02:16.064871 140239850956544 logging_writer.py:48] [476000] global_step=476000, grad_norm=3.0202343463897705, loss=1.0048288106918335
I0305 04:02:25.774171 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:02:36.244811 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:03:05.836852 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:03:07.468902 140437341357888 submission_runner.py:411] Time since start: 232229.02s, 	Step: 476023, 	{'train/accuracy': 0.8905664086341858, 'train/loss': 0.40742355585098267, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 213030.53802657127, 'total_duration': 232229.01929712296, 'accumulated_submission_time': 213030.53802657127, 'accumulated_eval_time': 19130.14138698578, 'accumulated_logging_time': 42.2940833568573}
I0305 04:03:07.645278 140239842563840 logging_writer.py:48] [476023] accumulated_eval_time=19130.141387, accumulated_logging_time=42.294083, accumulated_submission_time=213030.538027, global_step=476023, preemption_count=0, score=213030.538027, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=232229.019297, train/accuracy=0.890566, train/loss=0.407424, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:03:38.878186 140239850956544 logging_writer.py:48] [476100] global_step=476100, grad_norm=3.1673200130462646, loss=1.2483093738555908
I0305 04:04:23.841546 140239842563840 logging_writer.py:48] [476200] global_step=476200, grad_norm=2.9546234607696533, loss=1.0928231477737427
I0305 04:05:09.491068 140239850956544 logging_writer.py:48] [476300] global_step=476300, grad_norm=2.8924083709716797, loss=0.9985517859458923
I0305 04:05:54.889553 140239842563840 logging_writer.py:48] [476400] global_step=476400, grad_norm=2.9061403274536133, loss=1.0674099922180176
I0305 04:06:40.392469 140239850956544 logging_writer.py:48] [476500] global_step=476500, grad_norm=2.9539082050323486, loss=1.6661189794540405
I0305 04:07:25.590035 140239842563840 logging_writer.py:48] [476600] global_step=476600, grad_norm=3.5454351902008057, loss=3.271463632583618
I0305 04:08:11.167472 140239850956544 logging_writer.py:48] [476700] global_step=476700, grad_norm=2.8046159744262695, loss=1.354519009590149
I0305 04:08:56.208574 140239842563840 logging_writer.py:48] [476800] global_step=476800, grad_norm=2.830202102661133, loss=1.4869556427001953
I0305 04:09:41.404436 140239850956544 logging_writer.py:48] [476900] global_step=476900, grad_norm=3.0826666355133057, loss=1.617299199104309
I0305 04:10:07.772662 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:10:18.019568 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:10:44.721976 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:10:46.352749 140437341357888 submission_runner.py:411] Time since start: 232687.90s, 	Step: 476960, 	{'train/accuracy': 0.8874413967132568, 'train/loss': 0.4190874397754669, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 213450.59983038902, 'total_duration': 232687.90293979645, 'accumulated_submission_time': 213450.59983038902, 'accumulated_eval_time': 19168.720163583755, 'accumulated_logging_time': 42.485562801361084}
I0305 04:10:46.473623 140239842563840 logging_writer.py:48] [476960] accumulated_eval_time=19168.720164, accumulated_logging_time=42.485563, accumulated_submission_time=213450.599830, global_step=476960, preemption_count=0, score=213450.599830, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=232687.902940, train/accuracy=0.887441, train/loss=0.419087, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:11:02.761403 140239850956544 logging_writer.py:48] [477000] global_step=477000, grad_norm=3.6459426879882812, loss=3.016911268234253
I0305 04:11:46.138438 140239842563840 logging_writer.py:48] [477100] global_step=477100, grad_norm=3.0854029655456543, loss=1.0895284414291382
I0305 04:12:31.217474 140239850956544 logging_writer.py:48] [477200] global_step=477200, grad_norm=2.9396982192993164, loss=1.133467435836792
I0305 04:13:16.801171 140239842563840 logging_writer.py:48] [477300] global_step=477300, grad_norm=3.0221428871154785, loss=2.0850541591644287
I0305 04:14:01.711602 140239850956544 logging_writer.py:48] [477400] global_step=477400, grad_norm=3.914358377456665, loss=3.1187515258789062
I0305 04:14:46.659030 140239842563840 logging_writer.py:48] [477500] global_step=477500, grad_norm=3.650489330291748, loss=3.161818504333496
I0305 04:15:31.795897 140239850956544 logging_writer.py:48] [477600] global_step=477600, grad_norm=3.090394973754883, loss=1.0355247259140015
I0305 04:16:17.048436 140239842563840 logging_writer.py:48] [477700] global_step=477700, grad_norm=3.1330995559692383, loss=1.849496603012085
I0305 04:17:02.301406 140239850956544 logging_writer.py:48] [477800] global_step=477800, grad_norm=3.0214507579803467, loss=1.037132978439331
I0305 04:17:46.630307 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:17:57.134829 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:18:27.861728 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:18:29.486690 140437341357888 submission_runner.py:411] Time since start: 233151.04s, 	Step: 477900, 	{'train/accuracy': 0.8867968320846558, 'train/loss': 0.4170536398887634, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 213870.68713450432, 'total_duration': 233151.0371210575, 'accumulated_submission_time': 213870.68713450432, 'accumulated_eval_time': 19211.575483083725, 'accumulated_logging_time': 42.624929428100586}
I0305 04:18:29.598713 140239842563840 logging_writer.py:48] [477900] accumulated_eval_time=19211.575483, accumulated_logging_time=42.624929, accumulated_submission_time=213870.687135, global_step=477900, preemption_count=0, score=213870.687135, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=233151.037121, train/accuracy=0.886797, train/loss=0.417054, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:18:30.005605 140239850956544 logging_writer.py:48] [477900] global_step=477900, grad_norm=3.785630941390991, loss=3.2192699909210205
I0305 04:19:10.905929 140239842563840 logging_writer.py:48] [478000] global_step=478000, grad_norm=3.2782912254333496, loss=1.3005821704864502
I0305 04:19:55.791553 140239850956544 logging_writer.py:48] [478100] global_step=478100, grad_norm=3.0620248317718506, loss=0.9813692569732666
I0305 04:20:41.047066 140239842563840 logging_writer.py:48] [478200] global_step=478200, grad_norm=2.94303297996521, loss=2.258371591567993
I0305 04:21:26.212657 140239850956544 logging_writer.py:48] [478300] global_step=478300, grad_norm=3.01347017288208, loss=1.1655309200286865
I0305 04:22:11.691931 140239842563840 logging_writer.py:48] [478400] global_step=478400, grad_norm=3.21938419342041, loss=2.814871072769165
I0305 04:22:56.926537 140239850956544 logging_writer.py:48] [478500] global_step=478500, grad_norm=3.7618696689605713, loss=3.0941379070281982
I0305 04:23:42.228156 140239842563840 logging_writer.py:48] [478600] global_step=478600, grad_norm=3.18791127204895, loss=2.7411389350891113
I0305 04:24:27.522808 140239850956544 logging_writer.py:48] [478700] global_step=478700, grad_norm=2.903167486190796, loss=2.6425914764404297
I0305 04:25:13.023856 140239842563840 logging_writer.py:48] [478800] global_step=478800, grad_norm=3.5395936965942383, loss=2.970066547393799
I0305 04:25:29.868844 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:25:40.122054 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:26:06.030868 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:26:07.674869 140437341357888 submission_runner.py:411] Time since start: 233609.23s, 	Step: 478839, 	{'train/accuracy': 0.8878905773162842, 'train/loss': 0.4166683554649353, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 214290.89451742172, 'total_duration': 233609.22505187988, 'accumulated_submission_time': 214290.89451742172, 'accumulated_eval_time': 19249.380172729492, 'accumulated_logging_time': 42.74868321418762}
I0305 04:26:07.850817 140239850956544 logging_writer.py:48] [478839] accumulated_eval_time=19249.380173, accumulated_logging_time=42.748683, accumulated_submission_time=214290.894517, global_step=478839, preemption_count=0, score=214290.894517, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=233609.225052, train/accuracy=0.887891, train/loss=0.416668, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:26:32.410291 140239842563840 logging_writer.py:48] [478900] global_step=478900, grad_norm=2.8736777305603027, loss=2.3155102729797363
I0305 04:27:16.604676 140239850956544 logging_writer.py:48] [479000] global_step=479000, grad_norm=3.070227861404419, loss=1.8907690048217773
I0305 04:28:01.639137 140239842563840 logging_writer.py:48] [479100] global_step=479100, grad_norm=2.9361259937286377, loss=0.9884164333343506
I0305 04:28:47.053482 140239850956544 logging_writer.py:48] [479200] global_step=479200, grad_norm=3.076237201690674, loss=1.0985090732574463
I0305 04:29:32.300876 140239842563840 logging_writer.py:48] [479300] global_step=479300, grad_norm=3.3587024211883545, loss=1.1912304162979126
I0305 04:30:17.490386 140239850956544 logging_writer.py:48] [479400] global_step=479400, grad_norm=3.2819838523864746, loss=1.1482335329055786
I0305 04:31:02.900324 140239842563840 logging_writer.py:48] [479500] global_step=479500, grad_norm=3.305535316467285, loss=2.3367509841918945
I0305 04:31:47.867229 140239850956544 logging_writer.py:48] [479600] global_step=479600, grad_norm=2.9059629440307617, loss=2.4751029014587402
I0305 04:32:33.361188 140239842563840 logging_writer.py:48] [479700] global_step=479700, grad_norm=3.0371901988983154, loss=1.0733342170715332
I0305 04:33:08.060696 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:33:18.458890 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:33:45.982674 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:33:47.608010 140437341357888 submission_runner.py:411] Time since start: 234069.16s, 	Step: 479778, 	{'train/accuracy': 0.8868359327316284, 'train/loss': 0.41677939891815186, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 214711.0296151638, 'total_duration': 234069.15846657753, 'accumulated_submission_time': 214711.0296151638, 'accumulated_eval_time': 19288.926438093185, 'accumulated_logging_time': 42.94045972824097}
I0305 04:33:47.715050 140239850956544 logging_writer.py:48] [479778] accumulated_eval_time=19288.926438, accumulated_logging_time=42.940460, accumulated_submission_time=214711.029615, global_step=479778, preemption_count=0, score=214711.029615, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=234069.158467, train/accuracy=0.886836, train/loss=0.416779, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:33:56.893898 140239842563840 logging_writer.py:48] [479800] global_step=479800, grad_norm=3.640688180923462, loss=3.3166184425354004
I0305 04:34:39.348533 140239850956544 logging_writer.py:48] [479900] global_step=479900, grad_norm=3.01859712600708, loss=1.7052993774414062
I0305 04:35:24.532620 140239842563840 logging_writer.py:48] [480000] global_step=480000, grad_norm=2.900190830230713, loss=1.1511164903640747
I0305 04:36:09.760405 140239850956544 logging_writer.py:48] [480100] global_step=480100, grad_norm=3.675074577331543, loss=1.151093602180481
I0305 04:36:54.699062 140239842563840 logging_writer.py:48] [480200] global_step=480200, grad_norm=3.0081586837768555, loss=1.9849188327789307
I0305 04:37:39.997251 140239850956544 logging_writer.py:48] [480300] global_step=480300, grad_norm=3.0147898197174072, loss=1.079217791557312
I0305 04:38:25.459662 140239842563840 logging_writer.py:48] [480400] global_step=480400, grad_norm=3.0817105770111084, loss=2.441466808319092
I0305 04:39:11.040439 140239850956544 logging_writer.py:48] [480500] global_step=480500, grad_norm=2.9569880962371826, loss=1.6733901500701904
I0305 04:39:56.125596 140239842563840 logging_writer.py:48] [480600] global_step=480600, grad_norm=3.5315606594085693, loss=2.9217045307159424
I0305 04:40:41.488162 140239850956544 logging_writer.py:48] [480700] global_step=480700, grad_norm=3.1544177532196045, loss=2.7375547885894775
I0305 04:40:47.950606 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:40:58.334996 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:41:25.997539 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:41:27.621701 140437341357888 submission_runner.py:411] Time since start: 234529.17s, 	Step: 480716, 	{'train/accuracy': 0.8891991972923279, 'train/loss': 0.4213533401489258, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 215131.20206475258, 'total_duration': 234529.17214751244, 'accumulated_submission_time': 215131.20206475258, 'accumulated_eval_time': 19328.59648346901, 'accumulated_logging_time': 43.05870342254639}
I0305 04:41:27.728849 140239842563840 logging_writer.py:48] [480716] accumulated_eval_time=19328.596483, accumulated_logging_time=43.058703, accumulated_submission_time=215131.202065, global_step=480716, preemption_count=0, score=215131.202065, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=234529.172148, train/accuracy=0.889199, train/loss=0.421353, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:42:02.478167 140239850956544 logging_writer.py:48] [480800] global_step=480800, grad_norm=3.414647102355957, loss=1.1570420265197754
I0305 04:42:47.508486 140239842563840 logging_writer.py:48] [480900] global_step=480900, grad_norm=3.295903205871582, loss=1.1981226205825806
I0305 04:43:32.995341 140239850956544 logging_writer.py:48] [481000] global_step=481000, grad_norm=3.2657628059387207, loss=1.4430570602416992
I0305 04:44:18.308133 140239842563840 logging_writer.py:48] [481100] global_step=481100, grad_norm=3.2075388431549072, loss=1.460121989250183
I0305 04:45:03.680999 140239850956544 logging_writer.py:48] [481200] global_step=481200, grad_norm=2.9408023357391357, loss=1.9668972492218018
I0305 04:45:48.805533 140239842563840 logging_writer.py:48] [481300] global_step=481300, grad_norm=2.9436211585998535, loss=1.215073585510254
I0305 04:46:34.102796 140239850956544 logging_writer.py:48] [481400] global_step=481400, grad_norm=3.224853515625, loss=1.2393237352371216
I0305 04:47:19.660386 140239842563840 logging_writer.py:48] [481500] global_step=481500, grad_norm=3.1920835971832275, loss=1.2355483770370483
I0305 04:48:05.305834 140239850956544 logging_writer.py:48] [481600] global_step=481600, grad_norm=2.7835333347320557, loss=1.0309314727783203
I0305 04:48:27.950884 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:48:38.310365 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:49:11.749634 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:49:13.412228 140437341357888 submission_runner.py:411] Time since start: 234994.96s, 	Step: 481652, 	{'train/accuracy': 0.8895312547683716, 'train/loss': 0.4089459180831909, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 215551.36306786537, 'total_duration': 234994.9626107216, 'accumulated_submission_time': 215551.36306786537, 'accumulated_eval_time': 19374.056756734848, 'accumulated_logging_time': 43.17589569091797}
I0305 04:49:13.586723 140239842563840 logging_writer.py:48] [481652] accumulated_eval_time=19374.056757, accumulated_logging_time=43.175896, accumulated_submission_time=215551.363068, global_step=481652, preemption_count=0, score=215551.363068, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=234994.962611, train/accuracy=0.889531, train/loss=0.408946, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:49:33.029771 140239850956544 logging_writer.py:48] [481700] global_step=481700, grad_norm=2.898839235305786, loss=1.0796175003051758
I0305 04:50:14.993342 140239842563840 logging_writer.py:48] [481800] global_step=481800, grad_norm=2.9179491996765137, loss=1.0733153820037842
I0305 04:51:00.404642 140239850956544 logging_writer.py:48] [481900] global_step=481900, grad_norm=3.0449419021606445, loss=1.2283685207366943
I0305 04:51:45.927707 140239842563840 logging_writer.py:48] [482000] global_step=482000, grad_norm=3.090998888015747, loss=1.0503255128860474
I0305 04:52:30.989681 140239850956544 logging_writer.py:48] [482100] global_step=482100, grad_norm=3.224867820739746, loss=1.1857692003250122
I0305 04:53:16.457274 140239842563840 logging_writer.py:48] [482200] global_step=482200, grad_norm=2.968890428543091, loss=1.2735570669174194
I0305 04:54:01.467860 140239850956544 logging_writer.py:48] [482300] global_step=482300, grad_norm=3.0273406505584717, loss=1.166475534439087
I0305 04:54:46.574843 140239842563840 logging_writer.py:48] [482400] global_step=482400, grad_norm=3.1997132301330566, loss=1.80500328540802
I0305 04:55:31.951338 140239850956544 logging_writer.py:48] [482500] global_step=482500, grad_norm=2.7602195739746094, loss=1.8898402452468872
I0305 04:56:13.454288 140437341357888 spec.py:321] Evaluating on the training split.
I0305 04:56:23.831399 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 04:56:48.464426 140437341357888 spec.py:349] Evaluating on the test split.
I0305 04:56:50.088630 140437341357888 submission_runner.py:411] Time since start: 235451.64s, 	Step: 482594, 	{'train/accuracy': 0.8869726657867432, 'train/loss': 0.42001819610595703, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 215971.16331911087, 'total_duration': 235451.63884043694, 'accumulated_submission_time': 215971.16331911087, 'accumulated_eval_time': 19410.689818143845, 'accumulated_logging_time': 43.365275382995605}
I0305 04:56:50.208219 140239842563840 logging_writer.py:48] [482594] accumulated_eval_time=19410.689818, accumulated_logging_time=43.365275, accumulated_submission_time=215971.163319, global_step=482594, preemption_count=0, score=215971.163319, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=235451.638840, train/accuracy=0.886973, train/loss=0.420018, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 04:56:52.987767 140239850956544 logging_writer.py:48] [482600] global_step=482600, grad_norm=3.818371534347534, loss=3.2981035709381104
I0305 04:57:34.246713 140239842563840 logging_writer.py:48] [482700] global_step=482700, grad_norm=2.938901424407959, loss=1.2249177694320679
I0305 04:58:19.333787 140239850956544 logging_writer.py:48] [482800] global_step=482800, grad_norm=2.935807466506958, loss=1.9850270748138428
I0305 04:59:04.522895 140239842563840 logging_writer.py:48] [482900] global_step=482900, grad_norm=3.380034923553467, loss=1.244481086730957
I0305 04:59:50.262779 140239850956544 logging_writer.py:48] [483000] global_step=483000, grad_norm=3.6152095794677734, loss=2.497133731842041
I0305 05:00:35.619904 140239842563840 logging_writer.py:48] [483100] global_step=483100, grad_norm=2.9334897994995117, loss=1.1472008228302002
I0305 05:01:20.906004 140239850956544 logging_writer.py:48] [483200] global_step=483200, grad_norm=2.9504892826080322, loss=1.1162364482879639
I0305 05:02:06.148910 140239842563840 logging_writer.py:48] [483300] global_step=483300, grad_norm=3.1441750526428223, loss=1.3055312633514404
I0305 05:02:51.367816 140239850956544 logging_writer.py:48] [483400] global_step=483400, grad_norm=3.2820615768432617, loss=1.2630060911178589
I0305 05:03:36.471224 140239842563840 logging_writer.py:48] [483500] global_step=483500, grad_norm=3.670426368713379, loss=2.9598770141601562
I0305 05:03:50.248308 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:04:00.973718 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:04:28.304481 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:04:29.925933 140437341357888 submission_runner.py:411] Time since start: 235911.48s, 	Step: 483532, 	{'train/accuracy': 0.8881444931030273, 'train/loss': 0.4166688323020935, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 216391.14154362679, 'total_duration': 235911.47638177872, 'accumulated_submission_time': 216391.14154362679, 'accumulated_eval_time': 19450.36641383171, 'accumulated_logging_time': 43.495421171188354}
I0305 05:04:30.036312 140239850956544 logging_writer.py:48] [483532] accumulated_eval_time=19450.366414, accumulated_logging_time=43.495421, accumulated_submission_time=216391.141544, global_step=483532, preemption_count=0, score=216391.141544, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=235911.476382, train/accuracy=0.888144, train/loss=0.416669, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:04:57.739545 140239842563840 logging_writer.py:48] [483600] global_step=483600, grad_norm=3.133364200592041, loss=2.726893901824951
I0305 05:05:42.729271 140239850956544 logging_writer.py:48] [483700] global_step=483700, grad_norm=2.991668224334717, loss=2.6806249618530273
I0305 05:06:28.071413 140239842563840 logging_writer.py:48] [483800] global_step=483800, grad_norm=3.3198437690734863, loss=1.147130012512207
I0305 05:07:13.580078 140239850956544 logging_writer.py:48] [483900] global_step=483900, grad_norm=3.0318925380706787, loss=1.1840002536773682
I0305 05:07:58.720662 140239842563840 logging_writer.py:48] [484000] global_step=484000, grad_norm=3.008774995803833, loss=1.1625094413757324
I0305 05:08:44.016192 140239850956544 logging_writer.py:48] [484100] global_step=484100, grad_norm=3.1329686641693115, loss=1.7737964391708374
I0305 05:09:29.733960 140239842563840 logging_writer.py:48] [484200] global_step=484200, grad_norm=3.1344988346099854, loss=1.1418205499649048
I0305 05:10:15.074769 140239850956544 logging_writer.py:48] [484300] global_step=484300, grad_norm=3.027956485748291, loss=1.1002274751663208
I0305 05:11:00.560721 140239842563840 logging_writer.py:48] [484400] global_step=484400, grad_norm=3.6037704944610596, loss=2.7347426414489746
I0305 05:11:30.154522 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:11:40.639000 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:12:19.873281 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:12:21.491422 140437341357888 submission_runner.py:411] Time since start: 236383.04s, 	Step: 484467, 	{'train/accuracy': 0.8903319835662842, 'train/loss': 0.4062535762786865, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 216811.19788599014, 'total_duration': 236383.04190945625, 'accumulated_submission_time': 216811.19788599014, 'accumulated_eval_time': 19501.702306985855, 'accumulated_logging_time': 43.616320848464966}
I0305 05:12:21.594377 140239850956544 logging_writer.py:48] [484467] accumulated_eval_time=19501.702307, accumulated_logging_time=43.616321, accumulated_submission_time=216811.197886, global_step=484467, preemption_count=0, score=216811.197886, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=236383.041909, train/accuracy=0.890332, train/loss=0.406254, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:12:35.053225 140239842563840 logging_writer.py:48] [484500] global_step=484500, grad_norm=3.25434947013855, loss=1.1399937868118286
I0305 05:13:16.704959 140239850956544 logging_writer.py:48] [484600] global_step=484600, grad_norm=3.178762197494507, loss=1.0199487209320068
I0305 05:14:01.872835 140239842563840 logging_writer.py:48] [484700] global_step=484700, grad_norm=2.815922737121582, loss=1.1782500743865967
I0305 05:14:47.265745 140239850956544 logging_writer.py:48] [484800] global_step=484800, grad_norm=3.248908519744873, loss=1.3050341606140137
I0305 05:15:32.587167 140239842563840 logging_writer.py:48] [484900] global_step=484900, grad_norm=3.5005292892456055, loss=3.306994915008545
I0305 05:16:17.715694 140239850956544 logging_writer.py:48] [485000] global_step=485000, grad_norm=2.9936041831970215, loss=1.0249298810958862
I0305 05:17:03.015989 140239842563840 logging_writer.py:48] [485100] global_step=485100, grad_norm=2.954448699951172, loss=1.2391722202301025
I0305 05:17:48.423156 140239850956544 logging_writer.py:48] [485200] global_step=485200, grad_norm=3.5435500144958496, loss=3.1178197860717773
I0305 05:18:33.998599 140239842563840 logging_writer.py:48] [485300] global_step=485300, grad_norm=2.9926774501800537, loss=1.6329435110092163
I0305 05:19:19.043785 140239850956544 logging_writer.py:48] [485400] global_step=485400, grad_norm=3.2070071697235107, loss=1.1295090913772583
I0305 05:19:21.896887 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:19:32.382435 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:19:58.702274 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:20:00.327723 140437341357888 submission_runner.py:411] Time since start: 236841.88s, 	Step: 485408, 	{'train/accuracy': 0.8874218463897705, 'train/loss': 0.41746610403060913, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 217231.43805646896, 'total_duration': 236841.87820458412, 'accumulated_submission_time': 217231.43805646896, 'accumulated_eval_time': 19540.132127523422, 'accumulated_logging_time': 43.72937512397766}
I0305 05:20:00.439966 140239842563840 logging_writer.py:48] [485408] accumulated_eval_time=19540.132128, accumulated_logging_time=43.729375, accumulated_submission_time=217231.438056, global_step=485408, preemption_count=0, score=217231.438056, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=236841.878205, train/accuracy=0.887422, train/loss=0.417466, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:20:38.782468 140239850956544 logging_writer.py:48] [485500] global_step=485500, grad_norm=2.9562084674835205, loss=2.1417739391326904
I0305 05:21:23.964338 140239842563840 logging_writer.py:48] [485600] global_step=485600, grad_norm=2.9694855213165283, loss=2.5998024940490723
I0305 05:22:09.119930 140239850956544 logging_writer.py:48] [485700] global_step=485700, grad_norm=3.0756289958953857, loss=1.1248712539672852
I0305 05:22:53.935434 140239842563840 logging_writer.py:48] [485800] global_step=485800, grad_norm=2.9617667198181152, loss=1.0814735889434814
I0305 05:23:39.078006 140239850956544 logging_writer.py:48] [485900] global_step=485900, grad_norm=3.0251832008361816, loss=1.618843913078308
I0305 05:24:24.296561 140239842563840 logging_writer.py:48] [486000] global_step=486000, grad_norm=3.8205223083496094, loss=1.1171683073043823
I0305 05:25:09.286125 140239850956544 logging_writer.py:48] [486100] global_step=486100, grad_norm=3.454045295715332, loss=3.0309159755706787
I0305 05:25:54.363681 140239842563840 logging_writer.py:48] [486200] global_step=486200, grad_norm=3.519524335861206, loss=2.8548483848571777
I0305 05:26:39.926393 140239850956544 logging_writer.py:48] [486300] global_step=486300, grad_norm=2.9230287075042725, loss=1.1520533561706543
I0305 05:27:00.649739 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:27:11.506620 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:27:40.070008 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:27:41.691996 140437341357888 submission_runner.py:411] Time since start: 237303.24s, 	Step: 486348, 	{'train/accuracy': 0.8887890577316284, 'train/loss': 0.4112873673439026, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 217651.5862724781, 'total_duration': 237303.24244117737, 'accumulated_submission_time': 217651.5862724781, 'accumulated_eval_time': 19581.17331981659, 'accumulated_logging_time': 43.85249710083008}
I0305 05:27:41.803742 140239842563840 logging_writer.py:48] [486348] accumulated_eval_time=19581.173320, accumulated_logging_time=43.852497, accumulated_submission_time=217651.586272, global_step=486348, preemption_count=0, score=217651.586272, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=237303.242441, train/accuracy=0.888789, train/loss=0.411287, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:28:02.808612 140239850956544 logging_writer.py:48] [486400] global_step=486400, grad_norm=3.371814727783203, loss=2.844320297241211
I0305 05:28:46.693236 140239842563840 logging_writer.py:48] [486500] global_step=486500, grad_norm=3.2042205333709717, loss=2.134120464324951
I0305 05:29:32.012305 140239850956544 logging_writer.py:48] [486600] global_step=486600, grad_norm=3.076373338699341, loss=1.2737343311309814
I0305 05:30:17.793591 140239842563840 logging_writer.py:48] [486700] global_step=486700, grad_norm=3.055720090866089, loss=1.2863285541534424
I0305 05:31:02.876604 140239850956544 logging_writer.py:48] [486800] global_step=486800, grad_norm=3.2203683853149414, loss=2.8443503379821777
I0305 05:31:48.174461 140239842563840 logging_writer.py:48] [486900] global_step=486900, grad_norm=3.062411069869995, loss=1.1709728240966797
I0305 05:32:33.470332 140239850956544 logging_writer.py:48] [487000] global_step=487000, grad_norm=3.202834129333496, loss=2.4005582332611084
I0305 05:33:18.856979 140239842563840 logging_writer.py:48] [487100] global_step=487100, grad_norm=2.8928890228271484, loss=2.274104595184326
I0305 05:34:04.278294 140239850956544 logging_writer.py:48] [487200] global_step=487200, grad_norm=3.030567169189453, loss=1.1041470766067505
I0305 05:34:42.001245 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:34:52.371093 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:35:20.620406 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:35:22.236593 140437341357888 submission_runner.py:411] Time since start: 237763.79s, 	Step: 487285, 	{'train/accuracy': 0.8875781297683716, 'train/loss': 0.4143383204936981, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 218071.72273302078, 'total_duration': 237763.78665471077, 'accumulated_submission_time': 218071.72273302078, 'accumulated_eval_time': 19621.407239437103, 'accumulated_logging_time': 43.97446012496948}
I0305 05:35:22.348811 140239842563840 logging_writer.py:48] [487285] accumulated_eval_time=19621.407239, accumulated_logging_time=43.974460, accumulated_submission_time=218071.722733, global_step=487285, preemption_count=0, score=218071.722733, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=237763.786655, train/accuracy=0.887578, train/loss=0.414338, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:35:28.705371 140239850956544 logging_writer.py:48] [487300] global_step=487300, grad_norm=3.0428173542022705, loss=1.1417962312698364
I0305 05:36:10.767359 140239842563840 logging_writer.py:48] [487400] global_step=487400, grad_norm=2.85518479347229, loss=1.3474738597869873
I0305 05:36:55.812519 140239850956544 logging_writer.py:48] [487500] global_step=487500, grad_norm=3.05806303024292, loss=1.0930461883544922
I0305 05:37:41.186331 140239842563840 logging_writer.py:48] [487600] global_step=487600, grad_norm=2.6874656677246094, loss=1.5190553665161133
I0305 05:38:26.410197 140239850956544 logging_writer.py:48] [487700] global_step=487700, grad_norm=4.11591911315918, loss=1.1478060483932495
I0305 05:39:11.579011 140239842563840 logging_writer.py:48] [487800] global_step=487800, grad_norm=3.3250675201416016, loss=2.692826509475708
I0305 05:39:56.501736 140239850956544 logging_writer.py:48] [487900] global_step=487900, grad_norm=3.1134145259857178, loss=1.2177703380584717
I0305 05:40:42.818101 140239842563840 logging_writer.py:48] [488000] global_step=488000, grad_norm=3.4951510429382324, loss=3.0811967849731445
I0305 05:41:28.363356 140239850956544 logging_writer.py:48] [488100] global_step=488100, grad_norm=3.469146490097046, loss=1.2339965105056763
I0305 05:42:13.772912 140239842563840 logging_writer.py:48] [488200] global_step=488200, grad_norm=3.1765239238739014, loss=1.1431176662445068
I0305 05:42:22.449224 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:42:32.911755 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:43:01.750128 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:43:03.370595 140437341357888 submission_runner.py:411] Time since start: 238224.92s, 	Step: 488221, 	{'train/accuracy': 0.8894335627555847, 'train/loss': 0.4136330187320709, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 218491.75671744347, 'total_duration': 238224.9208495617, 'accumulated_submission_time': 218491.75671744347, 'accumulated_eval_time': 19662.32736802101, 'accumulated_logging_time': 44.102455615997314}
I0305 05:43:03.488811 140239850956544 logging_writer.py:48] [488221] accumulated_eval_time=19662.327368, accumulated_logging_time=44.102456, accumulated_submission_time=218491.756717, global_step=488221, preemption_count=0, score=218491.756717, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=238224.920850, train/accuracy=0.889434, train/loss=0.413633, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:43:35.850687 140239842563840 logging_writer.py:48] [488300] global_step=488300, grad_norm=2.899702787399292, loss=1.3048343658447266
I0305 05:44:20.934493 140239850956544 logging_writer.py:48] [488400] global_step=488400, grad_norm=3.0992493629455566, loss=1.16557776927948
I0305 05:45:06.401591 140239842563840 logging_writer.py:48] [488500] global_step=488500, grad_norm=3.304053544998169, loss=2.3990159034729004
I0305 05:45:51.665315 140239850956544 logging_writer.py:48] [488600] global_step=488600, grad_norm=3.2061619758605957, loss=1.1974010467529297
I0305 05:46:37.173210 140239842563840 logging_writer.py:48] [488700] global_step=488700, grad_norm=2.6553590297698975, loss=1.2520807981491089
I0305 05:47:22.707174 140239850956544 logging_writer.py:48] [488800] global_step=488800, grad_norm=3.1757936477661133, loss=2.5846314430236816
I0305 05:48:07.849009 140239842563840 logging_writer.py:48] [488900] global_step=488900, grad_norm=3.0504066944122314, loss=2.7490689754486084
I0305 05:48:53.257412 140239850956544 logging_writer.py:48] [489000] global_step=489000, grad_norm=3.1085968017578125, loss=2.766538619995117
I0305 05:49:38.551423 140239842563840 logging_writer.py:48] [489100] global_step=489100, grad_norm=2.9029181003570557, loss=1.023592472076416
I0305 05:50:03.658817 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:50:14.046496 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:50:45.568499 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:50:47.193235 140437341357888 submission_runner.py:411] Time since start: 238688.74s, 	Step: 489157, 	{'train/accuracy': 0.88916015625, 'train/loss': 0.4151538014411926, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 218911.8640100956, 'total_duration': 238688.74359989166, 'accumulated_submission_time': 218911.8640100956, 'accumulated_eval_time': 19705.860652446747, 'accumulated_logging_time': 44.23263597488403}
I0305 05:50:47.311997 140239850956544 logging_writer.py:48] [489157] accumulated_eval_time=19705.860652, accumulated_logging_time=44.232636, accumulated_submission_time=218911.864010, global_step=489157, preemption_count=0, score=218911.864010, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=238688.743600, train/accuracy=0.889160, train/loss=0.415154, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:51:04.740864 140239842563840 logging_writer.py:48] [489200] global_step=489200, grad_norm=3.2697746753692627, loss=1.143906593322754
I0305 05:51:48.110192 140239850956544 logging_writer.py:48] [489300] global_step=489300, grad_norm=3.921107530593872, loss=3.1113247871398926
I0305 05:52:33.492356 140239842563840 logging_writer.py:48] [489400] global_step=489400, grad_norm=2.943556308746338, loss=2.45827317237854
I0305 05:53:18.995606 140239850956544 logging_writer.py:48] [489500] global_step=489500, grad_norm=3.136244297027588, loss=1.1411036252975464
I0305 05:54:04.133989 140239842563840 logging_writer.py:48] [489600] global_step=489600, grad_norm=3.513812303543091, loss=3.0743608474731445
I0305 05:54:49.529328 140239850956544 logging_writer.py:48] [489700] global_step=489700, grad_norm=3.0304512977600098, loss=1.811845064163208
I0305 05:55:34.531722 140239842563840 logging_writer.py:48] [489800] global_step=489800, grad_norm=3.337851047515869, loss=2.6677815914154053
I0305 05:56:19.745215 140239850956544 logging_writer.py:48] [489900] global_step=489900, grad_norm=3.981931447982788, loss=3.1507728099823
I0305 05:57:04.995054 140239842563840 logging_writer.py:48] [490000] global_step=490000, grad_norm=3.416605234146118, loss=1.3973686695098877
I0305 05:57:47.343182 140437341357888 spec.py:321] Evaluating on the training split.
I0305 05:57:57.656421 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 05:58:29.576936 140437341357888 spec.py:349] Evaluating on the test split.
I0305 05:58:31.194028 140437341357888 submission_runner.py:411] Time since start: 239152.74s, 	Step: 490095, 	{'train/accuracy': 0.8889452815055847, 'train/loss': 0.4118638038635254, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 219331.83431482315, 'total_duration': 239152.7444009781, 'accumulated_submission_time': 219331.83431482315, 'accumulated_eval_time': 19749.71036696434, 'accumulated_logging_time': 44.36157035827637}
I0305 05:58:31.307815 140239850956544 logging_writer.py:48] [490095] accumulated_eval_time=19749.710367, accumulated_logging_time=44.361570, accumulated_submission_time=219331.834315, global_step=490095, preemption_count=0, score=219331.834315, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=239152.744401, train/accuracy=0.888945, train/loss=0.411864, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 05:58:33.706395 140239842563840 logging_writer.py:48] [490100] global_step=490100, grad_norm=3.6242311000823975, loss=3.1854989528656006
I0305 05:59:15.070410 140239850956544 logging_writer.py:48] [490200] global_step=490200, grad_norm=2.9508419036865234, loss=2.160276412963867
I0305 06:00:00.177510 140239842563840 logging_writer.py:48] [490300] global_step=490300, grad_norm=2.964601755142212, loss=1.1227021217346191
I0305 06:00:45.510896 140239850956544 logging_writer.py:48] [490400] global_step=490400, grad_norm=2.9374239444732666, loss=1.16028892993927
I0305 06:01:30.978128 140239842563840 logging_writer.py:48] [490500] global_step=490500, grad_norm=2.8099493980407715, loss=1.568920373916626
I0305 06:02:16.153939 140239850956544 logging_writer.py:48] [490600] global_step=490600, grad_norm=3.113964796066284, loss=1.0943927764892578
I0305 06:03:01.434702 140239842563840 logging_writer.py:48] [490700] global_step=490700, grad_norm=4.754147529602051, loss=3.2858078479766846
I0305 06:03:46.723964 140239850956544 logging_writer.py:48] [490800] global_step=490800, grad_norm=2.7846908569335938, loss=1.0702494382858276
I0305 06:04:31.984257 140239842563840 logging_writer.py:48] [490900] global_step=490900, grad_norm=3.2291336059570312, loss=2.0993916988372803
I0305 06:05:17.132635 140239850956544 logging_writer.py:48] [491000] global_step=491000, grad_norm=3.1632204055786133, loss=1.4945054054260254
I0305 06:05:31.558124 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:05:42.083124 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 06:06:10.156942 140437341357888 spec.py:349] Evaluating on the test split.
I0305 06:06:11.807592 140437341357888 submission_runner.py:411] Time since start: 239613.36s, 	Step: 491034, 	{'train/accuracy': 0.8895898461341858, 'train/loss': 0.4138146638870239, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 219752.01549005508, 'total_duration': 239613.35805392265, 'accumulated_submission_time': 219752.01549005508, 'accumulated_eval_time': 19789.958799123764, 'accumulated_logging_time': 44.49367165565491}
I0305 06:06:11.929261 140239842563840 logging_writer.py:48] [491034] accumulated_eval_time=19789.958799, accumulated_logging_time=44.493672, accumulated_submission_time=219752.015490, global_step=491034, preemption_count=0, score=219752.015490, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=239613.358054, train/accuracy=0.889590, train/loss=0.413815, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 06:06:38.468226 140239850956544 logging_writer.py:48] [491100] global_step=491100, grad_norm=2.874239683151245, loss=1.9793139696121216
I0305 06:07:22.522933 140239842563840 logging_writer.py:48] [491200] global_step=491200, grad_norm=3.200385808944702, loss=1.456997275352478
I0305 06:08:07.944238 140239850956544 logging_writer.py:48] [491300] global_step=491300, grad_norm=3.265011787414551, loss=1.1739654541015625
I0305 06:08:53.562132 140239842563840 logging_writer.py:48] [491400] global_step=491400, grad_norm=2.825679063796997, loss=2.044865369796753
I0305 06:09:38.464453 140239850956544 logging_writer.py:48] [491500] global_step=491500, grad_norm=2.8038744926452637, loss=1.556661605834961
I0305 06:10:23.615520 140239842563840 logging_writer.py:48] [491600] global_step=491600, grad_norm=2.9867355823516846, loss=1.2525429725646973
I0305 06:11:09.356441 140239850956544 logging_writer.py:48] [491700] global_step=491700, grad_norm=3.0797648429870605, loss=2.718630313873291
I0305 06:11:54.308532 140239842563840 logging_writer.py:48] [491800] global_step=491800, grad_norm=3.2813475131988525, loss=1.1639479398727417
I0305 06:12:39.526703 140239850956544 logging_writer.py:48] [491900] global_step=491900, grad_norm=2.862823486328125, loss=1.6955616474151611
I0305 06:13:12.028580 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:13:23.084581 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 06:13:50.318003 140437341357888 spec.py:349] Evaluating on the test split.
I0305 06:13:51.936583 140437341357888 submission_runner.py:411] Time since start: 240073.49s, 	Step: 491973, 	{'train/accuracy': 0.8890038728713989, 'train/loss': 0.4148271977901459, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 220172.04870462418, 'total_duration': 240073.48684430122, 'accumulated_submission_time': 220172.04870462418, 'accumulated_eval_time': 19829.86556172371, 'accumulated_logging_time': 44.63035583496094}
I0305 06:13:52.046593 140239842563840 logging_writer.py:48] [491973] accumulated_eval_time=19829.865562, accumulated_logging_time=44.630356, accumulated_submission_time=220172.048705, global_step=491973, preemption_count=0, score=220172.048705, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=240073.486844, train/accuracy=0.889004, train/loss=0.414827, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 06:14:03.152772 140239850956544 logging_writer.py:48] [492000] global_step=492000, grad_norm=3.12206768989563, loss=2.8177051544189453
I0305 06:14:46.000295 140239842563840 logging_writer.py:48] [492100] global_step=492100, grad_norm=3.0527029037475586, loss=1.1233940124511719
I0305 06:15:31.099992 140239850956544 logging_writer.py:48] [492200] global_step=492200, grad_norm=3.6256015300750732, loss=2.2783994674682617
I0305 06:16:16.688870 140239842563840 logging_writer.py:48] [492300] global_step=492300, grad_norm=2.9509849548339844, loss=1.0910217761993408
I0305 06:17:02.023530 140239850956544 logging_writer.py:48] [492400] global_step=492400, grad_norm=3.9026832580566406, loss=2.849947214126587
I0305 06:17:47.267244 140239842563840 logging_writer.py:48] [492500] global_step=492500, grad_norm=3.1614232063293457, loss=1.0564221143722534
I0305 06:18:32.529946 140239850956544 logging_writer.py:48] [492600] global_step=492600, grad_norm=8.434605598449707, loss=3.188772201538086
I0305 06:19:17.855777 140239842563840 logging_writer.py:48] [492700] global_step=492700, grad_norm=2.9880964756011963, loss=1.4958572387695312
I0305 06:20:03.186008 140239850956544 logging_writer.py:48] [492800] global_step=492800, grad_norm=3.37520694732666, loss=1.1118321418762207
I0305 06:20:48.356817 140239842563840 logging_writer.py:48] [492900] global_step=492900, grad_norm=2.6745095252990723, loss=1.7243534326553345
I0305 06:20:52.111829 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:21:02.861448 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 06:21:31.254414 140437341357888 spec.py:349] Evaluating on the test split.
I0305 06:21:32.886717 140437341357888 submission_runner.py:411] Time since start: 240534.44s, 	Step: 492910, 	{'train/accuracy': 0.8866601586341858, 'train/loss': 0.41593635082244873, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 220592.05123972893, 'total_duration': 240534.43725800514, 'accumulated_submission_time': 220592.05123972893, 'accumulated_eval_time': 19870.639471769333, 'accumulated_logging_time': 44.751044273376465}
I0305 06:21:32.999493 140239850956544 logging_writer.py:48] [492910] accumulated_eval_time=19870.639472, accumulated_logging_time=44.751044, accumulated_submission_time=220592.051240, global_step=492910, preemption_count=0, score=220592.051240, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=240534.437258, train/accuracy=0.886660, train/loss=0.415936, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 06:22:10.542550 140239842563840 logging_writer.py:48] [493000] global_step=493000, grad_norm=3.431377649307251, loss=2.1795880794525146
I0305 06:22:55.340504 140239850956544 logging_writer.py:48] [493100] global_step=493100, grad_norm=2.969653606414795, loss=1.275733232498169
I0305 06:23:40.698328 140239842563840 logging_writer.py:48] [493200] global_step=493200, grad_norm=3.0040791034698486, loss=1.4115879535675049
I0305 06:24:26.063100 140239850956544 logging_writer.py:48] [493300] global_step=493300, grad_norm=3.6870899200439453, loss=1.4080424308776855
I0305 06:25:11.473631 140239842563840 logging_writer.py:48] [493400] global_step=493400, grad_norm=2.8156888484954834, loss=1.9462214708328247
I0305 06:25:56.608444 140239850956544 logging_writer.py:48] [493500] global_step=493500, grad_norm=3.1095921993255615, loss=1.0374767780303955
I0305 06:26:41.824504 140239842563840 logging_writer.py:48] [493600] global_step=493600, grad_norm=3.2381417751312256, loss=2.6920642852783203
I0305 06:27:27.053825 140239850956544 logging_writer.py:48] [493700] global_step=493700, grad_norm=2.9209465980529785, loss=1.0205127000808716
I0305 06:28:12.098469 140239842563840 logging_writer.py:48] [493800] global_step=493800, grad_norm=3.360374927520752, loss=1.1969728469848633
I0305 06:28:33.005190 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:28:43.297056 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 06:29:14.881439 140437341357888 spec.py:349] Evaluating on the test split.
I0305 06:29:16.536092 140437341357888 submission_runner.py:411] Time since start: 240998.09s, 	Step: 493848, 	{'train/accuracy': 0.887499988079071, 'train/loss': 0.4184769093990326, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 221011.99106287956, 'total_duration': 240998.08652853966, 'accumulated_submission_time': 221011.99106287956, 'accumulated_eval_time': 19914.169314861298, 'accumulated_logging_time': 44.8757050037384}
I0305 06:29:16.626291 140239850956544 logging_writer.py:48] [493848] accumulated_eval_time=19914.169315, accumulated_logging_time=44.875705, accumulated_submission_time=221011.991063, global_step=493848, preemption_count=0, score=221011.991063, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=240998.086529, train/accuracy=0.887500, train/loss=0.418477, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 06:29:37.617560 140239842563840 logging_writer.py:48] [493900] global_step=493900, grad_norm=3.2573893070220947, loss=1.1544243097305298
I0305 06:30:20.449766 140239850956544 logging_writer.py:48] [494000] global_step=494000, grad_norm=3.7663562297821045, loss=3.1946487426757812
I0305 06:31:05.967218 140239842563840 logging_writer.py:48] [494100] global_step=494100, grad_norm=2.97353196144104, loss=2.60971999168396
I0305 06:31:51.896303 140239850956544 logging_writer.py:48] [494200] global_step=494200, grad_norm=3.1893110275268555, loss=1.1260817050933838
I0305 06:32:37.265543 140239842563840 logging_writer.py:48] [494300] global_step=494300, grad_norm=2.9414901733398438, loss=1.0663039684295654
I0305 06:33:22.359198 140239850956544 logging_writer.py:48] [494400] global_step=494400, grad_norm=3.603978157043457, loss=3.271678924560547
I0305 06:34:07.615370 140239842563840 logging_writer.py:48] [494500] global_step=494500, grad_norm=3.3587424755096436, loss=2.0933918952941895
I0305 06:34:52.873293 140239850956544 logging_writer.py:48] [494600] global_step=494600, grad_norm=2.862508773803711, loss=1.2782775163650513
I0305 06:35:38.175094 140239842563840 logging_writer.py:48] [494700] global_step=494700, grad_norm=2.739164352416992, loss=1.3167545795440674
I0305 06:36:16.747947 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:36:27.162934 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 06:36:51.280448 140437341357888 spec.py:349] Evaluating on the test split.
I0305 06:36:52.904730 140437341357888 submission_runner.py:411] Time since start: 241454.46s, 	Step: 494787, 	{'train/accuracy': 0.8898242115974426, 'train/loss': 0.41217684745788574, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 221432.05100941658, 'total_duration': 241454.45515203476, 'accumulated_submission_time': 221432.05100941658, 'accumulated_eval_time': 19950.32503771782, 'accumulated_logging_time': 44.97604584693909}
I0305 06:36:53.014282 140239850956544 logging_writer.py:48] [494787] accumulated_eval_time=19950.325038, accumulated_logging_time=44.976046, accumulated_submission_time=221432.051009, global_step=494787, preemption_count=0, score=221432.051009, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=241454.455152, train/accuracy=0.889824, train/loss=0.412177, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 06:36:58.595689 140239842563840 logging_writer.py:48] [494800] global_step=494800, grad_norm=3.218205451965332, loss=2.2565746307373047
I0305 06:37:40.709225 140239850956544 logging_writer.py:48] [494900] global_step=494900, grad_norm=3.191053867340088, loss=2.705538511276245
I0305 06:38:25.825868 140239842563840 logging_writer.py:48] [495000] global_step=495000, grad_norm=3.011629819869995, loss=2.1416642665863037
I0305 06:39:11.054723 140239850956544 logging_writer.py:48] [495100] global_step=495100, grad_norm=2.996767044067383, loss=1.1082801818847656
I0305 06:39:56.079766 140239842563840 logging_writer.py:48] [495200] global_step=495200, grad_norm=3.216216802597046, loss=2.666731595993042
I0305 06:40:41.311031 140239850956544 logging_writer.py:48] [495300] global_step=495300, grad_norm=3.2763116359710693, loss=1.1715079545974731
I0305 06:41:26.744044 140239842563840 logging_writer.py:48] [495400] global_step=495400, grad_norm=3.995361328125, loss=3.208911657333374
I0305 06:42:12.520128 140239850956544 logging_writer.py:48] [495500] global_step=495500, grad_norm=2.9224607944488525, loss=1.2540030479431152
I0305 06:42:57.475267 140239842563840 logging_writer.py:48] [495600] global_step=495600, grad_norm=2.8734683990478516, loss=1.609138011932373
I0305 06:43:42.713646 140239850956544 logging_writer.py:48] [495700] global_step=495700, grad_norm=2.987833023071289, loss=2.0309090614318848
I0305 06:43:53.142518 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:44:03.900329 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 06:44:37.161206 140437341357888 spec.py:349] Evaluating on the test split.
I0305 06:44:38.777724 140437341357888 submission_runner.py:411] Time since start: 241920.33s, 	Step: 495725, 	{'train/accuracy': 0.89013671875, 'train/loss': 0.4112144410610199, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 221852.11770009995, 'total_duration': 241920.32781767845, 'accumulated_submission_time': 221852.11770009995, 'accumulated_eval_time': 19995.958854675293, 'accumulated_logging_time': 45.096198320388794}
I0305 06:44:38.884045 140239842563840 logging_writer.py:48] [495725] accumulated_eval_time=19995.958855, accumulated_logging_time=45.096198, accumulated_submission_time=221852.117700, global_step=495725, preemption_count=0, score=221852.117700, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=241920.327818, train/accuracy=0.890137, train/loss=0.411214, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 06:45:09.520422 140239850956544 logging_writer.py:48] [495800] global_step=495800, grad_norm=3.0728440284729004, loss=1.1636408567428589
I0305 06:45:54.752572 140239842563840 logging_writer.py:48] [495900] global_step=495900, grad_norm=2.764270305633545, loss=1.177886962890625
I0305 06:46:40.648352 140239850956544 logging_writer.py:48] [496000] global_step=496000, grad_norm=3.2414331436157227, loss=1.13272225856781
I0305 06:47:26.305450 140239842563840 logging_writer.py:48] [496100] global_step=496100, grad_norm=3.0200610160827637, loss=2.0976245403289795
I0305 06:48:12.022808 140239850956544 logging_writer.py:48] [496200] global_step=496200, grad_norm=2.8891947269439697, loss=1.3933805227279663
I0305 06:48:57.266299 140239842563840 logging_writer.py:48] [496300] global_step=496300, grad_norm=3.9977076053619385, loss=2.640265464782715
I0305 06:49:42.602839 140239850956544 logging_writer.py:48] [496400] global_step=496400, grad_norm=3.0213685035705566, loss=1.0512996912002563
I0305 06:50:28.133452 140239842563840 logging_writer.py:48] [496500] global_step=496500, grad_norm=2.8992953300476074, loss=2.205711603164673
I0305 06:51:13.477222 140239850956544 logging_writer.py:48] [496600] global_step=496600, grad_norm=3.0711872577667236, loss=1.0757803916931152
I0305 06:51:39.010828 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:51:49.306723 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 06:52:26.857149 140437341357888 spec.py:349] Evaluating on the test split.
I0305 06:52:28.479861 140437341357888 submission_runner.py:411] Time since start: 242390.03s, 	Step: 496658, 	{'train/accuracy': 0.8859961032867432, 'train/loss': 0.4209813177585602, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 222272.18267846107, 'total_duration': 242390.0301771164, 'accumulated_submission_time': 222272.18267846107, 'accumulated_eval_time': 20045.42670416832, 'accumulated_logging_time': 45.213632106781006}
I0305 06:52:28.570940 140239842563840 logging_writer.py:48] [496658] accumulated_eval_time=20045.426704, accumulated_logging_time=45.213632, accumulated_submission_time=222272.182678, global_step=496658, preemption_count=0, score=222272.182678, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=242390.030177, train/accuracy=0.885996, train/loss=0.420981, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 06:52:45.598983 140239850956544 logging_writer.py:48] [496700] global_step=496700, grad_norm=2.8332808017730713, loss=1.2792222499847412
I0305 06:53:27.746366 140239842563840 logging_writer.py:48] [496800] global_step=496800, grad_norm=3.2565152645111084, loss=1.2215278148651123
I0305 06:54:13.379045 140239850956544 logging_writer.py:48] [496900] global_step=496900, grad_norm=3.038618803024292, loss=1.1358814239501953
I0305 06:54:59.136459 140239842563840 logging_writer.py:48] [497000] global_step=497000, grad_norm=3.096658229827881, loss=1.1639368534088135
I0305 06:55:44.248863 140239850956544 logging_writer.py:48] [497100] global_step=497100, grad_norm=3.1181986331939697, loss=1.1462204456329346
I0305 06:56:29.511926 140239842563840 logging_writer.py:48] [497200] global_step=497200, grad_norm=3.266712188720703, loss=1.3657759428024292
I0305 06:57:14.878481 140239850956544 logging_writer.py:48] [497300] global_step=497300, grad_norm=3.3447253704071045, loss=1.0313340425491333
I0305 06:57:59.896881 140239842563840 logging_writer.py:48] [497400] global_step=497400, grad_norm=3.058265209197998, loss=1.1136351823806763
I0305 06:58:45.325524 140239850956544 logging_writer.py:48] [497500] global_step=497500, grad_norm=3.013779878616333, loss=2.2323360443115234
I0305 06:59:28.639075 140437341357888 spec.py:321] Evaluating on the training split.
I0305 06:59:39.166040 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:00:02.894700 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:00:04.523038 140437341357888 submission_runner.py:411] Time since start: 242846.07s, 	Step: 497598, 	{'train/accuracy': 0.8863281011581421, 'train/loss': 0.4229179620742798, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 222692.19125318527, 'total_duration': 242846.07332277298, 'accumulated_submission_time': 222692.19125318527, 'accumulated_eval_time': 20081.30944299698, 'accumulated_logging_time': 45.31370210647583}
I0305 07:00:04.636238 140239842563840 logging_writer.py:48] [497598] accumulated_eval_time=20081.309443, accumulated_logging_time=45.313702, accumulated_submission_time=222692.191253, global_step=497598, preemption_count=0, score=222692.191253, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=242846.073323, train/accuracy=0.886328, train/loss=0.422918, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:00:05.831052 140239850956544 logging_writer.py:48] [497600] global_step=497600, grad_norm=3.0301458835601807, loss=1.2072954177856445
I0305 07:00:48.334872 140239842563840 logging_writer.py:48] [497700] global_step=497700, grad_norm=2.845942735671997, loss=1.077800989151001
I0305 07:01:34.059840 140239850956544 logging_writer.py:48] [497800] global_step=497800, grad_norm=2.906215190887451, loss=1.0823566913604736
I0305 07:02:19.432387 140239842563840 logging_writer.py:48] [497900] global_step=497900, grad_norm=2.9424073696136475, loss=1.180911898612976
I0305 07:03:05.407326 140239850956544 logging_writer.py:48] [498000] global_step=498000, grad_norm=2.9095497131347656, loss=2.2732105255126953
I0305 07:03:50.912049 140239842563840 logging_writer.py:48] [498100] global_step=498100, grad_norm=3.7005722522735596, loss=3.2274365425109863
I0305 07:04:36.777740 140239850956544 logging_writer.py:48] [498200] global_step=498200, grad_norm=2.928330421447754, loss=1.1512527465820312
I0305 07:05:22.596860 140239842563840 logging_writer.py:48] [498300] global_step=498300, grad_norm=2.901792049407959, loss=0.9666869640350342
I0305 07:06:08.295257 140239850956544 logging_writer.py:48] [498400] global_step=498400, grad_norm=3.004720449447632, loss=1.27229642868042
I0305 07:06:53.900602 140239842563840 logging_writer.py:48] [498500] global_step=498500, grad_norm=2.924186944961548, loss=2.3041553497314453
I0305 07:07:04.664191 140437341357888 spec.py:321] Evaluating on the training split.
I0305 07:07:15.373926 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:07:45.109742 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:07:46.726901 140437341357888 submission_runner.py:411] Time since start: 243308.28s, 	Step: 498525, 	{'train/accuracy': 0.8882030844688416, 'train/loss': 0.41538047790527344, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 223112.15406513214, 'total_duration': 243308.27743959427, 'accumulated_submission_time': 223112.15406513214, 'accumulated_eval_time': 20123.3711745739, 'accumulated_logging_time': 45.43738150596619}
I0305 07:07:46.843217 140239850956544 logging_writer.py:48] [498525] accumulated_eval_time=20123.371175, accumulated_logging_time=45.437382, accumulated_submission_time=223112.154065, global_step=498525, preemption_count=0, score=223112.154065, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=243308.277440, train/accuracy=0.888203, train/loss=0.415380, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:08:17.632219 140239842563840 logging_writer.py:48] [498600] global_step=498600, grad_norm=3.17806077003479, loss=2.7959227561950684
I0305 07:09:02.838783 140239850956544 logging_writer.py:48] [498700] global_step=498700, grad_norm=3.3283934593200684, loss=1.1186435222625732
I0305 07:09:48.119412 140239842563840 logging_writer.py:48] [498800] global_step=498800, grad_norm=3.006464958190918, loss=1.076432228088379
I0305 07:10:33.469643 140239850956544 logging_writer.py:48] [498900] global_step=498900, grad_norm=3.821789264678955, loss=3.1918606758117676
I0305 07:11:18.772300 140239842563840 logging_writer.py:48] [499000] global_step=499000, grad_norm=3.023345947265625, loss=1.0378663539886475
I0305 07:12:04.270600 140239850956544 logging_writer.py:48] [499100] global_step=499100, grad_norm=3.4310762882232666, loss=1.0924913883209229
I0305 07:12:49.783447 140239842563840 logging_writer.py:48] [499200] global_step=499200, grad_norm=3.2204582691192627, loss=1.3461582660675049
I0305 07:13:35.022125 140239850956544 logging_writer.py:48] [499300] global_step=499300, grad_norm=2.9388134479522705, loss=1.5718556642532349
I0305 07:14:20.205439 140239842563840 logging_writer.py:48] [499400] global_step=499400, grad_norm=3.723958969116211, loss=3.2072606086730957
I0305 07:14:46.961536 140437341357888 spec.py:321] Evaluating on the training split.
I0305 07:14:57.249070 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:15:28.610794 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:15:30.236227 140437341357888 submission_runner.py:411] Time since start: 243771.79s, 	Step: 499461, 	{'train/accuracy': 0.8899218440055847, 'train/loss': 0.4086339771747589, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 223532.21031570435, 'total_duration': 243771.78656983376, 'accumulated_submission_time': 223532.21031570435, 'accumulated_eval_time': 20166.644693613052, 'accumulated_logging_time': 45.56512475013733}
I0305 07:15:30.349645 140239850956544 logging_writer.py:48] [499461] accumulated_eval_time=20166.644694, accumulated_logging_time=45.565125, accumulated_submission_time=223532.210316, global_step=499461, preemption_count=0, score=223532.210316, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=243771.786570, train/accuracy=0.889922, train/loss=0.408634, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:15:46.183651 140239842563840 logging_writer.py:48] [499500] global_step=499500, grad_norm=3.240356206893921, loss=1.0945868492126465
I0305 07:16:29.591613 140239850956544 logging_writer.py:48] [499600] global_step=499600, grad_norm=3.1046524047851562, loss=1.2459886074066162
I0305 07:17:15.041784 140239842563840 logging_writer.py:48] [499700] global_step=499700, grad_norm=3.6897852420806885, loss=3.2411484718322754
I0305 07:18:00.145466 140239850956544 logging_writer.py:48] [499800] global_step=499800, grad_norm=3.111309289932251, loss=1.7206014394760132
I0305 07:18:45.304404 140239842563840 logging_writer.py:48] [499900] global_step=499900, grad_norm=2.9492225646972656, loss=2.481382369995117
I0305 07:19:30.635008 140239850956544 logging_writer.py:48] [500000] global_step=500000, grad_norm=3.008617877960205, loss=1.3926472663879395
I0305 07:20:16.088149 140239842563840 logging_writer.py:48] [500100] global_step=500100, grad_norm=2.880747079849243, loss=1.1253705024719238
I0305 07:21:01.183849 140239850956544 logging_writer.py:48] [500200] global_step=500200, grad_norm=2.8105690479278564, loss=1.1031848192214966
I0305 07:21:46.357537 140239842563840 logging_writer.py:48] [500300] global_step=500300, grad_norm=3.0117833614349365, loss=1.1279537677764893
I0305 07:22:30.319610 140437341357888 spec.py:321] Evaluating on the training split.
I0305 07:22:40.762746 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:23:12.754218 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:23:14.409235 140437341357888 submission_runner.py:411] Time since start: 244235.96s, 	Step: 500399, 	{'train/accuracy': 0.8868749737739563, 'train/loss': 0.4158554673194885, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 223952.1179277897, 'total_duration': 244235.95967531204, 'accumulated_submission_time': 223952.1179277897, 'accumulated_eval_time': 20210.7332572937, 'accumulated_logging_time': 45.69040513038635}
I0305 07:23:14.538957 140239850956544 logging_writer.py:48] [500399] accumulated_eval_time=20210.733257, accumulated_logging_time=45.690405, accumulated_submission_time=223952.117928, global_step=500399, preemption_count=0, score=223952.117928, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=244235.959675, train/accuracy=0.886875, train/loss=0.415855, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:23:15.346318 140239842563840 logging_writer.py:48] [500400] global_step=500400, grad_norm=2.792811155319214, loss=1.9023724794387817
I0305 07:23:55.382825 140239850956544 logging_writer.py:48] [500500] global_step=500500, grad_norm=3.401512384414673, loss=2.9512572288513184
I0305 07:24:40.571085 140239842563840 logging_writer.py:48] [500600] global_step=500600, grad_norm=2.992074728012085, loss=1.325561285018921
I0305 07:25:26.308846 140239850956544 logging_writer.py:48] [500700] global_step=500700, grad_norm=3.250408172607422, loss=2.6144089698791504
I0305 07:26:11.460655 140239842563840 logging_writer.py:48] [500800] global_step=500800, grad_norm=2.8088762760162354, loss=1.1011006832122803
I0305 07:26:56.698526 140239850956544 logging_writer.py:48] [500900] global_step=500900, grad_norm=3.0930123329162598, loss=1.1986706256866455
I0305 07:27:41.900576 140239842563840 logging_writer.py:48] [501000] global_step=501000, grad_norm=3.1753909587860107, loss=1.0247435569763184
I0305 07:28:26.931211 140239850956544 logging_writer.py:48] [501100] global_step=501100, grad_norm=3.525390625, loss=3.2165884971618652
I0305 07:29:12.248259 140239842563840 logging_writer.py:48] [501200] global_step=501200, grad_norm=2.9985365867614746, loss=1.4731378555297852
I0305 07:29:57.355846 140239850956544 logging_writer.py:48] [501300] global_step=501300, grad_norm=3.044182300567627, loss=2.5980255603790283
I0305 07:30:14.748350 140437341357888 spec.py:321] Evaluating on the training split.
I0305 07:30:25.046787 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:30:57.996239 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:30:59.621215 140437341357888 submission_runner.py:411] Time since start: 244701.17s, 	Step: 501340, 	{'train/accuracy': 0.8868359327316284, 'train/loss': 0.41674742102622986, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 224372.26052856445, 'total_duration': 244701.171677351, 'accumulated_submission_time': 224372.26052856445, 'accumulated_eval_time': 20255.60511660576, 'accumulated_logging_time': 45.836000204086304}
I0305 07:30:59.735434 140239842563840 logging_writer.py:48] [501340] accumulated_eval_time=20255.605117, accumulated_logging_time=45.836000, accumulated_submission_time=224372.260529, global_step=501340, preemption_count=0, score=224372.260529, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=244701.171677, train/accuracy=0.886836, train/loss=0.416747, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:31:23.947467 140239850956544 logging_writer.py:48] [501400] global_step=501400, grad_norm=3.051706075668335, loss=1.128718614578247
I0305 07:32:08.156998 140239842563840 logging_writer.py:48] [501500] global_step=501500, grad_norm=3.394085168838501, loss=1.1798155307769775
I0305 07:32:53.402133 140239850956544 logging_writer.py:48] [501600] global_step=501600, grad_norm=3.007486581802368, loss=2.532982587814331
I0305 07:33:39.140461 140239842563840 logging_writer.py:48] [501700] global_step=501700, grad_norm=3.3953776359558105, loss=1.095709204673767
I0305 07:34:24.123709 140239850956544 logging_writer.py:48] [501800] global_step=501800, grad_norm=3.271590232849121, loss=2.8806653022766113
I0305 07:35:09.693071 140239842563840 logging_writer.py:48] [501900] global_step=501900, grad_norm=3.752300977706909, loss=3.1060147285461426
I0305 07:35:54.632836 140239850956544 logging_writer.py:48] [502000] global_step=502000, grad_norm=3.6908159255981445, loss=3.148172616958618
I0305 07:36:40.139492 140239842563840 logging_writer.py:48] [502100] global_step=502100, grad_norm=2.945563316345215, loss=1.2542102336883545
I0305 07:37:25.505580 140239850956544 logging_writer.py:48] [502200] global_step=502200, grad_norm=3.1316580772399902, loss=1.1635671854019165
I0305 07:37:59.844679 140437341357888 spec.py:321] Evaluating on the training split.
I0305 07:38:10.776789 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:38:36.618341 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:38:38.243717 140437341357888 submission_runner.py:411] Time since start: 245159.79s, 	Step: 502278, 	{'train/accuracy': 0.8883398175239563, 'train/loss': 0.4172844886779785, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 224792.3078968525, 'total_duration': 245159.79407262802, 'accumulated_submission_time': 224792.3078968525, 'accumulated_eval_time': 20294.00301527977, 'accumulated_logging_time': 45.96119236946106}
I0305 07:38:38.360202 140239842563840 logging_writer.py:48] [502278] accumulated_eval_time=20294.003015, accumulated_logging_time=45.961192, accumulated_submission_time=224792.307897, global_step=502278, preemption_count=0, score=224792.307897, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=245159.794073, train/accuracy=0.888340, train/loss=0.417284, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:38:47.491709 140239850956544 logging_writer.py:48] [502300] global_step=502300, grad_norm=3.194350481033325, loss=1.2021448612213135
I0305 07:39:30.271635 140239842563840 logging_writer.py:48] [502400] global_step=502400, grad_norm=3.1310133934020996, loss=2.5378081798553467
I0305 07:40:15.324789 140239850956544 logging_writer.py:48] [502500] global_step=502500, grad_norm=4.676651954650879, loss=1.863031268119812
I0305 07:41:00.700859 140239842563840 logging_writer.py:48] [502600] global_step=502600, grad_norm=3.6684536933898926, loss=1.2449644804000854
I0305 07:41:45.938660 140239850956544 logging_writer.py:48] [502700] global_step=502700, grad_norm=3.255394697189331, loss=1.173364520072937
I0305 07:42:31.233360 140239842563840 logging_writer.py:48] [502800] global_step=502800, grad_norm=3.0164835453033447, loss=1.114587664604187
I0305 07:43:16.474822 140239850956544 logging_writer.py:48] [502900] global_step=502900, grad_norm=3.2423722743988037, loss=2.671236515045166
I0305 07:44:02.087598 140239842563840 logging_writer.py:48] [503000] global_step=503000, grad_norm=3.1830344200134277, loss=1.248202919960022
I0305 07:44:47.786113 140239850956544 logging_writer.py:48] [503100] global_step=503100, grad_norm=2.831441640853882, loss=1.445107102394104
I0305 07:45:33.095426 140239842563840 logging_writer.py:48] [503200] global_step=503200, grad_norm=3.2530195713043213, loss=2.9468045234680176
I0305 07:45:38.671165 140437341357888 spec.py:321] Evaluating on the training split.
I0305 07:45:49.137579 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:46:23.830885 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:46:25.459639 140437341357888 submission_runner.py:411] Time since start: 245627.01s, 	Step: 503214, 	{'train/accuracy': 0.8876562118530273, 'train/loss': 0.4177963137626648, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 225212.55551242828, 'total_duration': 245627.0100402832, 'accumulated_submission_time': 225212.55551242828, 'accumulated_eval_time': 20340.790374994278, 'accumulated_logging_time': 46.09040856361389}
I0305 07:46:25.568420 140239850956544 logging_writer.py:48] [503214] accumulated_eval_time=20340.790375, accumulated_logging_time=46.090409, accumulated_submission_time=225212.555512, global_step=503214, preemption_count=0, score=225212.555512, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=245627.010040, train/accuracy=0.887656, train/loss=0.417796, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:47:00.014042 140239842563840 logging_writer.py:48] [503300] global_step=503300, grad_norm=3.0734002590179443, loss=1.2658578157424927
I0305 07:47:45.050186 140239850956544 logging_writer.py:48] [503400] global_step=503400, grad_norm=3.5662693977355957, loss=1.1283143758773804
I0305 07:48:30.562023 140239842563840 logging_writer.py:48] [503500] global_step=503500, grad_norm=2.7011525630950928, loss=1.5564149618148804
I0305 07:49:15.976879 140239850956544 logging_writer.py:48] [503600] global_step=503600, grad_norm=3.420961856842041, loss=1.0533795356750488
I0305 07:50:00.980267 140239842563840 logging_writer.py:48] [503700] global_step=503700, grad_norm=3.264251708984375, loss=1.1490886211395264
I0305 07:50:46.301064 140239850956544 logging_writer.py:48] [503800] global_step=503800, grad_norm=3.1864795684814453, loss=1.1694375276565552
I0305 07:51:31.590729 140239842563840 logging_writer.py:48] [503900] global_step=503900, grad_norm=3.23009991645813, loss=1.8576459884643555
I0305 07:52:16.506062 140239850956544 logging_writer.py:48] [504000] global_step=504000, grad_norm=3.502997875213623, loss=3.284771203994751
I0305 07:53:01.451875 140239842563840 logging_writer.py:48] [504100] global_step=504100, grad_norm=2.935255289077759, loss=1.1819897890090942
I0305 07:53:25.858134 140437341357888 spec.py:321] Evaluating on the training split.
I0305 07:53:36.396473 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 07:54:02.680600 140437341357888 spec.py:349] Evaluating on the test split.
I0305 07:54:04.298500 140437341357888 submission_runner.py:411] Time since start: 246085.85s, 	Step: 504153, 	{'train/accuracy': 0.8895312547683716, 'train/loss': 0.41464972496032715, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 225632.78150820732, 'total_duration': 246085.8487613201, 'accumulated_submission_time': 225632.78150820732, 'accumulated_eval_time': 20379.229496002197, 'accumulated_logging_time': 46.2122004032135}
I0305 07:54:04.420398 140239850956544 logging_writer.py:48] [504153] accumulated_eval_time=20379.229496, accumulated_logging_time=46.212200, accumulated_submission_time=225632.781508, global_step=504153, preemption_count=0, score=225632.781508, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=246085.848761, train/accuracy=0.889531, train/loss=0.414650, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 07:54:23.433114 140239842563840 logging_writer.py:48] [504200] global_step=504200, grad_norm=2.917912006378174, loss=1.493586540222168
I0305 07:55:07.744784 140239850956544 logging_writer.py:48] [504300] global_step=504300, grad_norm=3.0089633464813232, loss=2.2725613117218018
I0305 07:55:52.855593 140239842563840 logging_writer.py:48] [504400] global_step=504400, grad_norm=3.0847766399383545, loss=1.0449979305267334
I0305 07:56:38.607520 140239850956544 logging_writer.py:48] [504500] global_step=504500, grad_norm=2.9964699745178223, loss=1.2722543478012085
I0305 07:57:23.948652 140239842563840 logging_writer.py:48] [504600] global_step=504600, grad_norm=2.8463995456695557, loss=1.2149178981781006
I0305 07:58:09.366654 140239850956544 logging_writer.py:48] [504700] global_step=504700, grad_norm=2.9889309406280518, loss=1.1062005758285522
I0305 07:58:54.377128 140239842563840 logging_writer.py:48] [504800] global_step=504800, grad_norm=2.857023000717163, loss=1.1430845260620117
I0305 07:59:39.695150 140239850956544 logging_writer.py:48] [504900] global_step=504900, grad_norm=2.970824718475342, loss=1.9361461400985718
I0305 08:00:24.900820 140239842563840 logging_writer.py:48] [505000] global_step=505000, grad_norm=3.032524585723877, loss=2.568396806716919
I0305 08:01:04.655814 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:01:15.353595 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:01:49.305174 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:01:50.926980 140437341357888 submission_runner.py:411] Time since start: 246552.48s, 	Step: 505090, 	{'train/accuracy': 0.8879687190055847, 'train/loss': 0.4165275990962982, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 226052.95351052284, 'total_duration': 246552.4772992134, 'accumulated_submission_time': 226052.95351052284, 'accumulated_eval_time': 20425.49946808815, 'accumulated_logging_time': 46.34702253341675}
I0305 08:01:51.038111 140239850956544 logging_writer.py:48] [505090] accumulated_eval_time=20425.499468, accumulated_logging_time=46.347023, accumulated_submission_time=226052.953511, global_step=505090, preemption_count=0, score=226052.953511, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=246552.477299, train/accuracy=0.887969, train/loss=0.416528, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:01:55.398641 140239842563840 logging_writer.py:48] [505100] global_step=505100, grad_norm=2.981642723083496, loss=1.1644212007522583
I0305 08:02:37.140203 140239850956544 logging_writer.py:48] [505200] global_step=505200, grad_norm=3.1164515018463135, loss=1.5814570188522339
I0305 08:03:22.054941 140239842563840 logging_writer.py:48] [505300] global_step=505300, grad_norm=3.038710355758667, loss=2.368302822113037
I0305 08:04:07.540106 140239850956544 logging_writer.py:48] [505400] global_step=505400, grad_norm=3.002980947494507, loss=1.467533826828003
I0305 08:04:53.276283 140239842563840 logging_writer.py:48] [505500] global_step=505500, grad_norm=2.99153470993042, loss=2.2522501945495605
I0305 08:05:38.514961 140239850956544 logging_writer.py:48] [505600] global_step=505600, grad_norm=3.0580835342407227, loss=1.152879238128662
I0305 08:06:23.841883 140239842563840 logging_writer.py:48] [505700] global_step=505700, grad_norm=3.11602520942688, loss=2.5958688259124756
I0305 08:07:09.377305 140239850956544 logging_writer.py:48] [505800] global_step=505800, grad_norm=3.048351764678955, loss=1.1532323360443115
I0305 08:07:54.410401 140239842563840 logging_writer.py:48] [505900] global_step=505900, grad_norm=3.008869171142578, loss=1.0573149919509888
I0305 08:08:39.711131 140239850956544 logging_writer.py:48] [506000] global_step=506000, grad_norm=3.6534416675567627, loss=3.1812777519226074
I0305 08:08:51.179410 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:09:01.411694 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:09:32.674000 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:09:34.289824 140437341357888 submission_runner.py:411] Time since start: 247015.84s, 	Step: 506027, 	{'train/accuracy': 0.8889062404632568, 'train/loss': 0.41194114089012146, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 226473.03325295448, 'total_duration': 247015.84028172493, 'accumulated_submission_time': 226473.03325295448, 'accumulated_eval_time': 20468.608820915222, 'accumulated_logging_time': 46.46912431716919}
I0305 08:09:34.405361 140239842563840 logging_writer.py:48] [506027] accumulated_eval_time=20468.608821, accumulated_logging_time=46.469124, accumulated_submission_time=226473.033253, global_step=506027, preemption_count=0, score=226473.033253, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=247015.840282, train/accuracy=0.888906, train/loss=0.411941, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:10:04.015621 140239850956544 logging_writer.py:48] [506100] global_step=506100, grad_norm=3.0360922813415527, loss=1.0905672311782837
I0305 08:10:48.810840 140239842563840 logging_writer.py:48] [506200] global_step=506200, grad_norm=2.9575469493865967, loss=1.0346201658248901
I0305 08:11:34.092162 140239850956544 logging_writer.py:48] [506300] global_step=506300, grad_norm=3.5186398029327393, loss=2.7421393394470215
I0305 08:12:19.462723 140239842563840 logging_writer.py:48] [506400] global_step=506400, grad_norm=3.0820980072021484, loss=1.455338716506958
I0305 08:13:04.503247 140239850956544 logging_writer.py:48] [506500] global_step=506500, grad_norm=3.7614176273345947, loss=3.2452192306518555
I0305 08:13:49.542221 140239842563840 logging_writer.py:48] [506600] global_step=506600, grad_norm=3.4547359943389893, loss=2.518655776977539
I0305 08:14:35.199366 140239850956544 logging_writer.py:48] [506700] global_step=506700, grad_norm=3.485872745513916, loss=1.1019119024276733
I0305 08:15:20.356324 140239842563840 logging_writer.py:48] [506800] global_step=506800, grad_norm=2.7601077556610107, loss=1.6066317558288574
I0305 08:16:05.671429 140239850956544 logging_writer.py:48] [506900] global_step=506900, grad_norm=3.566272258758545, loss=3.1100637912750244
I0305 08:16:34.418379 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:16:44.907770 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:17:16.316792 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:17:17.966799 140437341357888 submission_runner.py:411] Time since start: 247479.52s, 	Step: 506965, 	{'train/accuracy': 0.8897460699081421, 'train/loss': 0.41393592953681946, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 226892.98617458344, 'total_duration': 247479.51724481583, 'accumulated_submission_time': 226892.98617458344, 'accumulated_eval_time': 20512.156184911728, 'accumulated_logging_time': 46.59465575218201}
I0305 08:17:18.059811 140239842563840 logging_writer.py:48] [506965] accumulated_eval_time=20512.156185, accumulated_logging_time=46.594656, accumulated_submission_time=226892.986175, global_step=506965, preemption_count=0, score=226892.986175, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=247479.517245, train/accuracy=0.889746, train/loss=0.413936, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:17:32.345832 140239850956544 logging_writer.py:48] [507000] global_step=507000, grad_norm=2.9329538345336914, loss=1.2053916454315186
I0305 08:18:14.166790 140239842563840 logging_writer.py:48] [507100] global_step=507100, grad_norm=3.1996445655822754, loss=1.8074979782104492
I0305 08:18:59.299120 140239850956544 logging_writer.py:48] [507200] global_step=507200, grad_norm=3.0197525024414062, loss=1.3660533428192139
I0305 08:19:45.031374 140239842563840 logging_writer.py:48] [507300] global_step=507300, grad_norm=3.6735286712646484, loss=3.1320459842681885
I0305 08:20:29.779587 140239850956544 logging_writer.py:48] [507400] global_step=507400, grad_norm=2.9111220836639404, loss=0.9964087009429932
I0305 08:21:14.763985 140239842563840 logging_writer.py:48] [507500] global_step=507500, grad_norm=3.2924461364746094, loss=2.8166399002075195
I0305 08:21:59.830170 140239850956544 logging_writer.py:48] [507600] global_step=507600, grad_norm=3.3033318519592285, loss=1.3680899143218994
I0305 08:22:44.952040 140239842563840 logging_writer.py:48] [507700] global_step=507700, grad_norm=3.426175117492676, loss=2.8049542903900146
I0305 08:23:29.972493 140239850956544 logging_writer.py:48] [507800] global_step=507800, grad_norm=3.2775309085845947, loss=1.5492743253707886
I0305 08:24:15.190942 140239842563840 logging_writer.py:48] [507900] global_step=507900, grad_norm=3.4730143547058105, loss=1.2835208177566528
I0305 08:24:18.062043 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:24:28.383907 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:24:56.396809 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:24:58.020582 140437341357888 submission_runner.py:411] Time since start: 247939.57s, 	Step: 507908, 	{'train/accuracy': 0.8889257907867432, 'train/loss': 0.411639004945755, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 227312.9258275032, 'total_duration': 247939.57105445862, 'accumulated_submission_time': 227312.9258275032, 'accumulated_eval_time': 20552.11368203163, 'accumulated_logging_time': 46.699103116989136}
I0305 08:24:58.137793 140239850956544 logging_writer.py:48] [507908] accumulated_eval_time=20552.113682, accumulated_logging_time=46.699103, accumulated_submission_time=227312.925828, global_step=507908, preemption_count=0, score=227312.925828, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=247939.571054, train/accuracy=0.888926, train/loss=0.411639, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:25:36.393638 140239842563840 logging_writer.py:48] [508000] global_step=508000, grad_norm=3.041590690612793, loss=1.1260751485824585
I0305 08:26:21.565161 140239850956544 logging_writer.py:48] [508100] global_step=508100, grad_norm=2.750349760055542, loss=1.8825455904006958
I0305 08:27:07.241520 140239842563840 logging_writer.py:48] [508200] global_step=508200, grad_norm=2.984553337097168, loss=1.3490016460418701
I0305 08:27:52.376227 140239850956544 logging_writer.py:48] [508300] global_step=508300, grad_norm=3.1070127487182617, loss=1.1865999698638916
I0305 08:28:37.497219 140239842563840 logging_writer.py:48] [508400] global_step=508400, grad_norm=3.1446356773376465, loss=1.08757483959198
I0305 08:29:22.663480 140239850956544 logging_writer.py:48] [508500] global_step=508500, grad_norm=3.051460027694702, loss=1.565407395362854
I0305 08:30:07.796846 140239842563840 logging_writer.py:48] [508600] global_step=508600, grad_norm=3.121508836746216, loss=1.1295998096466064
I0305 08:30:53.022045 140239850956544 logging_writer.py:48] [508700] global_step=508700, grad_norm=3.083839178085327, loss=1.6091312170028687
I0305 08:31:38.403569 140239842563840 logging_writer.py:48] [508800] global_step=508800, grad_norm=3.2432217597961426, loss=1.1616746187210083
I0305 08:31:58.087881 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:32:08.944061 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:32:36.027612 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:32:37.658353 140437341357888 submission_runner.py:411] Time since start: 248399.21s, 	Step: 508845, 	{'train/accuracy': 0.8868945240974426, 'train/loss': 0.4153727889060974, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 227732.81487941742, 'total_duration': 248399.20882964134, 'accumulated_submission_time': 227732.81487941742, 'accumulated_eval_time': 20591.683132648468, 'accumulated_logging_time': 46.82708263397217}
I0305 08:32:37.773036 140239850956544 logging_writer.py:48] [508845] accumulated_eval_time=20591.683133, accumulated_logging_time=46.827083, accumulated_submission_time=227732.814879, global_step=508845, preemption_count=0, score=227732.814879, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=248399.208830, train/accuracy=0.886895, train/loss=0.415373, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:32:59.947748 140239842563840 logging_writer.py:48] [508900] global_step=508900, grad_norm=3.0399489402770996, loss=1.794407844543457
I0305 08:33:44.111500 140239850956544 logging_writer.py:48] [509000] global_step=509000, grad_norm=3.1625115871429443, loss=2.2558462619781494
I0305 08:34:29.276772 140239842563840 logging_writer.py:48] [509100] global_step=509100, grad_norm=3.511166572570801, loss=3.0628769397735596
I0305 08:35:14.700039 140239850956544 logging_writer.py:48] [509200] global_step=509200, grad_norm=3.0346455574035645, loss=1.0450975894927979
I0305 08:35:59.827953 140239842563840 logging_writer.py:48] [509300] global_step=509300, grad_norm=3.840080499649048, loss=3.260751247406006
I0305 08:36:45.414496 140239850956544 logging_writer.py:48] [509400] global_step=509400, grad_norm=3.9678328037261963, loss=3.2151644229888916
I0305 08:37:30.860789 140239842563840 logging_writer.py:48] [509500] global_step=509500, grad_norm=2.8429224491119385, loss=2.2487785816192627
I0305 08:38:16.086695 140239850956544 logging_writer.py:48] [509600] global_step=509600, grad_norm=3.1074721813201904, loss=1.131274700164795
I0305 08:39:01.181447 140239842563840 logging_writer.py:48] [509700] global_step=509700, grad_norm=3.7650792598724365, loss=2.654534101486206
I0305 08:39:37.703103 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:39:48.135390 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:40:21.792460 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:40:23.424044 140437341357888 submission_runner.py:411] Time since start: 248864.97s, 	Step: 509782, 	{'train/accuracy': 0.8875781297683716, 'train/loss': 0.4177852272987366, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 228152.68364787102, 'total_duration': 248864.97451901436, 'accumulated_submission_time': 228152.68364787102, 'accumulated_eval_time': 20637.40304684639, 'accumulated_logging_time': 46.952224254608154}
I0305 08:40:23.539509 140239850956544 logging_writer.py:48] [509782] accumulated_eval_time=20637.403047, accumulated_logging_time=46.952224, accumulated_submission_time=228152.683648, global_step=509782, preemption_count=0, score=228152.683648, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=248864.974519, train/accuracy=0.887578, train/loss=0.417785, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:40:31.079845 140239842563840 logging_writer.py:48] [509800] global_step=509800, grad_norm=2.989529848098755, loss=1.078449010848999
I0305 08:41:13.356287 140239850956544 logging_writer.py:48] [509900] global_step=509900, grad_norm=2.9224770069122314, loss=1.3830658197402954
I0305 08:41:58.475820 140239842563840 logging_writer.py:48] [510000] global_step=510000, grad_norm=3.5375561714172363, loss=2.986395835876465
I0305 08:42:43.960460 140239850956544 logging_writer.py:48] [510100] global_step=510100, grad_norm=2.934098958969116, loss=1.0556185245513916
I0305 08:43:29.130514 140239842563840 logging_writer.py:48] [510200] global_step=510200, grad_norm=3.0183842182159424, loss=1.0992189645767212
I0305 08:44:14.663165 140239850956544 logging_writer.py:48] [510300] global_step=510300, grad_norm=3.7958829402923584, loss=3.1736040115356445
I0305 08:44:59.975836 140239842563840 logging_writer.py:48] [510400] global_step=510400, grad_norm=2.808558225631714, loss=1.0824178457260132
I0305 08:45:45.717077 140239850956544 logging_writer.py:48] [510500] global_step=510500, grad_norm=3.1715521812438965, loss=1.0830250978469849
I0305 08:46:30.825037 140239842563840 logging_writer.py:48] [510600] global_step=510600, grad_norm=3.2366507053375244, loss=1.1008435487747192
I0305 08:47:16.541697 140239850956544 logging_writer.py:48] [510700] global_step=510700, grad_norm=3.0607171058654785, loss=1.1609760522842407
I0305 08:47:23.884458 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:47:34.676994 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:48:05.890695 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:48:07.517056 140437341357888 submission_runner.py:411] Time since start: 249329.07s, 	Step: 510718, 	{'train/accuracy': 0.8883788585662842, 'train/loss': 0.4152357876300812, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 228572.96571731567, 'total_duration': 249329.06751060486, 'accumulated_submission_time': 228572.96571731567, 'accumulated_eval_time': 20681.034592151642, 'accumulated_logging_time': 47.079352617263794}
I0305 08:48:07.640326 140239842563840 logging_writer.py:48] [510718] accumulated_eval_time=20681.034592, accumulated_logging_time=47.079353, accumulated_submission_time=228572.965717, global_step=510718, preemption_count=0, score=228572.965717, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=249329.067511, train/accuracy=0.888379, train/loss=0.415236, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:48:41.067196 140239850956544 logging_writer.py:48] [510800] global_step=510800, grad_norm=2.8717458248138428, loss=0.9687259197235107
I0305 08:49:26.088157 140239842563840 logging_writer.py:48] [510900] global_step=510900, grad_norm=3.5006070137023926, loss=3.2024810314178467
I0305 08:50:11.533766 140239850956544 logging_writer.py:48] [511000] global_step=511000, grad_norm=3.632302761077881, loss=3.19551944732666
I0305 08:50:56.646787 140239842563840 logging_writer.py:48] [511100] global_step=511100, grad_norm=2.972510576248169, loss=1.1025662422180176
I0305 08:51:41.869781 140239850956544 logging_writer.py:48] [511200] global_step=511200, grad_norm=3.0518648624420166, loss=1.0065211057662964
I0305 08:52:27.034890 140239842563840 logging_writer.py:48] [511300] global_step=511300, grad_norm=3.019153594970703, loss=1.132503867149353
I0305 08:53:12.140882 140239850956544 logging_writer.py:48] [511400] global_step=511400, grad_norm=3.43896484375, loss=2.7439894676208496
I0305 08:53:57.201153 140239842563840 logging_writer.py:48] [511500] global_step=511500, grad_norm=3.6214613914489746, loss=3.060962677001953
I0305 08:54:42.307221 140239850956544 logging_writer.py:48] [511600] global_step=511600, grad_norm=3.045792579650879, loss=1.0904158353805542
I0305 08:55:07.889382 140437341357888 spec.py:321] Evaluating on the training split.
I0305 08:55:18.336501 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 08:55:49.095067 140437341357888 spec.py:349] Evaluating on the test split.
I0305 08:55:50.719015 140437341357888 submission_runner.py:411] Time since start: 249792.27s, 	Step: 511658, 	{'train/accuracy': 0.8885741829872131, 'train/loss': 0.4134371876716614, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 228993.1485798359, 'total_duration': 249792.2692861557, 'accumulated_submission_time': 228993.1485798359, 'accumulated_eval_time': 20723.862995624542, 'accumulated_logging_time': 47.216553688049316}
I0305 08:55:50.835242 140239842563840 logging_writer.py:48] [511658] accumulated_eval_time=20723.862996, accumulated_logging_time=47.216554, accumulated_submission_time=228993.148580, global_step=511658, preemption_count=0, score=228993.148580, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=249792.269286, train/accuracy=0.888574, train/loss=0.413437, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 08:56:08.044365 140239850956544 logging_writer.py:48] [511700] global_step=511700, grad_norm=3.28865385055542, loss=1.2607483863830566
I0305 08:56:51.013906 140239842563840 logging_writer.py:48] [511800] global_step=511800, grad_norm=3.1406772136688232, loss=1.207182765007019
I0305 08:57:36.309815 140239850956544 logging_writer.py:48] [511900] global_step=511900, grad_norm=3.084070920944214, loss=1.1983981132507324
I0305 08:58:21.793024 140239842563840 logging_writer.py:48] [512000] global_step=512000, grad_norm=2.9622859954833984, loss=1.1035860776901245
I0305 08:59:06.971053 140239850956544 logging_writer.py:48] [512100] global_step=512100, grad_norm=3.243941068649292, loss=1.1824140548706055
I0305 08:59:52.519148 140239842563840 logging_writer.py:48] [512200] global_step=512200, grad_norm=3.3697292804718018, loss=2.8479790687561035
I0305 09:00:37.982493 140239850956544 logging_writer.py:48] [512300] global_step=512300, grad_norm=2.8017466068267822, loss=1.0448143482208252
I0305 09:01:22.932234 140239842563840 logging_writer.py:48] [512400] global_step=512400, grad_norm=3.8948144912719727, loss=3.1560604572296143
I0305 09:02:08.108680 140239850956544 logging_writer.py:48] [512500] global_step=512500, grad_norm=2.871250867843628, loss=1.769728183746338
I0305 09:02:50.830166 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:03:01.285984 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:03:32.154875 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:03:33.777863 140437341357888 submission_runner.py:411] Time since start: 250255.33s, 	Step: 512596, 	{'train/accuracy': 0.8901171684265137, 'train/loss': 0.4124380052089691, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 229413.08163452148, 'total_duration': 250255.3282535076, 'accumulated_submission_time': 229413.08163452148, 'accumulated_eval_time': 20766.809602737427, 'accumulated_logging_time': 47.343963384628296}
I0305 09:03:33.902255 140239842563840 logging_writer.py:48] [512596] accumulated_eval_time=20766.809603, accumulated_logging_time=47.343963, accumulated_submission_time=229413.081635, global_step=512596, preemption_count=0, score=229413.081635, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=250255.328254, train/accuracy=0.890117, train/loss=0.412438, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:03:35.912184 140239850956544 logging_writer.py:48] [512600] global_step=512600, grad_norm=3.590024471282959, loss=2.947092294692993
I0305 09:04:17.559104 140239842563840 logging_writer.py:48] [512700] global_step=512700, grad_norm=3.2404444217681885, loss=2.94163179397583
I0305 09:05:02.521563 140239850956544 logging_writer.py:48] [512800] global_step=512800, grad_norm=3.516035795211792, loss=1.121410846710205
I0305 09:05:47.612732 140239842563840 logging_writer.py:48] [512900] global_step=512900, grad_norm=3.332646608352661, loss=1.1941934823989868
I0305 09:06:33.590806 140239850956544 logging_writer.py:48] [513000] global_step=513000, grad_norm=3.5628459453582764, loss=2.991429328918457
I0305 09:07:18.696632 140239842563840 logging_writer.py:48] [513100] global_step=513100, grad_norm=3.5277154445648193, loss=3.282975912094116
I0305 09:08:03.936615 140239850956544 logging_writer.py:48] [513200] global_step=513200, grad_norm=3.215824842453003, loss=1.273036241531372
I0305 09:08:49.288500 140239842563840 logging_writer.py:48] [513300] global_step=513300, grad_norm=3.111158609390259, loss=2.0288424491882324
I0305 09:09:34.802735 140239850956544 logging_writer.py:48] [513400] global_step=513400, grad_norm=3.0200014114379883, loss=2.052412271499634
I0305 09:10:19.979573 140239842563840 logging_writer.py:48] [513500] global_step=513500, grad_norm=3.180724859237671, loss=1.1669002771377563
I0305 09:10:34.045634 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:10:44.636579 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:11:12.070149 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:11:13.728110 140437341357888 submission_runner.py:411] Time since start: 250715.28s, 	Step: 513533, 	{'train/accuracy': 0.8909960985183716, 'train/loss': 0.40929147601127625, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 229833.16347169876, 'total_duration': 250715.27859401703, 'accumulated_submission_time': 229833.16347169876, 'accumulated_eval_time': 20806.49105668068, 'accumulated_logging_time': 47.4794237613678}
I0305 09:11:13.913889 140239850956544 logging_writer.py:48] [513533] accumulated_eval_time=20806.491057, accumulated_logging_time=47.479424, accumulated_submission_time=229833.163472, global_step=513533, preemption_count=0, score=229833.163472, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=250715.278594, train/accuracy=0.890996, train/loss=0.409291, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:11:40.846765 140239842563840 logging_writer.py:48] [513600] global_step=513600, grad_norm=3.38308048248291, loss=2.754593849182129
I0305 09:12:24.664996 140239850956544 logging_writer.py:48] [513700] global_step=513700, grad_norm=3.2309811115264893, loss=2.382355213165283
I0305 09:13:09.878091 140239842563840 logging_writer.py:48] [513800] global_step=513800, grad_norm=2.88091778755188, loss=1.4108425378799438
I0305 09:13:55.092813 140239850956544 logging_writer.py:48] [513900] global_step=513900, grad_norm=2.8896052837371826, loss=1.3432198762893677
I0305 09:14:40.211773 140239842563840 logging_writer.py:48] [514000] global_step=514000, grad_norm=3.593552350997925, loss=1.7651805877685547
I0305 09:15:25.433809 140239850956544 logging_writer.py:48] [514100] global_step=514100, grad_norm=3.1055006980895996, loss=1.097156047821045
I0305 09:16:10.438947 140239842563840 logging_writer.py:48] [514200] global_step=514200, grad_norm=2.992462158203125, loss=1.025968074798584
I0305 09:16:55.946518 140239850956544 logging_writer.py:48] [514300] global_step=514300, grad_norm=3.183838367462158, loss=2.653965473175049
I0305 09:17:41.042623 140239842563840 logging_writer.py:48] [514400] global_step=514400, grad_norm=3.503671646118164, loss=3.0907135009765625
I0305 09:18:13.750892 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:18:24.282491 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:18:50.913199 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:18:52.557500 140437341357888 submission_runner.py:411] Time since start: 251174.11s, 	Step: 514474, 	{'train/accuracy': 0.8879101276397705, 'train/loss': 0.412520170211792, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 230252.9332678318, 'total_duration': 251174.10797166824, 'accumulated_submission_time': 230252.9332678318, 'accumulated_eval_time': 20845.29662656784, 'accumulated_logging_time': 47.680049657821655}
I0305 09:18:52.675254 140239850956544 logging_writer.py:48] [514474] accumulated_eval_time=20845.296627, accumulated_logging_time=47.680050, accumulated_submission_time=230252.933268, global_step=514474, preemption_count=0, score=230252.933268, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=251174.107972, train/accuracy=0.887910, train/loss=0.412520, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:19:03.381825 140239842563840 logging_writer.py:48] [514500] global_step=514500, grad_norm=2.8644347190856934, loss=2.4194326400756836
I0305 09:19:46.095521 140239850956544 logging_writer.py:48] [514600] global_step=514600, grad_norm=2.9240472316741943, loss=1.156259298324585
I0305 09:20:31.460496 140239842563840 logging_writer.py:48] [514700] global_step=514700, grad_norm=3.087501287460327, loss=1.119657278060913
I0305 09:21:16.584304 140239850956544 logging_writer.py:48] [514800] global_step=514800, grad_norm=2.9228098392486572, loss=1.4854397773742676
I0305 09:22:01.435844 140239842563840 logging_writer.py:48] [514900] global_step=514900, grad_norm=2.9669034481048584, loss=1.0560100078582764
I0305 09:22:46.775370 140239850956544 logging_writer.py:48] [515000] global_step=515000, grad_norm=3.2310054302215576, loss=1.2233606576919556
I0305 09:23:32.073186 140239842563840 logging_writer.py:48] [515100] global_step=515100, grad_norm=3.771728992462158, loss=1.207773208618164
I0305 09:24:17.092588 140239850956544 logging_writer.py:48] [515200] global_step=515200, grad_norm=3.092543840408325, loss=2.5246574878692627
I0305 09:25:02.348636 140239842563840 logging_writer.py:48] [515300] global_step=515300, grad_norm=3.125196933746338, loss=1.1292903423309326
I0305 09:25:47.346621 140239850956544 logging_writer.py:48] [515400] global_step=515400, grad_norm=3.025925874710083, loss=2.4043307304382324
I0305 09:25:52.869068 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:26:04.097189 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:26:33.868232 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:26:35.492632 140437341357888 submission_runner.py:411] Time since start: 251637.04s, 	Step: 515414, 	{'train/accuracy': 0.8891406059265137, 'train/loss': 0.4178435504436493, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 230673.0644853115, 'total_duration': 251637.04307699203, 'accumulated_submission_time': 230673.0644853115, 'accumulated_eval_time': 20887.919131040573, 'accumulated_logging_time': 47.809616804122925}
I0305 09:26:35.621791 140239842563840 logging_writer.py:48] [515414] accumulated_eval_time=20887.919131, accumulated_logging_time=47.809617, accumulated_submission_time=230673.064485, global_step=515414, preemption_count=0, score=230673.064485, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=251637.043077, train/accuracy=0.889141, train/loss=0.417844, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:27:11.163732 140239850956544 logging_writer.py:48] [515500] global_step=515500, grad_norm=3.161663293838501, loss=1.3402667045593262
I0305 09:27:56.179578 140239842563840 logging_writer.py:48] [515600] global_step=515600, grad_norm=3.0715737342834473, loss=2.0706539154052734
I0305 09:28:41.898513 140239850956544 logging_writer.py:48] [515700] global_step=515700, grad_norm=3.0214173793792725, loss=1.7006582021713257
I0305 09:29:27.252731 140239842563840 logging_writer.py:48] [515800] global_step=515800, grad_norm=3.667619466781616, loss=2.969700336456299
I0305 09:30:12.939523 140239850956544 logging_writer.py:48] [515900] global_step=515900, grad_norm=2.7634212970733643, loss=1.0550698041915894
I0305 09:30:58.296440 140239842563840 logging_writer.py:48] [516000] global_step=516000, grad_norm=3.1905834674835205, loss=2.6316778659820557
I0305 09:31:43.824913 140239850956544 logging_writer.py:48] [516100] global_step=516100, grad_norm=2.684955358505249, loss=1.7159020900726318
I0305 09:32:29.301867 140239842563840 logging_writer.py:48] [516200] global_step=516200, grad_norm=2.9439663887023926, loss=1.7972700595855713
I0305 09:33:14.864243 140239850956544 logging_writer.py:48] [516300] global_step=516300, grad_norm=3.025053024291992, loss=1.1072282791137695
I0305 09:33:35.867473 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:33:46.449904 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:34:21.677961 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:34:23.306294 140437341357888 submission_runner.py:411] Time since start: 252104.86s, 	Step: 516348, 	{'train/accuracy': 0.8887499570846558, 'train/loss': 0.41334712505340576, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 231093.2486963272, 'total_duration': 252104.85655498505, 'accumulated_submission_time': 231093.2486963272, 'accumulated_eval_time': 20935.356714487076, 'accumulated_logging_time': 47.949020862579346}
I0305 09:34:23.399633 140239842563840 logging_writer.py:48] [516348] accumulated_eval_time=20935.356714, accumulated_logging_time=47.949021, accumulated_submission_time=231093.248696, global_step=516348, preemption_count=0, score=231093.248696, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=252104.856555, train/accuracy=0.888750, train/loss=0.413347, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:34:44.387455 140239850956544 logging_writer.py:48] [516400] global_step=516400, grad_norm=2.973808526992798, loss=1.1441400051116943
I0305 09:35:27.254921 140239842563840 logging_writer.py:48] [516500] global_step=516500, grad_norm=3.0385468006134033, loss=1.9458575248718262
I0305 09:36:12.453443 140239850956544 logging_writer.py:48] [516600] global_step=516600, grad_norm=3.355910301208496, loss=1.1273380517959595
I0305 09:36:57.922033 140239842563840 logging_writer.py:48] [516700] global_step=516700, grad_norm=3.35718035697937, loss=2.8681232929229736
I0305 09:37:43.442516 140239850956544 logging_writer.py:48] [516800] global_step=516800, grad_norm=3.121920585632324, loss=1.1851567029953003
I0305 09:38:28.911330 140239842563840 logging_writer.py:48] [516900] global_step=516900, grad_norm=3.2894599437713623, loss=1.955553650856018
I0305 09:39:14.569598 140239850956544 logging_writer.py:48] [517000] global_step=517000, grad_norm=3.7199785709381104, loss=3.266200542449951
I0305 09:39:59.872109 140239842563840 logging_writer.py:48] [517100] global_step=517100, grad_norm=3.3759467601776123, loss=1.2242292165756226
I0305 09:40:45.338065 140239850956544 logging_writer.py:48] [517200] global_step=517200, grad_norm=2.955777883529663, loss=1.781470775604248
I0305 09:41:23.499270 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:41:33.946384 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:42:00.080666 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:42:01.710988 140437341357888 submission_runner.py:411] Time since start: 252563.26s, 	Step: 517285, 	{'train/accuracy': 0.8858202695846558, 'train/loss': 0.41800329089164734, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 231513.2865588665, 'total_duration': 252563.2615237236, 'accumulated_submission_time': 231513.2865588665, 'accumulated_eval_time': 20973.56746840477, 'accumulated_logging_time': 48.052809715270996}
I0305 09:42:01.851453 140239842563840 logging_writer.py:48] [517285] accumulated_eval_time=20973.567468, accumulated_logging_time=48.052810, accumulated_submission_time=231513.286559, global_step=517285, preemption_count=0, score=231513.286559, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=252563.261524, train/accuracy=0.885820, train/loss=0.418003, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:42:08.217097 140239850956544 logging_writer.py:48] [517300] global_step=517300, grad_norm=3.325061798095703, loss=1.196664810180664
I0305 09:42:50.783804 140239842563840 logging_writer.py:48] [517400] global_step=517400, grad_norm=3.349493980407715, loss=2.771265983581543
I0305 09:43:36.243617 140239850956544 logging_writer.py:48] [517500] global_step=517500, grad_norm=3.0860610008239746, loss=1.1922110319137573
I0305 09:44:21.994014 140239842563840 logging_writer.py:48] [517600] global_step=517600, grad_norm=2.9834749698638916, loss=1.0585370063781738
I0305 09:45:07.386265 140239850956544 logging_writer.py:48] [517700] global_step=517700, grad_norm=3.405977964401245, loss=3.0105552673339844
I0305 09:45:52.713544 140239842563840 logging_writer.py:48] [517800] global_step=517800, grad_norm=3.2767624855041504, loss=2.180309772491455
I0305 09:46:38.541148 140239850956544 logging_writer.py:48] [517900] global_step=517900, grad_norm=3.724581480026245, loss=3.317355155944824
I0305 09:47:24.307533 140239842563840 logging_writer.py:48] [518000] global_step=518000, grad_norm=3.184145212173462, loss=1.1378830671310425
I0305 09:48:09.558512 140239850956544 logging_writer.py:48] [518100] global_step=518100, grad_norm=3.811009168624878, loss=2.8957180976867676
I0305 09:48:54.887850 140239842563840 logging_writer.py:48] [518200] global_step=518200, grad_norm=2.9823241233825684, loss=2.257399559020996
I0305 09:49:02.222917 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:49:12.965051 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:49:46.757290 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:49:48.390930 140437341357888 submission_runner.py:411] Time since start: 253029.94s, 	Step: 518218, 	{'train/accuracy': 0.8895898461341858, 'train/loss': 0.4120994210243225, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 231933.59404420853, 'total_duration': 253029.94160294533, 'accumulated_submission_time': 231933.59404420853, 'accumulated_eval_time': 21019.734656095505, 'accumulated_logging_time': 48.206233501434326}
I0305 09:49:48.499110 140239850956544 logging_writer.py:48] [518218] accumulated_eval_time=21019.734656, accumulated_logging_time=48.206234, accumulated_submission_time=231933.594044, global_step=518218, preemption_count=0, score=231933.594044, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=253029.941603, train/accuracy=0.889590, train/loss=0.412099, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:50:22.183446 140239842563840 logging_writer.py:48] [518300] global_step=518300, grad_norm=3.0681099891662598, loss=2.141183376312256
I0305 09:51:07.467843 140239850956544 logging_writer.py:48] [518400] global_step=518400, grad_norm=4.016032695770264, loss=3.230462074279785
I0305 09:51:52.726830 140239842563840 logging_writer.py:48] [518500] global_step=518500, grad_norm=3.100667715072632, loss=1.0685306787490845
I0305 09:52:38.067590 140239850956544 logging_writer.py:48] [518600] global_step=518600, grad_norm=3.7001140117645264, loss=3.3363561630249023
I0305 09:53:23.123061 140239842563840 logging_writer.py:48] [518700] global_step=518700, grad_norm=3.6368014812469482, loss=2.6688711643218994
I0305 09:54:08.594970 140239850956544 logging_writer.py:48] [518800] global_step=518800, grad_norm=2.817868232727051, loss=1.2985230684280396
I0305 09:54:53.930019 140239842563840 logging_writer.py:48] [518900] global_step=518900, grad_norm=3.083078622817993, loss=1.218050479888916
I0305 09:55:39.336989 140239850956544 logging_writer.py:48] [519000] global_step=519000, grad_norm=2.821115255355835, loss=2.29122257232666
I0305 09:56:24.872767 140239842563840 logging_writer.py:48] [519100] global_step=519100, grad_norm=3.090221405029297, loss=1.1832139492034912
I0305 09:56:48.655342 140437341357888 spec.py:321] Evaluating on the training split.
I0305 09:56:59.065331 140437341357888 spec.py:333] Evaluating on the validation split.
I0305 09:57:32.863126 140437341357888 spec.py:349] Evaluating on the test split.
I0305 09:57:34.493345 140437341357888 submission_runner.py:411] Time since start: 253496.04s, 	Step: 519154, 	{'train/accuracy': 0.8883984088897705, 'train/loss': 0.4173663556575775, 'validation/accuracy': 0.7806599736213684, 'validation/loss': 0.8491368293762207, 'validation/num_examples': 50000, 'test/accuracy': 0.6628000140190125, 'test/loss': 1.439961552619934, 'test/num_examples': 10000, 'score': 232353.68795967102, 'total_duration': 253496.0437746048, 'accumulated_submission_time': 232353.68795967102, 'accumulated_eval_time': 21065.571618556976, 'accumulated_logging_time': 48.32579302787781}
I0305 09:57:34.610736 140239850956544 logging_writer.py:48] [519154] accumulated_eval_time=21065.571619, accumulated_logging_time=48.325793, accumulated_submission_time=232353.687960, global_step=519154, preemption_count=0, score=232353.687960, test/accuracy=0.662800, test/loss=1.439962, test/num_examples=10000, total_duration=253496.043775, train/accuracy=0.888398, train/loss=0.417366, validation/accuracy=0.780660, validation/loss=0.849137, validation/num_examples=50000
I0305 09:57:53.238462 140239842563840 logging_writer.py:48] [519200] global_step=519200, grad_norm=3.8540663719177246, loss=2.8467891216278076
I0305 09:58:37.157741 140239850956544 logging_writer.py:48] [519300] global_step=519300, grad_norm=2.9611804485321045, loss=1.1868929862976074
I0305 09:59:22.570426 140239842563840 logging_writer.py:48] [519400] global_step=519400, grad_norm=2.824129581451416, loss=1.350920557975769
I0305 10:00:08.174432 140239850956544 logging_writer.py:48] [519500] global_step=519500, grad_norm=3.336430072784424, loss=1.2433592081069946
I0305 10:00:53.190597 140239842563840 logging_writer.py:48] [519600] global_step=519600, grad_norm=2.926419496536255, loss=1.6422078609466553
I0305 10:01:01.481137 140239850956544 logging_writer.py:48] [519620] global_step=519620, preemption_count=0, score=232560.407587
I0305 10:01:02.258859 140437341357888 checkpoints.py:490] Saving checkpoint at step: 519620
I0305 10:01:03.919111 140437341357888 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification_self_tuning/study_3/imagenet_vit_jax/trial_1/checkpoint_519620
I0305 10:01:03.943818 140437341357888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification_self_tuning/study_3/imagenet_vit_jax/trial_1/checkpoint_519620.
I0305 10:01:05.039541 140437341357888 submission_runner.py:676] Final imagenet_vit score: 232560.4075872898
